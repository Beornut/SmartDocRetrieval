[{"title": "Dynamic Cutoff Prediction in Multi-Stage Retrieval Systems", "authors": ["J. Shane Culpepper\n,", "Charles L. A. Clarke\n,", "Jimmy Lin"], "publication": "ADCS '16: Proceedings of the 21st Australasian Document Computing Symposium", "abstract": "ABSTRACT\nModern multi-stage retrieval systems are comprised of a candidate generation stage followed by one or more reranking stages. In such an architecture, the quality of the final ranked list may not be sensitive to the quality of the initial candidate pool, especially in terms of early precision. This provides several opportunities to increase retrieval efficiency without significantly sacrificing effectiveness. In this paper, we explore a new approach to dynamically predicting the size of an initial result set in the candidate generation stage, which can directly affect the overall efficiency and effectiveness of the entire system. Previous work exploring this tradeoff has focused on global parameter settings that apply to all queries, even though optimal settings vary across queries. In contrast, we propose a technique that makes a parameter prediction to maximize efficiency within an effectiveness envelope on a per query basis, using only static pre-retrieval features. Experimental results show that substantial efficiency gains are achievable. In addition, our framework provides a versatile tool that can be used to estimate the effectiveness-efficiency tradeoffs that are possible before selecting and tuning algorithms to make machine-learned predictions.", "references": ["N. Asadi and J. Lin. Fast candidate generation for two-phase document ranking: Postings list intersection with Bloom filters. In Proc. CIKM, pages 2419--2422, 2012.", "N. Asadi and J. Lin. Document vector representations for feature extraction in multi-stage document ranking. Inf. Retr., 16(6):747--768, 2013.", "N. Asadi and J. Lin. Effectiveness/efficiency tradeoffs for candidate generation in multi-stage retrieval architectures. In Proc. SIGIR, pages 997--1000, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015022.3015026"}, {"title": "Using Navigation to Improve Recommendations in Real-Time", "authors": ["Chao-Yuan Wu\n,", "Christopher V. Alvino\n,", "Alexander J. Smola\n,", "Justin Basilico"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nImplicit feedback is a key source of information for many recommendation and personalization approaches. However, using it typically requires multiple episodes of interaction and roundtrips to a recommendation engine. This adds latency and neglects the opportunity of immediate personalization for a user while the user is navigating recommendations.\nWe propose a novel strategy to address the above problem in a principled manner. The key insight is that as we observe a user's interactions, it reveals much more information about her desires. We exploit this by inferring the within-session user intent on-the-fly based on navigation interactions, since they offer valuable clues into a user's current state of mind. Using navigation patterns and adapting recommendations in real-time creates an opportunity to provide more accurate recommendations. By prefetching a larger amount of content, this can be carried out entirely in the client (such as a browser) without added latency. We define a new Bayesian model with an efficient inference algorithm. We demonstrate significant improvements with this novel approach on a real-world, large-scale dataset from Netflix on the problem of adapting the recommendations on a user's homepage.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In KDD, pages 19--28. ACM, 2009.", "D. Agarwal and B.-C. Chen. FLDA: matrix factorization through latent Dirichlet allocation. In WSDM, pages 91--100. ACM, 2010.", "D. Agarwal, B.-C. Chen and P. Elango. Spatio-temporal models for estimating click-through rate. In WWW, pages 21--30. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959174"}, {"title": "When Watson Went to Work: Leveraging Cognitive Computing in the Real World", "authors": ["Aya Soffer\n,", "David Konopnicki\n,", "Haggai Roitman"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A Kalyanpur, Adam Lally, J William Murdock, Eric Nyberg, John Prager, et al. Building watson: An overview of the deepqa project. AI magazine, 31(3):59--79, 2010.", "Jonathan Herzig, Guy Feigenblat, Michal Shmueli-Scheuer, David Konopnicki, and Anat Rafaeli. Predicting customer satisfaction in customer support conversations in social media using affective features. In To be published in: User Modeling, Adaptation, and Personalization, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926724"}, {"title": "Lifecycle Modeling for Buzz Temporal Pattern Discovery", "authors": ["Yi Chang\n,", "Makoto Yamada\n,", "Antonio Ortega\n,", "Yan Liu"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nIn social media analysis, one critical task is detecting a burst of topics or buzz, which is reflected by extremely frequent mentions of certain keywords in a short-time interval. Detecting buzz not only provides useful insights into the information propagation mechanism, but also plays an essential role in preventing malicious rumors. However, buzz modeling is a challenging task because a buzz time-series often exhibits sudden spikes and heavy tails, wherein most existing time-series models fail. In this article, we propose novel buzz modeling approaches that capture the rise and fade temporal patterns via Product Lifecycle (PLC) model, a classical concept in economics. More specifically, we propose to model multiple peaks in buzz time-series with PLC mixture or PLC group mixture and develop a probabilistic graphical model (K-Mixture of Product Lifecycle (K-MPLC) to automatically discover inherent lifecycle patterns within a collection of buzzes. Furthermore, we effectively utilize the model parameters of PLC mixture or PLC group mixture for burst prediction. Our experimental results show that our proposed methods significantly outperform existing leading approaches on buzz clustering and buzz-type prediction.", "references": ["Gustavo Batista, Xiaoyue Wang, and Eamonn J. Keogh. 2011. A complexity-invariant distance measure for time series. In Proceedings of SDM.", "Christian Bauckhage, Kristian Kersting, and Fabian Hadiji. 2013. Mathematical models of fads explain the temporal dynamics of internet memes. In Proceedings of EMNLP.", "Christopher M. Bishop and Nasser M. Nasrabadi. 2006. Pattern Recognition and Machine Learning. Springer, New York, NY."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994605"}, {"title": "Collaborative Filtering Bandits", "authors": ["Shuai Li\n,", "Alexandros Karatzoglou\n,", "Claudio Gentile"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nClassical collaborative filtering, and content-based filtering methods try to learn a static recommendation model given training data. These approaches are far from ideal in highly dynamic recommendation domains such as news recommendation and computational advertisement, where the set of items and users is very fluid. In this work, we investigate an adaptive clustering technique for content recommendation based on exploration-exploitation strategies in contextual multi-armed bandit settings. Our algorithm takes into account the collaborative effects that arise due to the interaction of the users with the items, by dynamically grouping users based on the items under consideration and, at the same time, grouping items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on medium-size real-world datasets, showing scalability and increased prediction performance (as measured by click-through rate) over state-of-the-art methods for clustering bandits. We also provide a regret analysis within a standard linear stochastic noise setting.", "references": ["C. Gentile, S. Li, and G. Zappella. Online clustering of bandits. In ICML, 2014.", "N. Korda, B. Szorenyi, and S. Li, Distributed Clustering of Linear Bandits in Peer to Peer Networks. In ICML, 2016.", "Y. Abbasi-Yadkori, D. Pál, and C. Szepesvári. Improved algorithms for linear stochastic bandits. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911548"}, {"title": "Collaborative Filtering with Low Regret", "authors": ["Guy Bresler\n,", "Devavrat Shah\n,", "Luis Filipe Voloch"], "publication": "SIGMETRICS '16: Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science", "abstract": "ABSTRACT\nThere is much empirical evidence that item-item collaborative filtering works well in practice. Motivated to understand this, we provide a framework to design and analyze various recommendation algorithms. The setup amounts to online binary matrix completion, where at each time a random user requests a recommendation and the algorithm chooses an entry to reveal in the user's row. The goal is to minimize regret, or equivalently to maximize the number of +1 entries revealed at any time. We analyze an item-item collaborative filtering algorithm that can achieve fundamentally better performance compared to user-user collaborative filtering. The algorithm achieves good \"cold-start\" performance (appropriately defined) by quickly making good recommendations to new users about whom there is little information.", "references": ["N. Alon, N. Cesa-Bianchi, C. Gentile, S. Mannor, Y. Mansour, and O. Shamir. Nonstochastic multi-armed bandits with graph-structured feedback. arXiv Technical Report arXiv:1409.8428, 2014.", "S. Arora, R. Ge, R. Kannan, and A. Moitra. Computing a nonnegative matrix factorization-provably. In STOC, 2012.", "A. Bellogin and J. Parapar. Using graph partitioning techniques for neighbour selection in user-based collaborative filtering. In RecSys, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896377.2901469"}, {"title": "Relating Newcomer Personality to Survival and Activity in Recommender Systems", "authors": ["Raghav Pavan Karumur\n,", "Joseph A. Konstan"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nIn this work, we explore the degree to which personality information can be used to model newcomer retention, investment, intensity of engagement, and distribution of activity in a recommender community. Prior work shows that Big-Five Personality traits can explain variation in user behavior in other contexts. Building on this, we carry out and report on an analysis of 1008 MovieLens users with identified personality profiles. We find that Introverts and low Agreeableness users are more likely to survive into the second and subsequent sessions compared to their respective counterparts; Introverts and low Conscientiousness users are a significantly more active population compared to their respective counterparts; High Openness and High Neuroticism users contribute (tag) significantly more compared to their counterparts, but their counterparts consume (browse and bookmark) more; and low Agreeableness users are more likely to rate whereas high Agreeableness users are more likely to tag. These results show how modeling newcomer behavior from user personality can be useful for recommender systems designers as they customize the system to guide people towards tasks that need to be done or tasks the users will find rewarding and also decide which users to invest retention efforts in.", "references": ["Adomavicius, G. and Tuzhilin, A. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17, 6 (June 2005) 734--749. DOI= 10.1109/TKDE.2005.99.", "Amichai-Hamburger, Y. and Ben-Artzi, E. 2000. The relationship between extraversion and neuroticism and the different uses of the Internet. Computers in human behavior, 16, 4, (July 2000), 441--449.", "Amichai-Hamburger, Y., Wainapel, G. and Fox, S. 2002. \"On the Internet no one knows I?m an introvert\": Extroversion, neuroticism, and Internet interaction. Cyber Psychology & Behavior, 5, 2 (April 2002), 125--128."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930246"}, {"title": "What Users Actually Do in a Social Tagging System: A Study of User Behavior in BibSonomy", "authors": ["Stephan Doerfel\n,", "Daniel Zoller\n,", "Philipp Singer\n,", "Thomas Niebler\n,", "Andreas Hotho\n,", "Markus Strohmaier"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nSocial tagging systems have established themselves as an important part in today’s Web and have attracted the interest of our research community in a variety of investigations. Henceforth, several aspects of social tagging systems have been discussed and assumptions have emerged on which our community builds their work. Yet, testing such assumptions has been difficult due to the absence of suitable usage data in the past. In this work, we thoroughly investigate and evaluate four aspects about tagging systems, covering social interaction, retrieval of posted resources, the importance of the three different types of entities, users, resources, and tags, as well as connections between these entities’ popularity in posted and in requested content. For that purpose, we examine live server log data gathered from the real-world, public social tagging system BibSonomy. Our empirical results paint a mixed picture about the four aspects. Although typical assumptions hold to a certain extent for some, other aspects need to be reflected in a very critical light. Our observations have implications for the understanding of social tagging systems and the way they are used on the Web. We make the dataset used in this work available to other researchers.", "references": ["David Abrams, Ron Baecker, and Mark Chignell. 1998. Information archiving with bookmarks: Personal Web space construction and organization. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’98). ACM, New York, NY, 41--48. DOI:http://dx.doi.org/10.1145/274644.274651", "Maristella Agosti, Franco Crivellari, and GiorgioMaria Di Nunzio. 2012. Web log analysis: A review of a decade of studies about information acquisition, inspection and interpretation of user interaction. Data Mining and Knowledge Discovery 24, 3, 663--696. DOI:http://dx.doi.org/10.1007/s10618-011-0228-8", "Morgan Ames and Mor Naaman. 2007. Why we tag: Motivations for annotation in mobile and online media. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’07). ACM, New York, NY, 971--980. DOI:http://dx.doi.org/10.1145/1240624.1240772"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896821"}, {"title": "Adaptive fuzzy clustering by fast search and find of density peaks", "authors": ["Rongfang Bie\n,", "Rashid Mehmood\n,", "Shanshan Ruan\n,", "Yunchuan Sun\n,", "Hussain Dawood"], "publication": "Personal and Ubiquitous Computing", "abstract": "Abstract\nClustering by fast search and find of density peaks (CFSFDP) is proposed to cluster the data by finding of density peaks. CFSFDP is based on two assumptions that: a cluster center is a high dense data point as compared to its surrounding neighbors, and it lies at a large distance from other cluster centers. Based on these assumptions, CFSFDP supports a heuristic approach, known as decision graph to manually select cluster centers. Manual selection of cluster centers is a big limitation of CFSFDP in intelligent data analysis. In this paper, we proposed a fuzzy-CFSFDP method for adaptively selecting the cluster centers, effectively. It uses the fuzzy rules, based on aforementioned assumption for the selection of cluster centers. We performed a number of experiments on nine synthetic clustering datasets and compared the resulting clusters with the state-of-the-art methods. Clustering results and the comparisons of synthetic data validate the robustness and effectiveness of proposed fuzzy-CFSFDP method.", "references": ["Li K et al (2013) Personalized multi-modality image management and search for mobile devices. Pers Ubiquitous Comput 17(8):1817---1834", "Jiwen L, Erin LV, Xiuzhuang Z, Jie Z (2015) Learning compact binary face descriptor for face recognition. IEEE Trans Pattern Anal Mach Intell (TPAMI) 37(10):2041---2256", "Lu J, Zhou X, Tan Y-P, Shang Y, Zhou J (2014) Neighborhood repulsed metric learning for kinshipverification. IEEE Trans Pattern Anal Mach Intell (T-PAMI) 36(2):331---345"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00779-016-0954-4"}, {"title": "Distributed implementation of the latent Dirichlet allocation on Spark", "authors": ["Karim Sayadi\n,", "Quang Vu Bui\n,", "Marc Bui"], "publication": "SoICT '16: Proceedings of the Seventh Symposium on Information and Communication Technology", "abstract": "ABSTRACT\nThe Latent Dirichlet Allocation (LDA) is one of the most used topic models to discover complex semantic structure. However, for massive corpora of text LDA can be very slow and can require days or even months. This problem created a particular interest in parallel solutions, like the Approximate Distributed LDA (AD-LDA), where clusters of computers are used to approximates the popular Gibbs sampling used by LDA. Nevertheless, this solution has two main issues : first, requiring local copies on each partition of the cluster (this can be inconvenient for large datasets). Second, it is common to have read/write memory conflicts. In this article, we propose a new implementation of the AD-LDA algorithm where we provide computation in memory and a good communication between the processors. The implementation was made possible with the syntax of Spark. We show empirically with a set of experimentations that our parallel implementation with Spark has the same predictive power as the sequential version and has a considerable speedup. We finally document an analysis of the scalability of our implementation and the super-linearity that we obtained. We provide an open source version of our Spark LDA.", "references": ["mertterzihan/pymc, https://github.com/mertterzihan/pymc, 2015-07-02.", "A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In Proceedings of the fifth ACM international conference on Web search and data mining, pages 123--132. ACM, 2012.", "G. M. Amdahl. Validity of the single processor approach to achieving large scale computing capabilities. In Proceedings of the April 18--20, 1967, Spring Joint Computer Conference, AFIPS '67 (Spring), pages 483--485, New York, NY, USA, 1967. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011077.3011136"}, {"title": "Design Tradeoffs of Data Access Methods", "authors": ["Manos Athanassoulis\n,", "Stratos Idreos"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nDatabase researchers and practitioners have been building methods to store, access, and update data for more than five decades. Designing access methods has been a constant effort to adapt to the ever changing underlying hardware and workload requirements. The recent explosion in data system designs - including, in addition to traditional SQL systems, NoSQL, NewSQL, and other relational and non-relational systems - makes understanding the tradeoffs of designing access methods more important than ever. Access methods are at the core of any new data system. In this tutorial we survey recent developments in access method design and we place them in the design space where each approach focuses primarily on one or a subset of read performance, update performance, and memory utilization. We discuss how to utilize designs and lessons-learned from past research. In addition, we discuss new ideas on how to build access methods that have tunable behavior, as well as, what is the scenery of open research problems.", "references": ["D. J. Abadi et al. The Design and Implementation of Modern Column-Oriented Database Systems. Found. Trends Databases, 5(3):197--280, 2013.", "D. Agrawal, D. Ganesan, R. Sitaraman, Y. Diao, and S. Singh. Lazy-Adaptive Tree: An Optimized Index Structure for Flash Devices. PVLDB, 2(1):361--372, 2009.", "M. Athanassoulis and A. Ailamaki. BF-Tree: Approximate Tree Indexing. PVLDB, 7(14):1881--1892, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2912569"}, {"title": "Towards to Vector Plain Model", "authors": ["Sylvia Poulimenou\n,", "Sozon Papavlasopoulos\n,", "Sarantos Kapidakis\n,", "Marios Poulos"], "publication": "PETRA '16: Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nThis paper presents a knowledge representation document model, which is based on the classic information retrieval vector model. The aim of this paper is to reduce the level of complexity of the classical vector space model (VSM) and to simplify it by presenting an implementation on the plane. Furthermore, a comparison of tf-idf weighting scheme with the introduced Vector Plain Model (VPM) is presented. This method constitutes a significant tool for searching terms through auto-correlation and an innovating link between the scientific fields of information retrieval and quantitative linguistics.", "references": ["Abramowitz, M. and Stegun, I. A (Eds.) (1972). Probability Functions. Ch. 26 in Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables. New York: Dover. P. 925--964.", "Croft, B.W., Metzler D. and Strohman, T. (2010). Search Engines: information retrieval in practice. Boston: Pearson.", "Parzen, E (1962). On estimation of a probability density function and mode. The annals of mathematical statics. 33. P. 1065--1076."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910674.2910693"}, {"title": "Spoken Conversational Search: Speech-only Interactive Information Retrieval", "authors": ["Johanne R. Trippas"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThis research investigates a new interface paradigm for interactive information retrieval (IIR) which forces us to shift away from the classic \"ten blue links\" search engine results page. Instead we investigate how to present search results through a conversation over a speech-only communication channel where no screen is available. Accessing information via speech is becoming increasingly pervasive and is already important for people with a visual impairment. However, presenting search results over a speech-only communication channel is challenging due to cognitive limitations and the transient nature of audio. Studies have indicated that the implementation of speech recognizers and screen readers must be carefully designed and cannot simply be added to an existing system. Therefore the aim of this research is to develop a new interaction framework for effective and efficient IIR over a speech-only channel: a Spoken Conversational Search System (SCSS) which provides a conversational approach to defining user information needs, presenting results and enabling search reformulations. In order to contribute to a more efficient and effective search experience when using a SCSS, we intend for a tighter integration between document search and conversational processes.", "references": ["J. F. Allen, D. K. Byron, M. Dzikovska, G. Ferguson, L. Galescu, and A. Stent. Toward conversational human-computer interaction. AI magazine, 22 (4): 27, 2001.", "S. Azenkot and N. B. Lee. Exploring the use of speech input by blind people on mobile devices. In Proc. SIGACCESS, 2013.", "C. Baber, B. Mellor, R. Graham, J. M. Noyes, and C. Tunley. Workload and the use of automatic speech recognition: The effects of time and resource demands. Speech Communication, 20 (1): 37--53, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854952"}, {"title": "The ComeWithMe System for Searching and Ranking Activity-Based Carpooling Rides", "authors": ["Vinicius Monteiro de Lira\n,", "Chiara Renso\n,", "Raffaele Perego\n,", "Salvatore Rinzivillo\n,", "Valeria Cesario Times"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nComeWithMe is an activity oriented carpooling service that enlarges the candidate destinations of a ride request by considering alternative places where the desired activity can be performed. It is based on the observation that individuals often move towards a place to perform an activity while the activity is often not strictly associated with a single place, as one may go for shopping or eating to many different locations. Activity-oriented carpooling hugely increases the number of rides matching a query, thus introducing requirements on system responsiveness and ranking effectiveness that are not common to traditional carpooling services. The demoed system implements the ComeWithMe service in almost its entirety, and includes the back-end and a user-friendly mobile application for smart-phones aimed at achieving users' acceptance and usability.", "references": ["C. Carpineto and G. Romano. A survey of automatic query expansion in information retrieval. ACM Comput. Surv., 44(1):1:1--1:50, 2012.", "V. M. de Lira, S. Rinzivillo, C. Renso, V. C. Times, and P. C. A. R. Tedesco. Investigating semantic regularity of human mobility lifestyle. In IDEAS 2014, Portugal, July 7--9, 2014.", "V. Monteiro De Lira, V. C. Times, C. Renso, and S. Rinzivillo. ComeWithMe: An activity-oriented carpooling approach. In IEEE 18th International Conference on Intelligent Transportation Systems, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911459"}, {"title": "Pulse Repetition Interval Detection using Statistical Modeling", "authors": ["Amin Amiri Tehrani Zade\n,", "Amir Mansour Pezeshk"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nPulse Repetition Interval (PRI) Modulation Detection is an important subsystem of a typical electronic warfare support system. In this paper, a robust, fast, and well designed structure for detection of simple and complex PRI modulations based on statistical and sequential analysis of Pulse Repetition Interval (PRI) is proposed. Accuracy and robustness of the technique against electromagnetic noise are demonstrated via simulations.", "references": ["Nishiguchi, Ken Ichi, and Masaaki Kobayashi. 2000. Improved algorithm for estimating pulse repetition intervals. Aerospace and Electronic Systems, IEEE Transactions on 36, no. 2 (2000): 407--421.", "Milojević, D. J., and B. M. Popović. 1992. Improved algorithm for the deinterleaving of radar pulses. In IEE Proceedings F (Radar and Signal Processing), vol. 139, no. 1, pp. 98--104. IET Digital Library, (1992).", "Kauppi, Jukka-Pekka, Kalle Martikainen, and Ulla Ruotsalainen. 2010. Hierarchical classification of dynamically varying radar pulse repetition interval modulation patterns. Neural Networks 23, no. 10 (2010): 1226--1237."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015170"}, {"title": "Watson Concept Insights: A Conceptual Association Framework", "authors": ["Michele M. Franceschini\n,", "Livio B. Soares\n,", "Luis A. Lastras Montaño"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWatson Concept Insights (WCI) is a service that was recently made publicly available by IBM. WCI provides an information retrieval framework that is designed to facilitate search and exploration of text documents, and is particularly effective on sparse data sets. Its methodology consists of first defining a dictionary of concepts which are interconnected in a concept graph and then modeling a document by predicting its relevance to any given concept in the concept graph using the concepts that are directly mentioned in the document itself. This technique in effect increases the document recall for any given query, even for very sparse data sets, exposing the user to a variety of connections between their query and a data set of interest.", "references": ["R. T. Fielding. Architectural styles and the design of network-based software architectures. PhD thesis, University of California, Irvine, 2000.", "I. Land, S. Huettinger, P. Hoeher, J. B. Huber, et al. Bounds on information combining. Information Theory, IEEE Transactions on, 51(2):612--619, 2005.", "R. Mihalcea and A. Csomai. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 233--242. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890548"}, {"title": "Addressing Complex and Subjective Product-Related Queries with Customer Reviews", "authors": ["Julian McAuley\n,", "Alex Yang"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline reviews are often our first port of call when considering products and purchases online. When evaluating a potential purchase, we may have a specific query in mind, e.g. `will this baby seat fit in the overhead compartment of a 747?' or `will I like this album if I liked Taylor Swift's 1989?'. To answer such questions we must either wade through huge volumes of consumer reviews hoping to find one that is relevant, or otherwise pose our question directly to the community via a Q/A system.\nIn this paper we hope to fuse these two paradigms: given a large volume of previously answered queries about products, we hope to automatically learn whether a review of a product is relevant to a given query. We formulate this as a machine learning problem using a mixture-of-experts-type framework---here each review is an `expert' that gets to vote on the response to a particular query; simultaneously we learn a relevance function such that `relevant' reviews are those that vote correctly. At test time this learned relevance function allows us to surface reviews that are relevant to new queries on-demand. We evaluate our system, Moqa, on a novel corpus of 1.4 million questions (and answers) and 13 million reviews. We show quantitatively that it is effective at addressing both binary and open-ended queries, and qualitatively that it surfaces reviews that human evaluators consider to be relevant.", "references": ["E. Agichtein, C. Castillo, D. Donato, A. Gionis, and G. Mishne. Finding high-quality content in social media. In WSDM, 2008.", "A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec. Discovering value from community activity on focused question answering sites: a case study of Stack Overflow. In KDD, 2012.", "A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. Bridging the lexical chasm: statistical approaches to answer- finding. In SIGIR, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883044"}, {"title": "The automated formation of corporate groups for software projects: a systematic mapping", "authors": ["Gilberto Aguiar\n,", "Avanilde Kemczinski\n,", "Isabela Gasparini"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe process of selection of human resources for software projects is complex and subjective, requiring the project manager to assess and identify the knowledge and experience of professionals needed for the project. There is a natural difficulty existing in corporate environments with multiple projects in parallel. However in the context of software projects, specific requirements must be taken into consideration to the execution of the project, such as very specific skills that the individual should already know in the beginning of the project because there will be no time for the project to develop them. The goal of this paper is to verify in the literature what are the approaches adopted by researchers to automate the selection of individuals for team formation on software projects and their skills. For this purpose, this work conducts a systematic literature review. Four research questions were set and from them a search argument was used in seven academic search engines. 497 articles were found and after the criteria for inclusion and exclusion, 12 articles were analyzed. From them, genetic algorithms were identify as one of the approaches most used by the authors in order to automate the selection of individuals supported by a set of skills needed to design, however, it is notorious in the evaluated papers that each author uses a simplified set of individuals, in many cases pointing for example that the individual meets certain programming language only, without highlighting that the professional level of maturity, which in projects can be a differentiator.", "references": ["Alba, E., Chicano, J. Francisco. Software project management with gas. Inf. Sci., Elsevier Science Inc., New York, NY, USA, 2007.", "Andre, M., Baldoqun, M.G., Acuna, S.T. Formal model for assigning human resources to teams in software projects. Information and Software Technology, 2011.", "Barreto, A. Barros, M., Werner C. Staffing a software project: a constraint satisfaction and optimization-based approach. Computers and Operations Research, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022057"}, {"title": "A Reproducibility Study of Information Retrieval Models", "authors": ["Peilin Yang\n,", "Hui Fang"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nDeveloping effective information retrieval models has been a long standing challenge in Information Retrieval (IR), and significant progresses have been made over the years. With the increasing number of developed retrieval functions and the release of new data collections, it becomes more difficult, if not impossible, to compare a new retrieval function with all existing retrieval functions over all available data collections. To tackle thisproblem, this paper describes our efforts on constructing a platform that aims to improve the reproducibility of IR researchand facilitate the evaluation and comparison of retrieval functions. With the developed platform, more than 20 state of the art retrieval functions have been implemented and systematically evaluated over 16 standard TREC collections (including the newly released ClueWeb datasets). Our reproducibility study leads to several interesting observations. First, the performance difference between the reproduced results and those reported in the original papers is small for most retrieval functions. Second, the optimal performance of a few representative retrieval functions is still comparable over the new TREC ClueWeb collections. Finally, the developed platform (i.e., RISE) is made publicly available so that any IR researchers would be able to utilize it to evaluate other retrieval functions.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20(4):357--389, 2002.", "J. Arguello, F. Diaz, J. Lin, and A. Trotman. Sigir 2015 workshop on reproducibility, inexplicability, and generalizability of results (rigor). In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15, pages 1147--1148, New York, NY, USA, 2015. ACM.", "T. G. Armstrong, A. Moffat, W. Webber, and J. Zobel. Has adhoc retrieval improved since 1994? In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '09, pages 692--693, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970415"}, {"title": "^muzicode$: Composing and Performing Musical Codes", "authors": ["Chris Greenhalgh\n,", "Steve Benford\n,", "Adrian Hazzard"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nWe present muzicodes, an approach to incorporating machine-readable 'codes' into music that allows the performer and/or composer to flexibly define what constitutes a code, and to perform around it. These codes can then act as triggers, for example to control an accompaniment or visuals during a performance. The codes can form an integral part of the music (composition and/or performance), and may be more or less obviously present. This creates a rich space of playful interaction with a system that recognises and responds to the codes. Our proof of concept implementation works with audio or MIDI as input. Muzicodes are represented textually and regular expressions are used to flexibly define them. We present two contrasting demonstration applications and summarise the findings from two workshops with potential users which highlight opportunities and challenges, especially in relation to specifying and matching codes and playing and performing with the system.", "references": ["A. Shenton. 2008. Olivier Messiaen's system of signs: notes towards understanding his music. Ashgate Publishing, Ltd.", "J. Wingstedt, S. Brändström, and J. Berg. 2010. Narrative music, visuals and meaning in film. Vis. Commun. 9, 2, 193-- 210.", "E. Sams. 1970. Elgar's Cipher Letter to Dorabella. Music. Times, 151--154."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986444"}, {"title": "When Recommendation Goes Wrong: Anomalous Link Discovery in Recommendation Networks", "authors": ["Bryan Perozzi\n,", "Michael Schueppert\n,", "Jack Saalweachter\n,", "Mayur Thakur"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWe present a secondary ranking system to find and remove erroneous suggestions from a geospatial recommendation system. We discover such anomalous links by \"double checking\" the recommendation system's output to ensure that it is both structurally cohesive, and semantically consistent.\nOur approach is designed for the Google Related Places Graph, a geographic recommendation system which provides results for hundreds of millions of queries a day. We model the quality of a recommendation between two geographic entities as a function of their structure in the Related Places Graph, and their semantic relationship in the Google Knowledge Graph.\nTo evaluate our approach, we perform a large scale human evaluation of such an anomalous link detection system. For the long tail of unpopular entities, our models can predict the recommendations users will consider poor with up to 42\\% higher mean precision (29 raw points) than the live system.\nResults from our study reveal that structural and semantic features capture different facets of relatedness to human judges. We characterize our performance with a qualitative analysis detailing the categories of real-world anomalies our system is able to detect, and provide a discussion of additional applications of our method.", "references": ["L. Akoglu, H. Tong, and D. Koutra. Graph based anomaly detection and description: a survey. Data Mining and Knowledge Discovery, 29(3), 2015.", "M. Al Hasan, V. Chaoji, S. Salem, and M. Zaki. Link prediction using supervised learning. In SDM'06: Workshop on Link Analysis, Counter-terrorism and Security, 2006.", "X. Amatriain and J. Basilico. Net ix recommendations: Beyond the 5 stars (part 1). http://techblog.netix.com/2012/04/netix-recommendations-beyond-5-stars.html, May 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939734"}, {"title": "Diversity, Serendipity, Novelty, and Coverage: A Survey and Empirical Analysis of Beyond-Accuracy Objectives in Recommender Systems", "authors": ["Marius Kaminskas\n,", "Derek Bridge"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nWhat makes a good recommendation or good list of recommendations?\nResearch into recommender systems has traditionally focused on accuracy, in particular how closely the recommender’s predicted ratings are to the users’ true ratings. However, it has been recognized that other recommendation qualities—such as whether the list of recommendations is diverse and whether it contains novel items—may have a significant impact on the overall quality of a recommender system. Consequently, in recent years, the focus of recommender systems research has shifted to include a wider range of “beyond accuracy” objectives.\nIn this article, we present a survey of the most discussed beyond-accuracy objectives in recommender systems research: diversity, serendipity, novelty, and coverage. We review the definitions of these objectives and corresponding metrics found in the literature. We also review works that propose optimization strategies for these beyond-accuracy objectives. Since the majority of works focus on one specific objective, we find that it is not clear how the different objectives relate to each other.\nHence, we conduct a set of offline experiments aimed at comparing the performance of different optimization approaches with a view to seeing how they affect objectives other than the ones they are optimizing. We use a set of state-of-the-art recommendation algorithms optimized for recall along with a number of reranking strategies for optimizing the diversity, novelty, and serendipity of the generated recommendations. For each reranking strategy, we measure the effects on the other beyond-accuracy objectives and demonstrate important insights into the correlations between the discussed objectives. For instance, we find that rating-based diversity is positively correlated with novelty, and we demonstrate the positive influence of novelty on recommendation coverage.", "references": ["Panagiotis Adamopoulos and Alexander Tuzhilin. 2014. On unexpectedness in recommender systems: Or how to better expect the unexpected. ACM Transactions on Intelligent Systems and Technology (TIST) 5, 4 (2014), 54.", "Gediminas Adomavicius and YoungOk Kwon. 2011. Maximizing aggregate recommendation diversity: A graph-theoretic approach. In Proceedings of the 1st International Workshop on Novelty and Diversity in Recommender Systems (DiveRS’11). 3--10.", "Gediminas Adomavicius and YoungOk Kwon. 2012. Improving aggregate recommendation diversity using ranking-based techniques. IEEE Transactions on Knowledge and Data Engineering 24, 5 (2012), 896--911."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926720"}, {"title": "Recommendations with a Purpose", "authors": ["Dietmar Jannach\n,", "Gediminas Adomavicius"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe purpose of recommenders is often summarized as \"help the users find relevant items\", and the predominant operationalization of this goal has been to focus on the ability to numerically estimate the users' preferences for unseen items or to provide users with item lists ranked in accordance to the estimated preferences. This dominant, albeit narrow, view of the recommendation problem has been tremendously helpful in advancing research in different ways, e.g., through the establishment of standardized evaluation procedures and metrics. In reality, recommender systems can serve a variety of purposes from the point of view of both consumers and providers. Most of the purposes, however, are significantly underexplored, even though many of them are arguably more aligned with the real-world expectations for recommenders than our current predominant paradigm. Therefore, it is important to revisit our conceptualizations of the potential goals of recommenders and their operationalization as research problems. In this paper, we discuss a framework of recommendation goals and purposes and highlight possible future directions and challenges related to the operationalization of such alternative problem formulations.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE TKDE, 17(6):734--749, 2005.", "F. Garcin, B. Faltings, O. Donatsch, A. Alazzawi, C. Bruttin, and A. Huber. Offline and online evaluation of news recommender systems at swissinfo.ch. In RecSys '14, pages 169--176, 2014.", "C. A. Gomez-Uribe and N. Hunt. The Netflix Recommender System: Algorithms, Business Value, and Innovation. ACM TMIS, 6(4):13:1--13:19, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959186"}, {"title": "On computing temporal functions for a time-dependent networks using trajectory data", "authors": ["Samara Martins Nascimento\n,", "Mirla R. R. Braga Chucre\n,", "Jose Antônio Fernandes de Macedo\n,", "Jose Monteiro\n,"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nTime dependent networks are of key importance to allow computing precise travel times taking into consideration moving object's departure time. However the computation of time functions that are used to annotate time dependent networks are challenging since we must cope with noisy and incomplete traffic data. Recent related works adopt approaches that build Piecewise linear functions, which do not cope with aforementioned problems. In this work, we propose a new method for generating Piecewise linear functions by applying a map-matching technique allied to a curve smoothing approach in order to treat outliers and complete data. We performed experiments using real trajectory data and compared our results with a baseline. Preliminary results show that our approach generates time functions with better approximation than the baseline competitor.", "references": ["Ugur Demiryurek, Farnoush Banaei Kashani, and Cyrus Shahabi. Efficient k-nearest neighbor search in time-dependent spatial networks. In Database and Expert Systems Applications, 21st International Conference, DEXA 2010, Bilbao, Spain, August 30-September 3, 2010, Proceedings, Part I, pages 432--449, 2010.", "Lívia A. Cruz, Mario A. Nascimento, and José Antônio Fernandes de Macêdo. k-nearest neighbors queries in time-dependent road networks. JIDM, 3(3):211--226, 2012.", "Camila F. Costa, Mario A. Nascimento, José Antônio Fernandes de Macêdo, and Javam C. Machado. Nearest neighbor queries with service time constraints in time-dependent road networks. In Proceedings of the Second ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems, MobiGIS 2013, November 5, 2013, Orlando, Florida, USA, pages 22--29, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938542"}, {"title": "ClusMAM: fast and effective unsupervised clustering of large complex datasets using metric access methods", "authors": ["Jessica A. de Souza\n,", "Mirela T. Cazzolato\n,", "Agma J. M. Traina"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nAn efficient and effective clustering process is a core task of data mining analysis, and has become more important in the nowadays scenario of big data, where scalability is an issue. In this paper we present the ClusMAM method, which proposes a new strategy for clustering large complex datasets through metric access methods. ClusMAM aims at accelerating the process of relational partitional clustering by taking advantage of the inherent node separations of metric access methods. In comparison with other methods from the literature, ClusMAM is up to four orders of magnitude faster than the competitors maintaining clustering quality. Additionally, ClusMAM exploits the datasets to find compact and coherent clusters, suggesting the number of clusters k found in the data. The method was evaluated employing synthetic and real datasets, and the behavior of the method was consistent regarding the number of distance calculations and time required for the clustering process as well.", "references": ["A. K. Jain, Data clustering: 50 years beyond K-means, Pattern recognition letters, Vol. 31, no. 8, pp. 651--666, 2010.", "R. T. Ng and J. Han, Efficient and effective clustering methods for spatial data mining, VLDB, pp. 144--155, 1994.", "L. Kaufman and P. J. Rousseeuw, Finding Groups in Data: An Introduction to Cluster Analysis, John Wiley and Sons, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851661"}, {"title": "A 2-phase frame-based knowledge extraction framework", "authors": ["Francesco Corcoglioniti\n,", "Marco Rospocher\n,", "Alessio Palmero Aprosio"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nWe present an approach for extracting knowledge from natural language English texts where processing is decoupled in two phases. The first phase comprises several standard NLP tasks whose results are integrated in a single RDF graph of mentions. The second phase processes the mention graph with SPARQL-like mapping rules to produce a knowledge graph organized around semantic frames (i.e., prototypical descriptions of events and situations). The decoupling allows: (i) choosing different tools for the NLP tasks without affecting the remaining computation; (ii) combining the outputs of different NLP tasks in non-trivial ways, leveraging their integrated and coherent representation in a mention graph; and (iii) relating each piece of extracted knowledge to the mention(s) it comes from, leveraging the single RDF representation. We evaluate precision and recall of our approach on a gold standard, showing its competitiveness w.r.t. the state of the art. We also evaluate execution times and (sampled) accuracy on a corpus of 110K Wikipedia pages, showing the applicability of the approach on large corpora.", "references": ["I. Augenstein, S. Padó, and S. Rudolph. LODifier: Generating Linked Data from unstructured text. In Proc. of ESWC'12, pages 210--224. Springer, 2012.", "P. Cimiano. Ontology learning and population from text. Springer, 2006.", "F. Corcoglioniti, M. Rospocher, R. Cattoni, B. Magnini, and L. Serafini. The KnowledgeStore: a storage framework for interlinking unstructured and structured knowledge. Int. J. Semantic Web Inf. Syst., 11(2):1--35, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851845"}, {"title": "Capturing complex behaviour for predicting distant future trajectories", "authors": ["Bertil Chapuis\n,", "Arielle Moro\n,", "Vaibhav Kulkarni\n,", "Benoît Garbinato"], "publication": "MobiGIS '16: Proceedings of the 5th ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems", "abstract": "ABSTRACT\nWe put forth a system, to predict distant-future positions of multiple moving entities and index the forecasted trajectories, in order to answer predictive queries involving long time horizons. Today, the proliferation of mobile devices with GPS functionality and internet connectivity has led to a rapid development of location-based services, accounting for user mobility prediction as a key paradigm. Mobility prediction is already playing a major role in traffic management, urban planning and location-based advertising, which demand accurate and long time horizon forecasting of user movements. Existing prediction methodologies either use motion patterns or techniques based on frequently visited places for predicting the next move. However, when it comes to distant-future, human mobility is too complex to be represented by such statistical functions. Therefore, the existing techniques are not well suited to answer distant-future queries with a satisfactory level of accuracy. To tackle this problem, we introduce a novel spatial object, 'Representative Trajectory', which embodies the movements of users amongst their zones of interest. We propose means to empirically evaluate the quality of this object and dynamically adapt its extraction method based on user mobility behaviour. We rely on an inverted index to store the predicted trajectories that scales well with the number of moving entities. Our evaluation results show that the technique achieves more than 70% accurate predictions with the best extraction technique. This shows that longer query time horizons do not necessarily demand complex spatial indexing schemes, which have to be rebalanced as they grow and which is a constantly experienced problem while answering predictive queries.", "references": ["S. Chen, C. S. Jensen, and D. Lin. A benchmark for evaluating moving object indexes. Proceedings of the VLDB Endowment, 1(2):1574--1585, 2008.", "M.-F. Chiang, W.-Y. Zhu, W.-C. Peng, and S. Y. Philip. Distant-time location prediction in low-sampling-rate trajectories. In 2013 IEEE 14th International Conference on Mobile Data Management, volume 1, pages 117--126. IEEE, 2013.", "S. Gambs, M.-O. Killijian, and M. N. del Prado Cortez. Show me how you move and i will tell you who you are. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Security and Privacy in GIS and LBS, pages 34--41. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3004725.3004730"}, {"title": "Retrieval of comic book images using context relevance information", "authors": ["Thanh-Nam Le\n,", "Muhammad Muzzamil Luqman\n,", "Jean-Christophe Burie\n,", "Jean-Marc Ogier"], "publication": "MANPU '16: Proceedings of the 1st International Workshop on coMics ANalysis, Processing and Understanding", "abstract": "ABSTRACT\nDespite the widespread research interest given in the recent years in analyzing the structure and content of comic books, the question of how to effectively query and retrieve comic images stays a challenge, due to the substantial differences between them and naturalistic images. In this paper, we present a scheme to represent the content in comic-page images using attributed region adjacency graphs. The frequent subgraphs are then mined, and we propose a similarity score for the graphs based on the overlap between them in terms of common component frequent subgraphs. We show that the relationship between the computed similarity score versus panel order can help locating and grouping panels with similar content, or to detect the changing between \"scenes\", which eventually help to retrieve more relevant results.", "references": ["K. Arai and H. Tolle. Automatic e-comic content adaptation. International Journal of Ubiquitous Computing, 1(1):1--11, 2010.", "H. Bunke and K. Riesen. Recent advances in graph-based pattern recognition with applications in document analysis. Pattern Recogn., 44(5):1057--1067, 2011.", "W.-T. Chu and Y.-C. Chao. Line-based drawing style description for manga classification. In Proceedings of the 22nd ACM international conference on Multimedia, pages 781--784. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011549.3011561"}, {"title": "Session details: Main Track - Process Management in IS", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3256001"}, {"title": "Orthogonal query recommendations for children", "authors": ["Alicia Wood\n,", "Yiu-Kai Ng"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nChildren have become an ever-popular group of users who explore and search the Web. However, with this rise in popularity, there is still a gap in the amount of research that has been done to help children receive query recommendations applicable to their age group and understanding. We propose to develop an orthogonal query recommendation system and apply it specifically to children's queries. By using this recommender, we provide queries that are semantically different but conceptually very similar to a child's initial query. We have also validated our query recommendation system through Mean Reciprocal Ranking and Mean Average Precision to determine the accuracy of the recommended queries. Through this process, we have shown that the searching and browsing experience for children have improved and help them more easily find results that match their information needs.", "references": ["Child Trends. Home Computer Access and Internet Use, 2012.", "A. Druin, E. Foss, L. Hatley, E. Golub, M. Guha, J. Fails, and H. Hutchison. How Children Search the Internet with Keyword Interfaces. In Proceedings of the 8th International Conference on Interactionl Design and Children (IDC'09), pages 89--96. ACM, 2009.", "A. Druin, E. Foss, H. Hutchinson, E. Golub, and L. Hatley. Children's Roles Using Keyword Search Interfaces at Home. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 413--422. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011220"}, {"title": "Combining NLP And Semantics For Mining Software Technologies From Research Publications", "authors": ["Hélène de Ribaupierre\n,", "Francesco Osborne\n,", "Enrico Motta"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe natural language processing (NLP) community has developed a variety of methods for extracting and disambiguating information from research publications. However, they usually focus only on standard research entities such as authors, affiliations, venues, references and keywords. We propose a novel approach, which combines NLP and semantic technologies for generating from the text of research publications an OWL ontology describing software technologies used or introduced by researchers, such as applications, systems, frameworks, programming languages, and formats. The method was tested on a sample of 300 publications in the Semantic Web field, yielding promising results.", "references": ["B. Sateli and R.Witte. 2015. What's in this paper?: Combining Rhetorical Entities with Linked Open Data for Semantic Literature Querying. WWW 2015 Companion.", "S. Teufel and M. Moens. 2002. Summarizing scientific articles: experiments with relevance and rhetorical status. Computational linguistics 28, 4:409--445.", "H. de Ribaupierre and G. Falquet. 2014. User-centric design and evaluation of a semantic annotation model for scientific documents. IKNOW2014. ACM, USA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889358"}, {"title": "Floor Determination Algorithm with Node Failure Consideration for Indoor Positioning Systems", "authors": ["Kriangkrai Maneerat\n,", "Chutima Prommak"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nOne of challenging problems for indoor wireless multi-floor positioning systems is a presence of Reference Node (RN) failures, which causes the missing of the values of Received Signal Strength (RSS) during the online positioning phase of the fingerprinting technique. This leads to performance degradation in terms of floor accuracy which affects other localization procedures. This paper presents a robust floor determination algorithm called Robust Confidence Interval Sum-RSS (RCIS), which can accurately determine the floor where mobile objects located and can work under either the fault-free scenario or the RN-failure scenarios. The proposed fault tolerance floor algorithm is based on the confidence interval of the summation of the strongest RSS obtained from the IEEE 802.15.4 Wireless Sensor Networks (WSNs) during the online phase. The performance of the proposed algorithm is compared with those of different floor determination algorithms in literature. The experimental results show that the proposed robust floor determination algorithm outperformed the other floor algorithms and can achieve the highest percentage of floor determination accuracy in all tested scenarios. Specifically, the proposed algorithm can achieve 100% correct floor determination under the scenario in which 40% of RNs failed.", "references": ["G. Yanying, A. Lo, and I. Niemegeers2009. A survey of indoor positioning systems for wireless personal networks. IEEE Communications Surveys & Tutorials, vol. 11 (Mar. 2009), 13--32.", "S. Gansemer, U. Grossmann, and S. Hakobyan 2010. RSSI-based euclidean distance algorithm for indoor positioning adapted for the use in dynamically changing WLAN environments and multi-level buildings. In Proceedings of the International conference on Indoor Positioning and Indoor Navigation(Sept. 2010), 1--6.", "A. S. Al-Ahmadi, T. A. Rahman, M. R. Kamarudin, M. H. Jamaluddin, and A. I. Omer2011. Single-phase wireless LAN based multi-floor indoor location determination system. In Proceedings of the IEEE 17th International conference on Parallel and Distributed Systems (Dec. 2011), 1057--1062."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015200"}, {"title": "Library of congress subject heading (LCSH) browsing and natural language searching", "authors": ["Charles-Antoine Julien\n,", "Banafsheh Asadi\n,", "Jesse D. Dinneen\n,", "Fei Shu"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nControlled topical vocabularies (CVs) are built into information systems to aid browsing and retrieval of items that may be unfamiliar, but it is unclear how this feature should be integrated with standard keyword searching. Few systems or scholarly prototypes have attempted this, and none have used the most widely used CV, the Library of Congress Subject Headings (LCSH), which organizes monograph collections in academic libraries throughout the world. This paper describes a working prototype of a Web application that concurrently allows topic exploration using an outline tree view of the LCSH hierarchy and natural language keyword searching of a real-world Science and Engineering bibliographic collection. Pilot testing shows the system is functional, and work to fit the complex LCSH structure into a usable hierarchy is ongoing. This study contributes to knowledge of the practical design decisions required when developing linked interactions between topical hierarchy browsing and natural language searching, which promise to facilitate information discovery and exploration.", "references": ["Chan, B., Wu, L., Talbot, J., Cammarano, M., & Hanrahan, P. (2008). Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration. IEEE Transactions on Visualization and Computer Graphics, 14(6), 1213--1220.", "Dork, M., Williamson, C., & Carpendale, S. (2012). Navigating tomorrow's web: From searching and browsing to visual exploration. ACM Transactions on the Web, 6(3), 1--28.", "Fitchett, S., Cockburn, A., & Gutwin, C. (2014). Finder highlights: field evaluation and design of an augmented file browser. Paper presented at the Proc. of the 32nd annual ACM conf. on Human factors in computing systems, Toronto, Ontario, Canada."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017563"}, {"title": "Algorithms Aside: Recommendation As The Lens Of Life", "authors": ["Tamas Motajcsek\n,", "Jean-Yves Le Moine\n,", "Martha Larson\n,", "Daniel Kohlsdorf\n,", "Andreas Lommatzsch\n,", "Domonkos Tikk\n,", "Omar Alonso\n,"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this position paper, we take the experimental approach of putting algorithms aside, and reflect on what recommenders would be for people if they were not tied to technology. By looking at some of the shortcomings that current recommenders have fallen into and discussing their limitations from a human point of view, we ask the question: if freed from all limitations, what should, and what could, RecSys be? We then turn to the idea that life itself is the best recommender system, and that people themselves are the query. By looking at how life brings people in contact with options that suit their needs or match their preferences, we hope to shed further light on what current RecSys could be doing better. Finally, we look at the forms that RecSys could take in the future. By formulating our vision beyond the reach of usual considerations and current limitations, including business models, algorithms, data sets, and evaluation methodologies, we attempt to arrive at fresh conclusions that may inspire the next steps taken by the community of researchers working on RecSys.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959164"}, {"title": "Tracky Notes: Trackable Sticky Notes for Indexing a Video of Meetings", "authors": ["Yoshiyuki Kajiwara\n,", "Shogo Fukushima\n,", "Daiya Aida\n,", "Takeshi Naemura"], "publication": "GROUP '16: Proceedings of the 19th International Conference on Supporting Group Work", "abstract": "ABSTRACT\nVideo records are sometimes used during meetings nowadays in order to compensate for the incompleteness of hand-written minutes. To use video effectively to record the minutes of a meeting, indices are considered necessary in addition to standard functions of movie players. Some systems can form indices by sensing human actions in the world, but such indices are not directly relevant to the contents of the discussions that occur in meetings. In this study, we propose an automated meeting index system based on people's discussions during daily meetings in the world. In our system, indices based on the contents of discussion can be automatically formulated in meetings if only paper, writing implements, and a camera are arranged in a certain manner. To this end, we develop trackable sticky notes, called \"Tracky Notes,\" as indices. Tracky Notes can be tracked with visible markers through a camera, and is robust against occlusion. We then propose a meeting viewer where Tracky Notes are used as indices. Finally, we report the result of a user study conducted in a university classroom. The study revealed the appropriate region of visible markers and the robustness against occlusion of Tracky Notes. We also measured the effectiveness of our system comparing with standard functions of movie players.", "references": ["Geyer, W., Richter, H., Fuchs, L., Frauenhofer, T., Daijavad, S., and Poltrock, S. 2001. TeamSpace: A collaborative workspace system supporting virtual meetings. IBM Research Report, RC 21961.", "Geyer, W., Richter, H. and Abowd, G. D. 2005. Towards a smarter meeting record-Capture and access of meetings revisited. Multimedia Tools and Applications 27, 393--410.", "Jaimes, A., Omura, K., Nagamine, T., and Hirata, K. 2004. Memory cues for meeting video retrieval. In Proceedings of the 1st ACM Workshop on Continuous Archival and Retrieval of Personal Experiences, Anonymous ACM, 74--85."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957276.2996285"}, {"title": "Industry Perspectives and the IT2017 Report", "authors": ["Barbara Viola"], "publication": "ITiCSE '16: Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education", "abstract": "ABSTRACT\nThe term \"information technology\" (IT) has many meanings for various stakeholders and it continues to evolve. This poster presents an overview of industry perspectives as they relate to information technology (IT), and in particular to the IT2017 report. This poster highlights the industry elements as they relate to IT", "references": ["Collins Dictionary; http://www.collinsdictionary.com/dictionary/ english/communication-skills. Accessed 2016 Mar 10.", "Dictionary.com; http://dictionary.reference.com/browse/teamwork. Accessed 2016 Mar 10.", "Investopedia; http://www.investopedia.com/terms/s/soft-skills.asp. Accessed 2016 Mar 10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899415.2925476"}, {"title": "Scalable Microblogs Data Management", "authors": ["Amr Magdy"], "publication": "SIGMOD'16 PhD: Proceedings of the 2016 on SIGMOD'16 PhD Symposium", "abstract": "ABSTRACT\nMicroblogs, e.g., tweets, reviews, or comments on news websites and social media, have become so popular among web users that many applications are exploiting them for different types of analysis. The distinguishing characteristics of microblogs have motivated a lot of research for managing such data. However, the developed technology for microblogs is still scattered efforts here and there which leads to several data management gaps that limits supporting microblogs-centric applications end-to-end. Our research aims to provide a holistic system approach to manage microblogs data, so that whoever builds new functionality on microblogs can seamlessly exploit a single data management system to power his applications. In this paper, we present a full proposal for Kite; the first holistic system that provides end-to-end management for microblogs data. Kite aims to fill the gap in existing systems to support scalable queries with selective search criteria on data that comes in high velocity and adds up to large volumes (billions of records). To this end, the system is going to exploit and extend the infrastructure of Apache Spark system. Throughout the paper, we represent a roadmap for the accomplished contributions, on-going contributions towards the first cut realization of Kite, and future contributions to iteratively improve the system maturity and capabilities.", "references": ["Daniel J. Abadi and et. al. Aurora: A New Model and Architecture for Data Stream Management. VLDB Journal, 12(2), 2003.", "Mohamed H. Ali and et. al. Spatio-Temporal Stream Processing in Microsoft StreamInsight. IEEE Data Engineering Bulletin, 33(2), 2010.", "Sattam Alsubaiee and et. al. AsterixDB: A Scalable, Open Source BDMS. PVLDB, 7(14), 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926693.2929898"}, {"title": "Unsupervised Neural Network optimized with Sequential Quadratic Programming for Linear and Non-Linear Dynamical Systems", "authors": ["M. Kashan Basit\n,", "Arslan Shaukat\n,", "Usman Akram\n,", "Umair Zafar Khan"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn this research article the neural network optimized with sequential quadratic programming has been exploited to numerically solve the complex systems based on linear and nonlinear ODE. The algebraic sum of log-sigmoid activation function has been manipulated in an unsupervised manner in the form of fitness function based on mean square error. The test systems involve linear system, non-linear system of homogenous and inhomogeneous nature as well as a well-known fluid system with varying magnetic parameters. The Monte Carlo simulations have been performed to see the reliability of the proposed scheme, level of convergence in optimization and computational complexity in term of time.", "references": ["Eves, H. An Introduction to the History of Mathematics, 4th Edition, 1976, Holt, Rinehold and Winston, New York.", "S. Chen and S. A. Billings, Neural network for nonlinear dynamic system modelling and identi_cation, International Journal of Control, vol. 56, no.2, pp. 319--346, 1992.", "A. Fekih, H. Xu and F. N. Chowdhury, Neural networks based system identi_cation techniques for model based fault detection of nonlinear systems, International Journal of Innovative Computing, Information and Control, vol.3, no.5, pp. 1073--1085, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015213"}, {"title": "Group-based Collaborative Filtering Supported by Multiple Users' Feedback to Improve Personalized Ranking", "authors": ["Arthur F. da Costa\n,", "Marcelo G. Manzato\n,", "Ricardo J.G.B. Campello"], "publication": "Webmedia '16: Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nRecommender systems were created to represent user preferences for the purpose of suggesting items to purchase or examine. However, there are several optimizations to be made in these systems mainly with respect to modeling the user profile and remove the noise information. This paper proposes a collaborative filtering approach based on preferences of groups of users to improve the accuracy of recommendation, where the distance among users is computed using multiple types of users' feedback. The advantage of this approach is that relevant items will be suggested based only on the subjects of interest of each group of users. Using this technique, we use a state-of-art collaborative filtering algorithm to generate a personalized ranking of items according to the preferences of an individual within each cluster. The experimental results show that the proposed technique has a higher precision than the traditional models without clustering.", "references": ["M. B.-R. F. T. A. Adomavicius, G. Context-aware recommender systems. AI Magazine, pages 67--80, 2011.", "J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, UAI'98, pages 43--52, San Francisco, CA, USA, 1998. Morgan Kaufmann Publishers Inc.", "I. Cantador, P. Brusilovsky, and T. Kuflik. 2nd workshop on information heterogeneity and fusion in recommender systems (hetrec 2011). In Proceedings of the 5th ACM conference on Recommender systems, RecSys 2011, New York, NY, USA, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2976796.2976852"}, {"title": "With a Little Help from my Neighbors: Person Name Linking Using the Wikipedia Social Network", "authors": ["Johanna Geiß\n,", "Michael Gertz"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nDriven by the popularity of social networks, there has been an increasing interest in employing such networks in the context of named entity linking. In this paper, we present a novel approach to person name disambiguation and linking that uses a large-scale social network extracted from the English Wikipedia. First, possible candidate matches for an ambiguous person name are determined. With each candidate match, a network substructure is associated. Based on the similarity between these network substructures and the latent network of an ambiguous person name in a document, we propose an efficient ranking method to resolve the ambiguity. We demonstrate the effectiveness of our approach, resulting in an overall precision of over 96% for disambiguating person names and linking them to real world entities.", "references": ["A. Bagga and B. Baldwin. Entity-based crossdocument coreferencing using the Vector Space Model. In COLING. ACL, 1998.", "A. Barrena, A. Soroa, and E. Agirre. Combining Mention Context and Hyperlinks from Wikipedia for Named Entity Disambiguation. In *SEM. ACL, 2015.", "R. Bunescu and M. P. Pasca. Using Encyclopedic Knowledge for Named Entity Disambiguation. In EACL, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891109"}, {"title": "Corpus COFLA: A Research Corpus for the Computational Study of Flamenco Music", "authors": ["Nadine Kroher\n,", "José-Miguel Díaz-Báñez\n,", "Joaquin Mora\n,", "Emilia Gómez"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nFlamenco is a music tradition from Southern Spain that attracts a growing community of enthusiasts around the world. Its unique melodic and rhythmic elements, the typically spontaneous and improvised interpretation, and its diversity regarding styles make this still largely undocumented art form a particularly interesting material for musicological studies. In prior works, it has already been demonstrated that research on computational analysis of flamenco music, despite it being a relatively new field, can provide powerful tools for the discovery and diffusion of this genre. In this article, we present corpusCOFLA, a data framework for the development of such computational tools. The proposed collection of audio recordings and metadata serves as a pool for creating annotated subsets that can be used in development and evaluation of algorithms for specific music information retrieval tasks. First, we describe the design criteria for the corpus creation and then provide various examples of subsets drawn from the corpus. We showcase possible research applications in the context of computational study of flamenco music and give perspectives regarding further development of the corpus.", "references": ["Mathieu Bastian, Sebastien Heymann, and Mathieu Jacomy. 2009. Gephi: An Open Source Software for Exploring and Manipulating Networks. Retrieved from http://www.aaai.org/ocs/index.php/ICWSM/09/paper/view/154.", "E. Benetos, S. Dixon, D. Giannoulis, H. Kirchhoff, and A. Klapuri. 2013. Automatic music transcription: Challenges and future directions. Journal of Intelligent Information Systems 41, 3 (2013), 407--434.", "T. Bertin-Mahieux, D. P. W. Ellis, B. Whitman, and P. Lamere. 2011. The million song dataset. In International Society International Society for Music Information Retrieval (ISMIR) Conference."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2875428"}, {"title": "Group Testing for Identification with Privacy", "authors": ["Ahmet Iscen\n,", "Teddy Furon"], "publication": "IH&MMSec '16: Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security", "abstract": "ABSTRACT\nThis paper describes an approach where group testing helps in enforcing security and privacy in identification. We detail a particular scheme based on embedding and group testing. We add a second layer of defense, group vectors, where each group vector represents a set of dataset vectors. Whereas the selected embedding poorly protects the data when used alone, the group testing approach makes it much harder to reconstruct the data when combined with the embedding. Even when curious server and user collude to disclose the secret parameters, they cannot accurately recover the data. Another byproduct of our approach is that it reduces the complexity of the search and the required storage space. We show the interest of our work in a benchmark biometrics dataset, where we verify our theoretical analysis with real data.", "references": ["J. Bringer, H. Chabanne, M. Favre, A. Patey, T. Schneider, and M. Zohner. GSHADE: faster privacy-preserving distance computation and biometric identification. In Proceedings of the 2Nd ACM Workshop on Information Hiding and Multimedia Security, IH&MMSec '14, pages 187--198, New York, NY, USA, 2014. ACM.", "J. Bringer, H. Chabanne, and A. Patey. SHADE: secure hamming distance computation from oblivious transfer. In Financial Cryptography and Data Security, volume 7862 of Lecture Notes in Computer Science, pages 164--176, 2013.", "M. S. Charikar. Similarity estimation techniques from rounding algorithms. In STOC, pages 380--388, May 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909827.2930792"}, {"title": "Retrievability of Code Mixed Microblogs", "authors": ["Debasis Ganguly\n,", "Ayan Bandyopadhyay\n,", "Mandar Mitra\n,", "Gareth J.F. Jones"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMixing multiple languages within the same document, a phenomenon called (linguistic) code mixing or code switching, is a frequent trend among multilingual users of social media. In the context of information retrieval (IR), code mixing may affect retrieval effectiveness due to the mixing of different vocabularies with different collection statistics within a single collection of documents. In this paper, we investigate the indexing and retrieval strategies for a mixed collection of documents, comprising of code-mixed and the monolingual documents. In particular, we address three alternative modes of indexing, namely (a) a single index for the two sub-collections; (b) a separate index for each sub-collection; and (c) a clustered index with two individual sub-collection statistics coupled with the overall one. We make use of the expected retrievability scores of the two classes of documents to empirically show that indexing strategies (a) and (b) mostly retrieve the monolingual documents at top ranks with standard retrieval approaches. Our experiments show that, by contrast, the clustered index (c) is able to alleviate this problem by improving the retrievability of the code-mixed documents.", "references": ["List of languages by number of native speakers. https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers. Accessed: 2016-02-09.", "G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20(4):357--389, 2002.", "P. Auer. Code-switching in conversation: language, interaction and identity. Taylor and Francis, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914727"}, {"title": "Multimodal Popularity Prediction of Brand-related Social Media Posts", "authors": ["Masoud Mazloom\n,", "Robert Rietveld\n,", "Stevan Rudinac\n,", "Marcel Worring\n,", "Willemijn van Dolen"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nBrand-related user posts on social networks are growing at a staggering rate, where users express their opinions about brands by sharing multimodal posts. However, while some posts become popular, others are ignored. In this paper, we present an approach for identifying what aspects of posts determine their popularity. We hypothesize that brand-related posts may be popular due to several cues related to factual information, sentiment, vividness and entertainment parameters about the brand. We call the ensemble of cues engagement parameters. In our approach, we propose to use these parameters for predicting brand-related user post popularity. Experiments on a collection of fast food brand-related user posts crawled from Instagram show that: visual and textual features are complementary in predicting the popularity of a post; predicting popularity using our proposed engagement parameters is more accurate than predicting popularity directly from visual and textual features; and our proposed approach makes it possible to understand what drives post popularity in general as well as isolate the brand specific drivers.", "references": ["Y. Bae and H. Lee. Sentiment analysis of twitter audiences: Measuring the positive or negative influence of popular twitterers. J. Am. Soc. Inf. Sci. Technol., 63(12):2521--2535, 2012.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In MM, 2013.", "S. Cappallo, T. Mensink, and C. Snoek. Latent factors of visual popularity prediction. In ICMR, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967210"}, {"title": "Big Data Clustering using Data Streams Approach", "authors": ["Ibrahim Louhi\n,", "Lydia Boudjeloud-Assala\n,", "Thomas Tamisier"], "publication": "BDAW '16: Proceedings of the International Conference on Big Data and Advanced Wireless Technologies", "abstract": "ABSTRACT\nIn this paper we propose to process big data using a data streams approach. The data set is divided into subsets, each subsets is considered as a time window from a data stream. Our approach uses a neighborhood-based clustering. Instead of processing each new element one by one, we propose to process each group of new elements simultaneously. A clustering is applied on each new group using neighborhood graphs. The obtained clusters are then used to incrementally construct a representative graph of the data. The data graph is visualized in real time with specific visualizations that reflect the processing algorithm. To validate the approach, we apply it to different data streams and we compare it with known data stream clustering approaches.", "references": ["C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for clustering evolving data streams. In Proceedings of the 29th international conference on Very large data bases-Volume 29, pages 81--92. VLDB Endowment, 2003.", "C. C. Aggarwal and K. Subbian. Event detection in social streams. In SDM, volume 12, pages 624--635. SIAM, 2012.", "P. Berkhin. A survey of clustering data mining techniques. In Grouping multidimensional data, pages 25--71. Springer, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010089.3010127"}, {"title": "Learning Contextualized Music Semantics from Tags Via a Siamese Neural Network", "authors": ["Ubai Sandouk\n,", "Ke Chen"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nMusic information retrieval faces a challenge in modeling contextualized musical concepts formulated by a set of co-occurring tags. In this article, we investigate the suitability of our recently proposed approach based on a Siamese neural network in fighting off this challenge. By means of tag features and probabilistic topic models, the network captures contextualized semantics from tags via unsupervised learning. This leads to a distributed semantics space and a potential solution to the out of vocabulary problem, which has yet to be sufficiently addressed. We explore the nature of the resultant music-based semantics and address computational needs. We conduct experiments on three public music tag collections—namely, CAL500, MagTag5K and Million Song Dataset—and compare our approach to a number of state-of-the-art semantics learning approaches. Comparative results suggest that this approach outperforms previous approaches in terms of semantic priming and music tag completion.", "references": ["Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. 2007. Greedy layer-wise training of deep networks. In Advances in Neural Information Processing Systems 19 (NIPS’06). Bernhard Schölkopf, John C. Platt, and Tim Hoffman (Eds.). 153--160.", "Thierry Bertin-Mahieux, Douglas Eck, and Michael Mandel. 2010. Automatic tagging of audio: the state-of-the-art. In Machine Audition: Principles, Algorithms and Systems, Wenwu Wang (Ed.). IGI Publishing, 334--352.", "Thierry Bertin-mahieux, Daniel P. W. Ellis, Brian Whitman, and Paul Lamere. 2011. The million song dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR’11)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2953886"}, {"title": "Address Geocoding using Street Profiles for Local Search", "authors": ["Michael Peterman\n,", "Omar Benomar\n,", "Hacene Mechedou\n,", "Felix-Herve Bachand"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nGeocoding is the process of converting addresses to geocoordinates. It is widely used in several fields such as public health to monitor socioeconomic inequalities for example or in Geographical Information Systems (GIS) to be able to use with its provided features. In this work, we describe a method to create an address geocoder from a free and open government street lines data source. The address geocoder transforms a street address into a location typically measured in latitude-longitude coordinates. The address geocoder is used in a search engine to relate spatial data to search results and improve accuracy.", "references": ["National road network. http://geogratis.gc.ca/api/en/nrcan-rncan/ess-sst/c0d1f299--179c-47b2-bcd8-da1ba68a8032.html. Accessed: 2016-01-08.", "P. A. Zandbergen. A comparison of address point, parcel and street geocoding techniques. Computers, Environment and Urban Systems, 32(3):214 -- 232, 2008. Discrete Global Grids."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890484"}, {"title": "Research Collaborations in Multidisciplinary Institutions: a Case Study of iSchools", "authors": ["Zhiya Zuo\n,", "Xi Wang\n,", "David Eichmann\n,", "Kang Zhao"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nAlthough closely related, multidisciplinarity and interdisciplinarity are different. The former indicates the co-existence of multiple disciplines while the latter is more about the integration among various areas. As collaboration between researchers from different areas is one of the major approaches for interdisciplinarity, this research investigated whether higher levels of multidisciplinarity in academic institutions are related to more collaborations, especially more interdisciplinary collaborations, among its faculty members. Using U.S. iSchools as a case study, we applied social network analysis and text mining techniques to faculty members' educational background and publication data, and proposed metrics for multidisciplinarity and collaboration interdisciplinarity. Our analysis results revealed that the multidisciplinarity of an iSchool is actually negatively correlated with the frequency and interdisciplinarity of research collaborations among its faculty members. This finding suggests that having a multidisciplinary environment alone is not sufficient to promote collaborations, nor interdisciplinary collaborations.", "references": ["Facilitating Interdisciplinary Research. National Academies Press, Washington, DC, USA, 2004.", "J. Adams and R. Light. Mapping interdisciplinary fields: Efficiencies, gaps and redundancies in HIV/AIDS research. PLoS ONE, 9(12), 2014.", "D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3(4--5):993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890522"}, {"title": "Proximity relevance model for query expansion", "authors": ["Liana Ermakova\n,", "Josiane Mothe\n,", "Elena Nikitina"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nQuery expansion (QE) aims at improving information retrieval effectiveness by enhancing the query formulation. Because users' queries are generally short and because of the language ambiguity, some information needs are difficult to satisfy. Query reformulation and QE methods have been developed to face this issue. Pseudo relevance feedback (PRF) considers the top retrieved documents as relevant and uses their content in order to expand the initial query. Rather than considering feedback documents as a bag of words, it is possible to exploit term proximity information. Although there are some researches in this direction, the majority of them is empirical. The lack of theoretical works in this area motivated us to introduce a novel method integrated into the language model formalism that takes advantage of the remoteness of candidate terms for QE from query terms within feedback documents. In contrast to previous works, our approach captures the proximity directly and in terms of sentences rather than tokens. We show that the method significantly improves the retrieval performance on TREC collections especially for difficult queries.", "references": ["G. Amati. Probability Models for Information Retrieval Based on Divergence from Randomness: PhD Thesis. University of Glasgow, 2003.", "G. Amati, C. Carpineto, and G. Romano. Query difficulty, robustness, and selective application of query expansion. Advances in Information Retrieval, page 127137, 2004.", "J. Bhogal, A. Macfarlane, and P. Smith. A review of ontology based query expansion. Inf. Process. Manage., 43(4):866886, July 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851696"}, {"title": "Technical Perspective: Mapping the universe", "authors": ["Valentina Salapura"], "publication": "Communications of the ACM", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015567"}, {"title": "How Informative is a Term?: Dispersion as a measure of Term Specificity", "authors": ["Rodney McDonell\n,", "Justin Zobel\n,", "Bodo Billerbeck"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSimilarity functions assign scores to documents in response to queries. These functions require as input statistics about the terms in the queries and documents, where the intention is that the statistics are estimates of the relative informativeness of the terms. Common measures of informativeness use the number of documents containing each term (the document frequency) as a key measure. We argue in this paper that the distribution of within-document frequencies across a collection is also pertinent to informativeness, a measure that has not been considered in prior work: the most informative words tend to be those whose frequency of occurrence has high variance. We propose use of relative standard deviation (RSD) as a measure of variability incorporating within-document frequencies, and show that RSD compares favourably with inverse document frequency (IDF), in both in-principle analysis and in practice in retrieval, with small but consistent gains.", "references": ["Church, K. and Gale, W. {1999}, Inverse document frequency (IDF): A measure of deviations from Poisson, in 'Natural language processing using very large corpora', Springer, pp. 283--295.", "Cooper, W. S. and Huizinga, P. {1982}, 'The maximum entropy principle and its application to the design of probabilistic retrieval systems.', Information Technology, Research and Development 1, 99--112.", "Fellbaum, C. {1998}, WordNet: An Electronic Lexical Database, Bradford Books."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914687"}, {"title": "Scalable Clustering by Iterative Partitioning and Point Attractor Representation", "authors": ["Junming Shao\n,", "Qinli Yang\n,", "Hoang-Vu Dang\n,", "Bertil Schmidt\n,", "Stefan Kramer"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nClustering very large datasets while preserving cluster quality remains a challenging data-mining task to date. In this paper, we propose an effective scalable clustering algorithm for large datasets that builds upon the concept of synchronization. Inherited from the powerful concept of synchronization, the proposed algorithm, CIPA (Clustering by Iterative Partitioning and Point Attractor Representations), is capable of handling very large datasets by iteratively partitioning them into thousands of subsets and clustering each subset separately. Using dynamic clustering by synchronization, each subset is then represented by a set of point attractors and outliers. Finally, CIPA identifies the cluster structure of the original dataset by clustering the newly generated dataset consisting of points attractors and outliers from all subsets. We demonstrate that our new scalable clustering approach has several attractive benefits: (a) CIPA faithfully captures the cluster structure of the original data by performing clustering on each separate data iteratively instead of using any sampling or statistical summarization technique. (b) It allows clustering very large datasets efficiently with high cluster quality. (c) CIPA is parallelizable and also suitable for distributed data. Extensive experiments demonstrate the effectiveness and efficiency of our approach.", "references": ["Juan A. Acebron, L. L. Bonilla, Conrad J. Perez Vicente, Felix Ritort, and Renato Spigler. 2005. The Kuramoto model: A simple paradigm for synchronization phenomena. Rev. Mod. Phys. 77, 2 (Jan. 2005), 137--185.", "Andrew Adinetz, Jiri Kraus, Jan Meinke, and Dirk Pleiter. 2013. GPUMAFIA: Efficient subspace clustering with MAFIA on GPUs. In Euro-Par 2013 Parallel Processing. Springer, 838--849.", "Periklis Andritsos, Panayiotis Tsaparas, Renée J. Miller, and Kenneth C. Sevcik. 2004. Limbo: Scalable clustering of categorical data. In Advances in Database Technology-EDBT 2004. Springer, 123--146."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934688"}, {"title": "Ontology-based query refinement for XML information retrieval", "authors": ["Olfa Arfaoui\n,", "Minyar Sassi Hidri"], "publication": "WIMS '16: Proceedings of the 6th International Conference on Web Intelligence, Mining and Semantics", "abstract": "ABSTRACT\nThe characteristics of XML (eXtensible Markup Language) documents have favored the need to develop specific and flexible querying systems while taking into account the coexistence of both structural and content information. The ultimate goal of these systems is to respond to different user expectations which tend to return appropriate answers to their preferences. However, people have often insufficient knowledge about XML data structure and contents, thus frequently obtaining empty answers or having to reformulate the queries several times. To solve this problem, we propose an ontology-based query refinement model for semi-structured information retrieval. It consists in reformulating a query by adding attributes from domain ontologies extracted from XML schemas.", "references": ["A. Alilaouar. Contribution àăl'interrogation flexible de données semi-structurées. 2007.", "S. Amer-Yahia, S. Cho, and D. Srivastava. Tree pattern relaxation. International Conference on Extending Database Technology, 2287:496--513, 2002.", "O. Arfaoui and M. Sassi. Mining semi-structured data. In Proceedings of the 5th Conference on Web and Information Technologies, pages 51--60, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2912845.2912882"}, {"title": "Learning to Project and Binarise for Hashing Based Approximate Nearest Neighbour Search", "authors": ["Sean Moran"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we focus on improving the effectiveness of hashing-based approximate nearest neighbour search. Generating similarity preserving hashcodes for images has been shown to be an effective and efficient method for searching through large datasets. Hashcode generation generally involves two steps: bucketing the input feature space with a set of hyperplanes, followed by quantising the projection of the data-points onto the normal vectors to those hyperplanes. This procedure results in the makeup of the hashcodes depending on the positions of the data-points with respect to the hyperplanes in the feature space, allowing a degree of locality to be encoded into the hashcodes. In this paper we study the effect of learning both the hyperplanes and the thresholds as part of the same model. Most previous research either learn the hyperplanes assuming a fixed set of thresholds, or vice-versa. In our experiments over two standard image datasets we find statistically significant increases in retrieval effectiveness versus a host of state-of-the-art data-dependent and independent hashing models.", "references": ["S. Moran and V. Lavrenko. Graph Regularised Hashing. In Proc. ECIR, 2015.", "S. Moran, V. Lavrenko, and M. Osborne. Neighbourhood Preserving Quantisation for LSH. In Proc. SIGIR, 2013.", "S. Moran, V. Lavrenko, and M. Osborne. Variable Bit Quantisation for LSH. In Proc. ACL, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914766"}, {"title": "How Relevant is the Irrelevant Data: Leveraging the Tagging Data for a Learning-to-Rank Model", "authors": ["Noor Ifada\n,", "Richi Nayak"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nFor the task of tag-based item recommendations, the underlying tensor model faces several challenges such as high data sparsity and inferring latent factors effectively. To overcome the inherent sparsity issue of tensor models, we propose the graded-relevance interpretation scheme that leverages the tagging data effectively. Unlike the existing schemes, the graded-relevance scheme interprets the tagging data richly, differentiates the non-observed tagging data insightfully, and annotates each entry as one of the \"relevant\", \"likely relevant\", \"irrelevant\", or \"indecisive\" labels. To infer the latent factors of tensor models correctly to produce the high quality recommendation, we develop a novel learning-to-rank method, Go-Rank, that optimizes Graded Average Precision (GAP). Evaluating the proposed method on real-world datasets, we show that the proposed interpretation scheme produces a denser tensor model by revealing \"relevant\" entries from the previously assumed \"irrelevant\" entries. Optimizing GAP as the ranking metric, the quality of the recommendations generated by Go-Rank is found superior against the benchmarking methods.", "references": ["Kim, H.-N., Ji, A.-T., Ha, I., and Jo, G.-S., Collaborative Filtering based on Collaborative Tagging for Enhancing the Quality of Recommendation. Electronic Commerce Research and Applications, 9(1): 73--83, 2010.", "Kolda, T. and Bader, B., Tensor Decompositions and Applications. SIAM Review, 51(3): 455--500, 2009.", "Ifada, N. and Nayak, R., A Two-Stage Item Recommendation Method Using Probabilistic Ranking with Reconstructed Tensor Model. In User Modeling, Adaptation, and Personalization, pages 98--110, Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835790"}, {"title": "Semiautomatic Construction of Cross-Period Thesaurus", "authors": ["Chaya Liebeskind\n,", "Ido Dagan\n,", "Jonathan Schler"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nA cross-period (diachronic) thesaurus enables users to search for information using modern terminology and obtain semantically related terms from earlier historical periods. The complex task of supporting the construction of a diachronic thesaurus by a domain expert lexicographer has hardly been addressed computationally until now. In this article, we introduce a semiautomatic iterative Query Expansion (QE) scheme for supporting diachronic thesaurus construction, which identifies candidate related terms based on statistical corpus-based measures. We use ancient-modern period classification to increase the performance of the statistical cooccurrence measures and extend our methods to deal with Multi-Word Expressions (MWEs). We demonstrate the empirical benefit of our scheme for a Jewish cross-period thesaurus and evaluate its impact on recall and on the effectiveness of the lexicographer’s manual efforts.", "references": ["Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pa şca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and WordNet-based approaches. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL’09). Association for Computational Linguistics, 19--27.", "Renlong Ai, Sebastian Krause, Walter Kasper, Feiyu Xu, and Hans Uszkoreit. 2015. Semi-automatic generation of multiple-choice tests from mentions of semantic relations. In Proceedings of the 2nd Workshop on Natural Language Processing Techniques for Educational Applications. Association for Computational Linguistics, 26--33.", "Hassan Al-Haj and Shuly Wintner. 2010. Identifying multi-word expressions by leveraging morphological and syntactic idiosyncrasy. In Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics, 10--18."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994151"}, {"title": "A tabletop instrument for manipulation of sound morphologies with hands, fingertips and upper-body", "authors": ["Edgar Hemery\n,", "Sotiris Manitsaris\n,", "Fabien Moutarde"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nWe present a musical instrument, named the Embodied Musical Instrument (EMI) which allows musicians to perform free gestures with the upper--body including hands and fingers thanks to 3D vision sensors, arranged around the tabletop. 3D interactive spaces delimit the boundaries in which the player performs metaphorical gestures in order to play with sound synthesis engines. A physical-based sound synthesis engine and a sampler have been integrated in the system in order to manipulate sound morphologies in the context of electro-acoustic and electronic composition.", "references": ["Pierre Schaeffer. Traité des objets musicaux. 1966.", "Luigi Russolo, Robert Filliou, Francesco Balilla Pratella, and Something Else Press. The Art of Noise: futurist manifesto, 1913. Something Else Press, 1967.", "Gaël Tissot. La notion de morphologie sonore et le developpement des technologies en musiques electroacoustiques: Deux elements complementaires d'une unique esthetique? 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948946"}, {"title": "SpaceJMP: Programming with Multiple Virtual Address Spaces", "authors": ["Izzat El Hajj\n,", "Alexander Merritt\n,", "Gerd Zellweger\n,", "Dejan Milojicic\n,", "Reto Achermann\n,", "Paolo Faraboschi\n,", "Wen-mei Hwu\n,", "Timothy Roscoe\n,", "Karsten Schwan"], "publication": "ASPLOS '16: Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems", "abstract": "ABSTRACT\nMemory-centric computing demands careful organization of the virtual address space, but traditional methods for doing so are inflexible and inefficient. If an application wishes to address larger physical memory than virtual address bits allow, if it wishes to maintain pointer-based data structures beyond process lifetimes, or if it wishes to share large amounts of memory across simultaneously executing processes, legacy interfaces for managing the address space are cumbersome and often incur excessive overheads. We propose a new operating system design that promotes virtual address spaces to first-class citizens, enabling process threads to attach to, detach from, and switch between multiple virtual address spaces. Our work enables data-centric applications to utilize vast physical memory beyond the virtual range, represent persistent pointer-rich data structures without special pointer representations, and share large amounts of memory between processes efficiently.\nWe describe our prototype implementations in the DragonFly BSD and Barrelfish operating systems. We also present programming semantics and a compiler transformation to detect unsafe pointer usage. We demonstrate the benefits of our work on data-intensive applications such as the GUPS benchmark, the SAMTools genomics workflow, and the Redis key-value store.", "references": ["Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska. The Interaction of Architecture and Operating System Design. In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS IV, pages 108--120, Santa Clara, California, USA, 1991.", "Andrew W. Appel and Kai Li. Virtual Memory Primitives for User Programs. In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS IV, pages 96--107, Santa Clara, California, USA, 1991.", "ARM Ltd. ARM Architecture Reference Manual: ARMv7-A and ARMv7-R Edition, 2014. ARM DDI 0406C.c."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872362.2872366"}, {"title": "The Solitude of Relevant Documents in the Pool", "authors": ["Aldo Lipani\n,", "Mihai Lupu\n,", "Evangelos Kanoulas\n,", "Allan Hanbury"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPool bias is a well understood problem of test-collection based benchmarking in information retrieval. The pooling method itself is designed to identify all relevant documents. In practice, 'all' translates to `as many as possible given some budgetary constraints' and the problem persists, albeit mitigated. Recently, methods to address this pool bias for previously created test collections have been proposed, for the evaluation measure precision at cut-off (P@n). Analyzing previous methods, we make the empirical observation that the distribution of the probability of providing new relevant documents to the pool, over the runs, is log-normal (when the pooling strategy is fixed depth at cut-off). We use this observation to calculate a prior probability of providing new relevant documents, which we then use in a pool bias estimator that improves upon previous estimates of precision at cut-off. Through extensive experimental results, covering 15 test collections, we show that the proposed bias correction method is the new state of the art, providing the closest estimates yet when compared to the original pool.", "references": ["Charles L. A. Clarke and Mark D. Smucker. Time well spent. In Proc. of IIiX, 2014.", "Gordon V. Cormack, Christopher R. Palmer, and Charles L. A. Clarke. Efficient construction of large test collections. In Proc. of SIGIR, 1998.", "Karen Sparck Jones. Letter to the editor. Information Processing & Management, 39(1), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983891"}, {"title": "Learning Multimodal Temporal Representation for Dubbing Detection in Broadcast Media", "authors": ["Nam Le\n,", "Jean-Marc Odobez"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nPerson discovery in the absence of prior identity knowledge requires accurate association of visual and auditory cues. In broadcast data, multimodal analysis faces additional challenges due to narrated voices over muted scenes or dubbing in different languages. To address these challenges, we define and analyze the problem of dubbing detection in broadcast data, which has not been explored before. We propose a method to represent the temporal relationship between the auditory and visual streams. This method consists of canonical correlation analysis to learn a joint multimodal space, and long short term memory (LSTM) networks to model cross-modality temporal dependencies. Our contributions also include the introduction of a newly acquired dataset of face-speech segments from TV data, which we have made publicly available. The proposed method achieves promising performance on this real world dataset as compared to several baselines.", "references": ["M. Bendris, D. Charlet, and G. Chollet. Lip activity detection for talking faces classification in TV-Content. In ICMV, 2010.", "Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependencies with gradient descent is difficult. IEEE Trans. on Neural Networks, 1994.", "G. Chetty and M. Wagner. Audio-visual multimodal fusion for biometric person authentication and liveness verification. In NICTA-HCSNet Multimodal User Interaction Workshop, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967211"}, {"title": "Data Aesthetics: The Ethics and Aesthetics of Big Data Gathering seen from the Artists Eye", "authors": ["Lucas Evers\n,", "Frank Nack"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nArt can reflect in depth about data (vertical) and at the same time has an aesthetical, ontological, intentional, and conscious realm (horizontal) that can communicate cross-dimensionally to the general public. In that way data can be contextualized in its being, can be made palpable and hence facilitate the communication of data into communication about data. The art exhibition of the 24th ACM MM conference will be presented at the Amsterdam Public Library (http://www.oba.nl/oba/english.html) and aims to provide art works that critically reflect on the use of data in procedural contexts. The presented art works were established in collaborations between artists and researchers that, in cases, have access to large data volumes. The presented art works make use of non-motivated and motivated functions art is valued for, as it is art in its act of resembling, expression and the presentation of the self that facilitates the representation of reality.", "references": ["DeLanda, M. 2011. Philosophy and Simulation: The Emergence of Synthetic Reason. Bloomsbury Academic", "Yuval Noah Harari, Y. N. 2016. Homo Deus: A Brief History of Tomorrow. Harvill Secker", "Kant, I 1951. Critique of Judgment. Trans. J.H. Bernard. Macmillan."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2993205"}, {"title": "Personality and information behavior in web search", "authors": ["Thomas Schmidt\n,", "Christian Wolff"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nIn this paper, we describe a quantitative study of personality aspects and their relationship with web search information behavior. We start with introducing personality and give an overview of information behavior research concerning personality aspects. In our study of 30 participants, their personality traits were operationalized by using a version of the Big 5, the B5T, a psychometric questionnaire that maps personality on different dimensions. The participants performed search tasks in a web context and data concerning their information behavior was collected via search logs as well as questionnaires. We show that there are selective correlations of slight and intermediate strength between the variables of information behavior and the personality dimensions. Finally, we discuss possible explanations and implications as well as new impulses for information behavior and retrieval research.", "references": ["Bawden, D. & Robinson, L. (2011). Individual Differences in Information-Related Behaviour: What Do We Know About Information Styles? In: A. Spink & J. Heinstrom (Eds.), New Directions in Information Behaviour. Library and Information Science, 1. (pp. 127--158). London, UK: Emerald.", "Bellardo, T. (1985). An investigation of online searcher traits and their relationship to search outcome. Journal of the American Society for Information Science, 36(4), 241--250.", "Berzins, J. I., Welling, M. A. & Wetter, R. E. (1978). A new measure of psychological androgyny based on the Personality Research Form. Journal of consulting and clinical psychology, 46(1), 126--138."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017568"}, {"title": "Deeper Knowledge Tracing by Modeling Skill Application Context for Better Personalized Learning", "authors": ["Yun Huang"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nTraditional Knowledge Tracing, which traces students' knowledge of each decomposed individual skill, has been a popular learner model for adaptive tutoring. Typically, a student is guided to the next skill when the student's knowledge on current skill is inferred as mastery. Unfortunately, this traditional approach no longer suffices to model complex skill practices where simple decompositions can not capture potential additional skills underlying the context as a whole. In such cases, mastery should only be granted when a student not only understands the basic of a skill but also can fluently apply a skill in varied application contexts. In this thesis, we aim to propose a data-driven approach to construct learner models considering different skill application contexts for tracing deeper knowledge, primarily based on Bayesian Networks. We aim to conduct novel, comprehensive, ``deep\" evaluations, including internal data-drive evaluations, and external end-user evaluations examining the real world impact for students' personalized learning.", "references": ["C. Carmona, E. Millán, J.-L. Pérez-de-la Cruz, M. Trella, and R. Conejo. Introducing prerequisite relations in a multi-layered bayesian student model. In User Modeling, pages 347--356. Springer, 2005.", "C. Conati, A. Gertner, and K. Vanlehn. Using bayesian networks to manage uncertainty in student modeling. User Modeling and User-Adapted Interaction, 12(4):371--417, 2002.", "A. T. Corbett and J. R. Anderson. Knowledge tracing: Modelling the acquisition of procedural knowledge. User Modeling and User-Adapted Interaction, 4(4):253--278, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930373"}, {"title": "Feature Generation and Selection on the Heterogeneous Graph for Music Recommendation", "authors": ["Chun Guo"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nNo abstract available.", "references": ["X. Geng, T.-Y. Liu, T. Qin, and H. Li. Feature selection for ranking. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '07, pages 407--414, New York, NY, USA, 2007. ACM.", "C. Guo and X. Liu. Automatic feature generation on heterogeneous graph for music recommendation. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15, pages 807--810, New York, NY, USA, 2015. ACM.", "Y. Song, S. Dixon, and M. Pearce. A survey of music recommendation systems and future perspectives. In Proceedings of the 9th International Symposium on Computer Music Modeling and Retrieval, CMMR '12, pages 395--410, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855088"}, {"title": "The Research and Selection of Ideal Cloud Services using Clustering Techniques: Track: Big Data, Data Mining, Cloud Computing and Remote Sensing", "authors": ["Hajar Rehioui\n,", "Abdellah Idrissi\n,", "Manar Abourezq"], "publication": "BDAW '16: Proceedings of the International Conference on Big Data and Advanced Wireless Technologies", "abstract": "ABSTRACT\nThe appropriate selection of cloud services is a new need that resulted from the increased use of Cloud Computing. Users want to find the cloud services that best meet their requirements from a large number of available cloud services. This requires a special treatment. Generally, it is done by using various techniques, such as Similarity, Data Mining, Recommender Systems, Multi-Criteria Decision Analysis (MCDA) methods, etc. The main problem of these cited methods, is firstly the large number of returned services and secondly the absence of direct communication between the user and the system. Most of methods are based on previous system knowledge, or they rely on other users feedback. In order to avoid these weaknesses we thought to add a form of communication between the user and the system. For this end, in our contribution, the user is requested to enter the values of his ideal service and then based on the techniques of clustering, the services which are the most closest to the ideal service are selected and returned to the final user.", "references": ["M. Abourezq and A. Idrissi. A cloud services research and selection system. In Proceedings of the IEEE 4th International Conference on Multimedia Computing and Systems (ICMCS'14), 2014.", "M. Abourezq and A. Idrissi. Introduction of an outranking method in the cloud computing research and selection system based on the skyline. In Proceedings of the IEEE 8th International Conference on Research Challenges in Information Science, 2014.", "M. Abourezq and A. Idrissi. Integration of Qos aspects in the cloud service research and selection system. International Journal of Advanced Computer Science and Applications, 6(6), 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010089.3010138"}, {"title": "Singing Voice Separation and Vocal F0 Estimation Based on Mutual Combination of Robust Principal Component Analysis and Subharmonic Summation", "authors": ["Yukara Ikemiya\n,", "Katsutoshi Itoyama\n,", "Kazuyoshi Yoshii\n,", "Yukara Ikemiya\n,", "Katsutoshi Itoyama\n,", "Kazuyoshi Yoshii"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nThis paper presents a new method of singing voice analysis that performs mutually-dependent singing voice separation and vocal fundamental frequency F0 estimation. Vocal F0 estimation is considered to become easier if singing voices can be separated from a music audio signal, and vocal F0 contours are useful for singing voice separation. This calls for an approach that improves the performance of each of these tasks by using the results of the other. The proposed method first performs robust principal component analysis RPCA for roughly extracting singing voices from a target music audio signal. The F0 contour of the main melody is then estimated from the separated singing voices by finding the optimal temporal path over an F0 saliency spectrogram. Finally, the singing voices are separated again more accurately by combining a conventional time-frequency mask given by RPCA with another mask that passes only the harmonic structures of the estimated F0s. Experimental results showed that the proposed method significantly improved the performances of both singing voice separation and vocal F0 estimation. The proposed method also outperformed all the other methods of singing voice separation submitted to an international music analysis competition called MIREX 2014.", "references": ["M. Goto, \"Active music listening interfaces based on signal processing,\" in Proc. Int. Conf. Acoust., Speech, Signal Process., 2007, pp. 1441-1444.", "H. Kawahara, M. Morise, T. Takahashi, R. Nisimura, T. Irino, and H. Banno, \"Tandem-STRAIGHT: A temporally stable power spectral representation for periodic signals and applications to interference-free spectrum, F0, and aperiodicity estimation,\" in Proc. Int. Conf. Acoust., Speech, Signal Process., 2008, pp. 3933-3936.", "Y. Ohishi, D. Mochihashi, H. Kameoka, and K. Kashino, \"Mixture of Gaussian process experts for predicting sung melodic contour with expressive dynamic fluctuations,\" in Proc. Int. Conf. Acoust., Speech, Signal Process., 2014, pp. 3714-3718."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2016.2577879"}, {"title": "Locus: locating bugs from software changes", "authors": ["Ming Wen\n,", "Rongxin Wu\n,", "Shing-Chi Cheung"], "publication": "ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nVarious information retrieval (IR) based techniques have been proposed recently to locate bugs automatically at the file level. However, their usefulness is often compromised by the coarse granularity of files and the lack of contextual information. To address this, we propose to locate bugs using software changes, which offer finer granularity than files and provide important contextual clues for bug-fixing. We observe that bug inducing changes can facilitate the bug fixing process. For example, it helps triage the bug fixing task to the developers who committed the bug inducing changes or enables developers to fix bugs by reverting these changes. Our study further identifies that change logs and the naturally small granularity of changes can help boost the performance of IR-based bug localization. Motivated by these observations, we propose an IR-based approach Locus to locate bugs from software changes, and evaluate it on six large open source projects. The results show that Locus outperforms existing techniques at the source file level localization significantly. MAP and MRR in particular have been improved, on average, by 20.1% and 20.5%, respectively. Locus is also capable of locating the inducing changes within top 5 for 41.0% of the bugs. The results show that Locus can significantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.", "references": ["https://bugs.eclipse.org/bugs/buglist.cgi? classification=Eclipse&amp;component=Core&amp;list id= 11582065&amp;product=JDT&amp;query format=advanced&amp; resolution=FIXED&amp;version=4.5. Accessed: 2015-03-22.", "https://bugs.eclipse.org/bugs/buglist.cgi? classification=Eclipse&amp;component=UI&amp;list id= 11582038&amp;product=PDE&amp;query format=advanced&amp; resolution=FIXED&amp;version=4.4. Accessed: 2015-03-22.", "https://bz.apache.org/bugzilla/buglist.cgi?product= Tomcat%208&amp;query format=advanced&amp;resolution= FIXED. Accessed: 2015-03-22."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970276.2970359"}, {"title": "A multi-tenant fair share approach to full-text search engine", "authors": ["Zong Peng\n,", "Beth Plale"], "publication": "DataCloud '16: Proceedings of the 7th International Workshop on Data-Intensive Computing in the Cloud", "abstract": "ABSTRACT\nFull text search engines underly the search of major content providers, Google, Bing and Yahoo. Open source search engines, such as Solr and ElasticSearch, are highly scalable and widely used in a Software-as-a-Service (SaaS) manner, in which multiple tenants share a single resource for improved resource utilization and lower management cost. Sharing of a full text search engine can exhibit unfairness in the form of performance interference. We propose a multi-tenancy solution that provides fair share of resource usage of a SaaS hosted search engine. It includes a revised deficit round robin technique for admission control, query resource usage estimation and a deadlock breaking mechanism. Experimental results show that our approach works well for both monolithic and distributed search engines.", "references": ["R. Krebs, S. Spinner, N. Ahmed, and S. Kounev, \"Resource usage control in multi-tenant applications,\" in 14th IEEE/ACM Int'l Symposium on Cluster, Cloud and Grid Computing(CCGrid'14). IEEE, 2014, pp. 122--131.", "J. Zeng, G. Ruan, A. Crowell, A. Prakash, and B. Plale, \"Cloud computing data capsules for non-consumptiveuse of texts,\" in Proceedings of the 5th ACM Workshop on Scientific Cloud Computing, ser. ScienceCloud '14. ACM, 2014, pp. 9--16.", "J. Zeng and B. Plale, \"Multi-tenant fair share in nosql data stores,\" in 2014 IEEE Int'l Conf on Cluster Computing (CLUSTER,14). IEEE, 2014, pp. 176--184."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3018100.3018107"}, {"title": "How do users handle inconsistent information?: the effect of search expertise", "authors": ["Kazutoshi Umemoto\n,", "Takehiro Yamamoto\n,", "Katsumi Tanaka"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nWhile search engines sometimes return different documents containing contradictory answers, little is known about how users handle inconsistent information. This paper investigates the effect of search expertise (defined as specialized knowledge on the internal workings of search engines) on search behavior and satisfaction criteria of users. We selected four tasks comprising factoid questions with inconsistent answers, extracted answers that 30 study participants had found in these tasks, and analyzed their answer-finding behavior in terms of the presence or absence of search expertise. Our main findings are as follows: (1) finding inconsistent answers causes users with search expertise (search experts) to feel dissatisfied, while effort in searching for answers is the dominant factor in task satisfaction for those without search expertise (search non-experts); (2) search experts tend to spend longer completing tasks than search non-experts even after finding possible answers; and (3) search experts narrow down the scope of searches to promising answers as time passes as opposed to search non-experts, who search for any answers even in the closing stage of task sessions. These findings suggest that search non-experts tend to be less concerned about the consistency in their found answers, on the basis of which we discuss the design implications for making search non-experts aware of the existence of inconsistent answers and helping them to search for supporting evidence for answers.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: A game for modeling different types of web search success using interaction data. In SIGIR, pp. 345--354 (2011).", "A. Aula, R. M. Khan, and Z. Guan. How does search behavior change as search becomes more difficult? In CHI, pp. 35--44 (2010).", "S. Büttcher, C. L. A. Clarke, and G. V. Cormack. Information retrieval: implementing and evaluating search engines. MIT Press (2010)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851698"}, {"title": "Vowel based Voice Activity Detection with LSTM Recurrent Neural Network", "authors": ["Juntae Kim\n,", "Jaeseok Kim\n,", "Seunghyung Lee\n,", "Jinuk Park\n,", "Minsoo Hahn"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nVoice activity detection (VAD) determines whether the incoming signal segments are speech or noiseand is an important technique in almost all of speech-related applications. In order to improve VAD performance in various noise environments, characterizing the speech feature has been the most crucial issue up to date. Among several proposed speech features, the context information of speech through time and vowel sound characteristics are known to current state-of-the-art speech features. Therefore, in order to reflect both on these merits, we propose vowel based VAD by Long short term memory recurrent neural network (LSTM-RNN). LSTM-RNN is known to the powerful model to capture dynamical context information through time. Moreover, with teaching the LSTM-RNN to only vowel sounds rather than whole speech, LSTM-RNN can learn more effectively because of the reduced manifold of speech. According to our experiments, proposed method shows better accuracy not only in the VAD task compared to LSTM-RNN based VAD but alsoa vowel detection task.", "references": ["Vlaj, D., Kotnik, B., Horvat, B. and Kačič, Z. A Computationally Efficient Mel-Filter Bank VAD Algorithm for Distributed Speech Recognition Systems. EURASIP Journal on Advances in Signal Processing, 2005, 4 2005), 1--11.", "Benyassine, A., Shlomot, E., Su, H. Y., Massaloux, D., Lamblin, C. and Petit, J. P. ITU-T Recommendation G. 729 Annex B: a silence compression scheme for use with G. 729 optimized for V.70 digital simultaneous voice and data applications. IEEE Communications Magazine, 35, 9 1997), 64--73.", "Zhang, X. L. and Wang, D. Boosting Contextual Information for Deep Neural Network Based Voice Activity Detection. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 24, 2 2016), 252--264."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015207"}, {"title": "Query Answering over Complete Data with Conceptual Constraints", "authors": ["Nhung Ngo"], "publication": "SIGMOD'16 PhD: Proceedings of the 2016 on SIGMOD'16 PhD Symposium", "abstract": "ABSTRACT\nQuery answering over databases with conceptual constraints is an important problem in database theory. To deal with the problem, the ontology-based data access approach uses ontologies to capture both constraints and databases. In this approach, databases are considered under open-world assumption which creates many issues including the necessity of restricting to only positive queries, and the failure of query composition. In our research, we focus on a combined approach that allows data in databases stays completely as under closed-world assumption while knowledge providing by conceptual constraints can be incomplete. We first study the complexity of query answering problem under description logic constraints in the presence of complete data and show that complete data makes query answering become harder than query answering over incomplete data only. We then provide a query rewriting technique that supports deciding the existence of a safe-range first-order equivalent reformulation of a query in terms of the database schema, and if so, it provides an effective approach to construct the reformulation. Since the reformulation is a safe-range formula, it is effectively executable as an SQL query. At the end, we study the definability abduction problem which aims to characterize the least committing extensions of conceptual constraints to gain the exact rewritable of queries. We also apply this idea to data exchange - where we want to characterize the case of lossless transformations of data.", "references": ["A. Artale, D. Calvanese, R. Kontchakov, and M. Zakharyaschev. The dl-lite family and relations. J. Artif. Int. Res., 36(1):1--69, Sept. 2009.", "F. Baader, S. Brand, and C. Lutz. Pushing the EL envelope. In Proc.\\,of IJCAI 2005, pages 364--369. Morgan-Kaufmann Publishers, 2005.", "F. Baader, S. Brandt, and C. Lutz. Pushing the EL envelope further. In K. Clark and P. F. Patel-Schneider, editors, In Proceedings of the OWLED 2008 DC Workshop on OWL: Experiences and Directions, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926693.2929899"}, {"title": "An improved symbolic aggregate approximation distance measure based on its statistical features", "authors": ["Chaw Thet Zan\n,", "Hayato Yamana"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThe challenges in efficient data representation and similarity measures on massive amounts of time series have enormous impact on many applications. This paper addresses an improvement on Symbolic Aggregate approXimation (SAX), is one of the efficient representations for time series mining. Because SAX represents its symbols by the average (mean) value of a segment with the assumption of Gaussian distribution, it is insufficient to serve the entire deterministic information and causes sometimes incorrect results in time series classification. In this work, SAX representation and distance measure is improved with the addition of another moment of the prior distribution, standard deviation; SAX_SD is proposed. We provide comprehensive analysis for the proposed SAX_SD and confirm both the highest classification accuracy and the highest dimensionality reduction ratio on University of California, Riverside (UCR) datasets in comparison to state of the art methods such as SAX, Extended SAX (ESAX) and SAX Trend Distance (SAX_TD).", "references": ["R. Agrawal, C. Faloutsos, and A. Swami. Efficient similarity search in sequence databases. In Proc. of the 4th Int'l Conf. on Foundations of Data Organization and Algorithms, pages 69--84, October 1993.", "P. Barnaghi, F. Ganz, and C. Henson. Computing perception from sensor data. In Proc. of IEEE Sensors, pages 1--4, 2014.", "D. J. Berndt and J. Clifford. Using dynamic time warping to find patterns in time series. In Proc. of the 3rd Int'l Conf. on Knowledge Discovery and Data Mining, pages 359--370, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011146"}, {"title": "Recommending New Items to Ephemeral Groups Using Contextual User Influence", "authors": ["Elisa Quintarelli\n,", "Emanuele Rabosio\n,", "Letizia Tanca"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nGroup recommender systems help groups of users in finding appropriate items to be enjoyed together. Lots of activities, like watching TV or going to the restaurant, are intrinsically group-based, thus making the group recommendation problem very relevant. In this paper we study ephemeral groups, i.e., groups where the members might be together for the first time. Recent approaches have tackled this issue introducing complex models to be learned offline, making them unable to deal with new items; on the contrary, we propose a group recommender able to manage new items too. In more detail, our technique determines the preference of a group for an item by combining the individual preferences of the group members on the basis of their contextual influence, where the contextual influence represents the ability of an individual, in a given situation, to direct the group's decision. We conducted an extensive experimental evaluation on a TV dataset containing a log of viewings performed by real groups, showing how our approach outperforms the comparable techniques from the literature.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of thestate-of-the-art and possible extensions. IEEE Trans. Knowl. Data Eng., 17(6):734--749, 2005.", "I. Ali and S. Kim. Group recommendations: Approaches and evaluation. In Proc. IMCOM, page 105. ACM, 2014.", "S. Amer-Yahia, S. Basu Roy, A. Chawla, G. Das, and C. Yu. Group recommendation: Semantics and efficiency. PVLDB, 2(1):754--765, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959137"}, {"title": "Learning-to-Rank for Real-Time High-Precision Hashtag Recommendation for Streaming News", "authors": ["Bichen Shi\n,", "Georgiana Ifrim\n,", "Neil Hurley"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe address the problem of real-time recommendation of streaming Twitter hashtags to an incoming stream of news articles. The technical challenge can be framed as large scale topic classification where the set of topics (i.e., hashtags) is huge and highly dynamic. Our main applications come from digital journalism, e.g., promoting original content to Twitter communities and social indexing of news to enable better retrieval and story tracking. In contrast to the state-of-the-art that focuses on topic modelling approaches, we propose a learning-to-rank approach for modelling hashtag relevance. This enables us to deal with the dynamic nature of the problem, since a relevance model is stable over time, while a topic model needs to be continuously retrained. We present the data collection and processing pipeline, as well as our methodology for achieving low latency, high precision recommendations. Our empirical results show that our method outperforms the state-of-the-art, delivering more than 80% precision. Our techniques are implemented in a real-time system that is currently under user trial with a big news organisation.", "references": ["C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning, pages 89--96. ACM, 2005.", "Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning, pages 129--136. ACM, 2007.", "C. Castillo, M. El-Haddad, J. Pfeffer, and M. Stempeck. Characterizing the life cycle of online news stories using social media reactions. In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, pages 211--223. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882982"}, {"title": "YASK: a why-not question answering engine for spatial keyword query services", "authors": ["Lei Chen\n,", "Jianliang Xu\n,", "Christian S. Jensen\n,", "Yafei Li"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith the proliferation of the mobile use of the web, spatial keyword query (SKQ) services are gaining in importance. However, state-of-the-art SKQ systems do not provide systematic functionality that allows users to ask why some known object is unexpectedly missing from a query result and do not provide an explanation for such missing objects. In this demonstration, we present a system called YASK, a wh<u>Y</u>-not question <u>A</u>nswering engine for <u>S</u>patial <u>K</u>eyword query services, that is capable of answering why-not questions posed in response to answers to spatial keyword top-k queries. Two explanation and query refinement models, namely preference adjustment and keyword adaption, are implemented in YASK. The system provides users not only with the reasons why desired objects are missing from query results, but provides also relevant refined queries that revive the expected but missing objects. This demonstration gives attendees hands-on experience with YASK through a map-based GUI interface in which attendees can issue spatial keyword queries, pose why-not questions, and visualize the results.", "references": ["S. S. Bhowmick, A. Sun, and B. Q. Truong. Why Not, WINE?: Towards answering why-not questions in social image search. In MM, pp. 917--926, 2013.", "X. Cao, L. Chen, G. Cong, C. S. Jensen, Q. Qu, A. Skovsgaard, D. Wu, and M. L. Yiu. Spatial Keyword Querying. In ER, pp. 16--29, 2012.", "A. Chapman and H. V. Jagadish. Why not? In SIGMOD, pp. 523--534, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007294"}, {"title": "Combining Holistic and Part-based Deep Representations for Computational Painting Categorization", "authors": ["Rao Muhammad Anwer\n,", "Fahad Shahbaz Khan\n,", "Joost van de Weijer\n,", "Jorma Laaksonen"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAutomatic analysis of visual art, such as paintings, is a challenging inter-disciplinary research problem. Conventional approaches only rely on global scene characteristics by encoding holistic information for computational painting categorization. We argue that such approaches are sub-optimal and that discriminative common visual structures provide complementary information for painting classification.\nWe present an approach that encodes both the global scene layout and discriminative latent common structures for computational painting categorization. The region of interests are automatically extracted, without any manual part labeling, by training class-specific deformable part-based models. Both holistic and region-of-interests are then described using multi-scale dense convolutional features. These features are pooled separately using Fisher vector encoding and concatenated afterwards in a single image representation. Experiments are performed on a challenging dataset with 91 different painters and 13 diverse painting styles. Our approach outperforms the standard method, which only employs the global scene characteristics. Furthermore, our method achieves state-of-the-art results outperforming a recent multi-scale deep features based approach by $6.4\\%$ and $3.8\\%$ respectively on artist and style classification.", "references": ["L. Bourdev, S. Maji, and J. Malik. Describing people: A poselet-based approach to attribute classification. In ICCV, 2011.", "G. Carneiro, N. Silva, A. Bue, and J. Costeira. Artistic image classification: An analysis on the printart database. In ECCV, 2012.", "M. Cimpoi, S. Maji, and A. Vedaldi. Deep filter banks for texture recognition and segmentation. In CVPR, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912063"}, {"title": "From word embeddings to document similarities for improved information retrieval in software engineering", "authors": ["Xin Ye\n,", "Hui Shen\n,", "Xiao Ma\n,", "Razvan Bunescu\n,", "Chang Liu"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering", "abstract": "ABSTRACT\nThe application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community question answering, or more generally the communication between technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are first trained on API documents, tutorials, and reference documents, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly defined task of linking API documents to computer programming questions.", "references": ["A. Bacchelli, M. Lanza, and R. Robbes. Linking e-mails and source code artifacts. In Proc. ICSE '10, pages 375--384, 2010.", "S. K. Bajracharya, J. Ossher, and C. V. Lopes. Leveraging usage similarity for effective retrieval of examples in code repositories. In Proc. FSE '10, pages 157--166, 2010.", "M. Baroni, G. Dinu, and G. Kruszewski. Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. In Proc. ACL '14, pages 238--247, Baltimore, Maryland, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2884781.2884862"}, {"title": "Comparing Pointwise and Listwise Objective Functions for Random-Forest-Based Learning-to-Rank", "authors": ["Muhammad Ibrahim\n,", "Mark Carman"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nCurrent random-forest (RF)-based learning-to-rank (LtR) algorithms use a classification or regression framework to solve the ranking problem in a pointwise manner. The success of this simple yet effective approach coupled with the inherent parallelizability of the learning algorithm makes it a strong candidate for widespread adoption. In this article, we aim to better understand the effectiveness of RF-based rank-learning algorithms with a focus on the comparison between pointwise and listwise approaches.\nWe introduce what we believe to be the first listwise version of an RF-based LtR algorithm. The algorithm directly optimizes an information retrieval metric of choice (in our case, NDCG) in a greedy manner. Direct optimization of the listwise objective functions is computationally prohibitive for most learning algorithms, but possible in RF since each tree maximizes the objective in a coordinate-wise fashion. Computational complexity of the listwise approach is higher than the pointwise counterpart; hence for larger datasets, we design a hybrid algorithm that combines a listwise objective in the early stages of tree construction and a pointwise objective in the latter stages. We also study the effect of the discount function of NDCG on the listwise algorithm.\nExperimental results on several publicly available LtR datasets reveal that the listwise/hybrid algorithm outperforms the pointwise approach on the majority (but not all) of the datasets. We then investigate several aspects of the two algorithms to better understand the inevitable performance tradeoffs. The aspects include examining an RF-based unsupervised LtR algorithm and comparing individual tree strength. Finally, we compare the the investigated RF-based algorithms with several other LtR algorithms.", "references": ["Gérard Biau. 2012. Analysis of a random forests model. Journal of Machine Learning Research 13, 1 (2012), 1063--1095.", "Gérard Biau, Luc Devroye, and Gábor Lugosi. 2008. Consistency of random forests and other averaging classifiers. Journal of Machine Learning Research 9 (2008), 2015--2033.", "Leo Breiman. 2001. Random forests. Machine Learning 45, 1 (2001), 5--32."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2866571"}, {"title": "Cross-Lingual Topic Discovery From Multilingual Search Engine Query Log", "authors": ["Di Jiang\n,", "Yongxin Tong\n,", "Yuanfeng Song"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nToday, major commercial search engines are operating in a multinational fashion to provide web search services for millions of users who compose search queries by different languages. Hence, the search engine query log, which serves as the backbone of many search engine applications, records millions of users’ search history in a wide spectrum of human languages and demonstrates a strong multilingual phenomenon. However, with its salience, the multilingual nature of a search engine query log is usually ignored by existing works, which usually consider query log entries of different languages as being orthogonal and independent. This kind of oversimplified assumption heavily distorts the underlying structure of web search data. In this article, we pioneer in recognition of the multilingual nature of a query log and make the first attempt to cross the language barrier in query logs. We propose a novel model named Cross-Lingual Query Log Topic Model (CL-QLTM) to analyze query logs from a cross-lingual perspective and derive the latent topics of web search data. The CL-QLTM comprehensively integrates web search data in different languages by collectively utilizing cross-lingual dictionaries, as well as the co-occurrence relations in the query log. In order to relieve the efficiency bottleneck of applying the CL-QLTM on voluminous query logs, we propose an efficient parameter inference algorithm based on the MapReduce computing paradigm. Both qualitative and quantitative experimental results show that the CL-QLTM is able to effectively derive cross-lingual topics from multilingual query logs and spawn a wide spectrum of new search engine applications.", "references": ["Vamshi Ambati and U. Rohini. 2006. Using monolingual clickthrough data to build cross-lingual search systems. New Directions in Multilingual Information Access (2006), 28.", "David M. Blei and John D. Lafferty. 2006. Dynamic topic models. In Proceedings of the 23rd International Conference on Machine Learning. ACM, 113--120, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent Dirichlet allocation. The Journal of Machine Learning Research 3 (2003), 993--1022."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2956235"}, {"title": "TAPER: A Contextual Tensor-Based Approach for Personalized Expert Recommendation", "authors": ["Hancheng Ge\n,", "James Caverlee\n,", "Haokai Lu"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe address the challenge of personalized recommendation of high quality content producers in social media. While some candidates are easily identifiable (say, by being \"favorited\" many times), there is a long-tail of potential candidates for whom we have little evidence. Through careful modeling of contextual factors like the geo-spatial, topical, and social preferences of users, we propose a tensor-based personalized expert recommendation framework that integrates these factors for revealing latent connections between homogeneous entities (e.g., users and users) and between heterogeneous entities (e.g., users and experts). Through extensive experiments over geo-tagged Twitter data, we find that the proposed framework can improve the quality of recommendation by over 30% in both precision and recall compared to the state-of-the-art.", "references": ["Supplementary material. http://students.cse.tamu.edu/hge/papers/recsys16_expert_supp.pdf.", "X. Amatriain, N. Lathia, J. M. Pujol, H. Kwak, and N. Oliver. The wisdom of the few: a collaborative filtering approach based on expert opinions from the web. In SIGIR, 2009.", "L. Backstrom, E. Sun, and C. Marlow. Find me if you can: improving geographical prediction with social and spatial proximity. In WWW, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959151"}, {"title": "Analysis of the Paragraph Vector Model for Information Retrieval", "authors": ["Qingyao Ai\n,", "Liu Yang\n,", "Jiafeng Guo\n,", "W. Bruce Croft"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nPrevious studies have shown that semantically meaningful representations of words and text can be acquired through neural embedding models. In particular, paragraph vector (PV) models have shown impressive performance in some natural language processing tasks by estimating a document (topic) level language model. Integrating the PV models with traditional language model approaches to retrieval, however, produces unstable performance and limited improvements. In this paper, we formally discuss three intrinsic problems of the original PV model that restrict its performance in retrieval tasks. We also describe modifications to the model that make it more suitable for the IR task, and show their impact through experiments and case studies. The three issues we address are (1) the unregulated training process of PV is vulnerable to short document over-fitting that produces length bias in the final retrieval model; (2) the corpus-based negative sampling of PV leads to a weighting scheme for words that overly suppresses the importance of frequent words; and (3) the lack of word-context information makes PV unable to capture word substitution relationships.", "references": ["Q. Ai, L. Yang, J. Guo, and W. B. Croft. Improving language estimation with the paragraph vector model for ad-hoc retrieval. In Proceedings of the 39th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2016.", "A. Atreya and C. Elkan. Latent semantic indexing (lsi) fails for trec collections. ACM SIGKDD Explorations Newsletter, 12(2):5--10, 2011.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970409"}, {"title": "Performance-Led Design of Computationally Generated Audio for Interactive Applications", "authors": ["Christian Heinrichs\n,", "Andrew McPherson"], "publication": "TEI '16: Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction", "abstract": "ABSTRACT\nStylized temporal behaviour is difficult to incorporate into computational models of environmental sound, requiring either a specialised algorithm or a potentially large amount of scripted automation. For decades Foley artists have relied on embodied performance to rapidly generate expressive sound effects for the moving image. This research project explores performance-led techniques in the design of computational audio for interactive applications.", "references": ["Edgar Berdahl and JO Smith. 2012. An introduction to the Synth-A-Modeler compiler: Modular and open-source sound synthesis using physical models. In Proceedings of the Linux Audio Conference.", "Alberto Boem. 2014. SculpTon: A Malleable Tangible Interface for Sound Sculpting. Proceedings of the Sound and Music Computing Conference (2014).", "Baptiste Caramiaux, Alessandro Altavilla, Scott G. Pobiner, and Atau Tanaka. 2015. Form Follows Sound: Designing Interactions from Sonic Memories. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 3943--3952."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2839462.2854109"}, {"title": "Development of Failure Detection System for Network Control using Collective Intelligence of Social Networking Service in Large-Scale Disasters", "authors": ["Chihiro Maru\n,", "Miki Enoki\n,", "Akihiro Nakao\n,", "Shu Yamamoto\n,", "Saneyasu Yamaguchi\n,", "Masato Oguchi"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nWhen the Great East Japan Earthquake occurred in 2011, it was difficult to immediately grasp all telecommunications network conditions using only information from network monitoring devices because the damage was considerably heavy and a severe congestion control state occurred. Moreover, at the time of the earthquake, telephone and e-mail services could not be used in many cases-although social networking services (SNSs) were still available. In an emergency, such as an earthquake, users proactively convey information on telecommunications network conditions through SNSs. Therefore the collective intelligence of SNSs is suitable as a means of information detection complementary to conventional observation through network monitoring devices. In this paper, we propose a network failure detection system that detects telephony failures with a high degree of accuracy by using the collective intelligence of Twitter, one of the most widely used SNSs. We also show that network control can be performed automatically and autonomically using information on telecommunications network conditions detected with our system.", "references": ["\"Great East Japan Earthquake - Wikipedia, March 2011\", https://en.wikipedia.org/wiki/2011_Tohoku_earthquake_and_tsunami", "K. Kagawa, Y. Kuno, H. Tamura, H. Takada, M. Furutani, and N. Minamikata, \"Improvement of Credibility for Operation System in the Case of Large Disaster,\" NTT DOCOMO technical journal, vol.20, no.4, pp.26-36, 2013.", "ITU-T Forcus Group on Disaster Relief Systems, \"Monitoring Systems for Outside Plant Facilities,\" ITU-T Recommendations, no.L.81, pp.1-10, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914620"}, {"title": "A computational Model for Accessibility in Smart Cities", "authors": ["Marcelo josue Telles\n,", "Jorge L.V. Barbosa\n,", "Rodrigo Rosa Righi"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis article presents the MASC, which is a computational model for accessibility in smart cities. The use of ubiquitous computing in the area of accessibility provides solutions to support persons with disabilities (PwD). Unlike the proposed approaches, the MASC uses the interactions of PwD to compose trails which will be offered as a service. Moreover supports various disabilities, is intended for mass applications. A prototype was developed to evaluate performance and functionality. This evaluation was conducted with data generated by a context simulator in Sao Leopoldo - RS. The results presented in the tests indicate that the services offered by the model can be applied in smart cities to collaborate with accessibility, helping PwD, health professionals and public administration.", "references": ["AASHTO, American Association of State Highway and Transportation Officials. A policy on geometric design of highways and streets. 2001.", "R. A. Afonso, C. H. Nascimento, V. C. Garcia, and A. Alvaro. Smartcluster: Utilizando dados publicos para agrupar cidades inteligentes por dominios. XI Simposio Brasileiro de Sistemas de Informacao (SBSI), pages 691-694, 2015", "P. C. Albarello. Controle de acesso sensivel ao contexto baseado na inferencia em trilhas. Master thesis, University of Vale do Rio dos Sinos (Unisinos), Applied Computing Graduate Program (PIPCA), Sao Leopoldo, Brazil, 2013.."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021975"}, {"title": "Providing Services in an Intelligent Environment: Smart Home Simulator based WoT", "authors": ["Wassila Guebli\n,", "Abdelkader Belkhir"], "publication": "ICC '16: Proceedings of the International Conference on Internet of things and Cloud Computing", "abstract": "ABSTRACT\nSmart house aims to offer the inhabitant the comfort and the security that they need and take in consideration the preferences and the needs of each member of the family. To do this, each household equipment is considered as a thing and it is connected to the internet. Using the concept of the Web of things, the user can control the home remotely, and activate many services. He can apply scenario, for example: \"sunny-day\" which consist to open all the curtains in the house or he can authorize a person to use or not a services like children. This is why we propose a smart house simulator based WoT, where the user can control his home remotely via the Web using his smart phone.", "references": ["Shiu Kuma, \"Ubiquitous Smart Home System Using Android Application\", International Journal of Computer Networks & Communications (IJCNC) Vol. 6, No. 1, January 2014.DOI: 10.5121/ijcnc.2014.6103 33", "Jonathan Synnott, Chris Nugent, Paul Jeffers, 'Simulation of Smart Home Activity datasets', Journal of Sensors, Vol. 14, Issue. 6, Juin2015.", "Poland, M.P.; Nugent, C.D.; Wang, H.; Chen, L. Development of a smart home simulator for use as a heuristic tool for management of sensor distribution. Technol. Health Care 2009, 17, 171--182."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896387.2896446"}, {"title": "Detecting Good Abandonment in Mobile Search", "authors": ["Kyle Williams\n,", "Julia Kiseleva\n,", "Aidan C. Crook\n,", "Imed Zitouni\n,", "Ahmed Hassan Awadallah\n,", "Madian Khabsa"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWeb search queries for which there are no clicks are referred to as abandoned queries and are usually considered as leading to user dissatisfaction. However, there are many cases where a user may not click on any search result page (SERP) but still be satisfied. This scenario is referred to as good abandonment and presents a challenge for most approaches measuring search satisfaction, which are usually based on clicks and dwell time. The problem is exacerbated further on mobile devices where search providers try to increase the likelihood of users being satisfied directly by the SERP. This paper proposes a solution to this problem using gesture interactions, such as reading times and touch actions, as signals for differentiating between good and bad abandonment. These signals go beyond clicks and characterize user behavior in cases where clicks are not needed to achieve satisfaction. We study different good abandonment scenarios and investigate the different elements on a SERP that may lead to good abandonment. We also present an analysis of the correlation between user gesture features and satisfaction. Finally, we use this analysis to build models to automatically identify good abandonment in mobile search achieving an accuracy of 75%, which is significantly better than considering query and session signals alone. Our findings have implications for the study and application of user satisfaction in search systems.", "references": ["M. S. Bernstein, J. Teevan, S. Dumais, D. Liebling, and E. Horvitz. Direct answers for search queries in the long tail. In Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, pages 237--246, 2012.", "Y. Chen, Y. Liu, K. Zhou, M. Wang, M. Zhang, and S. Ma. Does Vertical Bring more Satisfaction -- Predicting Search Satisfaction in a Heterogeneous Environment. In International Conference on Information and knowledge management (to appear), 2015.", "L. B. Chilton and J. Teevan. Addressing people's information needs directly in a web search result page. In Proceedings of the International Conference on World Wide Web, pages 27--36, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883074"}, {"title": "Evaluating the mobile web accessibility of electronic text for print impaired people in higher education", "authors": ["Neil Rogers\n,", "Professor Mike Wald\n,", "E. A. Draffan"], "publication": "W4A '16: Proceedings of the 13th Web for All Conference", "abstract": "ABSTRACT\nThe aim of this extended abstract is to demonstrate a framework that provides a novel solution for evaluating the mobile web accessibility of electronic text for print impaired people in Higher Education (HE). The current framework explores over 500 device settings. Furthermore, the scope of this research is outlined alongside two research questions. The paper then concludes by suggesting the potential impact this research could have on existing standards, the public availability of metadata and guidelines, and the automatic generation of personalised eTexts as per user needs.", "references": ["DEPARTMENT FOR EDUCATION., 2015. National curriculum in England: framework for key stages 1 to 4 Department for Education, London. http://goo.gl/lG0sV7", "Jeffries, S. and Everatt, J., 2004. Working memory: Its role in dyslexia and other specific learning difficulties. Dyslexia 10, 3 (//), 196--214. DOI= http://dx.doi.org/10.1002/dys.278.", "Kerscher, G., 2015. The definition of \"print disabled\"? Reading Rights Coalition, United States of America. http://goo.gl/JItGm1"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899475.2899504"}, {"title": "The Role of the Unconscious in Information Retrieval: What User Perception Tells Us", "authors": ["Jingjing Liu\n,", "Kendra Albright\n,", "Hassan Zamir"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nIncreasing evidence from psychoanalytic and psychodynamic research suggests that the unconscious influences our daily decisions, and psychologists have suggested that as much as 85-95% of decision making occurs outside our conscious awareness. For information science, it is important to understand how these unconscious processes play a role in information seeking. The current study uses subliminal psychodynamic activation (SPA), through the use of subliminal messages that appeared below the threshold of conscious awareness, to investigate the influence of the unconscious in information searching. Twenty-four college students participated in a controlled laboratory experiment, each searching freely on the Internet for information for three search tasks, with various SPA messages appearing in each search. Participants were systematically assigned to one of the four SPA conditions with various subliminal messages. Users' perceptions of search task topic interest, topic knowledge and task difficulty was examined between different SPA conditions, as well as the change of users' perceptions on topic interest, knowledge, and difficulty before and after searching in different SPA conditions. Findings suggested that users' pre- and post-task ratings of topic interest, knowledge, and difficulty did not show significant differences among the 4 SPA conditions. However, the change in users' perceptions of topic interest and topic knowledge before and after searching showed significant differences when SPA messages were present. Our findings inspire future research in this underexplored field.", "references": ["Albright, K. S. (2010). Multidisciplinarity in Information Behaviour: Expanding Boundaries or Fragmentation of the Field? Libri, 60(2), 98--106.", "Balay, J. & Shevrin, H. (1988). The subliminal psychodynamic activation method: A critical review. American Psychologist, 43, 161--174.", "Birgegakd, A. & Sohlberg, S. (2001). Methodology in Subliminal Psychodynamic Activation: The Next Step in the Debate. Perceptual and Motor Skills, 92, 504--506."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854986"}, {"title": "An Architecture for Privacy-Preserving and Replicable High-Recall Retrieval Experiments", "authors": ["Adam Roegiest\n,", "Gordon V. Cormack"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe demonstrate the infrastructure used in the TREC 2015 Total Recall track to facilitate controlled simulation of \"assessor in the loop\" high-recall retrieval experimentation. The implementation and corresponding design decisions are presented for this platform. This includes the necessary considerations to ensure that experiments are privacy-preserving when using test collections that cannot be distributed. Furthermore, we describe the use of virtual machines as a means of system submission in order to to promote replicable experiments while also ensuring the security of system developers and data providers.", "references": ["http://www.securityfocus.com/news/11497.", "http://www.securitypronews.com/new-scam-tricking-people-by-offering-new-facebook-profile-look-2012--11.", "G. V. Cormack. TREC 2006 Spam Track Overview. In Proc. TREC-2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911456"}, {"title": "Polygon consensus: smart crowdsourcing for extracting building footprints from historical maps", "authors": ["Benedikt Budig\n,", "Thomas C. van Dijk\n,", "Fabian Feitsch\n,", "Mauricio Giraldo Arteaga"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nOver the course of three years, the New York Public Library has run a crowdsourcing project to extract polygonal representation of the building footprints from insurance atlases of the 19th and early-20th century. As is common in crowd-sourcing projects, the overall problem was decomposed into small user tasks and each task was given to multiple users. In the case of polygons representing building footprints, it is unclear how best to integrate the answers into a majority vote: given a set of polygons ostensibly describing the same footprint, what is the consensus? We discuss desirable properties of such a \"consensus polygon\" and arrive at an efficient algorithm. We have manually evaluated the algorithm on approximately 3,000 polygons corresponding to 200 footprints and observe that our algorithmic consensus polygons are correct for 96% of the footprints whereas only 85% of the (input) crowd polygons are correct.", "references": ["C. Balletti, L. Galeazzo, C. Gottardi, F. Guerra, and P. Vernier. New technologies applied to the history of the Venice Lagoon. In Proc. 11th ICA Conf. on Digital Appr. to Cart. Heritage, pages 182--190, 2016.", "K. Buchin, M. Buchin, M. van Kreveld, M. Löffler, R. I. Silveira, C. Wenk, and L. Wiratma. Median Trajectories. Algorithmica, 66(3):595--614, 2013.", "Y.-Y. Chiang, S. Leyk, and C. A. Knoblock. A Survey of Digital Map Processing Techniques. ACM Comp. Surv., 47(1):1:1--1:44, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996951"}, {"title": "Answering why-not and why questions on reverse top-k queries", "authors": ["Qing Liu\n,", "Yunjun Gao\n,", "Gang Chen\n,", "Baihua Zheng\n,", "Linlin Zhou"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWhy-not and why questions can be posed by database users to seek clarifications on unexpected query results. Specifically, why-not questions aim to explain why certain expected tuples are absent from the query results, while why questions try to clarify why certain unexpected tuples are present in the query results. This paper systematically explores the why-not and why questions on reverse top-k queries, owing to its importance in multi-criteria decision making. We first formalize why-not questions on reverse top-k queries, which try to include the missing objects in the reverse top-k query results, and then, we propose a unified framework called WQRTQ to answer why-not questions on reverse top-k queries. Our framework offers three solutions to cater for different application scenarios. Furthermore, we study why questions on reverse top-k queries, which aim to exclude the undesirable objects from the reverse top-k query results, and extend the framework WQRTQ to efficiently answer why questions on reverse top-k queries, which demonstrates the flexibility of our proposed algorithms. Extensive experimental evaluation with both real and synthetic data sets verifies the effectiveness and efficiency of the presented algorithms under various experimental settings.", "references": ["Arnold, S.J., Handelman, J., Tigert, D.J.: The impact of a market spoiler on consumer preference structures (or, what happens when Wal-Mart comes to town). J. Retail. Consum. Serv. 5(1), 1---13 (1998)", "Beckmann, N., Kriegel, H., Schneider, R., Seeger, B.: The r*-tree: an efficient and robust access method for points and rectangles. In: SIGMOD, pp. 322---331 (1990)", "Berg, M., Kreveld, M., Overmars, M., Schwarzkopf, O.: Computational Geometry: Algorithms and Applications. Springer, New York (1997)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0443-4"}, {"title": "Learning Distributed Representations of Data in Community Question Answering for Question Retrieval", "authors": ["Kai Zhang\n,", "Wei Wu\n,", "Fang Wang\n,", "Ming Zhou\n,", "Zhoujun Li"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nWe study the problem of question retrieval in community question answering (CQA). The biggest challenge within this task is lexical gaps between questions since similar questions are usually expressed with different but semantically related words. To bridge the gaps, state-of-the-art methods incorporate extra information such as word-to-word translation and categories of questions into the traditional language models. We find that the existing language model based methods can be interpreted using a new framework, that is they represent words and question categories in a vector space and calculate question-question similarities with a linear combination of dot products of the vectors. The problem is that these methods are either heuristic on data representation or difficult to scale up. We propose a principled and efficient approach to learning representations of data in CQA. In our method, we simultaneously learn vectors of words and vectors of question categories by optimizing an objective function naturally derived from the framework. In question retrieval, we incorporate learnt representations into traditional language models in an effective and efficient way. We conduct experiments on large scale data from Yahoo! Answers and Baidu Knows, and compared our method with state-of-the-art methods on two public data sets. Experimental results show that our method can significantly improve on baseline methods for retrieval relevance. On 1 million training data, our method takes less than 50 minutes to learn a model on a single multicore machine, while the translation based language model needs more than 2 days to learn a translation table on the same machine.", "references": ["R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. JMLR '03, 3:1137--1155, Mar. 2003.", "A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. Bridging the lexical chasm: statistical approaches to answer-finding. In SIGIR'00, pages 192--199, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835786"}, {"title": "In-depth Exploration of Geotagging Performance using Sampling Strategies on YFCC100M", "authors": ["Giorgos Kordopatis-Zilos\n,", "Symeon Papadopoulos\n,", "Yiannis Kompatsiaris"], "publication": "MMCommons '16: Proceedings of the 2016 ACM Workshop on Multimedia COMMONS", "abstract": "ABSTRACT\nEvaluating multimedia analysis and retrieval systems is a highly challenging task, of which the outcomes can be highly volatile depending on the selected test collection. In this paper, we focus on the problem of multimedia geotagging, i.e. estimating the geographical location of a media item based on its content and metadata, in order to showcase that very different evaluation outcomes may be obtained depending on the test collection at hand. To alleviate this problem, we propose an evaluation methodology based on an array of sampling strategies over a reference test collection, and a way of quantifying and summarizing the volatility of performance measurements. We report experimental results on the MediaEval 2015 Placing Task dataset, and demonstrate that the proposed methodology could help capture the performance of geotagging systems in a comprehensive manner that is complementary to existing evaluation approaches.", "references": ["A. Z. Broder. On the resemblance and containment of documents. In Compression and Complexity of Sequences 1997. Proceedings, pages 21--29. IEEE, 1997.", "J. Choi, C. Hauff, O. V. Laere, and B. Thomee. The placing task at mediaeval 2015. In Working Notes Proceedings of the MediaEval 2015 Workshop, Wurzen, Germany, September 14--15, 2015., 2015.", "J. Choi et al. The placing task: A large-scale geo-estimation challenge for social-media videos and images. In Proceedings of GeoMM Workshop, pages 27--31, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983554.2983558"}, {"title": "An Image Retrieval using combined approach Wavelets and Local Binary Pattern", "authors": ["Padmashree Desai\n,", "Jagadeesh Pujari\n,", "Anita Kinnikar"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nWith the invent of Internet and the availability of efficient image capturing devices such as image scanners, digital cameras and high capacity public networks, cheap storage; the volume of digital images is increasing exponentially. This created a need of image searching, retrieval and browsing tool for users from various domains including fashion, crime prevention, publishing, remote sensing, architecture, medicine etc. Content Based Image Retrieval (CBIR) provides a solution for above said issues. Content based image retrieval is the utilization of computer vision techniques to the issue of digital image searching in large databases. The basic principle is the representation of image as a feature vector and to measure the similarities between the query image and feature vectors of images in the database using image processing techniques. Determining correct features to represent the images and the similarity metric that groups visually similar images together are the two main milestones in construction of any CBIR system. In CBIR, the images are sorted/indexed based on visual features, such as color, texture, shape, motion, structure or combining above different features.\nOur proposed approach in content-based image retrieval (CBIR) uses the combination of low level features such as color, texture and shape as main feature to retrieve similar images. Color feature is extracted by transforming the color space from RGB model to HSV model, and then extracting color histogram to form color feature vector. Texture features are extracted by using Gray Level Co-occurrence Matrix (GLCM). Shape feature is extracted by combining features extracted from wavelet transformation and Local Binary Pattern (LBP). Performance of the proposed method is measured using precision-recall. Also its performance is compared with existing method. Results indicate that our combined approach is better than other methods.", "references": ["Amol P Bhagat, and Mohammad Atique, \"Design and Development of Systems for Image Segmentation and Content Based Image Retrieval\", in CISP Proceedings, pp. 109--113, 2012.", "P. S. Hiremath and Jagadeesh Pujari, \"Content Based Image Retrieval using Color, Texture and Shape features\", in 15th International Conference on Advanced Computing and Communications, pp. 780--784, 2007.", "Kavitha and P. Jeyanthi, \"Exemplary Content Based Image Retrieval Using Visual Contents & Genetic Approach\" in IEEE ICCSP conference, pp. 1378--1384, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980404"}, {"title": "An AID for Avoiding Inadvertent Disclosure: Supporting Interactive Review for Privilege in E-Discovery", "authors": ["Jyothi K. Vinjumur\n,", "Douglas W. Oard\n,", "Amittai Axelrod"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWhen searching for evidence in civil litigation, parties to a lawsuit have the right to withhold some content on grounds of specific privileges that serve to foster socially desirable outcomes such as open communication between attorneys and their clients. As inadvertent disclosure of privileged content can adversely impact a client's interests, review for privilege is a high-stakes process that is most often performed manually. Because the circumstances in which privilege can be claimed are generally well defined, review for privilege is amenable to some degree of automation. This paper describes the design of an interactive system to support privilege review in which the goals are to improve the speed and accuracy of privilege review. Results are reported for a within-subjects study in which six reviewers with different levels of expertise examined email for attorney-client privilege or any other valid basis for withholding the content from release. Quantitative results indicate that substantial and statistically significant improvements in recall can be achieved, but no significant differences in average review speed were detected. Participants self-reported that the identity features exposed by the system were most useful to them, and that the present implementation of features based on content or date added no discernible additional value.", "references": ["Armstrong v. Bush, 1989.", "A. Agresti and B. A. Coull. Approximate is better than \"exact\" for interval estimation of binomial proportions. The American Statistician, 1998.", "R. Artstein and M. Poesio. Inter-coder agreement for computational linguistics. Computational Linguistics, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854964"}, {"title": "Patterns in the Chaos—A Study of Performance Variation and Predictability in Public IaaS Clouds", "authors": ["Philipp Leitner\n,", "Jürgen Cito"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nBenchmarking the performance of public cloud providers is a common research topic. Previous work has already extensively evaluated the performance of different cloud platforms for different use cases, and under different constraints and experiment setups. In this article, we present a principled, large-scale literature review to collect and codify existing research regarding the predictability of performance in public Infrastructure-as-a-Service (IaaS) clouds. We formulate 15 hypotheses relating to the nature of performance variations in IaaS systems, to the factors of influence of performance variations, and how to compare different instance types. In a second step, we conduct extensive real-life experimentation on four cloud providers to empirically validate those hypotheses. We show that there are substantial differences between providers. Hardware heterogeneity is today less prevalent than reported in earlier research, while multitenancy has a dramatic impact on performance and predictability, but only for some cloud providers. We were unable to discover a clear impact of the time of the day or the day of the week on cloud performance.", "references": ["Sayaka Akioka and Yoichi Muraoka. 2010. HPC benchmarks on Amazon EC2. In Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA’10). 1029--1034. DOI:http://dx.doi.org/10.1109/WAINA.2010.166", "Michael Armbrust, Armando Fox, Rean Griffith, Anthony D. Joseph, Randy Katz, Andy Konwinski, Gunho Lee, David Patterson, Ariel Rabkin, Ion Stoica, and Matei Zaharia. 2010. A view of cloud computing. Communications of the ACM 53, 4, 50--58.", "Gültekin Ataş and Vehbi Cagri Gungor. 2014. Performance evaluation of cloud computing platforms using statistical methods. Computers and Electrical Engineering 40, 5, 1636--1649. DOI:http://dx.doi.org/10.1016/j.compeleceng.2014.03.017"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2885497"}, {"title": "HRRP Reconstruction of Sub-Nyquist Sampled Chirp Signals with CS-based Dechirping", "authors": ["Zhaoyu Gu\n,", "Wei Wang\n,", "Guoyu Wang"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nBenefiting bythe large time-bandwidth product, chirp signals arefrequentlyadopted in modern radars. In this paper, the influence on thehigh-resolution range profile (HRRP) reconstruction of chirp waveform after sub-Nyquist sampling is investigated, where the (compressive sensing) CS-based dechirpingalgorithms are applied to achieve the range compression of the sub-Nyquist sampled chirp signals. The conditions that the HRRP can be recovered from the sub-Nyquist sampled chirp signals via CS-based dechirping are addressed. The simulated echoes, formed by the sub-Nyquist sampled chirp signals and scattered by moving targets, are collected by radars to yieldthe high-resolution range profile (HRRP) which validate the correctness of the analyses.", "references": ["Skolink, M. I. 2001. Introduction to radar systems. McGraw-Hill.", "Caputi, W. J. 1971. Stretch: A Time-transformation technique, IEEE Transactions on Aerospace and Electronic Systems, AES-7,2, 269--278.", "Yang, J., Zhang, Y. 2015. An airborne SAR moving target imaging and motion parameters estimation algorithm with azimuth-dechirping and the second-order keystone transform applied, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 8,8, 3967--3976."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015195"}, {"title": "Multileave Gradient Descent for Fast Online Learning to Rank", "authors": ["Anne Schuth\n,", "Harrie Oosterhuis\n,", "Shimon Whiteson\n,", "Maarten de Rijke"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nModern search systems are based on dozens or even hundreds of ranking features. The dueling bandit gradient descent (DBGD) algorithm has been shown to effectively learn combinations of these features solely from user interactions. DBGD explores the search space by comparing a possibly improved ranker to the current production ranker. To this end, it uses interleaved comparison methods, which can infer with high sensitivity a preference between two rankings based only on interaction data. A limiting factor is that it can compare only to a single exploratory ranker. We propose an online learning to rank algorithm called multileave gradient descent (MGD) that extends DBGD to learn from so-called multileaved comparison methods that can compare a set of rankings instead of merely a pair. We show experimentally that MGD allows for better selection of candidates than DBGD without the need for more comparisons involving users. An important implication of our results is that orders of magnitude less user interaction data is required to find good rankers when multileaved comparisons are used within online learning to rank. Hence, fewer users need to be exposed to possibly inferior rankers and our method allows search engines to adapt more quickly to changes in user preferences.", "references": ["L. Azzopardi, M. de Rijke, and K. Balog. Building simulated queries for known-item topics: an analysis using six European languages. SIGIR '07. ACM, 2007.", "R. Berendsen, M. Tsagkias, W. Weerkamp, and M. de Rijke. Pseudo test collections for training and tuning microblog rankers. SIGIR '13. ACM, 2013.", "B. Carterette and J. Allan. Incremental test collections. In CIKM. ACM, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835804"}, {"title": "The impacts of time constraint on users' search strategy during search process", "authors": ["Chang Liu\n,", "Yiming Wei"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis study examined the effects of time constraints on searchers' information search strategies during search process, particularly at two search stages (first round and end point). A user experiment with forty participants was conducted, and each participant was asked to search with and without time constraint. The results showed that time constraint had significant effect on users' first/mean dwell time on search engine result pages (SERPs) during the first query interval; however, time constraint did not influence their dwell time on SERPs or content pages when the whole session was considered, and it only had significant effect on the number of pages viewed per query. The findings indicated that users did employ different search strategies when searching with and without time constraint, and their search strategies changed over time within the search session. Generally, when there was no time constraint, users tended to employ economic-style search strategy at the beginning of search; but when given time constraint, they became more selective and cautious in examining the search results. The findings of this study have implications for search system design to assist searchers under time constraint and help them search more effectively and efficiently.", "references": ["Aula, A., Majaranta, P., & Räihä, K. J. (2005). Eye-tracking reveals the personal styles for search result evaluation. In Human-Computer Interaction-INTERACT 2005 (pp. 1058--1061). Springer Berlin Heidelberg.", "Anderson, L. W. & Krathwohl, D. A. (2001). A taxonomy for learning, teaching and assessing: A revision of Bloom's taxonomy of educational objectives. New York: Longman.", "Bates, M.J. (1979). Information search tactics. Journal of the American Society for Information Science, 30(4):205--214."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017498"}, {"title": "Interruptibility research: opportunities for future flourishment", "authors": ["Tadashi Okoshi\n,", "Jin Nakazawa\n,", "Hideyuki Tokuda"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nAs users enjoy their computing with an increasing number of devices, applications and services, and connected other users, users' attention is getting the most precious resource in computing due to increasing information fragments provided proactively. Research on user's attention management and especially interruptibility have been accelerated in the recent years. After clarifying some recent background computing trends, this paper focuses on those researches areas, specifies several possible opportunities in the area, and proposes 3 key future opportunities that include being a layer and platform, communication with industries, and intersection with research areas. This paper aims to motivate active discussion on how we can make our research flourish in rather longer term.", "references": ["BI Intelligence. 2014. Here Comes The Internet Of Things. https://intelligence.businessinsider.com/the-internet-of-things-2013--10. (Aug. 2014).", "Fitbit Inc. 2014. Fitbit Trackers. http://www.fitbit.com/. (2014).", "Flurry. 2014. App Install Addiction Shows No Signs of Stopping. http://flurrymobile.tumblr.com/post/115194583975/app-install-addiction-shows-no-signs-of-stopping. (Dec. 2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2968543"}, {"title": "Why do you Think this Query is Difficult?: A User Study on Human Query Prediction", "authors": ["Stefano Mizzaro\n,", "Josiane Mothe"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPredicting if a query will be difficult for a system is important to improve retrieval effectiveness by implementing specific processing. There have been several attempts to predict difficulty, both automatically and manually; but without high accuracy at a pre-retrieval stage. In this paper, we focus rather on understanding Why a query is perceived by humans as difficult. We ran two separated but related experiments in which we asked humans to provide both a query difficulty prediction and reasons to explain their prediction. Results show that: (i) reasons can be categorized into 4 classes; (ii) reasons can be framed into closed questions to be answered on a Likert scale; and (iii) some reasons correlate in a coherent way with the human predicted numerical difficulty. On the basis of these results it is possible to derive hints to be provided to help users when formulating their queries and to avoid them to rely on their wrong perception of difficulty.", "references": ["J.-P. Benzécri et al. Correspondence analysis handbook. Marcel Dekker New York, 1992.", "D. Carmel and E. Yom-Tov. Estimating the query difficulty for information retrieval. Morgan & Claypool Publishers, 2010.", "K. Collins-Thompson, C. Macdonald, P. Bennett, F. Diaz, and E. Voorhees. TREC 2014 Web Track Overview. In Text REtrieval Conference, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914696"}, {"title": "Integrating Decision Making Methods on Requerimentos Elicitation Process", "authors": ["Maria A.C. Meireles\n,", "Jorge Y. Kanda\n,", "Bruno A. Bonifacio\n,", "Jonatan S. Leao"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe identification of requirements of a computer system, which satisfy the needs of users, has become a key factor for the success of this system over the years. It is important to ensure that the requirements are correctly identified with minimal effort in its elicitation process. For this, we propose the use of methods that favor the choice of the most appropriate techniques for elicitation of requirements in order to minimize the cases in which the requirements are incorrectly indicated. This paper presents an approach that uses a decision matrix composed of values, which represent the importance of the techniques based on a set of criteria previously known. The matrix is submitted to the decision-making methods Electre II and AHP Referenced that generate the most promising alternatives. In our studies, the procedures for calculating these methods have been automated in the software named ATD (Assistant Decision Making), which we are developing for mobile devices. A set of data generated from the literature and information provided by professionals of the area of information systems development was submitted to ATD. The results obtained are promising and can help professionals from mentioned area in their activities of selection process of the most appropriate elicitation techniques to be applied to the problem whose solution will be solved by a computer system.", "references": ["Pressman, R. S. 2011. Engenharia de Software: Uma abordagem Profissional. Porto Alegre: AMGH.", "Espindola, Rodrigo dos Santos., Majdenbaum, Azriel., e Audy, Jorge Luis Nicolas. 2004. Uma Analise Critica dos Desafios para Engenharia de Requisitos em Manutencao de Software. In: Anais do VII Workshop em Engenharia de Requisitos, Tandil: Argentina, p. 226-238.", "Sommerville, I., and Sawyer, Peter. 1997. Requirements Engineering - a good practice guide. New York: John Wiley e Sons Ltda."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022044"}, {"title": "Query Processing over Large RDF using SPARQL in Big Data", "authors": ["Priti Khodke\n,", "Saurabh Lawange\n,", "Amol Bhagat\n,", "Kiran Dongre\n,", "Chetan Ingole"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nInternet search is done by exploring the link graph and keyword frequency. In 2012, Google released \"Knowledge Graph\" --Semantic Web. The human reasoning can be enhanced by the use semantic web an emerging area. Most of the current applications link open data views due to which there is huge flow of data in semantic web, particularly Resource Description Framework (RDF) data. In the semantic web research community this leads to design and development of scalable data processing techniques for RDF data. The aim of semantic web is to make available semantically connected data across the globe. This is a review paper giving analysis of techniques implemented to achieve the aim of semantic web, various approaches to processes RDF data. Within the semantic web community, RDF is a common acronym because it forms one of the basic building blocks for forming the web of semantic data, called a \"graph database\". This paper compares various methodologies followed by different researchers along with the results analysis of implemented techniques over different datasets.", "references": ["Husain M. F., McGlothlin J., Masud M. M., Khan L. R., Thuraisingham B.: Data Intensive Query Processing for Large RDF Graphs Using Cloud Computing Tools. IEEE 3rd International Conference on Cloud Computing (2010).", "Chang L, Haofen W, Yong Y., Linhao X.: Towards Efficient SPARQL Query Processing on RDF Data. Tsinghua Science and Tech. 613--622, Vol. 15, No. 6, (2011).", "Husain M. F., McGlothlin J., Masud M. M., Khan L. R., Thuraisingham B.: Heuristic Based Query Processing for Large RDF Graphs Using Cloud Computing, IEEE Trans On Knowledge and Data Engg. Vol. 23, No. 9, (2011)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905124"}, {"title": "One Query, Many Clicks: Analysis of Queries with Multiple Clicks by the Same User", "authors": ["Elad Kravi\n,", "Ido Guy\n,", "Avihai Mejer\n,", "David Carmel\n,", "Yoelle Maarek\n,", "Dan Pelleg\n,", "Gilad Tsur"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we study multi-click queries - queries for which more than one click is performed by the same user within the same query session. Such queries may reflect a more complex information need, which leads the user to examine a variety of results. We present a comprehensive analysis that reveals unique characteristics of multi-click queries, in terms of their syntax, lexical domains, contextual properties, and returned search results page. We also show that a basic classifier for predicting multi-click queries can reach an accuracy of 75% over a balanced dataset. We discuss the implications of our findings for the design of Web search tools.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In Proceedings of SIGIR, pages 19--26. ACM, 2006.", "A. Berger and J. Lafferty. Information retrieval as statistical translation. In Proceedings of SIGIR, pages 222--229, 1999.", "M. S. Bernstein, J. Teevan, S. Dumais, D. Liebling, and E. Horvitz. Direct answers for search queries in the long tail. In Proceedings of CHI, pages 237--246. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983856"}, {"title": "Session details: Volume I: Artificial intelligence and agents, distributed systems, and information systems: Web technologies track", "authors": ["Angelo Di Iorio\n,", "Davide Rossi\n,", "Cristian Mateos"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252790"}, {"title": "OREGANO: Play a concert organ using your voice", "authors": ["Johan Fagerlönn\n,", "Stefan Lindberg\n,", "Anna Sirkka\n,", "Gunnar Oledal"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nThis paper describes the first version of Oregano, a system that allows people to interact with a large concert organ using their voices and a touch display. The main objective of the design was to increase the organ's accessibility for the general public and enhance their experience when visiting the Studio Acusticum concert hall in Piteå, Sweden. A number of built-in prerecorded songs allow visitors and concert-hall personnel to easily experience and demonstrate the instrument's capabilities. In addition, the voice interaction facilitates new types of fun interaction and musical expressions using the instrument. The concept will be set up in a permanent installation inside the concert hall during upcoming work.", "references": ["Jason Nolan, Steve Mann and Danny Bakan. 2012. Nessie the Hydraulophone: A Water-Driven Musical Object for Children. Children Youth and Environments 22, 2: 263--272.", "Wayne Siegel. Everyone talks about the weather. Retrieved May 18, 2016 from http://waynesiegel.dk/?page_id=1223", "Chris Vik. Controlling a four-story pipe organ with the Kinect. Retrieved May 18, 2016 from https://chrisvik.wordpress.com/2012/04/03/controlling-a-4-story-pipe-organ-with-the-kinect/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986454"}, {"title": "Toward Estimating the Rank Correlation between the Test Collection Results and the True System Performance", "authors": ["Julián Urbano\n,", "Mónica Marrero"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe Kendall ? and AP rank correlation coefficients have become mainstream in Information Retrieval research for comparing the rankings of systems produced by two different evaluation conditions, such as different effectiveness measures or pool depths. However, in this paper we focus on the expected rank correlation between the mean scores observed with a test collection and the true, unobservable means under the same conditions. In particular, we propose statistical estimators of ? and AP correlations following both parametric and non-parametric approaches, and with special emphasis on small topic sets. Through large scale simulation with TREC data, we study the error and bias of the estimators. In general, such estimates of expected correlation with the true ranking may accompany the results reported from an evaluation experiment, as an easy to understand figure of reliability. All the results in this paper are fully reproducible with data and code available online", "references": ["B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. If I Had a Million Queries. In ECIR, 2009.", "W. H. Holtzman. The Unbiased Estimate of the Population Variance and Standard Deviation. Am. J. Psychology, 1950.", "M. G. Kendall. A New Measure of Rank Correlation. Biometrika, 1938."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914752"}, {"title": "A reference architecture for big data systems in the national security domain", "authors": ["John Klein\n,", "Ross Buglak\n,", "David Blockow\n,", "Troy Wuttke\n,", "Brenton Cooper"], "publication": "BIGDSE '16: Proceedings of the 2nd International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nAcquirers, system builders, and other stakeholders of big data systems need to define requirements, develop and evaluate solutions, and integrate systems together. A reference architecture enables these software engineering activities by standardizing nomenclature, defining key solution elements and their relationships, collecting relevant solution patterns, and classifying existing technologies. Within the national security domain, existing reference architectures for big data systems have not been useful because they are too general or are not vendor-neutral. We present a reference architecture for big data systems that is focused on addressing typical national defence requirements and that is vendor-neutral, and we demonstrate how to use this reference architecture to define solutions in one mission area.", "references": ["Lockheed Martin, \"Autonomic Logistics Information System (ALIS).\" Lockheed Martin, Inc., Brochure, CS00086-55, 2009.", "Infochimps, \"CIOs and big data: What your team wants you to know.\", http://www.infochimps.com/resources/report-cios-big-data-what-your-it-team-wants-you-to-know-6/ (Accessed 18 Jan 2016).", "I. Gorton and J. Klein, \"Distribution, Data, Deployment: Software Architecture Convergence in Big Data Systems,\" IEEE Software, vol. 32, no. 3, pp. 78--85, May/June 2015. doi: 10.1109/MS.2014.51."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896825.2896834"}, {"title": "AntiLoiter: A Loitering Discovery System for Longtime Videos across Multiple Surveillance Cameras", "authors": ["Jianquan Liu\n,", "Shoji Nishimura\n,", "Takuya Araki"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nSince loitering is a suspicious behavior that often leads to abnormal situations, such as pickpocketing and terrorist attacks, its analysis attracts increasing research attention. In this paper, we present AntiLoiter, a practical loitering discovery system for surveillance. AntiLoiter can efficiently discover loitering candidates from longtime videos across multiple cameras. Most of existing systems mainly focus on how to detect or identify loiterers by behavior tracking techniques. However, the difficulties of tracking-based methods are known as that their analysis results are heavily influenced by occlusions, overlaps, and shadows. Moreover, tracking-based methods need to track the human appearance continuously. Therefore, they are not readily applied to longtime videos across multiple cameras due to the appearance discontinuity of criminal loitering. For instance, a suspect would probably come to the same place several times on different dates for preliminary inspections before a terrorist attack happens, where the loitering behavior is discontinuous. To solve this problem, we abandon the tracking method, instead, design a novel approach to efficiently discover loiterers based on their frequent appearance patterns for longtime videos across multiple cameras. Our approach simply yet effectively adopts existing face recognition techniques for loitering discovery. We conducted extensive experiments on both synthetic and real surveillance videos to evaluate the efficiency and efficacy of our approach. The experimental results show that our system can find out loitering candidates correctly and outperforms existing method by 100 times in terms of runtime.", "references": ["Tomi R\\\"aty. Survey on contemporary remote surveillance systems for public safety. IEEE Trans. Systems, Man, and Cybernetics, Part C, 40(5):493--515, 2010.", "Mubarak Shah, Omar Javed, and Khurram Shafique. Automated visual surveillance in realistic scenarios. IEEE MultiMedia, 14(1):30--39, 2007.", "Paris attacks: What happened on the night, 9 Dec. 2015. www.bbc.com/news/world-europe-34818994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2970927"}, {"title": "Q2P: Discovering Query Templates via Autocompletion", "authors": ["Wensheng Wu\n,", "Weiyi Meng\n,", "Weifeng Su\n,", "Guangyou Zhou\n,", "Yao-Yi Chiang"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nWe present Q2P, a system that discovers query templates from search engines via their query autocompletion services. Q2P is distinct from the existing works in that it does not rely on query logs of search engines that are typically not readily available. Q2P is also unique in that it uses a trie to economically store queries sampled from a search engine and employs a beam-search strategy that focuses the expansion of the trie on its most promising nodes. Furthermore, Q2P leverages the trie-based storage of query sample to discover query templates using only two passes over the trie. Q2P is a key part of our ongoing project Deep2Q on a template-driven data integration on the Deep Web, where the templates learned by Q2P are used to guide the integration process in Deep2Q. Experimental results on four major search engines indicate that (1) Q2P sends only a moderate number of queries (ranging from 597 to 1,135) to the engines, while obtaining a significant number of completions per query (ranging from 4.2 to 8.5 on the average); (2) a significant number of templates (ranging from 8 to 32 when the minimum support for frequent templates is set to 1%) may be discovered from the samples.", "references": ["Ganesh Agarwal, Govind Kabra, and Kevin Chen-Chuan Chang. 2010. Towards rich query interpretation: Walking back and forth for mining query templates. In Proc. of WWW. 1--10.", "Rakesh Agrawal and Ramakrishnan Srikant. 1995. Mining sequential patterns. In Proc. of ICDE. 3--14.", "Amazon. 2014. Amazon Autocompletion API. Retrieved from http://completion.amazon.com/search/complete?method&equals;completion&search-alias&equals;&equals;aps&client&equals;&equals;amazon-search-ui&mkt&equals;&equals;1&x&equals;&equals;updateISSCompletion& sc&equals;&equals;1&noCacheIE&equals;&equals;1294493634389&q&equals;&equals;{query}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2873061"}, {"title": "Data depth based clustering analysis", "authors": ["Myeong-Hun Jeong\n,", "Yaping Cai\n,", "Clair J. Sullivan\n,", "Shaowen Wang"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nThis paper proposes a new algorithm for identifying patterns within data, based on data depth. Such a clustering analysis has an enormous potential to discover previously unknown insights from existing data sets. Many clustering algorithms already exist for this purpose. However, most algorithms are not affine invariant. Therefore, they must operate with different parameters after the data sets are rotated, scaled, or translated. Further, most clustering algorithms, based on Euclidean distance, can be sensitive to noises because they have no global perspective. Parameter selection also significantly affects the clustering results of each algorithm. Unlike many existing clustering algorithms, the proposed algorithm, called data depth based clustering analysis (DBCA), is able to detect coherent clusters after the data sets are affine transformed without changing a parameter. It is also robust to noises because using data depth can measure centrality and outlyingness of the underlying data. Further, it can generate relatively stable clusters by varying the parameter. The experimental comparison with the leading state-of-the-art alternatives demonstrates that the proposed algorithm outperforms DBSCAN and HDBSCAN in terms of affine invariance, and exceeds or matches the ro-bustness to noises of DBSCAN or HDBSCAN. The robust-ness to parameter selection is also demonstrated through the case study of clustering twitter data.", "references": ["P. F. Alcantarilla, A. Bartoli, and A. J. Davison. Kaze features. In European Conference on Computer Vision, pages 214--227. Springer, 2012.", "M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. OPTICS: Ordering points to identify the clustering structure. In Proc. of the 1999 ACM SIGMOD International Conference on Management of Data, SIGMOD '99, pages 49--60, New York, NY, USA, 1999.", "D. Arthur and S. Vassilvitskii. K-means++: The advantages of careful seeding. In Proc. of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA '07, pages 1027--1035, Philadelphia, PA, USA, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996984"}, {"title": "Time-Quality Trade-offs in Search", "authors": ["Ryan Burton"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, I propose a research agenda surrounding the notion of slow search, where retrieval speed may be traded for improvements in result quality. This time-quality trade- off leads to a number of implications in the areas of human- computer interaction and information retrieval algorithms, and I plan to explore this space along various dimensions, including adjustments in user behavior when exposed to new search paradigms, investigating the utility a user perceives when given the option to use slow search in addition to traditional search, and examining different notions of 'quality'.\nI have conducted preliminary studies to probe user behavior and attitudes towards a particular implementation of slow search, and how users? expected behaviors compare to their actual behaviors. I will provide an outline of these studies, and propose future work in this as well as related areas.", "references": ["M. Dörk, P. Bennett, and R. Davies. Taking our sweet time to search. In Proceedings of CHI 2013 Workshop on Changing Perspectives of Time in HCI, 2013.", "M. L. Mauldin. Retrieval performance in FERRET: A conceptual information retrieval system. In Proceedings of SIGIR 1991, pages 347--355. ACM, 1991.", "L. Poirier and L. Robinson. Informational balance: slow principles in the theory and practice of information behaviour. Journal of Documentation, 70(4):687--707, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911484"}, {"title": "On the Retrieval of Wikipedia Articles Containing Claims on Controversial Topics", "authors": ["Haggai Roitman\n,", "Shay Hummel\n,", "Ella Rabinovich\n,", "Benjamin Sznajder\n,", "Noam Slonim\n,", "Ehud Aharoni"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThis work presents a novel claim-oriented document retrieval task. For a given controversial topic, relevant articles containing claims that support or contest the topic are retrieved from a Wikipedia corpus. For that, a two-step retrieval approach is proposed. At the first step, an initial pool of articles that are relevant to the topic are retrieved using state-of-the-art retrieval methods. At the second step, articles in the initial pool are re-ranked according to their potential to contain as many relevant claims as possible using several claim discovery features. Hence, the second step aims at maximizing the overall claim recall of the retrieval system. Using a recently published claims benchmark, the proposed retrieval approach is demonstrated to provide more relevant claims compared to several other retrieval alternatives.", "references": ["E. Aharoni, A. Polnarov, T. Lavee, D. Hershcovich, R. Levy, R. Rinott, D. Gutfreund, and N. Slonim. A benchmark dataset for automatic detection of claims and evidence in the context of controversial topics. In Proceedings of the First Workshop on Argumentation Mining, ACL '14, 2014.", "P. Bellot, A. Doucet, S. Geva, S. Gurajada, J. Kamps, G. Kazai, M. Koolen, A. Mishra, V. Moriceau, J. Mothe, et al. Overview of inex 2013. In Information Access Evaluation. Multilinguality, Multimodality, and Visualization, pages 269--281. Springer, 2013.", "E. Cabrio and S. Villata. Combining textual entailment and argumentation theory for supporting online debates interactions. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL '12, pages 208--212, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891115"}, {"title": "Marbling Grading Framework Applied on Meat Boutique Environment", "authors": ["Saulo M. Mastelini\n,", "Matheus C. Silva\n,", "Ana P.A.C. Barbon\n,", "Sylvio Barbon Junior"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nBovine meat commercialization has an important role in the general food market scenario. The beef quality evaluation is realized through many ways, being one of the parameters the intramuscular fat amount (marbling). This evaluation is often made by a visual approach, so the process is subjective and susceptible to some errors sources. The use of Computer Vision techniques results in an automatized, non-subjective, fast and accurate method for evaluation. This paper presents the modeling and development of a Computer Vision System for Marbling evaluation, applied on a meat Boutique, localized in Londrina - PR. The proposed System uses a Computer Vision approach to control the features of the marbling analysis tool, aiming to satisfy sanitary requirements for non-contamination of the analyzed samples. Besides that, multiples samples on the scene are supported by our application. The proposed Computer Vision System has proved to be suitable for implantation in a production environment, like a meat Boutique.", "references": ["D. E. Anderson and M. Rings. Current veterinary therapy: food animal practice. Elsevier Health Sciences, 2008.", "A. M. S. Association et al. Meat evaluation handbook. American Meat Science Association National Cattlemen's Beef Association (US) National Pork Producers Council (US), 2001.", "S. Beucher et al. The watershed transformation applied to image segmentation. SCANNING MICROSCOPY-SUPPLEMENT-, pages 299-299, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022046"}, {"title": "SolidNoise: Making Musical Robots", "authors": ["Jiffer Harriman\n,", "Matthew Bethancourt\n,", "Abhishek Narula\n,", "Michael Theodore\n,", "Mark Gross"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis late breaking work submission describes the development of tools and techniques aimed to simplify the development and use of musical robots. We describe these tools and techniques as utilized to produce an event known as SolidNoise. The event showcased a series of automated instruments and musical compositions created for the robotic ensemble. Our developments are motivated by historical examples of automated instruments and our vision for musical robots in the future.", "references": ["Diakopoulos, D., & Kapur, a. (2011). HIDUINO: A firmware for building driverless USB-MIDI devices using the Arduino microcontroller. Proceedings of the International Conference on New Interfaces for Musical Expression.", "Doyle, Tom. \"Pat Metheny's Orchestrion.\" Sound On Sound. April, 2010.", "Fiebrink, Rebecca, Ge Wang, and Perry R. Cook. \"Don't forget the laptop: using native input capabilities for expressive musical control.\" Proceedings of the 7th international conference on New interfaces for musical expression. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892539"}, {"title": "The Goal Behind the Action: Toward Goal-Aware Systems and Applications", "authors": ["Dimitra Papadimitriou\n,", "Georgia Koutrika\n,", "John Mylopoulos\n,", "Yannis Velegrakis"], "publication": "ACM Transactions on Database Systems", "abstract": "Abstract\nHuman activity is almost always intentional, be it in a physical context or as part of an interaction with a computer system. By understanding why user-generated events are happening and what purposes they serve, a system can offer a significantly improved and more engaging experience. However, goals cannot be easily captured. Analyzing user actions such as clicks and purchases can reveal patterns and behaviors, but understanding the goals behind these actions is a different and challenging issue. Our work presents a unified, multidisciplinary viewpoint for goal management that covers many different cases where goals can be used and techniques with which they can be exploited. Our purpose is to provide a common reference point to the concepts and challenging tasks that need to be formally defined when someone wants to approach a data analysis problem from a goal-oriented point of view. This work also serves as a springboard to discuss several open challenges and opportunities for goal-oriented approaches in data management, analysis, and sharing systems and applications.", "references": ["Icek Ajzen. 1991. The theory of planned behavior. Organizational Behavior and Human Decision Processes 50, 2 (1991), 179--211.", "Han The Anh and Luis Moniz Pereira. 2013. State-of-the-art of intention recognition and its use in decision making. AI Communications 26, 2 (2013), 237--246.", "Marcelo Gabriel Armentano and Anala Amandi. 2007. Plan recognition for interface agents. Artificial Intelligence Review 28, 2 (2007), 131--162."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934666"}, {"title": "Sound and Music Recommendation with Knowledge Graphs", "authors": ["Sergio Oramas\n,", "Vito Claudio Ostuni\n,", "Tommaso Di Noia\n,", "Xavier Serra\n,", "Eugenio Di Sciascio"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nThe Web has moved, slowly but steadily, from a collection of documents towards a collection of structured data. Knowledge graphs have then emerged as a way of representing the knowledge encoded in such data as well as a tool to reason on them in order to extract new and implicit information. Knowledge graphs are currently used, for example, to explain search results, to explore knowledge spaces, to semantically enrich textual documents, or to feed knowledge-intensive applications such as recommender systems. In this work, we describe how to create and exploit a knowledge graph to supply a hybrid recommendation engine with information that builds on top of a collections of documents describing musical and sound items. Tags and textual descriptions are exploited to extract and link entities to external graphs such as WordNet and DBpedia, which are in turn used to semantically enrich the initial data. By means of the knowledge graph we build, recommendations are computed using a feature combination hybrid approach. Two explicit graph feature mappings are formulated to obtain meaningful item feature representations able to catch the knowledge embedded in the graph. Those content features are further combined with additional collaborative information deriving from implicit user feedback. An extensive evaluation on historical data is performed over two different datasets: a dataset of sounds composed of tags, textual descriptions, and user’s download information gathered from Freesound.org and a dataset of songs that mixes song textual descriptions with tags and user’s listening habits extracted from Songfacts.com and Last.fm, respectively. Results show significant improvements with respect to state-of-the-art collaborative algorithms in both datasets. In addition, we show how the semantic expansion of the initial descriptions helps in achieving much better recommendation quality in terms of aggregated diversity and novelty.", "references": ["Gediminas Adomavicius and YoungOk Kwon. 2012. Improving aggregate recommendation diversity using ranking-based techniques. IEEE Trans. Knowl. Data Eng. 24, 5 (2012), 896--911.", "Mehdi Hosseinzadeh Aghdam, Negar Hariri, Bamshad Mobasher, and Robin D. Burke. 2015. Adapting recommendations to contextual changes using hierarchical hidden Markov models. In Proceedings of the 9th ACM Conference on Recommender Systems (RecSys’15). 241--244.", "Sarabjot Singh Anand, Patricia Kearney, and Mary Shapcott. 2007. Generating semantically enriched user profiles for web personalization. ACM Trans. Internet Technol. 7, 4, Article 22 (Oct. 2007)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926718"}, {"title": "CALAPPA: a toolchain for mining Android applications", "authors": ["Vitalii Avdiienko\n,", "Konstantin Kuznetsov\n,", "Paolo Calciati\n,", "Juan Carlos Caiza Román\n,", "Alessandra Gorla\n,", "Andreas Zeller"], "publication": "WAMA 2016: Proceedings of the International Workshop on App Market Analytics", "abstract": "ABSTRACT\nSoftware engineering researchers and practitioners working on the Android ecosystem frequently have to do the same tasks over and over: retrieve data from the Google Play store to analyze it, decompile the Dalvik bytecode to understand the behavior of the app, and analyze applications metadata and user reviews. In this paper we present CALAPPA, a highly reusable and customizable toolchain that allows researchers to easily run common analysis tasks on large Android application datasets. CALAPPA includes components to retrieve the data from different Android stores, and comes with a predefined, but extensible, set of modules that can analyze apps metadata and code.", "references": ["K. Allix, T. F. Bissyandé, J. Klein, and Y. Le Traon. Androzoo: Collecting millions of android apps for the research community. In Proceedings of MSR, pages 468–471, 2016.", "S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel. Flowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for android apps. In Proceedings of PLDI, 2014.", "K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. Pscout: Analyzing the android permission specification. In Proceedings of CCS, pages 217–228, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993259.2993262"}, {"title": "Regex-based entity extraction with active learning and genetic programming", "authors": ["Alberto Bartoli\n,", "Andrea De Lorenzo\n,", "Eric Medvet\n,", "Fabiano Tarlao"], "publication": "ACM SIGAPP Applied Computing Review", "abstract": "Abstract\nWe consider the long-standing problem of the automatic generation of regular expressions for text extraction, based solely on examples of the desired behavior. We investigate several active learning approaches in which the user annotates only one desired extraction and then merely answers extraction queries generated by the system.\nThe resulting framework is attractive because it is the system, not the user, which digs out the data in search of the samples most suitable to the specific learning task. We tailor our proposals to a state-of-the-art learner based on Genetic Programming and we assess them experimentally on a number of challenging tasks of realistic complexity. The results indicate that active learning is indeed a viable framework in this application domain and may thus significantly decrease the amount of costly annotation effort required.\nWe consider the long-standing problem of the automatic generation of regular expressions for text extraction, based solely on examples of the desired behavior. We investigate several active learning approaches in which the user anno- tates only one desired extraction and then merely answers extraction queries generated by the system.\nThe resulting framework is attractive because it is the sys- tem, not the user, which digs out the data in search of the samples most suitable to the specific learning task. We tailor our proposals to a state-of-the-art learner based on Genetic Programming and we assess them experimentally on a num- ber of challenging tasks of realistic complexity. The results indicate that active learning is indeed a viable framework in this application domain and may thus significantly decrease the amount of costly annotation effort required.", "references": ["D. Angluin. Queries and concept learning. Machine learning, 2(4):319--342, 1988.", "J. Atserias, M. Simi, and H. Zaragoza. H.: Active learning for building a corpus of questions for parsing. In In: Proceedings of LREC 2010, 2010.", "R. Babbar and N. Singh. Clustering based approach to learning regular expressions over large alphabet for noisy unstructured text. In Proceedings of the Fourth Workshop on Analytics for Noisy Unstructured Text Data, AND '10, pages 43--50, New York, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993231.2993232"}, {"title": "Learning Query and Document Relevance from a Web-scale Click Graph", "authors": ["Shan Jiang\n,", "Yuening Hu\n,", "Changsung Kang\n,", "Tim Daly\n,", "Dawei Yin\n,", "Yi Chang\n,", "Chengxiang Zhai"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nClick-through logs over query-document pairs provide rich and valuable information for multiple tasks in information retrieval. This paper proposes a vector propagation algorithm on the click graph to learn vector representations for both queries and documents in the same semantic space. The proposed approach incorporates both click and content information, and the produced vector representations can directly improve ranking performance for queries and documents that have been observed in the click log. For new queries and documents that are not in the click log, we propose a two-step framework to generate the vector representation, which significantly improves the coverage of our vectors while maintaining the high quality. Experiments on Web-scale search logs from a major commercial search engine demonstrate the effectiveness and scalability of the proposed method. Evaluation results show that NDCG scores are significantly improved against multiple baselines by using the proposed method both as a ranking model and as a feature in a learning-to-rank framework.", "references": ["E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In Proceedings of SIGIR, pages 3--10, 2006.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In Proceedings of Workshop at EDBT, pages 588--596, 2005.", "R. Baeza-Yates and A. Tiberi. Extracting semantic relations from query logs. In Proceedings of SIGKDD, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911531"}, {"title": "Session details: Main Track - Intelligent IS and Social Media (I)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255992"}, {"title": "Geotagging Named Entities in News and Online Documents", "authors": ["Jiangwei Yu Rafiei\n,", "Davood Rafiei"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNews sources generate constant streams of text with many references to real world entities; understanding the content from such sources often requires effectively detecting the geographic foci of the entities. We study the problem of associating geography to named entities in online documents. More specifically, given a named entity and a page (or a set of pages) where the entity is mentioned, the problem being studied is how the geographic focus of the name can be resolved at a location granularity (e.g. city or country), assuming that the name has a geographic focus. We further study dispersion, and show that the dispersion of a name can be estimated with a good accuracy, allowing a geo-centre to be detected at an exact dispersion level. Two key features of our approach are: (i) minimal assumption is made on the structure of the mentions hence the approach can be applied to a diverse and heterogeneous set of web pages, and (ii) the approach is unsupervised, leveraging shallow English linguistic features and the large volume of location data in public domain.\nWe evaluate our methods under different task settings and with different categories of named entities. Our evaluation reveals that the geo-centre of a name can be estimated with a good accuracy based on some simple statistics of the mentions, and that the accuracy of the estimation varies with the categories of the names.", "references": ["E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-where: geotagging web content. In Proc. of the SIGIR Conf., pages 273--280, 2004.", "Nguyen Bach and Sameer Badaskar. A review of relation extraction. Technical report, Language Technologies Institute, Carnegie Mellon University, 2007.", "L. Backstrom, J. Kleinberg, R. Kumar, and J. Novak. Spatial variation in search engine queries. In Proc. of the WWW Conf., pages 357--366, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983795"}, {"title": "The accuracy of Android energy measurements for offloading computational expensive tasks: poster", "authors": ["Quang-Huy Nguyen\n,", "Falko Dressler"], "publication": "MobiHoc '16: Proceedings of the 17th ACM International Symposium on Mobile Ad Hoc Networking and Computing", "abstract": "ABSTRACT\nComputational offloading from smartphones into the cloud has proved to be one of useful approaches for improving energy efficiency. To assess the benefit of offloading and decide the most suitable offloading strategies, it is essential to account the energy consumption of smartphones. In this paper, we investigate the accuracy and capabilities of the Android smart battery interface. For comparison, we measure the energy consumption using an oscilloscope. We experimentally investigate the energy consumption of different applications on a modern smartphones including local computation and network communication over WiFi. Our results show that both of methods bring high accuracy. Our work builds the basis for next generation offloading algorithms.", "references": ["A. Aijaz, H. Aghvami, and M. Amani. A survey on mobile data offloading: technical and business perspectives. IEEE Wireless Communications, 20(2):104--112, 2013.", "F. Rebecchi, M. Dias de Amorim, V. Conan, A. Passarella, R. Bruno, and M. Conti. Data Offloading Techniques in Cellular Networks: A Survey. IEEE Communications Surveys and Tutorials, 17(2):580--603, 2014.", "A. Saarinen, M. Siekkinen, Y. Xiao, J. K. Nurminen, M. Kemppainen, and P. Hui. SmartDiet: offloading popular apps to save energy. ACM SIGCOMM Computer Communication Review, 42(4):297--298, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2942358.2942412"}, {"title": "Pagination versus Scrolling in Mobile Web Search", "authors": ["Jaewon Kim\n,", "Paul Thomas\n,", "Ramesh Sankaranarayana\n,", "Tom Gedeon\n,", "Hwan-Jin Yoon"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nVertical scrolling is the standard method of exploring search results pages. For touch-enabled mobile devices that are not equipped with a mouse or keyboard, we adopt other methods of controlling the viewport with the aim of investigating user interaction. From the intuition that people are used to reading books by turning pages horizontally, we conducted a user experiment to investigate the effects of horizontal and vertical control types (pagination versus scrolling) on a touch-enabled mobile phone. Our findings suggest that participants using pagination were more likely to find relevant documents, especially those over the fold; spent more time attending to relevant results; and were faster to click while spending less time on the search result pages overall. We also found that the main reason for the difference in search speed is the time taken for the scroll itself. We conclude that search engines need to provide different viewport controls to allow better search experiences on touch-enabled mobile devices.", "references": ["Adwords. Building for the next moment, 2015. Retrieved April 03, 2016 from http://adwords.blogspot.com.au/2015/05/building- for-next-moment.html.", "N. E. Breslow and D. G. Clayton. Approximate inference in generalized linear mixed models. Journal of the American Statistical Association, 88(421):9--25, 1993.", "A. Broder. A taxonomy of web search. ACM SIGIR Forum, 36(2):3--10, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983720"}, {"title": "The application of the method of TDOA localization in locating a human being behind corners based on the multistatic radar system", "authors": ["Kewei Wu\n,", "Chongyi Fan\n,", "Xiaotao Huang\n,", "Xiangyang Li"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn the classic positioning applications, non-line of sight (NLOS) is a fatal problem which has a seriousimpact on the accuracy of target location. In this paper, we use NLOS range measurements based on themultistatic radar system to locate a human targethidingbehind corners. There is a transmitter radar and 5 receiver radars in the multistatic radar system introduced by this paper. When the transmitted antenna hides in the corner, the anti-radiation missiles are difficult in attacking the transmittedantenna. However, the multistatic radar system can locate the target. This paper put forwarded an experiment to illustrate our idea. After obtaining the range measurements of the target, the time difference of arrival (TDOA) method is employed to get estimation of the staff position. The common path can be eliminated by the TDOA method while the scattering points on thewall are unknown. The priori information about scene needs not to be known.", "references": ["J. Mason, \"Algebraic two-satellite TOA/FOA position solution on an ellipsoidal Earth,\" IEEE Transactions on Aerospace and Electronic Systems, Vol. 40, No. 3, pp. 1087--1092, 2004", "N. Salman, M. W. Khan and A. H. Kemp, \"Enhanced hybrid positioning in wireless networks II: AoA-RSS,\" Telecommunications and Multimedia (TEMU), 2014 International Conference on, Heraklion, 2014, pp. 92--97.", "M.I. Silventoinen and T. Rantalainen. Mobile station emergency locating in gsm. IEEE International Conference on Personal Communication, February 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015175"}, {"title": "Searching by Talking: Analysis of Voice Queries on Mobile Web Search", "authors": ["Ido Guy"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe growing popularity of mobile search and the advancement in voice recognition technologies have opened the door for web search users to speak their queries, rather than type them. While this kind of voice search is still in its infancy, it is gradually becoming more widespread. In this paper, we examine the logs of a commercial search engine's mobile interface, and compare the spoken queries to the typed-in queries. We place special emphasis on the semantic and syntactic characteristics of the two types of queries. %Our analysis suggests that voice queries focus more on audio-visual content and question answering, and less on social networking and adult domains. We also conduct an empirical evaluation showing that the language of voice queries is closer to natural language than typed queries. Our analysis reveals further differences between voice and text search, which have implications for the design of future voice-enabled search tools.", "references": ["A. Acero, N. Bernstein, R. Chambers, Y. Ju, X. Li, J. Odell, P. Nguyen, O. Scholz, and G. Zweig. Live search for mobile: Web services by voice on the cellphone. In Proc. ICASSP, pages 5256--5259, 2008.", "L. A. Adamic, J. Zhang, E. Bakshy, and M. S. Ackerman. Knowledge sharing and yahoo answers: Everyone knows something. In Proc. WWW, pages 665--674, 2008.", "A. H. Awadallah, R. Gurunath Kulkarni, U. Ozertem, and R. Jones. Characterizing and predicting voice query reformulation. In Proc. CIKM, pages 543--552, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911525"}, {"title": "The Liquid.js Framework for Migrating and Cloning Stateful Web Components across Multiple Devices", "authors": ["Andrea Gallidabino\n,", "Cesare Pautasso"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe are heading toward an era in which users own more than one single Web-enabled device. These devices range from smart phones, tablets and personal computers to smart Web-enabled devices found in houses and cars. The access mechanisms and usage patterns of Web applications are changing accordingly, as users interact more and more with Web applications through all their devices, even if the majority of Web applications are not ready to offer a good user experience taking full advantage of multiple devices. In this demonstration we introduce Liquid.js, a framework whose goal is to enable Web developers to take advantage of multiple heterogeneous devices and offer to their users a liquid user experience, whereby any device can be used sequentially or concurrently with Web applications that can effortlessly roam from one device to another. This way, as highlighted in the demonstration users do not need to stop and resume their work on their Web application as they migrate and clone them across different devices. The demo will also show how developers can easily add such liquid behavior to any Polymer Web component.", "references": ["D. Bonetta and C. Pautasso. An architectural style for liquid web services. In Proc. of the 9th Working IEEE/IFIP Conference on Software Architecture (WICSA), pages 232--241, 2011.", "A. Carzaniga, G. P. Picco, and G. Vigna. Designing distributed applications with mobile code paradigms. In Proceedings of the 19th international conference on Software engineering, pages 22--32. ACM, 1997.", "A. Fuggetta, G. P. Picco, and G. Vigna. Understanding code mobility. Software Engineering, IEEE Transactions on, 24(5):342--361, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890538"}, {"title": "Off the Beaten Path: Let's Replace Term-Based Retrieval with k-NN Search", "authors": ["Leonid Boytsov\n,", "David Novak\n,", "Yury Malkov\n,", "Eric Nyberg"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRetrieval pipelines commonly rely on a term-based search to obtain candidate records, which are subsequently re-ranked. Some candidates are missed by this approach, e.g., due to a vocabulary mismatch. We address this issue by replacing the term-based search with a generic k-NN retrieval algorithm, where a similarity function can take into account subtle term associations. While an exact brute-force k-NN search using this similarity function is slow, we demonstrate that an approximate algorithm can be nearly two orders of magnitude faster at the expense of only a small loss in accuracy. A retrieval pipeline using an approximate k-NN search can be more effective and efficient than the term-based pipeline. This opens up new possibilities for designing effective retrieval pipelines. Our software (including data-generating code) and derivative data based on the Stack Overflow collection is available online.", "references": ["A. Andoni, P. Indyk, T. Laarhoven, I. Razenshteyn, and L. Schmidt. Practical and optimal lsh for angular distance. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pp. 1225--1233. Curran Associates, Inc., 2015.", "S. Arya and D. M. Mount. Approximate nearest neighbor queries in fixed dimensions. In Proceedings of the fourth annual ACM-SIAM Symposium on Discrete algorithms, pp. 271--280. Society for Industrial and Applied Mathematics, 1993.", "V. Athitsos, M. Potamias, P. Papapetrou, and G. Kollios. Nearest neighbor retrieval using distance-based hashing. In 24th International Conference on Data Engineering, pp. 327--336. IEEE, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983815"}, {"title": "Generating weighted vector for concepts in indonesian translation of Quran", "authors": ["Syopiansyah Jaya Putra\n,", "Khodijah Hulliyah\n,", "Nashrul Hakiem\n,", "Rayi Pradono Iswara\n,", "Asep Fajar Firmansyah"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThis paper presents a work in generating Weighted Vector for each Concept in Indonesian Translation of Quran (ITQ). This task is done in aiming to provide a resource needed in implementing a semantic-based question answering system (QAS) for Indonesian ITQ, particularly in retrieving semantically related verses. Semantic approach on QAS employs Ontology concepts of the domain. Since there is no Ontology for ITQ remains, we built one by utilizing the existing Ontology from Quranic Arabic corpus (http://corpus.quran.com/). Furthermore, each leaf concept that enriched by related Quran verse (as its instance) had a representation vector of terms that occur in the corresponding Quran verse to express how strength the concept in relates with verse terms. This vector is assigned with a weight resulted from applying TFIDF method. From 222 leaf concepts in the Ontology, we applied the process only to those that categorized as a member group of Person, Location, and Time named entity. They are 107 in a total. The result shows that the most strength concept in association with verse terms is syaitan which is scored at 0.895 of 1. In overall, 16.82 % concepts had score that more than 0.4, following by 14.95%, 23.36% and 11.21% concepts scored at more than 0.3 ,0.2 and less than 0.1 respectively, and finally the rest ones were the biggest in volume where 33.64% concepts obtained score more than 0.1 and less than 0.2.", "references": ["M. Sheker, S. Saad, R. Abood, and M. Shakir, \"Domain-Specific Ontology-Based Approach for Arabic Question Answering,\" J. Theor. Appl. Inf. Technol., vol. 83, no. 1, 2016.", "F. A. Zaghoul and S. Al-Dhaheri, \"Arabic Text Classification Based on Features Reduction Using Artificial Neural Networks,\" in Computer Modelling and Simulation (UKSim), 2013 UKSim 15th International Conference on, 2013, pp. 485--490.", "K. S. Jones, \"A statistical interpretation of term specificity and its application in retrieval,\" J. Doc., vol. 28, pp. 11--21, 1972."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011218"}, {"title": "Using smartphones for prototyping semantic sensor analysis systems", "authors": ["Hassan Issa\n,", "Ludger van Elst\n,", "Andreas Dengel"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nThe increasing usage of sensors in modern technical systems and in consumer products necessitates using efficient and scalable methods for storing and processing sensor data. Coupling big data technologies with semantic techniques not only helps achieving the desired storage and processing goals, but also facilitates data integration, data analysis and the utilization of data in unforeseen future applications through preserving the data generation context. In this work, an approach for prototyping semantic sensor analysis systems using Apache Spark is proposed. The approach uses smartphones to generate sensor data which is transformed into semantic data according to the Semantic Sensor Network ontology. Efficient storage and processing methods of semantic data are proposed and a use case where a smartphone is deployed in a transportation bus is presented along with a street anomaly detection application.", "references": ["Measurement units ontology (muo). http://idi.fundacionctic.org/muo/. Accessed: 2016-02-29.", "M. Compton, P. Barnaghi, L. Bermudez, R. García-Castro, O. Corcho, S. Cox, J. Graybeal, M. Hauswirth, C. Henson, A. Herzog, V. Huang, K. Janowicz, W. D. Kelsey, D. L. Phuoc, L. Lefort, M. Leggieri, H. Neuhaus, A. Nikolov, K. Page, A. Passant, A. Sheth, and K. Taylor. The {SSN} ontology of the {W3C} semantic sensor network incubator group. Web Semantics: Science, Services and Agents on the World Wide Web, 17(0):25--32, 2012.", "O. Curé, H. Naacke, M.-A. Baazizi, and B. Amann. On the evaluation of rdf distribution algorithms implemented over apache spark. arXiv preprint, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928299"}, {"title": "Increasing Datasets Discoverability in an Engineering Data Platform using Keyword Extraction", "authors": ["Parthasarathy Gopavarapu\n,", "Line C. Pouchard\n,", "Santiago Pujol"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIn this paper we describe the use of keyword extraction in a data management platform for the storage, publication, and sharing of scientific and engineering datasets primarily related to the stress of concrete structures under earthquake conditions. To improve discoverability of datasets and assist scientists who upload data, we designed an automated keyword extraction system that will propose keywords for uploaded datasets.", "references": ["Hasan, KS. And Vincent Ng.2014. Automatic Keyphrase Extraction : A Survey of the State of the Art. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1262--1273, 2014.", "Dumais, S.T. 2005. Latent Semantic Analysis. Annual Review of Information Science and Technology. 38,1(Sep. 2005) 188--230.", "Salton, G. and Buckley, C. 1988. Term Weighting Approaches in Automatic Text Retrieval. Information Processing & Management. (1988), 513--524."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925443"}, {"title": "Neural Autoregressive Collaborative Filtering for Implicit Feedback", "authors": ["Yin Zheng\n,", "Cailiang Liu\n,", "Bangsheng Tang\n,", "Hanning Zhou"], "publication": "DLRS 2016: Proceedings of the 1st Workshop on Deep Learning for Recommender Systems", "abstract": "ABSTRACT\nThis paper proposes implicit CF-NADE, a neural autoregressive model for collaborative filtering tasks using implicit feedback( e.g. click/watch/browse behaviors). We first convert a user's implicit feedback into a \"like\" vector and a confidence vector, and then model the probability of the \"like\" vector, weighted by the confidence vector. The training objective of implicit CF-NADE is to maximize a weighted negative log-likelihood. We test the performance of implicit CF-NADE on a dataset collected from a popular digital TV streaming service. More specifically, in the experiments, we describe how to convert watch counts into implicit \"relative rating\", and feed into implicit CF-NADE. Then we compare the performance of implicit CF-NADE model with the popular implicit matrix factorization approach. Experimental results show that implicit CF-NADE significantly outperforms the baseline.", "references": ["M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016.", "J. Bennett and S. Lanning. The netflix prize. In Proceedings of KDD cup and workshop, volume 2007, page 35, 2007.", "G. K. Dziugaite and D. M. Roy. Neural network matrix factorization. arXiv preprint arXiv:1511.06443, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988450.2988453"}, {"title": "Ordinal Text Quantification", "authors": ["Giovanni Da San Martino\n,", "Wei Gao\n,", "Fabrizio Sebastiani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn recent years there has been a growing interest in text quantification, a supervised learning task where the goal is to accurately estimate, in an unlabelled set of items, the prevalence (or \"relative frequency\") of each class c in a predefined set C. Text quantification has several applications, and is a dominant concern in fields such as market research, the social sciences, political science, and epidemiology. In this paper we tackle, for the first time, the problem of ordinal text quantification, defined as the task of performing text quantification when a total order is defined on the set of classes; estimating the prevalence of \"five stars\" reviews in a set of reviews of a given product, and monitoring this prevalence across time, is an example application. We present OQT, a novel tree-based OQ algorithm, and discuss experimental results obtained on a dataset of tweets classified according to sentiment strength.", "references": ["A. Bella, C. Ferri, J. Hernández-Orallo, and M. J. Ramírez-Quintana. Quantification via probability estimators. In Proceedings of the 11th IEEE International Conference on Data Mining (ICDM 2010), pages 737--742, Sydney, AU, 2010.", "W. Chu and S. S. Keerthi. Support vector ordinal regression. Neural Computation, 19(3):145--152, 2007.", "H. Drucker, C. J. Burges, L. Kaufman, A. Smola, and V. Vapnik. Support vector regression machines. In Proceedings of the 11th Annual Conference on Neural Information Processing Systems (NIPS 1997), pages 155--161, Denver, US, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914749"}, {"title": "Asynchronous video interviews vs. face-to-face interviews for communication skill measurement: a systematic study", "authors": ["Sowmya Rasipuram\n,", "Pooja Rao S. B.\n,", "Dinesh Babu Jayagopi"], "publication": "ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nCommunication skill is an important social variable in em- ployment interviews. As recent trends point to, increasingly asynchronous or interface-based video interviews are becom- ing popular. Also getting increasing interest is automatic hiring analysis, of which automatic communication skill pre- diction is one such task. In this context, a research gap that exists and which our paper addresses is â€oeAre there any differences in perception of communication skill and the accuracy of automatic prediction of say classes of communicators (e.g. those below average) when we compare interface-based and face-to-face interviewsâ€❝. To this end, we have collected a set of 106 interview videos from graduate students in both the settings i.e., interface-based and face-to-face. We observe that perception of behavior of participants in interface-based (when no person is involved) vs. face-to-face (when inter- viewer is involved) according to the external naive observers is slightly different. In this paper, we present an automatic system to predict the communication skill of a person in interface-based and face-to-face interviews by automatically extracting several low level features based on audio, visual and lexical behavior of the participants and using Machine Learning algorithms like Linear Regression, Support Vec- tor Machine (SVM) and Logistic Regression. We also make an extensive study of the verbal behavior of the participant when the spoken response is obtained from manual tran- scriptions and Automatic Speech Recognition (ASR) tool. Our best automatic prediction results achieve an accuracy of 80% in interface-based and 83% in face-to-face setting.", "references": ["Discover big voice intelligence. https://www.voicebase.com/products-features/, 2016.", "Hassle-free efficient hiring. https://www.talview.com/automated-video, 2016.", "K. Anderson et al. The TARDIS framework: intelligent virtual agents for social coaching in job interviews. In Advances in Computer Entertainment, pages 476–491. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993148.2993183"}, {"title": "A declarative query processing system for nowcasting", "authors": ["Dolan Antenucci\n,", "Michael R. Anderson\n,", "Michael Cafarella"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nNowcasting is the practice of using social media data to quantify ongoing real-world phenomena. It has been used by researchers to measure flu activity, unemployment behavior, and more. However, the typical nowcasting workflow requires either slow and tedious manual searching of relevant social media messages or automated statistical approaches that are prone to spurious and low-quality results.\nIn this paper, we propose a method for declaratively specifying a nowcasting model; this method involves processing a user query over a very large social media database, which can take hours. Due to the human-in-the-loop nature of constructing nowcasting models, slow runtimes place an extreme burden on the user. Thus we also propose a novel set of query optimization techniques, which allow users to quickly construct nowcasting models over very large datasets. Further, we propose a novel query quality alarm that helps users estimate phenomena even when historical ground truth data is not available. These contributions allow us to build a declarative nowcasting data management system, RaccoonDB, which yields high-quality results in interactive time.\nWe evaluate RaccoonDB using 40 billion tweets collected over five years. We show that our automated system saves work over traditional manual approaches while improving result quality---57% more accurate in our user study---and that its query optimizations yield a 424x speedup, allowing it to process queries 123x faster than a 300-core Spark cluster, using only 10% of the computational resources.", "references": ["Box Office Mojo Weekly Box Office Index. http://www.boxofficemojo.com/weekly/, 2015.", "CDC Influenza Surveillance Data via Google. http://www.google.org/flutrends/data.txt, 2015.", "FBI - NICS. http://fbi.gov/services/cjis/nics, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3021924.3021931"}, {"title": "Context Matters: Towards Extracting a Citation's Context Using Linguistic Features", "authors": ["Daniel Duma\n,", "Charles Sutton\n,", "Ewan Klein"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nNo abstract available.", "references": ["A. Athar and S. Teufel. Context-enhanced citation sentiment detection. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 597--601. Association for Computational Linguistics, 2012.", "D. Duma and E. Klein. Citation resolution: A method for evaluating context-based citation recommendation systems. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 2014.", "J. He, J.-Y. Nie, Y. Lu, and W. X. Zhao. Position-aligned translation model for citation recommendation. In String Processing and Information Retrieval, pages 251--263. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925431"}, {"title": "Aggregated Search and Interleaving Methods: A survey", "authors": ["Sara Lasri\n,", "El Habib Nfaoui"], "publication": "BDAW '16: Proceedings of the International Conference on Big Data and Advanced Wireless Technologies", "abstract": "ABSTRACT\nAggregated search attempts to satisfy user's need by searching and assembling information from variety verticals and placing them into a single result page. Aggregated search has two research directions namely, cross-vertical Aggregated Search (cvAS) and Relational Aggregated Search (RAS). The first one focuses to find relations between the keywords of query. The second one tries to attain the variety results from different information sources. The outcomes (results) given by aggregated search should be evaluated to determine which system is reliable. To achieve this evaluation we use various metrics. Then for improving the ranked list which given by web search engines we must utilize interleaved methods for comparing the relative quality of two ranking systems. In addition to present the perfect result to users. The purpose of this article is to collect and classify the different methods of aggregated search and interleaving methods that exist so far in literature. Furthermore, we conduct some comparisons between interleaved methods and other ranking systems.", "references": ["Maunendra Sankar Desarkar, Sudeshna Sarkar, Pabitra Mitra. 2015. Preference relations based unsupervised rank aggregation for metasearch. Department of CSE, IIT Kharagpur, Kharagpur 721302, India.", "M. Shokouhi and L. Si. 2011. Federated Information Retrieval. Foundations and Trends in Information Retrieval. Upcoming Issue.", "Mounia Lalmas. 2011. Aggregated Search. Springer-Verlag Berlin Heidelberg."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010089.3010098"}, {"title": "StarrySky: A Practical System to Track Millions of High-Precision Query Intents", "authors": ["Qi Ye\n,", "Feng Wang\n,", "Bo Li"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nQuery intent mining is a critical problem in various real-world search applications. In the past few years we have witnessed dramatic advances in the field of query intent mining area. In this paper, we present a practical system---StarrySky for identifying and inferring millions of query intents in daily sponsored search with high precision and acceptable coverage. We have already achieved great advantages by deploying this system in Sogou sponsored search engine\\footnote {http://www.sogou.com}. The general architecture of StarrySky consists of three stages. First, we detect millions of fine-grained query clusters from two years of click logs which can represent different query intents. Second, we refine the qualities of query clusters with a series of well-designed operations, and call the final refined clusters as concepts. Third and foremost, we build a flexible real-time inference algorithm for assigning query intents to the detected concepts with high precision. Beyond the description of the system, we employ several experiments to evaluate its performance and flexibility. Our inference algorithm achieves up to 96% precision and 68% coverage on daily search requests. We believe StarrySky is a practical and valuable system for tracking query intents.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. J. Stat. Mech., page 10008, 9 October 2008.", "A. Z. Broder, M. Fontoura, and et al. Robust classification of rare queries using web knowledge. In Proceedings of the 30th Annual International ACM SIGIR, pages 231--238, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890588"}, {"title": "Probabilistic Models for Contextual Agreement in Preferences", "authors": ["Loc Do\n,", "Hady W. Lauw"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nThe long-tail theory for consumer demand implies the need for more accurate personalization technologies to target items to the users who most desire them. A key tenet of personalization is the capacity to model user preferences. Most of the previous work on recommendation and personalization has focused primarily on individual preferences. While some focus on shared preferences between pairs of users, they assume that the same similarity value applies to all items. Here we investigate the notion of “context,” hypothesizing that while two users may agree on their preferences on some items, they may also disagree on other items. To model this, we design probabilistic models for the generation of rating differences between pairs of users across different items. Since this model also involves the estimation of rating differences on unseen items for the purpose of prediction, we further conduct a systematic analysis of matrix factorization and tensor factorization methods in this estimation, and propose a factorization model with a novel objective function of minimizing error in rating differences. Experiments on several real-life rating datasets show that our proposed model consistently yields context-specific similarity values that perform better on a prediction task than models relying on shared preferences.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering 17, 6 (2005), 734--749.", "Gediminas Adomavicius and Alexander Tuzhilin. 2011. Context-aware recommender systems. In Recommender Systems Handbook. Springer, 217--253.", "Amr Ahmed, Bhargav Kanagal, Sandeep Pandey, Vanja Josifovski, Lluis Garcia Pueyo, and Jeff Yuan. 2013. Latent factor models with additive and hierarchically-smoothed user preferences. In Proceedings of the ACM International Conference on Web Search and Data Mining (WSDM’13). 385--394."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854147"}, {"title": "Shop Together, Search Together: Collaborative E-commerce", "authors": ["Yanjun Gao\n,", "Madhu Reddy\n,", "Bernard J. Jansen"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nWe present research on the development of a collaborative searching system for ecommerce shopping, based on domain specific requirements of retail shopping. We describe the design rationale for the system development and inclusion of collaborative search features, including search, chat, clipboard, product suggestions, shared views, and shopping cart. Our research goal is to understand whether collaborative searching tools are useful in supporting actual collaborative shopping tasks. In addition to describing the system development, we report findings from some preliminary user study. The findings highlight that collaborative search systems for domain specific areas such as online shopping can support collaborative searching, shared views, and group communication to aid in the completion of collaborative tasks.", "references": ["Robert Capra, Annie T. Chen, Katie Hawthorne, Jaime Arguello, Lee Shaw, and Gary Marchionini. 2012. Design and evaluation of a system to support collaborative search.", "Robert Capra, Jaime Arguello, Annie Chen, Katie Hawthorne, Gary Marchionini, and Lee Shaw. 2012. The ResultsSpace collaborative search environment. The 12th ACM/IEEE-CS joint conference on Digital Libraries. Washington, DC. 435--436.", "Roberto González-Ibáñez and Chirag Shah. 2011. Coagmento: A System for Supporting Collaborative Information Seeking. The74th Annual Meeting of the American Society for Information Science and Technology ASIST 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892348"}, {"title": "Toward G-OWL: A Graphical, Polymorphic And Typed Syntax For Building Formal OWL2 Ontologies", "authors": ["Michel Héon\n,", "Roger Nkambou\n,", "Christian Langheit"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe Web Ontology Language (OWL-2) aims at offering a family of syntax such as RDF/XML, Manchester Turtle and others, for building ontologies. Ontology engineering is a complex task that requires skills that are rarely accessible to content experts. On the other hand, to model contents pertaining to a specific domain, graphical modeling is a technique that is often used to offer a knowledge representation tool to content experts that are not well acquainted with the process of formal ontology design. In this paper, we present the way in which the usage of polymorphism and symbol typing of graphical vocabulary have allowed us to design the G-OWL syntax, a graphical syntax that aims to graphically represent domain-specific knowledge using the OWL-2.", "references": ["G. Paquette, M. Léonard, J. Basque, and B. Pudelko, \"Modeling for Knowledge Management in Organizations,\" in Visual Knowledge Modeling for Semantic Web Technologies: Models and Ontologies, ed: IGI Global, 2010, pp. 393--413.", "D. D. Suthers, \"Representational guidance for collaborative inquiry,\" in Arguing to Learn J. Andriessen, M. Baker, and D. Suthers, Eds., ed Dordrecht/Boston/London: Kluwer, 2003, pp. 27--46.", "D. Gaýević, D. Djurić, and V. Devedžić, Model Driven Architecture and Ontology Development. New York, Inc.: Springer-Verlag, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889377"}, {"title": "aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model", "authors": ["Liu Yang\n,", "Qingyao Ai\n,", "Jiafeng Guo\n,", "W. Bruce Croft"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAs an alternative to question answering methods based on feature engineering, deep learning approaches such as convolutional neural networks (CNNs) and Long Short-Term Memory Models (LSTMs) have recently been proposed for semantic matching of questions and answers. To achieve good results, however, these models have been combined with additional features such as word overlap or BM25 scores. Without this combination, these models perform significantly worse than methods based on linguistic feature engineering. In this paper, we propose an attention based neural matching model for ranking short answer text. We adopt value-shared weighting scheme instead of position-shared weighting scheme for combining different matching signals and incorporate question term importance learning using question attention network. Using the popular benchmark TREC QA data, we show that the relatively simple aNMM model can significantly outperform other neural network models that have been used for the question answering task, and is competitive with models that are combined with additional features. When aNMM is combined with additional features, it outperforms all baselines.", "references": ["W. B. Croft, D. Metzler, and T. Strohman. Search Engines: Information Retrieval in Practice. Addison-Wesley Publishing Company, USA, 1st edition, 2009.", "O. Etzioni. Search needs a shake-up. Nature, 476(7358):25--26, Aug. 2011.", "Y. Ganjisaffar, R. Caruana, and C. Lopes. Bagging gradient-boosted trees for high precision, low variance ranking models. In SIGIR '11, pages 85--94, New York, NY, USA, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983818"}, {"title": "Evaluating Item-Item Similarity Algorithms for Movies", "authors": ["Lucas Colucci\n,", "Prachi Doshi\n,", "Kun-Lin Lee\n,", "Jiajie Liang\n,", "Yin Lin\n,", "Ishan Vashishtha\n,", "Jia Zhang\n,", "Alvin Jude"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nRecommender systems such as those used in e-commerce or Video-On-Demand systems generally show users a list of \"similar items.\" Many algorithms exist to calculate item-item similarity and we wished to evaluate how users perceive these numerically expressed similarity. In our experiment, we performed a user study with four similarity algorithms to evaluate perceived correctness in item-item similarity as it relates to movies. We implemented three algorithms: collaborative filtering with Pearson, collaborative filtering with cosine, and content-filtering with TF-IDF. A pre-generated similarity list from TheMovieDB.org (TMDb) was used as the baseline. Our experiment showed that TMDb has the highest perceived similarity, followed by cosine and TF-IDF, while Pearson was practically unusable for users. A by-product of our experiment was a set of similar movie pairs, which we intend to use for offline evaluation.", "references": ["David G. Stork. 2000. Open data collection for training intelligent software in the open mind initiative. In Proceedings of the Engineering Intelligent Systems (EIS'00).", "Luis von Ahn and Laura Dabbish. 2004. Labeling images with a computer game. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04). ACM, New York, NY, USA, 319--326. DOI=http://dx.doi.org/10.1145/985692.985733", "Yan Chen Harper, F. Maxwell, Joseph Konstan, and Sherry Xin Li. 2010. Social comparisons and contributions to online communities: A field experiment on movielens. The American economic review: 1358--1398."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892362"}, {"title": "Dealing with Concept Drift in Exploratory Search: An Interactive Bayesian Approach", "authors": ["Antti Kangasrääsiö\n,", "Yi Chen\n,", "Dorota Glowacka\n,", "Samuel Kaski"], "publication": "IUI '16 Companion: Companion Publication of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nIn exploratory search, when the user formulates a query iteratively through relevance feedback, it is likely that the feedback given earlier requires adjustment later on. The main reason for this is that the user learns while searching, which causes changes in the relevance of items and features as estimated by the user -- a phenomenon known as {it concept drift}. It might be helpful for the user to see the recent history of her feedback and get suggestions from the system about the accuracy of that feedback. In this paper we present a timeline interface that visualizes the feedback history, and a Bayesian regression model that can estimate jointly the user's current interests and the accuracy of each user feedback. We demonstrate that the user model can improve retrieval performance over a baseline model that does not estimate accuracy of user feedback. Furthermore, we show that the new interface provides usability improvements, which leads to the users interacting more with it.", "references": ["Hagai Attias. 1999. Inferring Parameters and Structure of Latent Variable Models by Variational Bayes. In Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI'99). Morgan Kaufmann Publishers Inc., 21--30. http: //dl.acm.org/citation.cfm?id=2073796.2073799", "João Gama, Indré Žliobaité, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia. 2014. A Survey on Concept Drift Adaptation. Comput. Surveys 46, 4, Article 44 (2014), 37 pages. DOI: http://dx.doi.org/10.1145/2523813", "Dorota Glowacka, Tuukka Ruotsalo, Ksenia Konuyshkova, Kumaripaba Athukorala, Samuel Kaski, and Giulio Jacucci. 2013. Directing Exploratory Search: Reinforcement Learning from User Interactions with Keywords. In Proceedings of the 2013 International Conference on Intelligent User Interfaces (IUI '13). ACM, 117--128. DOI: http://dx.doi.org/10.1145/2449396.2449413"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876456.2879487"}, {"title": "Topic Exploration in Spatio-Temporal Document Collections", "authors": ["Kaiqi Zhao\n,", "Lisi Chen\n,", "Gao Cong"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nHuge amounts of data with both spatial and temporal information (e.g., geo-tagged tweets) are being generated, and are often used to share and spread personal updates, spontaneous ideas, and breaking news. We refer to such data as spatio-temporal documents. It is of great interest to explore topics in a collection of spatio-temporal documents.\nIn this paper, we study the problem of efficiently mining topics from spatio-temporal documents within a user specified bounded region and timespan, to provide users with insights about events, trends, and public concerns within the specified region and time period. We propose a novel algorithm that is able to efficiently combine two pre-trained topic models learnt from two document sets with a bounded error, based on which we develop an efficient approach to mining topics from a large number of spatio-temporal documents within a region and a timespan. Our experimental results show that our approach is able to improve the runtime by at least an order of magnitude compared with the baselines. Meanwhile, the effectiveness of our proposed method is close to the baselines.", "references": ["A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In WSDM, pages 123--132, 2012.", "L. AlSumait, D. Barbará, and C. Domeniconi. On-line LDA: adaptive topic models for mining text streams with applications to topic detection and tracking. In ICDM, pages 3--12, 2008.", "A. Angel, N. Koudas, N. Sarkas, and D. Srivastava. What's on the grapevine? In SIGMOD, pages 1047--1050, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2882921"}, {"title": "3rd Workshop on Recommendation Systems for Television and Online Video (RecSysTV 2016)", "authors": ["Jan Neumann\n,", "John Hannon\n,", "Claudio Riefolo\n,", "Hassan Sayyadi"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nFor many households the television is the central entertainment hub in their home, and the average TV viewer spends about half of their leisure time in front of a TV. At any given moment, a costumer has hundreds to thousands of entertainment choices available, which makes some sort of automatic, personalized recommendations desirable to help consumers deal with the often overwhelming number of choices they face. The 3rd Workshop on Recommendation Systems for Television and Online Video aims to offer a place to present and discuss the latest academic and industrial research on recommendation systems for this challenging and exciting application domain.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959198"}, {"title": "A Simple Tags Categorization Framework Using Spatial Coverage to Discover Geospatial Semantics", "authors": ["Camille Tardy\n,", "Laurent Moccozet\n,", "Gilles Falquet"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThere exist many popular crowdsourcing and social services (Volunteered Geographic Information (VGI)) to share information and documents such as Flickr, Foursquare, Twitter , Facebook, etc. They all use metadata, folksonomy and more importantly a geographic axis with GPS coordinates and/or geographic tags. Using this available folksonomy in VGI services we propose a logical approach to highlight and possibly discover the characteristics of geographic places. The approach is based on the notion of spatial coverage and a model of tags categorization and on their semantic identification, using semantic services such as GeoNames, OpenStreetMap or WordNet. We illustrate our model with Flickr to retrieve the characteristics (function, usage?) of places even if those places have a small number of related photos. Those found characteristics allow tag disambiguation and can be use to complete the semantic gap on places and POIs such as the function of buildings, which can exist in geographic services.", "references": ["Abbasi, R. 2011. Discovering and Exploiting Semantics in Folksonomies.", "Antoniou, V. et al. 2010. Web 2.0 geotagged photos: Assessing the spatial dimension of the phenomenon. Geomatica. 64, 1 (2010), 99--110.", "Bunescu, R.C. and Pasca, M. 2006. Using Encyclopedic Knowledge for Named entity Disambiguation. EACL. (2006)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890483"}, {"title": "Improving Automated Controversy Detection on the Web", "authors": ["Myungha Jang\n,", "James Allan"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAutomatically detecting controversy on the Web is a useful capability for a search engine to help users review web content with a more balanced and critical view. The current state-of-the art approach is to find K-Nearest-Neighbors in Wikipedia to the document query, and to aggregate their controversy scores that are automatically computed from the Wikipedia edit-history features. In this paper, we discover two major weakness in the prior work and propose modifications. First, the generated single query from document to find KNN Wikipages easily becomes ambiguous. Thus, we propose to generate multiple queries from smaller but more topically coherent paragraph of the document. Second, the automatically computed controversy scores of Wikipedia articles that depend on \"edit war\" features have a drawback that without an edit history, there can be no edit wars. To infer more reliable controversy scores for articles with little edit history, we smooth the original score from the scores of the neighbors with more established edit history. We show that the modified framework is improved by up to 5% for binary controversy classification in a publicly available dataset.", "references": ["Y. Choi, Y. Jung, and S.-H. Myaeng. Identifying controversial issues and their sub-topics in news articles. In PAISI, volume 6122 of Lecture Notes in Computer Science, pages 140--153. Springer, 2010.", "S. Das, A. Lavoie, and M. Magdon-Ismail. Manipulation among the arbiters of collective intelligence: how wikipedia administrators mold public opinion. CIKM '13, pages 1097--1106, New York, NY, USA, 2013. ACM.", "S. Dori-Hacohen and J. Allan. Detecting controversy on the web. In CIKM, pages 1845--1848. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914764"}, {"title": "Click-based Hot Fixes for Underperforming Torso Queries", "authors": ["Masrour Zoghi\n,", "Tomáš Tunys\n,", "Lihong Li\n,", "Damien Jose\n,", "Junyan Chen\n,", "Chun Ming Chin\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRanking documents using their historical click-through rate (CTR) can improve relevance for frequently occurring queries, i.e., so-called head queries. It is difficult to use such click signals on non-head queries as they receive fewer clicks. In this paper, we address the challenge of dealing with torso queries on which the production ranker is performing poorly. Torso queries are queries that occur frequently enough so that they are not considered as tail queries and yet not frequently enough to be head queries either. They comprise a large portion of most commercial search engines' traffic, so the presence of a large number of underperforming torso queries can harm the overall performance significantly. We propose a practical method for dealing with such cases, drawing inspiration from the literature on learning to rank (LTR). Our method requires relatively few clicks from users to derive a strong re-ranking signal by comparing document relevance between pairs of documents instead of using absolute numbers of clicks per document. By infusing a modest amount of exploration into the ranked lists produced by a production ranker and extracting preferences between documents, we obtain substantial improvements over the production ranker in terms of page-level online metrics. We use an exploration dataset consisting of real user clicks from a large-scale commercial search engine to demonstrate the effectiveness of the method. We conduct further experimentation on public benchmark data using simulated clicks to gain insight into the inner workings of the proposed method. Our results indicate a need for LTR methods that make more explicit use of the query and other contextual information.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, 2006.", "P. Bennett, M. Shokouhi, and R. Caruana. Implicit preference labels for learning highly selective personalized rankers. In ICTIR, 2015.", "J. Bian, X. Li, F. Li, Z. Zheng, and H. Zha. Ranking specialization for web search: A divide-and-conquer approach by using topical RankSVM. In WWW, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911500"}, {"title": "PDFFigures 2.0: Mining Figures from Research Papers", "authors": ["Christopher Clark\n,", "Santosh Divvala"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nFigures and tables are key sources of information in many scholarly documents. However, current academic search engines do not make use of figures and tables when semantically parsing documents or presenting document summaries to users. To facilitate these applications we develop an algorithm that extracts figures, tables, and captions from documents called \"PDFFigures 2.0.\" Our proposed approach analyzes the structure of individual pages by detecting captions, graphical elements, and chunks of body text, and then locates figures and tables by reasoning about the empty regions within that text. To evaluate our work, we introduce a new dataset of computer science papers, along with ground truth labels for the locations of the figures, tables, and captions within them. Our algorithm achieves impressive results (94% precision at 90% recall) on this dataset surpassing previous state of the art. Further, we show how our framework was used to extract figures from a corpus of over one million papers, and how the resulting extractions were integrated into the user interface of a smart academic search engine, Semantic Scholar (www.semanticscholar.org). Finally, we present results of exploratory data analysis completed on the extracted figures as well as an extension of our method for the task of section title extraction. We release our dataset and code on our project webpage for enabling future research (http://pdffigures2.allenai.org).", "references": ["PDFBox. https://pdfbox.apache.org/.", "Poppler. https://poppler.freedesktop.org/.", "Semantic Scholar. www.semanticscholar.org."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910904"}, {"title": "The use of text retrieval and natural language processing in software engineering", "authors": ["Sonia Haiduc\n,", "Venera Arnaoudova\n,", "Andrian Marcus\n,", "Giuliano Antoniol"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering Companion", "abstract": "ABSTRACT\nThis technical briefing presents the state of the art Text Retrieval and Natural Language Processing techniques used in Software Engineering and discusses their applications in the field.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2889160.2891053"}, {"title": "Space odyssey: efficient exploration of scientific data", "authors": ["Mirjana Pavlovic\n,", "Eleni Tzirita Zacharatou\n,", "Darius Sidlauskas\n,", "Thomas Heinis\n,", "Anastasia Ailamaki"], "publication": "ExploreDB '16: Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web", "abstract": "ABSTRACT\nAdvances in data acquisition---through more powerful supercomputers for simulation or sensors with better resolution---help scientists tremendously to understand natural phenomena. At the same time, however, it leaves them with a plethora of data and the challenge of analysing it. Ingesting all the data in a database or indexing it for an efficient analysis is unlikely to pay off because scientists rarely need to analyse all data. Not knowing a priori what parts of the datasets need to be analysed makes the problem challenging.\nTools and methods to analyse only subsets of this data are rather rare. In this paper we therefore present Space Odyssey, a novel approach enabling scientists to efficiently explore multiple spatial datasets of massive size. Without any prior information, Space Odyssey incrementally indexes the datasets and optimizes the access to datasets frequently queried together. As our experiments show, through incrementally indexing and changing the data layout on disk, Space Odyssey accelerates exploratory analysis of spatial data by substantially reducing query-to-insight time compared to the state of the art.", "references": ["I. Alagiannis, R. Borovica, M. Branco, S. Idreos, and A. Ailamaki. NoDB: Efficient Query Execution on Raw Data Files. In SIGMOD '12.", "J. Cieslewicz, K. A. Ross, K. Satsumi, and Y. Ye. Automatic Contention Detection and Amelioration for Data-intensive Operations. In SIGMOD '10.", "V. Gaede and O. Günther. Multidimensional Access Methods. ACM Computing Surveys, 30(2), 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948674.2948677"}, {"title": "Chalkboarding: A New Spatiotemporal Query Paradigm for Sports Play Retrieval", "authors": ["Long Sha\n,", "Patrick Lucey\n,", "Yisong Yue\n,", "Peter Carr\n,", "Charlie Rohlf\n,", "Iain Matthews"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nThe recent explosion of sports tracking data has dramatically increased the interest in effective data processing and access of sports plays (i.e., short trajectory sequences of players and the ball). And while there exist systems that offer improved categorizations of sports plays (e.g., into relatively coarse clusters), to the best of our knowledge there does not exist any retrieval system that can effectively search for the most relevant plays given a specific input query. One significant design challenge is how best to phrase queries for multi-agent spatiotemporal trajectories such as sports plays.We have developed a novel query paradigm and retrieval system, which we call Chalkboarding, that allows the user to issue queries by drawing a play of interest (similar to how coaches draw up plays). Our system utilizes effective alignment, templating, and hashing techniques tailored to multi-agent trajectories, and achieves accurate play retrieval at interactive speeds.We showcase the efficacy of our approach in a user study, where we demonstrate orders-of-magnitude improvements in search quality compared to baseline systems.", "references": ["Bennett, P. N., Radlinski, F., White, R. W., and Yilmaz, E. Inferring and using location metadata to personalize web search. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, ACM (2011), 135--144.", "Berndt, D. J., and Clifford, J. Using dynamic time warping to find patterns in time series. In KDD workshop, Seattle, WA (1994), 359--370.", "Bialkowski, A., Lucey, P., Carr, P., Yue, Y., and Matthews, I. \"win at home and draw away\": Automatic formation analysis highlighting the differences in home and away team behaviors. In MIT Sloan Sports Analytics Conference (SSAC) (2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856772"}, {"title": "Multi-modal Multi-view Topic-opinion Mining for Social Event Analysis", "authors": ["Shengsheng Qian\n,", "Tianzhu Zhang\n,", "Changsheng Xu"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we propose a novel multi-modal multi-view topic-opinion mining (MMTOM) model for social event analysis in multiple collection sources. Compared with existing topic-opinion mining methods, our proposed model has several advantages: (1) The proposed MMTOM can effectively take into account multi-modal and multi-view properties jointly in a unified and principled way for social event modeling. (2) Our model is general and can be applied to many other applications in multimedia, such as opinion mining and sentiment analysis, multi-view association visualization, and topic-opinion mining for movie review. (3) The proposed MMTOM is able to not only discover multi-modal common topics from all collections as well as summarize the similarities and differences of these collections along each specific topic, but also automatically mine multi-view opinions on the learned topics across different collections. (4) Our topic-opinion mining results can be effectively applied to many applications including multi-modal multi-view topic-opinion retrieval and visualization, which achieve much better performance than existing methods. To evaluate the proposed model, we collect a real-world dataset for research on multi-modal multi-view social event analysis, and will release it for academic use. We have conducted extensive experiments, and both qualitative and quantitative evaluation results have demonstrated the effectiveness of the proposed MMTOM.", "references": ["R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Susstrunk. Slic superpixels, 2010. In Technical report, EPFL.", "N. Akiva, E. Greitzer, Y. Krichman, and J. Schler. Mining and visualizing online web content using bam: Brand association map. In ICWSM, 2008.", "Y. Bao, N. Collier, and A. Datta. A partially supervised cross-collection topic model for cross-domain text classification. In CIKM, pages 239--248, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964294"}, {"title": "An improved ANN search algorithm for visual search applications", "authors": ["Fuqiang Ma\n,", "Jing Chen\n,", "Yanfeng Tong\n,", "Lei Sun"], "publication": "VRCAI '16: Proceedings of the 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry - Volume 1", "abstract": "ABSTRACT\nApproximate nearest neighbor search is a kind of significant algorithm to ensure the accuracy and speed for visual search system. In this paper, we ameliorate the search algorithm following the framework of product quantization. Product quantization can generate an exponentially large codebook by a product quantizer and then achieve rapid search with the asymmetric distance computation or symmetric distance computation, while it will still produce a larger distortion in some cases when calculating the approximate distance. Therefore, we design the hierarchical residual product quantization which simultaneously quantifies the input and residual space and meanwhile we extend the asymmetric distance computation to handle this quantization method which is still very efficient to estimate the approximate distance. We have tested our method on several datasets, and the experiment shows that our method consistently improves the accuracy against the-state-of-the-art methods.", "references": ["Friedman J., Bentley. J. L. and Finkel. R. A. 1977. An algorithm for finding best matches in logarithmic expected time. ACM Transaction on Mathematical Software, vol. 3, 209--226.", "Gray, R., Vector quantization, 1984. ASSP Magazine, IEEE.", "Chen, D. Tsai. S, and Chandrasekhar, V. 2013. Residual enhanced visual vector as a compact signature for mobile visual search. Signal Processing, vol. 93, 2316--2327."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3013971.3014011"}, {"title": "From discussion to wisdom: web resource recommendation for hyperlinks in stack overflow", "authors": ["Jing Li\n,", "Zhenchang Xing\n,", "Deheng Ye\n,", "Xuejiao Zhao"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nStack Overflow has been providing question and answering service for 7 years. It has become a tremendous knowledge repository for developers' thoughts and practices. Hyperlinks in discussion threads of Stack Overflow are essential knowledge entities for programming on the Web, such as a software library, an API documentation, a code example, or a tutorial. Tens of millions of hyperlinks are disseminated in Stack Overflow, while wisdom on what web resources have been highly recognized by the community is implicit in millions of discussion threads. In this paper, we develop the WisLinker framework that extracts knowledge from discussion, then turns knowledge into wisdom by learning through the knowledge dissemination history. With this wisdom, for a specific hyperlink that users are concerned with, WisLinker can recommend web resources highly recognized by the Stack Overflow community. We evaluate the validity of WisLinker in an open-ended setting using Stack Overflow data dump. We also implement a browser extension for live recommendation of web resources while users browse web pages. WisLinker could enable more efficient exploratory search and information discovery of programming-related web resources.", "references": ["A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec. Discovering value from community activity on focused question answering sites: a case study of stack overflow. In Proc. of KDD, pages 850--858. ACM, 2012.", "A. Bacchelli, L. Ponzanelli, and M. Lanza. Harnessing stack overflow for the ide. In Proc. of the Third International Workshop on Recommendation Systems for Software Engineering, pages 26--30, 2012.", "G. Bellinger, D. Castro, and A. Mills. Data, information, knowledge, and wisdom. 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851815"}, {"title": "Language-independent multi-document text summarization with document-specific word associations", "authors": ["Oskar Gross\n,", "Antoine Doucet\n,", "Hannu Toivonen"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe goal of automatic text summarization is to generate an abstract of a document or a set of documents. In this paper we propose a word association based method for generating summaries in a variety of languages. We show that a robust statistical method for finding associations which are specific to the given document(s) is applicable to many languages. We introduce strategies that utilize the discovered associations to effectively select sentences from the document(s) to constitute the summary. Empirical results indicate that the method works reliably in a relatively large set of languages and outperforms methods reported in MultiLing 2013.", "references": ["E. Baralis and L. Cagliero. Learning from summaries: supporting e-learning activities by means of document summarization. Emerging Topics in Computing, IEEE Transactions on, (99):1--12, 2015.", "E. Baralis, L. Cagliero, A. Fiori, and P. Garza. Mwi-sum: A multilingual summarizer based on frequent weighted itemsets. ACM Transactions on Information Systems, 34(1):5:1--5:35, 2015.", "J. Beasley and P. Chu. A genetic algorithm for the set covering problem. European Journal of Operational Research, 94(2):392--404, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851647"}, {"title": "LifeBook: A Mobile Personal Information Management System on the Cloud", "authors": ["Rita Francese\n,", "Michele Risi\n,", "Giuseppe Scanniello\n,", "Genoveffa Tortora"], "publication": "AVI '16: Proceedings of the International Working Conference on Advanced Visual Interfaces", "abstract": "ABSTRACT\nIn this paper, we present LifeBook, a Personal Information Management (PIM) system that handles information on events captured by all the user's devices. Our PIM retrieves events on the basis of both the user's context and event similarity, which is computed by exploiting an information retrieval technique. We aggregated together the similarity of content, location, time, and event type to relate and surf the events. To this aim, we propose a re-find interface enabling the user to search and visualize information already seen before, of which he remembers some context aspects, such as time and/or place. The events captured on different devices are stored on the cloud without user intervention. A preliminary quantitative and qualitative evaluation has been also conducted to assess the effectiveness of LifeBook. Results in terms of time, effort and relevance of the information provided suggest that LifeBook be a viable means to retrieve personal information. Participants in the empirical investigation also considered the tool appropriate for supporting information re-finding tasks.", "references": ["R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "V. Basili, G. Caldiera, and D. H. Rombach. The Goal Question Metric Paradigm, Encyclopedia of Software Engineering. John Wiley and Sons, 1994.", "V. Bush and J. Wang. As We May Think. Atlantic Monthly, 176:101--108, 1945."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909132.2909264"}, {"title": "Mobile Web Application Generation Features for SuperSQL", "authors": ["Kento Goto\n,", "Motomichi Toyama"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nA lot of time and knowledge are necessary for the Mobile Web application development. In this study, we have implemented the Mobile Web application generation features for SuperSQL, which generates HTML files, JavaScript files, and server-side PHP files as the result of a query execution. This feature consists of 55 new functions of SuperSQL. In the evaluation, we have created three Mobile Web applications and compared the amount of lines of code with other popular technologies. As a result, the extended SuperSQL achieved 97% reduction of code amount compared to HTML / JavaScript / PHP and 89% reduction compared to Ruby on Rails / JavaScript.", "references": ["Apache Tapestry Home Page. http://tapestry.apache.org/.", "Ark. https://metacpan.org/release/Ark.", "R. M. Borromeo and M. Toyama. Optimization of SuperSQL Execution by Query Decomposition. In Proceedings of the Fifth International Conference on Advances in Databases, Knowledge, and Data Applications, pages 65--70, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938524"}, {"title": "Similarity analysis of neuronal activation patterns", "authors": ["Eugênio de Carvalho Saraiva\n,", "Herman Martins Gomes"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nUnderstanding the relationship between neuronal activation patterns of specific brain areas resulting from sensorial experiences is a challenging problem. In this context, we analyzed the levels of similarity between neuronal activation patterns using a semi-supervised method and data acquired from microelectrode arrays implanted on specific brain areas of rats, during an experiment of tactile exploration of four classes of physical objects in the dark. Eight factors were considered (animal, brain region, pair of objects, clustering algorithm, clustering evaluation metric, bin size, window size and contact interval), resulting in 294.912 similarity measurements. Hypotheses regarding the relationship of each of the factors were statistically tested. Not all degrees of similarity between the patterns extracted from pairs of different exploration intervals, for two different objects, were equivalent to a given treatment. This indicated that the similarity between the patterns is sensitive to all the factors analyzed and provides evidence about the complexity of neuronal coding in the brain.", "references": ["Nicolelis, M. A. L, and Lebedev, M. A. Principles of neural ensemble physiology underlying the operation of brain-machine interfaces. Nature reviews. Neuroscience, 10, 7, 2009, 530--540.", "Larry, S., et al., Fundamental Neuroscience, Academic Press, 4th ed., 2012.", "Pang, C. C., Upton, A. R., Shine, G., and Kamath, M. V. A comparison of algorithms for detection of spikes in the electroencephalogram. IEEE transactions on bio-medical engineering, 50, 4, 2003, 521--526."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851723"}, {"title": "Linked Data Profiling: Identifying the Domain of Datasets Based on Data Content and Metadata", "authors": ["Andrejs Abele"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nSince the beginning of the Linked Open Data initiative, the number of published open datasets has gradually increased, but the datasets often do not contain description about content such as the dataset domain (e.g., medicine, cancer), when this information is available, it is usually coarse-grained e.g. organic-edunet contains the metadata about a collection of learning objects exposed through the Organic.Edunet portal, but it is classified as Life science. In this work we propose approaches that will provide a detailed description of existing datasets as well as linking assistance when publishing new datasets by generating detailed descriptions of the publishers dataset.", "references": ["Z. Abedjan, T. Gruetze, A. Jentzsch, and F. Naumann. Profiling and mining rdf data with prolod", ". In Data Engineering (ICDE), 2014 IEEE 30th International Conference on, pages 1198--1201. IEEE, 2014.", "S. Auer, J. Demter, M. Martin, and J. Lehmann. Lodstats--an extensible framework for high-performance dataset analytics. In Knowledge Engineering and Knowledge Management, pages 353--362. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888603"}, {"title": "Analyzing the Decorative Style of 3D Heritage Collections Based on Shape Saliency", "authors": ["Karina Rodriguez Echavarria\n,", "Ran Song"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nAs technologies for 3D acquisition become widely available, it is expected that 3D content documenting heritage artifacts will become increasingly popular. Nevertheless, to provide access to and enable the creative use of this content, it is necessary to address the challenges to its access. These include the automatic enrichment of 3D content with suitable metadata so that content does not get lost. To address these challenges, this article presents research on developing technologies to support the organization and discoverability of 3D content in the Cultural Heritage (CH) domain. This research takes advantage of the fact that heritage artifacts have been designed throughout the centuries with distinctive design styles. Hence, the shape and the decoration of an artifact can provide significant information on the history of the artifact. The main contributions of this article include an ontology for documenting 3D representations of heritage artifacts decorated with ornaments such as architectural mouldings. In addition, the article presents a complementary shape retrieval method based on shape saliency to improve the automatic classification of the artifact’s semantic information based on its 3D shape. This method is tested on a collection of Regency ornament mouldings found in domestic interiors. This content provides a rich dataset on which to base the exploration of issues common to many CH artifacts, such as design styles and decorative ornament.", "references": ["3D-COFORM Project. 2016. 3D Data Catalogue. Retrieved from http://www.3dcoform.eu/x3domCatalogue/.", "Daniel G. Aliaga, Elisa Bertino, and Stefano Valtolina. 2011. DECHO—A framework for the digital exploration of cultural heritage objects. Journal on Computing and Cultural Heritage 3, 3, Article 12 (Feb. 2011), 26 pages.", "Marco Attene, Francesco Robbiano, Michela Spagnuolo, and Bianca Falcidieno. 2007. Semantic annotation of 3D surface meshes based on feature characterization. In Proceedings of the Semantic and Digital Media Technologies. Springer-Verlag, 126--139."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2943778"}, {"title": "Session details: Volume I: Artificial intelligence and agents, distributed systems, and information systems: The semantic web and applications track", "authors": ["Soon Ae Chun\n,", "Hyoil Han\n,", "Sangsoo Sung"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252766"}, {"title": "Understanding Document Semantics from Summaries: A Case Study on Hindi Texts", "authors": ["Karthik Krishnamurthi\n,", "Vijayapal Reddy Panuganti\n,", "Vishnu Vardhan Bulusu"], "publication": "ACM Transactions on Asian and Low-Resource Language Information Processing", "abstract": "Abstract\nSummary of a document contains words that actually contribute to the semantics of the document. Latent Semantic Analysis (LSA) is a mathematical model that is used to understand document semantics by deriving a semantic structure based on patterns of word correlations in the document. When using LSA to capture semantics from summaries, it is observed that LSA performs quite well despite being completely independent of any external sources of semantics. However, LSA can be remodeled to enhance its capability to analyze correlations within texts. By taking advantage of the model being language independent, this article presents two stages of LSA remodeling to understand document semantics in the Indian context, specifically from Hindi text summaries. One stage of remodeling is done by providing supplementary information, such as document category and domain information. The second stage of remodeling is done by using a supervised term weighting measure in the process. The remodeled LSA’s performance is empirically evaluated in a document classification application by comparing the accuracies of classification to plain LSA. An improvement in the performance of LSA in the range of 4.7% to 6.2% is achieved from the remodel when compared to the plain model. The results suggest that summaries of documents efficiently capture the semantic structure of documents and is an alternative to full-length documents for understanding document semantics.", "references": ["K. Baker 2005. Singular Value Decomposition Tutorial. Retrieved September 22, 2016, from http://www.ling.ohio-state.edu/&sim;kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf.", "M. Berry and S. Dumais. 1995. Using linear algebra for intelligent information retrieval. SIAM Review 37, 4, 573--595.", "E. Chisholm and T. Kolda. 1999. New Term Weighting Formulas for the Vector Space Method in Information Retrieval. Report ORNL/TM-13756. Computer Science and Mathematics Division, Oak Ridge National Laboratory."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2956236"}, {"title": "Semantic enrichment of places with VGI sources: a knowledge based approach", "authors": ["Camille Tardy\n,", "Gilles Falquet\n,", "Laurent Moccozet"], "publication": "GIR '16: Proceedings of the 10th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nWe propose a categorization algorithm for text content description such as tags for images from social media or crowd sourcing services, to identify places characteristics. The algorithm is based on a spatial coverage and a multi-facets categorization. We describe how it can be applied to individually process images from Flickr in order to extract geo-spatial knowledge. It is particularly dedicated for places with a small number of photos. The extraction process is done using categorization rules based on geographic and terminological knowledge resources.", "references": ["Harispe, S., Ranwez, S., Janaqi, S., and Montmain, J. 2014. The semantic measures library and toolkit: fast computation of semantic similarity and relatedness using biomedical ontologies. Bioinformatics. 30, 5 (Feb. 2014), 740--742.", "Moro, A., Raganato, A., and Navigli, R. 2014. Entity linking meets word sense disambiguation: a unified approach. Transactions of the Association for Computational Linguistics (TACL). 2, 231--244.", "Purves, R., Edwardes, A., and Wood, J. 2011. Describing place through user generated content. First Monday. 16, 9 (Sep. 2011)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003464.3003470"}, {"title": "Veracity of Big Data: Challenges of Cross-Modal Truth Discovery", "authors": ["Laure Berti-Equille\n,", "Mouhamadou Lamine Ba"], "publication": "Journal of Data and Information Quality", "abstract": "", "references": ["Laure Berti-Equille and Javier Borge-Holthoefer. 2015. Veracity of Data: From Truth Discovery Computation Algorithms to Models of Misinformation Dynamics. Morgan & Claypool Publishers.", "Jing Gao, Qi Li, Bo Zhao, Wei Fan, and Jiawei Han. 2015. Truth discovery and crowdsourcing aggregation: A unified perspective. Proc. of the VLDB Endowment 8, 12 (2015), 2048--2059.", "Giannis Haralabopoulos, Ioannis Anagnostopoulos, and Sherali Zeadally. 2016. The challenge of improving credibility of user-generated content in online social networks. ACM JDIQ (2016)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2935753"}, {"title": "ArchiRI - An ontology-based architecture for the exchange of reputation information", "authors": ["Claudio A.S. Lelis\n,", "Regina Braga\n,", "Marco A.P. Araujo\n,", "Jose M.N. David"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nReputation information has become an important asset for the software development companies. Such information depends on the context for which the reputation was established. In geographically distributed teams, each team may represent a different context. To allow the exchange of information between groups and contexts, one should use an interoperable reputation model. Therefore, the ArchiRI architecture was specified. Through ontologies and views, supports decision making in software maintenance projects. A scenario of evaluation was detailed, presenting evidence that ArchiRI can help managers in analyzing the members' reputation, compare this information and make decisions.", "references": ["Alnemr, R. e Meinel, C. 2012. Reputation objects for interoperable reputation exchange: Implementation and design decisions. Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom), 8th International Conference on, 672-680", "Anastacio, W.M. e Prado, E.P. V 2014. Fatores Criticos de Sucesso na Integracao de Sistemas?: Um Estudo de Caso em Uma Organizacao Publica Brasileira. X Simposio Brasileiro de Sistemas de Informacao (SBSI), 78-89", "Casare, S. e Sichman, J.S. 2005. Using a functional ontology of reputation to interoperate different agent reputation models. Journal of the Brazilian Computer Society, 79-94."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021967"}, {"title": "Beyond Ranking: Optimizing Whole-Page Presentation", "authors": ["Yue Wang\n,", "Dawei Yin\n,", "Luo Jie\n,", "Pengyuan Wang\n,", "Makoto Yamada\n,", "Yi Chang\n,", "Qiaozhu Mei"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nModern search engines aggregate results from different verticals: webpages, news, images, video, shopping, knowledge cards, local maps, etc. Unlike \"ten blue links\", these search results are heterogeneous in nature and not even arranged in a list on the page. This revolution directly challenges the conventional \"ranked list\" formulation in ad hoc search. Therefore, finding proper presentation for a gallery of heterogeneous results is critical for modern search engines.\nWe propose a novel framework that learns the optimal page presentation to render heterogeneous results onto search result page (SERP). Page presentation is broadly defined as the strategy to present a set of items on SERP, much more expressive than a ranked list. It can specify item positions, image sizes, text fonts, and any other styles as long as variations are within business and design constraints. The learned presentation is content-aware, i.e. tailored to specific queries and returned results. Simulation experiments show that the framework automatically learns eye-catchy presentations for relevant results. Experiments on real data show that simple instantiations of the framework already outperform leading algorithm in federated search result presentation. It means the framework can learn its own result presentation strategy purely from data, without even knowing the \"probability ranking principle\".", "references": ["Eye tracking study: Google results with videos. https://www.looktracker.com/blog/eye-tracking-case-study/google-results-with-videos-eye-tracking-study.", "Google ads in second position get more attention. http://miratech.com/blog/eye-tracking-google.html.", "Trec federated web search track. https://sites.google.com/site/trecfedweb."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835824"}, {"title": "Optimizing Nugget Annotations with Active Learning", "authors": ["Gaurav Baruah\n,", "Haotian Zhang\n,", "Rakesh Guttikonda\n,", "Jimmy Lin\n,", "Mark D. Smucker\n,", "Olga Vechtomova"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNugget-based evaluations, such as those deployed in the TREC Temporal Summarization and Question Answering tracks, require human assessors to determine whether a nugget is present in a given piece of text. This process, known as nugget annotation, is labor-intensive. In this paper, we present two active learning techniques that prioritize the sequence in which candidate nugget/sentence pairs are presented to an assessor, based on the likelihood that the sentence contains a nugget. Our approach builds on the recognition that nugget annotation is similar to high-recall retrieval, and we adapt proven existing solutions. Simulation experiments with four existing TREC test collections show that our techniques yield far more matches for a given level of effort than baselines that are typically deployed in previous nugget-based evaluations.", "references": ["J. Allan. HARD Track Overview in TREC 2004 High Accuracy Retrieval fromDocuments. TREC, 2004.", "J. A. Aslam, M. Ekstrand-Abueg, V. Pavlu, F. Diaz, and T. Sakai. TREC 2013 Temporal Summarization. TREC, 2013.", "J. A. Aslam, M. Ekstrand-Abueg, V. Pavlu, F. Diaz, and T. Sakai. TREC 2014 Temporal Summarization. TREC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983694"}, {"title": "Snapscreen: Linking Traditional TV and the Internet", "authors": ["Sabine Lösch\n,", "Thomas Willomitzer\n,", "Gabriele Anderst-Kotsis"], "publication": "MoMM '16: Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media", "abstract": "ABSTRACT\nWe present \"Snapscreen\", a prototype second-screen app. Snapscreen is a platform that allows content providers (TV channels, broadcasters) to offer transparently content-related information and services to users watching TV. Users need only install the app on their mobile devices and can then take a snapshot of TV content they are currently watching. The resulting \"snap\" image is processed by the app to generate an identification key that is sent to the Snapscreen server, where it is matched to TV content in real time. Once a specific program/TV station has been identified, information and services related to this content are sent back to the user for interaction.\nThus, Snapscreen can bridge television and Internet intuitively by using the television content detected to form the basis of an Internet query. An advantage of Snapscreen (over most state-of-the-art apps) is that this single app can offer access to a variety of interactive services and can link to a wide range of content offered by any television channel (station, broadcaster).", "references": ["E. Anstead, S. Benford, and R. J. Houghton. Many-screen viewing: Evaluating an olympics companion application. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video, TVX '14, pages 103--110, New York, NY, USA, 2014. ACM.", "D. Eversman, T. Major, M. Tople, L. Schaffer, and J. Murray. United universe: A second screen transmedia experience. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video, TVX '15, pages 173--178, New York, NY, USA, 2015. ACM.", "D. Geerts, R. Leenheer, D. De Grooff, J. Negenman, and S. Heijstraten. In front of and behind the second screen: Viewer and producer perspectives on a companion app. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video, TVX '14, pages 95--102, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007120.3007139"}, {"title": "Online Food Recipe Title Semantics: Combining Nutrient Facts and Topics", "authors": ["Tomasz Kusmierczyk\n,", "Kjetil Nørvåg"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDietary pattern analysis is an important research area, and recently the availability of rich resources in food-focused social networks has enabled new opportunities in that field. However, there is a little understanding of how online textual content is related to actual health factors, e.g., nutritional values. To contribute to this lack of knowledge, we present a novel approach to mine and model online food content by combining text topics with related nutrient facts. Our empirical analysis reveals a strong correlation between them and our experiments show the extent to which it is possible to predict nutrient facts from meal name.", "references": ["S. Abbar, Y. Mejova, and I. Weber. You tweet what you eat: Studying food consumption through Twitter. In Proc. of CHI, 2015.", "M. De Choudhury and S. S. Sharma. Characterizing dietary choices, nutrition, and language in food deserts via social media. In Proc. of CSCW, 2016.", "H. A. Schwartz et al. Characterizing geographic variation in well-being using tweets. In Proc. of ICWSM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983897"}, {"title": "Personalized Search: Potential and Pitfalls", "authors": ["Susan T. Dumais"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTraditionally search engines have returned the same results to everyone who asks the same question. However, using a single ranking for everyone in every context at every point in time limits how well a search engine can do in providing relevant information. In this talk I present a framework to quantify the \"potential for personalization\" which we use to characterize the extent to which different people have different intents for the same query. I describe several examples of how we represent and use different kinds of contextual features to improve search quality for individuals and groups. Finally, I conclude by highlighting important challenges in developing personalized systems at Web scale including privacy, transparency, serendipity, and evaluation.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983367"}, {"title": "DeuZikaChico: the power of AGI to monitor and combat epidemics such as Dengue, Zika and Chikungunya", "authors": ["Luiz H. Andrade\n,", "Brunna S.P. Amorim\n,", "Maxwell G. Oliveira\n,", "Andre L.F. Alves\n,", "Jose N.L. Abrante\n,", "Daniel F.B. Leite\n,", "Julio H. Rocha\n,"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nWith the advent of the social web, users contribute actively sharing their content instead of just navigate the Web. Such users have become truly human sensors through collaborative platforms such as the LBSNs (Location-Based Social Networks), bringing a collective intelligence for problems solving. Human sensors are in charge of producing VGI (Volunteered Geographic Information) and AGI (Ambient Geographic Information), very useful information in the most diverse application domains, such as the Smart Cities. These sensors assist on solving various problems of urban areas and contributing to the citizens' life quality improvement. Currently, the growing number of diseases cases transmitted by the Aedes aegypti mosquito, such as Dengue, Zika and Chikungunya, has led both Brazil and other countries to an alert state. The most efficient combating method nowadays relies on the population taking preventive actions, posing a challenge to the local authorities. In this context, this paper presents the DeuZikaChico, a framework that makes use of GIS technologies, mobile platforms, crowdsourcing and social networking, with the purpose of providing public managers better monitoring of epidemics with the support from the society.", "references": ["M. N. Antunes, C. H. d. Silva, M. C. S. Guimaraes, and M. H. L. Rabaco. Monitoramento de informacao em midias sociais: o e-Monitor Dengue. Transinformacao, 26:9-18, 2014.", "G. Calvet, R. S. Aguiar, A. S. O. Melo, S. A. Sampaio, I. de Filippis, A. Fabri, E. S. M. Araujo, P. C. de Sequeira, M. C. L. de Mendonca, L. de Oliveira, D. A. Tschoeke, C. G. Schrago, F. L. Thompson, P. Brasil, F. B. dos Santos, R. M. R. Nogueira, A. Tanuri, and A. M. B. de Filippis. Detection and sequencing of Zika virus from amniotic fluid of fetuses with microcephaly in Brazil: a case study. The Lancet Infectious Diseases, pages 1-8, 2016.", "J. Cranshaw, E. Toch, J. Hong, A. Kittur, and N. Sadeh. Bridging the Gap Between Physical Location and Online Social Networks. In Proceedings of the 12th ACM International Conference on Ubiquitous Computing, UbiComp '10, pages 119-128, New York, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022019"}, {"title": "Understanding user behavior in textual analysis: a thinking aloud approach for digital humanities research contexts", "authors": ["Patricia Martin-Rodilla\n,", "Cesar Gonzalez-Perez"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nThe exponential increase in availability of scientific papers, institutional reports or research monographies in digital contexts (i.e. in digital repositories, archives or social scientific networks) has led to the advancement of manual, semi-automatic or automatic-based methods to analyze these texts in the digital environment. These techniques cover a heterogeneous range, from manual expert analysis using computer methods (usually by annotation systems), to the application of natural language processing algorithms or discourse analysis techniques, which are able to identify cognitive relationships between text elements, e.g. causal structures or contrasts argumentations. This advancement is more evident in humanities research contexts, where most of the knowledge generated are expressed in textual formats. However, how the use of these techniques is affecting the analysis conducted by researchers in humanities' texts? Is it possible to measure the quality of the textual analysis? What kind of cognitive structures are identified in the text using these methods?\nThis paper presents an empirical study conducted with humanities researchers, with the goal of obtaining a better understanding about how texts in digital contexts are analyzed by these professionals using semiautomatic discourse analysis techniques. The paper also proposes a method, based on Thinking Aloud protocols, in order to design experiments and evaluate software cognitive aspects, such as digital textual analysis, with humanities professionals. Finally, the paper discusses about how empirical studies and the Thinking Aloud method constitute a solid basis to better understand the relationship between expert textual analysis in humanities and it conducting using software methods.", "references": ["R. Gate. (2008--2016). Reseach Gate. Available: https://www.researchgate.net/", "Academia. (2016). Academia Edu. Available: https://www.academia.edu/", "L. Ratinov and D. Roth, \"Design challenges and misconceptions in named entity recognition,\" in Proceedings of the Thirteenth Conference on Computational Natural Language Learning, 2009, pp. 147--155."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012528"}, {"title": "Hilbert Exclusion: Improved Metric Search through Finite Isometric Embeddings", "authors": ["Richard Connor\n,", "Franco Alberto Cardillo\n,", "Lucia Vadicamo\n,", "Fausto Rabitti"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nMost research into similarity search in metric spaces relies on the triangle inequality property. This property allows the space to be arranged according to relative distances to avoid searching some subspaces. We show that many common metric spaces, notably including those using Euclidean and Jensen-Shannon distances, also have a stronger property, sometimes called the four-point property: In essence, these spaces allow an isometric embedding of any four points in three-dimensional Euclidean space, as well as any three points in two-dimensional Euclidean space. In fact, we show that any space that is isometrically embeddable in Hilbert space has the stronger property. This property gives stronger geometric guarantees, and one in particular, which we name the Hilbert Exclusion property, allows any indexing mechanism which uses hyperplane partitioning to perform better. One outcome of this observation is that a number of state-of-the-art indexing mechanisms over high-dimensional spaces can be easily refined to give a significant increase in performance; furthermore, the improvement given is greater in higher dimensions. This therefore leads to a significant improvement in the cost of metric search in these spaces.", "references": ["Aleksandr Danilovich Aleksandrov, Andre Nikolaevich Kolmogorov, and Mikhail Alekseevich Lavrent’ev. 1999. Mathematics: Its Content, Methods and Meaning (Dover Books on Mathematics). Dover Publications.", "Leonard M. Blumenthal. 1933. A note on the four-point property. Bull. Am. Math. Soc. 39, 6 (1933), 423--426.", "Leonard M. Blumenthal. 1953. Theory and Applications of Distance Geometry. Clarendon Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001583"}, {"title": "An optimal approach for extraction of Web Contents using Semantic Web framework", "authors": ["Shabina Dhuria\n,", "Harmunish Taneja\n,", "Kavita Taneja"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nWeb Mining aspires to discern insights in relation to the significance of resources and their usage existing over the web. The sighting of meaning is not possible by specifying the syntactical nature of the data only. This highlights the need of tapping the navigation behavior of user and formalization of web site semantics. The imperative objective of semantic web mining is to equip the search engines to figure out the content available at both web pages and web sites in an optimal manner by applying the ontology. This paper has a fourfold objective. Firstly, it highlights features of major approaches to mine web contents that can be structured, unstructured and semi-structured data. Secondly, a variety of web content mining tools along with their relative features are discussed. Thirdly, it focuses on various challenges and evolving research issues related to the mining of contents available over the web. Lastly, Semantic Web based Mining framework for effective extraction of web contents by applying the Web Mining techniques for structuring the Semantic Web and incorporating semantic structures to the Web is elaborated.", "references": ["Raymond, K. and Hendrik, B. 2000. Web Mining Research, A Survey. SIGKDD Explorations. 2 (2000), 1--15.", "Ajoudanian, S. and Jazi, M. D. 2009. Deep Web Content Mining. WASET. 49 (2009).", "Johnson, F. and Gupta, S. K. 2012. Web Content Mining Techniques- A Survey. International Journal of Computer Applications. 47, 11 (2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905246"}, {"title": "Teaching High School Students Computational Thinking with Hands-on Activities", "authors": ["Wei-Lin Li\n,", "Chiu-Fan Hu\n,", "Cheng-Chih Wu"], "publication": "ITiCSE '16: Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education", "abstract": "ABSTRACT\nIn this study we developed three hands-on activities to teach high school students computational thinking (CT) and, specifically, the decomposition skills. The activities were designed to enable students to solve problems by using application tools. The computer science concepts utilized in the activities included binary search, quick sort and iteration. We evaluated the effect of the activities utilizing a post-activity questionnaire, a post-test, students' worksheets, and semi-structured interviews with the participating students. The results indicated that the hands-on activities developed in this study improved students' CT ability.", "references": ["Google. (2015). Google for Education. Retrieved from https://www.google.com/edu/resources/programs/exploring-computational-thinking/", "Rubinstein, A., & Chor, B. (2014). Computational Thinking in Life Science Education. PLoS Computational Biology, 10(11), e1003897. http://doi.org/10.1371/journal.pcbi.100389"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899415.2925496"}, {"title": "Coherence-based Dual Microphone Wind Noise Reduction by Wiener Filtering", "authors": ["Jinuk Park\n,", "Jihoon Park\n,", "Seunghyung Lee\n,", "Juntae Kim\n,", "Minsoo Hahn"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn this paper, we propose a two-step method to reduce wind noise in dual microphone environments. Wind noise in outdoors recording often leads to critical degradation to the speech signal. Therefore, it is necessary to apply algorithms for reduction of wind noise. The proposed algorithm exploits the coherence of input signals and use a Wiener filter to noise frequency regions. For evaluating the proposed algorithm, we compare with existing algorithms in terms of the noise attenuation minus speech attenuation (NA-SA). Sentences from the IEEE sentence were recorded in meeting room environments and wind noise was collected in outdoors. Then, those signals are synthesized with variant SNR conditions. Proposed algorithm shows the best performance compared with other reference algorithms.", "references": ["Loizou, P.C. 2007. Speech Enhancement. Boca Raton, FL, USA: CRC Press.", "Steven F. Boll. 1979. Suppression of acoustic noise in speech using spectral subtraction. IEEE Trans. Acoustics, Speech, and Signal Processing. 27, 2 (1979), 113--120.", "Nelke, C.M. and Vary, P. 2015. Wind noise short term power spectrum estimation using pitch adaptive inverse binary masks. Proc. of IEEE Intern. Conf. on Acoustics Speech and Signal Process (Apr. 2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015206"}, {"title": "Model-Based Collaborative Personalized Recommendation on Signed Social Rating Networks", "authors": ["Gianni Costa\n,", "Riccardo Ortale"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nRecommendation on signed social rating networks is studied through an innovative approach. Bayesian probabilistic modeling is used to postulate a realistic generative process, wherein user and item interactions are explained by latent factors, whose relevance varies within the underlying network organization into user communities and item groups. Approximate posterior inference captures distrust propagation and drives Gibbs sampling to allow rating and (dis)trust prediction for recommendation along with the unsupervised exploratory analysis of network organization. Comparative experiments reveal the superiority of our approach in rating and link prediction on Epinions and Ciao, besides community quality and recommendation sensitivity to network organization.", "references": ["D. Agarwal and B.-C. Chen. 2009. Regression-based latent factor models. In Proc. of ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining. 19--28.", "E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. 2008. Mixed membership stochastic blockmodels. Journal of Machine Learning Research 9 (2008), 1981--2014.", "L. Backstrom and J. Leskovec. 2011. Supervised random walks: Predicting and recommending links in social networks. In Proc. of ACM Int. Conf. on Web Search and Data Mining. 635--644."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934681"}, {"title": "Exploiting accelerators for efficient high dimensional similarity search", "authors": ["Sandeep R. Agrawal\n,", "Christopher M. Dee\n,", "Alvin R. Lebeck"], "publication": "PPoPP '16: Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming", "abstract": "ABSTRACT\nSimilarity search finds the most similar matches in an object collection for a given query; making it an important problem across a wide range of disciplines such as web search, image recognition and protein sequencing. Practical implementations of High Dimensional Similarity Search (HDSS) search across billions of possible solutions for multiple queries in real time, making its performance and efficiency a significant challenge. Existing clusters and datacenters use commercial multicore hardware to perform search, which may not provide the optimal performance and performance per Watt.\nThis work explores the performance, power and cost benefits of using throughput accelerators like GPUs to perform similarity search for query cohorts even under tight deadlines. We propose optimized implementations of similarity search for both the host and the accelerator. Augmenting existing Xeon servers with accelerators results in a 3× improvement in throughput per machine, resulting in a more than 2.5× reduction in cost of ownership, even for discounted Xeon servers. Replacing a Xeon based cluster with an accelerator based cluster for similarity search reduces the total cost of ownership by more than 6× to 16× while consuming significantly less power than an ARM based cluster.", "references": ["S. R. Agrawal. Harnessing Data Parallel Hardware for Server Workloads. PhD thesis, Duke University, 2015.", "S. R. Agrawal, V. Pistol, J. Pang, J. Tran, D. Tarjan, and A. R. Lebeck. Rhythm: Harnessing data parallel hardware for server workloads. In Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS '14, pages 19--34, New York, NY, USA, 2014. ACM. ISBN 978-1-4503-2305-5. doi: 10.1145/2541940.2541956.", "L. A. Barroso, J. Clidaras, and U. Hölzle. The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, Second Edition. 2013. doi: 10.2200/S00516ED2V01Y201306CAC024."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851141.2851144"}, {"title": "Document Filtering for Long-tail Entities", "authors": ["Ridho Reinanda\n,", "Edgar Meij\n,", "Maarten de Rijke"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nFiltering relevant documents with respect to entities is an essential task in the context of knowledge base construction and maintenance. It entails processing a time-ordered stream of documents that might be relevant to an entity in order to select only those that contain vital information. State-of-the-art approaches to document filtering for popular entities are entity-dependent: they rely on and are also trained on the specifics of differentiating features for each specific entity. Moreover, these approaches tend to use so-called extrinsic information such as Wikipedia page views and related entities which is typically only available only for popular head entities. Entity-dependent approaches based on such signals are therefore ill-suited as filtering methods for long-tail entities. In this paper we propose a document filtering method for long-tail entities that is entity-independent and thus also generalizes to unseen or rarely seen entities. It is based on intrinsic features, i.e., features that are derived from the documents in which the entities are mentioned. We propose a set of features that capture informativeness, entity-saliency, and timeliness. In particular, we introduce features based on entity aspect similarities, relation patterns, and temporal expressions and combine these with standard features for document filtering. Experiments following the TREC KBA 2014 setup on a publicly available dataset show that our model is able to improve the filtering performance for long-tail entities over several baselines. Results of applying the model to unseen entities are promising, indicating that the model is able to learn the general characteristics of a vital document. The overall performance across all entities---i.e., not just long-tail entities---improves upon the state-of-the-art without depending on any entity-specific training data.", "references": ["J. Allan. Introduction to topic detection and tracking. In Topic Detection and Tracking, pages 1--16. Kluwer Academic Publishers, 2002.", "N. Balasubramanian and S. Cucerzan. Automatic generation of topic pages using query-based aspect models. In CIKM '09, pages 2049--2052. ACM, 2009.", "N. Balasubramanian and S. Cucerzan. Topic pages: An alternative to the ten blue links. In ICSC '10. IEEE, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983728"}, {"title": "Image Search Reranking with Relevance, Diversity and Topic Coverage", "authors": ["Xuefei Lin\n,", "Tian Zhang"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nImage search reranking has recently been proposed to improve image search results. Most of the conventional reranking methods cannot leverage both relevance and diversity of the search results simultaneously. In addition, they usually ignore the latent topics of images. Towards this end, this paper proposes a new reranking method by exploring relevance, diversity and topic coverage of the search results simultaneously. Specifically, the proposed method first groups the returned images by exploring the underlying topics. Then, the desired ranking list is generated by a greedy algorithm based on the relevance score, visual similarity, topic coverage and representativeness scores. Experimental results on an image set collected from Flickr demonstrate the performance of the proposed method.", "references": ["D. Cai, X. He, Z. Li, W. Y. Ma, and J. R. Wen. Hierarchical clustering of www image search results using visual. In ACM ICM, pages 952--959, 2004.", "R. L. Cilibrasi and P. M. B. Vitanyi. The google similarity distance. IEEE Transactions on Knowledge Data Engineering, 19(3):370--383, 2007.", "T. Deselaers, T. Gass, P. Dreuw, and H. Ney. Jointly optimising relevance and diversity in image retrieval. In ACM, pages 1--8, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007738"}, {"title": "Predicting location semantics combining active and passive sensing with environment-independent classifier", "authors": ["Masaya Tachikawa\n,", "Takuya Maekawa\n,", "Yasuyuki Matsushita"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nThis paper presents a method for estimating a user's indoor location without using training data collected by the user in his/her environment. Specifically, we attempt to predict the user's location semantics, i.e., location classes such as restroom and meeting room. While indoor location information can be used in many real-world services, e.g., context-aware systems, lifelogging, and monitoring the elderly, estimating the location information requires training data collected in an environment of interest. In this study, we combine passive sensing and active sound probing to capture and learn inherent sensor data features for each location class using labeled training data collected in other environments. In addition, this study modifies the random forest algorithm to effectively extract inherent sensor data features for each location class. Our evaluation showed that our method achieved about 85% accuracy without using training data collected in test environments.", "references": ["Nobuharu Aoshima. 1981. Computer-generated pulse signal applied for sound measurement. The Journal of the Acoustical Society of America 69, 5 (1981), 1484--1488.", "Satoshi Asano, Yuki Wakuda, Noboru Koshizuka, and Ken Sakamura. 2012. A robust pedestrian dead-reckoning positioning based on pedestrian behavior and sensor validity. In IEEE/ION Position Location and Navigation Symposium (PLANS 2012). 328--333.", "Martin Azizyan, Ionut Constandache, and Romit Roy Choudhury. 2009. SurroundSense: mobile phone localization via ambience fingerprinting. In MobiCom 2009. 261--272."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971684"}, {"title": "Retrievability: An Independent Evaluation Measure", "authors": ["Colin Wilkie"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation Retrieval systems have traditionally been evaluated in terms of efficiency and performance. These aspects of retrieval systems, whilst very important, do not cover a crucial aspect of the system, the access it provides to the documents of the collection. Retrievability, a document centric evaluation measure, introduced by Azzopardi and Vinay, provides an alternative approach to evaluation [1]. Retrievability is the ease with which a document can be retrieved using a retrieval system. The more queries which retrieve the document, and the higher up the document is returned, the more retrievable it is. It can thus be used to describe how difficult it is to find documents in the collection given a particular configuration of a retrieval system. Unlike typical performance evaluations, performing a retrievability analysis can be done without recourse to relevancy judgements meaning there is no reliance on a test collection. This has major advantages when tuning a retrieval systems parameters as the tuning can be performed on the live collection.", "references": ["Azzopardi, L., Vinay, V.: Retrievability: An evaluation measure for higher order information access tasks. In: Proc. of the 17th ACM CIKM. pp. 561--570 (2008)", "Wilkie, C., Azzopardi, L.: Relating retrievability, performance and length. In: Proc. of the 36th ACM SIGIR conference. pp. 937--940 (2013)", "Wilkie, C., Azzopardi, L.: Best and fairest: An empirical analysis of retrieval system bias. Advances in Information Retrieval pp. 13--25 (2014)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911478"}, {"title": "GeoBurst: Real-Time Local Event Detection in Geo-Tagged Tweet Streams", "authors": ["Chao Zhang\n,", "Guangyu Zhou\n,", "Quan Yuan\n,", "Honglei Zhuang\n,", "Yu Zheng\n,", "Lance Kaplan\n,", "Shaowen Wang\n,", "Jiawei Han"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe real-time discovery of local events (e.g., protests, crimes, disasters) is of great importance to various applications, such as crime monitoring, disaster alarming, and activity recommendation. While this task was nearly impossible years ago due to the lack of timely and reliable data sources, the recent explosive growth in geo-tagged tweet data brings new opportunities to it. That said, how to extract quality local events from geo-tagged tweet streams in real time remains largely unsolved so far.\nWe propose GeoBurst, a method that enables effective and real-time local event detection from geo-tagged tweet streams. With a novel authority measure that captures the geo-topic correlations among tweets, GeoBurst first identifies several pivots in the query window. Such pivots serve as representative tweets for potential local events and naturally attract similar tweets to form candidate events. To select truly interesting local events from the candidate list, GeoBurst further summarizes continuous tweet streams and compares the candidates against historical activities to obtain spatiotemporally bursty ones. Finally, GeoBurst also features an updating module that finds new pivots with little time cost when the query window shifts. As such, GeoBurst is capable of monitoring continuous streams in real time. We used crowdsourcing to evaluate GeoBurst on two real-life data sets that contain millions of geo-tagged tweets. The results demonstrate that GeoBurst significantly outperforms state-of-the-art methods in precision, and is orders of magnitude faster.", "references": ["http://goo.gl/GQF38b.", "http://goo.gl/i0Gdol.", "H. Abdelhaq, C. Sengstock, and M. Gertz. Eventweet: Online localized event detection from twitter. PVLDB, 6(12):1326--1329, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911519"}, {"title": "Report on the Second International Workshop on Exploratory Search in Databases and the Web (ExploreDB 2015)", "authors": ["Georgia Koutrika\n,", "Laks V.S. Lakshmanan\n,", "Mirek Riedewald\n,", "Mohamed A. Sharaf\n,", "Kostas Stefanidis"], "publication": "ACM SIGMOD Record", "abstract": "", "references": ["S. Agrawal and S. Chaudhuri. Automated ranking of database query results. In Proc. CIDR, pages 888--899, 2003.", "S. Agrawal, S. Chaudhuri, and G. Das. Dbxplorer: A system for keyword-basedsearch over relational databases. In Proc. ICDE, pages 5--16, 2002.", "U. Cetintemel, M. Cherniack, J. DeBrabant, Y. Diao, K. Dimitriadou, A. Kalinin, O. Papaemmanouil, and S. B. Zdonik. Query steering for interactive data exploration. In Proc. CIDR, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2935694.2935706"}, {"title": "The LFM-1b Dataset for Music Retrieval and Recommendation", "authors": ["Markus Schedl"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWe present the LFM-1b dataset of more than one billion music listening events created by more than 120,000 users of Last.fm. Each listening event is characterized by artist, album, and track name, and further includes a timestamp. On the (anonymous) user level, basic demographics and a selection of more elaborate user descriptors are included.\nThe dataset is foremost intended for benchmarking in music information retrieval and recommendation. To facilitate experimentation in a straightforward manner, it also includes a precomputed user-item-playcount matrix. In addition, sample Python scripts showing how to load the data and perform efficient computations are provided. An implementation of a simple collaborative filtering recommender rounds off the code package.\nWe discuss in detail the LFM-1b dataset's acquisition, availability, statistics, and content, and place it in the context of existing datasets. We also showcase its usage in a simple artist recommendation task, whose results are intended to serve as baseline against which more elaborate techniques can be assessed. The two unique features of the dataset in comparison to existing ones are (i) its substantial size and (ii) a wide range of additional user descriptors that reflect their music taste and consumption behavior.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-aware Recommender Systems. AI Magazine, 32:67--80, 2011.", "T. Bertin-Mahieux, D. P. Ellis, B. Whitman, and P. Lamere. The Million Song Dataset. In Proceedings of the 12\\textsuperscriptth International Society for Music Information Retrieval Conference (ISMIR), Miami, FL, USA, October 2011.", "O. Celma. Music Recommendation and Discovery -- The Long Tail, Long Fail, and Long Play in the Digital Music Space. Springer, Berlin, Heidelberg, Germany, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912004"}, {"title": "Visual Recognition of Ancient Inscriptions Using Convolutional Neural Network and Fisher Vector", "authors": ["Giuseppe Amato\n,", "Fabrizio Falchi\n,", "Lucia Vadicamo"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nBy bringing together the most prominent European institutions and archives in the field of Classical Latin and Greek epigraphy, the EAGLE project has collected the vast majority of the surviving Greco-Latin inscriptions into a single readily-searchable database. Text-based search engines are typically used to retrieve information about ancient inscriptions (or about other artifacts). These systems require that the users formulate a text query that contains information such as the place where the object was found or where it is currently located. Conversely, visual search systems can be used to provide information to users (like tourists and scholars) in a most intuitive and immediate way, just using an image as query. In this article, we provide a comparison of several approaches for visual recognizing ancient inscriptions. Our experiments, conducted on 17, 155 photos related to 14, 560 inscriptions, show that BoW and VLAD are outperformed by both Fisher Vector (FV) and Convolutional Neural Network (CNN) features. More interestingly, combining FV and CNN features into a single image representation allows achieving very high effectiveness by correctly recognizing the query inscription in more than 90% of the cases. Our results suggest that combinations of FV and CNN can be also exploited to effectively perform visual retrieval of other types of objects related to cultural heritage such as landmarks and monuments.", "references": ["Epigraphic Database Roma. 1999. Retrieved from http://www.edr-edr.it.", "G. Amato, F. Falchi, and C. Gennaro. 2013. On reducing the number of visual words in the bag-of-features representation. In Proceedings of the International Conference on Computer Vision Theory and Applications (VISIGRAPP’13). 657--662.", "G. Amato, F. Falchi, and C. Gennaro. 2015. Fast image classification for monument recognition. Journal on Computing and Cultural Heritage 8, 4, Article 18 (Aug. 2015), 25 pages."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964911"}, {"title": "Search Result Prefetching Using Cursor Movement", "authors": ["Fernando Diaz\n,", "Qi Guo\n,", "Ryen W. White"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch result examination is an important part of searching. High page load latency for landing pages (clicked results) can reduce the efficiency of the search process. Proactively prefetching landing pages in advance of clickthrough can save searchers valuable time. However, prefetching consumes resources that are wasted unless the prefetched results are requested by searchers. Balancing the costs in prefetching particular results against the benefits in reduced latency to searchers represents the search result prefetching challenge. We present methods that leverage searchers' cursor movements on search result pages in real time to dynamically estimate the result that searchers will request next. We demonstrate through large-scale log analysis that our approach significantly outperforms three strong baselines that prefetch results based on (i) the search engine result ranking, (ii) past clicks from all searchers for the query, or (iii) past clicks from the current searcher for the query. Our promising findings have implications for the design of search support that makes the search process more efficient.", "references": ["E. Agichtein and Z. Zheng. Identifying \"best bet\" web search results by mining past user behavior. SIGKDD, 902--908, 2006.", "I. Arapakis, X. Bai, and B.B. Cambazoglu. Impact of response latency on user behavior in web search. SIGIR, 103--112, 2014.", "M. Barreda-Ángeles et al. Unconscious physiological effects of search latency on users and their click behaviour. SIGIR, 203--212, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911516"}, {"title": "Effective Recommendation with Category Hierarchy", "authors": ["Zhu Sun\n,", "Guibing Guo\n,", "Jie Zhang"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nAlthough flat item category structure where categories are independent in a same level has been well studied to enhance recommendation performance, in many real applications, item category is often organized in hierarchies to reflect the inherent correlations among categories. In this paper, we propose a novel matrix factorization model by exploiting category hierarchy from the perspectives of users and items for effective recommendation. Specifically, a user (an item) can be influenced (characterized) by her preferred categories (the categories it belongs to) in the hierarchy. We incorporate how different categories in the hierarchy co-influence a user and an item. Empirical results show the superiority of our approach against other counterparts.", "references": ["N. Koenigstein, G. Dror, and Y. Koren. Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy. In RecSys, 2011.", "Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, (8):30--37, 2009.", "S. Rendle. Factorization machines. In ICDM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930269"}, {"title": "RaTeR: Search Plugin supporting Temporal Operators based Information Retrieval", "authors": ["V. Uma\n,", "L. M. Nikhila\n,", "G. Aghila"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nIn this paper, a temporal search plugin, RaTeR has been implemented to support web search based on temporal operators. Traditional commercial search engines provide web search based on time. Google, the most used search engine supports search tools based on time but does not support information retrieval based on temporal relations (operators). Information retrieval based on temporal information helps in temporal ordering of events. The efficiency of the system depends on the effective representation of temporal knowledge. Temporal knowledge representation has to be unambiguous for efficient reasoning about temporal order of events. Allen's temporal relation \"before\" is ambiguous with respect to ordering as it is contextual. REseT (Reference Event based Temporal) relations reduces the ambiguity and hence facilitate better ordering of events. The architecture of RaTeR is presented and some key modules are discussed. And finally, RaTeR has been evaluated using the measures precision, fall-out and is found to be more efficient for temporal operator based web queries.", "references": ["Sato, N., Uehara, M. and Sakai, Y. 2003. Temporal information retrieval in cooperative search engine, In Proceedings 14th International Workshop on Database and Expert Systems Applications, pp. 215--220.", "Jin, P., Lian, J., Zhao, X. and Wan, S. 2008. TISE: A temporal search engine for web contents. In Second International Symposium on Intelligent Information Technology Application, IITA'08, vol. 3, pp. 220--224.", "Pasca, M. 2008. Towards temporal web search. In Proceedings of the 2008 ACM symposium on Applied computing, pp. 1117--1121."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980288"}, {"title": "Burst Detection in Social Media Streams for Tracking Interest Profiles in Real Time", "authors": ["Cody Buntain\n,", "Jimmy Lin"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis work presents RTTBurst, an end-to-end system for ingesting descriptions of user interest profiles and discovering new and relevant tweets based on those interest profiles using a simple model for identifying bursts in token usage. Our approach differs from standard retrieval-based techniques in that it primarily focuses on identifying noteworthy moments in the tweet stream, and ?summarizes? those moments using selected tweets. We lay out the architecture of RTTBurst, our participation in and performance at the TREC 2015 Microblog track, and a method for combining and potentially improving existing TREC systems. Official results and post hoc experiments show that our simple targeted burst detection technique is competitive with existing systems. Furthermore, we demonstrate that our burst detection mechanism can be used to improve the performance of other systems for the same task.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. SIGIR, 1998.", "F. Atefeh and W. Khreich. A survey of techniques for event detection in Twitter. Computational Intelligence, 31(1):132--164, 2015.", "C. Buntain, J. Lin, and J. Golbeck. Discovering Key Moments in Social Media Streams. CCNC, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914733"}, {"title": "References", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915054"}, {"title": "Computer-Supported Assessment for Tailoring Assistive Technology", "authors": ["Helena Lindgren\n,", "Jayalakshmi Baskar\n,", "Esteban Guerrero\n,", "Juan Carlos Nieves\n,", "Ingeborg Nilsson\n,", "Chunli Yan"], "publication": "DH '16: Proceedings of the 6th International Conference on Digital Health Conference", "abstract": "ABSTRACT\nThe main purpose of assistive technology is to support an individual's daily activities, in order to increase ability, autonomy, relatedness and quality of life. The aim for the work presented in this article is to develop automated methods to tailor the behavior of the assistive technology for the purpose to provide just-in-time, adaptive interventions targeting multiple domains. This requires methods for representing and updating the user model, including goals, preferences, abilities, activity and its situation. We focus the assessment and intervention tasks typically performed by therapists and provide knowledge-based technology for supporting the process. A formative evaluation study was conducted as a part of a participatory action research process, involving two rehabilitation experts, two young individuals and one senior individual as end-user participants, in addition to knowledge engineers. The main contribution of this work is a theory-based method for assessing the individual's goals, preferences, abilities and motives, which is used for building a holistic user model. The user model is continuously updated and functions as the base for tailoring the system's assistive behavior during intervention and follow-up.", "references": ["G. Andrews, R. Poulton, and G. Skoog. Lifetime risk of depression: restricted to a minority or waiting for most? The British Journal of Psychology, 187:495--496, December 2005.", "R. Annicchiarico, F. Campana, A. Federici, C. Barrué, U. Cortés, A. Villar, and C. Caltagirone. Using scenarios to draft the support of intelligent tools for frail elders in the share-it approach. In Proceedings of the 10th International Work-Conference on Artificial Neural Networks: Part I: Bio-Inspired Systems: Computational and Ambient Intelligence, IWANN '09, pages 635--641, 2009.", "J. Baskar and H. Lindgren. Towards Personalised Support for Monitoring and Improving Health in Risky Environments. In VIII Workshop on Agents Applied in Health Care (A2HC), pages 93--104, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896338.2896352"}, {"title": "Learning at Scale: Using an Evidence Hub To Make Sense of What We Know", "authors": ["Rebecca Ferguson"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nThe large datasets produced by learning at scale, and the need for ways of dealing with high learner/educator ratios, mean that MOOCs and related environments are frequently used for the deployment and development of learning analytics. Despite the current proliferation of analytics, there is as yet relatively little hard evidence of their effectiveness. The Evidence Hub developed by the Learning Analytics Community Exchange (LACE) provides a way of collating and filtering the available evidence in order to support the use of analytics and to target future studies to fill the gaps in our knowledge.", "references": ["Shane Dawson, Dragan Gašević, George Siemens and Srecko Joksimovic. 2014. Current state and future trends: a citation analysis of the learning analytics field. Proceedings of LAK 14 (Indianapolis, IN, USA), ACM, 231--240.", "Rita Kop. 2011. The challenges to connectivist learning on open online networks: learning experiences during a massive open online course. IRRODL 12, 3.", "LAK Dataset and Challenge. Retrieved January 14, 2016 from http://lak.linkededucation.org/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893419"}, {"title": "A First Study on Temporal Dynamics of Topics on the Web", "authors": ["Aécio Santos\n,", "Bruno Pasini\n,", "Juliana Freire"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWhile much work has been devoted to understanding Web dynamics and using this knowledge to efficiently maintain the freshness of the indexes of generic search engines, the same is not true for domain-specific indexes constructed by focused crawlers. For the latter, the problem is compounded by the fact that it is important not only to maintain already-crawled pages fresh, but also to identify new relevant content and expand the collection. In this paper, we discuss the challenges involved in this problem and describe our preliminary efforts in building a testbed to better understand the dynamics of specific topics and characterize how they evolve over time. We propose a data collection methodology and a set of experiments to answer important questions about temporal dynamics and evolution of topics. We also present the results of the experimental analysis we carried out using data collected over a period of four weeks using two distinct topics. These results suggest that topic-specific refreshing strategies can be beneficial for focused crawlers.", "references": ["E. Adar, J. Teevan, S. T. Dumais, and J. L. Elsas. The web changes everything: understanding the dynamics of web content. In Proceedings of the Second International Conference on Web Search and Web Data Mining, pages 282--291, 2009.", "Z. Bar-Yossef, A. Z. Broder, R. Kumar, and A. Tomkins. Sic transit gloria telae: Towards an understanding of the web's decay. In Proceedings of the 13th International Conference on World Wide Web, pages 328--337, 2004.", "L. Barbosa and J. Freire. Searching for hidden-web databases. In Proceedings of the Eight International Workshop on the Web & Databases (WebDB 2005), pages 1--6, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889291"}, {"title": "Semantics-aware Graph-based Recommender Systems Exploiting Linked Open Data", "authors": ["Cataldo Musto\n,", "Pasquale Lops\n,", "Pierpaolo Basile\n,", "Marco de Gemmis\n,", "Giovanni Semeraro"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThe ever increasing interest in semantic technologies and the availability of several open knowledge sources have fueled recent progress in the field of recommender systems. In this paper we feed recommender systems with features coming from the Linked Open Data (LOD) cloud - a huge amount of machine-readable knowledge encoded as RDF statements - with the aim of improving recommender systems effectiveness. In order to exploit the natural graph-based structure of RDF data, we study the impact of the knowledge coming from the LOD cloud on the overall performance of a graph-based recommendation algorithm. In more detail, we investigate whether the integration of LOD-based features improves the effectiveness of the algorithm and to what extent the choice of different feature selection techniques influences its performance in terms of accuracy and diversity. The experimental evaluation on two state of the art datasets shows a clear correlation between the feature selection technique and the ability of the algorithm to maximize a specific evaluation metric. Moreover, the graph-based algorithm leveraging LOD-based features is able to overcome several state of the art baselines, such as collaborative filtering and matrix factorization, thus confirming the effectiveness of the proposed approach.", "references": ["C. Aggarwal, J. Wolf, K.L. Wu, and P. Yu. Horting hatches an egg: A new graph-theoretic approach to collaborative filtering. In Proceedings of the 5th ACM SIGKDD Conference, pages 201--212. ACM, 1999.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A nucleus for a web of open data. Springer, 2007.", "P. Basile, C. Musto, M. de Gemmis, P. Lops, F. Narducci, and G. Semeraro. Aggregation strategies for linked open data-enabled recommender systems. In European Semantic Web Conference, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930249"}, {"title": "Modeling User Feedback in Dynamic Search and Browsing", "authors": ["Jiyun Luo"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNowadays searching for complicated information needs becomes more and more common. These complicated needs usually require the users to reform different queries and conduct multiple retrievals in a search session. There are a lot of technologies are developed to help session searches. Riccho, pseudo relevance feedback, and etc. can help finding relevant documents. xQuAD, RxQuAD, and etc. can help the user to explore. However none of these approaches alone works well in session searches, because they don't treat a search session as a whole. They can't answer questions like when to explore and when to exploit. In this work, we model session searches as Partially Observable Markov Decision Processes (POMDP). We model user's implicit feedbacks, such as query reformulation and user clickthrough data into the POMDP framework. Further we extend the forms of user feedbacks. We implement a new search interface which allows us to capture more explicit feedbacks from users, such as passage level relevance judgments, irrelevant judgments, duplicate judgment, and etc. We propose algorithms to effectively model these feedback signals into the POMDP framework and improve session search performance. Our algorithm is able to automatically balance users' needs of exploration and exploitation.", "references": ["C. Brandt, T. Joachims, Y. Yue, and J. Bank. Dynamic ranked retrieval. In WSDM '11.", "L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. Planning and acting in partially observable stochastic domains. Artificial intelligence, 101(1):99--134, 1998.", "J. Luo, S. Zhang, and H. Yang. Win-win search: Dual-agent stochastic game in session search. In SIGIR '14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911483"}, {"title": "Academic Coupled Dictionary Learning for Sketch-based Image Retrieval", "authors": ["Dan Xu\n,", "Xavier Alameda-Pineda\n,", "Jingkuan Song\n,", "Elisa Ricci\n,", "Nicu Sebe"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn the last few years, the query-by-visual-example paradigm gained popularity, specially for content based retrieval systems. As sketches represent a natural way of expressing a synthetic query, recent research efforts focused on developing algorithmic solutions to address the sketch-based image retrieval (SBIR) problem. Within this context, we propose a novel approach for SBIR that, unlike previous methods, is able to exploit the visual complexity inherently present in sketches and images. We introduce academic learning, a paradigm in which the sample learning order is constructed both from the data, as in self-paced learning, and from partial curricula. We propose an instantiation of this paradigm within the framework of coupled dictionary learning to address the SBIR task. We also present an efficient algorithm to learn the dictionaries and the codes, and to pace the learning combining the reconstruction error, the prior knowledge suggested by the partial curricula and the cross-domain code coherence. In order to evaluate the proposed approach, we report an extensive experimental validation showing that the proposed method outperforms the state-of-the-art in coupled dictionary learning and in SBIR on three different publicly available datasets.", "references": ["B. Alexe, T. Deselaers, and V. Ferrari. Measuring the objectness of image windows. IEEE Trans. on PAMI, 34(11):2189--2202, 2012.", "A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM J. Imag. Sciences, 2(1):183--202, 2009.", "Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964329"}, {"title": "Active learning approaches for learning regular expressions with genetic programming", "authors": ["Alberto Bartoli\n,", "Andrea De Lorenzo\n,", "Eric Medvet\n,", "Fabiano Tarlao"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nWe consider the long-standing problem of the automatic generation of regular expressions for text extraction, based solely on examples of the desired behavior. We investigate several active learning approaches in which the user annotates only one desired extraction and then merely answers extraction queries generated by the system.\nThe resulting framework is attractive because it is the system, not the user, which digs out the data in search of the samples most suitable to the specific learning task. We tailor our proposals to a state-of-the-art learner based on Genetic Programming and we assess them experimentally on a number of challenging tasks of realistic complexity. The results indicate that active learning is indeed a viable framework in this application domain and may thus significantly decrease the amount of costly annotation effort required.", "references": ["D. Angluin. Queries and concept learning. Machine learning, 2(4):319--342, 1988.", "J. Atserias, M. Simi, and H. Zaragoza. H.: Active learning for building a corpus of questions for parsing. In In: Proceedings of LREC 2010, 2010.", "R. Babbar and N. Singh. Clustering based approach to learning regular expressions over large alphabet for noisy unstructured text. In Proceedings of the Fourth Workshop on Analytics for Noisy Unstructured Text Data, AND '10, pages 43--50, New York, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851668"}, {"title": "Efficient Memory-Mapped I/O on Fast Storage Device", "authors": ["Nae Young Song\n,", "Yongseok Son\n,", "Hyuck Han\n,", "Heon Young Yeom"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nIn modern operating systems, memory-mapped I/O (mmio) is an important access method that maps a file or file-like resource to a region of memory. The mapping allows applications to access data from files through memory semantics (i.e., load/store) and it provides ease of programming. The number of applications that use mmio are increasing because memory semantics can provide better performance than file semantics (i.e., read/write). As more data are located in the main memory, the performance of applications can be enhanced owing to the effect of a large cache. When mmio is used, hot data tend to reside in the main memory and cold data are located in storage devices such as HDD and SSD; data placement in the memory hierarchy depends on the virtual memory subsystem of the operating system. Generally, the performance of storage devices has a direct impact on the performance of mmio. It is widely expected that better storage devices will lead to better performance. However, the expectation is limited when fast storage devices are used since the virtual memory subsystem does not reflect the performance feature of those devices.\nIn this article, we examine the Linux virtual memory subsystem and mmio path to determine the influence of fast storage on the existing Linux kernel. Throughout our investigation, we find that the overhead of the Linux virtual memory subsystem, negligible on the HDD, prevents applications from using the full performance of fast storage devices. To reduce the overheads and fully exploit the fast storage devices, we present several optimization techniques. We modify the Linux kernel to implement our optimization techniques and evaluate our prototyped system with low-latency storage devices. Experimental results show that our optimized mmio has up to 7x better performance than the original mmio. We also compare our system to a system that has enough memory to keep all data in the main memory. The system with insufficient memory and our mmio achieves 92% performance of the resource-rich system. This result implies that our virtual memory subsystem for mmap can effectively extend the main memory with fast storage devices.", "references": ["Nadav Amit, Dan Tsafrir, and Assaf Schuster. 2014. VSwapper: A memory swapper for virtualized environments. In Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS’14). ACM, New York, NY, 349--366. DOI:http://dx.doi.org/10.1145/2541940.2541969", "Timothy G. Armstrong, Vamsi Ponnekanti, Dhruba Borthakur, and Mark Callaghan. 2013. LinkBench: A database benchmark based on the Facebook social graph. In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD’13). ACM, New York, NY, 1185--1196. DOI:http://dx.doi.org/10.1145/2463676.2465296", "Anirudh Badam and Vivek S. Pai. 2011. SSDAlloc: Hybrid SSD/RAM memory management made easy. In Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation (NSDI’11). USENIX Association, Berkeley, CA, 16--16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2846100"}, {"title": "Array Shape Calibration for Non-planar Array Using Disjoint Sources", "authors": ["Zheng Dai\n,", "Weimin Su\n,", "Hong Gu"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nMost high resolution direction-of-arrival (DOA) estimation algorithms have good performance on the premise that the array manifold is accurately known. However, the performance degrades severely in presence of sensor positions uncertainties. In this contribution, we propose an algorithm to estimate sensor locations usingauxiliary sources. The auxiliary sources are disjoint sources, which appear independently of both space and time. First, we remove the contribution of noise from the data covariance matrix. Second, the sensor locations are estimated by solving the simultaneous equations. Third, we provide two methods, which are beneficial to engineering realization. The proposed algorithm is applicable to non-planar array. Computer simulations are presented to show the performance of the proposed algorithm.", "references": ["Schmidt, R. O. 1986. Multiple emitter location and signal parameter estimation. IEEE Trans. Antennas Propag. 34, 3 (Mar. 1986), 276--280.", "Roy, R., Paulraj, A., and Kailath T. 1986. ESPRIT-A subspace rotation approach to estimation of parameters of cisoids in noise. IEEE Trans. Acoust., Speech, Signal Process. 34,5 (Oct. 1986), 1340--1342.", "Ziskind, I., and Wax, M. 1988. Maximum likelihood localization of multiple sources by alternating projection. IEEE Trans. Acoust., Speech, Signal Process. 36, 10 (Oct. 1988), 1553--1560."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015192"}, {"title": "Scalable Compression of Deep Neural Networks", "authors": ["Xing Wang\n,", "Jie Liang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nDeep neural networks generally involve some layers with millions of parameters, making them difficult to be deployed and updated on devices with limited resources such as mobile phones and other smart embedded systems. In this paper, we propose a scalable representation of the network parameters, so that different applications can select the most suitable bit rate of the network based on their own storage constraints. Moreover, when a device needs to upgrade to a high-rate network, the existing low-rate network can be reused, and only some incremental data are needed to be downloaded. We first hierarchically quantize the weights of a pre-trained deep neural network to enforce weight sharing. Next, we adaptively select the bits assigned to each layer given the total bit budget. After that, we retrain the network to fine-tune the quantized centroids. Experimental results show that our method can achieve scalable compression with graceful degradation in the performance.", "references": ["J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. J. Mach. Learn. Res., 13:281--305, Feb. 2012.", "W. Chen, J. Wilson, S. Tyree, K. Q. Weinberger, and Y. Chen. Compressing neural networks with the hashing trick. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2285--2294. JMLR Workshop and Conference Proceedings, 2015.", "E. L. Denton, W. Zaremba, J. Bruna, Y. Lecun, and R. Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In Advances in Neural Information Processing Systems 27, pages 1269--1277. Curran Associates, Inc., 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967273"}, {"title": "Supporting Ideation by Integrating Exploratory Search, Browsing, and Curation", "authors": ["Yin Qu"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThis research integrates exploratory search, browsing, and curation in information-based ideation (IBI) environments, to support users finding, discovering, and combining web content. Information-based ideation refers to open-ended activities in which humans work to imagine, generate, and develop new problems and solutions. We use web semantics as a basis for summarizing and representing heterogeneous content from diverge sources involved in ideation tasks. To enable working with web semantics, we develop a novel type system that brings together data models, dynamic extraction, and presentation of semantic information. Based on the web semantics type system, we build interfaces that preserve contexts during exploratory browsing, and plan to build integrated interactive environments to address exploratory search, curation, and ideation. We will investigate how integrated environments affect people's practices with finding and combining information, and derive new principles for supporting exploratory search, browsing, curation, and ideation. Methods, techniques, and findings developed through this research have the potential to transform infrastructures and human experiences of the web.", "references": ["N. Belkin. Anomalous states of knowledge as a basis for information retrieval. Canadian Journal of Information and Library Science, 5:133--143, 1980.", "G. Booch et al. Object-Oriented Analysis and Design with Applications. Pearson Education, 2007.", "P. Chandler and J. Sweller. Cognitive load theory and the format of instruction. Cognition and Instruction, 8(4):293--332, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854948"}, {"title": "A Deep Relevance Matching Model for Ad-hoc Retrieval", "authors": ["Jiafeng Guo\n,", "Yixing Fan\n,", "Qingyao Ai\n,", "W. Bruce Croft"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn recent years, deep neural networks have led to exciting breakthroughs in speech recognition, computer vision, and natural language processing (NLP) tasks. However, there have been few positive results of deep models on ad-hoc retrieval tasks. This is partially due to the fact that many important characteristics of the ad-hoc retrieval task have not been well addressed in deep models yet. Typically, the ad-hoc retrieval task is formalized as a matching problem between two pieces of text in existing work using deep models, and treated equivalent to many NLP tasks such as paraphrase identification, question answering and automatic conversation. However, we argue that the ad-hoc retrieval task is mainly about relevance matching while most NLP matching tasks concern semantic matching, and there are some fundamental differences between these two matching tasks. Successful relevance matching requires proper handling of the exact matching signals, query term importance, and diverse matching requirements. In this paper, we propose a novel deep relevance matching model (DRMM) for ad-hoc retrieval. Specifically, our model employs a joint deep architecture at the query term level for relevance matching. By using matching histogram mapping, a feed forward matching network, and a term gating network, we can effectively deal with the three relevance matching factors mentioned above. Experimental results on two representative benchmark collections show that our model can significantly outperform some well-known retrieval models as well as state-of-the-art deep matching models.", "references": ["C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML, pages 89--96. ACM, 2005.", "J. P. Callan, W. B. Croft, and J. Broglio. Trec and tipster experiments with inquery. IPM, 31(3):327--343, 1995.", "G. V. Cormack, M. D. Smucker, and C. L. Clarke. Efficient and effective spam filtering and re-ranking for large web datasets. Information retrieval, 14(5):441--465, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983769"}, {"title": "Examining task relationships in multitasking consumer search sessions: a query log analysis", "authors": ["Xiang Zhou\n,", "Pengyi Zhang\n,", "Jun Wang"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nWith the advancement of the Internet, search has expanded to every aspect of our daily lives including online shopping. Previous research has discovered that the focused, one-time search task model does not apply in many real-life settings and people engage in multitasking sessions. In this poster, we examined the relationships among tasks in multitasking product search through query log analysis. We analyzed 2,910 users' 47,387 queries in 18,102 product search sessions from taobao.com, the biggest Chinese C2C e-commerce site. Results show that: (1) 35.7% of all search sessions were multi-tasking sessions; (2) users' issued more queries and spent more time in multitasking sessions, but the number of queries per task remained similar for mono-tasking and multitasking sessions; (3) about 80% of the tasks were unrelated in multitasking sessions, while the other 20% were hierarchical and sibling tasks. The results provide exploratory understanding of the relationships among multiple product search tasks, and could be useful for query recommendation and product recommendation.", "references": ["Agichtein, E., White, R. W., Dumais, S. T., & Bennet, P. N. (2012). Search, interrupted: understanding and predicting search task continuation. Paper presented at the Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, Portland, Oregon, USA.", "Feild, H., & Allan, J. (2013). Task-aware query recommendation. Paper presented at the Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, Dublin, Ireland.", "Fortune. (1998). Net profits: making the Internet work for you and your business. Technology Buyer's Guide Supplement, Summer(240--43)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017549"}, {"title": "Growing Wikipedia Across Languages via Recommendation", "authors": ["Ellery Wulczyn\n,", "Robert West\n,", "Leila Zia\n,", "Jure Leskovec"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe different Wikipedia language editions vary dramatically in how comprehensive they are. As a result, most language editions contain only a small fraction of the sum of information that exists across all Wikipedias. In this paper, we present an approach to filling gaps in article coverage across different Wikipedia editions. Our main contribution is an end-to-end system for recommending articles for creation that exist in one language but are missing in an- other. The system involves identifying missing articles, ranking the missing articles according to their importance, and recommending important missing articles to editors based on their interests. We empirically validate our models in a controlled experiment involving 12,000 French Wikipedia editors. We find that personalizing recommendations increases editor engagement by a factor of two. Moreover, recommending articles increases their chance of being created by a factor of 3.2. Finally, articles created as a result of our recommendations are of comparable quality to organically created articles. Overall, our system leads to more engaged editors and faster growth of Wikipedia with no effect on its quality.", "references": ["P. Adams and F. Fleck. Bridging the language divide in health. Bulletin of the World Health Organization, 93(6):356--366, June 2015.", "E. Adar, M. Skinner, and D. S. Weld. Information arbitrage across multi-lingual wikipedia. In WSDM, 2009.", "P. Bao, B. Hecht, S. Carton, M. Quaderi, M. Horn, and D. Gergle. Omnipedia: Bridging the wikipedia language gap. In CHI, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883077"}, {"title": "Neural network based multi-label semantic video concept detection using novel mixed-hybrid-fusion approach", "authors": ["Nitin J. Janwe\n,", "Kishor K. Bhoyar"], "publication": "ICCIP '16: Proceedings of the 2nd International Conference on Communication and Information Processing", "abstract": "ABSTRACT\nThe performance of the semantic concept detection method depends on, the selection of the low-level visual features used to represent key-frames of a shot and the selection of the feature-fusion method. This paper proposes a set of low-level visual features of considerably smaller size and also proposes novel 'hybrid-fusion' and 'mixed-hybrid-fusion' approaches which are formulated by combining contemporary early and late-fusion strategies. In the proposed hybrid-fusion approach, the features from the same feature group are combined using early-fusion before classifier training; and the concept probability scores from multiple classifiers are merged using late-fusion approach, to get final detection scores. A feature group is defined as the features from the same feature family like color moments. The hybrid-fusion approach is refined and the 'mixed-hybrid-fusion' approach is proposed additionally to further improve the detection rate. Neural Network is used to build classifiers that produce concept probabilities for a test frame. The proposed approaches are evaluated on TRECVID development dataset which contains multi-labeled key-frames. Results show that, the proposed approaches outperform early-fusion and late-fusion approaches by large margins with respect to feature set dimensionality and mean Average Precision (mAP) values.", "references": ["Zhu, Q., Lin, L., Shyu, M.L. and Liu, D. 2011. Utilizing context information to enhance content-based image classification. International Journal of Multimedia Data Engineering and Management, 2, 3, 34--51.", "Vailaya, A., Figueiredo, M.A.T., Jain, A.K. and Zhang, H.J. 2001. Image classification for content-based indexing. IEEE Transactions on Image Processing. 10, 117--130.", "Perronnin, F., Sanchez, J. and Mensink, T. 2010. Improving the fisher kernel for large-scale image classification. In 11th Eur. Conf. on Computer Vision: Part IV. 143--156."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3018009.3018052"}, {"title": "The impact of information amount on the performance of recommender systems", "authors": ["Hyun Sil Moon\n,", "Jung Hyun Yoon\n,", "Jae Kyeong Kim"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nDue to the development of the Internet and smart technology, massive amounts of data with transaction records have been generated by online and offline environments. And the proliferation of items has made it difficult for customers to find the specific items they want to buy. In order to solve this problem, many companies have adopted recommender systems to provide personalization services. However, due to the explosive growth of data, they try to use only meaningful and essential data in order to reduce these costs. And, because recommender systems necessarily deal with personal and sensitive information, some customers are concerned that their private information may be exposed by them. Based on these concerns, in this study, we analyze the effects of the amount of information on the recommendation performance. We assume that a customer could choose to provide overall information or partial information. Using two data sets which are obtained by on-line and off-line environments, we evaluate the difference in the performance of customers who provided overall information and partial information. The experimental results indicated that the recommendation performance for customers who provided overall information generally shows higher accuracy but there are some differences between on-line and off-line environments. Therefore, our study can provide some insight to companies concerning the efficient utilization of data.", "references": ["Aimeur, E., Brassard, G., Fernandez, J. M., Onana, F. S. M., & Rakowski, Z. 2008. Experimental demonstration of a hybrid privacy-preserving recommender system. In Proceedings of the Third International Conference on Availability, Reliability and Security.", "Bandara, U., & Chen, J. 2011. Ubira: a mobile platform for an integrated online/offline shopping experience. In Proceedings of the 13th international conference on Ubiquitous computing.", "Beath, C., Becerra-Fernandez, I., Ross, J., & Short, J. 2012. Finding value in the information explosion. MIT SLOAN Manage. Rev., 53, 4 (Jul. 2012), 18--20."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971609"}, {"title": "Recommendations For Streaming Data", "authors": ["Karthik Subbian\n,", "Charu Aggarwal\n,", "Kshiteesh Hegde"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRecommender systems have become increasingly popular in recent years because of the broader popularity of many web-enabled electronic commerce applications. However, most recommender systems today are designed in the context of an offline setting. The online setting is, however, much more challenging because the existing methods do not work very effectively for very large-scale systems. In many applications, it is desirable to provide real-time recommendations in large-scale scenarios. The main problem in applying streaming algorithms for recommendations is that the in-core storage space for memory-resident operations is quite limited. In this paper, we present a probabilistic neighborhood-based algorithm for performing recommendations in real-time. We present experimental results, which show the effectiveness of our approach in comparison to state-of-the-art methods.", "references": ["C. Aggarwal. Data Streams: Models and Algorithms, Springer, 2007.", "C. Aggarwal. Recommender Systems: The Textbook, Springer, 2016.", "M. Deshpande, and G. Karypis. Item-based top-n recommendation algorithms. ACM TOIS, 22(1), pp. 143--177, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983663"}, {"title": "From Footprint to Evidence: An Exploratory Study of Mining Social Data for Credit Scoring", "authors": ["Guangming Guo\n,", "Feida Zhu\n,", "Enhong Chen\n,", "Qi Liu\n,", "Le Wu\n,", "Chu Guan"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nWith the booming popularity of online social networks like Twitter and Weibo, online user footprints are accumulating rapidly on the social web. Simultaneously, the question of how to leverage the large-scale user-generated social media data for personal credit scoring comes into the sight of both researchers and practitioners. It has also become a topic of great importance and growing interest in the P2P lending industry. However, compared with traditional financial data, heterogeneous social data presents both opportunities and challenges for personal credit scoring. In this article, we seek a deep understanding of how to learn users’ credit labels from social data in a comprehensive and efficient way. Particularly, we explore the social-data-based credit scoring problem under the micro-blogging setting for its open, simple, and real-time nature. To identify credit-related evidence hidden in social data, we choose to conduct an analytical and empirical study on a large-scale dataset from Weibo, the largest and most popular tweet-style website in China. Summarizing results from existing credit scoring literature, we first propose three social-data-based credit scoring principles as guidelines for in-depth exploration. In addition, we glean six credit-related insights arising from empirical observations of the testbed dataset. Based on the proposed principles and insights, we extract prediction features mainly from three categories of users’ social data, including demographics, tweets, and networks. To harness this broad range of features, we put forward a two-tier stacking and boosting enhanced ensemble learning framework. Quantitative investigation of the extracted features shows that online social media data does have good potential in discriminating good credit users from bad. Furthermore, we perform experiments on the real-world Weibo dataset consisting of more than 7.3 million tweets and 200,000 users whose credit labels are known through our third-party partner. Experimental results show that (i) our approach achieves a roughly 0.625 AUC value with all the proposed social features as input, and (ii) our learning algorithm can outperform traditional credit scoring methods by as much as 17% for social-data-based personal credit scoring.", "references": ["William Adams, Liran Einav, and Jonathan Levin. 2007. Liquidity Constraints and Imperfect Information in Subprime Lending. Technical Report. National Bureau of Economic Research.", "Sumit Agarwal, John C. Driscoll, Xavier Gabaix, and David Laibson. 2008. Learning in the Credit Card Market. Technical Report. National Bureau of Economic Research.", "Sumit Agarwal, Paige M. Skiba, and Jeremy Tobacman. 2009. Payday Loans and Credit Cards: New Liquidity and Credit Scoring Puzzles? Technical Report. National Bureau of Economic Research."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996465"}, {"title": "Nearest Neighbour based Transformation Functions for Text Classification: A Case Study with StackOverflow", "authors": ["Piyush Arora\n,", "Debasis Ganguly\n,", "Gareth J.F. Jones"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nsignificant increase in the number of questions in question answering forums has led to the interest in text categorization methods for classifying a newly posted question as good (suitable) or bad (otherwise) for the forum. Standard text categorization approaches, e.g. multinomial Naive Bayes, are likely to be unsuitable for this classification task because of: i) the lack of sufficient informative content in the questions due to their relatively short length; and ii) considerable vocabulary overlap between the classes. To increase the robustness of this classification task, we propose to use the neighbourhood of existing questions which are similar to the newly asked question. Instead of learning the classification boundary from the questions alone, we transform each question vector into a different one in the feature space. We explore two different neighbourhood functions using: the discrete term space, the continuous vector space of real numbers obtained from vector embeddings of documents. Experiments conducted on StackOverflow data show that our approach of using the neighborhood transformation can improve classification accuracy by up to about 8%.", "references": ["P. Arora, D. Ganguly, and G. J. Jones. The good, the bad and their kins: Identifying questions with negative scores in stackoverflow. In Proc. of ASONAM '15, pages 1232--1239. ACM, 2015.", "D. Correa and A. Sureka. Chaff from the wheat: characterization and modeling of deleted questions on stack overflow. In Proceedings of WWW '14, pages 631--642, 2014.", "M. Efron, P. Organisciak, and K. Fenlon. Improving retrieval of short texts through document expansion. In Proceedings of the SIGIR '12, pages 911--920, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970426"}, {"title": "Book review: <product xlink: Type=\"simple\">morgan & claypool synthesis lectures on human language technologies, edited by graeme hirst, volume 30, 2015, xix+146 pp; paperbound, isbn 978-1-62705-388-4; ebook, isbn 978-1-62705-389-1; doi 10.2200/s00659ed1v01y201508hlt030, $55.00", "authors": ["Annie Louis"], "publication": "Computational Linguistics", "abstract": "", "references": ["Danescu-Niculescu-Mizil, Cristian, Michael Gamon, and Susan Dumais. 2011. Mark my words!: Linguistic style accommodation in social media. In Proceedings of the 20th International Conference on World Wide Web (WWW), pages 745-754, Hyderabad.", "Doyle, Gabriel. 2014. Mapping dialectal variation by querying social media. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 98-106, Gothenburg.", "Doyle, Gabriel, Dan Yurovsky, and Michael C. Frank. 2016. A robust framework for estimating linguistic alignment in twitter conversations. In Proceedings of the 25th International Conference on World Wide Web (WWW), pages 637-648, Montreal."], "doi_url": "https://dl.acm.org/doi/abs/10.1162/COLI_r_00270"}, {"title": "ArabicWeb16: A New Crawl for Today's Arabic Web", "authors": ["Reem Suwaileh\n,", "Mucahid Kutlu\n,", "Nihal Fathima\n,", "Tamer Elsayed\n,", "Matthew Lease"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb crawls provide valuable snapshots of the Web which enable a wide variety of research, be it distributional analysis to characterize Web properties or use of language, content analysis in social science, or Information Retrieval (IR) research to develop and evaluate effective search algorithms. While many English-centric Web crawls exist, existing public Arabic Web crawls are quite limited, limiting research and development. To remedy this, we present ArabicWeb16, a new public Web crawl of roughly 150M Arabic Web pages with significant coverage of dialectal Arabic as well as Modern Standard Arabic. For IR researchers, we expect ArabicWeb16 to support various research areas: ad-hoc search, question answering, filtering, cross-dialect search, dialect detection, entity search, blog search, and spam detection. Combined use with a separate Arabic Twitter dataset we are also collecting may provide further value.", "references": ["P. Bailey, N. Craswell, and D. Hawking. Engineering a multi-purpose test collection for web retrieval experiments. Information Processing & Management, 39(6):853--871, 2003.", "M. Baroni and S. Bernardini. BootCaT: Bootstrapping Corpora and Terms from the Web. In Proceedings of the Language Resources and Evaluation Conf. (LREC), 2004.", "H. Bouamor, N. Habash, and K. Oflazer. A Multidialectal Parallel Corpus of Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), pages 1240--1245, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914677"}, {"title": "Dataset linking in a multilingual linked open data context", "authors": ["Melkamu Beyene\n,", "Pierre-Edouard Portier\n,", "Solomon Atnafu\n,", "Sylvie Calabretto"], "publication": "MEDES: Proceedings of the 8th International Conference on Management of Digital EcoSystems", "abstract": "ABSTRACT\nAlthough, the syntactical and structural heterogeneities among inter-language linked open data (LOD) data sources bring many challenges, entity co-reference resolution in a multilingual linked open data (MLOD) setting is not well studied.\nIn this research, a three phase approach is proposed. First, statistical relational learning (SRL) with factorization of three way tensor is used to compute structural similarity between entities. Second, textual data from the Web of documents is associated in order to increase our knowledge of entities. Through a latent Dirichlet allocation (LDA), entities' textual data is projected into a cross-lingual topic space. This cross-lingual topic space is used to find textual similarities between entities. Third, a belief aggregation strategy is used to combine the structural and textual similarity results into a global similarity score.\nWe have shown by experiments that our algorithm out-performs state of the art approaches based on tensor decomposition for the task of entity co-reference resolution in a MLOD setting.", "references": ["Berners-Lee, T. (2010). Linked Data. W3C Design Issues, July 2006.", "de Assis Costa, G., and De Oliveira, J. M. P. (2014, October). A relational learning approach for collective entity resolution in the web of data. In Proceedings of the 5th International Conference on Consuming Linked Data-Volume 1264 (pp. 13--24). CEUR-WS. org.", "Nickel, M. (2013). Tensor factorization for relational learning (Doctoral dissertation, lmu)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012071.3012090"}, {"title": "Improved Indexing & Searching Throughput", "authors": ["Matt Crane"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nInformation retrieval is the process of finding relevant information in large corpora of documents based on user queries. Within the discipline there are a number of open research questions and areas. This thesis presents a systematic study into improving the speed of all aspects of an information retrieval system, without such improvements having an adverse effect on the effectiveness of that system.\nSeveral key areas of the indexing process were investigated: the effect of removing spam and correcting encoding errors at indexing time; the amount of parallelism and further improvements to the indexing process; the methods of vocabulary accumulation and collision resolution within a hash table; and as part of the indexing process, a new family of hash functions for information retrieval which exploit the properties of natural language was proposed.\nSearch performance was also investigated by examining the effects of the spam removal on search quality. A relationship between the size of a collection and the pre-calculation of retrieval scores was discovered.\nOverall results indicate a 30% improvement of indexing throughput. This is accompanied by a 15% increase in search quality, whilst its speed could be increased by 25% without degrading quality. The pre-calculation of retrieval scores further improves retrieval speed by up to 3--.\nThese results were compared against other open-source indexing systems by ATIRE when participating in the SIGIR 2015 RIGOR Workshop Reproducibility Challenge. The results of this challenge show that ATIRE is the fastest indexing system (taking half the time of the next best system), and the second fastest search system using the discovered relationship.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964812"}, {"title": "(The Lack of) Privacy Concerns with Sharing Web Activity at Work and the Implications for Collaborative Search", "authors": ["Scott Bateman\n,", "Carl Gutwin"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nCollaborative information seeking frequently occurs in an opportunistic and loosely-coupled fashion that is supported by awareness of others' activities on the web. Automatically sharing traces of information about web activity could substantially improve these collaborative information tasks, but conventional wisdom suggests that people are very reluctant to share information about web usage. Because work settings have different rules and practices about privacy, we carried out the first systematic study of people's privacy concerns about sharing web activity within workgroups. To provide a better understanding of privacy concerns about sharing web activity at work, we conducted a two-week diary study with 18 participants. Our study system asked participants to report on their search tasks and privacy concerns. Surprisingly, our results showed that people have little concern about sharing the majority of their activities with their work colleagues, and had even fewer concerns with sharing work-related activities. Our results provide new insights into the possibilities of sharing web activities within workgroups, and provide evidence that tools based on automatic sharing of awareness information can be feasible.", "references": ["Amershi, S. & Morris, M.R. Co-located Collaborative Web Search: Understanding Status Quo Practices. Proc. CHI, 2009, 3937--3640.", "Bateman, S., Gutwin, C., & McCalla, G. Social Navigation for Loosely-Coupled Information Seeking in Tightly-Knit Groups using WebWear. In Proc. CSCW, 2013. 955--966.", "Birnholtz, J., Gutwin, C., Hawkey, K. Privacy in the Open: How Attention Mediates Awareness and Privacy in Open-Plan Offices. In Proc. of ACM Group, 2007, 51--60."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854977"}, {"title": "From Design to Analysis: Conducting Controlled Laboratory Experiments with Users", "authors": ["Diane Kelly\n,", "Anita Crescenzi"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis full-day tutorial provides general instruction about the design of controlled laboratory experiments that are conducted in order to better understand human information interaction and retrieval. Different data collection methods and procedures are described, with an emphasis on self-report measures and scales. This tutorial also introduces the use of statistical power analysis for sample size estimation and introduces and demonstrate two data analysis procedures, Multilevel Modeling and Structural Equation Modeling, that allow for examination of the whole set of variables present in interactive information retrieval (IIR) experiments, along with their various effect sizes. The goals of the tutorial are (1) to increase participants? understanding of the uses of controlled laboratory experiments with human participants; (2) to increase participants? understanding of the technical vocabulary and procedures associated with such experiments and (2) to increase participants? confidence in conducting and evaluating IIR experiments. Ultimately, we hope our tutorial will increase research capacity and research quality in IR by providing instruction about best practices to those contemplating interactive IR experiments.", "references": ["Bausell, R. B. & Li, Y. F. (2002). Power analysis for experimental research: A practical guide for the biological, medical and social sciences. New York: Cambridge Press.", "Bollen, K. (1989). Structural equation modeling with latent variables. New York: Wiley & Sons.", "Borlund, P. (2003). The IIR evaluation model: A framework for the evaluation of interactive information retrieval systems. Information Research, 8(3), paper 152."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914809"}, {"title": "Query Variations and their Effect on Comparing Information Retrieval Systems", "authors": ["Guido Zuccon\n,", "Joao Palotti\n,", "Allan Hanbury"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe explore the implications of using query variations for evaluating information retrieval systems and how these variations should be exploited to compare system effectiveness. Current evaluation approaches consider the availability of a set of topics (information needs), and only one expression of each topic in the form of a query is used for evaluation and system comparison. While there is strong evidence that considering query variations better models the usage of retrieval systems and accounts for the important user aspect of user variability, it is unclear how to best exploit query variations for evaluating and comparing information retrieval systems.\nWe propose a framework for evaluating retrieval systems that explicitly takes into account query variations. The framework considers both the system mean effectiveness and its variance over query variations and topics, as opposed to current approaches that only consider the mean across topics or perform a topic-focused analysis of variance across systems. Furthermore, the framework extends current evaluation practice by encoding: (1) user tolerance to effectiveness variations, (2) the popularity of different query variations, and (3) the relative importance of individual topics. These extensions and our findings make information retrieval comparisons more aligned with user behaviour.", "references": ["J. A. Aslam, V. Pavlu, and R. Savell. A Unified Model for Metasearch, Pooling, and System Evaluation. In CIKM, 2003.", "P. Bailey, A. Moffat, F. Scholer, and P. Thomas. User Variability and IR System Evaluation. In SIGIR, 2015.", "P. Bailey, A. Moffat, F. Scholer, and P. Thomas. UQV: A Test Collection with Query Variability. In SIGIR, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983723"}, {"title": "Electronic Armonica: a Tangible Musical Interface inspired by the Glass Harmonica", "authors": ["Razvan Paisa\n,", "Cumhur Erkut\n,", "Stefania Serafin"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nThis paper describes the design, implementation and evaluation of a tangible musical interface inspired by the glass harmonica, and two methods for synthesizing a glass sound: additive synthesis and physical modeling using banded waveguides. These methods were implemented in Pure Data and in Max/MSP, respectively. An interface was created using laser cutting and 3D printing tools. An Arduino microcontroller is used to create a virtual capacitive sensor for detecting touch. The interface has been evaluated in order to test its playability and to evaluate the overall behavior of the system. Besides having technical limitations expected from a prototype, the results are promising.", "references": ["Badger, Paul. Arduino Playground - Capsense. 2014. http://playground.arduino.cc/Main/CapacitiveSensor?from=Main.CapSense.", "Baxter, L.K. \"Capacitive Sensors.\" IEEE, 2000.", "Bloch, Thomas. Glass Harmonica. 12 2014. http://www.thomasbloch.net/en_glassharmonica.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986434"}, {"title": "Recognizing and Releasing Drivers' Negative Emotions by Using Music: Evidence from Driver Anger", "authors": ["Yueyan Zhu\n,", "Ying Wang\n,", "Guofa Li\n,", "Xiang Guo"], "publication": "AutomotiveUI '16 Adjunct: Adjunct Proceedings of the 8th International Conference on Automotive User Interfaces and Interactive Vehicular Applications", "abstract": "ABSTRACT\nNegative emotions influence driving safety and possibly lead to traffic accidents. However, how to perceive negative emotions timely, release drivers from negative emotions and mitigate their potential harm to the roadway performance of drivers has not been discussed well. Listening to music is an effective way to influence driver emotion. Therefore, taking anger as an example, this study aims to examine the effects of music tempo and personal familiarity on releasing drivers from negative emotions and mitigating their negative effects on driving performance. Thirty drivers participated in a simulated driving experiment, and their driving performance and driver heart rate data were acquired. Data analysis are still in progress. Expected results would be that music with specific tempo or familiarity will be significantly better in mitigating anger emotion and in improving driving performance. The leverage of expected findings will be helpful for the application design of emotion perception and context music adjustment to improve driving safety.", "references": ["Mesken J., Hagenzieker P. M., Rothengatter T., and D. Waard. 2007. Frequency, determinants, and consequences of different drivers' emotions: an on-the-road study using self-reports, (observed) behaviour, and physiology. Transportation Research Part F: Traffic Psychology & Behaviour, 10, 6: 458--475.", "AAA Foundation for Traffic Safety. 2009. Aggressive Driving: Research-Update. Washington, DC: AAA Foundation for Traffic Safety", "Jeon M., and B. N. Walker. 2011. What to detect? analyzing factor structures of effect in driving contexts for an emotion detection and regulation system, in The 55th Annual Meeting of the Human Factors and Ergonomics Society, Las Vegas, Nevada."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3004323.3004344"}, {"title": "HACC: extreme scaling and performance across diverse architectures", "authors": ["Salman Habib\n,", "Vitali Morozov\n,", "Nicholas Frontiere\n,", "Hal Finkel\n,", "Adrian Pope\n,", "Katrin Heitmann\n,", "Kalyan Kumaran\n,", "Venkatram Vishwanath\n,"], "publication": "Communications of the ACM", "abstract": "Abstract\nSupercomputing is evolving toward hybrid and accelerator-based architectures with millions of cores. The Hardware/Hybrid Accelerated Cosmology Code (HACC) framework exploits this diverse landscape at the largest scales of problem size, obtaining high scalability and sustained performance. Developed to satisfy the science requirements of cosmological surveys, HACC melds particle and grid methods using a novel algorithmic structure that flexibly maps across architectures, including CPU/GPU, multi/many-core, and Blue Gene systems. In this Research Highlight, we demonstrate the success of HACC on two very different machines, the CPU/GPU system Titan and the BG/Q systems Sequoia and Mira, attaining very high levels of scalable performance. We demonstrate strong and weak scaling on Titan, obtaining up to 99.2% parallel efficiency, evolving 1.1 trillion particles. On Sequoia, we reach 13.94 PFlops (69.2% of peak) and 90% parallel efficiency on 1,572,864 cores, with 3.6 trillion particles, the largest cosmological benchmark yet performed. HACC design concepts are applicable to several other supercomputer applications.", "references": ["Bhattacharya, S., Habib, S., Heitmann, K., Vikhlinin, A. Dark matter Halo profiles of massive clusters: Theory versus observations. Astrophys. J. 766 (2013), 32.", "Bryan, G.L., Norman, M.L. In 12th Kingston Meeting on Theoretical Astrophysics, Proceedings of Meeting Held in Halifax; Nova Scotia (ASP Conference Series # 123), D.A. Clarke and M. Fall, eds. 1996; see also O'Shea, B.W., Nagamine, K., Springel, V., Hernquist, L., Norman, M.L. Astrophys. J. Supp. 160 (2005), 1.", "Couchman, H.M.P., Thomas, P.A., Pearce, F.R. Hydra: An adaptive-mesh implementation of P 3M-SPH Astrophys. J. 452, 797 (1995)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015569"}, {"title": "Multimodal and Crossmodal Representation Learning from Textual and Visual Features with Bidirectional Deep Neural Networks for Video Hyperlinking", "authors": ["Vedran Vukotić\n,", "Christian Raymond\n,", "Guillaume Gravier"], "publication": "iV&L-MM '16: Proceedings of the 2016 ACM workshop on Vision and Language Integration Meets Multimedia Fusion", "abstract": "ABSTRACT\nVideo hyperlinking represents a classical example of multimodal problems. Common approaches to such problems are early fusion of the initial modalities and crossmodal translation from one modality to the other. Recently, deep neural networks, especially deep autoencoders, have proven promising both for crossmodal translation and for early fusion via multimodal embedding. A particular architecture, bidirectional symmetrical deep neural networks, have been proven to yield improved multimodal embeddings over classical autoencoders, while also being able to perform crossmodal translation. In this work, we focus firstly at evaluating good single-modal continuous representations both for textual and for visual information. Word2Vec and paragraph vectors are evaluated for representing collections of words, such as parts of automatic transcripts and multiple visual concepts, while different deep convolutional neural networks are evaluated for directly embedding visual information, avoiding the creation of visual concepts. Secondly, we evaluate methods for multimodal fusion and crossmodal translation, with different single-modal pairs, in the task of video hyperlinking. Bidirectional (symmetrical) deep neural networks were shown to successfully tackle downsides of multimodal autoencoders and yield a superior multimodal representation. In this work, we extensively tests them in different settings, with different single-modal representations, within the context of video-hyperlinking. Our novel bidirectional symmetrical deep neural networks are compared to classical autoencoders and are shown to yield significantly improved multimodal embeddings that significantly (alpha=0.0001) outperform multimodal embeddings obtained by deep autoencoders with an absolute improvement in precision at 10 of 14.1% when embedding visual concepts and automatic transcripts and an absolute improvement of 4.3% when embedding automatic transcripts with features obtained with very deep convolutional neural networks, yielding 80% of precision at 10.", "references": ["M. Campr and K. Je\\vzek. Comparing semantic models for evaluating automatic document summarization. In Text, Speech, and Dialogue, 2015.", "M. Cha, Y. Gwon, and H. T. Kung. Multimodal sparse representation learning and applications. CoRR, abs/1511.06238, 2015.", "F. Feng, X. Wang, and R. Li. Cross-modal retrieval with correspondence autoencoder. In ACM Intl. Conf. on Multimedia, pages 7--16, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983563.2983567"}, {"title": "Dissertation Research Problems in Data Management and Related Areas", "authors": ["Gerard de Melo\n,", "Mouna Kacimi\n,", "Aparna S. Varde"], "publication": "ACM SIGMOD Record", "abstract": "Abstract\nDatabases and related fields such as Information Retrieval, Data Mining and Knowledge Management offer many topics of interest for dissertation research. Specific areas include, for instance, big data, social networks, Web question answering and interactive knowledge discovery. In this article, we provide a summary and critique of research problems presented in these and related areas at a workshop on dissertation proposals and early doctoral research.", "references": ["Gerard de Melo, Mouna Kacimi, Aparna S. Varde (Eds.): Proceedings of the 7th Workshop on Ph.D Students, PIKM at CIKM 2014, Shanghai, China, November 3, 2014. ACM, ISBN 978-1-4503-1481.", "Lin Chen, Richi Nayak. Leveraging the network information for evaluating answer quality in a collaborative question answering portal. Social Network Analysis and Mining 2(3), pp. 197-215, Springer, 2012.", "Abhishek Mukherji, Elke A. Rundensteiner, and Matthew O. Ward. COLARM: Cost-based optimization for localized association rule mining. In Proceedings of EDBT, pages 181--192, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2935694.2935707"}, {"title": "Question Answering with Knowledge Base, Web and Beyond", "authors": ["Wen-tau Yih\n,", "Hao Ma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this tutorial, we give the audience a coherent overview of the research of question answering (QA). We first introduce a variety of QA problems proposed by pioneer researchers and briefly describe the early efforts. By contrasting with the current research trend in this domain, the audience can easily comprehend what technical problems remain challenging and what the main breakthroughs and opportunities are during the past half century. For the rest of the tutorial, we select three categories of the QA problems that have recently attracted a great deal of attention in the research community, and present the tasks with the latest technical survey. We conclude the tutorial by discussing the new opportunities and future directions of QA research.", "references": ["J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on freebase from question-answer pairs. In EMNLP, pages 1533--1544, 2013.", "J. Berant and P. Liang. Semantic parsing via paraphrasing. In Proceedings of ACL, 2014.", "E. Brill, S. Dumais, and M. Banko. An analysis of the askmsr question-answering system. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 257--264. Association for Computational Linguistics, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914804"}, {"title": "Real-time Tweet Classification in Disaster Situation", "authors": ["Fujio Toriumi\n,", "Seigo Baba"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nDuring a disaster, appropriate information must be collected quickly. For example, residents along the coast require information about tsunamis and those who have lost their houses need information about shelters. Twitter can attract more attention than other forms of mass media under these circumstances because it can quickly provide such information. Since Twitter has an enormous amount of tweets, they must be classified to provide users with the information they need. Previous works on extracting information from Twitter focused on the text data of tweets. However, in some cases, text mining has difficulty extracting information. For example, it might be difficult for text mining to group tweets with URLs. On the other hand, by assuming that users who retweet the same tweet are interested in the same topic, we can classify tweets that are required by users with similar interests based on retweets. Thus, we employ the tweet classification method that focuses on retweets. In this paper, we demonstrated that our method works quickly in disaster situations and that it can quickly classify the required information based on the needs in disaster situations and is helpful for collecting information under them.", "references": ["S. Baba, F. Toriumi, T. Sakaki, K. Shinoda, S. Kurihara, K. Kazama, and I. Noda. Classification method for shared information on twitter without text data. In Proceedings of the 24th International Conference on World Wide Web Companion, pages 1173--1178. International World Wide Web Conferences Steering Committee, 2015.", "A. Clauset, M. E. J. Newman, , and C. Moore. Finding community structure in very large networks. Physical Review E, pages 1-- 6, 2004.", "A. García-Silva, J.-H. Kang, K. Lerman, and O. Corcho. Characterising emergent semantics in twitter lists. In Proceedings of the 9th International Conference on The Semantic Web: Research and Applications, ESWC'12, pages 530--544, Berlin, Heidelberg, 2012. Springer-Verlag."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889365"}, {"title": "An eye-tracking study of web search interaction design patterns", "authors": ["Dimitra Dimitrakopoulou\n,", "Evanthia Faliagka\n,", "Maria Rigou"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nThe term 'design pattern' was initially introduced in the architectural field and passed into computer science via software engineering. The idea also grew in the HCI domain in the form of interaction design (ID) patterns, which outline common UI design problems along with suggested solution(s) based on theory, good practice and perceivable interaction behavior. In this paper, a study is presented that focuses on how web users perceive and use available interaction design patterns when they search for specific information on specific sites. To this end, a set of testing scenarios were designed and users were monitored using eye-tracking, a method that collects rich data and allows for detailed study of user visual behavior, apart from navigational actions. The paper concludes on how successfully patterns have been deployed and which are the patterns users seem to prefer.", "references": ["Alexander, C. 1964. Notes on the Synthesis of Form. Harvard University Press.", "Pauwels, S.L., Husbscher, C., Bargas-Avila, J., and Opwis K. 2010. Building an interaction design pattern language: A case study. Computers in Human Behavior, 26, 3, 452-463 {Online} Available: http://chuebscher.ch/papers/pdf/2010-Building_a_pattern_language.pdf", "C. Alexander, S. Ishikawa, and M. Silverstein (1977). A Pattern Language. Oxford University Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003795"}, {"title": "Smart filters for social retrieval", "authors": ["Balaji Vasan Srinivasan\n,", "Tanya Goyal\n,", "Nikhil Mohan Nainani\n,", "Kartik Sreenivasan"], "publication": "CODS '16: Proceedings of the 3rd IKDD Conference on Data Science, 2016", "abstract": "ABSTRACT\nSocial media platform are increasingly becoming a rich source of information for capturing the views and opinions of online customers. Major brands listen to the social streams to understand the general pulse of their online community. The foremost task here is to construct a \"filter\" to fetch the brand-relevant data from the social streams. Due to the nature of social platforms, simple filters/queries for retrieval yield a lot of noise leading to a need for complicated filters. Constructing such complicated filters is a non-trivial task and requires significant time-investment from a social marketer. In this paper, we propose a method to automate this task by expanding a seed set of watch keywords to maximize the number of retrieved relevant social feeds around the brand and combining them appropriately into a social query. We show the strengths and weaknesses of the proposed approach in the light of real-world social feeds for various brands.", "references": ["A. Bandyopadhyay, K. Ghosh, P. Majumder, and M. Mitra. Query expansion for microblog retrieval. International Journal of Web Science, 2012.", "M. Efron. Hashtag retrieval in a microblogging environment. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 787--788. ACM, 2010.", "J. A. Rodriguez Perez and J. M. Jose. Predicting query performance in microblog retrieval. In 37th International ACM SIGIR Conference on Research & Development in Information Retrieval. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2888451.2888457"}, {"title": "Powering Content Discovery through Scalable, Realtime Profiling of Users' Content Preferences", "authors": ["Ido Tamir\n,", "Roy Bass\n,", "Guy Kobrinsky\n,", "Baruch Brutman\n,", "Ronny Lempel\n,", "Yoram Dayagi"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nOutbrain is the Web's leading content discovery service, recommending billions of stories daily to a global audience across many of the world's most prestigious and respected publishers. Outbrain's recommendation technology com- bines contextual cues with personalization, where the per- sonalization aspects are a combination of content-based and collaborative filtering techniques. This paper, and the accompanying demo, offer a behind- the-scenes view of the content-based aspects of Outbrain's personalization technology. We detail the types of features we extract from content, as well as the attributes we keep in each user's content-affinity profile. We then describe and demonstrate how we update each user's profile, in real time, as the user consumes content while browsing the Web.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry. Commun. ACM, 35(12):61--70, Dec. 1992.", "J. Herlocker, J. Konstan, and J. Riedl. An empirical analysis of design choices in neighborhood-based collaborative filtering algorithms. Information Retrieval, 5(4):287--310, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959111"}, {"title": "A Dynamic Recurrent Model for Next Basket Recommendation", "authors": ["Feng Yu\n,", "Qiang Liu\n,", "Shu Wu\n,", "Liang Wang\n,", "Tieniu Tan"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNext basket recommendation becomes an increasing concern. Most conventional models explore either sequential transaction features or general interests of users. Further, some works treat users' general interests and sequential behaviors as two totally divided matters, and then combine them in some way for next basket recommendation. Moreover, the state-of-the-art models are based on the assumption of Markov Chains (MC), which only capture local sequential features between two adjacent baskets. In this work, we propose a novel model, Dynamic REcurrent bAsket Model (DREAM), based on Recurrent Neural Network (RNN). DREAM not only learns a dynamic representation of a user but also captures global sequential features among baskets. The dynamic representation of a specific user can reveal user's dynamic interests at different time, and the global sequential features reflect interactions of all baskets of the user over time. Experiment results on two public datasets indicate that DREAM is more effective than the state-of-the-art models for next basket recommendation.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 17(6):734--749, 2005.", "S. Chen, J. L. Moore, D. Turnbull, and T. Joachims. Playlist prediction via metric embedding. In SIGKDD, pages 714--722, 2012.", "A. Gatzioura and M. Sanchez-Marre. A case-based recommendation approach for market basket data. IEEE Intelligent Systems, 30(1):20--27, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914683"}, {"title": "Domain-specific cross-language relevant question retrieval", "authors": ["Bowen Xu\n,", "Zhenchang Xing\n,", "Xin Xia\n,", "David Lo\n,", "Qingye Wang\n,", "Shanping Li"], "publication": "MSR '16: Proceedings of the 13th International Conference on Mining Software Repositories", "abstract": "ABSTRACT\nIn software development process, developers often seek solutions to the technical problems they encounter by searching relevant questions on Q&A sites. When developers fail to find solutions on Q&A sites in their native language (e.g., Chinese), they could translate their query and search on the Q&A sites in another language (e.g., English). However, developers who are non-native English speakers often are not comfortable to ask or search questions in English, as they do not know the proper translation of the Chinese technical words into the English technical words. Furthermore, the process of manually formulating cross-language queries and determining the weight of query words is a tedious and time-consuming process.\nFor the purpose of helping Chinese developers take advantage of the rich knowledge base of the English version of Stack Overflow and simplify the retrieval process, we propose an automated cross-language relevant question retrieval (CLRQR) system to retrieve relevant English questions on Stack Overflow for a given Chinese question. Our CLRQR system first extracts essential information (both Chinese and English) from the title and description of the input Chinese question, then performs domain-specific translation of the essential Chinese information into English, and formulates a query with highest-scored English words for retrieving relevant questions in a repository of 684,599 Java questions in English from Stack Overflow. To evaluate the performance of our proposed approach, we also propose four online retrieval approaches as baselines. We randomly select 80 Java questions in SegmentFault and V2EX (two Chinese Q&A websites for computer programming) as the query Chinese questions. Each approach returns top-10 most relevant questions for a given Chinese question. We invite 5 users to evaluate the relevance of the retrieved English questions. The experiment results show that CLRQR system outperforms the four baseline approaches, and the statistical tests show the improvements are significant.", "references": ["Ictclasnlp. Available at http://ictclas.nlpir.org/docs, 2015.", "Stackoverflow developer survey. http://StackOverflow.com/research/developer-survey-2015, 2015.", "R. M. Aceves-Pérez, M. Montes-y Gómez, and L. Villaseñor-Pineda. Enhancing cross-language question answering by combining multiple question translations. In Computational Linguistics and Intelligent Text Processing, pages 485--193. Springer, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901739.2901746"}, {"title": "SiAPP: An Information System for Crime Analytics Based on Logical Relational Learning", "authors": ["Vitor Lourenco\n,", "Paulo Mann\n,", "Aline Paes\n,", "Daniel Oliveira"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe growing of criminality in Brazilian cities is a common theme addressed by media as well as by the legal authorities. To effectively reduce the criminality, people and infrastructure must be carefully involved to not only punish who had committed crimes, but also predict and prevent it. Since acquiring official data about crimes is far from trivial, citizens have become important data sources through Web-based collaborative systems. These systems provide a huge volume of data that has to be analyzed. How to analyze this volume of data and identify patterns in crimes is an important, yet open, issue. Thus, this work presents a system called SiAPP. Its main objective is to support the analysis and prediction of crime patterns using a machine learning algorithm. SiAPP automatically acquires data from collaborative sources, generate logical rules and visualizes the found patterns. Experimental analysis shows that SiAPP is a promising solution tool to assist crimes prevention.", "references": ["Felipe, \"Tendencias criminais sul-americanas em perspectiva comparada,\" Revista Brasileira de Seguranca Publica", "ISP, Instituto de Seguranca Publica do Rio de Janeiro, http://www.isp.rj.gov.br/..", "M. Marathe, \"Resilient Cities and Urban Analytics: The Role of Big Data and High Performance Pervasive Computing,\" in Proceedings of the 2Nd IKDD Conference on Data Sciences, New York, NY, USA, 2015, pp. 4:1-4:1."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021984"}, {"title": "People Recommendation Tutorial", "authors": ["Ido Guy\n,", "Luiz Pizzato"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPeople recommenders have become a rich research area within the broad recommender systems community and social recommender systems in particular. From \"people you may know\" and \"who to follow\" widgets, through people introduction at conferences, job recommendations and job-candidate search, to dating partner matchmakers, people recommendations proliferate. This tutorial will present an overview of the people recommender systems domain. We will present the different types and use cases of people recommendations, the special techniques used to recommend people to themselves, key research work, and open challenges.", "references": ["J. Chen, W. Geyer, C. Dugan, M. Muller, and I. Guy. Make new friends, but keep the old: recommending people on social networking sites. In PROC. CHI, pages 201--210, 2009.", "J. Freyne, M. Jacovi, I. Guy, and W. Geyer. Increasing engagement through early recommender intervention. In Proc. RecSys, pages 85--92, 2009.", "Y. Gong, Q. Zhang, X. Sun, and X. Huang. Who will you \"@\"? In Proc. CIKM, pages 533--542, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959196"}, {"title": "Build Emotion Lexicon from the Mood of Crowd via Topic-Assisted Joint Non-negative Matrix Factorization", "authors": ["Kaisong Song\n,", "Wei Gao\n,", "Ling Chen\n,", "Shi Feng\n,", "Daling Wang\n,", "Chengqi Zhang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn the research of building emotion lexicons, we witness the exploitation of crowd-sourced affective annotation given by readers of online news articles. Such approach ignores the relationship between topics and emotion expressions which are often closely correlated. We build an emotion lexicon by developing a novel joint non-negative matrix factorization model which not only incorporates crowd-annotated emotion labels of articles but also generates the lexicon using the topic-specific matrices obtained from the factorization process. We evaluate our lexicon via emotion classification on both benchmark and built-in-house datasets. Results demonstrate the high-quality of our lexicon.", "references": ["S. Baccianella, A. Esuli, and F. Sebastiani. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC, pages 2200--2204, 2010.", "C. H. Q. Ding, T. Li, W. Peng, and H. Park. Orthogonal nonnegative matrix t-factorizations for clustering. In SIGKDD, pages 126--135, 2006.", "S. Feng, K. Song, D. Wang, and G. Yu. A word-emoticon mutual reinforcement ranking model for building sentiment lexicon from massive collection of microblogs. World Wide Web, 18(4):949--967, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914759"}, {"title": "A Weighted Question Retrieval Model using Descriptive Information in Community Question Answering", "authors": ["Beomseok Hong\n,", "Yanggon Kim"], "publication": "RACS '16: Proceedings of the International Conference on Research in Adaptive and Convergent Systems", "abstract": "ABSTRACT\nCommunity Question Answering (CQA) sites such as Yahoo! Answers and Stack Overflow, are knowledge sharing platforms that allow users to post questions and answer questions asked by other users. One of the characteristics of CQA is a time lag between questions and answers. To reduce the time lag between them, various approaches have been suggested such as question retrieval and question routing. In this paper we propose a weighted question retrieval model that uses question titles, question descriptions, and their relationship for calculating question similarity in large-scale CQA archives. From the experiment our weighted question retrieval model outperforms the baseline that uses only question titles, and we found that exploiting the question descriptions increases the ranks of the relevant questions while reducing the recalls of them as compared with the baseline.", "references": ["V. Bhat, A. Gokhale, R. Jadhav, J. Pudipeddi, and L. Akoglu. Min(e)d your tags: Analysis of question response time in stackoverflow. In IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, August 2014.", "L. Cai, G. Zhou, K. Liu, and J. Zhao. Learning the latent topics for question retrieval in community qa. In Proceedings of the 5th International Joint Conference on Natural Language Processing, November 2011.", "J. Jeon, W. B. Croft, and J. H. Lee. Finding similar questions in large question and answer archives. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, November 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987386.2987434"}, {"title": "Behavioural role analysis for multi-faceted communication campaigns in Twitter", "authors": ["Paraskevi Lazaridou\n,", "Athanasia Ntalla\n,", "Jasminko Novak"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nThis paper describes a method for identifying and characterizing different types of behavioural roles of Twitter users that can support communication campaigns in a more fine-grained way than the influencer-based approaches, addressing different types of users. We apply the method to an experimental dataset and discuss how the results can support multi-faceted campaigns.", "references": ["Beguerisse-Díaz, M. et al. 2014. Interest communities and flow roles in directed networks: the Twitter network of the UK riots. J. R. Soc. Interface, 11, (2014), 101.", "Cha, M., Haddadi, H., Benevenuto, F., and Gummadi, K. P. 2010. Measuring user influence in Twitter: the million follower fallacy. In ICWSM, 10, 10--17 (2010), 30.", "Pal, A., and Counts, S. 2011. Identifying topical authorities in microblogs. In WSDM'11. (Hong Kong, China), 45--54."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908202"}, {"title": "A Layer for the Mapping Management of SQL DML Instructions to the Key-Value NoSQL Database Voldemort", "authors": ["Augusto Verzbickas Costa\n,", "Patricia Vilain\n,", "Ronaldo Santos Mello"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nInformation systems that uses relational databases for data maintenance are increasingly migrating to cloud databases in order to minimize costs related to the management of huge data volumes. In this context, NoSQL databases are good options, in particular, the key-value databases, which present a simple data model and scalable solutions. Even that, the costs regarding the migration to a NoSQL data management may be high, mainly in terms of source code updating of the information system for adapting database access interfaces. This paper presents VoldemortSQL, a layer that maps SQL DML instructions to the access methods of the NoSQL key-value database Voldemort with the purpose of avoiding the laborious work with data and access interface migrations from a relational database to Voldemort. The usage of this layer allows the manipulation of data in the cloud through the continuous usage of the SQL standard. An experimental evaluation had demonstrated that the overhead introduced with the layer is not prohibitive", "references": ["Tiwari, S. Professional NoSQL. Wrox, 2011.", "Sadalage, P. J. and Fowler, M. NoSQL Distilled. AddisonWesley Professional, 2012.", "Planet Cassandra. What is NoSQL. Disponivel em: http://www.planetcassandra.org/what-is-nosql/. ultimo acesso em 28/02/2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021993"}, {"title": "Weighted Linear Fusion of Multimodal Data: A Reasonable Baseline?", "authors": ["Ognjen Arandjelovic"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe ever-increasing demand for reliable inference capable of handling unpredictable challenges of practical application in the real world, has made research on information fusion of major importance. There are few fields of application and research where this is more evident than in the sphere of multimedia which by its very nature inherently involves the use of multiple modalities, be it for learning, prediction, or human-computer interaction, say. In the development of the most common type, score-level fusion algorithms, it is virtually without an exception desirable to have as a reference starting point a simple and universally sound baseline benchmark which newly developed approaches can be compared to. One of the most pervasively used methods is that of weighted linear fusion. It has cemented itself as the default off-the-shelf baseline owing to its simplicity of implementation, interpretability, and surprisingly competitive performance across a wide range of application domains and information source types. In this paper I argue that despite this track record, weighted linear fusion is not a good baseline on the grounds that there is an equally simple and interpretable alternative - namely quadratic mean-based fusion - which is theoretically more principled and which is more successful in practice. I argue the former from first principles and demonstrate the latter using a series of experiments on a diverse set of fusion problems: computer vision-based object recognition, arrhythmia detection, and fatality prediction in motor vehicle accidents.", "references": ["G. Aggarwal and D. Roth. Learning a sparse representation for object detection. In Proc. European Conference on Computer Vision, 2002.", "A. Ahmadyfard and J. Kittler. A comparative study of two object recognition methods. In Proc. British Machine Vision Conference, pages 1--10, 2002.", "O. Arandjelović. Matching objects across the textured--smooth continuum. In Proc. Australasian Conference on Robotics and Automation, pages 354--361, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964304"}, {"title": "Dystemo: Distant Supervision Method for Multi-Category Emotion Recognition in Tweets", "authors": ["Valentina Sintsova\n,", "Pearl Pu"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nEmotion recognition in text has become an important research objective. It involves building classifiers capable of detecting human emotions for a specific application, for example, analyzing reactions to product launches, monitoring emotions at sports events, or discerning opinions in political debates. Most successful approaches rely heavily on costly manual annotation. To alleviate this burden, we propose a distant supervision method—Dystemo—for automatically producing emotion classifiers from tweets labeled using existing or easy-to-produce emotion lexicons. The goal is to obtain emotion classifiers that work more accurately for specific applications than available emotion lexicons. The success of this method depends mainly on a novel classifier—Balanced Weighted Voting (BWV)—designed to overcome the imbalance in emotion distribution in the initial dataset, and on novel heuristics for detecting neutral tweets. We demonstrate how Dystemo works using Twitter data about sports events, a fine-grained 20-category emotion model, and three different initial emotion lexicons. Through a series of carefully designed experiments, we confirm that Dystemo is effective both in extending initial emotion lexicons of small coverage to find correctly more emotional tweets and in correcting emotion lexicons of low accuracy to perform more accurately.", "references": ["Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing. ACL, 579--586.", "Saima Aman and Stan Szpakowicz. 2007. Identifying expressions of emotion in text. In Text, Speech and Dialogue. Springer, 196--205.", "Gustavo E. A. P. A. Batista, Ronaldo C. Prati, and Maria Carolina Monard. 2004. A study of the behavior of several methods for balancing machine learning training data. ACM SIGKDD Explorations Newsletter 6, 1 (2004), 20--29."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2912147"}, {"title": "Considering Supplier Relations and Monetization in Designing Recommendation Systems", "authors": ["Jan Krasnodebski\n,", "John Dines"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nE-commerce merchants need to optimize their recommendations and sort listings on multi-dimensional requirements beyond product attributes to include supplier considerations, long-term customer experience and the value of the sale to achieve long term success. Product recommendations for optimizing customer conversion can be modeled effectively with predictive analytic methodologies. However, supplier and customer experience elements are not easily modeled in the same manner. This paper outlines an algorithmic approach for these considerations from Expedia's experiences.", "references": ["Fuchs, M. and Zanker M. 2012 Multi-criteria ratings for recommender systems: An empirical analysis in the tourism domain. In C. Huemer and P. Lops, editors, E-Commerce and Web Technologies, volume 123 of Lecture Notes in Business Information Processing, pages 100--111. Springer Berlin Heidelberg.", "Joachims, T. 2002 Optimizing search engines using click-through data. Proceedings of the eighth ACM SIGKDD international conference on knowledge discovery and data mining, pages 133--142. ACM, NY.", "Ebay, http://pages.ebay.com/help/sell/searchstanding.html"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959124"}, {"title": "Semantic Matching by Non-Linear Word Transportation for Information Retrieval", "authors": ["Jiafeng Guo\n,", "Yixing Fan\n,", "Qingyao Ai\n,", "W. Bruce Croft"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA common limitation of many information retrieval (IR) models is that relevance scores are solely based on exact (i.e., syntactic) matching of words in queries and documents under the simple Bag-of-Words (BoW) representation. This not only leads to the well-known vocabulary mismatch problem, but also does not allow semantically related words to contribute to the relevance score. Recent advances in word embedding have shown that semantic representations for words can be efficiently learned by distributional models. A natural generalization is then to represent both queries and documents as Bag-of-Word-Embeddings (BoWE), which provides a better foundation for semantic matching than BoW. Based on this representation, we introduce a novel retrieval model by viewing the matching between queries and documents as a non-linear word transportation (NWT) problem. With this formulation, we define the capacity and profit of a transportation model designed for the IR task. We show that this transportation problem can be efficiently solved via pruning and indexing strategies. Experimental results on several representative benchmark datasets show that our model can outperform many state-of-the-art retrieval models as well as recently introduced word embedding-based models. We also conducted extensive experiments to analyze the effect of different settings on our semantic matching model.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM TOIS, 20(4):357--389, 2002.", "A. Atreya and C. Elkan. Latent semantic indexing (LSI) fails for TREC collections. ACM SIGKDD Explorations Newsletter, 12(2):5--10, 2011.", "A. Berger and J. Lafferty. Information retrieval as statistical translation. In SIGIR, pages 222--229. ACM, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983768"}, {"title": "Can Disputed Topic Suggestion Enhance User Consideration of Information Credibility in Web Search?", "authors": ["Yusuke Yamamoto\n,", "Satoshi Shimada"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nDuring web search and browsing, people often accept misinformation due to their inattention to information credibility and biases. To obtain correct web information and support effective decision making, it is important to enhance searcher credibility assessment and develop algorithms to detect suspicious information. In this paper, we investigate how credibility alarms for web search results affect searcher behavior and decision making in information access systems. This study focuses on disputed topic suggestion as a credibility alarm approach. We conducted an online user study in which 92 participants performed a search task for health information. Through log analysis and user surveys, we confirmed the following. (1) Disputed topic suggestion in a search results list makes participants spend more time browsing pages than ordinary search conditions, thereby promoting careful information seeking. (2) Disputed topic suggestion during web browsing does not change participant behaviors but works as complementary information. This study contributes to system designs to enhance user engagement in critical and careful information seeking.", "references": ["B. T. Adler and L. de Alfaro. A Content-Driven Reputation System for the Wikipedia. In Proceedings of the 16th International Conference on World Wide Web (WWW 2007), pages 261--270, 2007.", "S. Akamine, D. Kawahara, Y. Kato, T. Nakagawa, K. Inui, S. Kurohashi, and Y. Kidawara. Wisdom: A web information credibility analysis system. In Proceedings of the ACL-IJCNLP Software Demonstrations (ACLDemos 2009), pages 1--4, 2009.", "C. Castillo, M. Mendoza, and B. Poblete. Information Credibility on Twitter. In Proceedings of the 20th International Conference on World Wide Web (WWW 2011), pages 675--684, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914592"}, {"title": "Investigations on Rating Computer Sciences Conferences: An Experiment with the Microsoft Academic Graph Dataset", "authors": ["Suhendry Effendy\n,", "Roland H.C. Yap"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe rating of Computer Science (CS) conferences are important as it influences how papers published at the conferences and may also be used to evaluate research. In this paper, we proposed a method, \\rsit{}, based on a small given set of top conference ({\\em pivots}) and a relatedness measure based this set as well as basic baseline methods using citation count and field rating. We experimented with a snapshot dataset from Microsoft Academic Graph together with conference data from Microsoft Academic Search. We evaluated the conference ratings from our methods with the CCF conference rating list. We showed that \\rsit{} correlates well with CCF rating and correlates better than ratings from using a baseline ranking with citation count or field rating.", "references": ["A. Barabási, H. Jeong, Z. Néda, E. Ravasz, A. Schubert, and T. Vicsek. Evolution of the social network of scientific collaborations. In SIGKDD, 2006.", "C. Bird, E. Barr, A. Nash, P. Devanbu, V. Filkov, and Z. Su. Structure and dynamics of research collaboration in computer science. In SDM, 2009.", "M. Biryukov and C. Dong. Analysis of computer science communities based on DBLP. In ECDL, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890525"}, {"title": "Towards Better Understanding of Academic Search", "authors": ["Madian Khabsa\n,", "Zhaohui Wu\n,", "C. Lee Giles"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nAcademics have relied heavily on search engines to identify and locate research manuscripts that are related to their research areas. Many of the early information retrieval sys- tems and technologies were developed while catering for li- brarians to help them sift through books and proceedings, followed by recent online academic search engines such as Google Scholar and Microsoft Academic Search. In spite of their popularity among academics and importance to academia, the usage, query behaviors, and retrieval models for aca- demic search engines have not been well studied. To this end, we study the distribution of queries that are received by an academic search engine. Furthermore, we delve deeper into academic search queries and classify them into navigational and informational queries. This work in- troduces a definition for navigational queries in academic search engines under which a query is considered naviga- tional if the user is searching for a specific paper or docu- ment. We describe multiple facets of navigational academic queries, and introduce a machine learning approach with a set of features to identify such queries.", "references": ["R. Baeza-Yates, L. Calderón-Benavides, and C. González-Caro. The intention behind web queries. In String processing and information retrieval, pages 98--109. Springer, 2006.", "A. Broder. A taxonomy of web search. In ACM Sigir forum, volume 36, pages 3--10. ACM, 2002.", "C. L. Giles, K. D. Bollacker, and S. Lawrence. Citeseer: An automatic citation indexing system. In Proceedings of the third ACM conference on Digital libraries, pages 89--98. ACM, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910922"}, {"title": "A feature terms extraction method based on polarity analysis of customer reviews for content-based recommendation", "authors": ["Tomofumi Yoshida\n,", "Daisuke Kitayama"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nOur paper proposes a method for extracting feature terms expressing feelings regarding the use of a product from customer reviews on e-commerce sites, based on content-based recommendation. Considering previous research indicating that negative events and impressions have a greater impact than positive ones, we define terms relating to factors over which customers argue the pros and cons in reviews as features related to feelings regarding the use of a product.\nOur approach involves extracting sentences expressing opinions from customer reviews, and recognizing each evaluated term as a candidate for product features. Using the positive opinion ratio of each candidate to measure the extent of how divided the opinions of reviewers are, we extract feature terms for the selected product by considering a feature score based on the positive opinion ratio. We present an experiment to evaluate the utility of the feature terms extracted using our proposed method.", "references": ["R. F. Baumeister, E. Bratslavsky, C. Finkenauer, and K. D. Vohs. Bad is stronger than good. Review of General Psychology, 5(4):323--370, 2001.", "L. Bing, T.-L. Wong, and W. Lam. Unsupervised extraction of popular product attributes from e-commerce web sites by considering customer reviews. ACM Trans. Internet Technol., 16(2):12:1--12:17, Apr. 2016.", "S. Hariharan, R. Srimathi, M. Sivasubramanian, and S. Pavithra. Opinion mining and summarization of reviews in web forums. In Proceedings of the Third Annual ACM Bangalore Conference, COMPUTE '10, pages 24:1--24:4, New York, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011193"}, {"title": "Monitoring top-k on real-time dynamic social-network graphs", "authors": ["Kamalas Udomlamlert\n,", "Cosmas Krisna Adiputra\n,", "Takahiro Hara"], "publication": "DEBS '16: Proceedings of the 10th ACM International Conference on Distributed and Event-based Systems", "abstract": "ABSTRACT\nThis paper presents our solution to 2016 DEBS Grand Challenge. We proposed our original program to efficiently calculate 2 continuous top-k queries on real-time social-network graph data. Our implementation tried to prevent processing of unaffected events by designing the algorithms to efficiently maintain the spare list of candidates of the top-k results. In addition, we improved the efficiency of the state-of-the-art algorithms to speed up the processing of the queries.", "references": ["V. Gulisano, Z. Jerzak, S. Voulgaris, and H. Ziekow. The DEBS 2016 Grand Challenge. In DEBS. ACM, 2016.", "P. Prosser. Exact algorithms for maximum clique: A computational study. Algorithms, 5(4):545--587, 2012.", "E. Tomita, Y. Sutani, T. Higashi, S. Takahashi, and M. Wakatsuki. A simple and faster branch-and-bound algorithm for finding a maximum clique. In WALCOM: Algorithms and computation, pages 191--203. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933267.2933510"}, {"title": "Query Expansion Using Word Embeddings", "authors": ["Saar Kuzi\n,", "Anna Shtok\n,", "Oren Kurland"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe present a suite of query expansion methods that are based on word embeddings. Using Word2Vec's CBOW embedding approach, applied over the entire corpus on which search is performed, we select terms that are semantically related to the query. Our methods either use the terms to expand the original query or integrate them with the effective pseudo-feedback-based relevance model. In the former case, retrieval performance is significantly better than that of using only the query, and in the latter case the performance is significantly better than that of the relevance model.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. UMASS at TREC 2004 -- novelty and hard. In Proc. of TREC-13, 2004.", "Q. Ai, L. Yang, J. Guo, and W. B. Croft. Improving language estimation with the paragraph vector model for ad-hoc retrieval. In Proc. of SIGIR, pages 869--872. ACM, 2016.", "M. Almasri, C. Berrut, and J. Chevallet. A comparison of deep learning based query expansion with pseudo-relevance feedback and mutual information. Proc. of ECIR, pages 709--715, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983876"}, {"title": "A hybrid feature selection rule measure and its application to systematic review", "authors": ["Brahim Ouhbi\n,", "Mostafa Kamoune\n,", "Bouchra Frikh\n,", "El Moukhtar Zemmouri\n,", "Hicham Behja"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nSystematic review is the scientific process that provides reliable answers to a particular research question. There is a significant shift from using manual human approach to decision support tools that provides a semi-automated screening phase by reducing the required time and effort. Text classification is useful in determining the statistical significance level of association rules to reduce workload in the systematic review. Several approaches to generate a Rule set for rule based classifiers were proposed in the literature. In this paper, we show that statistic as well as semantic measures of a rule can be combined and effectively computed as a hybrid feature selection rule measure (HFSRM). Moreover, we propose a new algorithm called Rules7-hybrid feature selection (Rules7-HFSRM) by combining the classical algorithm Rules7 and the HFSRM and then used it on the systematic review problem. Our results show that our algorithm significantly outperforms the state-of-the-art benchmark algorithms in the systematic review context.", "references": ["Navid Sheydaei, M. S. (2015). A novel feature selection method for text classification using association rules and clustering. Journal of Information Science Vol. 41(1) 3--15.", "Benghabrit, A., Ouhbi, B., Frikh, B., Zemmouri, E., Behja, H. (2013). Text Document Clustering with Hybrid Feature Selection. In Proceedings of International Conference on Information Integration and Web-based Applications & Services (IIWAS '13). ACM, New York, NY, USA, Pages 600--605.", "Sellak, FL, Ouhbi, B., and Frikh, B. 2015. Using rule-based classifiers in systematic reviews: a semantic class association rules approach. In Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services (iiWAS '15). ACM, New York, NY, USA, Article 43, 5 pages."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011177"}, {"title": "Sonification Platform for Interaction with Real-Time Particle Collision Data from the ATLAS Detector", "authors": ["Juliana Cherston\n,", "Ewan Hill\n,", "Steven Goldfarb\n,", "Joseph A. Paradiso"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis paper presents a platform that enables composers to generate unique auditory representations of real-time particle collision data from the ATLAS experiment at CERN. An associated web page then enables the public to listen to real-time experimental data through the aesthetic lens of selected artists. The current tool is built in collaboration with the ATLAS Outreach team and is designed to increase public engagement in high energy physics by exposing the data through a novel interaction mode. More broadly, it is part of a larger vision to better harness audio as a medium to interact with big data from ever more prevalent real-time sensors.", "references": ["2014. Ableton Live. (2014). Retrieved January 11th, 2016 from http://ableton.com/.", "2015. Pure Data. (2015). Retrieved January 11th, 2016 from http://puredata.info.", "2016. Cycling '74 Max MSP. (2016). Retrieved January 11th, 2016 from https://cycling74.com/products/max/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892295"}, {"title": "Measuring Similarity Similarly: LDA and Human Perception", "authors": ["W. Ben Towne\n,", "Carolyn P. Rosé\n,", "James D. Herbsleb"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nSeveral intelligent technologies designed to improve navigability in and digestibility of text corpora use topic modeling such as the state-of-the-art Latent Dirichlet Allocation (LDA). This model and variants on it provide lower-dimensional document representations used in visualizations and in computing similarity between documents. This article contributes a method for validating such algorithms against human perceptions of similarity, especially applicable to contexts in which the algorithm is intended to support navigability between similar documents via dynamically generated hyperlinks. Such validation enables researchers to ground their methods in context of intended use instead of relying on assumptions of fit. In addition to the methodology, this article presents the results of an evaluation using a corpus of short documents and the LDA algorithm. We also present some analysis of potential causes of differences between cases in which this model matches human perceptions of similarity more or less well.", "references": ["David Andrzejewski and Xiaojin Zhu. 2009. Latent Dirichlet allocation with topic-in-set knowledge. In Proceedings of the NAACL HLT 2009 Workshop on Semi-Supervised Learning for Natural Language Processing (SemiSupLearn’09). Stroudsburg, PA: Association for Computational Linguistics, 43--48.", "David Andrzejewski, Xiaojin Zhu, Mark Craven, and Benjamin Recht. 2011. A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence - Volume Two (IJCAI’11). Barcelona, Catalonia, Spain: AAAI Press, 1171--1177. DOI:http://dx.doi.org/10.5591/978-1-57735-516-8/IJCAI11-200", "Brian P. Bailey and Eric Horvitz. 2010. What's your idea?: A case study of a grassroots innovation pipeline within a large software company. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’10). New York, NY: ACM, 2065--2074. DOI:http://dx.doi.org/10.1145/1753326.1753641"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2890510"}, {"title": "A Methodology to Detect and Track Breaking News on Twitter", "authors": ["Anmol Shukla\n,", "Dhruv Aggarwal\n,", "Ravindra B. Keskar"], "publication": "COMPUTE '16: Proceedings of the 9th Annual ACM India Conference", "abstract": "ABSTRACT\nTwitter is an interesting platform for the dissemination of news. The real-time nature and brevity of the tweets are conducive to sharing of information related to important events as they unfold. But, one of the greatest challenges is to find the tweets that we can characterize as news in the ocean of tweets. In this paper, we propose a novel method for detecting and tracking breaking news from Twitter in real-time. We filter the stream of incoming tweets to remove junk tweets using a text classification algorithm. We also compare the performance of different supervised text classification algorithms for this task. We then cluster similar tweets, so that, tweets in the same cluster relate to the same real-life event and can be termed as a breaking news. Finally, we rank the news using a dynamic scoring system which also allows us to track the news over a period of time.", "references": ["H. Bäcklund, A. Hedblom, and N. Neijman. A density-based spatial clustering of application with noise. Data Mining TNM033, pages 11--30, 2011.", "H. Becker, M. Naaman, and L. Gravano. Beyond trending topics: Real-world event identification on twitter. ICWSM, 11:438--441, 2011.", "D. W. Hosmer Jr and S. Lemeshow. Applied logistic regression. John Wiley & Sons, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2998476.2998491"}, {"title": "An efficient algorithm for partially matched services in internet of services", "authors": ["Mariwan Ahmed\n,", "Lu Liu\n,", "James Hardy\n,", "Bo Yuan\n,", "Nick Antonopoulos"], "publication": "Personal and Ubiquitous Computing", "abstract": "Abstract\nInternet of Things (IoT) connects billions of devices in an Internet-like structure. Each device encapsulated as a real-world service which provides functionality and exchanges information with other devices. This large-scale information exchange results in new interactions between things and people. Unlike traditional web services, internet of services is highly dynamic and continuously changing due to constant degrade, vanish and possibly reappear of the devices, this opens a new challenge in the process of resource discovery and selection. In response to increasing numbers of services in the discovery and selection process, there is a corresponding increase in number of service consumers and consequent diversity of quality of service (QoS) available. Increase in both sides' leads to the diversity in the demand and supply of services, which would result in the partial match of the requirements and offers. This paper proposed an IoT service ranking and selection algorithm by considering multiple QoS requirements and allowing partially matched services to be counted as a candidate for the selection process. One of the applications of IoT sensory data that attracts many researchers is transportation especially emergency and accident services which is used as a case study in this paper. Experimental results from real-world services showed that the proposed method achieved significant improvement in the accuracy and performance in the selection process.", "references": ["Guinard D, Trifa V, Karnouskos S, Spiess P, Savio D (2010) Interacting with the SOA-based internet of things: discovery, query, selection, and on-demand provisioning of web services. IEEE Trans Serv comput 3(3):223---235", "Yan L, Zhang Y, Yang LT, Ning H (2008) The internet of things: from RFID to the next-generation pervasive networked systems (Hardback). Auerbach Publications, New York", "Health and Social Care Information Centre (2014). http://www.hscic.gov.uk/catalogue/PUB13464/acci-emer-atte-eng-2012-2013-rep.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00779-016-0917-9"}, {"title": "Search as research practices on the web: the SaR-Web platform for cross-language engine results analysis", "authors": ["Davide Taibi\n,", "Richard Rogers\n,", "Ivana Marenzi\n,", "Wolfgang Nejdl\n,", "Qazi Asim Ijaz Ahmad\n,", "Giovanni Fulantelli"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nSearch engines are the most utilized tools to access information on the Web. The success of large companies such as Google owes to their capacity to conduct users through the vast troves of knowledge and information online. Recently, the concept of search as research has been used to shift the research focus from workings of information-seeking tools towards methods for the social study of Web and particularly the social meanings of engine results. In this paper, we present SaR-Web, a web search tool that provides an automatic means to carry out search as research on the Web. It compares the results of same (translated) queries across search engine language domains, thereby enabling cross-linguistic and cross-cultural comparisons of results. SaR-Web outputs enable the comparative study of cultural mores as well as societal associations and concerns, interpreted through search engine results.", "references": ["Baldry, A. P. (2011a) Multimodal Web Genres: Exploring Scientific English. Como: IBIS.", "Baldry, A. P., Gaggia, A. and Porta, M. (2011) \"Multimodal Web Concordancing and Annotation. An overview of the MCAWEB System\", in Vasta, N., Riem N., A., Bortoluzzi M. and Saidero D. (eds.). Identities in Transition in the English-Speaking World, Udine: Forum Editrice Universitaria Udinese, pp. 39--60.", "Callahan, E. S. and Herring, S. C. (2011). Cultural bias in Wikipedia content on famous persons. Journal of the American Society for Information Science and Technology. 62, pp. 1899--1915"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908201"}, {"title": "Tempas: Temporal Archive Search Based on Tags", "authors": ["Helge Holzmann\n,", "Avishek Anand"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nLimited search and access patterns over Web archives have been well documented. One of the key reasons is the lack of understanding of the user access patterns over such collections, which in turn is attributed to the lack of effective search interfaces. Current search interfaces for Web archives are (a) either purely navigational or (b) have sub-optimal search experience due to ineffective retrieval models or query modeling. We identify that external longitudinal resources, such as social bookmarking data, are crucial sources to identify important and popular websites in the past. To this extent we present Tempas, a tag-based temporal search engine for Web archives.\nWebsites are posted at specific times of interest on several external platforms, such as bookmarking sites like Delicious. Attached tags not only act as relevant descriptors useful for retrieval, but also encode the time of relevance. With Tempas we tackle the challenge of temporally searching a Web archive by indexing tags and time. We allow temporal selections for search terms, rank documents based on their popularity and also provide meaningful query recommendations by exploiting tag-tag and tag-document co-occurrence statistics in arbitrary time windows. Finally, Tempas operates as a fairly non-invasive indexing framework. By not dealing with contents from the actual Web archive it constitutes an attractive and low-overhead approach for quick access into Web archives.", "references": ["Susan Schreibman, Ray Siemens, and John Unsworth. phA Companion to Digital Humanities. 2008.", "Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K Gray, Joseph P Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig, and Jon Orwant. Quantitative Analysis of Culture Using Millions of Digitized Books. phscience, 2010.", "Sarah Cohen, Chengkai Li, Jun Yang, and Cong Yu. Computational journalism: A call to arms to database researchers. In phProceedings of the 5th Biennial Conference on Innovative Data Systems Research, pages 148--151, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890555"}, {"title": "An Exploration of Automated Grading of Complex Assignments", "authors": ["Chase Geigle\n,", "ChengXiang Zhai\n,", "Duncan C. Ferguson"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nAutomated grading is essential for scaling up learning. In this paper, we conduct the first systematic study of how to automate grading of a complex assignment using a medical case assessment as a test case. We propose to solve this problem using a supervised learning approach and introduce three general complementary types of feature representations of such complex assignments for use in supervised learning. We first show with empirical experiments that it is feasible to automate grading of such assignments provided that the instructor can grade a number of examples. We further study how to integrate an automated grader with human grading and propose to frame the problem as learning to rank assignments to exploit pairwise preference judgments and use NDPM as a measure for evaluation of the accuracy of ranking. We then propose a sequential pairwise online active learning strategy to minimize the effort of human grading and optimize the collaboration of human graders and an automated grader. Experiment results show that this strategy is indeed effective and can substantially reduce human effort as compared with randomly sampling assignments for manual grading.", "references": ["R. Alur, L. D'Antoni, S. Gulwani, D. Kini, and M. Viswanathan. 2013. Automated Grading of DFA Constructions (IJCAI). 1976--1982.", "S. P. Balfour. 2013. Assessing writing in MOOCs: Automated essay scoring and calibrated peer review. Research and Practice in Assessment 8, 1 (2013), 40--48.", "M. Brooks, S. Basu, C. Jacobs, and L. Vanderwende. 2014. Divide and Correct: Using Clusters to Grade Short Answers at Scale. In ACM L@S. 89--98."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2876049"}, {"title": "Effects of Position and Time Bias on Understanding Onsite Users' Behavior", "authors": ["Seyyed Hadi Hashemi\n,", "Wim Hupperetz\n,", "Jaap Kamps\n,", "Merel van der Vaart"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThe existence of different biases in logged users' behavior makes it difficult to extract realistic topical and social information from users' interaction logs (e.g., query logs). To understand users' behavior and their interests in the cultural heritage domain, we have logged onsite user interaction logs of visits in a museum. This prompts the question on the reliability of the social information being gathered from the onsite logs: How does the position of museum objects affect users' behavior in the museum? How does order of visiting point of interests affect their dwell-time in front of each point of interest? How do different users' characteristics affect their behavior in the museum? In short, what are different kinds of biases that should be considered in the onsite logs? Our main findings are the following: First, there is a considerable position bias, which is due to the design of the exhibition and should be considered during extraction of social signals from the log. Second, there is a bias in the amount of time that users spend for interacting with the point of interests and the order of picking them to visit. This shows a fatigue on users' interactions while they are reaching to the end of the exhibition. Third, we find out some variations among the users' visit, which shows context is an important factor to consider while using onsite logs for different purposes.", "references": ["N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An Experimental Comparison of Click Position-bias Models. In WSDM, pages 87--94, 2008.", "L. A. Granka, T. Joachims, and G. Gay. Eye-tracking Analysis of User Behavior in WWW Search. In SIGIR, pages 478--479, 2004.", "S. H. Hashemi, C. L. Clarke, A. Dean-Hall, J. Kamps, and J. Kiseleva. On the Reusability of Open Test Collections. In SIGIR, pages 827--830, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855004"}, {"title": "Visual Recommendation Use Case for an Online Marketplace Platform: allegro.pl", "authors": ["Anna Wróblewska\n,", "Łukasz Rączkowski"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we describe a small content-based visual recommendation project built as part of the Allegro online marketplace platform. We extracted relevant data only from images, as they are inherently better at capturing visual attributes than textual offer descriptions. We used several image descriptors to extract color and texture information in order to find visually similar items. We tested our results against available textual offer tags and also asked human users to subjectively assess the precision. Finally, we deployed the solution to our platform.", "references": ["Allegro online marketplace platform: http://allegro.pl.", "Bhardwaj, A., Das Sarma, A., Di, W., Hamid, R., Piramuthu, R. and Sundaresan, N. 2013. Palette power: enabling visual search through colors. Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2013), 1321--1329.", "Bosch, A., Zisserman, A. and Munoz, X. 2007. Representing shape with a spatial pyramid kernel. Proceedings of the 6th ACM international conference on Image and video retrieval (2007), 401--408."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926722"}, {"title": "STAR: Semiring Trust Inference for Trust-Aware Social Recommenders", "authors": ["Peixin Gao\n,", "Hui Miao\n,", "John S. Baras\n,", "Jennifer Golbeck"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nSocial recommendation takes advantage of the influence of social relationships in decision making and the ready availability of social data through social networking systems. Trust relationships in particular can be exploited in such systems for rating prediction and recommendation, which has been shown to have the potential for improving the quality of the recommender and alleviating the issue of data sparsity, cold start, and adversarial attacks. An appropriate trust inference mechanism is necessary in extending the knowledge base of trust opinions and tackling the issue of limited trust information due to connection sparsity of social networks. In this work, we offer a new solution to trust inference in social networks to provide a better knowledge base for trust-aware recommender systems. We propose using a semiring framework as a nonlinear way to combine trust evidences for inferring trust, where trust relationship is model as 2-D vector containing both trust and certainty information. The trust propagation and aggregation rules, as the building blocks of our trust inference scheme, are based upon the properties of trust relationships. In our approach, both trust and distrust (i.e., positive and negative trust) are considered, and opinion conflict resolution is supported. We evaluate the proposed approach on real-world datasets, and show that our trust inference framework has high accuracy, and is capable of handling trust relationship in large networks. The inferred trust relationships can enlarge the knowledge base for trust information and improve the quality of trust-aware recommendation.", "references": ["Epinions trust network dataset -- KONECT, Oct. 2014.", "C. C. Aggarwal. Social and trust-centric recommender systems. In Recommender Systems. Springer, 2016.", "R. Andersen, C. Borgs, J. Chayes, U. Feige, A. Flaxman, A. Kalai, V. Mirrokni, and M. Tennenholtz. Trust-based recommendation systems: an axiomatic approach. In WWW 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959148"}, {"title": "FSA and NLP based Un-supervised non template Web data extraction in the construction Of Dynamic Ontology", "authors": ["K. Uma Pavan Kumar\n,", "S. Saraswathi"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nThe main focus of our research work is to construct the Job Recommendation System (JRS) based on the ontology construction. The current discussion is related to web data extraction process in the construction of ontology. The importance of this concept is how best data can be extracted from various web pages to minimize the time requirement and improve the efficiency. The process followed to construct ontology is first identified various sources of job portals, then extraction of data from those portals for that the proposed a method is FSA(Finite State Automata) and NLP(Natural Language Processing) based extraction of data. The outcome of this method is efficient data extraction in terms of time and space usage when compared with other models.", "references": ["Chia-Hui Chang, A Survey on web information extraction system. IEEE Transactions on Knowledge and Data engineering, 15, 5 (Nov. 2013),", "Disha Patel, A Survey of Unsupervised techniques for web data extraction, International Journal Of Computer Science, Volume 6-Number 2 April -sep 2015 pp 1--5..", "Ms. Prital Bhure, A Survey paper on the method of automatic data extraction and alignment from web database., International Journal of engineering research and Technology, Vol 3, Issue 1, January 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980292"}, {"title": "A classification of autonomous bilateral cloud SLA negotiation strategies", "authors": ["Benedikt Pittl\n,", "Werner Mach\n,", "Erich Schikuta"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nCurrently digital markets emerge where cloud resources are traded in the form of computational services. Usually the so called supermarket approach is applied on these service markets, where consumers buy offered services from providers based on fixed functional and non-functional characteristics without negotiations. However, bilateral multi round negotiation, which allows to customize the traded services, is considered as a promising improvement to the static supermarket approach aiming for higher market efficiency.\nIn this paper we introduce a novel generic service market ecosystem from which requirements for bilateral negotiation strategies are derived. Evaluating a survey on published bilateral negotiation strategies along these requirements shows that important market elements are not considered in current research. Most of the published bilateral negotiation strategies are focusing on a single negotiation phases only neglecting the complete negotiation process. Hence we classify the identified strategies along the different phases of the generic negotiation process. Based on our analysis we identify two different groups in their scientific approach: One group assumes complete information during bilateral negotiations while the other group assumes incomplete information.", "references": ["M. Al-Aaidroos, N. Jailani, and M. Mukhtar. Agent-based negotiation framework for web service's SLA. In Information Technology in Asia (CITA 11), 2011 7th International Conference on, pages 1--7. IEEE, 2011.", "Amazon. Amazon ec2 spot market, https://aws.amazon.com/ec2/spot/.", "L. Ashok and D. Mukhopadhyay. Single Gateway Negotiation for Cloud Service during Service Level Agreement. In 2015 International Conference on Information Technology (ICIT), pages 181--186. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011159"}, {"title": "Query Adaptive Search System Based On Hamming Distance for Image Retrieval", "authors": ["Sonal Vijay Kesare\n,", "Bela Joglekar"], "publication": "VisionNet'16: Proceedings of the Third International Symposium on Computer Vision and the Internet", "abstract": "ABSTRACT\nThe most recent active topic of research for image retrieval is scalable image search based on visual similarity. The main motivation for image retrieval is based on image ranking, given by multiple retrieval methods without affecting their scalability. This paper describes ranking and retrieval as graphs of candidate images and proposes a graph-based query specific rank fusion approach, in which graphs are created by using nearest neighbour node and multiple graphs are merged together and re-ranked them by conducting link analysis on the fused graph. Then rank fusion maintains the efficiency and scalability of image retrieval by applying the rank aggregation method. The proposed system will add the query adaptive image to the search system. In this system, hamming distance is calculated and query adaptive weights are computed between query image and database image. Based on these weights, images are ranked. A finer-grained ranking of search results is produced by query --adaptive approach. The proposed will improve the efficiency and scalability of image retrieval.", "references": ["Tianxu Ji, Xianglong Liu, Cheng Deng, Lei Huang, Bo Lang, 'Query-Adaptive Hash Code Ranking for Fast Nearest Neighbor Search', ACM transaction, 2014.", "Shaoting Zhang, Ming Yang, TimotheeCour, Kai Yu, Dimitris Metaxas, 'Query specific rank fusion for image retrival', IEEE Transactions on Pattern Analysis and Machine Intelligence - 2013.", "T. Ge, K. He, Q. Ke, and J. Sun., 'Optimized product quantization for approximate nearest neighbor search', In IEEE Conf. on Computer Vision and Pattern Recognition, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983402.2983443"}, {"title": "Using Shortlists to Support Decision Making and Improve Recommender System Performance", "authors": ["Tobias Schnabel\n,", "Paul N. Bennett\n,", "Susan T. Dumais\n,", "Thorsten Joachims"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper, we study shortlists as an interface component for recommender systems with the dual goal of supporting the user's decision process, as well as improving implicit feedback elicitation for increased recommendation quality. A shortlist is a temporary list of candidates that the user is currently considering, e.g., a list of a few movies the user is currently considering for viewing. From a cognitive perspective, shortlists serve as digital short-term memory where users can off-load the items under consideration -- thereby decreasing their cognitive load. From a machine learning perspective, adding items to the shortlist generates a new implicit feedback signal as a by-product of exploration and decision making which can improve recommendation quality. Shortlisting therefore provides additional data for training recommendation systems without the increases in cognitive load that requesting explicit feedback would incur.\nWe perform an user study with a movie recommendation setup to compare interfaces that offer shortlist support with those that do not. From the user studies we conclude: (i) users make better decisions with a shortlist; (ii) users prefer an interface with shortlist support; and (iii) the additional implicit feedback from sessions with a shortlist improves the quality of recommendations by nearly a factor of two.", "references": ["A. D. Baddeley. Essentials of human memory. Psychology Press, 1999.", "L. Chen, M. de Gemmis, A. Felfernig, P. Lops, F. Ricci, and G. Semeraro. Human decision making and recommender systems. TiiS, 3(3):17, 2013.", "P. Cremonesi, A. Donatacci, F. Garzotto, and R. Turrin. Decision-making in recommender systems: The role of user's goals and bounded resources. In RecSys: Workshop on Human Decision Making in Recommender Systems."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883012"}, {"title": "Learning to Extract Conditional Knowledge for Question Answering using Dialogue", "authors": ["Pengwei Wang\n,", "Lei Ji\n,", "Jun Yan\n,", "Lianwen Jin\n,", "Wei-Ying Ma"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nKnowledge based question answering (KBQA) has attracted much attention from both academia and industry in the field of Artificial Intelligence. However, many existing knowledge bases (KBs) are built by static triples. It is hard to answer user questions with different conditions, which will lead to significant answer variances in questions with similar intent. In this work, we propose to extract conditional knowledge base (CKB) from user question-answer pairs for answering user questions with different conditions through dialogue. Given a subject, we first learn user question patterns and conditions. Then we propose an embedding based co-clustering algorithm to simultaneously group the patterns and conditions by leveraging the answers as supervisor information. After that, we extract the answers to questions conditioned on both question pattern clusters and condition clusters as a CKB. As a result, when users ask a question without clearly specifying the conditions, we use dialogues in natural language to chat with users for question specification and answer retrieval. Experiments on real question answering (QA) data show that the dialogue model using automatically extracted CKB can more accurately answer user questions and significantly improve user satisfaction for questions with missing conditions.", "references": ["J. Bao, N. Duan, M. Zhou, and T. Zhao. Knowledge-based question answering as machine translation. In Proceedings of the 52nd Annual Meeting of the ACL, 2014.", "J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1533--1544, 2013.", "J. Berant and P. Liang. Semantic parsing via paraphrasing. In Proceedings of the 52nd Annual Meeting of the ACL, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983777"}, {"title": "Table Cell Search for Question Answering", "authors": ["Huan Sun\n,", "Hao Ma\n,", "Xiaodong He\n,", "Wen-tau Yih\n,", "Yu Su\n,", "Xifeng Yan"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nTables are pervasive on the Web. Informative web tables range across a large variety of topics, which can naturally serve as a significant resource to satisfy user information needs. Driven by such observations, in this paper, we investigate an important yet largely under-addressed problem: Given millions of tables, how to precisely retrieve table cells to answer a user question. This work proposes a novel table cell search framework to attack this problem. We first formulate the concept of a relational chain which connects two cells in a table and represents the semantic relation between them. With the help of search engine snippets, our framework generates a set of relational chains pointing to potentially correct answer cells. We further employ deep neural networks to conduct more fine-grained inference on which relational chains best match the input question and finally extract the corresponding answer cells. Based on millions of tables crawled from the Web, we evaluate our framework in the open-domain question answering (QA) setting, using both the well-known WebQuestions dataset and user queries mined from Bing search engine logs. On WebQuestions, our framework is comparable to state-of-the-art QA systems based on knowledge bases (KBs), while on Bing queries, it outperforms other systems with a 56.7% relative gain. Moreover, when combined with results from our framework, KB-based QA performance can obtain a relative improvement of 28.1% to 66.7%, demonstrating that web tables supply rich knowledge that might not exist or is difficult to be identified in existing KBs.", "references": ["Freebase wiki. http://wiki.freebase.com/wiki/Wikipedia.", "M. D. Adelfio and H. Samet. Schema extraction for tabular data on the web. VLDB, 6(6):421--432, 2013.", "I. Androutsopoulos, G. D. Ritchie, and P. Thanisch. Natural language interfaces to databases--an introduction. Natural language engineering, 1(01):29--81, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883080"}, {"title": "Automatic programming error class identification with code plagiarism-based clustering", "authors": ["Sébastien Combéfis\n,", "Arnaud Schils"], "publication": "CHESE 2016: Proceedings of the 2nd International Code Hunt Workshop on Educational Software Engineering", "abstract": "ABSTRACT\nOnline platforms to learn programming are very popular nowadays. These platforms must automatically assess codes submitted by the learners and must provide good quality feedbacks in order to support their learning. Classical techniques to produce useful feedbacks include using unit testing frameworks to perform systematic functional tests of the submitted codes or using code quality assessment tools. This paper explores how to automatically identify error classes by clustering a set of submitted codes, using code plagiarism detection tools to measure the similarity between the codes. The proposed approach and analysis framework are presented in the paper, along with a first experiment using the Code Hunt dataset.", "references": ["J. Bishop, R. N. Horspool, T. Xie, N. Tillmann, and J. de Halleux. Code hunt: Experience with coding contests at scale. In Proceedings of the 37th International Conference on Software Engineering (ICSE 2015), pages 398–407. ACM, May 2015.", "S. Combéfis, A. Bibal, and P. Van Roy. Recasting a traditional course into a mooc by means of a spoc. In Proceedings of the European MOOCs Stakeholders Summit 2014 (EMOOCs 2014), pages 205–208, Feb. 2014.", "S. Combéfis and V. le Clément de Saint-Marcq. Teaching programming and algorithm design with pythia, a web-based learning platform. Olympiads in Informatics, 6:31–43, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993270.2993271"}, {"title": "Situation Recognition from Multimodal Data", "authors": ["Vivek K. Singh\n,", "Siripen Pongpaichet\n,", "Ramesh Jain"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nNo abstract available.", "references": ["M. Balduini, E. Della Valle, M. Azzi, R. Larcher, F. Antonelli, and P. Ciuccarelli. Citysensing: visual story telling of city-scale events by fusing social media streams and call data records captured at places and events. IEEE MultiMedia, 22(3), 2015.", "C. Dousson, P. Gaborit, and M. Ghallab. Situation recognition: representation and algorithms. In IJCAI, volume 93, pages 166--172, 1993.", "V. K. Singh, M. Gao, and R. Jain. Social pixels: genesis and evaluation. In Proc. Int. Conf. on Multimedia, pages 481--490. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2986913"}, {"title": "A Quality Adaptive Multimodal Affect Recognition System for User-Centric Multimedia Indexing", "authors": ["Rishabh Gupta\n,", "Mojtaba Khomami Abadi\n,", "Jesús Alejandro Cárdenes Cabré\n,", "Fabio Morreale\n,", "Tiago H. Falk\n,", "Nicu Sebe"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe recent increase in interest for online multimedia streaming platforms has availed massive amounts of multimedia information that need to be indexed to be searchable and retrievable. User-centric implicit affective indexing employing emotion detection based on psycho-physiological signals, such as electrocardiography (ECG), galvanic skin response (GSR), electroencephalography (EEG) and face tracking, has recently gained attention. However, real world psycho-physiological signals obtained from wearable devices and facial trackers are contaminated by various noise sources that can result in spurious emotion detection. Therefore, in this paper we propose the development of psycho-physiological signal quality estimators for unimodal affect recognition systems. The presented systems perform adequately in classifying users affect however, they resulted in high failure rates due to rejection of bad quality samples. Thus, to reduce the affect recognition failure rate, a quality adaptive multimodal fusion scheme is proposed. The proposed scheme yields no failure, while at the same time classify the users' arousal/valence and liking with significantly above chance weighted F1-scores in a cross-user experiment. Another finding of this study is that head movements encode liking perception of users in response to music snippets. This work also includes the release of the employed dataset including psycho-physiological signals, their quality annotations, and users' affective self-assessments.", "references": ["M. Esterman, B. J. Tamber-Rosenau, Y.-C. Chiu, and S. Yantis. Avoiding non-independence in fmri data analysis: leave one subject out. Neuroimage, 50(2):572--576, 2010.", "R. Gupta, K. ur Rehman Laghari, and T. H. Falk. Relevance vector classifier decision fusion and EEG graph-theoretic features for automatic affective state characterization. Neurocomputing, 174(PB):875--884, Jan. 2016.", "A. Hanjalic and L.-Q. Xu. Affective video content representation and modeling. IEEE Transactions on Multimedia, 7(1):143--154, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912059"}, {"title": "Smoothing Class Frequencies for KNN Medical Article Classification", "authors": ["Kostas Fragos\n,", "Christos Skourlas"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nK-Nearest Neighbor (KNN) is one of the most popular algorithms for text classification. In many experiments researchers have found that the KNN algorithm accomplishes very good performance on different data sets. In a previous work [16], we proposed an algorithm, called lf-igf KNN, to classify medical articles using local from neighborhood and global from corpus class label frequencies to device a weighting scheme for ranking all data points in the training set. In this work, we modify this previous work going beyond simple counting, both smoothing class label frequencies and neighbor's distances. We provide by this way an alternative and more robust weighted scheme for KNN classification. The evaluation experiments on the collection of medical documents, called Ohsumed, show promising results and inspire us to use smoothing techniques to treat class occurrences in traditional KNN classification.", "references": ["Taeho Jo. Application of table based similarity to classification of biomedical documents. IEEE International Conference on Granular Computing 2013: 162--166.", "Mohammed GH A Z., Can A B. ROLEX-SP: Rules of lexical syntactic patterns for free text categorization. Journal of Knowledge-Based Systems Elsevier 2011; 24: 58--65.", "Parvin, H., Alizadeh, H. and Minaei-Bidgoli, B. A Modification on K-Nearest Neighbor Classifier, pp 37--41, Vol.10, Issue 14, November 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003806"}, {"title": "Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2016)", "authors": ["Guillaume Cabanac\n,", "Muthu Kumar Chandrasekaran\n,", "Ingo Frommholz\n,", "Kokil Jaidka\n,", "Min-Yen Kan\n,", "Philipp Mayr\n,", "Dietmar Wolfram"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe large scale of scholarly publications poses a challenge for scholars in information-seeking and sensemaking. Bibliometric, information retrieval~(IR), text mining and NLP techniques could help in these activities, but are not yet widely used in digital libraries. This workshop is intended to stimulate IR researchers and digital library professionals to elaborate on new approaches in natural language processing, information retrieval, scientometric and recommendation techniques which can advance the state-of-the-art in scholarly document understanding, analysis and retrieval at scale.", "references": ["Iana Atanassova, Marc Bertin, and Philipp Mayr. Proceedings of the First Workshop on Mining Scientific Papers: Computational Linguistics and Bibliometrics. Istanbul, Turkey, 2015.", "Kokil Jaidka, Muthu Kumar Chandrasekaran, Beatriz Fisas Elizalde, Rahul Jha, Christopher Jones, Min-Yen Kan, Ankur Khanna, Diego Molla-Aliod, Dragomir R Radev, Francesco Ronzano, et al. The computational linguistics summarization pilot task. In Proceedings of Text Ananlysis Conference, Gaithersburg, USA, 2014.", "Philipp Mayr, Ingo Frommholz, and Guillaume Cabanac. Proceedings of the Third Workshop on Bibliometric-enhanced Information Retrieval. Padova, Italy, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2926734"}, {"title": "ReStream: Accelerating Backtesting and Stream Replay with Serial-Equivalent Parallel Processing", "authors": ["Johann Schleier-Smith\n,", "Erik T. Krogen\n,", "Joseph M. Hellerstein"], "publication": "SoCC '16: Proceedings of the Seventh ACM Symposium on Cloud Computing", "abstract": "ABSTRACT\nReal-time predictive applications can demand continuous and agile development, with new models constantly being trained, tested, and then deployed. Training and testing are done by replaying stored event logs, running new models in the context of historical data in a form of backtesting or \"what if?\" analysis. To replay weeks or months of logs while developers wait, we need systems that can stream event logs through prediction logic many times faster than the real-time rate. A challenge with high-speed replay is preserving sequential semantics while harnessing parallel processing power. The crux of the problem lies with causal dependencies inherent in the sequential semantics of log replay.\nWe introduce an execution engine that produces serial-equivalent output while accelerating throughput with pipelining and distributed parallelism. This is made possible by optimizing for high throughput rather than the traditional stream processing goal of low latency, and by aggressive sharing of versioned state, a technique we term Multi-Versioned Parallel Streaming (MVPS). In experiments we see that this engine, which we call ReStream, performs as well as batch processing and more than an order of magnitude better than a single-threaded implementation.", "references": ["D. J. Abadi, D. Carney, U. Çetintemel, M. Cherniack, C. Convey, S. Lee, M. Stonebraker, N. Tatbul, and S. Zdonik. Aurora: A new model and architecture for data stream management. The VLDB Journal, 12(2):120--139, Aug. 2003.", "T. Akidau, A. Balikov, K. Bekiroğlu, S. Chernyak, J. Haberman, R. Lax, S. McVeety, D. Mills, P. Nordstrom, and S. Whittle. MillWheel: Fault-tolerant stream processing at internet scale. Proceedings of the VLDB Endowment, 6(11):1033--1044, 2013.", "T. Akidau, R. Bradshaw, C. Chambers, S. Chernyak, R. J. Fernández-Moctezuma, R. Lax, S. McVeety, D. Mills, F. Perry, E. Schmidt, et al. The Dataflow Model: A practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing. Proceedings of the VLDB Endowment, 8(12):1792--1803, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987550.2987573"}, {"title": "Learning a dual-language vector space for domain-specific cross-lingual question retrieval", "authors": ["Guibin Chen\n,", "Chunyang Chen\n,", "Zhenchang Xing\n,", "Bowen Xu"], "publication": "ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nThe lingual barrier limits the ability of millions of non-English speaking developers to make effective use of the tremendous knowledge in Stack Overflow, which is archived in English. For cross-lingual question retrieval, one may use translation-based methods that first translate the non-English queries into English and then perform monolingual question retrieval in English. However, translation-based methods suffer from semantic deviation due to inappropriate translation, especially for domain-specific terms, and lexical gap between queries and questions that share few words in common. To overcome the above issues, we propose a novel cross-lingual question retrieval based on word embeddings and convolutional neural network (CNN) which are the state-of-the-art deep learning techniques to capture word- and sentence-level semantics. The CNN model is trained with large amounts of examples from Stack Overflow duplicate questions and their corresponding translation by machine, which guides the CNN to learn to capture informative word and sentence features to recognize and quantify semantic similarity in the presence of semantic deviations and lexical gaps. A uniqueness of our approach is that the trained CNN can map documents in two languages (e.g., Chinese queries and English questions) in a dual-language vector space, and thus reduce the cross-lingual question retrieval problem to a simple k-nearest neighbors search problem in the dual-language vector space, where no query or question translation is required. Our evaluation shows that our approach significantly outperforms the translation-based method, and can be extended to dual-language documents retrieval from different sources.", "references": ["Y. Bengio, H. Schwenk, J.-S. Senécal, F. Morin, and J.-L. Gauvain. Neural probabilistic language models. In Innovations in Machine Learning, pages 137–186. Springer, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022, 2003.", "D. Bogdanova, C. dos Santos, L. Barbosa, and B. Zadrozny. Detecting semantically equivalent questions in online user forums. CoNLL 2015, page 123, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970276.2970317"}, {"title": "Subspace Clustering Based Tag Sharing for Inductive Tag Matrix Refinement with Complex Errors", "authors": ["Yuqing Hou\n,", "Zhouchen Lin\n,", "Jin-ge Yao"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAnnotating images with tags is useful for indexing and retrieving images. However, many available annotation data include missing or inaccurate annotations. In this paper, we propose an image annotation framework which sequentially performs tag completion and refinement. We utilize the subspace property of data via sparse subspace clustering for tag completion. Then we propose a novel matrix completion model for tag refinement, integrating visual correlation, semantic correlation and the novelly studied property of complex errors. The proposed method outperforms the state-of-the-art approaches on multiple benchmark datasets even when they contain certain levels of annotation noise.", "references": ["G. Carneiro, A. Chan, P. Moreno, and N. Vasconcelos. Supervised learning of semantic classes for image annotation and retrieval. TPAMI, 2007.", "M. Chen, A. Zheng, and K. Weinberger. Fast image tagging. In ICML, 2013.", "F. Chung. Spectral graph theory. 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914693"}, {"title": "Emotional Fingerprint from Authors in Classical Literature", "authors": ["Matheus Lima Diniz Araujo\n,", "Iuro Nascimento\n,", "Gustavo Caetano Rafael\n,", "Raquel de Melo-Minardi\n,", "Fabrício Benevenuto"], "publication": "Webmedia '16: Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe Internet deeply changed the way people share their knowledge. Almost all content that people produces is now available in digital formats, like e-books, apps, newspapers, and magazines. That content has commonly some metadata available that can be used to generate complex recommendation systems that track content similarity. Since there is some effort in the literature to explore this direction, almost all use classical recommendation approaches, like collaborative filter data and information present on websites that sells books. While most efforts in the literature use features derived from the text syntax to create a recommendation model, our approach aims to trace an emotional fingerprint of authors extracted from their texts. This approach, known as psychometry, consists of the study of behavioral characteristics like positivity, negativity, sadness, fear, religiosity, sexuality, which are able to disguise individuals. Using two sentiment analysis lexicons and a collection of 641 books from the English literature written by 56 authors, we show the effectiveness of these psychometric features in order to trace those authors emotional fingerprint.", "references": ["Project gutenberg. http://www.gutenberg.org/.", "M. Araujo, J. P. Diniz, L. Bastos, E. Soares, M. Junior, M. Ferreira, F. Ribeiro, and F. Benevenuto. ifeel 2.0: A multilingual benchmarking system for sentence-level sentiment analysis. ICWSM, 2016.", "N. Cheng, R. Chandramouli, and K. Subbalakshmi. Author gender identification from text. Digital Investigation, 8(1):78--88, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2976796.2976868"}, {"title": "Towards Comprehensive User Modeling on the Social Web for Personalized Link Recommendations", "authors": ["Guangyuan Piao"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nUser modeling for individual users on the Social Web plays a significant role and is a fundamental step for personalization as well as recommendations. Previous studies have proposed various user modeling strategies in different dimensions such as (1) interest representation, (2) interest propagation, (3) content enrichment and (4) temporal dynamics of user interests. This research mainly focuses on the first two dimensions interest representation and propagation. In addition, we also investigate the combination of these four dimensions and their synergistic effect on the quality of user modeling. Different user modeling strategies will then be evaluated in the context of personalized link recommender systems using standard evaluation methodologies such as Mean Reciprocal Rank (MRR), recall (R@N) and success (S@N) at rank N.", "references": ["F. Abel. Contextualization, User Modeling and Personalization in the Social Web--From Social Tagging via Context to Cross-System User Modeling and Personalization. PhD thesis, Leibniz University of Hanover, 2011.", "F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing temporal dynamics in twitter profiles for personalized recommendations in the social web. In Proceedings of the 3rd International Web Science Conference, page 2. ACM, 2011.", "F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user modeling on twitter for personalized news recommendations. In User Modeling, Adaption and Personalization, pages 1--12. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930367"}, {"title": "Using Semantic and Context Features for Answer Summary Extraction", "authors": ["Evi Yulianti\n,", "Ruey-Cheng Chen\n,", "Falk Scholer\n,", "Mark Sanderson"], "publication": "ADCS '16: Proceedings of the 21st Australasian Document Computing Symposium", "abstract": "ABSTRACT\nWe investigate the effectiveness of using semantic and context features for extracting document summaries that are designed to contain answers for non-factoid queries. The summarization methods are compared against state-of-the-art factoid question answering and query-biased summarization techniques. The accuracy of generated answer summaries are evaluated using ROUGE as well as sentence ranking measures, and the relationship between these measures are further analyzed. The results show that semantic and context features give significant improvement to the state-of-the-art techniques.", "references": ["M. Ageev, D. Lagun, and E. Agichtein. Improving Search Result Summaries by Using Searcher Behavior Data. In Proc. of SIGIR, pages 13--22, 2013.", "M. S. Bernstein, J. Teevan, S. Dumais, D. Liebling, and E. Horvitz. Direct Answers for Search Queries in the Long Tail. In Proc. of SIGCHI, pages 237--246, 2012.", "M. Keikha, J. H. Park, and W. B. Croft. Evaluating Answer Passages Using Summarization Measures. In Proc. of SIGIR, pages 963--966, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015022.3015031"}, {"title": "Using Metafeatures to Increase the Effectiveness of Latent Semantic Models in Web Search", "authors": ["Alexey Borisov\n,", "Pavel Serdyukov\n,", "Maarten de Rijke"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn web search, latent semantic models have been proposed to bridge the lexical gap between queries and documents that is due to the fact that searchers and content creators often use different vocabularies and language styles to express the same concept. Modern search engines simply use the outputs of latent semantic models as features for a so-called global ranker. We argue that this is not optimal, because a single value output by a latent semantic model may be insufficient to describe all aspects of the model's prediction, and thus some information captured by the model is not used effectively by the search engine. To increase the effectiveness of latent semantic models in web search, we propose to create metafeatures-feature vectors that describe the structure of the model's prediction for a given query-document pair and pass them to the global ranker along with the models? scores. We provide simple guidelines to represent the latent semantic model's prediction with more than a single number, and illustrate these guidelines using several latent semantic models. We test the impact of the proposed metafeatures on a web document ranking task using four latent semantic models. Our experiments show that (1) through the use of metafeatures, the performance of each individual latent semantic model can be improved by 10.2% and 4.2% in NDCG scores at truncation levels 1 and 10; and (2) through the use of metafeatures, the performance of a combination of latent semantic models can be improved by 7.6% and 3.8% in NDCG scores at truncation levels 1 and 10, respectively.", "references": ["B. Bai, J. Weston, D. Grangier, R. Collobert, K. Sadamasa, Y. Qi, O. Chapelle, and K. Weinberger. Supervised semantic indexing. In CIKM 2009, pages 187--196. ACM, 2009.", "B. Bai, J. Weston, D. Grangier, R. Collobert, K. Sadamasa, Y. Qi, O. Chapelle, and K. Weinberger. Learning to rank with (a lot of) word features. Information Retrieval, 13 (3): 291--314, 2010.", "Y. Bengio. Learning deep architectures for AI. Foundations and trends in Machine Learning, 2 (1): 1--127, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882987"}, {"title": "The Forgotten Needle in My Collections: Task-Aware Ranking of Documents in Semantic Information Space", "authors": ["Tuan A. Tran\n,", "Sven Schwarz\n,", "Claudia Niederée\n,", "Heiko Maus\n,", "Nattiya Kanhabua"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWith the growing amount of content stored in personal and organizational information spaces, finding and re-finding documents becomes both more crucial and challenging. In this work, we propose an approach to reduce information overload in navigation by automatically focusing on important documents, adaptively to the tasks at hand. Based on the idea of managed forgetting, we present a ranking method, which unifies activity logs and semantic information about documents into a common framework to identify important documents to the user's current tasks. Our experiments on two real-world datasets, both collected from knowledge work activities in professional scenarios, show that our ranking approach outperforms the baseline methods for both subsequent access prediction and the effectiveness in ranking important documents. Furthermore, we implemented and demonstrated a system for decluttering information spaces as a proof of concept of our managed forgetting approach.", "references": ["B. Adrian, M. Klinkigt, H. Maus, and A. Dengel. Using iDocument for document categorization in Nepomuk Social Semantic Desktop. In I-SEMANTICS, pages 638--643, 2009.", "J. R. Anderson and L. J. Schooler. Reflections of the environment in memory. Psychological Science, 6(2):396--408, 1991.", "M. Awad, L. Khan, and B. Thuraisingham. Predicting www surfing using multiple evidence combination. The VLDB Journal, 17(3):401--417, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854971"}, {"title": "Leveraging Context-Free Grammar for Efficient Inverted Index Compression", "authors": ["Zhaohua Zhang\n,", "Jiancong Tong\n,", "Haibing Huang\n,", "Jin Liang\n,", "Tianlong Li\n,", "Rebecca J. Stones\n,", "Gang Wang\n,", "Xiaoguang Liu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLarge-scale search engines need to answer thousands of queries per second over billions of documents, which is typically done by querying a large inverted index. Many highly optimized integer encoding techniques are applied to compress the inverted index and reduce the query processing time. In this paper, we propose a new grammar-based inverted index compression scheme, which can improve the performance of both index compression and query processing.\nOur approach identifies patterns (common subsequences of docIDs) among different posting lists and generates a context-free grammar to succinctly represent the inverted index. To further optimize the compression performance, we carefully redesign the index structure. Experiments show a reduction up to 8.8% in space usage while decompression is up to 14% faster.\nWe also design an efficient list intersection algorithm which utilizes the proposed grammar-based inverted index. We show that our scheme can be combined with common docID reassignment methods and encoding techniques, and yields about 14% to 27% higher throughput for AND queries by utilizing multiple threads.", "references": ["V. N. Anh and A. Moffat. Index compression using fixed binary codewords. In Proc. 15th Australasian Database Conference, volume 27, pages 61--67, Darlinghurst, Australia, 2004.", "V. N. Anh and A. Moffat. Inverted index compression using word-aligned binary codes. Information Retrieval, 8:151--166, 2005.", "D. Arroyuelo, S. González, M. Oyarzún, and V. Sepulveda. Document identifier reassignment and run-length-compressed inverted indexes for improved search performance. In Proc. 36th International ACM SIGIR Conference, pages 173--182, New York, NY, USA, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911518"}, {"title": "Knowledge Extraction for Literature Review", "authors": ["Tatiana Erekhinskaya\n,", "Mithun Balakrishna\n,", "Marta Tatu\n,", "Steven Werner\n,", "Dan Moldovan"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nResearchers in all domains need to keep abreast with recent scientific advances. Finding relevant publications and reviewing them is a labor-intensive task that lacks efficient automatic tools to support it. Current tools are limited to standard keyword-based search systems that return potentially relevant documents and then leave the user with a monumental task of sifting through them. In this paper, we present a semantic-driven system to automatically extract the most important knowledge from a publication and reduces the effort required for the literature review. The system extracts key findings from biomedical papers in PubMed, populates a predefined template and displays it. This allows the user to get the key ideas of the content even before opening or downloading the publication.", "references": ["E. Blanco and D. Moldovan. Composition of semantic relations: Theoretical framework and case study. ACM Trans. Speech Lang. Process., 10(4):17:1--17:36, Jan. 2014.", "K. B. Cohen and D. Demner-Fushman. Biomedical Natural Language Processing. John Benjamin Publishing Company, 2014.", "J. Eisner. How to read a technical paper. https://www.cs.jhu.edu/ jason/advice/how-to-read-a-paper.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925441"}, {"title": "On Obtaining Effort Based Judgements for Information Retrieval", "authors": ["Manisha Verma\n,", "Emine Yilmaz\n,", "Nick Craswell"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nDocument relevance has been the primary focus in the design, optimization and evaluation of retrieval systems. Traditional testcollections are constructed by asking judges the relevance grade for a document with respect to an input query. Recent work of Yilmaz et al. found an evidence that effort is another important factor in determining document utility, suggesting that more thought should be given into incorporating effort into information retrieval. However, that work did not ask judges to directly assess the level of effort required to consume a document or analyse how effort judgements relate to traditional relevance judgements.\nIn this work, focusing on three aspects associated with effort, we show that it is possible to get judgements of effort from the assessors. We further show that given documents of the same relevance grade, effort needed to find the portion of the document relevant to the query is a significant factor in determining user satisfaction as well as user preference between these documents. Our results suggest that if the end goal is to build retrieval systems that optimize user satisfaction, effort should be included as an additional factor to relevance in building and evaluating retrieval systems. We further show that new retrieval features are needed if the goal is to build retrieval systems that jointly optimize relevance and effort and propose a set of such features. Finally, we focus on the evaluation of retrieval systems and show that incorporating effort into retrieval evaluation could lead to significant differences regarding the performance of retrieval systems.", "references": ["A. Al-Maskari, M. Sanderson, P. Clough, and E. Airio. The good and the bad system: Does the test collection predict users' effectiveness? In Proc. SIGIR, 2008.", "J. Allan, B. Carterette, and J. Lewis. When will information retrieval be \"good enough\"? In Proc. SIGIR, 2005.", "O. Alonso and S. Mizzaro. Using crowdsourcing forTREC relevance assessment. Inf. Process. Manage., 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835840"}, {"title": "A Unified Video Recommendation by Cross-Network User Modeling", "authors": ["Ming Yan\n,", "Jitao Sang\n,", "Changsheng Xu\n,", "M. Shamim Hossain"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nOnline video sharing sites are increasingly encouraging their users to connect to the social network venues such as Facebook and Twitter, with goals to boost user interaction and better disseminate the high-quality video content. This in turn provides huge possibilities to conduct cross-network collaboration for personalized video recommendation. However, very few efforts have been devoted to leveraging users’ social media profiles in the auxiliary network to capture and personalize their video preferences, so as to recommend videos of interest. In this article, we propose a unified YouTube video recommendation solution by transferring and integrating users’ rich social and content information in Twitter network. While general recommender systems often suffer from typical problems like cold-start and data sparsity, our proposed recommendation solution is able to effectively learn from users’ abundant auxiliary information on Twitter for enhanced user modeling and well address the typical problems in a unified framework. In this framework, two stages are mainly involved: (1) auxiliary-network data transfer, where user preferences are transferred from an auxiliary network by learning cross-network knowledge associations; and (2) cross-network data integration, where transferred user preferences are integrated with the observed behaviors on a target network in an adaptive fashion. Experimental results show that the proposed cross-network collaborative solution achieves superior performance not only in terms of accuracy, but also in improving the diversity and novelty of the recommended videos.", "references": ["Fabian Abel, Samur Araújo, Qi Gao, and Geert-Jan Houben. 2011. Analyzing cross-system user modeling on the social web. In Web Engineering. Springer, 28--43.", "Marko Balabanović and Yoav Shoham. 1997. Fab: Content-based, collaborative recommendation. Communications of the ACM 40, 3 (1997), 66--72.", "Marko Balabanović and Yoav Shohom. 1997. Content-based, callaborative recommendation. Communications of the ACM 40, 3 (1997)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957755"}, {"title": "Audio Event Detection using Weakly Labeled Data", "authors": ["Anurag Kumar\n,", "Bhiksha Raj"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nAcoustic event detection is essential for content analysis and description of multimedia recordings. The majority of current literature on the topic learns the detectors through fully-supervised techniques employing strongly labeled data. However, the labels available for majority of multimedia data are generally weak and do not provide sufficient detail for such methods to be employed. In this paper we propose a framework for learning acoustic event detectors using only weakly labeled data. We first show that audio event detection using weak labels can be formulated as an Multiple Instance Learning problem. We then suggest two frameworks for solving multiple-instance learning, one based on support vector machines, and the other on neural networks. The proposed methods can help in removing the time consuming and expensive process of manually annotating data to facilitate fully supervised learning. Moreover, it can not only detect events in a recording but can also provide temporal locations of events in the recording. This helps in obtaining a complete description of the recording and is notable since temporal information was never known in the first place in weakly labeled data.", "references": ["Multimedia event detection. http://www.nist.gov/itl/iad/mig/med11.cfm.", "Youtube statistics. http://www.youtube.com/yt/press/statistics.html.", "E. Amid, A. Mesaros, K. J. Palomaki, J. Laaksonen, and M. Kurimo. Unsupervised feature extraction for multimedia event detection and ranking using audio content. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on, pages 5939--5943. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964310"}, {"title": "Dynamically Integrating Item Exposure with Rating Prediction in Collaborative Filtering", "authors": ["Ting-Yi Shih\n,", "Ting-Chang Hou\n,", "Jian-De Jiang\n,", "Yen-Chieh Lien\n,", "Chia-Rui Lin\n,", "Pu-Jen Cheng"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe paper proposes a novel approach to appropriately promote those items with few ratings in collaborative filtering. Different from previous works, we force the items with few ratings to be promoted to the users who would potentially be able to give ratings, and then leverage the gathered user preference to punish the promoted items with low quality intrinsically. By slightly sacrificing the benefit of recommending the best items in terms of user satisfaction, our approach seeks to provide all of the items with a chance to be visible equally. The results of the experiments conducted on MovieLens and Netflix data demonstrate its feasibility.", "references": ["A. S. Harpale and Y. Yang, \"Personalized active learning for collaborative filtering,\" in Proc. of ACM SIGIR Conference, pp. 91--98, 2008.", "Y. Koren, R. Bell, and C. Volinsky, \"Matrix factorization techniques for recommender systems,\" Computer 42(8), pp. 30--37, 2009.", "J.-H. Liu, T. Zhou, Z.-K. Zhang, Z. Yang, C. Liu, and W.-M. Li, \"Promoting cold-start items in recommender systems,\" PLoS ONE 9(12), pp. 1--13, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914769"}, {"title": "Sampling Strategies and Active Learning for Volume Estimation", "authors": ["Haotian Zhang\n,", "Jimmy Lin\n,", "Gordon V. Cormack\n,", "Mark D. Smucker"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper tackles the challenge of accurately and efficiently estimating the number of relevant documents in a collection for a particular topic. One real-world application is estimating the volume of social media posts (e.g., tweets) pertaining to a topic, which is fundamental to tracking the popularity of politicians and brands, the potential sales of a product, etc. Our insight is to leverage active learning techniques to find all the \"easy\" documents, and then to use sampling techniques to infer the number of relevant documents in the residual collection. We propose a simple yet effective technique for determining this \"switchover\" point, which intuitively can be understood as the \"knee\" in an effort vs. recall gain curve, as well as alternative sampling strategies beyond the knee. We show on several TREC datasets and a collection of tweets that our best technique yields more accurate estimates (with the same effort) than several alternatives.", "references": ["M. Bagdouri, W. Webber, D. Lewis, and D. Oard. Towards minimizing the annotation cost of certified text classification. CIKM, 2013.", "P. Bommannavar, J. Lin, and A. Rajaraman. Estimating topical volume in social media streams. SAC, 2016.", "G. Cormack and M. Grossman. Autonomy and reliability of continuous active learning for technology-assisted review. arXiv:1504.06868v1, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914685"}, {"title": "Interactive Information Retrieval: An Evaluation Perspective", "authors": ["Pia Borlund"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThis presentation addresses methodological issues of interactive information retrieval (IIR) evaluation in terms of what it entails to study users' use and interaction with IR systems, as well as their satisfaction with retrieved information. In particular, the presentation focuses on test design, and it takes a look into the toolbox of IIR test design with reference to data collection methods and test procedure. It calls for careful and well-planned studies to qualify the knowledgebase generated as a result of the conducted IIR studies. The presentation further reflects on the need for an updated theoretical framework to describe partly the various types of IIR, and partly how IIR nowadays often is carried out in a seamless task switching IT environment on various platforms, including via apps. This type of environment furthermore calls for new methodologies to study the IIR behaviour in the habitat of the users to ensure a complete and realistic picture to enhance our understanding of IIR.\nThe presentation also reflects on whether a re-thinking of the concept on an information need is necessary. One may ask whether it still makes sense to talk about types of information needs. Or should we rather study IIR from the perspective of search dedication and task load in order to also include everyday life information seeking?\nWith this presentation, the IIR community is invited to an exchange of ideas and is encouraged to engage in collaborations with the solving of these (and other) issues to our joint advantage.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2870648"}, {"title": "Temporal Query Expansion Using a Continuous Hidden Markov Model", "authors": ["Jinfeng Rao\n,", "Jimmy Lin"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nIn standard formulations of pseudo-relevance feedback, document timestamps do not play a role in identifying expansion terms. Yet we know that when searching social media posts such as tweets, relevant documents are bursty and usually occur in temporal clusters. The main insight of our work is that term expansions should be biased to draw from documents that occur in bursty temporal clusters. This is formally captured by a continuous hidden Markov model (cHMM), for which we derive an EM algorithm for parameter estimation. Given a query, we estimate the parameters for a cHMM that best explains the observed distribution of an initial set of retrieved documents, and then use Viterbi decoding to compute the most likely state sequence. In identifying expansion terms, we only select documents from bursty states. Experiments on test collections from the TREC 2011 and 2012 Microblog tracks show that our approach is significantly more effective than the popular RM3 pseudo-relevance feedback model.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, D. Metzler, M. D. Smucker, T. Strohman, H. Turtle, and C. Wade. UMass at TREC 2004: Novelty and HARD. TREC, 2004.", "J. A. Bilmes. A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models. Technical report, International Computer Science Institute, 1998.", "J. Choi and W. B. Croft. Temporal models for microblogs. CIKM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970424"}, {"title": "On Effective Location-Aware Music Recommendation", "authors": ["Zhiyong Cheng\n,", "Jialie Shen"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nRapid advances in mobile devices and cloud-based music service now allow consumers to enjoy music anytime and anywhere. Consequently, there has been an increasing demand in studying intelligent techniques to facilitate context-aware music recommendation. However, one important context that is generally overlooked is user’s venue, which often includes surrounding atmosphere, correlates with activities, and greatly influences the user’s music preferences. In this article, we present a novel venue-aware music recommender system called VenueMusic to effectively identify suitable songs for various types of popular venues in our daily lives. Toward this goal, a Location-aware Topic Model (LTM) is proposed to (i) mine the common features of songs that are suitable for a venue type in a latent semantic space and (ii) represent songs and venue types in the shared latent space, in which songs and venue types can be directly matched. It is worth mentioning that to discover meaningful latent topics with the LTM, a Music Concept Sequence Generation (MCSG) scheme is designed to extract effective semantic representations for songs. An extensive experimental study based on two large music test collections demonstrates the effectiveness of the proposed topic model and MCSG scheme. The comparisons with state-of-the-art music recommender systems demonstrate the superior performance of VenueMusic system on recommendation accuracy by associating venue and music contents using a latent semantic space. This work is a pioneering study on the development of a venue-aware music recommender system. The results show the importance of considering the influence of venue types in the development of context-aware music recommender systems.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions in Knowledge Data Engineering 17, 6 (2005), 734--749.", "Anupriya Ankolekar and Thomas Sandholm. 2011. Foxtrot: A soundtrack for where you are. In Proceedings of Interacting with Sound Workshop: Exploring Context-Aware, Local and Social Audio Applications. ACM, 26--31.", "Linas Baltrunas, Marius Kaminskas, Bernd Ludwig, Omar Moling, Francesco Ricci, Aykan Aydin, Karl-Heinz Lüke, and Roland Schwaiger. 2011. Incarmusic: Context-aware music recommendations in a car. In Proceedings of the International Conference on Electronic Commerce and Web Technologies. Springer, 89--100."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2846092"}, {"title": "Hierarchical Incomplete Multi-source Feature Learning for Spatiotemporal Event Forecasting", "authors": ["Liang Zhao\n,", "Jieping Ye\n,", "Feng Chen\n,", "Chang-Tien Lu\n,", "Naren Ramakrishnan"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nForecasting significant societal events is an interesting and challenging problem as it taking into consideration multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi source event forecasting has proven promising but still suffers from several challenges, including 1) geographical hierarchies in multi-source data features, 2) missing values, and 3) characterization of structured feature sparsity. This paper proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically, given multi-source data from different geographical levels, we design a new forecasting model by characterizing the lower-level features' dependence on higher-level features. To handle the correlations amidst structured feature sets and deal with missing values among the coupled features, we propose a novel feature learning model based on an $N$th-order strong hierarchy and fused-overlapping group Lasso. An efficient algorithm is developed to optimize model parameters and ensure global optima. Extensive experiments on 10 datasets in different domains demonstrate the effectiveness and efficiency of the proposed model.", "references": ["J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1--8, 2011.", "S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends® in Machine Learning, 3(1):1--122, 2011.", "P. Chakraborty, P. Khadivi, B. Lewis, A. Mahendiran, J. Chen, P. Butler, E. O. Nsoesie, S. R. Mekaru, J. S. Brownstein, M. Marathe, et al. Forecasting a moving target: Ensemble models for ILI case count predictions. In SDM 2014, pages 262--270, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939847"}, {"title": "Generalized BROOF-L2R: A General Framework for Learning to Rank Based on Boosting and Random Forests", "authors": ["Clebson C.A. de Sá\n,", "Marcos A. Gonçalves\n,", "Daniel X. Sousa\n,", "Thiago Salles"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe task of retrieving information that really matters to the users is considered hard when taking into consideration the current and increasingly amount of available information. To improve the effectiveness of this information seeking task, systems have relied on the combination of many predictors by means of machine learning methods, a task also known as learning to rank (L2R). The most effective learning methods for this task are based on ensembles of tress (e.g., Random Forests) and/or boosting techniques (e.g., RankBoost, MART, LambdaMART). In this paper, we propose a general framework that smoothly combines ensembles of additive trees, specifically Random Forests, with Boosting in a original way for the task of L2R. In particular, we exploit out-of-bag samples as well as a selective weight updating strategy (according to the out-of-bag samples) to effectively enhance the ranking performance. We instantiate such a general framework by considering different loss functions, different ways of weighting the weak learners as well as different types of weak learners. In our experiments our rankers were able to outperform all state-of-the-art baselines in all considered datasets, using just a small percentage of the original training set and faster convergence rates.", "references": ["L. Breiman. Random forests. Mach. Learn., 45(1):5--32, 2001.", "R. Busa-Fekete, B. Kégl, T. Éltetö, and G. Szarvas. Tune and mix: learning to rank using ensembles of calibrated multi-class classifiers. Machine Learning, 93(2):261--292, 2013.", "S. D. Canuto, F. M. Belém, J. M. Almeida, and M. A. Gonçalves. A comparative study of learning-to-rank techniques for tag recommendation. JIDM, 4(3):453--468, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911540"}, {"title": "Web Search", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915042"}, {"title": "QUINT: On Query-Specific Optimal Networks", "authors": ["Liangyue Li\n,", "Yuan Yao\n,", "Jie Tang\n,", "Wei Fan\n,", "Hanghang Tong"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nMeasuring node proximity on large scale networks is a fundamental building block in many application domains, ranging from computer vision, e-commerce, social networks, software engineering, disaster management to biology and epidemiology. The state of the art (e.g., random walk based methods) typically assumes the input network is given a priori, with the known network topology and the associated edge weights. A few recent works aim to further infer the optimal edge weights based on the side information. This paper generalizes the challenge in multiple dimensions, aiming to learn optimal networks for node proximity measures. First (optimization scope), our proposed formulation explores a much larger parameter space, so that it is able to simultaneously infer the optimal network topology and the associated edge weights. This is important as a noisy or missing edge could greatly mislead the network node proximity measures. Second (optimization granularity), while all the existing works assume one common optimal network, be it given as the input or learned by the algorithms, exists for all queries, our method performs optimization at a much finer granularity, essentially being able to infer an optimal network that is specific to a given query. Third (optimization efficiency), we carefully design our algorithms with a linear complexity wrt the neighborhood size of the user preference set. We perform extensive empirical evaluations on a diverse set of 10+ real networks, which show that the proposed algorithms (1) consistently outperform the existing methods on all six commonly used metrics; (2) empirically scale sub-linearly to billion-scale networks and (3) respond in a fraction of a second.", "references": ["L. A. Adamic and E. Adar. Friends and neighbors on the web. Social networks, 25(3):211--230, 2003.", "A. Agarwal and S. Chakrabarti. Learning random walks to rank nodes in graphs. In ICML, 2007.", "A. Agarwal, S. Chakrabarti, and S. Aggarwal. Learning to rank networked entities. In KDD, pages 14--23. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939768"}, {"title": "Leveraging Contextual Cues for Generating Basketball Highlights", "authors": ["Vinay Bettadapura\n,", "Caroline Pantofaru\n,", "Irfan Essa"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe massive growth of sports videos has resulted in a need for automatic generation of sports highlights that are comparable in quality to the hand-edited highlights produced by broadcasters such as ESPN. Unlike previous works that mostly use audio-visual cues derived from the video, we propose an approach that additionally leverages contextual cues derived from the environment that the game is being played in. The contextual cues provide information about the excitement levels in the game, which can be ranked and selected to automatically produce high-quality basketball highlights. We introduce a new dataset of 25 NCAA games along with their play-by-play stats and the ground-truth excitement data for each basket. We explore the informativeness of five different cues derived from the video and from the environment through user studies. Our experiments show that for our study participants, the highlights produced by our system are comparable to the ones produced by ESPN for the same games.", "references": ["Gallup sports popularity survey. http://www.gallup.com/poll/4735/sports.aspx.", "A. Ekin, A. M. Tekalp, and R. Mehrotra. Automatic soccer video analysis and summarization. IEEE Transactions on Image Processing, 12(7):796--807, 2003.", "J. L. Fleiss and J. Cohen. The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability. Educational and psychological measurement, 1973."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964286"}, {"title": "An approach to identify user interest by reranking personalize web", "authors": ["Patel Jay\n,", "Pinal Shah\n,", "Kamlesh Makvana\n,", "Parth Shah"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nThe existence of abundance information, in combination with the heterogeneous and dynamic nature of the web, makes web exploration a complex process for the average end user. Lower ability of user to precisely express the need and ambiguous queries are the challenging obstacle in improving search results. Retrieved results are sometimes not of user relevance due to keyword based search, so to fill the gap between retrieved result and user interest we need to personalize the results. For example, a biologist and a programmer may use the same query \"mouse\" with different search context, but the search systems would return same results.. In this paper we proposed an architecture that attempts to identify user search context by analyzing and mapping semantic data using semantic similarity to predict the query topic.", "references": ["Patel Jay, Pinal Shah, Makvana Kamlesh and Parth Shah. \"Review on web search personalization through semantic data\" Electrical, Computer and communication Technologies (ICECCT), 2015 International Conference on IEEE, 2015.", "Makvana Kamlesh, Pinal Shah and Parth Shah. \"A novel approach to personalize web search through user profiling and query reformulation\" Data Mining and Intelligent Computing (ICDMIC), 2014 International Conference on IEEE, 2014.", "Pannu, Mandeep, RachidAnane, and Anne James. \"Hybrid profiling in information retrieval.\" Computer Supported Cooperative Work in Design (CSCWD), 2013 IEEE 17th International Conference on. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905270"}, {"title": "Design is Not What You Think It Is", "authors": ["Peter Bil'ak"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nIn this talk, Peter Bil'ak will examine the ways that current publishing practices are rooted in the 19th century, and how in order to move forward, we may have to go back to the roots and reconnect with readers. He will also talk about his recent project, Works That Work magazine, which set out to rethink publishing paradigms, starting with its financing, distribution and production. Works That Work aims to discuss design outside of the traditional design discourse, and Peter Bil'ak will argue for widening the understanding of the design discipline.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967145"}, {"title": "Understanding and Predicting Online Food Recipe Production Patterns", "authors": ["Tomasz Kusmierczyk\n,", "Christoph Trattner\n,", "Kjetil Nørvåg"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nStudying online food patterns has recently become an active field of research. While there are a growing body of studies that investigate how online food in consumed, little effort has been devoted yet to understand how online food recipes are being created. To contribute to this lack of knowledge in the area, we present in this paper the results of a large-scale study that aims at understanding how historical, social and temporal factors impact on the online food creation process. Several experiments reveal the extent to which various factors are useful in predicting future recipe production.", "references": ["S. Abbar, Y. Mejova, and I. Weber. You tweet what you eat: Studying food consumption through twitter. In Proc. of CHI'15, 2015.", "Y.-Y. Ahn, S. E. Ahnert, J. P. Bagrow, and A.-L. Barabási. Flavor network and the principles of food pairing. Scientific reports, 1, 2011.", "S. Berkovsky and J. Freyne. Group-based recipe recommendations: Analysis of data aggregation strategies. In Proc. of RecSys '10, pages 111--118, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914632"}, {"title": "Discrete Collaborative Filtering", "authors": ["Hanwang Zhang\n,", "Fumin Shen\n,", "Wei Liu\n,", "Xiangnan He\n,", "Huanbo Luan\n,", "Tat-Seng Chua"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe address the efficiency problem of Collaborative Filtering (CF) by hashing users and items as latent vectors in the form of binary codes, so that user-item affinity can be efficiently calculated in a Hamming space. However, existing hashing methods for CF employ binary code learning procedures that most suffer from the challenging discrete constraints. Hence, those methods generally adopt a two-stage learning scheme composed of relaxed optimization via discarding the discrete constraints, followed by binary quantization. We argue that such a scheme will result in a large quantization loss, which especially compromises the performance of large-scale CF that resorts to longer binary codes. In this paper, we propose a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing. The formulation of DCF has two advantages: 1) the Hamming similarity induced loss that preserves the intrinsic user-item similarity, and 2) the balanced and uncorrelated code constraints that yield compact yet informative binary codes. We devise a computationally efficient algorithm with a rigorous convergence proof of DCF. Through extensive experiments on several real-world benchmarks, we show that DCF consistently outperforms state-of-the-art CF hashing techniques, e.g, though using only 8 bits, DCF is even significantly better than other methods using 128 bits.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 2005.", "D. Agarwal, B.-C. Chen, and P. Elango. Fast online learning through offline initialization for time-sensitive recommendation. In KDD, 2010.", "S. Balakrishnan and S. Chopra. Collaborative ranking. In WSDM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911502"}, {"title": "Quantitative Evaluation of Percussive Gestures by Ranking Trainees versus Teacher", "authors": ["Lei Chen\n,", "Sylvie Gibet\n,", "Pierre-François Marteau\n,", "Fabrice Marandola\n,", "Marcelo M. Wanderley"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nIn this paper we characterize timpani gestures by temporal kinematic features, containing most information responsible for the sound-producing actions. In order to evaluate the feature sets, a classification approach is conducted under three main attack categories (legato, accent and vertical accent) and sub-categories (dynamics, striking position). Two studies are carried out: intra-subject and inter-subjects classification. Results are presented in terms of a quantitative ranking of students, using professional gestures as training set, and their gestures as test set.", "references": ["Bouënard, A. Synthesis of Music Performances: Virtual Character Animation as a Controller of Sound Synthesis. PhD thesis, Université Bretagne Sud, France, 2009.", "Bouënard, A., Gibet, S., and Wanderley, M. M. Hybrid inverse motion control for virtual characters interacting with sound synthesis - Application to percussion motion. The Visual Computer 28, 4 (2012), 357--370.", "Bouënard, A., Wanderley, M., and Gibet, S. Virtual Gesture Control of Sound Synthesis: Analysis and Classification of Percussion Gestures. Acta Acustica united with Acustica 96, 4 (2010), 668--677."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948934"}, {"title": "Measuring Interestingness of Political Documents", "authors": ["Hosein Azarbonyad"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPolitical texts are pervasive on the Web covering laws and policies in national and supranational jurisdictions. Access to this data is crucial for government transparency and accountability to the population. The main aim of our research is developing a ranking method for political documents which captures the interesting content within political documents. Text interestingness is a measure of assessing the quality of documents from users' perspective which shows their willingness to read a document. Different approaches are proposed for measuring the interestingness of texts. In this research we focus on measuring political texts' interestingness. As political data sources, we use publicly available parliamentary proceedings.", "references": ["H. Azarbonyad, F. Saan, M. Dehghani, M. Marx, and J. Kamps. Are topically diverse documents also interesting? CLEF'15, 2015.", "M. Dehghani, H. Azarbonyad, M. Marx, and J. Kamps. Sources of bevidence for automatic indexing of political texts. ECIR'15, 2015.", "M. Derzinski and K. Rohanimanesh. An information theoretic approach to quantifying text interestingness. In NIPS MLNLP, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911485"}, {"title": "Recommending Sellers to Buyers in Virtual Marketplaces Leveraging Social Information", "authors": ["Lukas Eberhard\n,", "Christoph Trattner"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nSocial information such as stated interests or geographic check-ins in social networks has shown to be useful in many recommender tasks recently. Although many successful examples exist, not much attention has been put on exploring the extent to which social impact is useful for the task of recommending sellers to buyers in virtual marketplaces. To contribute to this sparse field of research we collected data of a marketplace and a social network in the virtual world of Second Life and introduced several social features and similarity metrics that we used as input for a user-based $k$-nearest neighbor collaborative filtering method. As our results reveal, most of the types of social information and features which we used are useful to tackle the problem we defined. Social information such as joined groups or stated interests are more useful, while others such as places users have been checking in, do not help much for recommending sellers to buyers. Furthermore, we find that some of the features significantly vary in their predictive power over time, while others show more stable behaviors. This research is relevant for researchers interested in recommender systems and online marketplace research as well as for engineers interested in feature engineering.", "references": ["L. A. Adamic and E. Adar. Friends and neighbors on the web. Social networks, 25(3):211--230, 2003.", "L. Balby Marinho, C. Trattner, and D. Parra. Are real-world place recommender algorithms useful in virtual world environments? In Proc. RecSys'15, pages 245--248. ACM, 2015.", "A.-L. Barabasi and R. Albert. Emergence of Scaling in Random Networks. Science, 286(5439):509--512, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890086"}, {"title": "Prototyping interactions with Online Multimodal Repositories and Interactive Machine Learning", "authors": ["Carles F. Juliá\n,", "Panos Papiotis\n,", "Sebastian Mealla Cincuegrani\n,", "Sergi Jordá"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nInteraction designers often use machine learning tools to generate intuitive mappings between complex inputs and outputs. These tools are usually trained live, which is not always feasible or practical. We combine RepoVizz, an online repository and visualizer for multimodal data, with a suite of Interactive Machine Learning tools, to demonstrate a technical solution for prototyping multimodal interactions that decouples the data acquisition step from the model training step. This way, different input data set-ups can be easily replicated, shared and experimented upon their capability to control complex output without the need to repeat the technical set-up.", "references": ["Caramiaux, B., Montecchio, N., Tanaka, A., and Bevilacqua, F. Adaptive Gesture Recognition with Variation Estimation for Interactive Systems. ACM Transactions on Interactive Intelligent Systems 4, 4 (2014), 1--34.", "Fiebrink, R. Real-time interaction with supervised learning. In Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems (2010), 2935--2938.", "Françoise, J., Schnell, N., Borghesi, R., Bevilacqua, F., and Stravinsky, P. I. Probabilistic Models for Designing Motion and Sound Relationships. Proceedings of the International Conference on New Interfaces for Musical Expression (2014), 287--292."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948915"}, {"title": "Improved Caching Techniques for Large-Scale Image Hosting Services", "authors": ["Xiao Bai\n,", "B. Barla Cambazoglu\n,", "Archie Russell"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCommercial image serving systems, such as Flickr and Facebook, rely on large image caches to avoid the retrieval of requested images from the costly backend image store, as much as possible. Such systems serve the same image in different resolutions and, thus, in different sizes to different clients, depending on the properties of the clients' devices. The requested resolutions of images can be cached individually, as in the traditional caches, reducing the backend workload. However, a potentially better approach is to store relatively high-resolution images in the cache and resize them during the retrieval to obtain lower-resolution images. Having this kind of on-the-fly image resizing capability enables image serving systems to deploy more sophisticated caching policies and improve their serving performance further. In this paper, we formalize the static caching problem in image serving systems which provide on-the-fly image resizing functionality in their edge caches or regional caches. We propose two gain-based caching policies that construct a static, fixed-capacity cache to reduce the average serving time of images. The basic idea in the proposed policies is to identify the best resolution(s) of images to be cached so that the average serving time for future image retrieval requests is reduced. We conduct extensive experiments using real-life data access logs obtained from Flickr. We show that one of the proposed caching policies reduces the average response time of the service by up to 4.2% with respect to the best-performing baseline that mainly relies on the access frequency information to make the caching decisions. This improvement implies about 25% reduction in cache size under similar serving time constraints.", "references": ["R. Baeza-Yates, A. Gionis, F. P. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. Design trade-offs for search engine caching. ACM Transactions on the Web, 2(4):20:1--20:28, 2008.", "D. Beaver, S. Kumar, H. C. Li, J. Sobel, and P. Vajgel. Finding a needle in haystack: Facebook's photo storage. In Proc. 9th USENIX Conf. Operating Systems Design and Implementation, pages 1--8, 2010.", "B. B. Cambazoglu and R. A. Baeza-Yates. Scalability Challenges in Web Search Engines. Synthesis Lectures on Information Concepts, Retrieval, and Services. Morgan & Claypool Publishers, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911513"}, {"title": "Answering Twitter Questions: a Model for Recommending Answerers through Social Collaboration", "authors": ["Laure Soulier\n,", "Lynda Tamine\n,", "Gia-Hung Nguyen"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we specifically consider the challenging task of solving a question posted on Twitter. The latter generally remains unanswered and most of the replies, if any, are only from members of the questioner's neighborhood. As outlined in previous work related to community Q&A, we believe that question-answering is a collaborative process and that the relevant answer to a question post is an aggregation of answer nuggets posted by a group of relevant users. Thus, the problem of identifying the relevant answer turns into the problem of identifying the right group of users who would provide useful answers and would possibly be willing to collaborate together in the long-term. Accordingly, we present a novel method, called CRAQ, that is built on the collaboration paradigm and formulated as a group entropy optimization problem. To optimize the quality of the group, an information gain measure is used to select the most likely ``informative\" users according to topical and collaboration likelihood predictive features. Crowd-based experiments performed on two crisis-related Twitter datasets demonstrate the effectiveness of our collaborative-based answering approach.", "references": ["I. Abraham, O. Alonso, V. Kandylas, R. Patel, S. Shelford, and A. Slivkins. Using worker quality scores to improve stopping rules. In SIGIR. ACM, 2016.", "L. E. Agustín-Blas, S. Salcedo-Sanz, E. G. Ortiz-García, A. Portilla-Figueras, A. M. Pérez-Bellido, and S. Jiménez-Fernández. Team formation based on group technology: A hybrid grouping genetic algorithm approach. Computers & Operations Research, 38(2):484--495, 2011.", "G. Barbara. Collaborating: finding common ground for multiparty problems. Jossey-Bass, 1989."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983771"}, {"title": "Rich data, poor fields", "authors": ["Tom Geller"], "publication": "Communications of the ACM", "abstract": "Abstract\nDiverse technologies help farmers produce food in resource-poor areas.", "references": ["Pongnumkul, S., Chaovalit, P., and Surasvadi, N. (2015). Applications of Smartphone-Based Sensors in Agriculture: A Systematic Review of Research. Journal of Sensors, 2015.", "Hengl, T., Heuvelink, G. B., Kempen, B., Leenaars, J. G., Walsh, M. G., Shepherd, K. D., and Tondoh, J. E. (2015). Mapping soil properties of Africa at 250 m resolution: Random forests significantly improve current predictions. PloS one, 10(6), e0125814.", "Derda, R., Gitaka, J., Klapperich, C. M., Mace, C. R., Kumar, A. A., Lieberman, M., and Yager, P. (2015). Enabling the Development and Deployment of Next Generation Point-of-Care Diagnostics, PLOS Negelected Tropical Diseases, http://bit.ly/1PnG40F. z."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2874309"}, {"title": "Contextual Support for Collaborative Information Retrieval", "authors": ["Shuguang Han\n,", "Daqing He\n,", "Zhen Yue\n,", "Jiepu Jiang"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nRecent research shows that Collaborative Information Retrieval (CIR), in which two or more users collaborate on the same search task, has become increasingly popular. The presence of both search and collaboration behaviors makes CIR a complex search format, which further drives a critical need to understand CIR's search context. The contextual support for CIR should consider search contexts derived from both team members' search histories (including users' own search histories and partners' search histories) and their explicit collaboration (e.g., chatting). As it stands, existing studies on contextual search support only focus on Individual Information Retrieval (IIR) and only utilize individuals' own search histories. In this paper, we examine the unique search contexts (e.g., partners' search histories and team collaboration histories) in CIR. Based on a user study data collection with 54 participants, we find that compared to the use of individuals' own search histories, CIR contextual support is more effective when utilizing partners' search histories and teams' collaboration behaviors. More interestingly, though the explicit communication information (i.e., chat content) often involves massive noisy information, involving such noise does not affect the ranking of relevant documents since it also does not appear in relevant documents.", "references": ["R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern information retrieval, volume 463. ACM press, 1999.", "S. Bateman, C. Gutwin, and G. McCalla. Social navigation for loosely-coupled information seeking in tightly-knit groups using webwear. In Proceedings of the 2013 conference on Computer supported cooperative work, pages 955--966. ACM, 2013.", "P. Bennett, R. White, W. Chu, S. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short-and long-term behavior on searchpersonalization. In Proceedings of the 35th ACM SIGIR conference on Research and development in information retrieval, pages 185--194, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854963"}, {"title": "Civic CrowdAnalytics: making sense of crowdsourced civic input with big data tools", "authors": ["Tanja Aitamurto\n,", "Kaiping Chen\n,", "Ahmed Cherif\n,", "Jorge Saldivar Galli\n,", "Luis Santana"], "publication": "AcademicMindtrek '16: Proceedings of the 20th International Academic Mindtrek Conference", "abstract": "ABSTRACT\nThis paper examines the impact of crowdsourcing on a policymaking process by using a novel data analytics tool called Civic CrowdAnalytics, applying Natural Language Processing (NLP) methods such as concept extraction, word association and sentiment analysis. By drawing on data from a crowdsourced urban planning process in the City of Palo Alto in California, we examine the influence of civic input on the city's Comprehensive City Plan update. The findings show that the impact of citizens' voices depends on the volume and the tone of their demands. A higher demand with a stronger tone results in more policy changes. We also found an interesting and unexpected result: the city government in Palo Alto mirrors more or less the online crowd's voice while citizen representatives rather filter than mirror the crowd's will. While NLP methods show promise in making the analysis of the crowdsourced input more efficient, there are several issues. The accuracy rates should be improved. Furthermore, there is still considerable amount of human work in training the algorithm.", "references": ["Aitamurto, T. 2016. Collective Intelligence in Law Reforms: When the Logic of the Crowds and the Logic of Policymaking Collide. 49th Hawaii International Conference on System Sciences, HICSS. Kauai, January 5--8, 2016. IEEE Transactions, pp. 2780--2789.", "Aitamurto, T. and Landemore, H. 2016. Crowdsourced Deliberation: The Case of the Law on Off-Road Traffic in Finland. Policy&Internet 7 (2) 174--196.", "Aitamurto, T. and Landemore, H. 2015. Five Design Principles for Crowdsourced Policymaking: Assessing the Case of Crowdsourced Off-Road Traffic law in Finland. Journal of Social Media for Organizations, vol. 2, no. 1, pp. 1--19."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994310.2994366"}, {"title": "Performance Evaluation Methods of Computer Vision Systems for Meal Assessment", "authors": ["Marios Anthimopoulos\n,", "Joachim Dehais\n,", "Stavroula Mougiakakou"], "publication": "MADiMa '16: Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management", "abstract": "ABSTRACT\nSeveral systems have been proposed for the automatic food intake assessment and dietary support by analyzing meal images captured by smartphones. A typical system consists of computational stages that detect/segment the existing foods, recognize each of them, compute their volume, and finally estimate the corresponding nutritional information. Although this newborn field has made remarkable progress over the last years, the lack of standardized datasets and established evaluation frameworks has made difficult the comparison between methods and eventually prevented the formal definition of the problem. In this paper, we present an overview of the datasets and protocols used for evaluating the computer vision stages of the proposed automatic meal assessment systems.", "references": ["Miyano R., Uematsu Y., and Saito H. Food region detection using bag of features representation and color feature. In Proceedings of the International Conference on Computer Vision Theory and Applications (Rome, Italy, February 24--26, 2012), 709", "Eskin Y., Mihailidis A. An intelligent nutritional assessment system. In AAAI Fall Symposium: Artificial Intelligence for Gerontechnology(Arlington, USA, November 2--1, 2012) , 2--7", "Morikawa C., Sugiyama H., Aizawa K., Food region segmentation in meal images using touch points, in ACM Workshop on Multimedia for cooking and eating activities, 2012"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986035.2986045"}, {"title": "BASS: Improving I/O Performance for Cloud Block Storage via Byte-Addressable Storage Stack", "authors": ["Hui Lu\n,", "Brendan Saltaformaggio\n,", "Cong Xu\n,", "Umesh Bellur\n,", "Dongyan Xu"], "publication": "SoCC '16: Proceedings of the Seventh ACM Symposium on Cloud Computing", "abstract": "ABSTRACT\nIn an Infrastructure-as-a-Service cloud, cloud block storage offers conventional, block-level storage resources via a storage area network. However, compared to local storage, this multilayered cloud storage model imposes considerable I/O overheads due to much longer I/O path in the virtualized cloud. In this paper, we propose a novel byte-addressable storage stack, BASS, to bridge the addressability gap between the storage and network stacks in cloud, and in return boost I/O performance for cloud block storage. Equipped with byte-addressability, BASS not only avails the benefits of using variable-length I/O requests that avoid unnecessary data transfer, but also enables a highly efficient non-blocking approach that eliminates the blocking of write processes. We have developed a generic prototype of BASS based on Linux storage stack, which is applicable to traditional VMs, lightweight containers and physical machines. Our extensive evaluation with micro-benchmarks, I/O traces and real-world applications demonstrates the effectiveness of BASS, with significantly improved I/O performance and reduced storage network usage.", "references": ["Fio - flexible I/O tester synthetic benchmark. http://www.storagereview.com/fio_flexible_i_o_tester_synthetic_benchmark.", "Linux scsi target framework. http://stgt.sourceforge.net/.", "Mobibench traces. https://github.com/ESOSLab/Mobibench/tree/master/MobiGen."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987550.2987557"}, {"title": "A Software Ecosystem approach to e-Learning domain", "authors": ["Welington Veiga\n,", "Fernanda Campos\n,", "Regina Braga\n,", "Jose M. David"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe e-learning domain is characterized by fragmented solutions and multiple similar implementations. This paper presents an approach to enable the development, sharing and reuse of educational services through the Software Ecosystem perspective, through the extension of existing systems information of elearning environments, known as Virtual Learning environments. To become platforms of an ecosystem that enables interorganizational collaboration. The proposal was evaluated by a case study, to verify its feasibility, as well as the concepts, architecture and technologies used.", "references": ["Experience API (xAPI). Acessado em 12 de outubro de 2015, de Advanced Distributed Learning http://www.adlnet.gov/tla/experience-api.", "Anrdt, J. E Dibbern, J. Co-Innovation in a Service Oriented Strategic Network. IEEE International Conference on Services Computing, 2006.SCC '06., p. 285 - 288. 2006.", "Barbosa, O. Santos, R.; Alves, C.; Werner, C. e Jansen, S. Chapter 4: A systematic mapping study on software ecosystems from a three-dimensional perspective. Software Ecosystems: Analyzing and Managing Business Networks in the Software Industry. Edward Elgar Publishing, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022051"}, {"title": "A Mathematical Information Retrieval System Based on RankBoost", "authors": ["Ke Yuan\n,", "Liangcai Gao\n,", "Yuehan Wang\n,", "Xiaohan Yi\n,", "Zhi Tang"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nMathematical Information Retrieval (MIR) systems are designed to help users to find related formulae and further understand the formulae in scientific documents. However, in existing MIR systems, nearly all the ranker models of MIR systems are based on tf-idf model, and few efforts have been made to discover the features besides the relevance between the query formula and related formulae. In this paper, we investigate a supervised ranking approach (RankBoost) in an MIR system, and we consider not only the relevance between a query formula and related formulae, but also the features of the query formula itself and plentiful features about the documents where the related formulae appear. Experimental results show that our system achieves better performance by comparing with state-of-the-art MIR systems.", "references": ["Wang, Y., Gao, L., el at. WikiMirs 3.0: A Hybrid MIR System Based on the Context, Structure and Importance of Formulae in a Document. JCDL'15. 173--182. ACM. 2015.", "Lin, X., Gao, L., el at. A mathematics retrieval system for formulae in layout presentation. SIGIR. 697--706. ACM, 2014.", "Freund, Y., Iyer, R., et al. An efficient boosting algorithm for combining preferences. JMLR. 4: 933--969. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925460"}, {"title": "Targeted Topic Modeling for Focused Analysis", "authors": ["Shuai Wang\n,", "Zhiyuan Chen\n,", "Geli Fei\n,", "Bing Liu\n,", "Sherry Emery"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nOne of the overarching tasks of document analysis is to find what topics people talk about. One of the main techniques for this purpose is topic modeling. So far many models have been proposed. However, the existing models typically perform full analysis on the whole data to find all topics. This is certainly useful, but in practice we found that the user almost always also wants to perform more detailed analyses on some specific aspects, which we refer to as targets (or targeted aspects). Current full-analysis models are not suitable for such analyses as their generated topics are often too coarse and may not even be on target. For example, given a set of tweets about e-cigarette, one may want to find out what topics under discussion are specifically related to children. Likewise, given a collection of online reviews about a camera, a consumer or camera manufacturer may be interested in finding out all topics about the camera's screen, the targeted aspect. As we will see in our experiments, current full topic models are ineffective for such targeted analyses. This paper studies this problem and proposes a novel targeted topic model (TTM) to enable focused analyses on any specific aspect of interest. Our experimental results demonstrate the effectiveness of the TTM.", "references": ["D. Andrzejewski, X. Zhu, and M. Craven. Incorporating domain knowledge into topic modeling via dirichlet forest priors. In ICML, pages 25--32. ACM, 2009.", "C. Archambeau, B. Lakshminarayanan, and G. Bouchard. Latent ibp compound dirichlet allocation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 37(2):321--333, 2015.", "Y. Bengio, A. C. Courville, and J. S. Bergstra. Unsupervised models of images by spike-and-slab rbms. In ICML, pages 1145--1152, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939743"}, {"title": "Finding News Citations for Wikipedia", "authors": ["Besnik Fetahu\n,", "Katja Markert\n,", "Wolfgang Nejdl\n,", "Avishek Anand"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAn important editing policy in Wikipedia is to provide citations for added statements in Wikipedia pages, where statements can be arbitrary pieces of text, ranging from a sentence to a paragraph. In many cases citations are either outdated or missing altogether.\nIn this work we address the problem of finding and updating news citations for statements in entity pages. We propose a two-stage supervised approach for this problem. In the first step, we construct a classifier to find out whether statements need a news citation or other kinds of citations (web, book, journal, etc.). In the second step, we develop a news citation algorithm for Wikipedia statements, which recommends appropriate citations from a given news collection. Apart from IR techniques that use the statement to query the news collection, we also formalize three properties of an appropriate citation, namely: (i) the citation should entail the Wikipedia statement, (ii) the statement should be central to the citation, and (iii) the citation should be from an authoritative source.\nWe perform an extensive evaluation of both steps, using 20 million articles from a real-world news collection. Our results are quite promising, and show that we can perform this task with high precision and at scale.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20.", "M. Anderka, B. Stein, and N. Lipka. Predicting quality flaws in user-generated content: the case of wikipedia. In The 35th ACM SIGIR, Portland, USA, 2012.", "K. Balog and H. Ramampiaro. Cumulative citation recommendation: classification vs. ranking. In 36th ACM SIGIR, Dublin, Ireland, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983808"}, {"title": "Cross-modal Retrieval by Real Label Partial Least Squares", "authors": ["Jianfeng He\n,", "Bingpeng Ma\n,", "Shuhui Wang\n,", "Yugui Liu\n,", "Qingming Huang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper proposes a novel method named Real Label Partial Least Squares (RL-PLS) for the task of cross-modal retrieval. Pervious works just take the texts and images as two modalities in PLS. But in RL-PLS, considering that the class label is more related to the semantics directly, we take the class label as the assistant modality. Specially, we build two KPLS models and project both images and texts into the label space. Then, the similarity of images and texts can be measured more accurately in the label space. Furthermore, we do not restrict the label indicator values as the binary values as the traditional methods. By contraries, in RL-PLS, the label indicator values are set to the real values. Specially, the label indicator values are comprised by two parts: positive or negative represents the sample class while the absolute value represents the local structure in the class. By this way, the discriminate ability of RL-PLS is improved greatly. To show the effectiveness of RL-PLS, the experiments are conducted on two cross-modal retrieval tasks (Wiki and Pascal Voc2007), on which the competitive results are obtained.", "references": ["J. Costa P, E. Coviello, G. Doyle, N. Rasiwasia, G. Lanckriet, R. Levy, and N. Vasconcelos. On the role of correlation and abstraction in cross-modal multimedia retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(3):521--535, 2014.", "B. Ding and R. Gentleman. Classification using generalized partial least squares. Journal of Computational and Graphical Statistics, pages 280--298, 2012.", "M. Everingham, L. Van Gool, C. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge 2007 (voc 2007) results. 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967216"}, {"title": "From More-Like-This to Better-Than-This: Hotel Recommendations from User Generated Reviews", "authors": ["Ruihai Dong\n,", "Barry Smyth"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nTo help users discover relevant products and items recommender systems must learn about the likes and dislikes of users and the pros and cons of items. In this paper, we present a novel approach to building rich feature-based user profiles and item descriptions by mining user-generated reviews. We show how this information can be integrated into recommender systems to deliver better recommendations and an improved user experience.", "references": ["Chen, L., Chen, G., and Wang, F. Recommender systems based on user reviews: the state of the art. User Modeling and User-Adapted Interaction 25, 2 (2015), 99--154.", "Dong, R., O'Mahony, M. P., Schaal, M., McCarthy, K., and Smyth, B. Combining similarity and sentiment in opinion mining for product recommendation. Journal of Intelligent Information Systems (2015), 1--28.", "Dong, R., O'Mahony, M. P., and Smyth, B. Further Experiments in Opinionated Product Recommendation. In Proceedings of The 22nd International Conference on Case-Based Reasoning (Cork, Ireland, Sept. 2014), 110--124."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930276"}, {"title": "Detecting Promotion Campaigns in Query Auto Completion", "authors": ["Yuli LIU\n,", "Yiqun Liu\n,", "Ke Zhou\n,", "Min Zhang\n,", "Shaoping Ma\n,", "Yue Yin\n,", "Hengliang Luo"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuery Auto Completion (QAC) aims to provide possible suggestions to Web search users from the moment they start entering a query, which is thought to reduce their physical and cognitive efforts in query formulation. However, the QAC has been misused by malicious users, being transformed into a new form of promotion campaign. These malicious users attack the search engines to replace legitimate auto-completion candidate suggestions with manipulated contents. Through this way, they provide a new malicious advertising service to promote their customers' products or services in QAC. To our best knowledge, we are among the first to investigate this new type of Promotion Campaign in QAC (PCQ). Firstly, we look into the causes of PCQ based on practical commercial search query logs. We found that various queries containing certain promotion intents are submitted multiple times to search engines to promote their rankings in QAC. Secondly, an effective promotion query detection framework is proposed by promotion intent propagation on query-user bipartite graph, which takes into account the behavioral characteristics of promotion campaigns. Finally, we extend the query detection framework to promotion target detection to identify the consistent promotion target which is the inherent goal of the promotion campaign. Large-scale manual annotations on practical data set convey both the effectiveness of our proposed algorithm, and an in-depth understanding of PCQ.", "references": ["Bhatia, S. Majumdar, D. and Mitra, P. 2011. Query suggestions in the absence of query logs. In SIGIR'11, ACM, 795--804.", "Hofmann, K. Mitra, B. Radlinski, F. and Shokouhi, M. 2014. An Eye-tracking Study of User Interactions with Query Auto Completion. In CIKM'14, ACM, 549--558.", "Shokouhi, M. and Radinsky, K. 2012. Time-sensitive query auto-completion. In SIGIR'12, ACM, 601--610."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983709"}, {"title": "MultiLanes: Providing Virtualized Storage for OS-Level Virtualization on Manycores", "authors": ["Junbin Kang\n,", "Chunming Hu\n,", "Tianyu Wo\n,", "Ye Zhai\n,", "Benlong Zhang\n,", "Jinpeng Huai"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nOS-level virtualization is often used for server consolidation in data centers because of its high efficiency. However, the sharing of storage stack services among the colocated containers incurs contention on shared kernel data structures and locks within I/O stack, leading to severe performance degradation on manycore platforms incorporating fast storage technologies (e.g., SSDs based on nonvolatile memories).\nThis article presents MultiLanes, a virtualized storage system for OS-level virtualization on manycores. MultiLanes builds an isolated I/O stack on top of a virtualized storage device for each container to eliminate contention on kernel data structures and locks between them, thus scaling them to manycores. Meanwhile, we propose a set of techniques to tune the overhead induced by storage-device virtualization to be negligible, and to scale the virtualized devices to manycores on the host, which itself scales poorly. To reduce the contention within each single container, we further propose SFS, which runs multiple file-system instances through the proposed virtualized storage devices, distributes all files under each directory among the underlying file-system instances, then stacks a unified namespace on top of them.\nThe evaluation of our prototype system built for Linux container (LXC) on a 32-core machine with both a RAM disk and a modern flash-based SSD demonstrates that MultiLanes scales much better than Linux in micro- and macro-benchmarks, bringing significant performance improvements, and that MultiLanes with SFS can further reduce the contention within each single container.", "references": ["Jonathan Appavoo, Dilma Da Silva, Orran Krieger, Marc A. Auslander, Michal Ostrowski, Bryan S. Rosenburg, Amos Waterland, Robert W. Wisniewski, Jimi Xenidis, Michael Stumm, and Livio Soares. 2007. Experience distributing objects in an SMMP OS. ACM Transactions on Computer Systems 25, 3.", "Gaurav Banga, Peter Druschel, and Jeffrey C. Mogul. 1999. Resource containers: A new facility for resource management in server systems. In Proceedings of the 3rd USENIX Symposium on Operating Systems Design and Implementation (OSDI’99).", "Andrew Baumann, Paul Barham, Pierre-Évariste Dagand, Timothy L. Harris, Rebecca Isaacs, Simon Peter, Timothy Roscoe, Adrian Schüpbach, and Akhilesh Singhania. 2009. The multikernel: A new OS architecture for scalable multicore systems. In Proceedings of the 22nd ACM Symposium on Operating Systems Principles (SOSP’09)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801155"}, {"title": "Unsupervised Extraction of Popular Product Attributes from E-Commerce Web Sites by Considering Customer Reviews", "authors": ["Lidong Bing\n,", "Tak-Lam Wong\n,", "Wai Lam"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nWe develop an unsupervised learning framework for extracting popular product attributes from product description pages originated from different E-commerce Web sites. Unlike existing information extraction methods that do not consider the popularity of product attributes, our proposed framework is able to not only detect popular product features from a collection of customer reviews but also map these popular features to the related product attributes. One novelty of our framework is that it can bridge the vocabulary gap between the text in product description pages and the text in customer reviews. Technically, we develop a discriminative graphical model based on hidden Conditional Random Fields. As an unsupervised model, our framework can be easily applied to a variety of new domains and Web sites without the need of labeling training samples. Extensive experiments have been conducted to demonstrate the effectiveness and robustness of our framework.", "references": ["Enrique Alfonseca, Marius Pasca, and Enrique Robledo-Arnuncio. 2010. Acquisition of instance attributes via labeled and related instances. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, New York, NY, 58--65.", "Lidong Bing, Wai Lam, and Yuan Gu. 2011. Towards a unified solution: Data record region detection and segmentation. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management (CIKM’11). ACM, New York, NY, 1265--1274.", "Lidong Bing, Wai Lam, and Tak-Lam Wong. 2013. Wikipedia entity expansion and attribute extraction from the web using semi-supervised learning. In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining (WSDM’13). ACM, New York, NY, USA, 567--576."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857054"}, {"title": "A document query search using an extended centrality with the word2vec", "authors": ["Wooju Kim\n,", "Heewon Jang\n,", "Hak-Jin Kim\n,", "Donghe Kim"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nWhile everyday document search is done by keyword-based queries to search engines, we have situations that need deep search of documents such as scrutinies of patents, legal documents, and so on. In such cases, using document queries, instead of keyword-based queries, can be more helpful because it exploits more information from the query document. This paper studies a scheme of document search based on document queries. In particular, it uses centrality vectors, instead of tf-idf vectors, to represent query documents, combined with the Word2vec method to capture the semantic similarity in contained words. This scheme improves the performance of document search and provides a way to find documents not only lexically, but semantically close to a query document.", "references": ["Mathieu Bastian, Sebastien Heymann, Mathieu Jacomy, et al. Gephi: an open source software for exploring and manipulating networks. ICWSM, 8:361--362, 2009.", "Yoshua Bengio. New distributed probabilistic language models. Dept. IRO, Université de Montréal, Montréal, QC, Canada, Tech. Rep, 1215, 2002.", "Yoshua Bengio and Samy Bengio. Modeling high-dimensional discrete data with multi-layer neural networks. In NIPS, volume 99, pages 400--406, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971617"}, {"title": "Topic Modeling for Short Texts with Auxiliary Word Embeddings", "authors": ["Chenliang Li\n,", "Haoran Wang\n,", "Zhiqian Zhang\n,", "Aixin Sun\n,", "Zongyang Ma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFor many applications that require semantic understanding of short texts, inferring discriminative and coherent latent topics from short texts is a critical and fundamental task. Conventional topic models largely rely on word co-occurrences to derive topics from a collection of documents. However, due to the length of each document, short texts are much more sparse in terms of word co-occurrences. Data sparsity therefore becomes a bottleneck for conventional topic models to achieve good results on short texts. On the other hand, when a human being interprets a piece of short text, the understanding is not solely based on its content words, but also her background knowledge (e.g., semantically related words). The recent advances in word embedding offer effective learning of word semantic relations from a large corpus. Exploiting such auxiliary word embeddings to enrich topic modeling for short texts is the main focus of this paper. To this end, we propose a simple, fast, and effective topic model for short texts, named GPU-DMM. Based on the Dirichlet Multinomial Mixture (DMM) model, GPU-DMM promotes the semantically related words under the same topic during the sampling process by using the generalized Polya urn (GPU) model. In this sense, the background knowledge about word semantic relatedness learned from millions of external documents can be easily exploited to improve topic modeling for short texts. Through extensive experiments on two real-world short text collections in two languages, we show that GPU-DMM achieves comparable or better topic representations than state-of-the-art models, measured by topic coherence. The learned topic representation leads to the best accuracy in text classification task, which is used as an indirect evaluation.", "references": ["Y. Bengio, H. Schwenk, J.-S. Senécal, F. Morin, and J.-L. Gauvain. Neural probabilistic language models. Springer, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 2003.", "J. Chang, S. Gerrish, C. Wang, J. L. Boyd-Graber, and D. M. Blei. Reading tea leaves: How humans interpret topic models. In NIPS, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911499"}, {"title": "To Suggest, or Not to Suggest for Queries with Diverse Intents: Optimizing Search Result Presentation", "authors": ["Makoto P. Kato\n,", "Katsumi Tanaka"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nWe propose a method of optimizing search result presentation for queries with diverse intents, by selectively presenting query suggestions for leading users to more relevant search results. The optimization is based on a probabilistic model of users who click on query suggestions in accordance with their intents, and modified versions of intent-aware evaluation metrics that take into account the co-occurrence between intents. Showing many query suggestions simply increases a chance to satisfy users with diverse intents in this model, while it in fact requires users to spend additional time for scanning and selecting suggestions, and may result in low satisfaction for some users. Therefore, we measured the loss of time caused by query suggestion presentation by conducting a user study in different settings, and included its negative effects in our optimization problem. Our experiments revealed that the optimization of search result presentation significantly improved that of a single ranked list, and was beneficial especially for patient users. Moreover, experimental results showed that our optimization was effective particularly when intents of a query often co-occur with a small subset of intents.", "references": ["Statcounter global stats. Retrieved January 14, 2015, from http://gs.statcounter.com/#desktop+mobile-comparison-ww-monthly-201312-201412.", "M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: a game for modeling different types of web search success using interaction data. In SIGIR, pages 345--354, 2011.", "R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835805"}, {"title": "Images Don't Lie: Transferring Deep Visual Semantic Features to Large-Scale Multimodal Learning to Rank", "authors": ["Corey Lynch\n,", "Kamelia Aryafar\n,", "Josh Attenberg"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nSearch is at the heart of modern e-commerce. As a result, the task of ranking search results automatically (learning to rank) is a multibillion dollar machine learning problem. Traditional models optimize over a few hand-constructed features based on the item's text. In this paper, we introduce a multimodal learning to rank model that combines these traditional features with visual semantic features transferred from a deep convolutional neural network. In a large scale experiment using data from the online marketplace Etsy, we verify that moving to a multimodal representation significantly improves ranking quality. We show how image features can capture fine-grained style information not available in a text-only representation. In addition, we show concrete examples of how image information can successfully disentangle pairs of highly different items that are ranked similarly by a text-only model.", "references": ["Aytar, Y., and Zisserman, A. Tabula rasa: Model transfer for object category detection. In Computer Vision (ICCV), 2011 IEEE International Conference on (2011), IEEE, pp. 2252--2259.", "Bai, B., Weston, J., Grangier, D., Collobert, R., Sadamasa, K., Qi, Y., Chapelle, O., and Weinberger, K. Learning to rank with (a lot of) word features. Information retrieval 13, 3 (2010), 291--314.", "Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N., and Hullender, G. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning (2005), ACM, pp. 89--96."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939728"}, {"title": "Entity Centric Information Retrieval", "authors": ["Xitong Liu"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nIn the past decade, the prosperity of the World Wide Web has led to fast explosion of information, and there is a long-standing demand on how to access such a huge volume of information effectively and efficiently. Information Retrieval (IR) aims to tackle the challenge by exploring approaches to obtain relevant information items (e.g., documents) relevant to a given information need (e.g., query) from a huge collection of textual data (e.g., the Web). Named entity (e.g., person, location, product, event, organization) is a type of term compound widely existing in textual data. Recent advances in Information Extraction make it possible to extract entities from large volume of free text efficiently, and the research community are actively exploring whether entities would contribute to the retrieval effectiveness.\nIn this thesis, we investigate how to leverage entities to improve retrieval in several directions. We start with finding entities with certain semantic relation, which aims at retrieving entities and their associated attributes to meet user's information need directly. This is different from traditional search paradigm in which only documents are retrieved. Entity retrieval is performed by first retrieving a list of documents and then extracting entities from those documents. We propose a novel probabilistic framework which leverages supporting documents as bridge to model the relevance between query and entities and rank entities accordingly.\nOn the other side, we also explore how to leverage entities to improve effectiveness of ad hoc document retrieval in two directions. The first direction is entity-centric query expansion. We find related entities of query, and perform query expansion using the names and relations of related entities. Significant improvements over several state-of-the-art feedback models could be observed on multiple data collections. Besides, we explore another direction: entity-centric relevance modeling. We propose a novel retrieval approach, i.e., Latent Entity Space (LES), which models the relevance by leveraging entity profiles to represent semantic content of documents and queries. Experimental results over several TREC collections show that LES is effective on capturing latent semantic content and can significantly improve the search accuracy of several state-of-the-art retrieval models for entity-bearing queries.\nThis thesis presents a series of research efforts on entity centric information retrieval in several directions, and reveals promising potential of entities on improving the retrieval effectiveness. With the fast curation of high-quality knowledge base, more information about entities could be easily accessed and integrated into retrieval models. We hope our work could serve as guideline for future work on leveraging entities to improve information retrieval in more applications.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964815"}, {"title": "Forensics of High Quality and Nearly Identical JPEG Image Recompression", "authors": ["Cecilia Pasquini\n,", "Pascal Schöttle\n,", "Rainer Böhme\n,", "Giulia Boato\n,", "Fernando Pèrez-Gonzàlez"], "publication": "IH&MMSec '16: Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security", "abstract": "ABSTRACT\nWe address the known problem of detecting a previous compression in JPEG images, focusing on the challenging case of high and very high quality factors (>= 90) as well as repeated compression with identical or nearly identical quality factors. We first revisit the approaches based on Benford--Fourier analysis in the DCT domain and block convergence analysis in the spatial domain. Both were originally conceived for specific scenarios. Leveraging decision tree theory, we design a combined approach complementing the discriminatory capabilities. We obtain a set of novel detectors targeted to high quality grayscale JPEG images.", "references": ["T. Bianchi, A. Piva, and F. Pérez-González. Near optimal detection of quantized signals and application to JPEG forensics. In IEEE Workshop on Informations Forensics and Security (WIFS), 2013.", "L. Breslow and D. Aha. Simplifying decision trees: A survey. The Knowledge Engineering Review, 12(1):1--40, 1997.", "M. Carnein, P. Schöttle, and R. Böhme. Forensics of high-quality JPEG images with color subsampling. In IEEE Workshop on Informations Forensics and Security (WIFS), 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909827.2930787"}, {"title": "MDBSCAN: Multi-level Density Based Spatial Clustering of Applications with Noise", "authors": ["Shimei Wang\n,", "Yun Liu\n,", "Bo Shen"], "publication": "KMO '16: Proceedings of the The 11th International Knowledge Management in Organizations Conference on The changing face of Knowledge Management Impacting Society", "abstract": "ABSTRACT\nWith the rapid development of information technology, more and more complex data has been produced. It has practical significance to mine valuable information from the complex data. Clustering is an important research in the field of data mining. As a density-based clustering algorithm, DBSCAN is sensitive to the input parameters and difficult to find out all the meaningful clusters for datasets with varied densities. Aiming at this shortcoming, this paper proposed the MDBSCAN algorithm. The algorithm can generate two different density parameters by statistical method, and then the clustering can be more accurate for datasets with varied densities. At first, the algorithm uses adjacency list to store the graph generated by the datasets with one parameter Eps. Adjacency list which has been established in the first step is conducive to generate the varied densities parameters MinPts0 and MinPts1. Then, based on the parameters and adjacency list, the clustering algorithm can be implemented more accurately. Finally, compared with algorithm DBSCAN, the experimental results show that the proposed algorithm has higher accuracy in clustering the datasets with varied densities while they have similar running time.", "references": ["J. Han, M. Kamber, J. Pei, Data Mining: Concepts and Techniques, 10.4. Density-Based Methods3rd ed., Elsevier, 2011. 471--479.", "P.N. Tan, M. Steinbach, V. Kumar, Introduction to Data Mining, Ch.8 ClusterAnalysis: Basic Concepts and Algorithms, Pearson, Addison-Wesley, 2006.487--568.", "M. Ester, H.-P. Kriegel, J. Sander, X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. in KDD, Portland, Oregon, USA, August 2--4, 1996, 226--231."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2925995.2926040"}, {"title": "Detecting Cyberbullying using Latent Semantic Indexing", "authors": ["Jacob L. Bigelow\n,", "April Edwards (Kontostathis)\n,", "Lynne Edwards"], "publication": "CyberSafety'16: Proceedings of the First International Workshop on Computational Methods for CyberSafety", "abstract": "ABSTRACT\nCyberbullying has proven consequential to youth Internet users and previous methods relied heavily on the use of manually developed dictionaries. This project describes preliminary results for a system that uses Latent Semantic Indexing (LSI) for the detection of cyberbullying in a labeled collection of posts from Formspring.me. After preprocessing to account for variations in spelling and use of emoticons, a search system was developed. Our system significantly outperforms the baseline with a very simple query and is not dependent on a dictionary of bullying terms.", "references": ["M. W. Berry, S. T. Dumais, and G. W. O'Brien. Using linear algebra for intelligent information retrieval. SIAM Review, 37(4):575--595, 1995.", "bullyingstatistics.com. Bullying statistics. http://www.bullyingstatistics.org/content/cyber-bullying-statistics.html. Accessed: 2016-07-24.", "M. Dadvar and F. de Jong. Cyberbullying detection: A step toward a safer internet yard. In Proceedings of the 21st International Conference on World Wide Web, WWW '12 Companion, pages 121--126, New York, NY, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3002137.3002144"}, {"title": "Collaborative Information Retrieval: Frameworks, Theoretical Models, and Emerging Topics", "authors": ["Lynda Tamine\n,", "Laure Soulier"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nA great amount of research in the IR domain mostly dealt with both the design of enhanced document ranking models allowing search improvement through user-to-system collaboration. However, in addition to user-to-system form of collaboration, user-to-user collaboration is increasingly acknowledged as an effective mean for gathering the complementary skills and/or knowledge of individual users in order to solve complex search tasks. This tutorial will first give an overview of the ways into collaboration has been implemented in IR models with the attempt of improving the search outcomes with respect to several tasks and related frameworks (ad-hoc search, group-based recommendation, social search, collaborative search). Second, as envisioned in collaborative IR domain (CIR), we will focus on the theoretical models that support and drive user-to-user collaboration in order to perform shared IR tasks. Third, we will develop a road map on emerging and relevant topics addressing issues related to collaboration design. Our goal is to provide participants with concepts and motivation allowing them to investigate this emerging IR domain as well as giving them some clues on how to tackle issues related to the optimization of collaborative tasks. More specifically, the tutorial aims to: (a) Give an overview of the key concept of collaboration in IR and related research topics; (b) Present state-of-the art CIR techniques and models; (c) Discuss about the emerging topics that deal with collaboration; (d) Point out some challenges ahead.", "references": ["S. Chang and A. Pal. Routing questions for collaborative answering in community question answering. In ASONAM '13, pages 494--501. ACM, 2013.", "C. Foley and A. F. Smeaton. Synchronous Collaborative Information Retrieval: Techniques and Evaluation. In ECIR '09, pages 42--53. Springer, 2009.", "J. Foster. Collaborative information seeking and retrieval. Annual Review of Information Science & Technology (ARIST), 40(1):329--356, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970442"}, {"title": "Poster: A Real-time Cattle Recognition System using Wireless Multimedia Networks", "authors": ["Santosh Kumar\n,", "Sanjay Kumar Singh\n,", "Tanima Dutta\n,", "Hari Prabhat Gupta"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nIn this paper, we propose a cattle recognition system using wireless multimedia networks. The images are captured and transferred them to the server using Wi-Fi technology. The system performs image pre-processing on the muzzle point image of cattle to mitigate and filter the noise. The system uses support vector machine to classify the extracted feature of the muzzle images of cattle. We use a similarity score measurement for matching the muzzle points with the database. We also developed a prototype for evaluating the accuracy of the system.", "references": ["H. P. Gupta, S. S. Bagi, and A. Uttav. Sensys-A sensor data sharing system for smart devices using bluetooth low energy. In CSAR workshop conjunction with ACM SenSys, pages 53--55, Seoul, South Korea, 2015.", "S. Kumar, S. Tiwari, and S. K. Singh. Face recognition of cattle: Can it be done? Proceedings of the National Academy of Sciences, India Section A: Physical Sciences, 86(2):137--148, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2948871"}, {"title": "Topic Model based Privacy Protection in Personalized Web Search", "authors": ["Wasi Uddin Ahmad\n,", "Md Masudur Rahman\n,", "Hongning Wang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModern search engines utilize users' search history for personalization, which provides more effective, useful and relevant search results. However, it also has the potential risk of revealing users' privacy by identifying their underlying intention from their logged search behaviors. To address this privacy issue, we proposed a Topic-based Privacy Protection solution on client side. In our solution, each user query will be submitted with k additional cover queries, which will act as a proxy to disguise users' intent from a search engine. The set of cover queries are generated in a controlled way so that each query carries similar uncertainty to randomize a user's search history while still providing necessary utility for the search engine to perform personalization. We used statistical topic models to infer topics from the original user query and generated cover queries of similar entropy but from unrelated topics. Extensive experiments are performed on AOL search log and the promising results demonstrated the effectiveness of our solution.", "references": ["M. Barbaro, T. Zeller, and S. Hansell. A face is exposed for aol searcher no. 4417749. New York Times, 9(2008):8For, 2006.", "D. M. Blei. Probabilistic topic models. Communications of the ACM, 55(4):77--84, 2012.", "G. Chen, H. Bai, L. Shou, K. Chen, and Y. Gao. Ups: efficient privacy protection in personalized web search. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 615--624. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914753"}, {"title": "Enhancing Personalized Document Ranking using Social Information", "authors": ["Nawal Ould Amer"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nNo abstract available.", "references": ["S. Bao, G. Xue, X. Wu, Y. Yu, B. Fei, and Z. Su. Optimizing web search using social annotations. In Proceedings of the 16th International Conference on World Wide Web, WWW '07, pages 501--510, New York, NY, USA, 2007. ACM.", "D. Benz, A. Hotho, R. Jaschke, B. Krause, F. Mitzlaff, C. Schmitz, and G. Stumme. The social bookmark and publication management system bibsonomy. The VLDB Journal, 19(6):849--875, Dec. 2010.", "C. Biancalana, F. Gasparetti, A. Micarelli, and G. Sansonetti. Social semantic query expansion. ACM Trans. Intell. Syst. Technol., 4(4):60:1--60:43, Oct. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930374"}, {"title": "Curve Separation for Line Graphs in Scholarly Documents", "authors": ["Sagnik Ray Choudhury\n,", "Shuting Wang\n,", "C. Lee Giles"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nLine graphs are abundant in scholarly papers. They are usually generated from a data table and that data can not be accessed. One important step in an automated data extraction pipeline is the curve separation problem: segmenting the pixels into separate curves. Previous work in this domain has focused on raster graphics extracted from scholarly PDFs, whereas most scholarly plots are embedded as vector graphics. We report a system to extract these plots as SVG images and show how that can improve both the accuracy (90%) and the scalability (5-8 seconds) of the curve separation problem.", "references": ["W. Browuer, S. Kataria, S. Das, P. Mitra, and C. L. Giles. Segregating and extracting overlapping data points in two-dimensional plots. In Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries, JCDL '08, pages 276--279, New York, NY, USA, 2008. ACM.", "C. Clark and S. Divvala. Looking beyond text: Extracting figures, tables, and captions from computer science paper. 2015.", "X. Lu, S. Kataria, W. J. Brouwer, J. Z. Wang, P. Mitra, and C. L. Giles. Automated analysis of images in documents for intelligent document search. IJDAR, 12(2):65--81, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925469"}, {"title": "Fairness in Information Retrieval", "authors": ["Aldo Lipani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe offline evaluation of Information Retrieval (IR) systems is performed through the use of test collections. A test collection, in its essence, is composed of: a collection of documents, a set of topics and, a set of relevance assessments for each topic, derived from the collection of documents. Ideally, for each topic, all the documents of the test collection should be judged, but due to the dimensions of the collections of documents, and their exponential growth over the years, this practice soon became impractical. Therefore, early in IR history, this problem has been addressed through the use of the pooling method. The pooling method consists of optimizing the relevance assessment process by pooling the documents retrieved by different search engines following a particular pooling strategy. The most common one consists on pooling the top d documents of each run. The pool is constructed from systems taking part in a challenge for which the collection was made, at a specific point in time, after which the collection is generally frozen in terms of relevance judgments. This method leads to a bias called pool bias, which is the effect that documents that were not selected in the pool created from the original runs will never be considered relevant. Thereby, this bias affects the evaluation of a system that has not been part of the pool, with any IR evaluation measures, making the comparison with pooled systems unfair.\nIR measures have evolved over the years and become more and more complex and difficult to interpret. Witnessing a need in industry for measures that 'make sense', I focus on the problematics of the two fundamental IR evaluation measures, Precision at cut-off P@n and Recall at cut-off $R@n$. There are two reasons to consider such 'simple' metrics: first, they are cornerstones for many other developed metrics and, second, they are easy to understand by all users. To the eyes of a practitioner, these two evaluation measures are interesting because they lead to more intuitive interpretations like, how much time people are reading useless documents (low precision), or how many relevant documents they are missing (low recall). But this last interpretation, due to the fact that recall is inversely proportional to the number of relevant documents per topic, is very difficult to be addressed if to be judged is just a portion of the collection of documents, as it is done when using the pooling method. To tackle this problem, another kind of evaluation has been developed, based on measuring how much an IR system makes documents accessible. Accessibility measures can be seen as a complementary evaluation to recall because they provide information on whether some relevant documents are not retrieved due to an unfairness in accessibility.\nThe main goal of this Ph.D. is to increase the stability and reusability of existing test collections, when to be evaluated are systems in terms of precision, recall, and accessibility. The outcome will be: the development of a novel estimator to tackle the pool bias issue for P@n, and R@n, a comprehensive analysis of the effect of the estimator on varying pooling strategies, and finally, to support the evaluation of recall, an analytic approach to the evaluation of accessibility measures.", "references": ["L. Azzopardi and V. Vinay. Accessibility in information retrieval. In Proc. of ECIR'08, pages 482--489.", "A. Lipani, M. Lupu, A. Aizawa, and A. Hanbury. An initial analytical exploration of retrievability. In Proc. of ICTIR'15, pages 329--332.", "A. Lipani, M. Lupu, and A. Hanbury. The curious incidence of bias corrections in the pool. In Proc. of ECIR'16, pages 267--279."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911473"}, {"title": "A framework to support effort estimation on software maintenance and evolution activities", "authors": ["Marcos Alexandre Miguel\n,", "Marco Antonio P. Araujo\n,", "Jose Maria N. David\n,", "Regina Braga"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe emergence of agile methods in software development has brought many opportunities and challenges for researchers and professionals. A major challenge is the effort estimate for agile software development. When the estimation of effort is not well defined or is inaccurate, the results can directly reflect the software delivery, causing customer dissatisfaction or decrease the quality of the product, thus leading to the need for new mechanisms that can assist in this process. Given this need, this paper presents a framework, called GiveMe Effort to support the effort estimation activities in the maintenance and evolution of software in agile methods. The solution is based on historical data change requests associated with the maintenance and evolution of software.", "references": ["Tavares, J., David, J. M. N., Araujo, M. A.P., Braga, R., Campos, F. C. A. Carneiro, C. GiveMe Views: uma ferramenta de suporte a evolucao de software baseada na analise de dados historicos. 2015. In Simposio Brasileiro de Sistemas de Informacao (SBSI), 55-62.", "Gestal, P. R. E, Barros, R. M. 2014 Proposta de Um Simulador para Auxiliar no Processo de Ensino do Scrum. In Simposio Brasileiro de Sistemas de Informacao (SBSI), 723- 736.", "Paredes, J., Anslow, C., e Maurer, F. 2014. Information Visualization for Agile Software Development. In Software Visualization (VISSOFT), 2014 Second IEEE Working Conference on. 157-166."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021995"}, {"title": "Coagmento 2.0: A System for Capturing Individual and Group Information Seeking Behavior", "authors": ["Matthew Mitsui\n,", "Chirag Shah"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIn this demo, we present Coagmento 2.0, a Web-based, open-source platform that provides support for one working in individual or group projects spanning multiple sessions that involve looking for, collecting, and synthesizing information. The system also provides a highly customizable platform for researchers who want to investigate individual and group information seeking behaviors in a lab or a field setting. The demo not only shows back-end components and front-end interaction elements of the system, but also how one could easily configure Coagmento for user studies involving information seeking/retrieval with digital libraries (including the Web).", "references": ["S. Amershi and M. R. Morris. Cosearch: A system for co-located collaborative web search. In Proceedings of CHI '08, pages 1647--1656, New York, NY, USA, 2008. ACM.", "X. Fu, D. Kelly, and C. Shah. Using collaborative queries to improve retrieval for difficult topics. In Proceedings of ACM SIGIR '07, New York, NY, USA, 2007. ACM.", "G. Golovchinsky, J. Adcock, J. Pickens, P. Qvarfordt, and M. Back. Cerchiamo: a collaborative exploratory search tool. Proceedings of CSCW, pages 8--12, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925447"}, {"title": "Large-Scale E-Commerce Image Retrieval with Top-Weighted Convolutional Neural Networks", "authors": ["Shichao Zhao\n,", "Youjiang Xu\n,", "Yahong Han"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nSeveral recent researches have shown that image features produced by Convolutional Neural Networks (CNNs) provide the state-of-the-art performance for image classification and retrieval. Moreover, some researchers have found that the features extracted from the deep convolutional layers of CNNs perform better than that from the fully-connected layers. Features extracted from the convolutional layers have a natural interpretation: descriptors of local image regions correspond well to the receptive fields of the particular features. In order to obtain both representative and discriminative descriptors for large-scale e-commerce image retrieval, we come up with a new feature extraction framework. At first, we propose the Top-Weight method to detect the interesting area of e-commerce images automatically. With the estimated weight, we then aggregate local deep features and produce high-quality global representation for e-commerce image retrieval. We have conducted experiments on an e-commerce dataset ALISC [1] released by Alibaba Group. Experimental results show that our method outperforms other deep learning based methods.", "references": ["Alisc. https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.100066.333.11.da8UHF&raceId=231510&lang=enUS, 2015.", "A. Babenko and V. Lempitsky. Aggregating local deep features for image retrieval. In CVPR, pages 1269--1277, 2015.", "A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. In ECCV, pages 584--599. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912052"}, {"title": "Towards a librarian of the web", "authors": ["Mario M. Kubek\n,", "Herwig Unger"], "publication": "ICCIP '16: Proceedings of the 2nd International Conference on Communication and Information Processing", "abstract": "ABSTRACT\nIf the World Wide Web (WWW) is considered to be a huge library, it would need a librarian, too. Google and other web search engines are more or less just keyword databases and cannot fulfil this person's tasks in a sufficient manner. Therefore, an approach to improve cataloguing and classifying documents in the WWW is introduced and its efficiency demonstrated in first simulations.", "references": ["R. Eberhardt, M. Kubek, and H. Unger. Why google isn't the future. Really not. In Autonomous Systems 2015, pages 268--281. VDI Verlag, 2015.", "L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical Report 1999--66, Stanford InfoLab, 1999.", "A. L. A. P. Committee. Presidential committee on information literacy: Final report. Final report, American Library Association, 1989."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3018009.3018031"}, {"title": "On the Applicability of Delicious for Temporal Search on Web Archives", "authors": ["Helge Holzmann\n,", "Wolfgang Nejdl\n,", "Avishek Anand"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb archives are large longitudinal collections that store webpages from the past, which might be missing on the current live Web. Consequently, temporal search over such collections is essential for finding prominent missing webpages and tasks like historical analysis. However, this has been challenging due to the lack of popularity information and proper ground truth to evaluate temporal retrieval models. In this paper we investigate the applicability of external longitudinal resources to identify important and popular websites in the past and analyze the social bookmarking service Delicious for this purpose. The timestamped bookmarks on Delicious provide explicit cues about popular time periods in the past along with relevant descriptors. These are valuable to identify important documents in the past for a given temporal query. Focusing purely on recall, we analyzed more than 12,000 queries and find that using Delicious yields average recall values from 46% up to 100%, when limiting ourselves to the best represented queries in the considered dataset. This constitutes an attractive and low-overhead approach for quick access into Web archives by not dealing with the actual contents.", "references": ["Avishek Anand, Srikanta Bedathur, Klaus Berberich, and Ralf Schenkel. Temporal index sharding for space-time efficiency in archive search. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, 2011.", "Avishek Anand, Srikanta Bedathur, Klaus Berberich, and Ralf Schenkel. Index maintenance for time-travel text search. In Proceedings of the 35th international ACM SIGIR conference on Research and development in Information Retrieval, 2012.", "Klaus Berberich, Srikanta Bedathur, Omar Alonso, and Gerhard Weikum. A language modeling approach for temporal information needs. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914724"}, {"title": "A distantly supervised method for extracting spatio-temporal information from text", "authors": ["Seyed Iman Mirrezaei\n,", "Bruno Martins\n,", "Isabel F. Cruz"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nThis paper describes Triplex-ST, a novel information extraction system for collecting spatio-temporal information from textual resources. Triplex-ST is based on a distantly supervised approach, which leverages rich linguistic annotations together with information in existing knowledge bases. In particular, we leverage triples associated with temporal and/or spatial contexts, e.g., as available from the YAGO knowledge base, so as to infer templates that capture new facts from previously unseen sentences.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. In International Semantic Web Conference (ISWC), pages 722--735, 2007.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: A collaboratively created graph database for structuring human knowledge. In ACM SIGMOD International Conference on Management of Data (SIGMOD), pages 1247--1250, 2008.", "M. Bronzi, Z. Guo, F. Mesquita, D. Barbosa, and P. Merialdo. Automatic Evaluation of Relation Extraction Systems on Large-scale. In Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC), pages 19--24, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996967"}, {"title": "Contextualizing bookmarks: an approach based on user context to improve organization and retrieval of bookmarks", "authors": ["Hyeon Kyeong Hwang\n,", "Marco Ronchetti"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nThe ubiquitous nature of the Web has rendered a vast amount of information accessible on demand transforming itself to be the primary hub of personal and collective knowledge. Consequently it is becoming more challenging to manage such information effectively as we face the era of information overload, a.k.a. infobesity. The most popular way of managing web pages is bookmarking. Bookmarks, however, would serve little purpose if they cannot be easily organized or found for re-use. In this paper, we discuss the pros and cons of current folder and tag-based tools and highlight the role user context plays in information retrieval. Then we propose \"MemoryLane\", a bookmarking tool that offers context-specific tags to help organize and allows navigation of bookmarks by any context users remember.", "references": ["Aula, A., Jhaveri, N., and Kaki, M. 2005. Information Search and Re-access Strategies of Experienced Web Users. In Proc. of the 14th Int'l Conf. World Wide Web (Chiba, Japan, May 10-14, 2005). WWW '05. ACM, New York, NY, 583--592.", "Bischoff, K., S. Firan, C., Nejdl, W. and Raluca, P. 2008. Can All Tags used for Search? In Proceedings of the 17th ACM Conference on Information and Knowledge management (Napa Valley, California, USA, Oct. 26--30, 2008). CIKM '08. ACM, New York, NY, 193--202.", "Civan A., Jones, W., Klasnja, P, and Bruce H. 2008. Better to organize personal information by folders or by tags?: The devil is in the details. Proc.Am.Soc.Info.Sci.Tech., 45: 1--13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908188"}, {"title": "Design of an annotation tool for educational resources", "authors": ["Félix Buendía García"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nAnnotation tools represent a wide set of environments and related technologies that enable to add small pieces of information as comments or tags over different kind of resources. They are very popular in educational and e-learning domains and the current work shows some ideas that deal with their design in the context of a research project to annotate educational resources in Humanities knowledge fields. This paper addresses several design aspects such as the support to the annotation requirements or the separation of concern principle when the different layers of the annotation tool are established. Finally, the design of an application prototype to annotate text documents is described as a case study and some conclusions are drawn.", "references": ["Wolfe, J. 2002. Annotation technologies: A software and research review. Computers and Composition, 19, p. 471--497.", "Glover, I., Xu, Z., & Hardaker, G. 2007. Online annotation - Research and practices. Computers and Education 49(4), 1308--1320.", "Bateman, S., Brooks, C., Mccalla, G., and Brusilovsky, P. 2007. Applying Collaborative Tagging to E-Learning. In Proceedings of the 16th International World Wide Web Conference (WWW2007)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012639"}, {"title": "Yak: a high-performance big-data-friendly garbage collector", "authors": ["Khanh Nguyen\n,", "Lu Fang\n,", "Guoqing Xu\n,", "Brian Demsky\n,", "Shan Lu\n,", "Sanazsadat Alamian\n,", "Onur Mutlu"], "publication": "OSDI'16: Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation", "abstract": "ABSTRACT\nMost \"Big Data\" systems are written in managed languages, such as Java, C#, or Scala. These systems suffer from severe memory problems due to the massive volume of objects created to process input data. Allocating and deallocating a sea of data objects puts a severe strain on existing garbage collectors (GC), leading to high memory management overheads and reduced performance.\nThis paper describes the design and implementation of Yak, a \"Big Data\" friendly garbage collector that provides high throughput and low latency for all JVM-based languages. Yak divides the managed heap into a control space (CS) and a data space (DS), based on the observation that a typical data-intensive system has a clear distinction between a control path and a data path. Objects created in the control path are allocated in the CS and subject to regular tracing GC. The lifetimes of objects in the data path often align with epochs creating them. They are thus allocated in the DS and subject to region-based memory management. Our evaluation with three large systems shows very positive results.", "references": ["AIKEN, A., FÄHNDRICH, M., AND LEVIEN, R. Better static memory management: improving region-based analysis of higher-order languages. In PLDI (1995), pp. 174-185.", "ALSUBAIEE, S., ALTOWIM, Y., ALTWAIJRY, H., BEHM, A., BORKAR, V. R., BU, Y., CAREY, M. J., CETINDIL, I., CHEELANGI, M., FARAAZ, K., GABRIELOVA, E., GROVER, R., HEILBRON, Z., KIM, Y., LI, C., LI, G., OK, J. M., ONOSE, N., PIRZADEH, P., TSOTRAS, V. J., VERNICA, R., WEN, J., AND WESTMANN, T. AsterixDB: A scalable, open source BDMS. Proc. VLDB Endow. 7, 14 (2014), 1905-1916.", "Giraph: Open-source implementation of Pregel. http://incubator.apache.org/giraph/."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3026877.3026905"}, {"title": "HLBPR: A Hybrid Local Bayesian Personal Ranking Method", "authors": ["Xu Chen\n,", "Pengfei Wang\n,", "Zheng Qin\n,", "Yongfeng Zhang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nBayesian Personal Ranking(BPR) method is a well-known model due to its high performance in the task of item recommendation. However, this method fail to distinguish user preference among the non-interacted items. In this paper, to enhance traditional BPR's performance, we introduce and analyse a hybrid method, namely Hybrid Local Bayesian Personal Ranking method(HLBPR for short). Our main idea is to construct additional item preference pairs among the products which haven't been purchased, and then utilize the extened pairs to optimize the ranking object. Experiments on two real-world transaction datasets demonstrated the effectiveness of our approach as compared with the state-of-the-art methods.", "references": ["L. Lerche and D. Jannach. Using graded implicit feedback for bayesian personalized ranking. In Recsys, 2014.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. In UAI, 2009.", "G.-E. Yap, X.-L. Li, and S. Y. Philip. Effective next-items recommendation via personalized sequential pattern mining. In Database Systems for Advanced Applications, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889349"}, {"title": "Poster: Sentiment Analysis of BGM Toward Automatic BGM Selection Based on Emotion", "authors": ["N'djabli Cedric Ange Konan\n,", "Hirohiko Suwa\n,", "Yutaka Arakawa\n,", "Keiichi Yasumoto"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nIt is essential to select/assign appropriate background mu- sic (BGM) for each scene/cut when we edit a video or a slideshow of photos. However, it is a laborious task. Aim- ing to realise automatic BGM selection/assignment, we pro- pose a method to automatically assign emotion tag to various BGM. To realise this method, we need a model for classify- ing BGM. To build our model, we use a set of movie scene BGMs that a group of 14 users tagged with five (5) differ- ent sentiments: Love, Surprise, Joy, Sadness, and Fear. Af- ter confirming their agreements, we extracted the features of each audio file of our dataset. Using the machine-learning tool WEKA and the random forest algorithm, we built a model. Through a cross validation process, we evaluated our model and obtained an accuracy of 94% in prediction of the emotion in the BGM, demonstrating the effectiveness of the proposed approach.", "references": ["Daiki Kato, Ryosuke Yamanishi, and Junichi Fukumoto. Segmentation and impression estimation of novels for automatic assignment of bgm. In Advanced Applied Informatics (IIAI-AAI), 2015 IIAI 4th International Congress on, pages 239--243. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2948770"}, {"title": "A simple efficient approximation algorithm for dynamic time warping", "authors": ["Rex Ying\n,", "Jiangwei Pan\n,", "Kyle Fox\n,", "Pankaj K. Agarwal"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nDynamic time warping (DTW) is a widely used curve similarity measure. We present a simple and efficient (1 + ε)- approximation algorithm for DTW between a pair of point sequences, say, P and Q, each of which is sampled from a curve. We prove that the running time of the algorithm is O([EQUATION]n log σ) for a pair of k-packed curves with a total of n points, assuming that the spreads of P and Q are bounded by σ. The spread of a point set is the ratio of the maximum to the minimum pairwise distance, and a curve is called K- packed if the length of its intersection with any disk of radius r is at most Kr. Although an algorithm with similar asymptotic time complexity was presented in [1], our algorithm is considerably simpler and more efficient in practice.\nWe have implemented our algorithm. Our experiments on both synthetic and real-world data sets show that it is an order of magnitude faster than the standard exact DP algorithm on point sequences of length 5, 000 or more while keeping the approximation error within 5--10%. We demonstrate the efficacy of our algorithm by using it in two applications - computing the k most similar trajectories to a query trajectory, and running the iterative closest point method for a pair of trajectories. We show that we can achieve 8--12 times speedup using our algorithm as a subroutine in these applications, without compromising much in accuracy.", "references": ["P. K. Agarwal, K. Fox, J. Pan, and R. Ying. Approximating dynamic time warping and edit distance for a pair of point sequences. In Proc. 32nd Int. Symp. Comp. Geom., pages 6:1--6:16, 2016.", "P. K. Agarwal, S. Har-Peled, and K. R. Varadarajan. Geometric approximation via coresets. In Combinatorial and Computational Geometry (J. E. Goodman, J. Pach, and E. Welzl, eds.), Cambridge Univ. Press, New York, 1--30, 2005.", "G. Al-Naymat, S. Chawla, and J. Taheri. Sparsedtw: A novel approach to speed up dynamic time warping. In Proc. 8th Aus. Data Mining Conf., pages 117--128, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996954"}, {"title": "Two Sample T-tests for IR Evaluation: Student or Welch?", "authors": ["Tetsuya Sakai"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThere are two well-known versions of the t-test for comparing means from unpaired data: Student's t-test and Welch's t-test. While Welch's t-test does not assume homoscedasticity (i.e., equal variances), nit involves approximations. A classical textbook recommendation would be to use Student's t-test if either the two sample sizes are similar or the two sample variances are similar, and to use Welch's t-test only when both of the above conditions are violated. However, a more recent recommendation seems to be to use Welch's t-test unconditionally. Using past data from both TREC and NTCIR, the present study demonstrates that the latter advice should not be followed blindly in the context of IR system evaluation. More specifically, our results suggest that if the sample sizes differ substantially and if the larger sample has a substantially larger variance,Welch's t-test may not be reliable.", "references": ["D. J. Gans. Use of a preliminary test in comparing two sample means. Communications in Statistics - Simuation and Computation, 10(2):163--174, 1981.", "D. Hawking and N. Craswell. The very large collection and web tracks. In E. M. Voorhees and D. K. Harman, editors, TREC: Experiment and Evaluation in Information Retrieval, chapter 9. The MIT Press, 2005.", "Y. Nagata. How to Understand Statistical Methods (in Japanese). Nikkagiren, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914684"}, {"title": "Accurate Aggregation of Local Features by using K-sparse Autoencoder for 3D Model Retrieval", "authors": ["Takahiko Furuya\n,", "Ryutarou Ohbuchi"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAggregating a set of local features has been used widely to realize recognition or retrieval of multimedia data including 2D images and 3D models. A number of feature aggregation algorithms (e.g., Bag-of-Features, Locality-constrained Linear coding, or Fisher Vector coding) have been proposed. They first learn a codebook, or a set of codewords, by clustering the local features and then encode these local features by using the learned codebook. Despite the great success of these feature aggregation algorithms, we argue that they are not necessarily optimal in terms of accuracy since their codebook learning and feature encoding are computed separately. In this paper, we propose two novel feature aggregation algorithms based on k-Sparse Autoencoder (kSA) that realize more accurate local feature aggregation. Our proposed algorithms, called Database-adaptive kSA (DkSA) aggregation and Per-data-adaptive kSA (PkSA) aggregation, jointly optimize codebook learning and feature encoding. In addition, the kSA-based feature encoding enhances saliency of local features due to k-sparseness constraints and non-negativity constraints. Of the two proposed algorithms, the PkSA aggregation exploits reconstruction error of a local feature derived from the kSA for more accurate aggregated feature. Experimental evaluation using a shape-based 3D model retrieval scenario showed that the retrieval accuracy of our proposed algorithms are superior to the existing feature aggregation algorithms we have compared against.", "references": ["Achlioptas, D. 2003. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences, 66(4), 671--687.", "Aharon, M., Elad, M., Bruckstein, A. 2006. K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation. IEEE Transactions on Signal Processing, 54(11), 4311--4322.", "Bell, A., Sejnowski, T.J. 1996. Edges are the 'Independent Components' of Natural Scenes. Proc. NIPS 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912054"}, {"title": "Advances in Formal Models of Search and Search Behaviour", "authors": ["Leif Azzopardi\n,", "Guido Zuccon"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nSearching is performed in the context of a task and as such the value of the information found is with respect to the task. Recently, there has been a drive to developing formal models of information seeking and retrieval that consider the costs and benefits arising through the interaction with the interface/system and the information surfaced during that interaction. In this full day tutorial we will focus on describing and explaining some of the more recent and latest formal models of Information Seeking and Retrieval. The tutorial is structured into two parts. In the first part we will present a series of models that have been developed based on: (i) economic theory, (ii) decision theory (iii) game theory and (iv) optimal foraging theory. The second part of the day will be dedicated to building models where we will discuss different techniques to build and develop models from which we can draw testable hypotheses from. During the tutorial participants will be challenged to develop various formals models, applying the techniques learnt during the day. We will then conclude with presentations on solutions followed by a summary and overview of challenges and future directions. This tutorial is aimed at participants wanting to know more about the various formal models of information seeking, search and retrieval, that have been proposed. The tutorial will be presented at an intermediate level, and is designed to support participants who want to be able to understand and build such models.", "references": ["K. Athukorala, A. Oulasvirta, D. Głowacka, J. Vreeken, and G. Jacucci. Narrow or broad?: Estimating subjective specificity in exploratory search. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM '14, pages 819--828, New York, NY, USA, 2014. ACM.", "C. W. Axelrod. The economic evaluation of information storage and retrieval systems. Information Processing & Management, 13(2):117--124, 1977.", "L. Azzopardi. Query side evaluation: an empirical analysis of effectiveness and effort. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 556--563. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970440"}, {"title": "Overcoming Key Weaknesses of Distance-based Neighbourhood Methods using a Data Dependent Dissimilarity Measure", "authors": ["Kai Ming Ting\n,", "Ye Zhu\n,", "Mark Carman\n,", "Yue Zhu\n,", "Zhi-Hua Zhou"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThis paper introduces the first generic version of data dependent dissimilarity and shows that it provides a better closest match than distance measures for three existing algorithms in clustering, anomaly detection and multi-label classification. For each algorithm, we show that by simply replacing the distance measure with the data dependent dissimilarity measure, it overcomes a key weakness of the otherwise unchanged algorithm.", "references": ["M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. OPTICS: ordering points to identify the clustering structure. In ACM Sigmod Record, volume 28, pages 49--60. ACM, 1999.", "S. Aryal, K. M. Ting, G. Haffari, and T. Washio. mp-dissimilarity: A data dependent dissimilarity measure. In Proceedings of the IEEE International Conference on Data Mining, pages 707--712, 2014.", "S. Aryal, K. M. Ting, G. Haffari, and T. Washio. Beyond tf-idf and cosine distance in documents dissimilarity measure. In Proceedings of the 11th Asia Information Retrieval Societies Conference, pages 400--406. Springer, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939779"}, {"title": "To Blend or Not to Blend?: Perceptual Speed, Visual Memory and Aggregated Search", "authors": ["Lauren Turpin\n,", "Diane Kelly\n,", "Jaime Arguello"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhile aggregated search interfaces that present vertical results to searchers are fairly common in today's search environments, little is known about how searchers' cognitive abilities impact how they use and evaluate these interfaces. This study evaluates the relationship between two cognitive abilities ? perceptual speed and visual memory ? and searchers' behaviors and interface preferences when using two aggregated search interfaces: one that blends vertical results into the search results (blended) and one that does not (non-blended). Cognitive tests were administered to sixteen participants who subsequently performed four search tasks using the two interfaces. Participants' search interactions were logged and after searching, they rated the usability, engagement and effectiveness of each interface, as well as made comparative evaluations. Results showed that participants with low perceptual speed spent significantly more time completing tasks when using the blended interface, while those with high perceptual speed spent roughly equivalent amounts of time completing tasks with the two interfaces. Those with low perceptual speed also rated both interfaces as significantly less usable along many measures, and were less satisfied with their searches. There were also main effects for interface: participants rated the non-blended interface significantly more usable than the blended interface.", "references": ["Al-Maskari, A. & Sanderson, M. (2011). The effect of user characteristics on search effectiveness in information retrieval. IP&M, 47, 719--729.", "Allen, B. (1994). Perceptual speed, learning and information retrieval performance. Proc. of SIGIR, 71--80.", "Arguello, J. & Capra, R. (2012) The effect of aggregated search coherence on search behavior. Proc. of SIGIR, 1293--1302."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914739"}, {"title": "The systematic review of literature in LIS: an approach", "authors": ["Tránsito Ferreras-Fernández\n,", "Helena Martín-Rodero\n,", "Francisco J. García-Peñalvo\n,", "José A. Merlo-Vega"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nSystematic reviews have become an important source of information and very popular in knowledge areas as health and allied sciences, but nevertheless, despite its indisputable benefits, they are yet infrequently used in Library and Information Science research (LIS).\nSystematic reviews are a type of scientific research that aims to integrate in an objective and systematic manner the results of empirical studies on a particular research problem in order to determine the state of the question in its field of study.\nIn this paper, we provide a brief survey on the literature reviews in the social science area and we propose the adoption of the systematic review as a methodology for recovering, analyzing, evaluating and critical appraising the relevant literature in library and information science (LIS).", "references": ["Campbell, S. A. and Menk, D. W. 2003. Editors' Introduction. Review of Educational Research. 73, 2, 123--124.", "Xu, J., Kang, Q., and Song, Z. 2015. The current state of systematic reviews in library and information studies. Library & Information Science Research. 37, 4, 296--310.", "Ferreira González, I., Urrútia, G., and Alonso-Coello, P. 2011. Revisiones sistemáticas y metaanálisis: bases conceptuales e interpretación. Revista Española de Cardiología. 64, 8, 688--696."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012531"}, {"title": "Query reranking as a service", "authors": ["Abolfazl Asudeh\n,", "Nan Zhang\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe ranked retrieval model has rapidly become the de facto way for search query processing in client-server databases, especially those on the web. Despite of the extensive efforts in the database community on designing better ranking functions/mechanisms, many such databases in practice still fail to address the diverse and sometimes contradicting preferences of users on tuple ranking, perhaps (at least partially) due to the lack of expertise and/or motivation for the database owner to design truly effective ranking functions. This paper takes a different route on addressing the issue by defining a novel query reranking problem, i.e., we aim to design a third-party service that uses nothing but the public search interface of a client-server database to enable the on-the-fly processing of queries with any user-specified ranking functions (with or without selection conditions), no matter if the ranking function is supported by the database or not. We analyze the worst-case complexity of the problem and introduce a number of ideas, e.g., on-the-fly indexing, domination detection and virtual tuple pruning, to reduce the average-case cost of the query reranking algorithm. We also present extensive experimental results on real-world datasets, in both offline and live online systems, that demonstrate the effectiveness of our proposed techniques.", "references": ["A. Asudeh, S. Thirumuruganathan, N. Zhang, and G. Das. Discovering the skyline of web databases. VLDB, 2016.", "N. Bruno, S. Chaudhuri, and L. Gravano. Top-k selection queries over relational databases: Mapping strategies and performance evaluation. TODS, 2002.", "K. C.-C. Chang and S.-w. Hwang. Minimal probing: supporting expensive predicates for top-k queries. In SIGMOD. ACM, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2983200.2983205"}, {"title": "Report on the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR '15)", "authors": ["Krisztian Balog\n,", "Jeffrey Dalton\n,", "Antoine Doucet\n,", "Yusra Ibrahim"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThe amount of structured content published on the Web has been growing rapidly, making it possible to address increasingly complex information access tasks. Recent years have witnessed the emergence of large scale human-curated knowledge bases as well as a growing array of techniques that identify or extract information automatically from unstructured and semi-structured sources. The ESAIR workshop series aims to advance the general research agenda on the problem of creating and exploiting semantic annotations. The eighth edition of ESAIR took place at CIKM 2015 in Melbourne, Australia, on the 23rd of October. Having a special focus on applications, we dedicated an \"annotations in action\" track to demonstrations that showcase innovative prototype systems, in addition to the regular research and position paper contributions. The workshop also featured invited talks from leaders in the field. This report presents an overview of the event and its major outcomes.", "references": ["K. Balog, J. Dalton, A. Doucet, and Y. Ibrahim, editors. ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval, New York, NY, USA, 2015. ACM.", "A. Bordes, J. Weston, and N. Usunier. Open question answering with weakly supervised embedding models. CoRR, abs/1404.4326, 2014. URL http://arxiv.org/abs/1404.4326.", "A. Cadilhac, A. Chisholm, B. Hachey, and S. Kharazmi. Hugo: Entity-based news search and summarisation. In Balog et al. {1}, pages 51--54."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964806"}, {"title": "Improving Flash-Based Disk Cache with Lazy Adaptive Replacement", "authors": ["Sai Huang\n,", "Qingsong Wei\n,", "Dan Feng\n,", "Jianxi Chen\n,", "Cheng Chen"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nFor years, the increasing popularity of flash memory has been changing storage systems. Flash-based solid-state drives (SSDs) are widely used as a new cache tier on top of hard disk drives (HDDs) to speed up data-intensive applications. However, the endurance problem of flash memory remains a concern and is getting worse with the adoption of MLC and TLC flash. In this article, we propose a novel cache management algorithm for flash-based disk cache named Lazy Adaptive Replacement Cache (LARC). LARC adopts the idea of selective caching to filter out seldom accessed blocks and prevent them from entering cache. This avoids cache pollution and preserves popular blocks in cache for a longer period of time, leading to a higher hit rate. Meanwhile, by avoiding unnecessary cache replacements, LARC reduces the volume of data written to the SSD and yields an SSD-friendly access pattern. In this way, LARC improves the performance and endurance of the SSD at the same time. LARC is self-tuning and incurs little overhead. It has been extensively evaluated by both trace-driven simulations and synthetic benchmarks on a prototype implementation. Our experiments show that LARC outperforms state-of-art algorithms for different kinds of workloads and extends SSD lifetime by up to 15.7 times.", "references": ["Nitin Agrawal, Vijayan Prabhakaran, Ted Wobber, John D. Davis, Mark Manasse, and Rina Panigrahy. 2008. Design tradeoffs for SSD performance. In Proceedings of the 2008 USENIX Annual Technical Conference (USENIX ATC’08). 57--70.", "Raja Appuswamy, David C. van Moolenbroek, and Andrew S. Tanenbaum. 2013. Cache, cache everywhere, flushing all hits down the sink: On exclusivity in multilevel, hybrid caches. In Proceedings of the 2013 IEEE 29th Symposium on Mass Storage Systems and Technologies (MSST’13). IEEE, Los Alamitos, CA, 1--14.", "Anirudh Badam and Vivek S. Pai. 2011. SSDAlloc: Hybrid SSD/RAM memory management made easy. In Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation. 16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737832"}, {"title": "Navigation of Pitch Space on a Digital Musical Instrument with Dynamic Tactile Feedback", "authors": ["Robert Jack\n,", "Tony Stockman\n,", "Andrew McPherson"], "publication": "TEI '16: Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction", "abstract": "ABSTRACT\nWe present a study investigating the impact of dynamic tactile feedback on performer navigation of a continuous pitch space on a digital musical instrument. Ten musicians performed a series of blind pitch selection and melodic tasks on a self-contained digital musical instrument with audio-frequency tactile feedback that was generated in response to their interaction. Results from the study show that tactile feedback can positively impact a performer's ability to play in tune when the instrument is hidden from sight, however with a temporal impact on performance. Furthermore, several playing techniques were observed that emerged from the performer's engagement with the tactile feedback conditions. We discuss the implications of our findings in the context of tangible interface design and non-visual interface navigation. We also discuss how our implementation suggests guidelines for future instruments and interfaces incorporating dynamic tactile feedback and present a novel tactile feedback technique that uses tactile 'beating'.", "references": ["Anders Askenfelt and EV Jansson. 1992. On vibration sensation and finger touch in stringed instrument playing. Music Perception 9, 3 (1992), 311--349.", "Edgar Berdahl, Günter Niemeyer, and Julius O Smith. 2009. Using Haptics to Assist Performers in Making Gestures to a Musical Instrument. In Proc. International Conference on New Interfaces for Musical Expression. Pittsburgh, PA, United States.", "DM Birnbaum and MM Wanderley. 2007. A systematic approach to musical vibrotactile feedback. Proc. International Computer Music Conference (2007)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2839462.2839503"}, {"title": "RecSys'16 Workshop on Deep Learning for Recommender Systems (DLRS)", "authors": ["Alexandros Karatzoglou\n,", "Balázs Hidasi\n,", "Domonkos Tikk\n,", "Oren Sar-Shalom\n,", "Haggai Roitman\n,", "Bracha Shapira\n,", "Lior Rokach"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe believe that Deep Learning is one of the next big things in Recommendation Systems technology. The past few years have seen the tremendous success of deep neural networks in a number of complex tasks such as computer vision, natural language processing and speech recognition. Despite this, only little work has been published on Deep Learning methods for Recommender Systems. Notable recent application areas are music recommendation, news recommendation, and session-based recommendation. The aim of the workshop is to encourage the application of Deep Learning techniques in Recommender Systems, to promote research in deep learning methods for Recommender Systems, and to bring together researchers from the Recommender Systems and Deep Learning communities.", "references": ["A. M. Elkahky, Y. Song, and X. He. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In WWW'15: 24th Int. Conf. on World Wide Web}, pages 278--288, 201", "R. He and J. McAuley. VBPR: Visual Bayesian Personalized Ranking from implicit feedback. CoRR, 1510.01784, 2015.", "B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. Session-based recommendations with recurrent neural networks. International Conference on Learning Representations, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959202"}, {"title": "Mood-Sensitive Truth Discovery For Reliable Recommendation Systems in Social Sensing", "authors": ["Jermaine Marshall\n,", "Dong Wang"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis work is motivated by the need to provide reliable information recommendation to users in social sensing. Social sensing has become an emerging application paradigm that uses humans as sensors to observe and report events in the physical world. These human sensed observations are often viewed as binary claims (either true or false). A fundamental challenge in social sensing is how to ascertain the credibility of claims and the reliability of sources without knowing either of them a priori. We refer to this challenge as truth discovery. While prior works have made progress on addressing this challenge, an important limitation exists: they did not explore the mood sensitivity aspect of the problem. Therefore, the claims identified as correct by current solutions can be completely biased in regards to the mood of human sources and lead to useless or even misleading recommendations. In this paper, we present a new analytical model that explicitly considers the mood sensitivity feature in the solution of truth discovery problem. The new model solves a multi-dimensional estimation problem to jointly estimate the correctness and mood neutrality of claims as well as the reliability and mood sensitivity of sources. We compare our model with state-of-the-art truth discovery solutions using four real world datasets collected from Twitter during recent disastrous and emergent events: Brussels Bombing, Paris Attack, Oregon Shooting, Baltimore Riots, which occurred in 2015 and 2016. The results show that our model has significant improvements over the compared baselines by finding more correct and mood neutral claims.", "references": ["Charu C Aggarwal and Tarek Abdelzaher. Social sensing. In Managing and Mining Sensor Data, pages 237--297. Springer, 2013.", "Dong Wang, Tarek Abdelzaher, and Lance Kaplan. Social Sensing: Building Reliable Systems on Unreliable Data. Morgan Kaufmann, 2015.", "Dong Wang, Lance Kaplan, Hieu Le, and Tarek Abdelzaher. On truth discovery in social sensing: A maximum likelihood estimation approach. In The 11th ACM/IEEE Conference on Information Processing in Sensor Networks (IPSN 12), April 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959147"}, {"title": "Studying the Effect of Data Structures on the Efficiency of Collaborative Filtering Systems", "authors": ["Pablo Sánchez\n,", "Alejandro Bellogín\n,", "Iván Cantador"], "publication": "CERI '16: Proceedings of the 4th Spanish Conference on Information Retrieval", "abstract": "ABSTRACT\nRecommender systems is an active research area where the major focus has been on how to improve the quality of generated recommendations, but less attention has been paid on how to do it in an efficient way. This aspect is increasingly important because the information to be considered by recommender systems is growing exponentially. In this paper we study how different data structures affect the performance of these systems. Our results with two public datasets provide relevant insights regarding the optimal data structures in terms of memory and time usages. Specifically, we show that classical data structures like Binary Search Trees and Red-Black Trees can beat more complex and popular alternatives like Hash Tables.", "references": ["A. Bellogín, J. Wang, and P. Castells. Bridging memory-based collaborative filtering and text retrieval. Inf. Retr., 16(6):697--724, 2013.", "Ò. Celma. Music Recommendation and Discovery - The Long Tail, Long Fail, and Long Play in the Digital Music Space. Springer, 2010.", "S. H. S. Chee, J. Han, and K. Wang. Rectree: An efficient collaborative filtering method. In Y. Kambayashi, W. Winiwarter, and M. Arikawa, editors, Data Warehousing and Knowledge Discovery, Third International Conference, DaWaK 2001, Munich, Germany, September 5-7, 2001, Proceedings, volume 2114 of Lecture Notes in Computer Science, pages 141--151. Springer, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934732.2934747"}, {"title": "Compressing Graphs and Indexes with Recursive Graph Bisection", "authors": ["Laxman Dhulipala\n,", "Igor Kabiljo\n,", "Brian Karrer\n,", "Giuseppe Ottaviano\n,", "Sergey Pupyrev\n,", "Alon Shalita"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nGraph reordering is a powerful technique to increase the locality of the representations of graphs, which can be helpful in several applications. We study how the technique can be used to improve compression of graphs and inverted indexes.\nWe extend the recent theoretical model of Chierichetti et al. (KDD 2009) for graph compression, and show how it can be employed for compression-friendly reordering of social networks and web graphs and for assigning document identifiers in inverted indexes. We design and implement a novel theoretically sound reordering algorithm that is based on recursive graph bisection.\nOur experiments show a significant improvement of the compression rate of graph and indexes over existing heuristics. The new method is relatively simple and allows efficient parallel and distributed implementations, which is demonstrated on graphs with billions of vertices and hundreds of billions of edges.", "references": ["A, B. Shalita, I. K. Karrer, A. Sharma, A. Presta, A. Adcock, H. Kllapi, and M. Stumm. Social hash: An assignment framework for optimizing distributed systems operations on social networks. In Networked Systems Design and Implementation, 2016.", "A. Apostolico and G. Drovandi. Graph compression by BFS. Algorithms, 2(3):1031--1044, 2009.", "S. Arora, S. Rao, and U. Vazirani. Expander flows, geometric embeddings and graph partitioning. Journal of the ACM, 56(2):5, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939862"}, {"title": "Are Secondary Assessors Uncertain When They Disagree About Relevance Judgements?", "authors": ["Aiman L. Al-Harbi\n,", "Mark D. Smucker"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThe collection of relevance judgements by assessors is important for many information retrieval (IR) tasks. In addition to the construction of test collections, relevance judging is critical to e-discovery and other applications where many assessors are hired to perform relevance judging. It is well known that assessors may differ in their judgements for a given document. One possible cause of a judgement difference is that an assessor may be uncertain in their judgement and thus may in effect be guessing the document's relevance. If assessors are aware of their uncertainty and can self-report their level of certainty, then uncertain relevance judgements can be targeted for adjudication by additional assessors. In this paper, we conducted a user study with 48 participants to test our hypothesis that assessors will be uncertain about their relevance judgements when the assessors are likely to disagree with each other. We found that for low consensus documents, i.e. documents known for assessor disagreement, assessors judge these documents with almost as much certainty as high consensus documents. In particular, assessor self-reported uncertainty is predictive of disagreement only for high consensus documents and not for low consensus documents.", "references": ["A. L. Al-Harbi and M. D. Smucker. A Qualitative Exploration of Secondary Assessor Relevance Judging Behavior. In IIiX, pages 195--204, 2014.", "P. Bailey, N. Craswell, I. Soboroff, P. Thomas, A. P. de Vries, and E. Yilmaz. Relevance assessment: are judges exchangeable and does it matter. In SIGIR, pages 667--674, 2008.", "C. W. Cleverdon. The Effect of Variations in Relevance Assessments in Comparative Experimental Tests of Index Languages. Tech. report, Cranfield Univ.; Aslib, 1970."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854993"}, {"title": "Research on fault feature extraction for analog circuits", "authors": ["Lihua Zhang\n,", "Yue Shang\n,", "Qi Qin\n,", "Shaowei Chen\n,", "Shuai Zhao"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn order to realize the accurate positioning and recognition effectively of the analog circuit, the feature extraction of fault information is an extremely important port. This arrival based on the experimental circuit which is designed as a failure mode to pick-up the fault sample set. We have chosen two methods, one is the combination of wavelet transform and principal component analysis, the other is the factorial analysis for the fault data's feature extraction, and we also use the extreme learning machine to train and diagnose the data, to compare the performance of these two methods through the accuracy of the diagnosis. The results of the experiment shows that the data which we get from the experimental circuit, after dealing with these two methods can quickly get the fault location.", "references": ["F. Aminian, M. Aminian, H. W. Collins. \"Analog fault diagnosis of actual circuits using neural Networks.\" IEEE Transactions on Instrumentation and Measurement, 2002, 51(3): 544--549.", "S.-W. Chen, S. Zhao, C. Wang, \"A new analog circuit fault diagnosis approach based on GA-SVM,\" TENCON 2013, PP:1--4.", "S.-W. Chen, S. Zhao, C. Wang et al. A new analog circuit fault diagnosis approach based on GA-SVM{C}. 2013 IEEE Region 10 Conference (TENCON 2013), October 22-25 2013, Xi an, Shaanxi, China. 2013: 1--4."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015177"}, {"title": "Knowledge Extraction in Web Media: At The Frontier of NLP, Machine Learning and Semantics", "authors": ["Julien Plu"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe identify two main factors that can cause numerous difficulties when developing a generic entity linking system: i) the amount of data currently available on the Web that do not stop to increase and where a large part comes in the form of natural language texts; ii) the velocity at which data is published that may impose to process streams of text in near real-time. Social media platforms such as Twitter, Facebook or LinkedIn become a reliable source of news and play a key role for being aware of events around the world. Encyclopedia and newspaper articles contain general knowledge of our world and they can be used to explain concepts and known entities. Videos can be associated with subtitles and images may have captions. Depending on where a text comes from, it can have different properties such as a specific language, style of writing or topic. In this research, we present a preliminary framework based on a novel hybrid architecture for an entity linking system, that combines methods from the Natural Language Processing (NLP), information retrieval and semantic fields. In particular, we propose a modular approach in order to be as independent as possible of the text to be processed. Our evaluation suggests that this framework can outperform the state-of-the-art systems or show encouraging results on three datasets: OKE2015, #Micropost 2014 and #Micropost 2015. We identify the current limitations and we provide promising future research directions.", "references": ["A. E. C. Basave, G. Rizzo, A. Varga, M. Rowe, M. Stankovic, and A. Dadzie. Making sense of microposts (#microposts2014) named entity extraction & linking challenge. In 4th Workshop on Making Sense of Microposts, Seoul, Korea, 2014.", "M. Chang, B. P. Hsu, H. Ma, R. Loynd, and K. Wang. E2E: an end-to-end entity linking system for short and noisy text. In 4th Workshop on Making Sense of Microposts, Seoul, Korea, 2014.", "J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes. Improving efficiency and accuracy in multilingual entity extraction. In 9th International Conference on Semantic Systems, (I-SEMANTICS), Graz, Austria, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888597"}, {"title": "The New Challenges when Modeling Context through Diversity over Time in Recommender Systems", "authors": ["Amaury L'Huillier\n,", "Sylvain Castagnos\n,", "Anne Boyer"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThe main goal of recommender systems is to help users to filter all the information available by suggesting items they may like without they had to find them by themselves. Although the rating prediction is a pretty well controlled topic, being able to make a recommendation at the right moment still remain a challenging task. To this end, most researches try to integrate contextual information (weather, mood, location of users, etc.) in the recommendation process. Even if this process increases users satisfaction, using personal information faces with users' privacy issues. In a different way, our approach is only giving credits to the evolution of diversity within the recent history of consultations, allowing us to automatically detect implicit contexts. In this paper, we will discuss the scientific challenges to be overcome to take maximum advantage of those implicit contexts in the recommendation process.", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. Recommender Systems Handbook, pages 217--253, 2011.", "S. Castagnos, A. Brun, and A. Boyer. When diversity is needed... but not expected! In IMMM, pages 44--50, 2013.", "S. Castagnos, A. L 'huillier, and A. Boyer. Toward a Robust Diversity-Based Model to Detect Changes of Context. In 27th IEEE International Conference on Tools with Artificial Intelligence (ICTAI 2015), Vietri sul Mare, Italy, Nov. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930370"}, {"title": "Kam1n0: MapReduce-based Assembly Clone Search for Reverse Engineering", "authors": ["Steven H.H. Ding\n,", "Benjamin C.M. Fung\n,", "Philippe Charland"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nAssembly code analysis is one of the critical processes for detecting and proving software plagiarism and software patent infringements when the source code is unavailable. It is also a common practice to discover exploits and vulnerabilities in existing software. However, it is a manually intensive and time-consuming process even for experienced reverse engineers. An effective and efficient assembly code clone search engine can greatly reduce the effort of this process, since it can identify the cloned parts that have been previously analyzed. The assembly code clone search problem belongs to the field of software engineering. However, it strongly depends on practical nearest neighbor search techniques in data mining and databases. By closely collaborating with reverse engineers and Defence Research and Development Canada (DRDC), we study the concerns and challenges that make existing assembly code clone approaches not practically applicable from the perspective of data mining. We propose a new variant of LSH scheme and incorporate it with graph matching to address these challenges. We implement an integrated assembly clone search engine called Kam1n0. It is the first clone search engine that can efficiently identify the given query assembly function's subgraph clones from a large assembly code repository. Kam1n0 is built upon the Apache Spark computation framework and Cassandra-like key-value distributed storage. A deployed demo system is publicly available. Extensive experimental results suggest that Kam1n0 is accurate, efficient, and scalable for handling large volume of assembly code.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1), 2008.", "M. Bawa, T. Condie, and P. Ganesan. LSH forest: self-tuning indexes for similarity search. In Proc. of WWW'05, 2005.", "M. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings on 34th Annual ACM STOC'02, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939719"}, {"title": "Immersive Recommendation: News and Event Recommendations Using Personal Digital Traces", "authors": ["Cheng-Kang Hsieh\n,", "Longqi Yang\n,", "Honghao Wei\n,", "Mor Naaman\n,", "Deborah Estrin"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe propose a new user-centric recommendation model, called Immersive Recommendation, that incorporates cross-platform and diverse personal digital traces into recommendations. Our context-aware topic modeling algorithm systematically profiles users' interests based on their traces from different contexts, and our hybrid recommendation algorithm makes high-quality recommendations by fusing users' personal profiles, item profiles, and existing ratings. Specifically, in this work we target personalized news and local event recommendations for their utility and societal importance. We evaluated the model with a large-scale offline evaluation leveraging users' public Twitter traces. In addition, we conducted a direct evaluation of the model's recommendations in a 33-participant study using Twitter, Facebook and email traces. In the both cases, the proposed model showed significant improvement over the state-of-the-art algorithms, suggesting the value of using this new user-centric recommendation model to improve recommendation quality, including in cold-start situations.", "references": ["Mozilla, firefox interest dashboard. https://www.mozilla.org/en-US/firefox/interest-dashboard/, 2014.", "Context-Aware LDA. https://github.com/changun/CA-LDA, 2015.", "F. Abel, N. Henze, E. Herder, and D. Krause. Interweaving public user profiles on the web. In User Modeling, Adaptation, and Personalization, pages 16--27. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883006"}, {"title": "A bootstrapping method for extracting attribute names with keys from the web", "authors": ["Yoshinori Hijikata\n,", "Shintaro Nomura\n,", "Fumitaka Nakane\n,", "Shogo Nishida"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nA large number of semi-structured documents (HTML documents) exist on the Web. To improve the accessibility of information related to an object, such as a product, human, or place, its attribute names and attribute values need to be extracted. Recently, many studies have aimed to extract attribute values automatically, whereas only a small number of studies have attempted to extract attribute names. Thus, we propose a method for extracting attribute names automatically. For the first time, we apply a bootstrapping algorithm to attribute name extraction in the area of information extraction. To solve a problem that is caused by applying a pure bootstrapping algorithm to attribute name extraction, we use keys, which are also extracted by a bootstrapping algorithm. We found that using extracted keys improve the accuracy of attribute name extraction.", "references": ["H. Chen, S. Tsai, and J. Tsai: Mining tables from large scale HTML texts, Proc. of the COLING'00, pp. 166--172, 2000.", "H. He, et al.: Automatic integration of web search interfaces with WISE-Integrator, VLDB Journal, Vol. 13, No. 3, pp. 256--273, 2004.", "Y. Hijikata, S. Nomura, F. Nakane and S. Nishida: Bootstrapping approach for extracting object attribute names from the Web, Proceedings of IEEE/WIC/ACM WI'15, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851992"}, {"title": "SAGEL: smart address geocoding engine for supply-chain logistics", "authors": ["Abhranil Chatterjee\n,", "Janit Anjaria\n,", "Sourav Roy\n,", "Arnab Ganguli\n,", "Krishanu Seal"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nWith the recent explosion of e-commerce industry in India, the problem of address geocoding, that is, transforming textual address descriptions to geographic reference, such as latitude, longitude coordinates, has emerged as a core problem for supply chain management. Some of the major areas that rely on precise and accurate address geocoding are supply chain fulfilment, supply chain analytics and logistics. In this paper, we present some of the challenges faced in practice while building an address geocoding engine as a core capability at Flipkart. We discuss the unique challenges of building a geocoding engine for a rapidly developing country like India, such as, fuzzy region boundaries, dynamic topography and lack of convention in spellings of toponyms, to name a few. We motivate the need for building a reliable and precise address geocoding system from a business perspective and argue why some of the commercially available solutions do not suffice for our requirements. SAGEL has evolved through 3 cycles of solution prototypes and pilot experiments. We describe the learnings from each of these phases and how we incorporated them to get to the first production-ready version. We describe how we store and index map data on a SolrCloud cluster of Apache Solr, an open-source search platform, and the core algorithm for geocoding which works post-retrieval in order to determine the best matches among a set of candidate results. We give a brief description of the system architecture and provide accuracy results of our geocoding engine by measuring deviations of geocoded customer addresses across India, from verified latitude, longitude coordinates of those addresses, for a sizeable address set. We also measure and report our system's ability to geocode up to different region levels, like city, locality or building. We compare our results with those of the geocoding service provided by Google against a set of addresses for which we have verified latitude-longitude coordinates and show that our geocoding engine is almost as accurate as Google's, while having a higher coverage.", "references": ["T. R. Babu, A. Chatterjee, S. Khandeparker, A. V. Subhash, and S. Gupta. Geographical address classification without using geolocation coordinates. In Proceedings of the 9th Workshop on Geographic Information Retrieval, page 8. ACM, 2015.", "R. Bellman. Dynamic programming and lagrange multipliers. Proceedings of the National Academy of Sciences, 42(10):767--769, 1956.", "M. R. Cayo and T. O. Talbot. Positional error in automated geocoding of residential addresses. International journal of health geographics, 2(1):1, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996917"}, {"title": "Research and Implementation of Image Haze Removal Algorithm", "authors": ["Feng Dong\n,", "Ye Pan"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nHaze has a great impact on the picture clarity, which cannot meetthe needs of high definition image areas. In this paper, image haze removal algorithms are studied, where the haze image are treated and restored using dark channel prior theory. Dark channel prior is an image Statistics Law -- within the vast majority of outdoor haze free image, there are always some points of a color channel whose value is close to zero; Using the law to establish a model, you can well recover haze free image.", "references": ["Joung Youn Kim, Lee Sup Kim, Seung Ho Hwang. \"An Advanced Contrast Enhancement Using Partially Overlapped Sub Block Histogram Equalization.\" IEEEE Transactions on Circuits and System for video Technology, 2001,11(3):475--484.", "J. Alex Stark.\"Adaptive Image Contrast Enhancemen Using Generalizations of Histogram Equalization.\" IEEE Transactions on Image Processing, 2000, 9(4):889--896.", "Z. Rahman, D. J. Jobson, G. A. Woodell. \"Multiscale retinexfor color image enhancement.\"IEEE Image Processing, Proceedings, International Conference on, Sep 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015187"}, {"title": "Preface", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915032"}, {"title": "User Activity Characterization in a Cultural Heritage Digital Library System", "authors": ["Cyrille Suire\n,", "Axel Jean-Caurant\n,", "Vincent Courboulay\n,", "Jean-Christophe Burie\n,", "Pascal Estraillier"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nDigital access to large amount of heterogeneous data can create methodological biases regarding the discovery and exploitation of resources, particularly when it comes to Social Sciences. In order to provide relevant adaptivity for social scientists, it is important to fully consider their research practice diversity. To do so, we consider an activity-based approach for researchers' information search behavior. We have also conducted an experiment in a Cultural Heritage use case. The main result shows us that social scientists have the same research behaviors as those observed in exact Sciences.", "references": ["M. Agosti, F. Crivellari, G. M. D. Nunzio, and S. Gabrielli. Understanding user requirements and preferences for a digital library Web portal. Int J Digit Libr, 11(4):225--238, Sept. 2011.", "K. Athukorala, D. Glowacka, G. Jacucci, A. Oulasvirta, and J. Vreeken. Is exploratory search different? A comparison of information search behavior for exploratory and lookup tasks. J. Assoc. Inf. Sci. Technol., 2015.", "N. Audenaert and R. Furuta. What Humanists Want: How Scholars Use Source Materials. In Proc. of the 10th JCDL, pages 283--292, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925459"}, {"title": "News Event Understanding by Mining Latent Factors From Multimodal Tensors", "authors": ["Chun-Yu Tsai\n,", "Ruilin Xu\n,", "Robert E. Colgan\n,", "John R. Kender"], "publication": "iV&L-MM '16: Proceedings of the 2016 ACM workshop on Vision and Language Integration Meets Multimedia Fusion", "abstract": "ABSTRACT\nWe present a novel and efficient constrained tensor factorization algorithm that first represents a video archive, of multimedia news stories concerning a news event, as a sparse tensor of order 4. The dimensions correspond to extracted visual memes, verbal tags, time periods and cultures. The iterative algorithm then approximately but accurately ex- tracts coherent quad-clusters, each of which represents a significant summary of an important independent aspect of the news event. We give examples of quad-clusters extracted from tensors with at least 108 entries derived from the international news coverage of the Ebola epidemic, AirAsia flight Q8501 and Zika virus. We show the method is fast, can be tuned to give preferences to any subset of its four dimensions, and exceeds three existing methods in performance.", "references": ["Hierarchical biclustering toolbox. https://sites.google.com/site/kittipat/hierarchical-biclustering.", "Microsoft translator text api. https://www.microsoft.com/en-us/translator/translatorapi.aspx.", "A. Banerjee, S. Basu, and S. Merugu. Multi-way clustering on relation graphs. SIAM International Conference on Data Mining, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983563.2983564"}, {"title": "Concept-Level Multimodal Ranking of Flickr Photo Tags via Recall Based Weighting", "authors": ["Rajiv Ratn Shah\n,", "Yi Yu\n,", "Suhua Tang\n,", "Shin'ichi Satoh\n,", "Akshay Verma\n,", "Roger Zimmermann"], "publication": "MMCommons '16: Proceedings of the 2016 ACM Workshop on Multimedia COMMONS", "abstract": "ABSTRACT\nSocial media platforms allow users to annotate photos with tags that significantly facilitate an effective semantics understanding, search, and retrieval of photos. However, due to the manual, ambiguous, and personalized nature of user tagging, many tags of a photo are in a random order and even irrelevant to the visual content. Aiming to automatically compute tag relevance for a given photo, we propose a tag ranking scheme based on voting from photo neighbors derived from multimodal information. Specifically, we determine photo neighbors leveraging geo, visual, and semantics concepts derived from spatial information, visual content, and textual metadata, respectively. We leverage high-level features instead traditional low-level features to compute tag relevance. Experimental results on a representative set of 203,840 photos from the YFCC100M dataset confirm that above-mentioned multimodal concepts complement each other in computing tag relevance. Moreover, we explore the fusion of multimodal information to refine tag ranking leveraging recall based weighting. Experimental results on the representative set confirm that the proposed algorithm outperforms state-of-the-arts.", "references": ["Apache Lucene. https://lucene.apache.org/core/, June 2016. Java API: Last Accessed June, 2016.", "By the Numbers: 14 Interesting Flickr Stats. http://expandedramblings.com/index.php/flickr-stats/, May 2016. Online: Last Accessed May, 2016.", "FourSquare. https://developer.foursquare.com/, June 2016. API: Last Accessed June, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983554.2983555"}, {"title": "Predicting User Preference Based on Matrix Factorization by Exploiting Music Attributes", "authors": ["Amir Hossein Nabizadeh\n,", "Alípio Mário Jorge\n,", "Suhua Tang\n,", "Yi Yu"], "publication": "C3S2E '16: Proceedings of the Ninth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nWith the emergence of online Music Streaming Services (MSS) such as Pandora and Spotify, listening to music online became very popular. Despite the availability of these services, users face the problem of finding among millions of music tracks the ones that match their music taste. MSS platforms generate interaction data such as users' defined playlists enriched with relevant metadata. These metadata can be used to predict users' preferences and facilitate personalized music recommendation. In this work, we aim to infer music tastes of users by using personal playlist information. Characterizing users' taste is important to generate trustable recommendations when the amount of usage data is limited. Here, we propose to predict the users' preferred music feature's value (e.g. Genre as a feature has different values like Pop, Rock, etc.) by modeling, not only usage information, but also music description features. Music attribute information and usage data are typically dealt with separately. Our method FPMF (Feature Prediction based on Matrix Factorization) treats music feature values as virtual users and retrieves the preferred feature values for real target users. Experimental results indicate that our proposal is able to handle the item cold start problem and can retrieve preferred music feature values with limited usage data. Furthermore, our proposal can be useful in recommendation explanation scenarios.", "references": ["M. Balabanović and Y. Shoham. Fab: content-based, collaborative recommendation. Communications of the ACM, 40(3):66--72, 1997.", "M. W. Berry, Z. Drmac, and E. R. Jessup. Matrices, vector spaces, and information retrieval. SIAM review, 41(2):335--362, 1999.", "Z. Gantner, L. Drumond, C. Freudenthaler, S. Rendle, and L. Schmidt-Thieme. Learning attribute-to-feature mappings for cold-start recommendations. In Data Mining (ICDM), 2010 IEEE 10th International Conference on, pages 176--185. IEEE, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948992.2949010"}, {"title": "WIMBY: What's in My Backyard?", "authors": ["Michael Dorkhom\n,", "Alan Woodley\n,", "Shlomo Geva\n,", "Richi Nayak"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nLocation-aware social media is increasing being used to inform decisions in a spatiotemporal context. However, collecting, fusing, processing and merging information from different social media platforms is a challenge because of diversity of information between different platforms. Here, we present the WIMBY, which is able to access multiple social media platforms to help users answer the question \"What's in my Backyard?\". In doing so, the WIMBY helps to address the challenge of dealing with diverse social media information. It is believed that the WIMBY can be extended to include more information sources (including other social media platforms) to help inform decision makers in a wider array of applications.", "references": ["Bice, S., Bortz, M., Sullivan, H., and Haines, F., 2015. Fear and licensing in Australia: Exploring a social licence to operate for an emerging coal seam gas industry. In Proceedings of the International Conference on Public Policy (Milian, Italy, 4 July 2015 2015).", "Cramb, S.M., Mengersen, K.L., and Baade, P.D., 2011. Atlas of Cancer in Queensland: Geographical variation in incidence and survival, 1998 to 2007. Viertel Centre for Research in Cancer Control, Cancer Council Queensland.", "Dashti, S., Leysia Palen, L., Heris, M.P., Anderson, K.M., Anderson, T.J., and Anderson, S., 2014. Supporting disaster reconnaissance with social media data: A design-oriented case study of the 2013 colorado floods. In Proceedings of the Proceedings of the 11th International ISCRAM Conference (Pennsylvania, United States of America2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973818"}, {"title": "Knowledge Graphs versus Hierarchies: An Analysis of User Behaviours and Perspectives in Information Seeking", "authors": ["Bahareh Sarrafzadeh\n,", "Alexandra Vtyurina\n,", "Edward Lank\n,", "Olga Vechtomova"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nIn exploratory search, how information is presented to the user and how the user interacts with the presented information heavily influence the user's success. In this paper, we examine two different spatial representations of search results: knowledge graphs and hierarchical trees. Through interaction logs we show that knowledge graphs can effectively reduce the need to read source content with no reduction in the quality of the information gathered by the user. Through qualitative interviews and thinkalounds we explore factors that influence user perception of different search results representations including biases, task, perceived structure of the data, and problem-solving approach. Overall, these results enhance our understanding of the role each of these representations can play in information seeking.", "references": ["J. Allan, B. Croft, A. Moffat, and M. Sanderson. Frontiers, challenges, and opportunities for information retrieval: Report from swirl 2012. In ACM SIGIR Forum, volume 46, pages 2--32. ACM, 2012.", "F. Amadieu and L. Salmerón. Concept maps for comprehension and navigation of hypertexts. In Digital Knowledge Maps in Education, pages 41--59. Springer, 2014.", "F. Amadieu, A. Tricot, and C. Mariné. Interaction between prior knowledge and concept-map structure on hypertext comprehension, coherence of reading orders and disorientation. Interacting with computers, 22(2):88--97, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854958"}, {"title": "Qualitative Analysis of the Adherence Between the Normative Instruction IN/SLTI/MPOG 04/2014 and the CMMI Models", "authors": ["Luiz S.P. Silva\n,", "Renata Teles Moreira\n,", "Alexandre M.L. Vasconcelos"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nIn recent years several initiatives have emerged seeking the improvement software processes and services. These initiatives are guided by quality norms, models and standards aiming to establish best practices to guide the definition of processes and support the assessment of the maturity and capability level of organizations. However, despite these initiatives, the application of best practices in Brazilian public organizations is impaired by various obstacles regarding the process of hiring IT solutions by the Federal Public Administration (APF), the main contractor of software and services in Brazil. Among these obstacles the ones that stand out are the complexity of processes and the continuous supervision of control bodies. To minimize these obstacles, the Tribunal de Contas da Uniao (TCU), recommended the establishment of the Normative Instruction SLTI/MPOG 04/2014, containing guidelines for the acquirement process of IT Solutions and Guide for Hiring IT Solutions (ITSCM). This work aims to identify the maturity and adherence ITSCM relative to CMMI models. For this, we carried out a mapped the ITSCM Guide to CMMI-ACQ, CMMI-DEV and CMMI-SVC practices.", "references": ["ABES - Associacao Brasileira de Empresas de Software. 2015.", "ABPMP. BPM CBOK - Guide to the Business Process Management Common Body of Knowledge. Versao 3. 2013.", "ABREU, M. F. Os riscos da terceirizacao da TI e da adocao de novas TIs e suas relacoes com os riscos para as estrategias competitivas das organizacoes. 2009"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021980"}, {"title": "The Effect of Document Order and Topic Difficulty on Assessor Agreement", "authors": ["Tadele T. Damessie\n,", "Falk Scholer\n,", "Kalvero Järvelin\n,", "J. Shane Culpepper"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nHuman relevance judgments are a key component for measuring the effectiveness of information retrieval systems using test collections. Since relevance is not an absolute concept, human assessors can disagree on particular topic-document pairs for a variety of reasons. In this work we investigate the effect that document presentation order has on inter-rater agreement, comparing two presentation ordering approaches similar to those used in IR evaluation campaigns: decreasing relevance order and document identifier order. We make a further distinction between \"easy\" topics and \"hard\" topics in order to explore system effects on inter-rater agreement. The results of our pilot user study indicate that assessor agreement is higher when documents are judged in document identifier order. In addition, there is higher overall agreement on easy topics than on hard topics.", "references": ["P. Bailey, N. Craswell, I. Soboroff, P. Thomas, A. P. de Vries, and E. Yilmaz. Relevance assessment: are judges exchangeable and does it matter. In Proc. SIGIR, pages 667--674. ACM, 2008.", "B. Carterette, V. Pavlu, H. Fang, and E. Kanoulas. Million query track 2009 overview. In TREC, 2009.", "C. A. Cuadra, R. V. Katter, E. H. Holmes, and E. M. Wallace. Experimental Studies of Relevance Judgments. Final Report. 3 Volumes. System Development Corporation, 1967."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970431"}, {"title": "A study of factuality, objectivity and relevance: three desiderata in large-scale information retrieval?", "authors": ["Christina Lioma\n,", "Birger Larsen\n,", "Wei Lu\n,", "Yong Huang"], "publication": "BDCAT '16: Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies", "abstract": "ABSTRACT\nMuch of the information processed by Information Retrieval (IR) systems is unreliable, biased, and generally untrust-worthy [15, 45, 48]. Yet, factuality & objectivity detection is not a standard component of IR systems, even though it has been possible in Natural Language Processing (NLP) in the last decade. Motivated by this, we ask if and how factuality & objectivity detection may benefit IR. We answer this in two parts. First, we use state-of-the-art NLP to compute the probability of document factuality & objectivity in two TREC collections, and analyse its relation to document relevance. We find that factuality is strongly and positively correlated to document relevance, but objectivity is not. Second, we study the impact of factuality & objectivity to retrieval effectiveness by treating them as query independent features that we combine with a competitive language modelling baseline. Experiments with 450 TREC queries show that factuality improves precision by more than 10% over strong baselines, especially for the type of uncurated data typically used in web search; objectivity gives mixed results. An overall clear trend is that document factuality & objectivity is much more beneficial to IR when searching uncurated (e.g. web) documents vs. curated (e.g. state documentation and newswire articles).\nTo our knowledge, this is the first study of factuality & objectivity for back-end IR, contributing novel findings about the relation between relevance and factuality/objectivity, and statistically significant gains to retrieval effectiveness in the competitive web search task.", "references": ["K. Al Khatib, H. Schütze, and C. Kantner. Automatic detection of point of view differences in Wikipedia. In COLING, pages 33--50, 2012.", "C. Banea, R. Mihalcea, and J. Wiebe. Sense-level subjectivity in a multilingual setting. Computer Speech & Language, 28(1):7--19, 2014.", "S. M. Beitzel, O. Frieder, E. C. Jensen, D. Grossman, A. Chowdhury, and N. Goharian. Disproving the fusion hypothesis. In SAC, pages 823--827, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3006299.3006315"}, {"title": "Beyond Clustering: Sub-DAG Discovery for Categorising Documents", "authors": ["Ramakrishna B. Bairi\n,", "Mark J. Carman\n,", "Ganesh Ramakrishnan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study the problem of generating DAG-structured category hierarchies over a given set of documents associated with \"importance\" scores. Example application includes automatically generating Wikipedia disambiguation pages for a set of articles having click counts associated with them. Unlike previous works, which focus on clustering the set of documents using the category hierarchy as features, we directly pose the problem as that of finding a DAG structured generative mode that has maximum likelihood of generating the observed \"importance\" scores for each document where documents are modeled as the leaf nodes in the DAG structure. Desirable properties of the categories in the inferred DAG-structured hierarchy include document coverage and category relevance, each of which, we show, is naturally modeled by our generative model. We propose two different algorithms for estimating the model parameters. One by modeling the DAG as a Bayesian Network and estimating its parameters via Gibbs Sampling; and the other by estimating the path probabilities using the Expectation Maximization algorithm. We empirically evaluate our method on the problem of automatically generating Wikipedia disambiguation pages using human generated clusterings as the ground truth. We find that our framework improves upon the baselines according to the F1 score and Entropy that are used as standard metrics to evaluate the hierarchical clustering.", "references": ["20Newsgroups. http://qwone.com/~jason/20newsgroups/.", "Ramakrishna~B Bairi, Rishabh Iyer, Ganesh Ramakrishnan, and Jeff Bilmes. Summarization of multi-document topic hierarchies using submodular mixtures. 2015.", "James K. Baker. Trainable grammars for speech recognition. 1979."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983810"}, {"title": "Discovering Author Interest Evolution in Topic Modeling", "authors": ["Min Yang\n,", "Jincheng Mei\n,", "Fei Xu\n,", "Wenting Tu\n,", "Ziyu Lu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDiscovering the author's interest over time from documents has important applications in recommendation systems, authorship identification and opinion extraction. In this paper, we propose an interest drift model (IDM), which monitors the evolution of author interests in time-stamped documents. The model further uses the discovered author interest information to help finding better topics. Unlike traditional topic models, our model is sensitive to the ordering of words, thus it extracts more information from the semantic meaning of the context. The experiment results show that the IDM model learns better topics than state-of-the-art topic models.", "references": ["C. M. Bishop. Pattern recognition and machine learning, volume 1. springer New York, 2006.", "D. M. Blei and J. D. Lafferty. Dynamic topic models. In Proceedings of the 23rd ICML, pages 113--120. ACM, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914723"}, {"title": "SPYSE: a semantic search engine for python packages and modules", "authors": ["Shiva Krishna Imminni\n,", "Mir Anamul Hasan\n,", "Michael Duckett\n,", "Puneet Sachdeva\n,", "Sudipta Karmakar\n,", "Piyush Kumar\n,", "Sonia Haiduc"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering Companion", "abstract": "ABSTRACT\nCode reuse is a common practice among software developers, whether novices or experts. Developers often rely on online resources in order to find code to reuse. For Python, the Python Package Index (PyPI) contains all packages developed for the community and is the largest catalog of reusable, open source packages developers can consult. While a valuable resource, the state of the art PyPI search has very limited capabilities, making it hard for developers to find useful, high quality Python code to use for their task at hand.\nWe introduce SPYSE (Semantic PYthon Search Engine), a web-based search engine that overcomes the limitations of the state of the art, making it easier for developers to find useful code. The power of SPYSE lays in the combination of three different aspects meant to provide developers with relevant, and at the same time high quality code: code semantics, popularity, and code quality. SPYSE also allows searching for modules, in addition to packages, which opens new reuse opportunities for developers, currently not supported. TOOL URL: https://pypi.compgeom.com VIDEO URL: https://youtu.be/Praglw-vS50", "references": ["S. Bajracharya, J. Ossher, and C. Lopes. Sourcerer: An infrastructure for large-scale collection and analysis of open-source code. Sci. Comp. Prog., 79:241--259, 2014.", "B. Jansen and A. Spink. How are we searching the www? a comparison of nine search engine transaction logs. Info. Proc. & Mgmt, 42(1):248--263, 2006.", "C. McMillan, D. Poshyvanyk, M. Grechanik, Q. Xie, and C. Fu. Portfolio: Searching for relevant functions and their usages in millions of lines of code. ACM Trans. Softw. Eng. Methodol., 22(4):37, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2889160.2889174"}, {"title": "Medical Information Search Workshop (MEDIR)", "authors": ["Steven Bedrick\n,", "Lorraine Goeuriot\n,", "Gareth J.F. Jones\n,", "Anastasia Krithara\n,", "Henning Mueller\n,", "George Paliouras"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917761"}, {"title": "Bag-of-Entities Representation for Ranking", "authors": ["Chenyan Xiong\n,", "Jamie Callan\n,", "Tie-Yan Liu"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThis paper presents a new bag-of-entities representation for document ranking, with the help of modern knowledge bases and automatic entity linking. Our system represents query and documents by bag-of-entities vectors constructed from their entity annotations, and ranks documents by their matches with the query in the entity space. Our experiments with Freebase on TREC Web Track datasets demonstrate that current entity linking systems can provide sufficient coverage of the general domain search task, and that bag-of-entities representations outperform bag-of-words by as much as 18% in standard document ranking tasks.", "references": ["J. Dalton, L. Dietz, and J. Allan. Entity query feature expansion using knowledge base links. In Proceedings of the 37th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2014), pages 365--374. ACM, 2014.", "P. Ferragina and U. Scaiella. Fast and accurate annotation of short texts with Wikipedia pages. arXiv preprint arXiv:1006.3498, 2010.", "E. Gabrilovich, M. Ringgaard, and A. Subramanya. FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Release date 2013-06-26, Format version 1, Correction level 0), June 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970423"}, {"title": "How to Compete Online for News Audience: Modeling Words that Attract Clicks", "authors": ["Joon Hee Kim\n,", "Amin Mantrach\n,", "Alejandro Jaimes\n,", "Alice Oh"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nHeadlines are particularly important for online news outlets where there are many similar news stories competing for users' attention. Traditionally, journalists have followed rules-of-thumb and experience to master the art of crafting catchy headlines, but with the valuable resource of large-scale click-through data of online news articles, we can apply quantitative analysis and text mining techniques to acquire an in-depth understanding of headlines. In this paper, we conduct a large-scale analysis and modeling of 150K news articles published over a period of four months on the Yahoo home page. We define a simple method to measure click-value of individual words, and analyze how temporal trends and linguistic attributes affect click-through rate (CTR). We then propose a novel generative model, headline click-based topic model (HCTM), that extends latent Dirichlet allocation (LDA) to reveal the effect of topical context on the click-value of words in headlines. HCTM leverages clicks in aggregate on previously published headlines to identify words for headlines that will generate more clicks in the future. We show that by jointly taking topics and clicks into account we can detect changes in user interests within topics. We evaluate HCTM in two different experimental settings and compare its performance with ALDA (adapted LDA), LDA, and TextRank. The first task, full headline, is to retrieve full headline used for a news article given the body of news article. The second task, good headline, is to specifically identify words in the headline that have high click values for current news audience. For full headline task, our model performs on par with ALDA, a state-of-the art web-page summarization method that utilizes click-through information. For good headline task, which is of more practical importance to both individual journalists and online news outlets, our model significantly outperforms all other comparative methods.", "references": ["M. Ahmed, S. Spagna, F. Huici, and S. Niccolini. A peek into the future: Predicting the evolution of popularity in user generated content. In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM '13, pages 607--616, New York, NY, USA, 2013.", "R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval - the concepts and technology behind search, Second edition. Pearson Education Ltd., Harlow, England, 2011.", "R. Bandari, S. Asur, and B. A. Huberman. The pulse of news in social media: Forecasting popularity. In ICWSM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939873"}, {"title": "Revealed Preference at Scale: Learning Personalized Preferences from Assortment Choices", "authors": ["Nathan Kallus\n,", "Madeleine Udell"], "publication": "EC '16: Proceedings of the 2016 ACM Conference on Economics and Computation", "abstract": "ABSTRACT\nWe consider the problem of learning the preferences of a heterogeneous population by observing choices from an assortment of products, ads, or other offerings. Our observation model takes a form common in assortment planning applications: each arriving customer is offered an assortment consisting of a subset of all possible offerings; we observe only the assortment and the customer's single choice. In this paper we propose a mixture choice model with a natural underlying low-dimensional structure, and show how to estimate its parameters. In our model, the preferences of each customer or segment follow a separate parametric choice model, but the underlying structure of these parameters over all the models has low dimension. We show that a nuclear-norm regularized maximum likelihood estimator can learn the preferences of all customers using a number of observations much smaller than the number of item-customer combinations. This result shows the potential for structural assumptions to speed up learning and improve revenues in assortment planning and customization. We provide a specialized factored gradient descent algorithm and study the success of the approach empirically.", "references": ["Fernando Bernstein, A Gürhan Kök, and Lei Xie. 2011. Dynamic assortment customization with limited inventories. Technical Report. Citeseer.", "Dimitris Bertsimas and Nathan Kallus. 2014. From Predictive to Prescriptive Analytics. arXiv preprint arXiv:1402.5481 (2014).", "Srinadh Bhojanapalli, Anastasios Kyrillidis, and Sujay Sanghavi. 2015. Dropping convexity for faster semi-definite optimization. arXiv preprint arXiv:1509.03917 (2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2940716.2940794"}, {"title": "Argumentation Mining: State of the Art and Emerging Trends", "authors": ["Marco Lippi\n,", "Paolo Torroni"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nArgumentation mining aims at automatically extracting structured arguments from unstructured textual documents. It has recently become a hot topic also due to its potential in processing information originating from the Web, and in particular from social media, in innovative ways. Recent advances in machine learning methods promise to enable breakthrough applications to social and economic sciences, policy making, and information technology: something that only a few years ago was unthinkable. In this survey article, we introduce argumentation models and methods, review existing systems and applications, and discuss challenges and perspectives of this exciting new research area.", "references": ["Palakorn Achananuparp, Xiaohua Hu, and Xiajiong Shen. 2008. The evaluation of sentence similarity measures. In Data Warehousing and Knowledge Discovery. Springer, 305--316.", "Ehud Aharoni, Anatoly Polnarov, Tamar Lavee, Daniel Hershcovich, Ran Levy, Ruty Rinott, Dan Gutfreund, and Noam Slonim. 2014. A benchmark dataset for automatic detection of claims and evidence in the context of controversial topics. In Proceedings of the 1st Workshop on Argumentation Mining. Association for Computational Linguistics, 64--68. http://acl2014.org/acl2014/W14-21/pdf/W14-2109.pdf.", "Kevin D. Ashley and Vern R. Walker. 2013. Toward constructing evidence-based legal arguments using legal decision documents and machine learning. In ICAIL 2012, Enrico Francesconi and Bart Verheij (Eds.). ACM, 176--180."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2850417"}, {"title": "Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM Encoder-Decoder", "authors": ["Soroush Vosoughi\n,", "Prashanth Vijayaraghavan\n,", "Deb Roy"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present Tweet2Vec, a novel method for generating general-purpose vector representation of tweets. The model learns tweet embeddings using character-level CNN-LSTM encoder-decoder. We trained our model on 3 million, randomly selected English-language tweets. The model was evaluated using two methods: tweet semantic similarity and tweet sentiment categorization, outperforming the previous state-of-the-art in both tasks. The evaluations demonstrate the power of the tweet embeddings generated by our model for various tweet categorization tasks. The vector representations generated by our model are generic, and hence can be applied to a variety of tasks. Though the model presented in this paper is trained on English-language tweets, the method presented can be used to learn tweet embeddings for different languages.", "references": ["J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.", "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493--2537, 2011.", "C. Fellbaum. WordNet. Wiley Online Library, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914762"}, {"title": "Dynamically ranked top-k spatial keyword search", "authors": ["Suprio Ray\n,", "Bradford G. Nickerson"], "publication": "GeoRich '16: Proceedings of the Third International ACM SIGMOD Workshop on Managing and Mining Enriched Geo-Spatial Data", "abstract": "ABSTRACT\nWith the growing data volume and popularity of Web services and Location-Based Services (LBS) new spatio-textual application are emerging. These applications are contributing to a deluge of geo-tagged documents. As a result, top-k spatial keyword searches have attracted a lot of attention and a number of spatio-textual indexes have been proposed. However, these indexes do not consider the \"recency\" of the indexed documents. Part of the challenge is due to the fact that the textual relevance score measures that these indexes use, require all documents to be inspected.\nTo address these issues, we propose the idea of \"dynamic ranking\" of spatio-textual objects. We also introduce a novel index, called STARI, which uses this ranking method to retrieve the most recent top-k relevant objects. Experimental evaluation demonstrates that that our system can support high document update rates and low query latency.", "references": ["L. Chen, G. Cong, C. S. Jensen, and D. Wu. Spatial keyword query processing: an experimental evaluation. In PVLDB, pages 217--228, 2013.", "S. Cheng, A. Arvanitis, M. Chrobak, and V. Hristidis. Multi-Query Diversification in Microblogging Posts. In EDBT, pages 133--144, 2014.", "F. M. Choudhury, J. S. Culpepper, and T. Sellis. Batch Processing of Top-k Spatial-textual Queries. In GeoRich, pages 7--12, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948649.2948655"}, {"title": "Bringing order to chaos in MOOC discussion forums with content-related thread identification", "authors": ["Alyssa Friend Wise\n,", "Yi Cui\n,", "Jovita Vytasek"], "publication": "LAK '16: Proceedings of the Sixth International Conference on Learning Analytics & Knowledge", "abstract": "ABSTRACT\nThis study addresses the issues of overload and chaos in MOOC discussion forums by developing a model to categorize and identify threads based on whether or not they are substantially related to the course content. Content-related posts were defined as those that give/seek help for the learning of course material and share/comment on relevant resources. A linguistic model was built based on manually-coded starting posts in threads from a statistics MOOC (n=837) and tested on thread starting posts from the second offering of the same course (n=304) and a different statistics course (n=298). The number of views and votes threads received were tested to see if they helped classification. Results showed that content-related posts in the statistics MOOC had distinct linguistic features which appeared to be unrelated to the subject-matter domain; the linguistic model demonstrated good cross-course reliability (all recall and precision > .77) and was useful across all time segments of the courses; number of views and votes were not helpful for classification.", "references": ["Agrawal, A., Venkatraman, J., Leonard, S., and Paepcke, A. 2015. YouEDU: addressing confusion in MOOC discussion forums by recommending instructional video clips. In Proceedings of the 8th International Conference on Education Data Mining (Madrid, Spain, June 26-29, 2015). ACM, New York, NY, USA, 297--304.", "Breslow, L., Pritchard, D. E., DeBoer, J., Stump, G. S., Ho, A. D., and Seaton, D. T. 2013. Studying learning in the worldwide classroom research into edX's first MOOC. Research & Practice In Assessment, 8, 13--25.", "Brinton, C. G., Chiang, M., Jain, S., Lam, H., Liu, Z., and Wong, F. M. F. 2014. Learning about social learning in MOOCs: from statistical analysis to generative model. IEEE Transactions on Learning Technologies, 7, 4, 346--359. DOI= 10.1109/TLT.2014.2337900."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2883851.2883916"}, {"title": "Babel: A Platform for Facilitating Research in Scholarly Article Discovery", "authors": ["Ian Wesley-Smith\n,", "Jevin D. West"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe body of scientific literature is growing at an exponential rate. This expansion of scientific knowledge has increased the need for tools to help users find relevant articles. However, researchers developing new scholarly article recommendation algorithms face two substantial hurdles: acquiring high-quality, large-scale scholarly metadata and mechanisms for evaluating their recommendation algorithms. To address these problems we created Babel---an open-source platform uniting publisher, researchers, and users. Babel includes tens of millions of scholarly articles, several recommendation algorithms, and tools for integrating recommendations into publisher websites and other scholarly platforms.", "references": ["J. Beel, M. Genzmehr, S. Langer, A. Nürnberger, and B. Gipp. A comparative analysis of offline and online evaluations and discussion of research paper recommender system evaluation. In Proceedings of the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation, RepSys '13, pages 7--14, New York, NY, USA, 2013. ACM.", "J. Beel, S. Langer, M. Genzmehr, B. Gipp, C. Breitinger, and A. Nürnberger. Research paper recommender system evaluation: A quantitative literature survey. In Proceedings of the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation, RepSys '13, pages 15--22, New York, NY, USA, 2013. ACM.", "P. B. Kantor, F. Ricci, L. Rokach, and B. Shapira. Recommender Systems Handbook. Springer, Dordrecht, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890517"}, {"title": "Rough co-citation as a measure of relationship to expand co-citation networks for scientific paper searches", "authors": ["Masaki Eto"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis paper proposes a \"rough co-citation\", which is a measure of relationship to expand co-citation networks so as to include new relevant documents. A rough co-citation relationship is a linkage between a pair of documents which are cited by two other documents in a similar citation context. The linkage strength of a rough co-citation relationship may be weaker than the original co-citation relationship, because a rough co-citation relationship is determined by citations in two separate documents. Rough co-citation linkages, however, may yield new relevant documents that are not identified by the original co-citation linkages. For example, the rough co-citation can identify relevant documents that are published after the citing document of the original co-citation becomes public. This study conducted IR experiments to evaluate the search performances of retrieval methods using the co-citation networks expanded by the rough co-citation relationships. Specifically, the random walk with restart, which is one of the latest graph search algorithms, is applied to the expanded and original co-citation networks. Scores of the normalized discounted cumulative gain (nDCG@K) are then compared. The results indicate that the search performance of the method using the expanded network outperforms a baseline method using the original network.", "references": ["Eto, M. (2013). Evaluations of context-based co-citation searching. Scientometrics, 94(2), 651--673.", "Eto, M. (2014). Document retrieval method using random walk with restart on weighted co-citation network, Proceedings of the 77th ASIS&T Annual Meeting.", "Eto, M. (2016). Incorporating satellite documents into co-citation networks for scientific paper searches. Proceedings of the Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL2016), 30--35."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017578"}, {"title": "User profile extraction engine", "authors": ["Kleanthis Gatziolis\n,", "Anthony C. Boucouvalas"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nThe Internet is overwhelmed by a huge amount of information every day and every user has different interests from another. It is therefore important that this information is filtered and sorted according to their preferences. Thus, the profiling systems exploit particularities and preferences of each user and finally they can be studied or used by other applications or humans. This paper analyzes the methods of collecting data (data gathering), and the ways in which this information can be used - filtered so as to create knowledge. A user profile extraction engine is presented and analyzed.", "references": ["https://technet.microsoft.com/en-us/library/ee721054.aspx, Last retrieved on March 01, 2016", "http://www1.janrain.com/rs/janrain/images/White-Paper-Best-Practices-in-Online-Registration.pdf, Last retrieved on March 01, 2016", "Ashwini Rao, Florian Schaub, Norman Sadeh, What do they know about me? Contents and Concerns of Online Behavioral Profiles, Contents and Concerns of Online Behavioral Profiles (2014) ASE BigData/SocialInformatics/PASSAT/BioMedCom Conference, 2015"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003761"}, {"title": "Trajbase: searching trajectories in multi-region", "authors": ["Renjie Zheng\n,", "Qin Liu\n,", "Hanjun Mao\n,", "Hongming Zhu\n,", "Weixiong Rao"], "publication": "UrbanGIS '16: Proceedings of the 2nd ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics", "abstract": "ABSTRACT\nThe recent years witnessed popular use of smart phones and wearable devices. Such mobile devices are widely equipped with GPS sensors to record their geographical positions, generating massive spatial trajectory data. Many real applications, such as urban computing and intelligent transportation systems, search the trajectory data. To process such queries, it is important to meet two objectives including fast running time and low space cost. Previous work frequently only meets one objective but compromises another. In this work, we design a compact data structure TrajBase to index trajectory data. The novelty of such an indexing structure is a carefully designed encoding approach. The approach can achieve comparable compression ratio compared with the state of the art approach and fast building time. Extensive evaluation with two real trajectory datasets can successfully verify that TrajBase outperforms previous works in terms of query processing time and indexing space cost.", "references": ["V. P. Chakka, A. Everspaugh, and J. M. Patel. Indexing Large Trajectory Data Sets With SETI. CIDR, 2003.", "L. Chen, M. T. Özsu, and V. Oria. Robust and fast similarity search for moving object trajectories. In SIGMOD, pages 491--502, 2005.", "Z. Chen, H. T. Shen, X. Zhou, Y. Zheng, and X. Xie. Searching trajectories by locations: an efficiency study. In SIGMOD, pages 255--266, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007540.3007543"}, {"title": "Demiourgos: Agent-Based Simulation for the Analysis of Camuflage Evolution of Living Beings", "authors": ["Luiz H.M. Aguiar\n,", "Alexandre Zaghetto\n,", "Caue Zaghetto\n,", "Celia Gheini Ralha\n,", "Flavio Barros Vidal"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis paper presents the modeling and the implementation of an agent-based simulation tool, here called Demiourgos, that allows the obervation of the camuflage evolution in virtual organisms that are put together with their predators. The case study developed was inspired by John A. Endler's research, in which he observed how natural selection induces color pattern changes in the lebistes fishes (Poecilia reticulata). The agents behavior model was defined through observation research. The preliminary results show that the proposed agent-based model achieves satisfactory levels in relation to the original work used as reference. The simulation tool can be mainly used by researchers that need to work with multiple variables to understand complex models of living beings interactions, helping the process of decision making about species conservation issues.", "references": ["Biologically inspired guidance for motion camouflage, volume 3, 2004.", "Richard Dawkins. O Maior Espetaculo da Terra - As Evidencias da Evolucao. Companhia das Letras, Sao Paulo, 2009.", "John A. Endler. Natural selection on color patterns in poecilia reticulata. Evolution, 8-34:76-91, 1980."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021972"}, {"title": "Sentiment Analysis: Comparing the use of tools and the human analysis", "authors": ["Vanessa S. Moreira\n,", "Sean W. Siqueira\n,", "Leila Andrade\n,", "Mariano Pimentel"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nSentiment Analysis emerged from the need to treat and evaluate texts, opinions and comments made by users on the Internet, in order to understand how they relate to a given entity. Several analytical methods have been developed in an attempt to better translate the uncertain and the subjectivity of human feelings. This research used data from interactions in a social network to identify the sentiments involved in each student comment. From the collected text different methods of sentiment analysis were used in order to identify which method had better results compared to the real ones. The comparison showed differences between these results and the real ones: while the used tools classified more than 40% of the comments as neutral, the analysis of the messages' author showed that 71% of the comments were positive. In the classification, the occurrence of outliers was identified as well as differences on the intensity of the sentiments acquired with each method. No approach, including the one performed by one of the researchers, was considered efficient enough as the highest level of accuracy obtained was less than 70%.", "references": ["Abbasi, A., Chen, H., e Salem, A. 2008. Sentiment analysis in multiple languages: Feature selection for opinion classification in Web forums. ACM Transactions on Information Systems (TOIS), Vol. 26, No. 3, p. 12.", "Ahmed, K.; El Tazi, N.; Hossny, A. H. Sentiment Analysis Over Social Networks: An Overview", "Altrabsheh, N., Cocea, M., e Fallahkhair, S. 2014. Learning sentiment from students' feedback for real-time interventions in classrooms. In: Adaptive and Intelligent Systems. Springer International Publishing. p. 40-49."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022029"}, {"title": "Towards geo-referencing infrastructure for local news", "authors": ["Guoray Cai\n,", "Ye Tian"], "publication": "GIR '16: Proceedings of the 10th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nLocal news articles are an important source of knowledge about local events, place-specific culture, and peoples' thoughts about their environment. Reliable geocoding of such articles is the first step towards unlocking such local knowledge for community engagement and development. However, existing geo-referencing methods and tools do not work well for local news because they do not reflect the ways local people encode and communicate geographical knowledge. This paper argues that local news requires a different method and infrastructure support for effective geo-referencing. To gain insights on the unique aspects of local gazetteers and the nature of ambiguities, we present an analysis of a collection of local new articles. We found that place references in local news have their special vocabulary, and that their ambiguities are handled differently by local people. We translated such insights into a gazetteer-based geocoding solution that combines progressive geocoding with a smart footprint recommender. Progressive geocoding service uses Nominatim (OpenStreetMap) as the initial gazetteer to jump-start the construction of local gazetteer for a community and by the community. LocusRecommender automatically suggests the best matches from gazetteer ranked by a set of heuristic rules. Preliminary evaluation shows that our smart footprint recommender predicts 80% of the answers by its top-three recommendations.", "references": ["E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-where: geotagging web content. Proceedings of SIGIR '04 conference on Research and development in information retrieval, pages 273--280, 2004.", "I. Bensalem and M. K. Kholladi. Toponym disambiguation by arborescent relationships. Journal of Computer Science, 6(6):653--659, 2010.", "C. Buchanan. Sense of place in the daily newspaper. Aether: The Journal of Media Geography, 4(March):62--84, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003464.3003473"}, {"title": "Understanding Website Behavior based on User Agent", "authors": ["Kien Pham\n,", "Aécio Santos\n,", "Juliana Freire"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb sites have adopted a variety of adversarial techniques to prevent web crawlers from retrieving their content. While it is possible to simulate users behavior using a browser to crawl such sites, this approach is not scalable. Therefore, understanding existing adversarial techniques is important to design crawling strategies that can adapt to retrieve the content as efficiently as possible. Ideally, a web crawler should detect the nature of the adversarial policies and select the most cost-effective means to defeat them.\nIn this paper, we discuss the results of a large-scale study of web site behavior based on their responses to different user-agents. We issued over 9 million HTTP GET requests to 1.3 million unique web sites from DMOZ using six different user-agents and the TOR network as an anonymous proxy. We observed that web sites do change their responses depending on user-agents and IP addresses. This suggests that probing sites for these features can be an effective means to detect adversarial techniques.", "references": ["D. Doran and S. S. Gokhale. Web robot detection techniques: Overview and limitations. Data Mining Knowledge Discovery, pages 183--210, Jan. 2011.", "C. L. Giles, Y. Sun, and I. G. Councill. Measuring the web crawler ethics. In roceedings of the 19th International Conference on World Wide Web, pages 1101--1102, 2010.", "B. Jones, T.-W. Lee, N. Feamster, and P. Gill. Automated detection and fingerprinting of censorship block pages. In Proceedings of the 2014 Conference on Internet Measurement Conference, pages 299--304, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914757"}, {"title": "Hybrid Indexing for Versioned Document Search with Cluster-based Retrieval", "authors": ["Xin Jin\n,", "Daniel Agun\n,", "Tao Yang\n,", "Qinghao Wu\n,", "Yifan Shen\n,", "Susen Zhao"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe previous two-phase method for searching versioned documents seeks a cost tradeoff by using non-positional information to rank document versions first. The second phase then re-ranks top document versions using positional information with fragment-based index compression. This paper proposes an alternative approach that uses cluster-based retrieval to quickly narrow the search scope guided by version representatives at Phase 1 and develops a hybrid index structure with adaptive runtime data traversal to speed up Phase 2 search. The hybrid scheme exploits the advantages of forward index and inverted index based on the term characteristics to minimize the time in extracting positional and other feature information during runtime search. This paper compares several indexing and data traversal options with different time and space tradeoffs and describes evaluation results to demonstrate their effectiveness. The experiment results show that the proposed scheme can be up-to about 4x as fast as the previous work on solid state drives while retaining good relevance.", "references": ["I. S. Altingovde, E. Demir, F. Can, and O. Ulusoy. Incremental cluster-based retrieval using compressed cluster-skipping inverted files. ACM Trans. Inf. Syst., 26(3):15:1--15:36, 2008.", "V. N. Anh and A. Moffat. Index compression using fixed binary codewords. In Proc. of 15th Australasian Database Conference, pages 61--67, 2004.", "P. G. Anick and R. A. Flynn. Versioning a full-text information retrieval system. In SIGIR, pages 98--111, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983733"}, {"title": "Requirements Traceability in Agile Methodologies: A Exploratory Survey", "authors": ["Gabriela O. Trindade\n,", "Marcia Lucena"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nAgile methodologies are increasingly present in the industry. Known as a methodology that adapts easily to changes, which reduces risk and provides product creation quickly and safely, it has features such as: constant contact with the client, generation of releases at the end of each iteration, prioritizing what has more value to the client, in addition to \"embrace\" easily the changes requested. Being requirements traceability important when we think of changes as it facilitates activities such as impact analysis, it is possible to realize that it would be a very useful activity in the agile process. However, there are some challenges when trying to apply traceability in agile environments. This paper is aimed to perform an exploratory research to raise the main problems related to traceability in agile environments, thus collecting information to assist in raising requirements for a tool that supports traceability in agile environments, and perform pre-traceability inter-tracking and post-traceability.", "references": ["Antonino, P.O., Keuler, T., Germann, N., and Cronauer, B. 2014. A non-invasive approach to trace architecture design, requirements specification and agile artifacts. In Software Engineering Conference (ASWEC), 2014 23rd Australian IEEE, p. 220-229.", "Arbain, F.B.A., Ghani, I., Kadir, W.M.N.W. 2014. Agile non functional requiremnents (NFR) traceability metamodel. In Software Engineering Conference (MySEC), 2014 8th Malaysian IEEE, p. 228-233.", "Bassi Filho, D.L. 2008. Experiencias com desenvolvimento agil, Dissertacao de Mestrado, Universidade de Sao Paulo."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022036"}, {"title": "Analysis of Information Retrieval in Call Center Documents - Case Study in Computer Solutions Bases.", "authors": ["Leandro Santos Gaspar\n,", "Flavia Cristina Bernardini\n,", "Leila Weitzel"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nCall Centers aim to be more productive by performing a standard service for its customers. In order to accomplish this goal, it is used procedures, which contains a set of likely solutions. It must be stressed that the current engine uses a simplified Boolean model, and left the systems less consistent e slow with the Call Center needs. This research aims to figure out which information retrieval methods, e.g., vector or probabilistic, have better performance in a search engine.", "references": ["SILVEIRA, Sandra Maria; MOURA, Maria Aparecida. Scripts de atendimento em call centers: uma visao de documentos eletronicos. Encontros Bibli: revista eletronica de biblioteconomia e ciencia da informacao, v. 15, n. 29, p. 145-168, 2010.", "SOUZA, Renato Rocha. Comparing three different techniques to retrieve documents using multiwords expressions.", "DA SILVA, Edson Marchetti; SOUZA, Renato Rocha. Comparing three different techniques to retrieve documents using multiwords expressions. In:10 CONTECSI. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021963"}, {"title": "GeoTrend: spatial trending queries on real-time microblogs", "authors": ["Amr Magdy\n,", "Ahmed M. Aly\n,", "Mohamed F. Mokbel\n,", "Sameh Elnikety\n,", "Yuxiong He\n,", "Suman Nath\n,", "Walid G. Aref"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nThis paper presents GeoTrend; a system for scalable support of spatial trend discovery on recent microblogs, e.g., tweets and online reviews, that come in real time. GeoTrend is distinguished from existing techniques in three aspects: (1) It discovers trends in arbitrary spatial regions, e.g., city blocks. (2) It supports trending measures that effectively capture trending items under a variety of definitions that suit different applications. (3) It promotes recent microblogs as first-class citizens and optimizes its system components to digest a continuous flow of fast data in main-memory while removing old data efficiently. GeoTrend queries are top-k queries that discover the most trending k keywords that are posted within an arbitrary spatial region and during the last T time units. To support its queries efficiently, GeoTrend employs an in-memory spatial index that is able to efficiently digest incoming data and expire data that is beyond the last T time units. The index also materializes top-k keywords in different spatial regions so that incoming queries can be processed with low latency. In case of peak times, a main-memory optimization technique is employed to shed less important data, so that the system still sustains high query accuracy with limited memory resources. Experimental results based on real Twitter feed and Bing Mobile spatial search queries show the scalability of GeoTrend to support arrival rates of up to 50,000 microblog/second, average query latency of 3 milli-seconds, and at least 90+% query accuracy even under limited memory resources.", "references": ["H. Abdelhaq, C. Sengstock, and M. Gertz. EvenTweet: Online Localized Event Detection from Twitter. In VLDB, 2013.", "A. Arasu and G. S. Manku. Approximate Counts and Quantiles over Sliding Windows. In PODS, 2004.", "W. G. Aref and H. Samet. Efficient Processing of Window Queries in The Pyramid Data Structure. In PODS, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996986"}, {"title": "Querylog-based Assessment of Retrievability Bias in a Large Newspaper Corpus", "authors": ["Myriam C. Traub\n,", "Thaer Samar\n,", "Jacco van Ossenbruggen\n,", "Jiyin He\n,", "Arjen de Vries\n,", "Lynda Hardman"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nBias in the retrieval of documents can directly influence the information access of a digital library. In the worst case, systematic favoritism for a certain type of document can render other parts of the collection invisible to users. This potential bias can be evaluated by measuring the retrievability for all documents in a collection. Previous evaluations have been performed on TREC collections using simulated query sets. The question remains, however, how representative this approach is of more realistic settings.\nTo address this question, we investigate the effectiveness of the retrievability measure using a large digitized newspaper corpus, featuring two characteristics that distinguishes our experiments from previous studies: (1) compared to TREC collections, our collection contains noise originating from OCR processing, historical spelling and use of language; and (2) instead of simulated queries, the collection comes with real user query logs including click data.\nFirst, we assess the retrievability bias imposed on the newspaper collection by different IR models. We assess the retrievability measure and confirm its ability to capture the retrievability bias in our setup. Second, we show how simulated queries differ from real user queries regarding term frequency and prevalence of named entities, and how this affects the retrievability results.", "references": ["L. Azzopardi and V. Vinay. Retrievability: An evaluation measure for higher order information access tasks. In Proceedings of the 17th ACM Conference on Infor- mation and Knowledge Management, CIKM '08, pages 561--570, New York, NY, USA, 2008. ACM.", "R. Bache and L. Azzopardi. Improving access to large patent corpora. In A. Hameurlain, J. Küng, R. Wagner, T. Bach Pedersen, and A. Tjoa, editors, Transactions on Large-Scale Data- and Knowledge-Centered Systems II, volume 6380 of Lecture Notes in Computer Science, pages 103--121. Springer Berlin Heidelberg, 2010.", "S. Bashir. Estimating retrievability ranks of documents using document features. Neurocomputing, 123(0):216--232, 2014. Contains Special issue articles: Advances in Pattern Recognition Applications and Methods."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910907"}, {"title": "User-Oriented Context Suggestion", "authors": ["Yong Zheng\n,", "Bamshad Mobasher\n,", "Robin Burke"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nRecommender systems have been used in many domains to assist users' decision making by providing item recommendations and thereby reducing information overload. Context-aware recommender systems go further, incorporating the variability of users' preferences across contexts, and suggesting items that are appropriate in different contexts. In this paper, we present a novel recommendation task, \"Context Suggestion\", whereby the system recommends contexts in which items may be selected. We introduce the motivations behind the notion of context suggestion and discuss several potential solutions. In particular, we focus specifically on user-oriented context suggestion which involves recommending appropriate contexts based on a user's profile. We propose extensions of well-known context-aware recommendation algorithms such as tensor factorization and deviation-based contextual modeling and adapt them as methods to recommend contexts instead of items. In our empirical evaluation, we compare the proposed solutions to several baseline algorithms using four real-world data sets.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-aware recommender systems. AI Magazine, 32(3):67--80, 2011.", "G. Adomavicius and A. Tuzhilin. Tutorial on Context-aware Recommender Systems, the 2nd ACM Conference on Recommender Systems. http://ids.csom.umn.edu/faculty/gedas/talks/RecSys2008-tutorial.pdf.", "L. Baltrunas, K. Church, A. Karatzoglou, and N. Oliver. Frappe: Understanding the usage and perception of mobile app recommendations in-the-wild. CoRR, abs/1505.03014, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930252"}, {"title": "Querying and reasoning over large scale building data sets: an outline of a performance benchmark", "authors": ["Pieter Pauwels\n,", "Tarcisio Mendes de Farias\n,", "Chi Zhang\n,", "Ana Roxin\n,", "Jakob Beetz\n,", "Jos De Roo\n,", "Christophe Nicolle"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nThe architectural design and construction domains work on a daily basis with massive amounts of data. Properly managing, exchanging and exploiting these data is an ever ongoing challenge in this domain. This has resulted in large semantic RDF graphs that are to be combined with a significant number of other data sets (building product catalogues, regulation data, geometric point cloud data, simulation data, sensor data), thus making an already huge dataset even larger. Making these big data available at high performance rates and speeds and into the correct (intuitive) formats is therefore an incredibly high challenge in this domain. Yet, hardly any benchmark is available for this industry that (1) gives an overview of the kind of data typically handled in this domain; and (2) that lists the query and reasoning performance results in handling these data. In this article, we therefore present a set of available sample data that explicates the scale of the situation, and we additionally perform a query and reasoning performance benchmark. This results not only in an initial set of quantitative performance results, but also in recommendations in implementing a web-based system relying heavily on large semantic data. As such, we propose an initial benchmark through which new upcoming data management proposals in the architectural design and construction domains can be measured.", "references": ["Apache. Jena, 2015. https://jena.apache.org/.", "F. Baader and W. Nutt. Basic description logics. In Description Logic Handbook: Theory, Implementation, and Applications, pages 47--100. Cambridge University Press, Cambridge, MA, USA, 2003.", "R. Barbau, S. Krima, S. Rachuri, A. Narayanan, X. Fiorentini, S. Foufou, and R. D. Sriram. OntoSTEP: Enriching product model data using ontologies. Computer-Aided Design, 44(6):575--590, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928303"}, {"title": "Concept of Interactive Machine Learning in Urban Design Problems", "authors": ["Artem M. Chirkin\n,", "Reinhard König"], "publication": "SEACHI 2016: Proceedings of the SEACHI 2016 on Smart Cities for Better Living with HCI and UX", "abstract": "ABSTRACT\nThis work presents a concept of interactive machine learning in a human design process. An urban design problem is viewed as a multiple-criteria optimization problem. The outlined feature of an urban design problem is the dependence of a design goal on a context of the problem. We model the design goal as a randomized fitness measure that depends on the context. In terms of multiple-criteria decision analysis (MCDA), the defined measure corresponds to a subjective expected utility of a user.\nIn the first stage of the proposed approach we let the algorithm explore a design space using clustering techniques. The second stage is an interactive design loop; the user makes a proposal, then the program optimizes it, gets the user's feedback and returns back the control over the application interface.", "references": ["Michel Avital and Dov Te'Eni. 2009. From generative fit to generative capacity: Exploring an emerging dimension of information systems design and task performance. In Information Systems Journal, Vol. 19. 345--367.", "Liu Baoding and Chen Xiaowei. 2013. Uncertain Multiobjective Programming and Uncertain Goal Programming. Journal of Uncertainty Analysis and Applications (2013), 1--10.", "John Frazer. 2002. Creative Design and the Generative Evolutionary Paradigm. In Creative Evolutionary Systems. Elsevier, 253--274."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2898365.2899795"}, {"title": "Are self-assessment of search ability and performance reliable?", "authors": ["Chang Liu\n,", "Lu Zhang\n,", "Xiaoxuan Song"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis study examined users' self-rated search ability with their objective search performance, their subjective assessed search performance, and the accuracy of subjective assessments. Thirty students were recruited for the lab mode online search competition. Participants were asked to rate their search abilities before searching, and predict search performance after searching. The results showed that users' self-rated search ability was not related to their objective search performance in this search competition. As for subjective evaluation of their search performance, no significant difference was found on predicted-as-right, predicted-as-unsureness rate, or the correct and incorrect prediction rates. Besides 70% of correct predictions, all searchers tended to overestimate their search performance, but self-rated low searchers had more chance to predict their answers to the search tasks as wrong and underestimated their search performance sometimes. This study is an exploratory examination on users' self-rated search ability, and has implications to understand how searchers evaluate their search abilities and search performance.", "references": ["Boud, D., & Falchikov, N. (1989). Quantitative studies of student self-assessment in higher education: a critical analysis of findings. Higher Education, 18(5), 529--549.", "Brantmeier, C. (2006). Advanced l2 learners and reading placement: self-assessment, CBT, and subsequent performance. System, 34(1), 15--35.", "Cole, M. J., Zhang, X., Liu, J., Liu, C., Belkin, N. J., & Ralf, B., et al. (2010). Are self - assessments reliable indicators of topic knowledge? Proceedings of the ASIS&T, 47(1), 1--10."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017534"}, {"title": "Generative Mappings of New Data Publics", "authors": ["Beth Coleman"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nI argue for a vital relationship between current understanding of Big Data and how we might move toward new modes of mobile application design that draw on affective and generative \"data sets\". Toward this end, I look at projects that use the city as a living laboratory, including mobile apps, social media mapping, and various civic uses of Internet of Things (IoT) and surveillance technology. I chose these case studies for their appropriation of psychogeographic \"small data\" to map a city as they engage affective and immersive aspects of interaction and spatial design.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889308"}, {"title": "Extending the integrated intelligent computer-assisted language learning (iiCALL) environment", "authors": ["Harald Wahl\n,", "Rudolf Galler\n,", "Werner Winiwarter"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThe Integrated Intelligent Computer-Assisted Language Learning (iiCALL) environment offers options to learn natural languages with the use of common working environments like Web browsers or e-mail clients. Therefore, we designed a generic data model and developed a software framework handling language learning processes and information exchanges. A corresponding prototype, implemented as Firefox plug-in, shows the applicability of the generic data model to a specific learning scenario within an iiCALL environment. For developers, the paper proves extensibility by describing the framework and the way of extending iiCALL to add new learning scenarios and functionalities.", "references": ["H. Wahl, W. Winiwarter, and G. Quirchmayr, \"Towards an intelligent integrated language learning environment,\" Int. J. Pervasive Comput. Commun., vol. 7, no. 3, pp. 220--239, Sep. 2011.", "H. Wahl and W. Winiwarter, \"A Technological Overview of an Intelligent Integrated Computer-Assisted Language Learning (iiCALL) Environment,\" in ED-MEDIA 2011--World Conference on Educational Multimedia, Hypermedia & Telecommunications, Lisbon, 2011, vol. 2011, pp. 3832--3837.", "H. Wahl and W. Winiwarter, \"The Intelligent Integrated Computer-assisted Language Learning (iiCALL) Environment: Work in Progress,\" in Proceedings of the 13th International Conference on Information Integration and Web-based Applications and Services, New York, NY, USA, 2011, pp. 426--429."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011209"}, {"title": "A Framework for Dynamic Knowledge Modeling in Textbook-Based Learning", "authors": ["Yun Huang\n,", "Michael Yudelson\n,", "Shuguang Han\n,", "Daqing He\n,", "Peter Brusilovsky"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nVarious e-learning systems that provide electronic textbooks are gathering data on large numbers of student reading interactions. This data can potentially be used to model student knowledge acquisition. However, reading activity is often overlooked in canonical student modeling. Prior studies modeling learning from reading either estimate student knowledge at the end of all reading activities, or use quiz performance data with expert-crafted knowledge components (KCs). In this work, we demonstrate that the dynamic modeling of student knowledge is feasible and that automatic text analysis can be applied to save expert effort. We propose a data-driven approach for dynamic student modeling in textbook-based learning. We formulate the problem of modeling learning from reading as a reading-time prediction problem, reconstruct existing popular student models (such as Knowledge Tracing) and explore two automatic text analysis approaches (bag-of-words-based and latent semantic-based) to build the KC model. We evaluate the proposed framework using a dataset collected from a Human-Computer Interaction course. Results show that our approach for reading modeling is plausible; the proposed Knowledge Tracing-based student model reliably outperforms baselines and the latent semantic-based approach can be a promising way to construct a KC model. Serving as the first step to model dynamic knowledge in textbook-based learning, our framework can be applied to a broader context of open-corpus personalized learning.", "references": ["S. Bechhofer, C. Goble, L. Carr, W. Hall, S. Kampa, and D. De Roure. Cohse: Conceptual open hypermedia service. In Annotation for the Semantic Web, pages 193--210. IOS Press, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "P. Brusilovsky and J. Eklund. A study of user-model based link annotation in educational hypermedia. Journal of Universal Computer Science, 4(4):429--448, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930258"}, {"title": "Session details: Main Track - Software Architecture and Web Services in IS (I)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255994"}, {"title": "Set of t-uples expansion by example", "authors": ["Ngurah Agus Sanjaya Er\n,", "Talel Abdessalem\n,", "Stéphane Bressan"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nSet expansion is the task of finding elements of a set given example members. We are interested in the design of algorithms and techniques for a set expansion tool that expands a set by searching, finding and extracting candidates from the World Wide Web. Existing approaches mostly consider sets of atomic data. We extend this idea to the expansion of sets of t-uples, that is relation instances or tables. We propose an approach for extracting relation instances from the World Wide Web given a handful set of t-uple seeds. For instance, when the user proposes the set of seeds <IDR, Indonesia, Jakarta>, <CYN, China, Beijing>, <CAD, Canada, Ottawa> the system returns a relation containing currency codes with their corresponding country and capital city. We show how a random walk in a heterogeneous graph of Web pages, wrappers, seeds and candidates is able to rank the candidates according to their relevance to the seeds. We evaluate the performance of the approach and show that it is efficient, effective and practical.", "references": ["T. Abdessalem, B. Cautis, and N. Derouiche. Objectrunner: Lightweight, targeted extraction and querying of structured web data. PVLDB, 3(2):1585--1588, 2010.", "S. Brin. Extracting patterns and relations from the world wide web. In Selected Papers from the International Workshop on The World Wide Web and Databases, WebDB '98, pages 172--183, London, UK, UK, 1999. Springer-Verlag.", "Z. Chen, M. Cafarella, and H. V. Jagadish. Long-tail vocabulary dictionary extraction from the web. In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, WSDM '16, pages 625--634, New York, NY, USA, 2016. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011144"}, {"title": "Auroral Video Temporal Segmentation Based on Time-constrained Spectral Clustering", "authors": ["Qian Wang\n,", "XiangWei Hou\n,", "JiuLing Du"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nAcquiring a large amount of samples is a prerequisite for statistical analysis. In study of auroral phenomena, a tool which is able to segment 24-hour uninterrupted auroral observation into subsequences is urgently provided. This study aims at segmenting long auroral video into isolate auroral events based on clustering algorithm. The primary problem is how many events exist in a long uninterrupted auroral observation, i.e. deciding the number of clusters. We proposed a cluster validity index dedicated for manifold structure considering consistency within clusters and regional distribution between clusters. Then, we used the spectral clustering on the auroral image sequence. In order to guarantee the continuity and isolation of segments, a new temporal constrain was incorporated into clustering algorithm. Using the proposed method, the auroral videos were automatically segmented into a proper number of events. Compared with keogram, the auroral appearance and motion in the resultant segments exhibit homogeneity and the number of segments conform to the actual situation.", "references": ["Wang Q., Liang J. M., Hu Z. J., Hu H. H., Zhao H., Hu H. Q., Gao X. B., Yang H. G. 2010. Spatial Texture Based Automatic Classification of Dayside Aurora in All-Sky Images. Journal of Atmospheric and Solar-Terrestrial Physics, 72 (5-6): 498--508.", "Blixt E., Semeter J., Ivchenko N. 2006. Optical flow analysis of the aurora borealis. Geoscience and Remote Sensing Letters, IEEE, 3: 159--163.", "Yang Q. J., Liang J. M., Hu Z. J., Xing Z.Y. and Zhao H. 2012. Auroral Sequence Representation and Classification Using Hidden Markov Models. IEEE transactions on geoscience and remote sensing, 50 (12): 5049--5060."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007724"}, {"title": "Managing persistent heap in NVRAM", "authors": ["Kumud Bhandari"], "publication": "Mobile! 2016: Proceedings of the 1st International Workshop on Mobile Development", "abstract": "ABSTRACT\nThe scalability limitations of current DRAM technology have prompted research in alternative memory technologies. Almost all new viable alternatives being explored are non-volatile in nature. In this talk, we explore the implication of emerging non-volatile memory technologies (NVRAM) to mobile computing, the persistence programming models inspired by the emergence of NVRAM, and the challenges of managing persistent memory. Finally, we present Makalu, an approach that represents one possible solution to the persistent memory management challenges. Makalu avoids failure-induced persistent memory leaks, offers interoperability with a variety of NVRAM programming libraries (NVMPLs), while supporting a less restrictive programming model and delivering better performance compared to existing NVMPLs' default allocators.", "references": ["Process integration, devices and structures. International Technology Roadmap for Semiconductors (ITRS), 2013.", "K. Bhandari, D. R. Chakrabarti, and H.-J. Boehm. Makalu: Fast recoverable allocation of non-volatile memory. In Proceedings of the 2016 ACM International Conference on Object Oriented Programming Systems Languages and Applications, OOPSLA ’16, New York, NY, USA, 2016. ACM.", "H.-J. Boehm and M. Weiser. Garbage collection in an uncooperative environment. Softw. Pract. Exper., 18(9):807–820, September 1988."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001854.3001861"}, {"title": "InLook: Revisiting Email Search Experience", "authors": ["Pranav Ramarao\n,", "Suresh Iyengar\n,", "Pushkar Chitnis\n,", "Raghavendra Udupa\n,", "Balasubramanyan Ashok"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nEmails continue to remain the most important and widely used mode of online communication despite having its origins in the middle of last century and being threatened by a variety of online communication innovations. While several studies have predicted the continuous growth of volume of email communication, there is little innovation on improving the search in emails, an imperative part of the user experience. In this work, we present a lightweight email application codenamed InLook, that intends to provide a productive search experience.", "references": ["Email statistics. http://www.radicati.com/wp/wp-content/uploads/2015/02/Email-Statistics-Report-2015--2019-Executive-Summary.pdf .", "Gmail. https://mail.google.com.", "Gmail tabs. https://support.google.com/mail/answer/3055016?hl=en."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911458"}, {"title": "Semantic Querying based Concept Hierarchy Construction for Ontology Learning", "authors": ["B. Sathiya\n,", "T. V. Geetha"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nThe method of identifying a set of concepts (domain specific) and the relations among these concepts from text is called ontology learning. These relations can be taxonomical (hypernym and hyponym) or non-taxonomical relations. The important step in ontology learning is to, extract the concepts representing the domain and building the concept hierarchy based on the taxonomical relations prevailing between them. The important resources of the text used for concept hierarchy construction are domain-specific corpus and vast text from web pages. The former resource is static and most likely outdated information, whereas the latter resource is uncertain. Therefore, to tackle these drawbacks, we have proposed a new two-level semantic query formation methodology which is based on lexical-syntactic patterns. It utilizes both the resources of text: corpus and web pages for automatic concept hierarchy construction by discovering the hypernyms and hyponyms. Specifically, it resolves the limited and static content problem of the corpus by utilizing the vast and current knowledge available from the web. Meanwhile, the uncertainty of the knowledge in the web is removed by adding two new contextual information to the semantic queries. From the experimental results, it is evident that the proposed concept hierarchy construction method achieved enhancement of 6.5%, 5.65% and 6.8% for metrics such as Precision, Recall, and F-Measure respectively.", "references": ["Brank, J., Madenic, D., Groblenik, M. 2006. Gold standard based ontology evaluation using instance assignment. In Proceedings of the fourth workshop on evaluating ontologies for the web (EON2006). Edinburgh, Scotland.", "Cederberg, S., Widdows, D. 2003. Using LSA and noun coordination information to improve the precision and recall of automatic hyponymy extraction. In Proceedings 7th conference on natural language learning at HLTNAACL. 4, 111--118. Association for Computational Linguistics.", "Church K. W., Hanks, P. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics. 16 (1990), 22--29."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980307"}, {"title": "Big linked data ETL benchmark on cloud commodity hardware", "authors": ["Dieter De Witte\n,", "Laurens De Vocht\n,", "Ruben Verborgh\n,", "Kenny Knecht\n,", "Filip Pattyn\n,", "Hans Constandt\n,", "Erik Mannens\n,", "Rik Van de Walle"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nLinked Data storage solutions often optimize for low latency querying and quick responsiveness. Meanwhile, in the back-end, offline ETL processes take care of integrating and preparing the data. In this paper we explain a workflow and the results of a benchmark that examines which Linked Data storage solution and setup should be chosen for different dataset sizes to optimize the cost-effectiveness of the entire ETL process. The benchmark executes diversified stress tests on the storage solutions. The results include an in-depth analysis of four mature Linked Data solutions with commercial support and full SPARQL 1.1 compliance. Whereas traditional benchmarks studies generally deploy the triple stores on premises using high-end hardware, this benchmark uses publicly available cloud machine images for reproducibility and runs on commodity hardware. All stores are tested using their default configuration. In this setting Virtuoso shows the best performance in general. The other tree stores show competitive results and have disjunct areas of excellence. Finally, it is shown that each store's performance heavily depends on the structural properties of the queries, giving an indication of where vendors can focus their optimization efforts.", "references": ["G. Aluç, O. Hartig, M. T. Özsu, and K. Daudjee. Diversified stress testing of RDF data management systems. In The Semantic Web--ISWC 2014, pages 197--212. Springer, 2014.", "C. Bizer and A. Schultz. The Berlin SPARQL Benchmark. International Journal on Semantic Web and Information Systems (IJSWIS), 5(2):1--24, 2009.", "P. Cudré-Mauroux, I. Enchev, S. Fundatureanu, P. Groth, A. Haque, A. Harth, F. L. Keppmann, D. Miranker, J. F. Sequeda, and M. Wylot. NoSQL databases for RDF: an empirical evaluation. In The Semantic Web--ISWC 2013, pages 310--325. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928304"}, {"title": "Detecting Social Media Icebergs by Their Tips: Rumors, Persuasion Campaigns, and Information Needs", "authors": ["Zhe Zhao"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nNo abstract available.", "references": ["S. Kong, Q. Mei, L. Feng, F. Ye, and Z. Zhao. Predicting bursts and popularity of hashtags in real-time. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval, pages 927-930. ACM, 2014.", "Z. Zhao and Q. Mei. Questions about questions: An empirical analysis of information needs on twitter. In WWW, pages 1545-1556, 2013.", "Z. Zhao, P. Resnick, and Q. Mei. Enquiring minds: Early detection of rumors in social media from enquiry posts. In WWW, pages 1395-1405, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855086"}, {"title": "Predicting Search User Examination with Visual Saliency", "authors": ["Yiqun Liu\n,", "Zeyang Liu\n,", "Ke Zhou\n,", "Meng Wang\n,", "Huanbo Luan\n,", "Chao Wang\n,", "Min Zhang\n,", "Shaoping Ma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPredicting users' examination of search results is one of the key concerns in Web search related studies. With more and more heterogeneous components federated into search engine result pages (SERPs), it becomes difficult for traditional position-based models to accurately predict users' actual examination patterns. Therefore, a number of prior works investigate the connection between examination and users' explicit interaction behaviors (e.g.~click-through, mouse movement). Although these works gain much success in predicting users' examination behavior on SERPs, they require the collection of large scale user behavior data, which makes it impossible to predict examination behavior on newly-generated SERPs. To predict user examination on SERPs containing heterogenous components without user interaction information, we propose a new prediction model based on visual saliency map and page content features. Visual saliency, which is designed to measure the likelihood of a given area to attract human visual attention, is used to predict users' attention distribution on heterogenous search components. With an experimental search engine, we carefully design a user study in which users' examination behavior (eye movement) is recorded. Examination prediction results based on this collected data set demonstrate that visual saliency features significantly improve the performance of examination model in heterogeneous search environments. We also found that saliency features help predict internal examination behavior within vertical results.", "references": ["J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 539--548. ACM, 2014.", "L. Azzopardi and G. Zuccon. An analysis of theories of search and search behavior. In Proceedings of the 2015 International Conference on The Theory of Information Retrieval, pages 81--90, 2015.", "J. Bar-Ilan, K. Keenoy, M. Levene, and E. Yaari. Presentation bias is significant in determining user preference for search results--a user study. Journal of the American Society for Information Science and Technology, 60(1):135--149, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911517"}, {"title": "Personal BORIS: flavor-based cocktail recommendation", "authors": ["Johanna Greindl\n,", "Theresa Reiml\n,", "Stefan Will\n,", "Norbert Zsak"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nRecommender systems slowly get more involved in our everyday life in order to help users make day-to-day decisions. We researched for already existing cocktail mixers that produce automatically the users chosen drink from its list. However, none of these cocktail mixers have a personal cocktail recommendation system implemented. Therefore we extended an already existing automatic cocktail mixer called BORIS, by this recommendation function. BORIS is now able to suggest cocktails based on the user's self-estimated preferences, his observed behavior and cocktail ratings. We then evaluated our implemented recommender algorithm at a public event. The evaluation showed, that BORIS is able to predict how much a user will like a certain cocktail and therefore recommend personally relevant cocktails to him.", "references": ["Kattenbeck. Messeauftritte - Gerührt und nicht geschüttelt. 2006. Retrieved June 09, 2016 from http://iw.ur.de/forschung/messeauftritte/", "Monsieur. Professional Quality Cocktails in Seconds. 2015. Retrieved March 15, 2016 from http://monsieur.co/.", "Somabar. Meet Somabar. Your Robotic Bartender. 2014. Retrieved March 15, 2016 from http://www.somabarkickstarter.com/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2971411"}, {"title": "Correlation Autoencoder Hashing for Supervised Cross-Modal Search", "authors": ["Yue Cao\n,", "Mingsheng Long\n,", "Jianmin Wang\n,", "Han Zhu"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nDue to its storage and query efficiency, hashing has been widely applied to approximate nearest neighbor search from large-scale datasets. While there is increasing interest in cross-modal hashing which facilitates cross-media retrieval by embedding data from different modalities into a common Hamming space, how to distill the cross-modal correlation structure effectively remains a challenging problem. In this paper, we propose a novel supervised cross-modal hashing method, Correlation Autoencoder Hashing (CAH), to learn discriminative and compact binary codes based on deep autoencoders. Specifically, CAH jointly maximizes the feature correlation revealed by bimodal data and the semantic correlation conveyed in similarity labels, while embeds them into hash codes by nonlinear deep autoencoders. Extensive experiments clearly show the superior effectiveness and efficiency of CAH against the state-of-the-art hashing methods on standard cross-modal retrieval benchmarks.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In IEEE Symposium on Foundations of Computer Science, 2006.", "Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1798--1828, Aug 2013.", "M. Bronstein, A. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In Computer Vision and Pattern Recognition, 2010 IEEE Conference on, CVPR'10, pages 3594--3601. IEEE, June 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912000"}, {"title": "Cluster-based Joint Matrix Factorization Hashing for Cross-Modal Retrieval", "authors": ["Dimitrios Rafailidis\n,", "Fabio Crestani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCross-modal retrieval has been an emerging topic over the last years, as modern applications have to efficiently search for multimedia documents with different modalities. In this study, we propose a cross-modal hashing method by following a cluster-based joint matrix factorization strategy. Our method first builds clusters for each modality separately and then generates a cross-modal cluster representation for each document. We formulate a joint matrix factorization process with the constraint that pushes the documents' representations of the different modalities and the cross-modal cluster representations into a common consensus matrix. In doing so, we capture the inter-modality, intra-modality and cluster-based similarities in a unified latent space. Finally, we present an efficient way to generate the hash codes using the maximum entropy principle and compute the binary codes for external queries. In our experiments with two publicly available data sets, we show that the proposed method outperforms state-of-the-art hashing methods for different cross-modal retrieval tasks.", "references": ["M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, pages 3594--3601, 2010.", "G. Ding, Y. Guo, and J. Zhou. Collective matrix factorization hashing for multimodal data. In CVPR, pages 2083--2090, 2014.", "J. Gao, J. Han, J. Liu, and C. Wang. Multi-view clustering via joint nonnegative matrix factorization. In SDM, pages 252--260, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914710"}, {"title": "SECC: A Novel Search Engine Interface with Live Chat Channel", "authors": ["Cheng Zhang\n,", "Peng Zhang\n,", "Jingfei Li\n,", "Dawei Song"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTraditional information retrieval systems rank documents according to their relevance to users' input queries. State of the art commercial search engines (SEs) train ranking models and suggest query refinements by exploiting collective intelligence implicitly using global users' query logs. However, they do not provide an explicit channel for users to communicate with each other in the search process. By asking or discussing with other users on the fly, a user could find relevant information more conveniently and gain a better search experience. In this paper, we present a demo of novel Search Engine with a live Chat Channel (SECC). SECC can group users automatically based on their input queries and allow them to communicate with each other in real time through a chat interface.", "references": ["P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, and S. Vigna. The query-flow graph: model and applications. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 609?618. ACM, 2008.", "P. Clark. Elementary school science and math tests as a driver for ai: Take the aristo challenge. to appear, 2015.", "H. Duan and B.-J. P. Hsu. Online spelling correction for query completion. In Proceedings of the 20th international conference on World wide web, pages 117?126. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911454"}, {"title": "Interactive Multimodal Learning on 100 Million Images", "authors": ["Jan Zahálka\n,", "Stevan Rudinac\n,", "Björn Þór Jónsson\n,", "Dennis C. Koelma\n,", "Marcel Worring"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper presents Blackthorn, an efficient interactive multimodal learning approach facilitating analysis of multimedia collections of 100 million items on a single high-end workstation. This is achieved by efficient data compression and optimizations to the interactive learning process. The compressed i-I64 data representation costs tens of bytes per item yet preserves most of the visual and textual semantic information. The optimized interactive learning model scores the i-I64-compressed data directly, greatly reducing the computational requirements. The experiments show that Blackthorn is up to 105x faster than the conventional relevance feedback baseline. Blackthorn is shown to vastly outperform the baseline with respect to recall over time. Blackthorn reaches up to 92% of the precision achieved by the baseline, validating the efficacy of the i-I64 representation. On the YFCC100M dataset, Blackthorn performes one complete interaction round in 0.7 seconds. Blackthorn thus opens multimedia collections comprising 100 million items to learning-based analysis in fully interactive time.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, 2008.", "K. S. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is 'nearest neighbor' meaningful? In ICDT, 1999.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912062"}, {"title": "Optimization of the Radial Basis Function Neural Network Spread Factor for Electrical Impedance Tomography Image Reconstruction", "authors": ["Marketa Venclikova\n,", "Jakub Hlavica\n,", "Michal Prauzek\n,", "Jiri Koziorek"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nElectrical impedance tomography (EIT) is a low cost, non-invasive imaging technique where the inner resistivity distribution of the investigated object, corresponding to different tissue resistivity, is estimated from voltage measured on the boundary of the this object. The Electrical impedance tomography main problem is to get the resistivity distribution image of a given cross-sectional area based on the boundary voltage measurement. We used Radial basis function (RBF) neural network for image reconstruction in EIT and focused on examining the impact changing spread factor of the RBF to the results of the image reconstruction with the RBF neural network.", "references": ["M. Abdi and P. Liatsis, \"EIT in Breast Cancer Imaging: Application to Patient-Specific Forward Model,\" in Developments in E-systems Engineering (DeSE), 2011.", "J. A. Gnecchi, \"Voltage Controlled Current Source (VCCS) for Electrical Impedance Tomography (EIT) Measurements in the alpha and beta Dispersion Frequency Ranges,\" in Electronics, Robotics and Automotive Mechanics Conference (CERMA), 2010.", "K. Wu, J. Yang, X. Dong, F. Fu, F. Tao and S. Liu, \"Comparative study of reconstruction algorithms for electrical impedance tomography,\" in IFMBE Proceedings, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015183"}, {"title": "Enriching Mobility Data with Linked Open Data", "authors": ["Livia Ruback\n,", "Marco Antonio Casanova\n,", "Alessandra Raffaetà\n,", "Chiara Renso\n,", "Vania Vidal"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nRecent research has pointed out the needs and advantages of the semantic enrichment of movement data, a process where trajectories are partitioned into homogeneous segments that are annotated with contextual information. However, the lack of a comprehensive and well-defined framework for the enrichment makes this process difficult and error-prone. In this paper, we therefore propose a conceptual framework for the semantic enrichment of movement data, which benefits from the emerging Web of Data (or Linked Open Data) both as a unifying formalism and as the source of contextual data, which can be greatly useful for trajectories enrichment. Moreover, the semantic structure of such sources makes it easier to share and process enriched trajectories. We illustrate the enrichment process by presenting a case study in the tourism domain.", "references": ["W3C OWL Working group, 2012. OWL 2 web ontology language. document overview (second edition). W3C recommendation 11 december 2012. available at https://www.w3.org/tr/owl2-overview/.", "Ana Alves, Bruno Antunes, Francisco C Pereira, and Carlos Bento. Semantic enrichment of places: Ontology learning from web. International Journal of Knowledge-based and Intelligent Engineering Systems, 13(1):19--30, 2009.", "Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938550"}, {"title": "Personalized PageRank Estimation and Search: A Bidirectional Approach", "authors": ["Peter Lofgren\n,", "Siddhartha Banerjee\n,", "Ashish Goel"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nWe present new algorithms for Personalized PageRank estimation and Personalized PageRank search. First, for the problem of estimating Personalized PageRank (PPR) from a source distribution to a target node, we present a new bidirectional estimator with simple yet strong guarantees on correctness and performance, and 3x to 8x speedup over existing estimators in experiments on a diverse set of networks. Moreover, it has a clean algebraic structure which enables it to be used as a primitive for the Personalized PageRank Search problem: Given a network like Facebook, a query like \"people named John,\" and a searching user, return the top nodes in the network ranked by PPR from the perspective of the searching user. Previous solutions either score all nodes or score candidate nodes one at a time, which is prohibitively slow for large candidate sets. We develop a new algorithm based on our bidirectional PPR estimator which identifies the most relevant results by sampling candidates based on their PPR; this is the first solution to PPR search that can find the best results without iterating through the set of all candidate results. Finally, by combining PPR sampling with sequential PPR estimation and Monte Carlo, we develop practical algorithms for PPR search, and we show via experiments that our algorithms are efficient on networks with billions of edges.", "references": ["R. Andersen, C. Borgs, J. Chayes, J. Hopcraft, V. S. Mirrokni, and S.-H. Teng. Local computation of pagerank contributions. In Algorithms and Models for the Web-Graph. Springer, 2007.", "K. Avrachenkov, N. Litvak, D. Nemirovsky, and N. Osipova. Monte carlo methods in pagerank computation: When one iteration is sufficient. SIAM Journal on Numerical Analysis, 2007.", "B. Bahmani, A. Chowdhury, and A. Goel. Fast incremental and personalized pagerank. Proceedings of the VLDB Endowment, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835823"}, {"title": "GNMID14: A Collection of 110 Million Global Music Identification Matches", "authors": ["Cameron Summers\n,", "Greg Tronel\n,", "Jason Cramer\n,", "Aneesh Vartakavi\n,", "Phillip Popp"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nA new dataset is presented composed of music identification matches from Gracenote, a leading global music metadata company. Matches from January 1, 2014 to December 31, 2014 have been curated and made available as a public dataset called Gracenote Music Identification 2014, or GNMID14, at the following address: https://developer.gracenote.com/mid2014. This collection is the first significant music identification dataset and one of the largest music related datasets available containing more than 110M matches in 224 countries for 3M unique tracks, and 509K unique artists. It features geotemporal information (i.e. country and match date), genre and mood metadata. In this paper, we characterize the dataset and demonstrate its utility for Information Retrieval (IR) research.", "references": ["T. Bertin-Mahieux, D. P. Ellis, B. Whitman, and P. Lamere. The million song dataset. In ISMIR 2011: Proceedings of the 12th International Society for Music Information Retrieval Conference, October 24--28, 2011, Miami, Florida, pages 591--596. University of Miami, 2011.", "R. Campos, G. Dias, A. M. Jorge, and A. Jatowt. Survey of temporal information retrieval and related applications. ACM Computing Surveys (CSUR), 47(2):15, 2014.", "P. Cano, E. Batlle, T. Kalker, and J. Haitsma. A review of audio fingerprinting. Journal of VLSI signal processing systems for signal, image and video technology, 41(3):271--284, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914679"}, {"title": "Where Can I Buy a Boulder?: Searching for Offline Retail Locations", "authors": ["Sandro Bauer\n,", "Filip Radlinski\n,", "Ryen W. White"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nPeople commonly need to purchase things in person, from large garden supplies to home decor. Although modern search systems are very effective at finding online products, little research attention has been paid to helping users find places that sell a specific product offline. For instance, users searching for an apron are not typically directed to a nearby kitchen store by a standard search engine. In this paper, we investigate \"where can I buy\"-style queries related to in-person purchases of products and services. Answering these queries is challenging since little is known about the range of products sold in many stores, especially those which are smaller in size. To better understand this class of queries, we first present an in-depth analysis of typical offline purchase needs as observed by a major search engine, producing an ontology of such needs. We then propose ranking features for this new problem, and learn a ranking function that returns stores most likely to sell a queried item or service, even if there is very little information available online about some of the stores. Our final contribution is a new evaluation framework that combines distance with store relevance in measuring the effectiveness of such a search system. We evaluate our method using this approach and show that it outperforms a modern web search engine.", "references": ["A. Ashkan and C. L. Clarke. Characterizing commercial intent. In Proc. CIKM, 2009.", "A. Ashkan, C. L. Clarke, E. Agichtein, and Q. Guo. Classifying and characterizing query intent. In Proc. ECIR, 2009.", "D. R. Bell, T. H. Ho, and C. S. Tang. Determining Where to Shop: Fixed and Variable Costs of Shopping. J. Marketing Research, 35(3), 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882998"}, {"title": "Modeling the semantic content of the socio-tagged images based on the extended conceptual graphs formalism", "authors": ["Mariam Bouchakwa\n,", "Yassine Ayadi\n,", "Ikram Amous"], "publication": "MoMM '16: Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media", "abstract": "ABSTRACT\nWith the emergence of Web 2.0, the volume of multimedia documents, particularly the socio-tagged images, has become very considerable. This has made it the annotation and interrogation process of this type of documents a consuming and elusive task. A promising solution is to design methods allowing to model the semantic content of socio-tagged images in order to facilitate their annotation and the research process. Thus, we present in this paper a conceptual modeling approach of the semantic content of these images. First, our idea consists in expanding the conceptual graphs formalism in order to represent the relationships between the concepts and those that are between the concepts and their properties. Second, we use the extended graph to model the semantic content of the socio-tagged images. Experimental studies are conducted on a collection of 25.000 socio-tagged images shared in Flickr. The results demonstrate the effectiveness of our proposed approach.", "references": ["S. Aditya, Y. Yang, C. Baral, C. Fermuller, and Y. Aloimonos. From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge. In: CVPR, 2015.", "A. Benafia, R. Maamri, Z. Sahnoun, S. Saadaoui, and Y. Saadna. A Representation model of images based on graphs and automatic Instantiation of its Skeletal Configuration. In: IIMSS, 2011.", "A. N. Bhute and B. B. Meshram. Text Based Approach For Indexing And Retrieval Of Image And Video: A Review. In: AVC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007120.3007160"}, {"title": "Curious: Searching for Unknown Regions of Space with a Subpopulation-based Algorithm", "authors": ["Danilo Vasconcellos Vargas\n,", "Junichi Murata"], "publication": "GECCO '16 Companion: Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion", "abstract": "ABSTRACT\nIntrinsic motivation and novelty search are promising approaches to deal with plateaus, deceptive functions and other exploration problems where using only the main objective function is insufficient. However, it is not clear until now how and if intrinsic motivation (novelty search) can improve single objective algorithms in general. The hurdle is that using multi-objective algorithms to deal with single-objective problems adds an unnecessary overhead such as the search for non-dominated solutions. Here, we propose the Curious algorithm which is the first multi-objective algorithm focused on solving single-objective problems. Curious uses two subpopulations algorithms. One subpopulation is dedicated for improving objective function values and another one is added to search for unknown regions of space based on objective prediction errors. By using a differential evolution operator, genes from individuals in all subpopulations are mixed. In this way, the promising regions (solutions with high fitness) and unknown regions (solutions with high prediction error) are searched simultaneously. Because of thus realized strong yet well controlled novelty search, the algorithm possesses powerful exploration ability and outperforms usual single population based algorithms such as differential evolution. Thus, it demonstrates that the addition of intrinsic motivation is promising and should improve further single objective algorithms in general.", "references": ["R. Storn and K. Price. Differential evolution--a simple and efficient heuristic for global optimization over continuous spaces.", "D. V. Vargas, J. Murata, H. Takano, and A. C. B. Delbem. General subpopulation framework and taming the conflict inside populations. Evolutionary computation, 23(1):1--36, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908961.2908982"}, {"title": "Fast First-Phase Candidate Generation for Cascading Rankers", "authors": ["Qi Wang\n,", "Constantinos Dimopoulos\n,", "Torsten Suel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCurrent search engines use very complex ranking functions based on hundreds of features. While such functions return high-quality results, they create efficiency challenges as it is too costly to fully evaluate them on all documents in the union, or even intersection, of the query terms. To address this issue, search engines use a series of cascading rankers, starting with a very simple ranking function and then applying increasingly complex and expensive ranking functions on smaller and smaller sets of candidate results. Researchers have recently started studying several problems within this framework of query processing by cascading rankers; see, e.g., [5, 13, 17, 51].\nWe focus on one such problem, the design of the initial cascade. Thus, the goal is to very quickly identify a set of good candidate documents that should be passed to the second and further cascades. Previous work by Asadi and Lin [3, 5] showed that while a top-k computation on either the union or intersection gives good results, a further optimization using a global document ordering based on spam scores leads to a significant reduction in quality. Our contribution is to propose an alternative framework that builds specialized single-term and pairwise index structures, and then during query time selectively accesses these structures based on a cost budget and a set of early termination techniques. Using an end-to-end evaluation with a complex machine-learned ranker, we show that our approach finds candidates about an order of magnitude faster than a conjunctive top-k computation, while essentially matching the quality.", "references": ["D. Agarwal and M. Gurevich. Fast top-k retrieval for model based recommendation. In Proc. of the Fifth Int. Conf. on Web Search and Data Mining, pages 483--492, 2012.", "V. N. Anh and A. Moffat. Pruned query evaluation using pre-computed impacts. In Proc. of the 29th Annual Int. ACM SIGIR Conf. on Research and Development in Information Retrieval, 2006.", "N. Asadi. Multi-Stage Search Architectures for Streaming Documents. PhD thesis, University of Maryland, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911515"}, {"title": "Novel Robust Audio Watermarking Scheme against Synchronization Attacks", "authors": ["Mingyuan Cao\n,", "Chen Li\n,", "Zongze Wu\n,", "Lihua Tian\n,", "Shaoyi Du"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn this paper, a new robust watermarking scheme is described. In this scheme, two complementary watermarking algorithms are used to resist different attacks. First, the largest singular value of every frame is calculated after discrete wavelet transform (DWT) and segment. After single value decomposition (SVD), the watermark sequences are embedded several times, for redundancy, by adjusting the largest singular values of the frames according to the pre-set rule. This watermarking algorithm works well in the case of common signal processing. The second watermarking algorithm based on the histogram is utilized to resist synchronization attacks. In the process of image extraction, two types of watermarking images are extracted using two different methods. Then, an appropriate judgment is enforced to determine the final watermark image. In this way, though each of the two watermarking algorithms is not robust enough to withstand all attacks, they have complementary advantages. In other words, by embedding two types of watermarks, the whole watermarking scheme displays great robustness when facing both common signal processing and synchronization attacks.", "references": ["Sobha, R. V. and M. Sucharitha. 2015. Secure transmission of data using audio watermarking with protection on synchronization attack. Global Conference on Communication Technologies (Thuckalay, 2015), 592--597.", "Xiang. Y, Natgunanathan. I., Rong. Y., and Guo. S. 2015. Spread Spectrum-Based High Embedding Capacity Watermarking Method for Audio Signals. IEEE/ACM Transactions on Audio, Speech, and Language Processing (Dec. 2015), 2228--2237.", "Pandey. M. K., Parmar. G., and Gupta. R. 2015. Audio watermarking by spreading echo in time domain using pseudo noise gray sequence. International Conference on Industrial Instrumentation and Control(Pune, 2015), 740--743."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007698"}, {"title": "Interaction Design for Online Video and Television", "authors": ["David Geerts\n,", "Pablo Cesar\n,", "Marianna Obrist"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis course will teach attendees how to design and evaluate interaction with online video and television. It provides attendees a pragmatic toolset, including techniques and guidelines, which can be directly applied in practice. The different tools will be contextualized based on current developments, giving participants a complete overview of the state of the art and industry.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2856684"}, {"title": "Noise-Contrastive Estimation for Answer Selection with Deep Neural Networks", "authors": ["Jinfeng Rao\n,", "Hua He\n,", "Jimmy Lin"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study answer selection for question answering, in which given a question and a set of candidate answer sentences, the goal is to identify the subset that contains the answer. Unlike previous work which treats this task as a straightforward pointwise classification problem, we model this problem as a ranking task and propose a pairwise ranking approach that can directly exploit existing pointwise neural network models as base components. We extend the Noise-Contrastive Estimation approach with a triplet ranking loss function to exploit interactions in triplet inputs over the question paired with positive and negative examples. Experiments on TrecQA and WikiQA datasets show that our approach achieves state-of-the-art effectiveness without the need for external knowledge sources or feature engineering.", "references": ["ACL. Question answering (state of the art), http://aclweb.org/aclwiki/index.php?title=Question_Answering_(State_of_the_art), accessed Aug., 18, 2016.", "J. Bromley, J. W. Bentz, L. Bottou, I. Guyon, Y. LeCun, C. Moore, E. Sackinger, and R. Shah. Signature verification using a \"siamese\" time delay neural network. IJPRAI, 1993.", "H. He, K. Gimpel, and J. Lin. Multi-perspective sentence similarity modeling with convolutional neural networks. EMNLP, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983872"}, {"title": "Higia: A model for ubiquitous care of people with depression", "authors": ["Milene M. Petry\n,", "Jorge L.V. Barbosa\n,", "Sandro J. Rigo\n,", "Rogerio L. Horta"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nIn this paper, we describe Higia a model designed with the goal of constructing usual trails to identify possible depressive signals, similar to those lived by the user in other previous moments, and warn the related people as quickly as possible, so actions can be taken. This is done through constant evaluation of user characteristics on social networks, e-mails and interactions with your smartphone, computer or other devices, as well as its location. A prototype of the designed solution was implemented and the model was evaluated by the users who used the prototype, their opinions, as well as the opinions of experts in the field were collected. It was found that these data can be rather favorable to treatment depending on the situation and how they are used.", "references": ["WHO. 2001. \"The world health report: 2001: mental health: new understanding, new hope.\" World Health Organization, Geneva. DOI= http://www.who.int/whr/2001/en", "Silva, M. T.; Galvao, T. F.; Martins, S. S. e M. G. 2014. \"Prevalence of depression morbility among Brazilian adults: a systematic review and meta-analysis\". Revista Brasileira de Psiquiatria, 36: 262-270.", "Arnich, B.; Osnami, V.; Bardram, J.; 2013. \"Mental Health and the Impact of Ubiquitous Technologies.\" Personal and Ubiquitous Computing."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022028"}, {"title": "Leveraging Tweet Ranking in an Optimization Frameworkfor Tweet Timeline Generation", "authors": ["Lili Yao\n,", "Feifan Fan\n,", "Yansong Feng\n,", "Dongyan Zhao"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWhen users search in Twitter, they are overloaded with a mass of microblog posts every time, which are not particularly informative and lack of meaningful organization. Therefore, it is helpful to produce a summarized tweet timeline about the topic. The tweet timeline generation is such a task aiming at selecting a small set of representative tweets to generate meaningful timeline. In this paper, we introduce an optimization framework to jointly model the relevance, novelty and coverage of the tweet timeline, including effective tweet ranking algorithm. Extensive experiments on the public TREC 2014 dataset demonstrate our method can achieve very competitive results against the state-of-art TTG systems.", "references": ["J. Lin and M. Efron. Overview of the trec-2014 microblog track. In TREC'14, pages 84--89, 2014.", "Q. Mei, J. Guo, and D. Radev. Divrank: the interplay of prestige and diversity in information networks. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1009--1018. ACM, 2010.", "R. Mihalcea and P. Tarau. Textrank: Bringing order into texts. Association for Computational Linguistics, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925453"}, {"title": "Bidirectional Joint Representation Learning with Symmetrical Deep Neural Networks for Multimodal and Crossmodal Applications", "authors": ["Vedran Vukotić\n,", "Christian Raymond\n,", "Guillaume Gravier"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nCommon approaches to problems involving multiple modalities (classification, retrieval, hyperlinking, etc.) are early fusion of the initial modalities and crossmodal translation from one modality to the other. Recently, deep neural networks, especially deep autoencoders, have proven promising both for crossmodal translation and for early fusion via multimodal embedding. In this work, we propose a flexible crossmodal deep neural network architecture for multimodal and crossmodal representation. By tying the weights of two deep neural networks, symmetry is enforced in central hidden layers thus yielding a multimodal representation space common to the two original representation spaces. The proposed architecture is evaluated in multimodal query expansion and multimodal retrieval tasks within the context of video hyperlinking. Our method demonstrates improved crossmodal translation capabilities and produces a multimodal embedding that significantly outperforms multimodal embeddings obtained by deep autoencoders, resulting in an absolute increase of 14.14 in precision at 10 on a video hyperlinking task.", "references": ["M. Campr and K. Je\\vzek. Comparing semantic models for evaluating automatic document summarization. In Text, Speech, and Dialogue, 2015.", "M. Cha, Y. Gwon, and H. T. Kung. Multimodal sparse representation learning and applications. CoRR, abs/1511.06238, 2015.", "M. Eskevich, R. Aly, D. N. Racca, R. Ordelman, S. Chen, and G. J. Jones. The search and hyperlinking task at MediaEval 2014. In Working Notes MediaEval Workshop, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912064"}, {"title": "Learning for Efficient Supervised Query Expansion via Two-stage Feature Selection", "authors": ["Zhiwei Zhang\n,", "Qifan Wang\n,", "Luo Si\n,", "Jianfeng Gao"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuery expansion (QE) is a well known technique to improve retrieval effectiveness, which expands original queries with extra terms that are predicted to be relevant. A recent trend in the literature is Supervised Query Expansion (SQE), where supervised learning is introduced to better select expansion terms. However, an important but neglected issue for SQE is its efficiency, as applying SQE in retrieval can be much more time-consuming than applying Unsupervised Query Expansion (UQE) algorithms. In this paper, we point out that the cost of SQE mainly comes from term feature extraction, and propose a Two-stage Feature Selection framework (TFS) to address this problem. The first stage is adaptive expansion decision, which determines if a query is suitable for SQE or not. For unsuitable queries, SQE is skipped and no term features are extracted at all, which reduces the most time cost. For those suitable queries, the second stage is cost constrained feature selection, which chooses a subset of effective yet inexpensive features for supervised learning. Extensive experiments on four corpora (including three academic and one industry corpus) show that our TFS framework can substantially reduce the time cost for SQE, while maintaining its effectiveness.", "references": ["M. Bendersky, D. Fisher, and W. B. Croft. Umass at trec 2010 web track: Term dependence, spam filtering and quality bias. In TREC, 2010.", "M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In WSDM, pages 443--452, 2012.", "B. Billerbeck and J. Zobel. Efficient query expansion with auxiliary data structures. In Information System, pages 573--584, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911539"}, {"title": "Semantic Processing for the Conversion of Unstructured Documents into Structured Information in the Enterprise Context", "authors": ["Adam Bartusiak\n,", "Jörg Lässig"], "publication": "SEMANTiCS 2016: Proceedings of the 12th International Conference on Semantic Systems", "abstract": "ABSTRACT\nWe present an on-going research project addressing the problem of massive amounts of unstructured data that is generated on a daily basis in most business organisations, regardless of size. Our motivation is to support in particular small and medium seized enterprises to gain a competitive advantage in the market. The goal is to improve their processes for extracting valuable business information from such disorganised data. To achieve this, we introduce a flexible and scalable data analysis framework capable of transforming various types of documents into semantically annotated structures. This includes emails, text files in various formats, slide presentations, blog entries, etc. Additionally, the solution provides a semantic search engine for structured retrieval of the analyzed information and a graphical layer to dynamically visualize the search results as an interactive graph. Throughout the paper, the architecture of two main engines that are responsible for data and text analysis and semantic search are described. We conclude that semantic processing of unstructured sources significantly improves data management and data integration within the enterprises.", "references": ["H. Bast, F. Bäurle, B. Buchhold, and E. Haussmann. Broccoli: Semantic full-text search at your fingertips. arXiv preprint arXiv:1207.2615, 2012.", "R. Bhagdev, S. Chapman, F. Ciravegna, V. Lanfranchi, and D. Petrelli. Hybrid search: Effectively combining keywords and semantic searches. Springer, 2008.", "E. Blomqvist. The use of semantic web technologies for decision support -- a survey. Semant. web, 5(3):177--201, July 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993318.2993341"}, {"title": "\"What Is the City but the People?\": Exploring Urban Activity Using Social Web Traces", "authors": ["Emre Çelikten\n,", "Géraud Le Falher\n,", "Michael Mathioudakis"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe demonstrate Geotopics, a system to explore geographical patterns of urban activity. The system collects publicly shared check-ins generated by Foursquare users, that reveal who spends time where, when, and on what type of activity. It then employs sparse probabilistic modeling techniques to learn associations between different regions of a city and multi-feature descriptions of urban activity. Through a web interface, users of the system can select a city of interest and explore visualizations that highlight how different types of activity are spatially and temporally distributed in the city.\nWe discuss the opportunities that web data offer to understand urban activity and the challenges one faces in that task. We then describe our approach and the architecture of Geotopics. Finally, we lay out the demonstration scenario.", "references": ["World Urbanization Prospects, the 2014 Revision: Highlights. Technical report, United Nations, Department of Economic and Social Affairs, New-York, 2014.", "S. Bocconi, A. Bozzon, A. Psyllidis, C. Titos Bolivar, and G.-J. Houben. Social glass: A platform for urban analytics and decision-making through heterogeneous social data. In Proceedings of the 24th International Conference on World Wide Web, pages 175--178, 2015.", "Z. Cao, S. Wang, G. Forestier, A. Puissant, and C. F. Eick. Analyzing the Composition of Cities Using Spatial Clustering. In Proceedings of the 2nd ACM SIGKDD International Workshop on Urban Computing, pages 14:1--14:8, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2901922"}, {"title": "Digital Preservation Based on Contextualized Dependencies", "authors": ["Nikolaos Lagos\n,", "Jean-Yves Vion-Dury"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nMost of existing efforts in digital preservation have focused on extending the life of documents beyond their period of creation, without taking into account intentions and assumptions made. However, in a continuously evolving setting, knowledge about the context of documents is nearly mandatory for their continuous understanding, use, care, and sustainable governance. In this work we propose a method that considers the preservation of a number of interdependent digital entities, including documents, in conformance with context related information. A change that influences one of these objects can be propagated to the rest of the objects via analysis of their represented dependencies. We propose to represent dependencies not only as simple links but as complex, semantically rich, constructs that encompass context-related information. We illustrate how this method can aid in fine-grained contextually-aware change propagation and impact analysis with a case study.", "references": ["Conway, P. 1996. Preservation in the Digital World. Council on Library and Information Resources, Washington, DC. http://www.clir.org/pubs/reports/reports/conway2/index.html, Accessed: 16 Mar 2016.", "Digital Preservation Coalition (2015). Glossary. Digital Preservation Handbook 2nd edition. York, UK. http://www.dpconline.org/advice/preservationhandbook/glossary. Accessed: 16 Mar 2016.", "Beaudoin, J. E. 2012. Context and Its Role in the Digital Preservation of Cultural Objects. D-Lib Magazine, 18, 11/12. http://www.dlib.org/dlib/november12/beaudoin/11beaudoin1.html, Accessed: 16 Mar 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2960818"}, {"title": "Automatic Assessment of Website Compliance to the European Cookie Law with CooLCheck", "authors": ["Caudio Carpineto\n,", "Davide Lo Re\n,", "Giovanni Romano"], "publication": "WPES '16: Proceedings of the 2016 ACM on Workshop on Privacy in the Electronic Society", "abstract": "ABSTRACT\nWe study the problem of automatically assessing whether a website meets the requirements of the Cookie Law, in particular to check that when some tracking cookie is installed the user is asked to give consent to its use. We present a methodology based on cookie disclosure and classification together with identification of natural language consent requests by web information retrieval techniques. This approach performs real time analysis and is very accurate. Using the 500 most popular websites in Italy as a test set, we found that the automatic diagnosis was always correct, except for the case when the consent request was expressed in a language not supported by the system. We also report the results of a systematic evaluation of the 23000 Italian Public Administration websites showing large-scale infringement. Our approach has been implemented as a web application named CooLCheck, which is currently being used by the Italian Data Protection Authority as a support tool for evaluating and monitoring the compliance of websites to the Cookie Law.", "references": ["A. Cahn, S. Alfeld, P. Barford, and S. Muthukrishnan. An empirical study of web cookies. In WWW '16: Proceedings of the 25th international conference on World Wide Web, Montreal, Canada, pages 891--901, 2016.", "R. R. Curtin, J. R. Cline, N. P. Slagle, W. B. March, P. Ram, N. A. Metha, and A. G. Gray. MLPACK: A Scalable C", "Machine Learning Library. Journal of Machine Learning Research, 14:801--805, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994620.2994622"}, {"title": "Sapphire: querying RDF data made simple", "authors": ["Ahmed El-Roby\n,", "Khaled Ammar\n,", "Ashraf Aboulnaga\n,", "Jimmy Lin"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThere is currently a large amount of publicly accessible structured data available as RDF data sets. For example, the Linked Open Data (LOD) cloud now consists of thousands of RDF data sets with over 30 billion triples, and the number and size of the data sets is continuously growing. Many of the data sets in the LOD cloud provide public SPARQL endpoints to allow issuing queries over them. These end-points enable users to retrieve data using precise and highly expressive SPARQL queries. However, in order to do so, the user must have sufficient knowledge about the data sets that she wishes to query, that is, the structure of data, the vocabulary used within the data set, the exact values of literals, their data types, etc. Thus, while SPARQL is powerful, it is not easy to use. An alternative to SPARQL that does not require as much prior knowledge of the data is some form of keyword search over the structured data. Keyword search queries are easy to use, but inherently ambiguous in describing structured queries.\nThis demonstration introduces Sapphire, a system for querying RDF data that strikes a middle ground between ambiguous keyword search and difficult-to-use SPARQL. Our system does not replace either, but utilizes both where they are most effective. Sapphire helps the user construct expressive SPARQL queries that represent her information needs without requiring detailed knowledge about the queried data sets. These queries are then executed over public SPARQL endpoints from the LOD cloud. Sapphire guides the user in the query writing process by showing suggestions of query terms based on the queried data, and by recommending changes to the query based on a predictive user model.", "references": ["S. Agrawal, S. Chaudhuri, and G. Das. DBXplorer: Enabling keyword search over relational databases. SIGMOD, 2002.", "W. Cohen, P. Ravikumar, and S. Fienberg. A comparison of string metrics for matching names and records. IJCAI, 2003.", "E. Demidova, X. Zhou, and W. Nejdl. A probabilistic scheme for keyword-based incremental query construction. TKDE, 24(3), 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007289"}, {"title": "Service Modeling from Business Process: A Model-Driven Approach", "authors": ["Joao Pedro Bittencourt\n,", "Edlane Proencia\n,", "Rita S.P. Maciel"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nBusiness processes modeling helps to understand and identify activities performed in an organization, which serve as a source of requirements for system modeling. It also can be used to discover candidate services to support these requirements. However, managing information between models of different levels of abstraction is not a trivial task. Several works have been proposed to solve this problem by deriving services from business models. This paper presents a method to assist services derivation from business process using the Model Driven Development approach and heuristics and in order to achieve services models that can be used to generate code. The method is divided into two phases. In the first phase, a business process, modeled in BPMN, is transformed into a UML activity diagram. In the second phase, UML models are transformed into a SoaML model", "references": ["AZEVEDO, L. G. et al. Identificacao automatica de servicos candidatos a partir de modelos de processos de negocio. In: Escola Regional de Sistemas de Informacao. 2009.", "DELGADO, A. et al. From BPMN business process models to SoaML service models: A transformation-driven approach. In: Software Technology and Engineering (ICSTE), 2010 2nd International Conference on. 2010. p. V1-314-V1-319", "ELVESAETER, B. et al. Aligning business and it models in service-oriented architectures using bpmn and soaml. In: Proceedings of the First International Workshop on ModelDriven Interoperability., 2010. P 61-68"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022005"}, {"title": "Discouraging Abusive Behavior in Privacy-Preserving Online Social Networking Applications", "authors": ["Álvaro García-Recuero"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn this position paper we present the challenge of detecting abuse in a modern Online Social Network (OSN) while balancing data utility and privacy, with the goal of limiting the amount of user sensitive information processed during data collection, extraction and analysis. While we are working with public domain data available in a contemporary OSN, our goal is to design a thorough method for future alternative OSN designs that both protect user's sensitive information and discourage abuse.\nIn this summary, we present initial results for detecting abusive behavior on Twitter. We plan to further investigate the impact of reducing input metadata on the quality of the abuse detection. In addition, we will consider defeating Byzantine behavior by opponents in the system.", "references": ["J. S. Alowibdi, U. Buy, P. S. Yu, L. Stenneth, et al. Detecting deception in online social networks. In Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on, pages 383--390. IEEE, 2014.", "C. M. Bishop. Pattern Recognition and Machine Learning, volume 4. 2006.", "J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1--8, 2011. http://dx.doi.org/10.1016/j.jocs.2010.12.007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888600"}, {"title": "A Survey and Comparative Study of Tweet Sentiment Analysis via Semi-Supervised Learning", "authors": ["Nadia Felix F. Da Silva\n,", "Luiz F. S. Coletta\n,", "Eduardo R. Hruschka"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nTwitter is a microblogging platform in which users can post status messages, called “tweets,” to their friends. It has provided an enormous dataset of the so-called sentiments, whose classification can take place through supervised learning. To build supervised learning models, classification algorithms require a set of representative labeled data. However, labeled data are usually difficult and expensive to obtain, which motivates the interest in semi-supervised learning. This type of learning uses unlabeled data to complement the information provided by the labeled data in the training process; therefore, it is particularly useful in applications including tweet sentiment analysis, where a huge quantity of unlabeled data is accessible. Semi-supervised learning for tweet sentiment analysis, although appealing, is relatively new. We provide a comprehensive survey of semi-supervised approaches applied to tweet classification. Such approaches consist of graph-based, wrapper-based, and topic-based methods. A comparative study of algorithms based on self-training, co-training, topic modeling, and distant supervision highlights their biases and sheds light on aspects that the practitioner should consider in real-world applications.", "references": ["Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media (LSM’11). Association for Computational Linguistics, Stroudsburg, PA, 30--38.", "Maria-Florina Balcan and Avrim Blum. 2010. A discriminative model for semi-supervised learning. J. ACM 57, 3, Article 19 (2010), 46 pages.", "Wesley Baugh. 2013. bwbaugh: Hierarchical sentiment analysis with partial self-training. In Second Joint Conference on Lexical and Computational Semantics (&ast;SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013). Association for Computational Linguistics, Atlanta, GA, 539--542."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2932708"}, {"title": "conteXinger: A Context-aware Song Generator to Enrich Daily Lives", "authors": ["Ayano Nishimura\n,", "Itiro Siio"], "publication": "ACE '16: Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nIn general, routine every-day work tends to be boring and monotonous, e.g. housework. Work songs have been written and sung by workers to reduce their labor load. In addition, text-to-song synthesizer software such as Yamaha's VOCALOID™ is commonly used by a wide variety of computer music creators. In this paper, we propose a real-time music synthesizer named \"conteXinger\". This system sings lyrics based on the listener's context, including the use of home appliances, e.g. vacuum cleaner, refrigerator, microwave oven, or dish washer, and Internet information, e.g. SNS messages, Web news, and weather reports. By presenting the synthesized music to a user through a home audio system or headphones, our system entertains users who may be bored due to their everyday work routines.", "references": ["Shinichi Yataka, Kohei Tanaka, Tsutomu Terada, and Masahiko Tsukamoto. 2011. A Context-aware Audio Presentation Method in Wearable Computing. In Proceedings of the 2011 ACM Symposium on Applied Computing (SAC '11). ACM, New York, NY, USA, 405--412. DOI: http://dx.doi.org/10.1145/1982185.1982274", "Veronica Halupka, Ali Almahr, Yupeng Pan, and Adrian David Cheok. 2012. Chop Chop: A Sound Augmented Kitchen Prototype. In Proceedings of the 9th International Conference on Advances in Computer Entertainment (ACE'12). Springer-Verlag, Berlin, Heidelberg, 494--497. DOI: http://dx.doi.org/10.1007/978-3-642-34292-9_43", "Taku Kudo. 2005. MeCab: Yet Another Part-of-Speech and Morphological Analyzer. http://mecab.sourceforge.net/ (2005). http://ci.nii.ac.jp/naid/10019716933/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001773.3014350"}, {"title": "METAlloc: efficient and comprehensive metadata management for software security hardening", "authors": ["Istvan Haller\n,", "Erik van der Kouwe\n,", "Cristiano Giuffrida\n,", "Herbert Bos"], "publication": "EuroSec '16: Proceedings of the 9th European Workshop on System Security", "abstract": "ABSTRACT\nMany systems software security hardening solutions rely on the ability to look up metadata for individual memory objects during the execution, but state-of-the-art metadata management schemes incur significant lookup-time or allocation-time overheads and are unable to handle different memory objects (i.e., stack, heap, and global) in a comprehensive and uniform manner.\nWe present METAlloc, a new memory metadata management scheme which addresses all the key limitations of existing solutions. Our design relies on a compact memory shadowing scheme empowered by an alignment-based object allocation strategy. METAlloc's allocation strategy ensures that all the memory objects within a page share the same alignment class and each object is always allocated to use the largest alignment class possible. This strategy provides a fast memory-to-metadata mapping, while minimizing metadata size and reducing memory fragmentation. We implemented and evaluated METAlloc on Linux and show that METAlloc (de)allocations incur just 3.6% run-time performance overhead, paving the way for practical software security hardening in real-world deployment scenarios.", "references": ["P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro. Preventing memory error exploits with wit. In Security and Privacy, 2008. SP 2008. IEEE Symposium on, pages 263--277. IEEE, 2008.", "P. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy bounds checking: An efficient and backwards-compatible defense against out-of-bounds errors. In USENIX Security Symposium, pages 51--66, 2009.", "N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R. Gross. Control-flow bending: On the effectiveness of control-flow integrity. In 24th USENIX Security Symposium (USENIX Security 15), pages 161--176, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905760.2905766"}, {"title": "Deep Visual-Semantic Hashing for Cross-Modal Retrieval", "authors": ["Yue Cao\n,", "Mingsheng Long\n,", "Jianmin Wang\n,", "Qiang Yang\n,", "Philip S. Yu"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nDue to the storage and retrieval efficiency, hashing has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval. Cross-modal hashing, which enables efficient retrieval of images in response to text queries or vice versa, has received increasing attention recently. Most existing work on cross-modal hashing does not capture the spatial dependency of images and temporal dynamics of text sentences for learning powerful feature representations and cross-modal embeddings that mitigate the heterogeneity of different modalities. This paper presents a new Deep Visual-Semantic Hashing (DVSH) model that generates compact hash codes of images and sentences in an end-to-end deep learning architecture, which capture the intrinsic cross-modal correspondences between visual data and natural language. DVSH is a hybrid deep architecture that constitutes a visual-semantic fusion network for learning joint embedding space of images and text sentences, and two modality-specific hashing networks for learning hash functions to generate compact binary codes. Our architecture effectively unifies joint multimodal embedding and cross-modal hashing, which is based on a novel combination of Convolutional Neural Networks over images, Recurrent Neural Networks over sentences, and a structured max-margin objective that integrates all things together to enable learning of similarity-preserving and high-quality hash codes. Extensive empirical evidence shows that our DVSH approach yields state of the art results in cross-modal retrieval experiments on image-sentences datasets, i.e. standard IAPR TC-12 and large-scale Microsoft COCO.", "references": ["J. Andreas, M. Rohrbach, T. Darrell, and D. Klein. Deep compositional question answering with neural module networks. CVPR, 2016.", "G. Andrew, R. Arora, J. Bilmes, and K. Livescu. Deep canonical correlation analysis. In ICML, 2013.", "Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. TPAMI, 35, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939812"}, {"title": "Neu-IR: The SIGIR 2016 Workshop on Neural Information Retrieval", "authors": ["Nick Craswell\n,", "W. Bruce Croft\n,", "Jiafeng Guo\n,", "Bhaskar Mitra\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn recent years, deep neural networks have yielded significant performance improvements on speech recognition and computer vision tasks, as well as led to exciting breakthroughs in novel application areas such as automatic voice translation, image captioning, and conversational agents. Despite demonstrating good performance on natural language processing (NLP) tasks (e.g., language modelling and machine translation, the performance of deep neural networks on information retrieval (IR) tasks has had relatively less scrutiny. Recent work in this area has mainly focused on word embeddings and neural models for short text similarity.\nThe lack of many positive results in this area of information retrieval is partially due to the fact that IR tasks such as ranking are fundamentally different from NLP tasks, but also because the IR and neural network communities are only beginning to focus on the application of these techniques to core information retrieval problems. Given that deep learning has made such a big impact, first on speech processing and computer vision and now, increasingly, also on computational linguistics, it seems clear that deep learning will have a major impact on information retrieval and that this is an ideal time for a workshop in this area.\nNeu-IR (pronounced \"new IR\") will be a forum for new research relating to deep learning and other neural network based approaches to IR. The purpose is to provide an opportunity for people to present new work and early results, compare notes on neural network toolkits, share best practices, and discuss the main challenges facing this line of research.", "references": ["D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.", "H. Fang, S. Gupta, F. Iandola, R. Srivastava, L. Deng, P. Dollár, J. Gao, X. He, M. Mitchell, J. Platt, et al. From captions to visual concepts and back. arXiv preprint arXiv:1411.4952, 2014.", "D. Ganguly, D. Roy, M. Mitra, and G. J. Jones. Word embedding based generalized language model for information retrieval. In Proc. SIGIR, pages 795--798. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917762"}, {"title": "Evaluating Clustering Algorithms on a Multimedia Metadata Dataset", "authors": ["Christina S. Kyrkou\n,", "Phivos Mylonas\n,", "Evaggelos Spyrou\n,", "Spyros Sioutas\n,", "Angeliki Rapti\n,", "Dimitrios Tsolis"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nIn the framework of informatics, data analysis always played a crucial role in understanding various phenomena. When it comes to multimedia content, this task is getting more difficult to tackle in an efficient manner. In principle, cluster analysis, i.e., primitive data exploration with little or no prior knowledge, consists of research developed across a wide variety of approaches. The aim of this paper is to present a comparative survey of five clustering algorithms, namely k means, EM, DBSCAN, Mean Shift and KVQ applied on a real-life multimedia metadata dataset derived from Flickr social network.", "references": ["http://www.cs.waikato.ac.nz/ml/weka/, last retrieved on 30/05/2016", "http://www.mathworks.com/products/matlab/?requestedDomain=www.mathworks.com, last retrieved on 30/05/2016", "Y. Kalantidis, G. Tolias, Y. Avrithis, M. Phinikettos, E. Spyrou, Ph. Mylonas, S. Kollias, VIRaL: Visual Image Retrieval and Localization. Multimedia Tools Appl. 51, 2, January 2011, 555--592."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003809"}, {"title": "A recipe recommendation system that considers user's mood", "authors": ["Mayumi Ueda\n,", "Yukitoshi Morishita\n,", "Tomiyo Nakamura\n,", "Natsuhiko Takata\n,", "Shinsuke Nakajima"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nHomemaker decide what to cook based on the mood they are in, the ingredients they have in their refrigerators, or the ingredients offered in a supermarket. Most of the existing services for searching recipes allow ingredient names or recipe names as search input. We propose a system that allows searching recipes based on the users' mood. To develop the system, we gather words to express a user's mood when making a menu decision and classify them according to their relationship. We determine six aspects of a user's mood. The result of our preliminary experiment and a questionnaire-based survey show that our method describes a user's mood when deciding for a menu and that the system helps in the decision-making. Furthermore, we propose a method for automatically generating recipe metadata, which we plan to add to our system.", "references": ["Cookpad. https://cookpad.com/us/ (Accessed 22 August 2016).", "M. Ueda and S. Nakajima, \"Cooking recipe recommendation method focusing on the relationship between user preference and ingredient quantity\", Transactions on Engineers and Computer Scientists 2014, pp.386--395, Springer Netherrlands, 2015.1.", "S. Karikome and A. Fujii, \"A System for Supporting Dietary Habits: Planning Menus and Visualizing Nutritional Intake Balance\", Proceedings of the 4th International Conference on Ubiquitous Information Management and Communication, pp.386--391, 2010.1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011192"}, {"title": "Active and Passive Utility of Search Interface Features in Different Information Seeking Task Stages", "authors": ["Hugo C. Huurdeman\n,", "Max L. Wilson\n,", "Jaap Kamps"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nModels of information seeking, including Kuhlthau's Information Search Process model, describe fundamentally different macro-level stages. Current search systems usually do not provide support for these stages, but provide a static set of features predominantly focused on supporting micro-level search interactions. This paper investigates the utility of search user interface (SUI) features at different macro-level stages of complex tasks. A user study was designed, using simulated work tasks, to explicitly place users within different stages of a complex task: pre-focus, focus, and post-focus. Active use, passive use and perceived usefulness of features were analysed in order to derive when search features are most useful. Our results identify significant differences in the utility of SUI features between each stage. Specifically, we have observed that informational features are naturally useful in every stage, while input and control features decline in usefulness after the pre-focus stage, and personalisable features become more useful after the pre-focus stage. From these findings, we conclude that features less commonly found in web search interfaces can provide value for users, without cluttering simple searches, when provided at the right times.", "references": ["P. Borlund. The IIR evaluation model: a framework for evaluation of interactive information retrieval systems. Inf. Res., 8 (3), 2003.", "G. Buscher, A. Dengel, and L. van Elst. Eye movements as implicit relevance feedback. In CHI'08 extended abstracts on Human factors in computing systems, pages 2991--2996. ACM, 2008.", "K. Byström and K. Järvelin. Task complexity affects information seeking and use. IP&M, 31 (2): 191--213, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854957"}, {"title": "SoMap: Dynamic Clustering and Ranking of Geotagged Posts", "authors": ["Marie Al-Ghossein\n,", "Talel Abdessalem"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThis demo presents SoMap, a web-based platform that provides new scalable methods to aggregate, analyse and valorise large collections of heterogeneous social data in urban contexts. The platform relies on geotagged data extracted from social networks and microblogging applications such as Instagram, Flickr and Twitter and on Points Of Interest gathered from OpenStreetMap. It could be very insightful and interesting for data scientists and decision-makers. SoMap enables dynamic clustering of filtered social data in order to display it on a map in a combined form. The key components of this platform are the clustering module, which relies on a scalable algorithm described in this paper, and the ranking algorithm that combines the popularity of the posts, their location and their link to the points of interest found in the neighbourhood. The system further detects mobility patterns by identifying and aggregating trajectories for all the users. SoMap will be demonstrated through several examples that highlight all of its functionalities and reveal its effectiveness and usefulness.", "references": ["S. Ahern, M. Naaman, R. Nair, and J. Yang. World explorer: Visualizing aggregate data from unstructured text in geo-referenced collections. In JCDL, 2007.", "D. J. Crandall, L. Backstrom, D. Huttenlocher, and J. Kleinberg. Mapping the world's photos. In WWW, 2009.", "D. Liu, X.-S. Hua, L. Yang, M. Wang, and H.-J. Zhang. Tag ranking. In WWW, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890550"}, {"title": "Strategies for Encouraging Sharing in Social Networks for Professionals", "authors": ["Francisco A. M. Valério\n,", "Tatiane G. Guimarães\n,", "Raquel O. Prates"], "publication": "IHC '16: Proceedings of the 15th Brazilian Symposium on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThe use of Online Social Networks (OSNs) has brought many challenges to its users. One of them is the compromise between the disclosure of personal information and privacy. In this work, we used the Semiotic Inspection Method (SIM) to analyze two OSNs for professionals: LinkedIn and ResearchGate. This way, we have identified strategies that are used to encourage users to disclose personal information on such contexts and which personal information are privileged by the OSNs. Based on [9], we show that previously identified strategies can be applied to another context. In addition, we identified a new strategy that complements previous works.", "references": ["C. S. de Souza and C. F. Leitão. 2009. Semiotic Engineering Methods for Scientific Research in HCI. Synthesis Lectures on Human-Centered Informatics 2, 1: 1--122.", "L. Emanuel, G. J. Neil, C. Bevan, et al. 2014. Who am I? Representing the self offline and in different online contexts. Computers in Human Behavior 41: 146--152.", "S. Kolimi, F. Zhu, and S. Carpenter. 2012. Contexts and sharing/not sharing private information. Proceedings of the 50th Annual Southeast Regional Conference, ACM, 292--297."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3033701.3033756"}, {"title": "Play and Rewind: Optimizing Binary Representations of Videos by Self-Supervised Temporal Hashing", "authors": ["Hanwang Zhang\n,", "Meng Wang\n,", "Richang Hong\n,", "Tat-Seng Chua"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe focus on hashing videos into short binary codes for efficient Content-based Video Retrieval (CBVR), which is a fundamental technique that supports access to the ever-growing abundance of videos on the Web. Existing video hash functions are built on three isolated stages: frame pooling, relaxed learning, and binarization, which have not adequately explored the temporal order of video frames in a joint binary optimization model, resulting in severe information loss. In this paper, we propose a novel unsupervised video hashing framework called Self-Supervised Temporal Hashing (SSTH) that is able to capture the temporal nature of videos in an end-to-end learning-to-hash fashion. Specifically, the hash function of SSTH is an encoder RNN equipped with the proposed Binary LSTM (BLSTM) that generates binary codes for videos. The hash function is learned in a self-supervised fashion, where a decoder RNN is proposed to reconstruct the original video frames in both forward and reverse orders. For binary code optimization, we develop a backpropagation rule that tackles the non-differentiability of BLSTM. This rule allows efficient deep network training without suffering from the binarization loss. Through extensive CBVR experiments on two real-world consumer video datasets of Youtube and Flickr, we show that SSTH consistently outperforms state-of-the-art video hashing methods, eg., in terms of mAP@20, SSTH using only 128 bits can still outperform others using 256 bits by at least 9% to 15% on both datasets.", "references": ["Y. Bengio, N. Léonard, and A. Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.", "A. Bergamo, L. Torresani, and A. W. Fitzgibbon. Picodes: Learning a compact code for novel-category recognition. In NIPS, 2011.", "L. Cao, Z. Li, Y. Mu, and S.-F. Chang. Submodular video hashing: a unified framework towards video pooling and indexing. In MM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964308"}, {"title": "Third Workshop on New Trends in Content-based Recommender Systems (CBRecSys 2016)", "authors": ["Toine Bogers\n,", "Marijn Koolen\n,", "Cataldo Musto\n,", "Pasquale Lops\n,", "Giovanni Semeraro"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWhile content-based recommendation has been applied successfully in many different domains, it has not seen the same level of attention as collaborative filtering techniques have. However, there are many recommendation domains and applications where content and metadata play a key role, either in addition to or instead of ratings and implicit usage data. For some domains, such as movies, the relationship between content and usage data has seen thorough investigation already, but for many other domains, such as books, news, scientific articles, and Web pages we still do not know if and how these data sources should be combined to provided the best recommendation performance. The CBRecSys 2016 workshop provides a dedicated venue for papers dedicated to all aspects of content-based recommendation.", "references": ["T. Bogers and M. Koolen, editors. Proceedings of the 2nd Workshop on New Trends in Content-based Recommender Systems, co-located with the 9th ACM Conference on Recommender Systems, CBRecSys@RecSys 2015, Vienna, Austria, September 20, 2015, volume 1448 of CEUR Workshop Proceedings. CEUR-WS.org, 2015.", "T. Bogers and M. Koolen. Report on RecSys 2015 Workshop on New Trends in Content-Based Recommender Systems. ACM SIGIR Forum, 49(2):141--146, December 2015.", "T. Bogers and M. Koolen. Second Workshop on New Trends in Content-based Recommender Systems: (CBRecSys 2015). In Ninth ACM Conference on Recommender Systems, RecSys '15, Vienna, Austria - September 16 - 20, 2015, pages 339--340, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959200"}, {"title": "The Dawn of Today's Popular Domains: A Study of the Archived German Web over 18 Years", "authors": ["Helge Holzmann\n,", "Wolfgang Nejdl\n,", "Avishek Anand"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe Web has been around and maturing for 25 years. The popular websites of today have undergone vast changes during this period, with a few being there almost since the beginning and many new ones becoming popular over the years. This makes it worthwhile to take a look at how these sites have evolved and what they might tell us about the future of the Web. We therefore embarked on a longitudinal study spanning almost the whole period of the Web, based on data collected by the Internet Archive starting in 1996, to retrospectively analyze how the popular Web as of now has evolved over the past 18 years.\nFor our study we focused on the German Web, specifically on the top 100 most popular websites in 17 categories. This paper presents a selection of the most interesting findings in terms of volume, size as well as age of the Web. While related work in the field of Web Dynamics has mainly focused on change rates and analyzed datasets spanning less than a year, we looked at the evolution of websites over 18 years. We found that around 70% of the pages we investigated are younger than a year, with an observed exponential growth in age as well as in size up to now. If this growth rate continues, the number of pages from the popular domains will almost double in the next two years. In addition, we give insights into our data set, provided by the Internet Archive, which hosts the largest and most complete Web archive as of today.", "references": ["J. Cho and H. Garcia-Molina. The evolution of the web and implications for an incremental crawler. In Proceedings of the 26th International Conference on Very Large Data Bases, VLDB '00.", "Dennis Fetterly, Mark Manasse, Marc Najork, and Janet Wiener. A large-scale study of the evolution of web pages. In Proceedings of the 12th International Conference on World Wide Web, WWW '03.", "Wallace Koehler. Web page change and persistence a four-year longitudinal study. Journal of the American Society for Information Science and Technology, 53 (2): 162--171, January 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910901"}, {"title": "Analytical Trends and Practices of Web Intelligence", "authors": ["B. Malathi\n,", "K. Chandra Sekharaiah\n,", "H. Jayasree"], "publication": "WIR '16: Proceedings of the ACM Symposium on Women in Research 2016", "abstract": "ABSTRACT\nThe web has undergone major transformation during last few years and revolutionized the world we live in. The amount of information and user-generated data on the web is increasing day by day. The major challenge of web research and development is in the effective usage of available data and information on web. Intelligence can be achieved by training the web to learn its content, structure (semantics of web) and by applying intelligent techniques to effectively access the web resources. In this context, Web Intelligence has been recognized as one of the most important as well as the fastest growing research field. This paper provides an overview on the trends and practices of Web Intelligence (WI) that play vital role in meeting the challenges of developing the intelligent web. We also introduce an analysis report on representative references in which the techniques and analytical methods are briefly described.", "references": ["Ning Zhong; Jiming Liu; Y. Y. Yao; S. Ohsuga, Web intelligence 2000 - ieeexplore.ieee.org", "Y. Y. Yao, N. Zhong, J. Liu, and S. Ohsuga, Web intelligence(WI): research challenges and trends in the new information age, in N. Zhong, et al. (eds.), Web Intelligence: Research and Development, LNAI 2198, Springer, 2001, pp. 1--17.", "Liu,J.2003, Web Intelligence (WI): What Makes Wisdom Web, IJCAI, 2003 - comp.hkbu.edu.hk"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909067.2909090"}, {"title": "Co-occurrence Analysis for Items Played in Radio Stations Programs", "authors": ["Alexandre P. Norberto\n,", "Luiz H.C. Merschmann\n,", "Amanda S. Nascimento\n,", "alvaro R.Pereira Junior"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nMusic recommendation systems such as Last.fm use collective knowledge bases containing ratings and historical use, in order to recommend items (such as artists and songs) considered similar to each other. With reference to the knowledge generated by Last.fm users, this work investigates the co-occurrence of items in radio station programs, that is, whether the radio playlists represent cohesive sets of related items. In this sense, we developed an analysis methodology in which frequent item sets containing artists, songs, and musical genres that co-occur within radio programs are extracted, in order to analyze the similarity among discovered item sets, using as reference the similarity lists from Last.fm. Experimental results show that the more strict the filters applied to define the set of frequent items are, the more items present in the Last.fm similarity lists are found. On the other hand, the study also reveals that new correlations between items, even though not classified by Last.fm, can be discovered, showing that even large-scale collaborative systems as Last.fm are not complete regarding data characterization for extracting abstract similarity concepts.", "references": ["R. Agrawal, R. Srikant, et al. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, VLDB, volume 1215, pages 487-499, 1994.", "J. Bu, S. Tan, C. Chen, C. Wang, H. Wu, L. Zhang, and X. He. Music recommendation by unified hypergraph: Combining social media information and music content. In Proceedings of the International Conference on Multimedia, MM '10, pages 391-400, New York, NY, USA, 2010. ACM.", "G. Geleijnse, M. Schedl, and P. Knees. The quest for ground truth in musical artist tagging in the social web era. In International Society for Music Information Retrieval (ISMIR), pages 525-530. Citeseer, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022013"}, {"title": "MeTA : A Unified Toolkit for Text Data Management and Analysis", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915036"}, {"title": "Prediction/Assessment of communication skill using multimodal cues in social interactions", "authors": ["Sowmya Rasipuram"], "publication": "ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nUnderstanding people’s behavior in social interactions is a very interesting problem in Social Computing. In this work, we automatically predict the communication skill of a person in various kinds of social interactions. We consider in particular, 1) Interview-based interactions - asynchronous interviews (web-based interview) Vs. synchronous interviews (regular face-to-face interviews) and 2) Non-interview based interactions - dyad and triad conversations (group discussions). We automatically extract multimodal cues related to verbal and non-verbal behavior content of the interaction. First, in interview-based interactions, we consider previously uninvestigated scenarios of comparing the participant’s behavioral and perceptual changes in the two contexts. Second, we address different manifestations of communication skill in different settings (face-to-face interaction vs. group). Third, the non-interview based interactions also leads to answer research questions such as “the relation between a good communicator and other group variables like dominance or leadership” Finally we look at several attributes (manually annotated) and features/feature groups (automatically extracted) that predicts communication skill well in all settings.", "references": ["Hassle-free Efficient Hiring. https://www.talview.com/automated-video.", "Batrinca, L. M. Multimodal personality recognition from audiovisual data. In Diss. University of Trento (2013).", "Biel, J. I., Teijeiro-Mosquera, L., and Gatica-Perez, D. Facetube: predicting personality from facial expressions of emotion in online conversational video. In Proceedings of the 14th ACM int. COnf. on Multimodal interaction, ACM (2012), 53–56."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993148.2997617"}, {"title": "Classification and Retrieval of Archaeological Potsherds Using Histograms of Spherical Orientations", "authors": ["Edgar Roman-Rangel\n,", "Diego Jimenez-Badillo\n,", "Stephane Marchand-Maillet"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nWe address the problem of the statistical description of 3D surfaces with the purpose of automatic classification and retrieval of archaeological potsherds. These are particularly interesting problems in archaeology, as pottery comprises a great volume of findings in archaeological excavations. Indeed, the analysis of potsherds brings relevant cues for understanding the culture of ancient groups. In particular, we develop a new local shape descriptor for 3D surfaces, called the histogram of spherical orientations (HoSO), which we use in combination with a bag-of-words approach to compute visual similarity between 3D surfaces. Given a point of interest on a 3D surface, its local shape descriptor (HoSO) captures the distribution of the spherical orientations of its neighboring points. In turn, those spherical orientations are computed with respect to the point of interest itself, both in the azimuth and the zenith axis. The proposed HoSO is invariant to scale transformations and highly robust to rotation and noise. In addition, it is efficient, as it only exploits the information of the position of the 3D points and disregards other types of information like faces or normals. We performed experiments on a set of 3D surfaces representing potsherds from the Teotihuacan civilization and further validations on a set of 3D models of generic objects. Our results show that our methodology is effective for describing 3D models and that it improves classification performance with respect to previous local descriptors.", "references": ["S. Belongie, J. Malik, and J. Puzicha. 2002. Shape matching and object recognition using shape contexts. IEEE Transactions on Pattern Analysis and Machine Intelligence 24, 4, 509--522.", "C. Cortes and V. Vapnik. 1995. Support-vector networks. Machine Learning 20, 3, 273--297.", "T. Cover and P. Hart. 1967. Nearest neighbor pattern classification. IEEE Transactions in Information Theory 13, 1, 21--27."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948069"}, {"title": "Empirical use of information retrieval to build synthetic data for SMT domain adaptation", "authors": ["Sadaf Abdul-Rauf\n,", "Holger Schwenk\n,", "Patrik Lambert\n,", "Mohammad Nawaz"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nIn this paper, we present information retrieval as a powerful tool for addressing an imperative problem in the field of statistical machine translation, i.e., improving translation quality when not enough parallel corpora are available. We devise a framework, which uses information retrieval to create a synthetic corpus from the easily available monolingual corpora. We propose an improved unsupervised training approach with a data selection mechanism, which selects only the most appropriate sentences, thus reducing the amount of data, which is less related to the domain in the additional bitext. We also introduce a new method to choose sentences based on their relative similarity/difference from the query sentence. Using the synthetic corpus created by our method, we are able to improve state-of-the-art statistical machine translation systems.", "references": ["C. D. Manning, P. Raghavan, and H. Schütze, Introduction to Information Retrieval, 1st ed. Cambridge, U.K.: Cambridge Univ. Press, Jul. 2009.", "P. F. Brown et al., \"A statistical approach to machine translation,\" Comput. Ling., vol. 16, no. 2, pp. 79--85, Jun. 1990.", "P. Koehn, \"Europarl: A parallel corpus for statistical machine translation,\" in Proc. MT Summit, 2006, vol. 5, pp. 79--86."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2016.2517318"}, {"title": "Conformance Check in Healthcare with the Supporting of Processes Mining", "authors": ["Gustavo Riz\n,", "Eduardo Alves Portela Santos\n,", "Eduardo Freitas Rocha Loures"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe healthcare processes are complex and require a certain level of interdisciplinary cooperation among the various specialists and sectors involved in the processes. Besides this complexity, the Brazilian healthcare area has a notorious problem in its public and private health assistance. These problems are structural, organizational and financial, reflecting in the low valuation of quality and service. The goal of this work is propose an adaptation of Process Mining to healthcare processes in order to contribute in improve the healthcare area in Brazil. In order to achieve this goal a study case was carried out in the Erasto Gaertner hospital, situated in Curitiba - PR, Brazil, that is a national reference in treatment of cancer.", "references": ["Mans, R. S., Schonenberg, M.H., Song, M., van der Aalst, W.M.P., Rakker, p.J.M. 2009. Process Mining in Healthcare - A Case Study in Healthcare - A Case Study in a Dutch Hospital. In Biomedical Engineering Systems and Technologies - Communication in Computer and Information Science, 25, pp 425-438;", "Kaymak, U., Mans, R., van de Steeg, T., Dierks, M. 2012. On Process Mining in Health Care, In IEEE International Conference on Systems, Man, and Cybernetics. 14-17 October, 2012, Seoul, Korea;", "A. Rozinat and W.M.P. van der Aalst. 2008. Conformance Checking of Processes Based on Monitoring Real Behavior. In Journal Information Systems archive. volume 33 Issue 1, pages 64-95, Elsevier Science Ltd. Oxford, UK, 2008;"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021965"}, {"title": "Unsupervised Head--Modifier Detection in Search Queries", "authors": ["Zhongyuan Wang\n,", "Fang Wang\n,", "Haixun Wang\n,", "Zhirui Hu\n,", "Jun Yan\n,", "Fangtao Li\n,", "Ji-Rong Wen\n,", "Zhoujun Li"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nInterpreting the user intent in search queries is a key task in query understanding. Query intent classification has been widely studied. In this article, we go one step further to understand the query from the view of head--modifier analysis. For example, given the query “popular iphone 5 smart cover,” instead of using coarse-grained semantic classes (e.g., find electronic product), we interpret that “smart cover” is the head or the intent of the query and “iphone 5” is its modifier. Query head--modifier detection can help search engines to obtain particularly relevant content, which is also important for applications such as ads matching and query recommendation. We introduce an unsupervised semantic approach for query head--modifier detection. First, we mine a large number of instance level head--modifier pairs from search log. Then, we develop a conceptualization mechanism to generalize the instance level pairs to concept level. Finally, we derive weighted concept patterns that are concise, accurate, and have strong generalization power in head--modifier detection. The developed mechanism has been used in production for search relevance and ads matching. We use extensive experiment results to demonstrate the effectiveness of our approach.", "references": ["Ganesh Agarwal, Govind Kabra, and Kevin Chen-Chuan Chang. 2010. Towards rich query interpretation: Walking back and forth for mining query templates. In WWW. ACM, 1--10.", "Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting relations from large plain-text collections. In DL. ACM, 85--94.", "Michael Bendersky, Donald Metzler, and W. Bruce Croft. 2010. Learning concept importance using a weighted dependence model. In WSDM. ACM, 31--40."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988235"}, {"title": "Accuracy Of User-Contributed Image Tagging In Flickr: A Natural Disaster Case Study", "authors": ["George Panteras\n,", "Xu Lu\n,", "Arie Croitoru\n,", "Andrew Crooks\n,", "Anthony Stefanidis"], "publication": "SMSociety '16: Proceedings of the 7th 2016 International Conference on Social Media & Society", "abstract": "ABSTRACT\nSocial media platforms have become extremely popular during the past few years, presenting an alternate, and often preferred, avenue for information dissemination within massive global communities. Such user-generated multimedia content is emerging as a critical source of information for a variety of applications, and particularly during times of crisis. In order to fully explore this potential, there is a need to better assess, and improve when possible, the accuracy of such information. This paper addresses this issue by focusing in particular on user-contributed image tagging in Flickr. We use as case study a natural disaster event (wildfire), and assess the reliability of user-generated tags. Furthermore, we compare these data to the results of a content-based annotation approach in order to assess the potential performance of an alternative, user-independent, automated approach to annotate such imagery. Our results show that Flickr user annotations can be considered quite reliable (at the level of ~50%), and that using a spatially distributed training dataset for our content-based image retrieval (CBIR) annotation process improves the performance of the content-based image labeling (to the level of ~75%).", "references": ["Radzikowski J, Stefanidis A, Jacobsen KH, Croitoru A, Crooks A, Delamater PL, 2016. The Measles Vaccination Narrative in Twitter: A Quantitative Analysis, JMIR Public Health Surveill 2(1): e1.", "Gao, H., Barbier, G. and Goolsby, R., 2011. Harnessing the crowdsourcing power of social media for disaster relief. IEEE Intelligent Systems, (3): 10--14.", "Imran, M., Castillo, C., Diaz, F. and Vieweg, S., 2015. Processing social media messages in mass emergency: a survey. ACM Computing Surveys (CSUR), 47(4), 67."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930971.2930986"}, {"title": "Overlapping Speech Detection with Cluster-based HMM Framework", "authors": ["Seunghyung Lee\n,", "Juntae Kim\n,", "Jinuk Park\n,", "Minsoo Hahn"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nOverlapping speech is known to be the major source of error in various speech processing algorithm. Many previous studies on overlapping speech detection focus on exploring the various feature set for representing speech and overlapping speech characteristics while using the HMM framework. In this study, however, we hypothesize that the capacity of single HMM will not be enough to cover the whole speech and overlapping speech distribution. Thus, we proposed a simple cluster-based HMM framework to construct multiple speech and overlapping speech model. The experimental results on GRID corpus show significant improvements compare to the conventional overlap detection system.", "references": ["Yella, S.H. and Bourlard, H. 2014. Overlapping speech detection using long-term conversational features for speaker diarization in meeting room conversations. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 22, 12 (Dec. 2014), 1688--1700.", "Cetin, O. and Shriberg, E. 2006. Speaker overlaps and ASR errors in meetings: Effects before, during, and after the overlap. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (Toulouse, France, 2006), 357--360.", "Tsai, W. and Liao, S. 2010. Speaker identification in overlapping speech, Journal of Information Science and Engineering, 26, 1891--1903."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015208"}, {"title": "Gold standard based evaluation of ontology learning techniques", "authors": ["Hela Sfar\n,", "Anja Habacha Chaibi\n,", "Amel Bouzeghoub\n,", "Henda Ben Ghezala"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nA growing attention has been paid to the ontology learning domain. This is due to its importance for overcoming the limits of manual ontology building. Thus, ontology evaluation becomes crucial and very much-needed in order to select the best performing ontology learning method. The aim of the present paper is to offer a new method for assessing a learned ontology in comparison to a gold standard one. In order to avoid issues of previous precision and recall measures, the proposed method is based on a new ontology disambiguation engine. The latter provides meaning annotations to concepts. Next, we propose a set of measures that exploits the meanings of concepts to evaluate the learned ontologies. To prove the efficiency of the proposed solution, we conduct a set of experiments that test our method on well-known ontologies. Experiments show that these measures scale gradually in the closed interval of [0; 1] as learned ontologies deviate increasingly from the gold standard.", "references": ["S. B. Abbes, H. Zargayouna, and A. Nazarenko. Evaluating semantic classes used for ontology building and learning from texts. International Conference on Knowledge Engineering and Ontology Development, 2011.", "M. Banek, B. Vrdoljak, and A. M. Tjoa. Word sense disambiguation as the primary step of ontology integration. International conference on Database and Expert Systems Applications, 2008.", "P. Basile, A. Caputo, and G. Semeraro. An enhanced lesk word sense disambiguation algorithm through a distributional semantic model. International Conference on Computational Linguistics, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851843"}, {"title": "Language Identification for Social Media: Short Messages and Transliteration", "authors": ["Pedro Miguel Dias Cardoso\n,", "Anindya Roy"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nConversations on social media and microblogging websites such as Twitter typically consist of short and noisy texts. Due to the presence of slang, misspellings, and special elements such as hashtags, user mentions and URLs, such texts present a challenging case for the task of language identification. Furthermore, the extensive use of transliteration for languages such as Arabic and Russian that do not use Latin script raises yet another problem.\nThis work studies the performance of language identification algorithms applied to tweets, i.e. short messages on Twitter. It uses a previously trained general purpose language identification model to semi-automatically label a large corpus of tweets - in order to train a tweet-specific language identification model. It gives special attention to text written in transliterated Arabic and Russian.", "references": ["F. Atefeh and W. Khreich. A survey of techniques for event detection in twitter. Computational Intelligence, 2013.", "S. Carter, W. Weerkamp, and M. Tsagkias. Microblog language identification: Overcoming the limitations of short, unedited and idiomatic text. Language Resources and Evaluation, 47(1):195--215, 2013.", "W. B. Cavnar, J. M. Trenkle, et al. N-gram-based text categorization. Ann Arbor MI, 48113(2):161--175, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890560"}, {"title": "Identification of emergent leaders in a meeting scenario using multiple kernel learning", "authors": ["Cigdem Beyan\n,", "Francesca Capozzi\n,", "Cristina Becchio\n,", "Vittorio Murino"], "publication": "ASSP4MI '16: Proceedings of the 2nd Workshop on Advancements in Social Signal Processing for Multimodal Interaction", "abstract": "ABSTRACT\nIn this paper, an effective framework for detection of emergent leaders in small group is presented. In this scope, the combination of different types of nonverbal visual features; the visual focus of attention, head activity and body activity based features are utilized. Using them together ensued significant results. For the first time, multiple kernel learning (MKL) was applied for the identification of the most and the least emergent leaders. Taking the advantage of MKL's capability to use different kernels which corresponds to different feature subsets having different notions of similarity, significantly improved results compared to the state of the art methods were obtained. Additionally, high correlations between the majority of the features and the social psychology questionnaires which are designed to estimate the leadership or dominance were demonstrated.", "references": ["N. Ambady, F. Bernieri, and J. Richeson. Toward a histology of social behavior: Judgmental accuracy from thin slices of the behavioral stream. Advances in Experimental Social Psychology, 32:201--257, 2000.", "O. Aran and D. Gatica-Perez. Fusing audio-visual nonverbal cues to detect dominant people in small group conversations. In ICPR, pages 3687--3690, 2010.", "O. Aran and D. Gatica-Perez. One of a kind: inferring personality impressions in meetings. In ICMI, pages 9--13, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3005467.3005469"}, {"title": "Modeling individual differences in information search", "authors": ["Saraschandra Karanam\n,", "Herre van Oostendorp"], "publication": "IHCI '16: Proceedings of the 8th Indian Conference on Human Computer Interaction", "abstract": "ABSTRACT\nA number of cognitive processes are involved in the process of information search on the Internet: memory, attention, comprehension, problem solving, executive control and decision making. Several cognitive factors such as aging-related cognitive abilities, domain knowledge, spatial ability and need for cognition, etc. in turn influence either positively or negatively these cognitive processes. Traditional click models from information retrieval community that predict user clicks do not fully take into account the effect of the above cognitive factors. We propose to exploit the capabilities of computational cognitive models to simulate the effects of cognitive factors on information search behavior. In this direction, we present some ideas how to incorporate these factors into a computational cognitive model called CoLiDeS+. Preliminary analysis of our ideas on modeling and predicting individual differences in information search due to age and domain knowledge show promising outcomes.", "references": ["Marilyn Hughes Blackmon, Muneo Kitajima, and Peter G Polson. 2005. Tool for accurately predicting website navigation problems, non-problems, problem severity, and effectiveness of repairs. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 31--40.", "Marilyn Hughes Blackmon, Dipti R Mandalia, Peter G Polson, and Muneo Kitajima. 2007. Automating usability evaluation: Cognitive walkthrough for the web puts LSA to work on real-world HCI design problems. Handbook of latent semantic analysis (2007), 345--375.", "Pia Borlund and Peter Ingwersen. 1997. The development of a method for the evaluation of interactive information retrieval systems. Journal of Documentation 53, 3 (1997), 225--250."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3014362.3014363"}, {"title": "BayesWipe: A Scalable Probabilistic Framework for Improving Data Quality", "authors": ["Sushovan De\n,", "Yuheng Hu\n,", "Venkata Vamsikrishna Meduri\n,", "Yi Chen\n,", "Subbarao Kambhampati"], "publication": "Journal of Data and Information Quality", "abstract": "Abstract\nRecent efforts in data cleaning of structured data have focused exclusively on problems like data deduplication, record matching, and data standardization; none of the approaches addressing these problems focus on fixing incorrect attribute values in tuples. Correcting values in tuples is typically performed by a minimum cost repair of tuples that violate static constraints like Conditional Functional Dependencies (which have to be provided by domain experts or learned from a clean sample of the database). In this article, we provide a method for correcting individual attribute values in a structured database using a Bayesian generative model and a statistical error model learned from the noisy database directly. We thus avoid the necessity for a domain expert or clean master data. We also show how to efficiently perform consistent query answering using this model over a dirty database, in case write permissions to the database are unavailable. We evaluate our methods over both synthetic and real data.", "references": ["Marcelo Arenas, Leopoldo Bertossi, and Jan Chomicki. 1999. Consistent query answers in inconsistent databases. In PODS. ACM, 68--79.", "A. Asuncion and D. J. Newman. 2007. UCI Machine Learning Repository &lsqb;http://www.ics.uci.edu/&sim;mlearn/MLRepository.html&rsqb;. Irvine, CA: University of California. School of Information and Computer Science.", "Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics 22 (1996), 39--71."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2992787"}, {"title": "A Discriminative and Compact Audio Representation for Event Detection", "authors": ["Liping Jing\n,", "Bo Liu\n,", "Jaeyoung Choi\n,", "Adam Janin\n,", "Julia Bernd\n,", "Michael W. Mahoney\n,", "Gerald Friedland"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper presents a novel two-phase method for audio representation: Discriminative and Compact Audio Representation (DCAR). In the first phase, each audio track is modeled using a Gaussian mixture model (GMM) that includes several components to capture the variability within that track. The second phase takes into account both global structure and local structure. In this phase, the components are rendered more discriminative and compact by formulating an optimization problem on Grassmannian manifolds, which we found represents the structure of audio effectively. Experimental results on the YLI-MED dataset show that the proposed DCAR representation consistently outperforms state-of-the-art audio representations: i-vector, mv-vector, and GMM.", "references": ["P. Absil, R. Mahony, and R. Sepulcher, editors. Optimization algorithms on matrix manifolds. Princeton University Press, 2008.", "V. Arsigny, P. Fillard, X. Pennec, and N. Apache. Geometric means in a novel vector space structure on symmetric positive definite matrices. SIAM on Matrix Analysis, 29(1):328--347, 2007.", "D. Barchiesi, D. Giannoulis, D. Stowell, and M. Plumbley. Acoustic scene classification: classifying environments from the sounds they produce. Signal Processing Magazine, 32(3):16--34, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2970377"}, {"title": "LSRS'16: Workshop on Large-Scale Recommender Systems", "authors": ["Tao Ye\n,", "Danny Bickson\n,", "Denis Parra"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWith the increase of data collected and computation power available, modern recommender systems are ever facing new challenges. While complex models are developed in academia, industry practice seems to focus on relatively simple techniques that can deal with the magnitude of data and the need to distribute the computation. The workshop on large-scale recommender systems (LSRS) is a meeting place for industry and academia to discuss the current and future challenges of applied large-scale recommender systems.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959206"}, {"title": "Performance Analysis of SVM ensemble methods for Air Pollution Data", "authors": ["Shahid Ali\n,", "S. S. Tirumala"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nAir pollution is currently considered to be one of the biggest environmental threats. Considering the fact, that air pollution causes health disorders, the data analysis is crucial and is of paramount importance to know the living suitability of the location. New Zealand is one such environment conscious country where the analysis of air pollution data is necessary not only to assess the current situation but also to predict future levels of pollution. Analysis of air pollution data is complex as well as challenging. Support Vector Machines or SVMs have attained good success for data analysis. In this research, we conduct an empirical study of SVM approaches to assess the capability of SVM in handling air pollution data set. We used a real-time dataset obtained from USA environmental research.\nWe carried out rigorous experiments with single SVM, and ensemble methods like Bagging and AdaboostM1. With the experimental results, it can be concluded that, ensemble methods outperformed single SVM approach in both accuracy and efficiency. It is noteworthy to observe that AdaBoostM1 outperformed other methods for full dataset. The critical review of SVM ensemble and the systematic experimental study are the key contributions of this paper.\nExperimental results on air pollution dataset demonstrated that the proposed SVM ensemble method with AdaboostM1 algorithm performs better than other algorithms. The classification accuracy of single SVM method was 76.33%t whereas with Bagging algorithm it was 79.66% However, comparing to those results the best percentage of classification accuracy of 91.28% was achieved through AdaboostM1 algorithm and lesser time of 128 minutes to build ensemble model 20 and 31 minutes less than Single SVM and Bagging respectively.", "references": ["P. Gosden, A. MacGowan, and G. Bannister. Importance of air quality and related factors in the prevention of infection in orthopaedic implant surgery. Journal of Hospital Infection, 39(3):173--180, 1998.", "L. Wang, C. Jang, Y. Zhang, K. Wang, Q. Zhang, D. Streets, J. Fu, Y. Lei, J. Schreifels, K. He, J. Hao, Y.-F. Lam, J. Lin, N. Meskhidze, S. Voorhees, D. Evarts, and S. Phillips. Assessment of air quality benefits from national air pollution control policies in china. part ii: Evaluation of air quality predictions and air quality benefits assessment. Atmospheric Environment, 44(28):3449--3457, 2010.", "G. State, I. V. Popescu, and A. Gheboianu. Identification of air pollution elements in lichens used as bioindicators by the xrf and aas methods. Applied Physics, 56(1):240--249, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015188"}, {"title": "Adaptive Distributional Extensions to DFR Ranking", "authors": ["Casper Petersen\n,", "Jakob Grue Simonsen\n,", "Kalervo Järvelin\n,", "Christina Lioma"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDivergence From Randomness (DFR) ranking models assume that informative terms are distributed in a corpus differently than non-informative terms. Different statistical models (e.g. Poisson, geometric) are used to model the distribution of non-informative terms, producing different DFR models. An informative term is then detected by measuring the divergence of its distribution from the distribution of non-informative terms. However, there is little empirical evidence that the distributions of non-informative terms used in DFR actually fit current datasets. Practically this risks providing a poor separation between informative and non-informative terms, thus compromising the discriminative power of the ranking model. We present a novel extension to DFR, which first detects the best-fitting distribution of non-informative terms in a collection, and then adapts the ranking computation to this best-fitting distribution. We call this model Adaptive Distributional Ranking (ADR) because it adapts the ranking to the statistics of the specific dataset being processed each time. Experiments on TREC data show ADR to outperform DFR models (and their extensions) and be comparable in performance to a query likelihood language model (LM).", "references": ["H. Akaike. A new look at the statistical model identification. IEEE TAC, 19(6):716--723, 1974.", "G. Amati and C. J. Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM TOIS, 20(4):357--389, 2002.", "A. Bookstein and D. R. Swanson. Probabilistic models for automatic indexing. JASIS, 25(5):312--316, 1974."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983895"}, {"title": "Multi-Word Generative Query Recommendation Using Topic Modeling", "authors": ["Matthew Mitsui\n,", "Chirag Shah"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nQuery recommendation predominantly relies on search logs to use existing queries for recommendation, typically calculating query similarity metrics or transition probabilities from the log. While effective, such recommendations are limited to the queries, words, and phrases in the log. They hence do not recommend potentially useful, entirely novel queries. Recent query recommendation methods have proposed generating queries on a topical or thematic level, though current approaches are limited to generating single words. We propose a hybrid method for constructing multi-word queries in this generative sense. It uses Latent Dirichlet Allocation to generate a topic for exploration and skip-gram modeling to generate queries from the topic. According to additional evaluation metrics we present, our model improves diversity and has some room for improving relevance, yet offers an interesting avenue for query recommendation.", "references": ["R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In Proceedings of the 2004 International Conference on Current Trends in Database Technology, EDBT'04, pages 588--596. Springer-Verlag, 2004.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "D. Donato, F. Bonchi, T. Chi, and Y. Maarek. Do you want to take notes?: Identifying research missions in yahoo! search pad. In Proceedings of the 19th International Conference on World Wide Web, WWW '10, pages 321--330, New York, NY, USA, 2010. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959154"}, {"title": "Classifying User Search Intents for Query Auto-Completion", "authors": ["Jyun-Yu Jiang\n,", "Pu-Jen Cheng"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThe function of query auto-completion in modern search engines is to help users formulate queries fast and precisely. Conventional context-aware methods primarily rank candidate queries according to term- and query- relationships to the context. However, most sessions are extremely short. How to capture search intents with such relationships becomes difficult when the context generally contains only few queries. In this paper, we investigate the feasibility of discovering search intents within short context for query auto-completion. The class distribution of the search session (i.e., issued queries and click behavior) is derived as search intents. Several distribution-based features are proposed to estimate the proximity between candidates and search intents. Finally, we apply learning-to-rank to predict the user's intended query according to these features. Moreover, we also design an ensemble model to combine the benefits of our proposed features and term-based conventional approaches. Extensive experiments have been conducted on the publicly available AOL search engine log. The experimental results demonstrate that our approach significantly outperforms six competitive baselines. The performance of keystrokes is also evaluated in experiments. Furthermore, an in-depth analysis is made to justify the usability of search intent classification for query auto-completion.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In WWW '11, pages 107--116. ACM, 2011.", "E. Baykan, M. Henzinger, L. Marian, and I. Weber. Purely url-based topic classification. In WWW '09, pages 1109--1110. ACM, 2009.", "S. M. Beitzel, E. C. Jensen, D. D. Lewis, A. Chowdhury, and O. Frieder. Automatic classification of web queries using very large unlabeled query logs. ACM TOIS, 25(2):9, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970400"}, {"title": "Investigating interruptibility at activity breakpoints using smartphone activity recognition API", "authors": ["Mikio Obuchi\n,", "Wataru Sasaki\n,", "Tadashi Okoshi\n,", "Jin Nakazawa\n,", "Hideyuki Tokuda"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nWe propose a system for improving the answer rate to ESM inquiry to reduce the user's mental burden by detecting breakpoints in user's physical activity and pushing notifications in such timings. We conducted an in-the-wild user study with 30 participants for 4-days. The results revealed the effectiveness of breakpoint-based notification delivery. In the best case, 70.0% improvement in user's response time to notifications was observed at a transition to the user's activity from \"walking\" to \"stationary\".", "references": ["Apple Inc. 2014. CMMotionActivityManager. https://developer.apple.com/library/ios/documentation/CoreMotion/Reference/CMMotionActivityManager_class/index.html. (2014).", "Ling Bao and Stephen S Intille. 2004. Activity recognition from user-annotated acceleration data. In Pervasive computing. Springer, 1--17.", "Joel E. Fischer, Chris Greenhalgh, and Steve Benford. 2011. Investigating Episodes of Mobile Phone Activity As Indicators of Opportune Moments to Deliver Notifications. In Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI '11). 181--190. DOI:http://dx.doi.org/10.1145/2037373.2037402"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2968556"}, {"title": "Predicting Matchups and Preferences in Context", "authors": ["Shuo Chen\n,", "Thorsten Joachims"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWe present a general probabilistic framework for predicting the outcome of pairwise matchups (e.g. two-player sport matches) and pairwise preferences (e.g. product preferences), both of which have widespread applications ranging from matchmaking in computer games to recommendation in e-commerce. Unlike existing models for these tasks, our model not only learns representations of the items in a more expressive latent vector space, but also models how context modifies matchup and preference outcomes. For example, the context \"weather\" may alter the winning probability in a tennis match, or the fact that the user is on a mobile device may alter his preferences among restaurants. More generally, the model is capable of handling any symmetric game/comparison problem that can be described by vectorized player/item and game/context features. We provide a comprehensive evaluation of its predictive performance with real datasets from both domains to show its ability to predict preference and game outcomes more accurately than existing models. Furthermore, we demonstrate on synthetic datasets the expressiveness of the model when compared against theoretical limits.", "references": ["Wikipedia page on elo rating system. https://en.wikipedia.org/wiki/Elo_rating_system.", "R. P. Adams, G. E. Dahl, and I. Murray. Incorporating side information in probabilistic matrix factorization with gaussian processes. arXiv preprint arXiv:1003.4944, 2010.", "G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Transactions on Information Systems (TOIS), 23(1):103--145, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939764"}, {"title": "Fusion of Face and Gait for Biometric Recognition: Systematic Literature Review", "authors": ["Edenilton L. Oliveira\n,", "Clodoaldo A.M. Lima\n,", "Sarajane M. Peres"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nIn this paper is presented a systematic literature review (SLR) conducted in the field of multimodal biometrics, considering the fusion of biometric characteristics of face and gait. Biometric systems based on fusion of face and gait are useful in non-controlled environments with non-cooperative users. This SLR includes 18 primary studies which allowed the conclusion that although the theme presents some trends, there are still important gaps that need to be investigated.", "references": ["M. S. Almohammad, G. I. Salama, and T. A. Mahmoud. Human identification system based on feature level fusion using face and gait biometrics. In Proc of Int. Conf. on Engineering and Technology (ICET), pages 1-5, Oct. 2012.", "I. Buciu. Challenges and specifications for robust face and gait recognition systems for surveillance application. J. of Electrical and Electronics Engineering, 7(1):25-30, 2014.", "R. Chellappa and G. Aggarwal. Advances in Biometrics: Sensors, Algorithms and Systems, chapter Pose and Illumination Issues in Face- and Gait- Based Identification, pages 307-322. Springer London, London, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021974"}, {"title": "ScentBar: A Query Suggestion Interface Visualizing the Amount of Missed Relevant Information for Intrinsically Diverse Search", "authors": ["Kazutoshi Umemoto\n,", "Takehiro Yamamoto\n,", "Katsumi Tanaka"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFor intrinsically diverse tasks, in which collecting extensive information from different aspects of a topic is required, searchers often have difficulty formulating queries to explore diverse aspects and deciding when to stop searching. With the goal of helping searchers discover unexplored aspects and find the appropriate timing for search stopping in intrinsically diverse tasks, we propose ScentBar, a query suggestion interface visualizing the amount of important information that a user potentially misses collecting from the search results of individual queries. We define the amount of missed information for a query as the additional gain that can be obtained from unclicked search results of the query, where gain is formalized as a set-wise metric based on aspect importance, aspect novelty, and per-aspect document relevance and is estimated by using a state-of-the-art algorithm for subtopic mining and search result diversification. Results of a user study involving 24 participants showed that the proposed interface had the following advantages when the gain estimation algorithm worked reasonably: (1) ScentBar users stopped examining search results after collecting a greater amount of relevant information; (2) they issued queries whose search results contained more missed information; (3) they obtained higher gain, particularly at the late stage of their sessions; and (4) they obtained higher gain per unit time. These results suggest that the simple query visualization helps make the search process of intrinsically diverse tasks more efficient, unless inaccurate estimates of missed information are visualized.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14, 2009.", "L. Azzopardi and G. Zuccon. An analysis of theories of search and search behavior. In ICTIR, pages 81--90, 2015.", "J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR, pages 335--336, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911546"}, {"title": "Accounting for Language Changes Over Time in Document Similarity Search", "authors": ["Sara Morsy\n,", "George Karypis"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nGiven a query document, ranking the documents in a collection based on how similar they are to the query is an essential task with extensive applications. For collections that contain documents whose creation dates span several decades, this task is further complicated by the fact that the language changes over time. For example, many terms add or lose one or more senses to meet people’s evolving needs. To address this problem, we present methods that take advantage of two types of information to account for the language change. The first is the citation network that often exists within the collection, which can be used to link related documents with significantly different creation dates (and hence different language use). The second is the changes in the usage frequency of terms that occur over time, which can indicate changes in their senses and uses. These methods utilize the preceding information while estimating the representation of both documents and terms within the context of nonprobabilistic static and dynamic topic models. Our experiments on two real-world datasets that span more than 40 years show that our proposed methods improve the retrieval performance of existing models and that these improvements are statistically significant.", "references": ["Amr Ahmed and Eric P. Xing. 2012. Timeline: A dynamic hierarchical Dirichlet process model for recovering birth/death and evolution of topics in text stream. arXiv preprint arXiv:1203.3463 (2012).", "Jean Aitchison. 2001. Language Change: Progress or Decay? Cambridge University Press.", "Klaus Berberich, Srikanta J. Bedathur, Mauro Sozio, and Gerhard Weikum. 2009. Bridging the terminology gap in web archive search. In WebDB."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934671"}, {"title": "A Survey of Opponent Modeling Techniques in Automated Negotiation", "authors": ["Tim Baarslag\n,", "Mark J.C. Hendrikx\n,", "Koen V. Hindriks\n,", "Catholijn M. Jonker"], "publication": "AAMAS '16: Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems", "abstract": "ABSTRACT\nNo abstract available.", "references": ["T. Baarslag, M. J. Hendrikx, K. V. Hindriks, and C. M. Jonker. Predicting the performance of opponent models in automated negotiation. In IEEE/WIC/ACM, volume 2, Nov 2013.", "T. Baarslag, M. J. Hendrikx, K. V. Hindriks, and C. M. Jonker. Learning about the opponent in automated bilateral negotiation: a comprehensive survey of opponent modeling techniques. Autonomous Agents and Multi-Agent Systems, pages 1--50, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2936924.2937008"}, {"title": "On the Computational Hardness of Manipulating Pairwise Voting Rules", "authors": ["Rohit Vaish\n,", "Neeldhara Misra\n,", "Shivani Agarwal\n,", "Avrim Blum"], "publication": "AAMAS '16: Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems", "abstract": "ABSTRACT\nStandard voting rules usually assume that the preferences of voters are provided in the form of complete rankings over a fixed set of alternatives. This assumption does not hold in applications like recommendation systems where the set of alternatives is extremely large and only partial preferences can be elicited. In this paper, we study the problem of strategic manipulation of voting rules that aggregate voter preferences provided in the form of pairwise comparisons between alternatives. Our contributions are twofold: first, we show that any onto pairwise voting rule is manipulable in principle. Next, we analyze how the computational complexity of manipulation of such rules varies with the structure of the graph induced by the pairs of alternatives that the manipulator is allowed to vote over and the type of the preference relation. Building on natural connections between the pairwise manipulation and sports elimination problems (including a mixed-elimination variant that we introduce in this paper), we show that manipulating pairwise voting rules can be computationally hard even in the single-manipulator setting, a setting where most standard voting rules are known to be easy to manipulate.", "references": ["Kenneth J Arrow, Amartya Sen, and Kotaro Suzumura. Handbook of Social Choice & Welfare, volume 2. Elsevier, 2010.", "A. Gibbard. Manipulation of Voting Schemes: a General Result. Econometrica: Journal of the Econometric Society, pages 587--601, 1973.", "M.A. Satterthwaite. Strategy-proofness and Arrow's Conditions: Existence and Correspondence Theorems for Voting Procedures and Social Welfare Functions. Journal of Economic Theory (JET), 10(2):187--217, 1975."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2936924.2936978"}, {"title": "WSDM Cup 2016: Entity Ranking Challenge", "authors": ["Alex D. Wade\n,", "Kuansan Wang\n,", "Yizhou Sun\n,", "Antonio Gulli"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nIn this paper, we describe the WSDM Cup entity ranking challenge held in conjunction with the 2016 Web Search and Data Mining conference (WSDM 2016). Participants in the challenge were provided access to the Microsoft Academic Graph (MAG), a large heterogeneous graph of academic entities, and were invited to calculate the query-independent importance of each publication in the graph. Submissions for the challenge were open from August through November 2015, and a public leaderboard displayed teams? progress against a set of training judgements. Final evaluations were performed against a separate, withheld portion of the evaluation judgements. The top eight performing teams were then invited to submit papers to the WSDM Cup workshop, held at the WSDM 2016 conference.", "references": ["Aral, S., and Walker, D. 2012. Identifying influential and susceptible members of social networks, Science, pp. 337--341, 2012. http://doi.org/10.1126/science.1215842", "Wang, Y., Cong, G., Song, G., and Xie, K. 2010. Community-based greedy algorithm for mining top-k influential nodes in mobile social network, in Proceedings of the 16th ACM SIGKDD international conference on knowledge discovery and data mining. http:// doi.org/10.1145/1835804.1835935", "Sun, Y., Yu, Y. and Han, J. 2009. Ranking-based clustering of heterogeneous information networks with star network schema, in Proceedings of the 15th ACM SIGKDD international conference on knowledge discovery and data mining. http://doi.org/10.1145/1557019.1557107"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855119"}, {"title": "Topic Analysis", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915049"}, {"title": "Computer aided disease detection system for gastrointestinal examinations", "authors": ["Michael Riegler\n,", "Konstantin Pogorelov\n,", "Jonas Markussen\n,", "Mathias Lux\n,", "Håkon Kvale Stensland\n,", "Thomas de Lange\n,", "Carsten Griwodz\n,"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nIn this paper, we present the computer-aided diagnosis part of the EIR system [9], which can support medical experts in the task of detecting diseases and anatomical landmarks in the gastrointestinal (GI) system. This includes automatic detection of important findings in colonoscopy videos and marking them for the doctors. EIR is designed in a modular way so that it can easily be extended for other diseases. For this demonstration, we will focus on polyp detection, as our system is trained with the ASU-Mayo Clinic polyp database [5].", "references": ["Z. Albisser, M. Riegler, P. Halvorsen, J. Zhou, C. Griwodz, I. Balasingham, and C. Gurrin. Expert driven semi-supervised elucidation tool for medical endoscopic videos. In Proc. of MMSys. ACM, 2015.", "L. B Kristiansen, J. Markussen, H. Kvale Stensland, M. Riegler, H. Kohmann, F. Seifert, R. Nordstrøm, C. Griwodz, and P. Halvorsen. Device lending in PCI express networks. In Proc. of NOSSDAV. ACM, 2016.", "H. J. Escalante, C. A. Hérnadez, L. E. Sucar, and M. Montes. Late fusion of heterogeneous methods for multimedia image retrieval. In Proc. of ACM ICMR, pages 172--179. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910629"}, {"title": "Session details: Session 24", "authors": ["Ben Zhao"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2872427.3257906"}, {"title": "NCM 3.1: A Conceptual Model for Hyperknowledge Document Engineering", "authors": ["Marcio Ferreira Moreno\n,", "Rafael Brandao\n,", "Renato Cerqueira"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nMost of multimedia documents available today are agnostic to data semantics and their specification language offer little to ease authoring and mechanisms to their players so they can retrieve and present meaningful content to improve user experience. In this paper, we present the main entities of the version 3.1 of the Nested Context Model (NCM), which concentrate efforts at integrating support for enriched knowledge description to the model. This extension enables the specification of relationships between knowledge descriptions in the traditional hypermedia way, composing what we call hyperknowledge in this paper. NCM previous version (NCM 3.0) is a conceptual model for hypermedia document engineering. NCL (Nested Context Language), which is part of international standards and ITU recommendations, is an XML application language that was engineered according to NCM 3.0 definitions. The extensions discussed in this paper contribute not only for advances in the NCL specifications, but mainly as a conceptual model for hyperknowledge document engineering.", "references": ["Smeulders, AWM, et al. \"Content-based image retrieval at the end of the early years.\" Pattern Analysis and Machine Intelligence, IEEE Transactions on 22.12: 1349--1380. 2000.", "Majidpour J., et al. Interactive tool to improve the automatic image annotation using MPEG-7 and multi-class SVM. In: Information and Knowledge Technology (IKT), 2015", "Arakaki FA, Costa PL, Alves RC. Evolution of Dublin Core Metadata Standard: An Analysis of the Literature from 1995--2013. Int. Conf. on Dublin Core and Metadata Apps 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967167"}, {"title": "Privacy or Security?: Take A Look And Then Decide", "authors": ["Bettina Fazzinga\n,", "Filippo Furfaro\n,", "Elio Masciari\n,", "Giuseppe M. Mazzeo"], "publication": "SSDBM '16: Proceedings of the 28th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nBig data paradigm is currently the leading paradigm for data production and management. As a matter of fact, new information are generated at high rates in specialized fields (e.g., cybersecurity scenario). This may cause that the events to be studied occur at rates that are too fast to be effectively analyzed in real time. For example, in order to detect possible security threats, millions of records in a high-speed flow stream must be screened. To ameliorate this problem, a viable solution is the use of data compression for reducing the amount of data to be analyzed. In this paper we propose the use of privacy-preserving histograms, that provide approximate answers to 'safe' queries, for analyzing data in the cybersecurity scenario without compromising individuals' privacy, and we describe our system that has been used in a real life scenario.", "references": ["Big data. Nature, 2008.", "D. Agrawal et al. Challenges and opportunities with big data. White Paper, 2011.", "K. Chakrabarti, M. Garofalakis, R. Rastogi, and K. Shim. Approximate query processing using wavelets. The VLDB Journal, 10(2-3):199--223, Sept. 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2949689.2949706"}, {"title": "Toward practical factory activity recognition: unsupervised understanding of repetitive assembly work in a factory", "authors": ["Takuya Maekawa\n,", "Daisuke Nakai\n,", "Kazuya Ohara\n,", "Yasuo Namioka"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nIn a line production system of a factory, a worker repetitively performs predefined operation processes. This paper tries to recognize work by factory workers in an unsupervised manner. Specifically, we propose an unsupervised measurement method for estimating lead time (duration) of each period of an operation process using a wrist-worn accelerometer because the lead time greatly affects productivity of the line production system. Our proposed method automatically finds a frequent sensor data segment as a \"motif\" that occurs once in each operation period using only prior knowledge about predefined standard lead time of the operation process, and uses the occurrence intervals of the motif to estimate the lead time. We evaluated our method using real factory data and the estimation error was only about 3.5%.", "references": ["Mario Aehnelt and Sebastian Bader. 2015. Information assistance for smart assembly stations. In the 7th International Conference on Agents and Artificial Intelligence (ICAART 2015), Vol. 2. 143--150.", "Mario Aehnelt, Enrico Gutzeit, and Bodo Urban. 2014. Using activity recognition for the tracking of assembly processes: Challenges and requirements. In WOAR 2014. 12--21.", "Mario Aehnelt and Bodo Urban. 2015. The knowledge gap: providing situation-aware information assistance on the shop floor. In HCI in Business. 232--243."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971721"}, {"title": "DICOMFLOW: An architectural model for the formation of a teleradiology information infrastructure", "authors": ["Danilo A.B. Araujo\n,", "Juracy R.L. Neto\n,", "Herson H.B. Damasceno\n,", "Denys A.B. Silva\n,", "Gustavo H. M. B. Motta"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nAn Information Infrastructure (II) provides a space for information sharing and collaboration that allows the spontaneous association of people, organizations and technological components located in different geographical contexts to develop some activity. II do not originate from projects specified a priori, its formation occurs through the evolution of an installed base. The current teleradiology infrastruc ture does not yet constitute an II for radiological practice, as the inertia present in its installed base hampers its evolution. This paper presents DicomFlow, a decentralized architectural model, built on the email and PACS-DICOM infrastructures, which uses this very inertia to promote the formation of an II for radiological practice.", "references": ["Dicomflow, 2015. \"www.dicomflow.org\"", "M. Aanestad and O. Hanseth. Implementing open network technologies in complex work practices: a case from telemedicine. In Organizational and social perspectives on information technology, pages 355-369. Springer, 2000", "K. W. Bonne. Where in the world is xds and cda. Google Maps, 2015. \"https://www.google.com/maps/ d/viewer?mid=zXd445XcIVCg.kn5LIvGtp1Uk\""], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022032"}, {"title": "A Spoken Dialog System for Coordinating Information Consumption and Exploration", "authors": ["Shinya Fujie\n,", "Ishin Fukuoka\n,", "Asumi Mugita\n,", "Hiroaki Takatsu\n,", "Yoshihiko Hayashi\n,", "Tetsunori Kobayashi"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nPassive consumption of information is boring in most cases and even painful in some cases, especially when the information content is delivered by employing speech media. The user of a speech-based information delivery system, for example a text-to-speech system, usually cannot interrupt the ongoing information flow, inhibiting her/him to confirm some part of the content, or to pose an inquiry for further information exploration. We argue that a carefully designed spoken dialog system could remedy these undesirable situations, and further enable an enjoyable conversation with the users. The key technologies to realize such an attractive dialog system are: (1) pre-compilation of a dialog plan based on the analysis of a source content, and (2) the dynamic recognition of user's state of understanding and interests. This paper illustrates technical views to implement these functionalities, and discusses a dialog example to exemplify the technical merits of the proposed system.", "references": ["S. Fujie, R. Miyake, and T. Kobayashi. Spoken dialogue system using recognition of user's feedback for rhythmic dialogue. In Speech Prosody 2006, May 2006. paper 147.", "S. Janarthanam, et al. Integrating location, visibility, and question-answering in a spoken dialogue system for pedestrian city exploration. In SIGDIAL '12, pages 134--136, 2012.", "N. Kaiki and Y. Sagisaka. Study of pause insertion rules based on local phrase dependency structure. IEICE Trans. (D-II), 79(9):1455--1463, Sept. 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854995"}, {"title": "Recommender systems — beyond matrix completion", "authors": ["Dietmar Jannach\n,", "Paul Resnick\n,", "Alexander Tuzhilin\n,", "Markus Zanker"], "publication": "Communications of the ACM", "abstract": "Abstract\nThe future success of these systems depends on more than a Netflix challenge.", "references": ["Adomavicius, G. and Tuzhilin, A. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. Knowledge and Data Engineering 17, 6 (2005), 734--749.", "Adomavicius, G. and Tuzhilin, A. Context-aware recommender systems. Recommender Systems Handbook. Springer, 2011, 217--253.", "Billsus, D. and Pazzani, M.J. Learning collaborative information filters. In Proceedings ICML '98 (1998), 46--54."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2891406"}, {"title": "A sampling-based approach to accelerating queries in log management systems", "authors": ["Tal Wagner\n,", "Eric Schkufza\n,", "Udi Wieder"], "publication": "SPLASH Companion 2016: Companion Proceedings of the 2016 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity", "abstract": "ABSTRACT\nLog management systems are common in industry and an essential part of a system administrator’s toolkit. Examples include Splunk, elk, Log Insight, Sexilog, and more. Logs in these systems are characterized by a small number of predefined fields such as timestamp and host, with the bulk of an entry being unstructured text. System administrators query these logs using a combination of range constraints over predefined fields and patterns or regular expressions over the text portion of the message. These queries are both complex and diverse.\nWe propose a method for maintaining a subset of these logs in a much smaller database known as a sublog. Because queries are issued against a much smaller data set they run to completion quickly and avoid common scaling bottlenecks. However, the improvement in performance comes at a price. Because we only consider a subset of the original data, we are only able to provide approximate responses. Nonetheless, the reduction in accuracy is minimal and we are able to produce high-quality, high-performance results.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984043.2989221"}, {"title": "Index", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915055"}, {"title": "Digesting News Reader Comments via Fine-Grained Associations with Event Facets and News Contents", "authors": ["Bei Shi\n,", "Wai Lam"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNews articles from different sources reporting the same event are often associated with an enormous amount of reader comments resulting in difficulty in digesting the comments manually. Some of these comments, despite coming from different sources, discuss about a certain facet of the event. On the other hand, some comments discuss on the specific topic of the corresponding news article. We propose a framework that can digest reader comments automatically via fine-grained associations with event facets and news. We propose an unsupervised model called DRC, based on collective matrix factorization and develop a multiplicative-update method to infer the parameters. Experimental results show that our proposed DRC model can provide an effective way to digest news reader comments.", "references": ["T. Bansal, M. Das, and C. Bhattacharyya. Content driven user profiling for comment-worthy recommendations of news and blog articles. In Proceedings of the 9th ACM Conference on Recommender Systems, pages 195--202, 2015.", "M. W. Berry, M. Browne, A. N. Langville, V. P. Pauca, and R. J. Plemmons. Algorithms and applications for approximate nonnegative matrix factorization. Computational Statistics & Data Analysis, 52(1):155--173, 2007.", "G. Bouchard, D. Yin, and S. Guo. Convex collective matrix factorization. In Proceedings of the 16th International Conference on Artificial Intelligence and Statistics, pages 144--152, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983684"}, {"title": "Incorporating Clicks, Attention and Satisfaction into a Search Engine Result Page Evaluation Model", "authors": ["Aleksandr Chuklin\n,", "Maarten de Rijke"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nModern search engine result pages often provide immediate value to users and organize information in such a way that it is easy to navigate. The core ranking function contributes to this and so do result snippets, smart organization of result blocks and extensive use of one-box answers or side panels. While they are useful to the user and help search engines to stand out, such features present two big challenges for evaluation. First, the presence of such elements on a search engine result page (SERP) may lead to the absence of clicks, which is, however, not related to dissatisfaction, so-called 'good abandonments.' Second, the non-linear layout and visual difference of SERP items may lead to non-trivial patterns of user attention, which is not captured by existing evaluation metrics.\nIn this paper we propose a model of user behavior on a SERP that jointly captures click behavior, user attention and satisfaction, the CAS model, and demonstrate that it gives more accurate predictions of user actions and self-reported satisfaction than existing models based on clicks alone. We use the CAS model to build a novel evaluation metric that can be applied to non-linear SERP layouts and that can account for the utility that users obtain directly on a SERP. We demonstrate that this metric shows better agreement with user-reported satisfaction than conventional evaluation metrics.", "references": ["O. Arkhipova and L. Grauer. Evaluating mobile web search performance by taking good abandonment into account. In SIGIR, pages 1043--1046. ACM, 2014.", "L. Aroyo and C. Welty. The three sides of CrowdTruth. Human Computation, 1 (1): 31--44, 2014.", "J. A. Aslam and E. Yilmaz. Inferring document relevance from incomplete information. In CIKM, pages 633--642. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983829"}, {"title": "Word Vector Compositionality based Relevance Feedback using Kernel Density Estimation", "authors": ["Dwaipayan Roy\n,", "Debasis Ganguly\n,", "Mandar Mitra\n,", "Gareth J.F. Jones"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA limitation of standard information retrieval (IR) models is that the notion of term composionality is restricted to pre-defined phrases and term proximity. Standard text based IR models provide no easy way of representing semantic relations between terms that are not necessarily phrases, such as the equivalence relationship between `osteoporosis' and the terms `bone' and `decay'. To alleviate this limitation, we introduce a relevance feedback (RF) method which makes use of word embedded vectors. We leverage the fact that the vector addition of word embeddings leads to a semantic composition of the corresponding terms, e.g. addition of the vectors for `bone' and `decay' yields a vector that is likely to be close to the vector for the word `osteoporosis'. Our proposed RF model enables incorporation of semantic relations by exploiting term compositionality with embedded word vectors. We develop our model for RF as a generalization of the relevance model (RLM). Our experiments demonstrate that our word embedding based RF model significantly outperforms the RLM model on standard TREC test collections, namely the TREC 6,7,8 and Robust ad-hoc and the TREC 9 and 10 WT10G test collections.", "references": ["A. Berger and J. Lafferty. Information retrieval as statistical translation. In SIGIR '99, pages 222--229, 1999.", "C. L. A. Clarke, N. Craswell, and I. Soboroff. Overview of the TREC 2004 terabyte track. In TREC '04, 2004.", "S. Clinchant and E. Gaussier. A theoretical analysis of pseudo-relevance feedback models. In ICTIR '13, pages 6--13, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983750"}, {"title": "A Usefulness-based Approach for Measuring the Local and Global Effect of IIR Services", "authors": ["Daniel Hienert\n,", "Peter Mutschke"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nIn Interactive Information Retrieval (IIR) different services such as search term suggestion can support users in their search process. The applicability and performance of such services is either measured with different user-centered studies (like usability tests or laboratory experiments) or, in the context of IR, with their contribution to measures like precision and recall. However, each evaluation methodology has its certain disadvantages. For example, user-centered experiments are often costly and small-scaled; IR experiments rely on relevance assessments and measure only relevance of documents. In this work we operationalize the usefulness model of Cole et al. (2009) on the level of system support to measure not only the local effect of an IR service, but the impact it has on the whole search process. We therefore use a log-based evaluation approach which models user interactions within sessions with positive signals and apply it for the case of a search term suggestion service. We found that the usage of the service significantly often implicates the occurrence of positive signals during the following session steps.", "references": ["Maristella Agosti, Franco Crivellari, and Giorgio Maria Di Nunzio. 201 Web log analysis: a review of a decade of studies about information acquisition, inspection and interpretation of user interaction. Data Mining and Knowledge Discovery 24, 3: 663--696. http://doi.org/10.1007/s10618-011-0228-8", "Leif Azzopardi. 2009. Usage Based Effectiveness Measures: Monitoring Application Performance in Information Retrieval. Proceedings of the 18th ACM Conference on Information and Knowledge Management, ACM, 631--640. http://doi.org/10.1145/1645953.1646034", "Nicholas J. Belkin, Colleen Cool, Adelheit Stein, and Ulrich Thiel. 1995. Cases, Scripts, and Information-Seeking Strategies: On the Design of Interactive Information Retrieval Systems. EXPERT SYSTEMS WITH APPLICATIONS 9: 379--395."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854962"}, {"title": "A Fault-Tolerant Framework for Asynchronous Iterative Computations in Cloud Environments", "authors": ["Zhigang Wang\n,", "Lixin Gao\n,", "Yu Gu\n,", "Yubin Bao\n,", "Ge Yu"], "publication": "SoCC '16: Proceedings of the Seventh ACM Symposium on Cloud Computing", "abstract": "ABSTRACT\nMany graph algorithms are iterative in nature and can be supported by distributed memory-based systems in a synchronous manner. However, an asynchronous model has been recently proposed to accelerate iterative computations. Nevertheless, it is challenging to recover from failures in such a system, since a typical checkpointing based approach requires many expensive synchronization barriers that largely offset the gains of asynchronous computations.\nThis paper first proposes a fault-tolerant framework that performs recovery by leveraging surviving data, rather than checkpointing. Our fault-tolerant approach guarantees the correctness of computations. Additionally, a novel asynchronous checkpointing method is introduced to further boost the recovery efficiency at the price of nearly zero overhead. Our solutions are implemented on a prototype system, Faiter, to facilitate tolerating failures for asynchronous computations. Also, Faiter performs load balancing on recovery by re-assigning lost data onto multiple machines. We conduct extensive experiments to show the effectiveness of our proposals using a broad spectrum of real-world graphs.", "references": ["Giraph. http://giraph.apache.org/.", "Apache spark. http://spark.apache.org/.", "S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik, S. Kumar, D. Ravichandran, and M. Aly. Video suggestion and discovery for youtube: taking random walks through the view graph. In Proc. of the 17th international conference on World Wide Web, pages 895--904. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987550.2987552"}, {"title": "Query Understanding for Search on All Devices at WSDM 2016", "authors": ["Amit Goyal\n,", "Jianfeng Gao\n,", "Hongbo Deng\n,", "Yi Chang"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nNo abstract available.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proceedings of the International Conference on World Wide Web (WWW), pages 107--116. ACM, 2011.", "H. Duan and B.-J. P. Hsu. Online spelling correction for query completion. In Proceedings of the 20th International Conference on World Wide Web, WWW '11, pages 117--126. ACM, 2011.", "J. Gao, X. Li, D. Micol, C. Quirk, and X. Sun. A large scale ranker-based system for search query spelling correction. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING '10, pages 358--366. Association for Computational Linguistics, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855115"}, {"title": "Multilingual Visual Sentiment Concept Matching", "authors": ["Nikolaos Pappas\n,", "Miriam Redi\n,", "Mercan Topkara\n,", "Brendan Jou\n,", "Hongyi Liu\n,", "Tao Chen\n,", "Shih-Fu Chang"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe impact of culture in visual emotion perception has recently captured the attention of multimedia research. In this study, we provide powerful computational linguistics tools to explore, retrieve and browse a dataset of 16K multilingual affective visual concepts and 7.3M Flickr images. First, we design an effective crowdsourcing experiment to collect human judgements of sentiment connected to the visual concepts. We then use word embeddings to represent these concepts in a low dimensional vector space, allowing us to expand the meaning around concepts, and thus enabling insight about commonalities and differences among different languages. We compare a variety of concept representations through a novel evaluation task based on the notion of visual semantic relatedness. Based on these representations, we design clustering schemes to group multilingual visual concepts, and evaluate them with novel metrics based on the crowdsourced sentiment annotations as well as visual semantic relatedness. The proposed clustering framework enables us to analyze the full multilingual dataset in-depth and also show an application on a facial data subset, exploring cultural insights of portrait-related affective visual concepts.", "references": ["B. Jou, T. Chen, N. Pappas, M. Redi, M. Topkara*, and S.-F. Chang, \"Visual affect around the world: A large-scale multilingual visual sentiment ontology,\" in ACM International Conference on Multimedia, (Brisbane, Australia), pp. 159--168, 2015.", "H. Liu, B. Jou, T. Chen, M. Topkara, N. Pappas, M. Redi, and S.-F. Chang, \"Complura: Exploring and leveraging a large-scale multilingual visual sentiment ontology,\" in ACM Interational Conference on Multimedia Retrieval, (New York, NY, USA), 2016.", "J. Turian, L. Ratinov, and Y. Bengio, \"Word representations: A simple and general method for semi-supervised learning,\" in 48th Annual Meeting of the Association for Computational Linguistics, ACL '10, (Uppsala, Sweden), pp. 384--394, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912016"}, {"title": "User-friendly spreadsheet querying: an empirical study", "authors": ["Rui Pereira\n,", "João Saraiva\n,", "Jácome Cunha\n,", "João Paulo Fernandes"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nSpreadsheets are nowadays used in a variety of contexts, including in in manipulatin large and complex data. This data is stored in a large unstructured matrix, which is hard to understand and to manipulate. Recent research has been done to manipulate and query such unstructured data, namely by proposing different query approaches to spreadsheets. In this paper we present an empirical study evaluating three recent query approaches to spreadsheets assessing their usage to query spreadsheets. The results of our study show that the end-users' productivity increases when using visual, model-driven queries are used.", "references": ["J. Fan, G. Li, and L. Zhou, \"Interactive sql query suggestion: Making databases user-friendly,\" in Int. Conf. Data Eng. (ICDE), April 2011, pp. 351--362.", "H. Lu, H. C. Chan, and K. K. Wei, \"A survey on usage of sql,\" ACM SIGMOD Record, vol. 22, no. 4, pp. 60--65, 1993.", "Google, \"Google query function,\" https://developers.google.com/chart/interactive/docs/querylanguage, September 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851910"}, {"title": "Video eCommerce: Towards Online Video Advertising", "authors": ["Zhi-Qi Cheng\n,", "Yang Liu\n,", "Xiao Wu\n,", "Xian-Sheng Hua"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe prevalence of online videos provides an opportunity for e-commerce companies to exhibit their product ads in videos by recommendation. In this paper, we propose an advertising system named Video eCommerce to exhibit appropriate product ads to particular users at proper time stamps of videos, which takes into account video semantics, user shopping preference and viewing behavior feedback by a two-level strategy. At the first level, Co-Relation Regression (CRR) model is novelly proposed to construct the semantic association between keyframes and products. Heterogeneous information network (HIN) is adopted to build the user shopping preference from two different e-commerce platforms, Tmall and MagicBox, which alleviates the problems of data sparsity and cold start. In addition, Video Scene Importance Model (VSIM) utilizes the viewing behavior of users to embed ads at the most attractive position within the video stream. At the second level, taking the results of CRR, HIN and VSIM as the input, Heterogeneous Relation Matrix Factorization (HRMF) is applied for product advertising. Extensive evaluation on a variety of online videos from Tmall MagicBox demonstrates that Video eCommerce achieves promising performance, which significantly outperforms the state-of-the-art advertising methods.", "references": ["G. Aggarwal, J. Feldman, S. Muthukrishnan, and M. Pál. Sponsored search auctions with markovian users. In Internet and Network Economics, pages 621--628. 2008.", "D. M. Chickering and D. Heckerman. Targeted advertising on the web with inventory management. Interfaces, 33(5):71--77, 2003.", "P. Cui, Z. Wang, and Z. Su. What videos are similar with you?: Learning a common attributed representation for video recommendation. In ACM MM, pages 597--606, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964326"}, {"title": "Recommender Systems for Self-Actualization", "authors": ["Bart P. Knijnenburg\n,", "Saadhika Sivakumar\n,", "Daricia Wilkinson"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nEvery day, we are confronted with an abundance of decisions that require us to choose from a seemingly endless number of choice options. Recommender systems are supposed to help us deal with this formidable task, but some scholars claim that these systems instead put us inside a \"Filter Bubble\" that severely limits our perspectives. This paper presents a new direction for recommender systems research with the main goal of supporting users in developing, exploring, and understanding their unique personal preferences.", "references": ["Alexander, C., Ishikawa, S. and Silverstein, M. 1977. A Pattern Language: Towns, Buildings, Construction. Oxford University Press.", "Amatriain, X., Pujol, J.M., Tintarev, N. and Oliver, N. 2009. Rate It Again: Increasing Recommendation Accuracy by User Re-rating. Proceedings of the Third ACM Conference on Recommender Systems (New York, NY, 2009), 173--180.", "Bettman, J.R., Luce, M.F. and Payne, J.W. 1998. Constructive consumer choice processes. Journal of consumer research. 25, 3 (1998), 187--217."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959189"}, {"title": "Detecting blog spam hashtags using topic modeling", "authors": ["Yoonjin Hyun\n,", "Namgyu Kim"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nTremendous amounts of data are generated daily. Accordingly, unstructured text data that is distributed through news, blogs, and social media has gained much attention from many researchers as this data contains abundant information about various consumers' opinions. However, as the usefulness of text data is increasing, attempts to gain profits by distorting text data maliciously or non-maliciously are also increasing. In this sense, various types of spam detection techniques have been studied to prevent the side effects of spamming. The most representative studies include e-mail spam detection, web spam detection, and opinion spam detection. \"Spam\" is recognized on the basis of three characteristics and actions: (1) if a certain user is recognized as a spammer, then all content created by that user should be recognized as spam; (2) if certain content is exposed to other users (regardless of the users' intention), then content is recognized as spam; and (3) any content that contains malicious or non-malicious false information is recognized as spam. Many studies have been performed to solve type (1) and type (2) spamming by analyzing various metadata, such as user networks and spam words. In the case of type (3), however, relatively few studies have been conducted because it is difficult to determine the veracity of a certain word or information. In this study, we regard a hashtag that is irrelevant to the content of a blog post as spam and devise a methodology to detect such spam hashtags.", "references": ["Economist Intelligence Unit. 2011. Big Data Harnessing a Game-Changing Asset. The Economist.", "McKinsey Global Institute. 2011. Big Data: The next Frontier for Innovation, Competition, and Productivity. McKinsey and Company.", "Gartner Inc. 2012. 2012 Hype Cycle for Emerging Technologies. Gartner Inc."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971646"}, {"title": "Exploring a framework for identity and attribute linking across heterogeneous data systems", "authors": ["Nathan Wilder\n,", "Jared M. Smith\n,", "Audris Mockus"], "publication": "BIGDSE '16: Proceedings of the 2nd International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nOnline-activity-generated digital traces provide opportunities for novel services and unique insights as demonstrated in, for example, research on mining software repositories. The inability to link these traces within and among systems, such as Twitter, GitHub, or Reddit, inhibit the advances in this area. Furthermore, no single approach to integrate data from these disparate sources is likely to work. We aim to design Foreseer, an extensible framework, to design and evaluate identity matching techniques for public, large, and low-accuracy operational data. Foreseer consists of three functionally independent components designed to address the issues of discovery and preparation, storage and representation, and analysis and linking of traces from disparate online sources. The framework includes a domain specific language for manipulating traces, generating insights, and building novel services. We have applied it in a pilot study of roughly 10TB of data from Twitter, Reddit, and StackExchange including roughly 6M distinct entities and, using basic matching techniques, found roughly 83,000 matches among these sources. We plan to add additional entity extraction and identification algorithms, data from other sources, and design tools for facilitating dynamic ingestion and tagging of incoming data on a more robust infrastructure using Apache Spark or another distributed processing framework. We will then evaluate the utility and effectiveness of the framework in applications ranging from identifying malicious contributors in software repositories to the evaluation of the utility of privacy preservation schemes.", "references": ["Apache Software Foundation. Apache crunch, January 2016. https://crunch.apache.org/.", "Apache Software Foundation. Apache spark - lightning-fast cluster computing, January 2016. https://spark.apache.org/.", "Apache Software Foundation. Apache storm, January 2016. https://storm.apache.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896825.2896833"}, {"title": "Context-Sensitive Auto-Completion for Searching with Entities and Categories", "authors": ["Andreas Schmidt\n,", "Johannes Hoffart\n,", "Dragan Milchevski\n,", "Gerhard Weikum"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhen searching in a document collection by keywords, good auto-completion suggestions can be derived from query logs and corpus statistics. On the other hand, when querying documents which have automatically been linked to entities and semantic categories, auto-completion has not been investigated much. We have developed a semantic auto-completion system, where suggestions for entities and categories are computed in real-time from the context of already entered entities or categories and from entity-level co-occurrence statistics for the underlying corpus. Given the huge size of the knowledge bases that underlie this setting, a challenge is to compute the best suggestions fast enough for interactive user experience. Our demonstration shows the effectiveness of our method, and its interactive usability.", "references": ["K. Balog, M. Bron, and M. de Rijke. Query Modeling for Entity Search Based on Terms, Categories, and Examples. ACM Transactions on Information Systems, 29(4), 2011.", "Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In WWW 2011, 2011.", "H. Bast, F. Baurle, B. Buchhold, and E. Hauffmann. Semantic full-text search with broccoli. In SIGIR 2014, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911461"}, {"title": "Neighborhood-Preserving Hashing for Large-Scale Cross-Modal Search", "authors": ["Botong Wu\n,", "Yizhou Wang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn the literature of cross-modal search, most methods employ linear models to pursue hash codes that preserve data similarity, in terms of Euclidean distance, both within-modal and across-modal. However, data dimensionality can be quite different across modalities. It is known that the behavior of Euclidean distance/similarity between datapoints can be drastically different in linear spaces of different dimensionality. In this paper, we identify this \"variation of dimensionality\" problem in cross-modal search that may harm most of distance-based methods. We propose a semi-supervised nonlinear probabilistic cross-modal hashing method, namely Neighborhood-Preserving Hashing (NPH), to alleviate the negative effect due to the variation of dimensionality issue. Inspired by tSNE \\cite{tSNE_van2008visualizing}, rather than preserve pairwise data distances, we propose to learn hash codes that preserve neighborhood relationship of datapoints via matching their conditional distribution derived from distance to that of datapoints of multi-modalities. Experimental results on three real-world datasets demonstrate that the proposed method outperforms the state-of-the-art distance-based semi-supervised cross-modal hashing methods as well as many fully-supervised ones.", "references": ["R. E. Bellman. Dynamic Programming. 1957.", "M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, 2010.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In CIVR, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967241"}, {"title": "Legal advice on the smartphone", "authors": ["Keith Kirkpatrick"], "publication": "Communications of the ACM", "abstract": "Abstract\nNew apps help individuals contest traffic, parking tickets.", "references": ["Fixed Blocked in Three Cities: https://nakedsecurity.sophos.com/2015/10/15/fixed-app-that-fights-parking-tickets-blocked-in-3-cities/.", "Parking Mobility: https://www.youtube.com/watch?v=vyCax5yVyC8."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933414"}, {"title": "Factor Analysis of a Search Self-Efficacy Scale", "authors": ["Kathy Brennan\n,", "Diane Kelly\n,", "Yinglong Zhang"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nParticipants in information search studies are often asked to characterize their search expertise using questionnaires provided by researchers. These questionnaires often contain ad hoc sets of items in part because there are no valid and reliable measures of search experience. In this paper, we present results of an exploratory factor analysis of 327 responses to a 14-item Search Self-Efficacy scale (SSE) that we have been using as a way to measure search experience in our research. The responses come from eight different interactive information retrieval (IIR) studies, which we have conducted over the last six years, with a variety of participant types: university students, participants from the general adult population and crowd-sourced participants. The purpose of this analysis is to understand the variation in search self-efficacy scores across different types of people and to evaluate the potential of the SSE scale as a tool for measuring search experience. Overall, participants from all eight studies reported similar levels of search self-efficacy; the overall average from all eight studies was 7.47 (items scored on a 10-point scale) with little variance (standard deviation=1.36). Both the lowest and highest scores (7.1 and 7.8) were observed in studies involving the general adult population. A factor analysis showed that the questionnaire items load onto six factors, although only four had sufficient numbers of items loading on them. These four factors represent overall task success, effective use of time, query development skills, and advanced search skills.", "references": ["Aula, A. & Käki, M., 2003. Understanding expert search strategies for designing user-friendly search interfaces. In ICWI 2003, 759--762.", "Aula, A. & Nordhausen, K., 2006. Modeling successful performance in Web searching. JASIS&T, 57, 12, 1678--1693.", "Bandura, A., 1986. Social Foundations of Thought and Action: A Social Cognitive Theory. Prentice-Hall, Englewood Cliffs, N.J."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855002"}, {"title": "Impacts of Time Constraints and System Delays on User Experience", "authors": ["Anita Crescenzi\n,", "Diane Kelly\n,", "Leif Azzopardi"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nDuring information search, people often experience time pressure. This might be a result of a deadline, the system's performance or some other event. In this paper, we report results of a study with forty-five participants which investigated how time constraints and system delays impacted the user experience during information search. We randomly assigned half of our study participants to a treatment condition where they were only allowed five minutes per search task (the other half were given no time limits). For half of participants' search tasks, five second delays were introduced after queries were submitted and SERP results were clicked. We used multilevel modeling to evaluate a number of hypotheses about the effects of time constraint, system delays and user experience. We found those in the time constraint condition reported significantly greater time pressure, experienced higher task difficulty, less satisfaction with their performance, increased importance of working fast and engaged in more metacognitive monitoring. We found when experiencing system delays participants reported slower system speeds when encountering delays on the second task. This work opens a new line of inquiry into how time pressure impacts the search experience and how tools and interfaces might be designed to support people who are searching under time pressure. It also presents an example of how multilevel modeling can be used to better understand and model the complex interactions that occur during interactive information retrieval.", "references": ["I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proc. of SIGIR Conference, pages 103--112, 2014.", "M. Barreda-Ángeles, I. Arapakis, X. Bai, B. B. Cambazoglu, and A. Pereda-Baños. Unconscious physiological effects of search latency on users and their click behaviour. In Proc. of SIGIR Conference, pages 203--212, 2015.", "M. Bates. The design of browsing and berrypicking techniques for the online search interface. Online review, 13(5):407--424, 1989."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854976"}, {"title": "A Study of Retrieval Models for Long Documents and Queries in Information Retrieval", "authors": ["Ronan Cummins"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecent research has shown that long documents are unfairly penalised by a number of current retrieval methods. In this paper, we formally analyse two important but distinct reasons for normalising documents with respect to length, namely verbosity and scope, and discuss the practical implications of not normalising accordingly. We review a number of language modelling approaches and a range of recently developed retrieval methods, and show that most do not correctly model both phenomena, thus limiting their retrieval effectiveness in certain situations. Furthermore, the retrieval characteristics of long natural language queries have not traditionally had the same attention as short keyword queries. We develop a new discriminative query language modelling approach that demonstrates improved performance on long verbose queries by appropriately weighting salient aspects of the query. When combined with query expansion, we show that our new approach yields state-of-the-art performance for long verbose queries.", "references": ["Michael Bendersky and W. Bruce Croft. Discovering key concepts in verbose queries. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '08, pages 491--498, New York, NY, USA, 2008. ACM.", "Michael Bendersky, Donald Metzler, and W. Bruce Croft. Parameterized concept weighting in verbose queries. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '11, pages 605--614, New York, NY, USA, 2011. ACM.", "David Bodoff. Fuhr's challenge: conceptual research, or bust. In ACM SIGIR Forum, volume 47, pages 3--16. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883009"}, {"title": "Evaluation of Cloud Computing Tools for Virtual Enterprises", "authors": ["Andre F. Ruaro\n,", "Ricardo J. Rabelo"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nCollaborative Networks (CN) has arisen as a prominent enterprise strategy for leveraging new sustainable models, to Small and Medium sized Enterprises (SME) in more particular. There are several types of CNs. This paper focuses on the Virtual Enterprise (VE) type, which can be defined as a dynamic and temporary network of SMEs that collaborate with each other towards achieving a common goal, sharing resources, knowledge, costs, risks and benefits. In a VE the diverse kinds of transactions among its members are performed pretty much via Internet, demanding a reasonable amount of investment on IT and human resources from the enterprises. However, SMEs usually have large technical and financial limitations. The underlying premise of this work is that VE members can also share IT resources so as to decrease their general costs. Cloud computing has become a sound approach nowadays and there are plenty of cloud-based tools already available. Therefore, it is important to SMEs knowing which ones fit the VE requirements best. This is the core goal of this paper, also identifying such requirements, the requirements to evaluate such cloud-based tools, and making a comparison among them. Results are assessed and some reflections about the feasibility of a cloud approach for VEs are presented in the end.", "references": ["Myers, J. (2006). \"Future Value Systems: Next Generation Economic Growth Engines e Manufacturing\", in IMS Vision Forum 2006, IMS International, Seoul, p. 30-47.", "Camarinha-Matos, LM; Afsarmanesh, H. (2005). \"Collaborative networks: A new scientific discipline\", in Journal of Intelligent Manufacturing. V 16 (4-5), p. 439-452", "Cancian, MH; Rabelo, RJ; Wangenheim, C G V. (2013). \"Supporting Processes for Collaborative SaaS\". Proc. 14th IFIP Working Conference on Virtual Enterprises, Springer, p. 183-190."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022025"}, {"title": "Collaborative Video Annotation Based on Ontological Themes, Temporal Duration and Pointing Regions", "authors": ["Shah Khusro\n,", "Mumtaz Khan\n,", "Irfan Ullah"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nThe development of standards like MPEG-7, MPEG-21 and ID3 tags in MP3 have recognized the importance of adding descriptions to multimedia content for the purpose of better organization and retrieval. However, these standards are limited in scope and are only suitable for closed world multimedia content where a lot of effort is put in the production stage. On the contrary, video content on the Web is of arbitrary nature, captured and uploaded in a variety of formats, with the primary aim of quick and easy sharing. The advent of Web 2.0 has resulted in the wide availability of different video-sharing applications like YouTube and has made video as a major content on the Web. These web applications not only allow users to browse and search multimedia content but also add comments and annotations which provide an opportunity to harvest wisdom of the crowd. However, these annotations have not been exploited to their fullest potential for the purpose of searching and retrieval. Video searching, ranking and recommendations could become more efficient if these annotations are made machine-processable under the guidance of domain-level ontologies. Moreover, associating annotations with a specific region, temporal duration and/or a specific theme of a video results in faster retrieval of required video scene of clip. In this paper, we propose a collaborative video annotation system that is based on temporal duration and pointing regions inside a video and also utilizing ontological themes of the selected domain. For the proof-of-concept development and evaluation, a comprehensive sports ontology (Cricket in this case) has been designed. The proposed system performs well in the context of free-text and ontological annotations. It performs at a higher level when browsing and searching related themes, scenes and objects as well as summarizing related themes, scenes and objects.", "references": ["Lella, A. 2014) comScore Releases March 2014 U.S. Online Video Rankings. comScore. http://www.comscore.com/Insights/Press-Releases?keywords=&tag=YouTube&country=&publishdate=l1y&searchBtn=GO. Accessed 25-12-2014", "O'Hara, K. and Sellen, A. 1997. A comparison of reading paper and on-line documents. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems. ACM, pp 335--342", "Haslhofer, B. Jochum, W. King, R. Sadilek, C. and Schellner K. 2009. The LEMO annotation framework: weaving multimedia annotations with the web. International Journal on Digital Libraries 10 (1):15--32"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908471"}, {"title": "Towards Identifying Potential Research Collaborations from Scientific Research Networks using Scholarly Data", "authors": ["Yanet Garay\n,", "Monika Akbar\n,", "Ann Q. Gates"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIdentifying research areas of researchers is a difficult task because of the various levels of abstraction in which information may be stored; however, such a task is essential for detecting potential research collaborations within an institution. This work describes an approach to create a scientific research network with topics identified from the researchers' scholarly data and relations between topics by analyzing data harvested from digital libraries and queries to domain ontologies. The relations are used to connect the researchers. Such networks have the potential for revealing the synergy between different topics and researchers within an institution. It will also show less explored research areas that can be targeted for further study. The poster will describe the approach and how it was applied to a biomedical domain at the university.", "references": ["Newman, M. E. 2004. Coauthorship networks and patterns of scientific collaboration. Proceedings of the national academy of sciences, 101(suppl 1), 5200--5205.", "Schlangen, M. 2015. Content, Credibility, and Readership: Putting Your Institutional Repository on the Map. Public Services Quarterly, 11(3), 217--224.", "Xiang, Z., Mungall, C., Ruttenberg, A., & He, Y. 2011. Ontobee: A Linked Data Server and Browser for Ontology Terms. In ICBO."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925439"}, {"title": "Instant Espresso: Interactive Analysis of Relationships in Knowledge Graphs", "authors": ["Stephan Seufert\n,", "Patrick Ernst\n,", "Srikanta J. Bedathur\n,", "Sarath Kumar Kondreddi\n,", "Klaus Berberich\n,", "Gerhard Weikum"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe demonstrate InstantEspresso, a system to explain the relationship between two sets of entities in knowledge graphs. Instant-Espresso answers questions of the form. Which European politicians are related to politicians in the United States, and how? or How can one summarize the relationship between China and countries from the Middle East? Each question is specified by two sets of query entities. These sets (e.g. European politicians or United States politicians) can be determined by an initial graph query over a knowledge graph capturing relationships between real-world entities. Instant-Espresso analyzes the (indirect) relationships that connect entities from both sets and provides a user-friendly explanation of the answer in the form of concise subgraphs. These so-called relatedness cores correspond to important event complexes involving entities from the two sets. Our system provides a user interface for the specification of entity sets and displays a visually appealing visualization of the extracted subgraph to the user. The demonstrated system can be used to provide background information on the current state-of-affairs between real-world entities such as politicians, organizations, and the like, e.g. to a journalist preparing an article involving the entities of interest. InstantEspresso is available for an online demonstration at the URL http://espresso.mpi-inf.mpg.de/.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. In The Semantic Web, LNCS volume 4825, 2007.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge. In SIGMOD'08.", "C. Faloutsos, K. S. McCurley, and A. Tomkins. Fast Discovery of Connection Subgraphs. In KDD'04."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890528"}, {"title": "What would users change in my app? summarizing app reviews for recommending software changes", "authors": ["Andrea Di Sorbo\n,", "Sebastiano Panichella\n,", "Carol V. Alexandru\n,", "Junji Shimagaki\n,", "Corrado A. Visaggio\n,", "Gerardo Canfora\n,", "Harald C. Gall"], "publication": "FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "abstract": "ABSTRACT\nMobile app developers constantly monitor feedback in user reviews with the goal of improving their mobile apps and better meeting user expectations. Thus, automated approaches have been proposed in literature with the aim of reducing the effort required for analyzing feedback contained in user reviews via automatic classification/prioritization according to specific topics. In this paper, we introduce SURF (Summarizer of User Reviews Feedback), a novel approach to condense the enormous amount of information that developers of popular apps have to manage due to user feedback received on a daily basis. SURF relies on a conceptual model for capturing user needs useful for developers performing maintenance and evolution tasks. Then it uses sophisticated summarisation techniques for summarizing thousands of reviews and generating an interactive, structured and condensed agenda of recommended software changes. We performed an end-to-end evaluation of SURF on user reviews of 17 mobile apps (5 of them developed by Sony Mobile), involving 23 developers and researchers in total. Results demonstrate high accuracy of SURF in summarizing reviews and the usefulness of the recommended changes. In evaluating our approach we found that SURF helps developers in better understanding user needs, substantially reducing the time required by developers compared to manually analyzing user (change) requests and planning future software changes.", "references": ["U. Abelein, H. Sharp, and B. Paech. Does involving users in software development really influence system success? IEEE Software, 30(6):17–23, 2013.", "R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "G. Bavota, M. Linares-Vasquez, C. Bernal-Cardenas, M. Di Penta, R. Oliveto, and D. Poshyvanyk. The impact of api change- and fault-proneness on the user ratings of android apps. Software Engineering, IEEE Transactions on, 41(4):384–407, April 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2950290.2950299"}, {"title": "A Thermal-Aware Physical Space Allocation Strategy for 3D Flash Memory Storage Systems", "authors": ["Yi Wang\n,", "Mingxu Zhang\n,", "Lisha Dong\n,", "Xuan Yang"], "publication": "ISLPED '16: Proceedings of the 2016 International Symposium on Low Power Electronics and Design", "abstract": "ABSTRACT\nThree-dimensional (3D) flash memory stacks layers of data storage cells vertically to overcome the scaling limits in conventional planar NAND flash memory. Current 3D flash memory faces new challenges including thermal issues and complex manufacturing process. This paper presents TheraPhy, a novel thermal-aware physical space allocation strategy for three-dimensional flash memory storage systems. TheraPhy permutes the allocation of physical blocks. Consecutively accessed logical blocks are distributed to different physical locations in order to prevent the accumulation of hotspots. TheraPhy requires no changes to the file system, on-chip memory hierarchy, or hardware implementation of 3D flash memory. Based on TheraPhy, we present an address mapping strategy that is capable of determining the allocation of physical blocks based on their thermal status. We demonstrate the viability of the proposed technique using a set of extensive experiments. Experimental results show that TheraPhy can reduce the peak temperature by 15.39% with less than 1% extra erase overhead in comparison with the baseline scheme.", "references": ["UMass trace repository. http://traces.cs.umass.edu/index.php/Storage, 2016.", "A. Chakraborty, H. Homayoun, A. Khajeh, N. Dutt, A. Eltawil, and F. Kurdahi. E&lt;mc2: Less energy through multi-copy cache. In Proceedings of the 2010 International Conference on Compilers, Architectures and Synthesis for Embedded Systems, CASES '10, pages 237--246, 2010.", "Y.-M. Chang, Y.-H. Chang, T.-W. Kuo, H.-P. Li, and Y.-C. Li. A disturb-alleviation scheme for 3D flash memory. In 2013 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pages 421--428, Nov 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934583.2934638"}, {"title": "Encouraging Diversity- and Representation-Awareness in Geographically Centralized Content", "authors": ["Eduardo Graells-Garrido\n,", "Mounia Lalmas\n,", "Ricardo Baeza-Yates"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nIn centralized countries, not only population, media and economic power are concentrated, but people give more attention to central locations. While this is not inherently bad, this behavior extends to micro-blogging platforms: central locations get more attention in terms of information flow. In this paper we study the effects of an information filtering algorithm that decentralizes content in such platforms. Particularly, we found that users from non-central locations were not able to identify the geographical diversity on timelines generated by the algorithm, which were diverse by construction. To make users see the inherent diversity, we define a design rationale to approach this problem, focused on the treemap visualization technique. Then, we deployed an\" in the wild\" implementation of our proposed system. On one hand, we found that there are effects of centralization in exploratory user behavior. On the other hand, we found that the treemap was able to make users see the inherent geographical diversity of timelines. We measured these effects based on how users engaged with content filtered by the algorithm. With these results in mind, we propose practical actions for micro-blogging platforms to account for the differences and biased behavior induced by centralization.", "references": ["Abel, F., Hauff, C., Houben, G.-J., Stronkman, R., and Tao, K. Semantics + filtering + search = Twitcident. Exploring information in social web streams. Proceedings of the 23rd ACM Conference on Hypertext and Social Media. 2012, 285--294.", "Aiello, L. M., Deplano, M., Schifanella, R., and Ruffo, G. People are strange when you're a stranger: impact and influence of bots on social networks. Links, 697(483,151), 2012: 1--566.", "Archambault, D., Greene, D., Cunningham, P., and Hurley, N. ThemeCrowds: multiresolution summaries of Twitter usage. Proceedings of the 3rd international workshop on Search and mining user-generated contents. 2011, 77--84."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856775"}, {"title": "Utilizing Knowledge Bases in Text-centric Information Retrieval", "authors": ["Laura Dietz\n,", "Alexander Kotov\n,", "Edgar Meij"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nGeneral-purpose knowledge bases are increasingly growing in terms of depth (content) and width (coverage). Moreover, algorithms for entity linking and entity retrieval have improved tremendously in the past years. These developments give rise to a new line of research that exploits and combines these developments for the purposes of text-centric information retrieval applications. This tutorial focuses on a) how to retrieve a set of entities for an ad-hoc query, or more broadly, assessing relevance of KB elements for the information need, b) how to annotate text with such elements, and c) how to use this information to assess the relevance of text. We discuss different kinds of information available in a knowledge graph and how to leverage each most effectively.\nWe start the tutorial with a brief overview of different types of knowledge bases, their structure and information contained in popular general-purpose and domain-specific knowledge bases. In particular, we focus on the representation of entity-centric information in the knowledge base through names, terms, relations, and type taxonomies. Next, we will provide a recap on ad-hoc object retrieval from knowledge graphs as well as entity linking and retrieval. This is essential technology, which the remainder of the tutorial builds on. Next we will cover essential components within successful entity linking systems, including the collection of entity name information and techniques for disambiguation with contextual entity mentions. We will present the details of four previously proposed systems that successfully leverage knowledge bases to improve ad-hoc document retrieval. These systems combine the notion of entity retrieval and semantic search on one hand, with text retrieval models and entity linking on the other. Finally, we also touch on entity aspects and links in the knowledge graph as it can help to understand the entities' context.\nThis tutorial is the first to compile, summarize, and disseminate progress in this emerging area and we provide both an overview of state-of-the-art methods and outline open research problems to encourage new contributions.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970441"}, {"title": "Interactive Modeling of Concept Drift and Errors in Relevance Feedback", "authors": ["Antti Kangasrääsiö\n,", "Yi Chen\n,", "Dorota Głowacka\n,", "Samuel Kaski"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nIn exploratory search tasks, users usually start with considerable uncertainty about their search goals, and so the search intent of the user may be volatile as the user is constantly learning and reformulating her search hypothesis during the search. This may lead to a noticeable concept drift in the relevance feedback given by the user. We formulate a Bayesian regression model for predicting the accuracy of each individual user feedback and thus find outliers in the feedback data set. To accompany this model, we introduce a timeline interface that visualizes the feedback history to the user and gives her suggestions on which past feedback is likely in need of adjustment. This interface also allows the user to adjust the feedback accuracy inferences made by the model. Simulation experiments demonstrate that the performance of the new user model outperforms a simpler baseline and that the performance approaches that of an oracle, given a small amount of additional user interaction. A user study shows that the proposed modeling technique, combined with the timeline interface, made it easier for the users to notice and correct mistakes in their feedback, resulted in better and more diverse recommendations, allowed users to easier find items they liked, and was more understandable.", "references": ["J. Ahn and P. Brusilovsky. Adaptive visualization of search results: Bringing user models to visual analytics. Information Visualization, 8(3):167--179, 2009.", "J. Ahn, P. Brusilovsky, J. Grady, D. He, and S. Y. Syn. Open user profiles for adaptive news systems: Help or harm? In Proc. of the 16th International Conference on World Wide Web, WWW '07, pages 11--20. ACM, 2007.", "H. Attias. Inferring parameters and structure of latent variable models by variational Bayes. In Proc. of the Fifteenth Conference on Uncertainty in Artificial Intelligence, UAI'99, pages 21--30. Morgan Kaufmann Publishers Inc., 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930243"}, {"title": "Session details: Main Track - Decision Support Systems", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255999"}, {"title": "Joint Collaborative Ranking with Social Relationships in Top-N Recommendation", "authors": ["Dimitrios Rafailidis\n,", "Fabio Crestani"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWith the advent of learning to rank methods, relevant studies showed that Collaborative Ranking (CR) models can produce accurate ranked lists in the top-N recommendation problem. However, in practice several real-world problems decrease their ranking performance, such as the sparsity and cold-start problems, which often occur in recommendation systems for inactive or new users. In this study, to account for the fact that the selections of social friends can improve the recommendation accuracy, we propose a joint CR model based on the users' social relationships. We propose two different CR strategies based on the notions of Social Reverse Height and Social Height, which consider how well the relevant and irrelevant items of users and their social friends have been ranked at the top of the list, respectively. We focus on the top of the list mainly because users see the top-N recommendations in real-world applications, and not the whole ranked list. Furthermore, we formulate a joint objective function to consider both CR strategies, and propose an alternating minimization algorithm to learn our joint CR model. Our experiments on benchmark datasets show that our proposed joint CR model outperforms other state-of-the-art models that either consider social relationships or focus on the ranking performance at the top of the list.", "references": ["C. C. Aggarwal. Recommender Systems - The Textbook. Springer, 2016.", "A. J.-B. Chaney, D. M. Blei, and T. Eliassi-Rad. A probabilistic model for using social networks in personalized item recommendation. In RecSys, pages 43--50, 2015.", "K. Christakopoulou and A. Banerjee. Collaborative ranking with a push at the top. In WWW, pages 205--215, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983839"}, {"title": "Mining Information for the Cold-Item Problem", "authors": ["Fatemeh Pourgholamali"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nOne of the strong points of E-commerce websites is that they are often abundant with product reviews from consumers who experienced the products and testify to the usefulness of the products or otherwise. These reviews are helpful for consumers to optimize their purchasing decisions. However, while popular products receive many reviews, many other products do not have an adequate number of reviews leading to the cold item problem. In this proposal, we propose a solution outline for the cold item problem by automatically generating reviews and predicting ratings for the cold products from available reviews of similar products in e-commerce websites as well as users' opinion shared in the microblogging platforms such as Twitter. We propose a framework to build a formal semantic representation of products from unstructured product descriptions, user reviews as well as user ratings. Such presentations assist us to measure product similarity and relatedness in a accurate and cost-effective way. Besides, we propose a model to generate additional reviews for a cold product by mining users' posts shared on medium such as Twitter and transfer them to the e-commerce website. Preliminary experiments show promising results in finding products similar to the cold products.", "references": ["I. Barjasteh, R. Forsati, D. Ross, A. Esfahanian, and H.Radha. Cold-start recommendation with provable guarantees: A decoupled approach. Knowledge and Data Engineering, IEEE Transactions on, 2016.", "C. Kim and J. Kim. A recommendation algorithm using multilevel association rules. In Proceedings of International Conference on Web Intelligence, 2003.", "C. Leung, S. Chan, and F. Chung. An empirical study of a cross level association rule mining approach to cold start recommendations. Knowledge Based Systems, 21:515--529, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959102"}, {"title": "Harnessing Crowdsourced Recommendation Preference Data from Casual Gameplay", "authors": ["Barry Smyth\n,", "Rachael Rafter\n,", "Sam Banks"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nRecommender systems have become a familiar part of our online experiences, suggesting movies to watch, music to listen to, and books to read, among other things. To make relevant suggestions, recommender systems need an accurate picture of our preferences and interests and sometimes even our friends and influencers. This information can be difficult to come by and expensive to source. In this paper we describe a game-with-a-purpose designed to infer useful recommendation data as a side-effect of gameplay. The game is a simple, single-player matching game in which players attempt to match movies with their friends. It has been developed as a Facebook app and harnesses the social graph and likes of players as a source of game data. We describe the basic game mechanics and evaluate the utility of the recommendation knowledge that can be inferred from its gameplay as part of a live-user trial.", "references": ["Adomavicius, G., and Tuzhilin, A. Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Transactions on Knowledge and Data Engineering 17, 6 (June 2005), 734--749.", "Ahn, L. V., Ginosar, S., Kedia, M., and Blum, M. Improving Image Search with PHETCH. Proceedings of the 2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07 4 (Apr. 2007).", "Banks, S., Rafter, R., and Smyth, B. The recommendation game: Using a game-with-a-purpose to generate recommendation data. In Proceedings of the 9th ACM Conference on Recommender Systems, RecSys 2015, Vienna, Austria, September 16--20, 2015 (2015), 305--308."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930260"}, {"title": "Refining imprecise spatio-temporal events: a network-based approach", "authors": ["Andreas Spitz\n,", "Johanna Geiß\n,", "Michael Gertz\n,", "Stefan Hagedorn\n,", "Kai-Uwe Sattler"], "publication": "GIR '16: Proceedings of the 10th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nEvents as composites of temporal, spatial and actor information are a central object of interest in many information retrieval (IR) scenarios. There are several challenges to such event-centric IR, which range from the detection and extraction of geographic, temporal and actor mentions in documents to the construction of event descriptions as triples of locations, dates, and actors that can support event query scenarios. For the latter challenge, existing approaches fall short when dealing with imprecise event components. For example, if the exact location or date is unknown, existing IR methods are often unaware of different granularity levels and the conceptual proximity of dates or locations.\nTo address these problems, we present a framework that efficiently answers imprecise event queries, whose geographic or temporal component is given only at a coarse granularity level. Our approach utilizes a network-based event model that includes location, date, and actor components that are extracted from large document collections. Instances of entity and event mentions in the network are weighted based on both their frequency of occurrence and textual distance to reflect semantic relatedness. We demonstrate the utility and flexibility of our approach for evaluating imprecise event queries based on a large collection of events extracted from the English Wikipedia for a ground truth of news events.", "references": ["H. Abdelhaq, M. Gertz, and A. Armiti. Efficient Online Extraction of Keywords for Localized Events in Twitter. GeoInformatica, 2016 (online April 2016).", "A. Abujabal and K. Berberich. Important Events in the Past, Present, and Future. In TempWeb, 2015.", "B. Adams and M. Gahegan. Exploratory Chronotopic Data Analysis. In GIScience, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003464.3003469"}, {"title": "Scaling Synchronization in Multicore Programs", "authors": ["Adam Morrison"], "publication": "Queue", "abstract": "Abstract\nAdvanced synchronization methods can boost the performance of multicore software.", "references": ["Al Bahra, S. 2013. Nonblocking algorithms and scalable multicore programming. Communications of the ACM 56(7): 50-61.", "Boyd-Wickizer, S., Frans Kaashoek, M., Morris, R., Zeldovich, N. 2012. Non-scalable locks are dangerous. In Proceedings of the Ottawa Linux Symposium: 121-132.", "Boyd-Wickizer, S., Frans Kaashoek, M., Morris, R., Zeldovich, N. 2014. OpLog: a library for scaling update-heavy data structures. Technical Report MIT-CSAIL-TR2014-019."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.2991130"}, {"title": "Supporting the Design of Machine Learning Workflows with a Recommendation System", "authors": ["Dietmar Jannach\n,", "Michael Jugovac\n,", "Lukas Lerche"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nMachine learning and data analytics tasks in practice require several consecutive processing steps. RapidMiner is a widely used software tool for the development and execution of such analytics workflows. Unlike many other algorithm toolkits, it comprises a visual editor that allows the user to design processes on a conceptual level. This conceptual and visual approach helps the user to abstract from the technical details during the development phase and to retain a focus on the core modeling task. The large set of preimplemented data analysis and machine learning operations available in the tool, as well as their logical dependencies, can, however, be overwhelming in particular for novice users.\nIn this work, we present an add-on to the RapidMiner framework that supports the user during the modeling phase by recommending additional operations to insert into the currently developed machine learning workflow. First, we propose different recommendation techniques and evaluate them in an offline setting using a pool of several thousand existing workflows. Second, we present the results of a laboratory study, which show that our tool helps users to significantly increase the efficiency of the modeling process. Finally, we report on analyses using data that were collected during the real-world deployment of the plug-in component and compare the results of the live deployment of the tool with the results obtained through an offline analysis and a replay simulation.", "references": ["Rakesh Agrawal, Tomasz Imieliński, and Arun Swami. 1993. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data (SIGMOD’93). 207--216.", "Szymon Bobek, Mateusz Baran, Krzysztof Kluza, and Grzegorz J. Nalepa. 2013. Application of Bayesian networks to recommendations in business process modeling. In Proceedings of the 2013 Workshop AI Meets Business Processes (AIBP’13). 41--50.", "Nguyen Ngoc Chan, Walid Gaaloul, and Samir Tata. 2011. Composition context matching for web service recommendation. In Proceedings of the 2011 IEEE International Conference on Services Computing (SCC’11). 624--631."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2852082"}, {"title": "News recommendation based on tweets for understanding of opinion variation and events", "authors": ["Douglas Rehem\n,", "Jonice Oliveira\n,", "Tiago França\n,", "Walkir Brito\n,", "Claudia Motta"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nOnline social networks (OSN) have become very popular in the last years. People use it to tell what they are thinking and feeling. As these OSN became bigger and its content propagation is fast, they are commonly used as personal-update mechanism. Sometimes, the quantity, variety and quality of information spread in OSN are a problem when a person tries to use this kind of system to keeping yourself updated. Aiming to find relevant news related to users' current interests or news that could explain an event, we present a recommender system based on Twitter.", "references": ["Lauand, B. and Oliveira, J. Inferindo as Condições de Trânsito através da Análise de Sentimentos no Twitter. iSys - Revista Brasileira de Sistemas de Informação (2014), 56--74.", "Tumasjan, A., O. Sprenger, T., G. Sandner, P. and M. Welpe, I. Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment. 2010.", "Santos, F. and Oliveira, J. More than Just a Game: The Power of Social Media on Super Bowl XLVI. Social Networking 03, 02 (2014), 142--145."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851988"}, {"title": "Discriminant Cross-modal Hashing", "authors": ["Xing Xu\n,", "Fumin Shen\n,", "Yang Yang\n,", "Heng Tao Shen"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nHashing based methods have attracted considerable attention for efficient cross-modal retrieval on large-scale multimedia data. The core problem of cross-modal hashing is how to effectively integrate heterogeneous features from different modalities to learn hash functions using available supervising information, e.g., class labels. Existing hashing based methods generally project heterogeneous features to a common space for hash codes generation, and the supervising information is incrementally used for improving performance. However, these methods may produce ineffective hash codes, due to the failure to explore the discriminative property of supervising information and to effectively bridge the semantic gap between different modalities. To address these challenges, we propose a novel hashing based method in a linear classification framework, in which the proposed method learns modality-specific hash functions for generating unified binary codes, and these binary codes are viewed as representative features for discriminative classification with class labels. An effective optimization algorithm is developed for the proposed method to jointly learn the modality-specific hash function, the unified binary codes and a linear classifier. Extensive experiments on three benchmark datasets highlight the advantage of the proposed method and show that it achieves the state-of-the-art performance.", "references": ["L. Ballan, T. Uricchio, L. Seidenari, and A. Del Bimbo. A cross-media model for automatic image annotation. In ACM International Conference on Multimedia Retrieval, 2014.", "M. Bronstein, A. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In IEEE Conference on Computer Vision and Pattern Recognition, pages 3594--3601, 2010.", "G. Ding, Y. Guo, and J. Zhou. Collective matrix factorization hashing for multimodal data. In IEEE Conference on Computer Vision and Pattern Recognition, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912056"}, {"title": "Can we find documents in web archives without knowing their contents?", "authors": ["Khoi Duy Vo\n,", "Tuan Tran\n,", "Tu Ngoc Nguyen\n,", "Xiaofei Zhu\n,", "Wolfgang Nejdl"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nRecent advances of preservation technologies have led to an increasing number of Web archive systems and collections. These collections are valuable to explore the past of the Web, but their value can only be uncovered with effective access and exploration mechanisms. Ideal search and ranking methods must be robust to the high redundancy and the temporal noise of contents, as well as scalable to the huge amount of data archived. Despite several attempts in Web archive search, facilitating access to Web archive still remains a challenging problem.\nIn this work, we conduct a first analysis on different ranking strategies that exploit evidences from metadata instead of the full content of documents. We perform a first study to compare the usefulness of non-content evidences to Web archive search, where the evidences are mined from the metadata of file headers, links and URL strings only. Based on these findings, we propose a simple yet surprisingly effective learning model that combines multiple evidences to distinguish \"good\" from \"bad\" search results. We conduct empirical experiments quantitatively as well as qualitatively to confirm the validity of our proposed method, as a first step towards better ranking in Web archives taking metadata into account.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. In ISWC / ASWC, pages 722--735. Springer, 2007.", "K. Berberich, S. Bedathur, O. Alonso, and G. Weikum. A language modeling approach for temporal information needs. In ECIR, pages 13--25. Springer, 2010.", "K. Berberich, S. Bedathur, T. Neumann, and G. Weikum. A time machine for text search. In SIGIR, pages 519--526. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908165"}, {"title": "Approximating Graph Pattern Queries Using Views", "authors": ["Jia Li\n,", "Yang Cao\n,", "Xudong Liu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper studies approximation of graph pattern queries using views. Given a pattern query Q and a set V of views, we propose to find a pair of queries Qu and Ql, referred to as the upper and lower approximations of Q w.r.t. V, such that (a) for any data graph G, answers to (part of) Q in G are contained in Qu(G) and contain Ql(G); and (b) both Qu and Ql can be answered by using views in V. We consider pattern queries based on both graph simulation and subgraph isomorphism. We study fundamental problems about approximation using views. Given Q and V, (1) we study whether there exist upper and lower approximations of Q w.r.t. V. (2) How to find approximations that are closest to Q w.r.t. V if exist? (3) How to answer upper and lower approximations using views in V? We give characterizations of the problems, study their complexity and approximation-hardness, and develop algorithms with provable bounds. Using real-life datasets, we verify the effectiveness and efficiency of approximating simulation and subgraph queries using views.", "references": ["DBpedia.sl http://wiki.dbpedia.org/Downloads2015-04.", "YouTube.sl http://netsg.cs.sfu.ca/youtubedata/.", "P. Barceló, L. Libkin, and M. Romero. Efficient approximations of conjunctive queries. SICOMP, 43(3):1085--1130, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983766"}, {"title": "DAJEE: A Dataset of Joint Educational Entities for Information Retrieval in Technology Enhanced Learning", "authors": ["Vladimir Estivill-Castro\n,", "Carla Limongelli\n,", "Matteo Lombardi\n,", "Alessandro Marani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn the Technology Enhanced Learning (TEL) community, the problem of conducting reproducible evaluations of recommender systems is still open, due to the lack of exhaustive benchmarks. The few public datasets available in TEL have limitations, being mostly small and local.\nRecently, Massive Open Online Courses (MOOC) are attracting many studies in TEL, mainly because of the huge amount of data for these courses and their potential for many applications in TEL. This paper presents DAJEE, a dataset built from the crawling of MOOCs hosted on the Coursera platform. DAJEE offers information on the usage of more than 20,000 resources in 407 courses by 484 instructors, with a conjunction of different educational entities in order to store the courses' structure and the instructors' teaching experiences.", "references": ["Drachsler, H., Verbert, K., Santos, O. C., and Manouselis, N. Panorama of recommender systems to support learning. In Recommender systems handbook. Springer, 2015, pp. 421--451.", "Kay, J., Reimann, P., Diebold, E., and Kummerfeld, B. Moocs: So many learners, so much potential... IEEE Intelligent Systems, 3 (2013), 70--77.", "Krieger, K. Creating learning material from web resources. In The Semantic Web. Latest Advances and New Domains. Springer, 2015, pp. 721--730."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914670"}, {"title": "A Literature Review about Technology Startups Ecosystems", "authors": ["Nagila N.J. Torres\n,", "Cleidson R.B. Souza"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThere is a global interest in encouraging startups companies because of the expected economic growth in the regions where these startups are located. However, startups are not individual companies, they live in an ecosystem that includes other startups, universities, incubators, investors, among other elements. Thus, understanding the components and the relationships that exist among the elements of a startup ecosystem enables decision making about how best to encourage this ecosystem. This study describes, through a critical review of the literature, a holistic view of the elements that make up a technology startup ecosystem. This work was guided by a literature review of 20 selected works through a process of snowball sampling. The main result is a conceptual framework with the elements that make up a startup ecosystem and their relationships. These are the elements that influence the ecosystem, although, in some cases, there is no consensus in the literature about whether this influence is positive or negative. Thus, the proposed framework identifies factors that have been extensively studied in the literature and, more importantly, other factors that deserve further exploration.", "references": ["TI Maior. Programa Estrategico de Software e Servicos de Tecnologia da Informacao, 2012", "MOTOYAMA, Y.; WALTKINS, K.. Examining the Connections within the Startup Ecosystem: A CASE Study of St. LouiS. Kauffman Foundation Research Series on City, Metro, and Regional Entrepreneurship. 2014", "RIES, Eric. A Startup Enxuta. Sao Paulo: Leya, 2012. 275p"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022020"}, {"title": "Trust-aware Privacy-Preserving Recommender System", "authors": ["Xiwei Wang\n,", "Jun Zhang\n,", "Yin Wang"], "publication": "MobiMedia '16: Proceedings of the 9th EAI International Conference on Mobile Multimedia Communications", "abstract": "ABSTRACT\nRecommender systems have achieved great success in providing product recommendations for online shopping. With recommender systems, customers can find their interested merchandise in a timely manner. It not only facilitates customers' purchases, but also promotes sales. While recommender systems can predict customers' preferences accurately, they suffer from privacy leakage in many aspects.\nIn this paper, we study an attack model in centralized recommender systems and present a privacy-preserving recommendation framework to neutralize such attack. In this model, an attacker holds some of the real customers' ratings and attempts to obtain their private preferences. The proposed framework is based on the weighted nonnegative matrix tri-factorization technique. It utilizes customers' trustworthiness to filter out unrelated ratings so that their privacy can be preserved. We performed experiments on two different datasets with respect to recommendation precision and privacy preservation level. The results demonstrate that our recommender system can distinguish between real customers and attackers to a great extent without compromising the prediction accuracy.", "references": ["S. Berkovsky, Y. Eytani, T. Kuik, and F. Ricci. Enhancing Privacy and Preserving Accuracy of a Distributed Collaborative Filtering. In Proceedings of the 2007 ACM Conference on Recommender Systems, pages 9--16, 2007.", "A. Bilge and H. Polat. Improving Privacy-Preserving NBC-based Recommendations by Preprocessing. In Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 143--147, 2010.", "J. Canny. Collaborative Filtering with Privacy. In Proceedings of the 2002 IEEE Symposium on Security and Privacy, pages 45--57, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021385.3021406"}, {"title": "How does Interest in a Work Task Impact Search Behavior and Engagement?", "authors": ["Ashlee Edwards\n,", "Diane Kelly"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nOne goal of using simulated work tasks in interactive information retrieval (IIR) experiments is to create a more relevant and interesting search experience for study participants. However, there is not much guidance about how to identify interesting tasks or how interest in a task impacts search behaviors and experiences, which is the purpose of this study. In this study, we created eight work tasks and asked forty participants to rank these tasks from most interesting to least interesting before they came into the lab for an IIR experiment. During the experiment, we asked participants to conduct searches for the two tasks they ranked as most interesting and the two they ranked as least interesting. Participants completed pre- and post-search questionnaires to characterize their interests in the tasks and their search experiences, including engagement. Participants rated their interest, prior knowledge and search experience, and the relevancy of interesting tasks significantly higher than uninteresting tasks. They also predicted these tasks would be significantly less difficult to complete. Participants reported significantly greater engagement with interesting tasks and they spent longer completing these tasks. However, there were no significant differences in participants' search behaviors including number of queries issued, number of SERPs, or number of documents bookmarked. These results provide evidence that our method of assigning tasks to participants that would interest and engage them, at least cognitively, if not behaviorally, was somewhat successful. This method can be used by others conducting laboratory IIR studies.", "references": ["Borlund, P. (2003). The IIR evaluation model: a framework for evaluation of interactive information retrieval systems. Information Research, 8.", "Borlund, P., Dreier, S., & Byström, K. (2012). What does time spent on searching indicate? Proc. of IIiX, 184--193.", "Borlund, P., & Schneider, J. W. (2010). Reconsideration of the simulated work task situation: A context instrument for evaluation of information retrieval interaction. In Proceedings of the Third Symposium on Information Interaction in Context, 155--164."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855000"}, {"title": "Link Prediction in Heterogeneous Social Networks", "authors": ["Sumit Negi\n,", "Santanu Chaudhury"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA heterogeneous social network is characterized by multiple link types which makes the task of link prediction in such networks more involved. In the last few years collective link prediction methods have been proposed for the problem of link prediction in heterogeneous networks. These methods capture the correlation between different types of links and utilize this information in the link prediction task. In this paper we pose the problem of link prediction in heterogeneous networks as a multi-task, metric learning (MTML) problem. For each link-type (relation) we learn a corresponding distance measure, which utilizes both network and node features. These link-type specific distance measures are learnt in a coupled fashion by employing the Multi-Task Structure Preserving Metric Learning (MT-SPML) setup. We further extend the MT-SPML method to account for task correlations, robustness to non-informative features and non-stationary degree distribution across networks. Experiments on the Flickr and DBLP network demonstrates the effectiveness of our proposed approach vis-à-vis competitive baselines.", "references": ["Y. Yang, N. V. Chawla, Y. Sun, and J. Han, \"Predicting links in multi-relational and heterogeneous networks.\" in ICDM, 2012. {Online}. Available: http://dblp.uni-trier.de/db/conf/icdm/icdm2012.html", "B. Cao, N. N. Liu, and Q. Y. 0001, \"Transfer learning for collective link prediction in multiple heterogenous domains.\" in ICML, J. Fürnkranz and T. Joachims, Eds. Omnipress, 2010, pp. 159--166. {Online}. Available: http://dblp.uni-trier.de/db/conf/icml/icml2010.html", "D. A. Davis, R. Lichtenwalter, and N. V. Chawla, \"Multi-relational link prediction in heterogeneous information networks,\" in ASONAM. IEEE Computer Society, 2011, pp. 281--288."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983722"}, {"title": "Non-negative multiple matrix factorization with social similarity for recommender systems", "authors": ["Guoying Zhang\n,", "Min He\n,", "Hao Wu\n,", "Guanghui Cai\n,", "Jianhong Ge"], "publication": "BDCAT '16: Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies", "abstract": "ABSTRACT\nA key problem in online social networks is the identification of users' link information and the analysis of how these are reflected in the recommender systems. The basis to tackle this issue is user similarity measures. In this paper, we propose non-negative multiple matrix factorization with social similarity for recommender systems, considering the similarities between users, the relationships of users-resources and tags-resources. On this basis, we comparatively analyzed different performances of the recommendation with every similarity measure between users. In addition, our method can also recommend friends, resources, and tags to users. Experimental results on Lastfm and Delicious datasets show that the proposed method can significantly improve the recommendation accuracy compared with the art collaborative filtering methods.", "references": ["B. Bringmann, M. Berlingerio, F. Bonchi, and A. Gionis. Learning and Predicting the Evolution of Social Networks. Intelligent Systems IEEE, 25(4):26--35, 2010.", "P. Brodka, S. Saganowski, and P. Kazienko. GED: the method for group evolution discovery in social networks. Social Network Analysis & Mining, 3(1):1--14, 2013.", "M. E. Newman and M. Girvan. Finding and evaluating community structure in networks. Physical Review E Statistical Nonlinear & Soft Matter Physics, 69(2 Pt 2):026113--026113, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3006299.3006323"}, {"title": "Wisdom of the local crowd: detecting local events using social media data", "authors": ["Søren B. Ranneries\n,", "Mads E. Kalør\n,", "Sofie Aa. Nielsen\n,", "Lukas N. Dalgaard\n,", "Lasse D. Christensen\n,", "Nattiya Kanhabua"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nEvent attendees post about their experiences on social media. We propose a novel approach for analyzing these posts to extract ongoing events. We gather posts from Twitter and Instagram and perform a number of processing steps to identify posts related to events based on hashtags and location information. Our approach detects events only using posts submitted during the past hour which ensures that only ongoing events are detected. The system can detect both large and small events with a high location accuracy, a precision of 0.20, and a recall of 0.60.", "references": ["A. Boettcher and D. Lee. Eventradar: A real-time local event detection scheme using twitter stream. In GreenCom 2012, Nov 2012.", "M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. AAAI Press, 1996.", "R. Lee and K. Sumiya. Measuring geographical regularities of crowd behaviors for twitter-based geo-social event detection. In SIGSPATIAL. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908197"}, {"title": "Correlation Between System and User Metrics in a Session", "authors": ["Jiepu Jiang\n,", "James Allan"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWe investigate the correlations between system-oriented evaluation metrics and a few user experience metrics for a search session. The system-oriented metrics include session-based DCG (sDCG), normalized sDCG (nsDCG), estimated session nDCG (esNDCG), and a few variants of these metrics. We also look into statistics (e.g., the mean, maximum, and minimum values) of individual queries' nDCG scores, as well as the first and the last query's nDCG in a session. These system-oriented metrics are compared with users' self-rated search performance and task difficulty for a session. Experimental results show that nsDCG and esNDCG have reasonable but weak correlations with the user metrics, while the worst and the last query's nDCG in a session have comparably strong correlations. This suggests future work may better measure users' search experience in a session by modeling each query in the session differently.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: A game for modeling different types of web search success using interaction data. In SIGIR '11, pages 345--354, 2011.", "J. Arguello. Predicting search task difficulty. In ECIR '14, pages 88--99, 2014.", "L. Azzopardi. Modelling interaction with economic models of search. In SIGIR '14, pages 3--12, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855005"}, {"title": "RECKON: an analytics framework for app developers", "authors": ["Abhinav Parate\n,", "Puneet Jain\n,", "Kyu-Han Kim"], "publication": "SmartObjects '16: Proceedings of the 2nd Workshop on Experiences in the Design and Implementation of Smart Objects", "abstract": "ABSTRACT\nThis paper argues that there is a need to expand the capabilities of mobile app analytics beyond providing low-level insights about how efficiently a user can execute an action on a mobile app, to deeper insights about how efficiently a user can complete a task using the app (e.g., flight reservation). This paper presents RECKON, a framework for mobile app analytics, that provides insights about end-to-end user experience in completing tasks, without explicit effort from the app developers. RECKON identifies and extracts task-level information from an unlabeled data stream of user actions. Based on the extracted information, RECKON outputs various helpful metrics to the developers. We have implemented and evaluated RECKON with a popular travel assistant app with 122, 243 users for 30 days. Our evaluation results validate RECKON's performance in obtaining critical mobile app insights as well as demonstrate its wide applicability for developers.", "references": ["Centrality, https://en.wikipedia.org/wiki/Centrality.", "Flurry Mobile Analytics, http://www.flurry.com/.", "Google Analytics For Mobile Apps, https://www.google.com/analytics/mobile/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980147.2980154"}, {"title": "Div150Multi: a social image retrieval result diversification dataset with multi-topic queries", "authors": ["Bogdan Ionescu\n,", "Alexandru Lucian Gînscă\n,", "Bogdan Boteanu\n,", "Mihai Lupu\n,", "Adrian Popescu\n,", "Henning Müller"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nIn this paper we introduce a new dataset, Div150Multi, that was designed to support shared evaluation of diversification techniques in different areas of social media photo retrieval and related areas. The dataset comes with associated relevance and diversity assessments performed by trusted annotators. The data consists of around 300 complex queries represented via 86,769 Flickr photos, around 27M photo links for around 6,000 users, metadata, Wikipedia pages and content descriptors for text and visual modalities, including state of the art deep features. To facilitate distribution, only Creative Commons content allowing redistribution was included in the dataset. The proposed dataset was validated during the 2015 Retrieving Diverse Social Images Task at the MediaEval Benchmarking.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14. ACM, 2009.", "D.-T. Dang-Nguyen, G. Boato, F. G. Natale, L. Piras, G. Giacinco, F. Tuveri, and M. Angioni. Multimodal-based diversified summarization in social image retrieval. 2015.", "D.-T. Dang-Nguyen, L. Piras, G. Giacinto, G. Boato, and F. G. De Natale. A hybrid approach for retrieving diverse social images of landmarks. In IEEE ICME, pages 1--6, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910620"}, {"title": "The Role of Language Skills in Interactive Social Book Search Sessions", "authors": ["Maria Gäde\n,", "Mark M. Hall"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWhen searching for books, people frequently have to deal with content that is in a language different from their own. However, research on multilingual systems has generally focused on the user interface's language rather than the content language. In this paper, we describe and compare early results from the multilingual aspects in the Interactive Social Book Search (iSBS) task at CLEF 2014 and 2015. A preliminary analysis of usage patterns for native English and non-native English speakers indicates an influence of language skills on search behaviour during goal-oriented and casual leisure tasks. Based on previous experiences and results, strengths and challenges of IIR studies are discussed.", "references": ["Bellot, P., Bogers, T., Geva, S., Hall, M., Huurdeman, H., Kamps, J., Kazai, G., Koolen, M., Moriceau, V., Mothe, J., et al. Overview of inex 2014. In Information Access Evaluation. Multilinguality, Multimodality, and Interaction. Springer, 2014, pp. 212--228.", "Gäde, M., Hall, M., Huurdeman, H., Kamps, J., Koolen, M., Skov, M., Toms, E., and Walsh, D. Overview of the sbs 2015 interactive track. In CEUR Workshop Proceedings (2015).", "Hall, M. M., Huurdemann, H., Skov, M., Walsh, D., et al. Overview of the inex 2014 interactive social book search track."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854990"}, {"title": "Motivating Invisible Contributions: Framing Volunteer Classification Design in a Fanfiction Repository", "authors": ["Julia Bullard"], "publication": "GROUP '16: Proceedings of the 19th International Conference on Supporting Group Work", "abstract": "ABSTRACT\nContributions from the crowd are not just content-sustainable systems require ongoing behind-the-scenes infrastructural work. In this paper, I explore potential strategies for motivating volunteer contributions to large-scale collaborative projects when volunteer contributions are procedural in nature and largely invisible in the published project. I use a user-driven classification system for a large, established, and growing fanfiction collection as an example of a successful project of this type. I compare the challenges and possibilities to those established in the study of open source, wiki, and citizen science projects, which share with classification design a need for distributed human contributions to procedural tasks. Textual analysis of recruiting and training documents, informed by prolonged engagement in the community, reveals strategies that diverge from other HCI research on motivation, such as a focus on work rather than fun and insider rather than public recognition.", "references": ["Ban Al-Ani, Gloria Mark, and Bryan Semaan. 2010. Blogging in a region of conflict. Proceedings of the 28th international conference on Human factors in computing systems - CHI '10, ACM Press, 1069. http://doi.org/10.1145/1753326.1753485", "Judd Antin. 2011. My kind of people? Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, ACM Press, 3411. http://doi.org/10.1145/1978942.1979451", "Richard P. Bagozzi and Utpal M Dholakia. 2006. Open Source Software User Communities: A Study of Participation in Linux User Groups. Management Science 52, 7: 1099--1115. http://doi.org/10.1287/mnsc.1060.0545"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957276.2957295"}, {"title": "Deep Learning for Information Retrieval", "authors": ["Hang Li\n,", "Zhengdong Lu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecent years have observed a significant progress in information retrieval and natural language processing with deep learning technologies being successfully applied into almost all of their major tasks. The key to the success of deep learning is its capability of accurately learning distributed representations (vector representations or structured arrangement of them) of natural language expressions such as sentences, and effectively utilizing the representations in the tasks. This tutorial aims at summarizing and introducing the results of recent research on deep learning for information retrieval, in order to stimulate and foster more significant research and development work on the topic in the future.\nThe tutorial mainly consists of three parts. In the first part, we introduce the fundamental techniques of deep learning for natural language processing and information retrieval, such as word embedding, recurrent neural networks, and convolutional neural networks. In the second part, we explain how deep learning, particularly representation learning techniques, can be utilized in fundamental NLP and IR problems, including matching, translation, classification, and structured prediction. In the third part, we describe how deep learning can be used in specific application tasks in details. The tasks are search, question answering (from either documents, database, or knowledge base), and image retrieval.", "references": ["J. Andreas, M. Rohrbach, T. Darrell, and D. Klein. Learning to compose neural networks for question answering. arXiv:1601.01705, 2016.", "D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. In Proceedings of ICLR'15, 2015.", "B. Bai, J. Weston, D. Grangier, R. Collobert, K. Sadamasa, Y. Qi, O. Chapelle, and K. Weinberger. Supervised semantic indexing. In Proceedings of CIKM'09, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914800"}, {"title": "Space Target Motion Attitude Discrimination based on RCS Time Sequence", "authors": ["Yuntao Li\n,", "Wei Qu\n,", "Zhennan Wang\n,", "Yibo Zhao"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThe radar echo can be modulated by the attitude change of space target, which is expressed as the randomness and the anisotropy of the radar cross section (RCS) time sequence, so as to provide an important feature for the target recognition. According to the motion characteristics of space targets, their motion attitude can be divided into three-axis stabilized attitude, spin stabilized attitude and free tumbling attitude. The run test method is used to analyze the randomness of RCS sequence. Three-axis stabilized satellite and debris can be separated by curve fitting variance threshold method. Spin stabilized satellite and tumbling object can be discriminated by period value, which is estimated by combination method of cyclic autocorrelation and cycle amplitude difference. The measured data test results verify the validity of the proposed method.", "references": ["Cravey R. L. 1995. RCS Measurements and Simulation of a Tethered Satellite. N95-19781.", "Quan B., Dai Z. J., and Hu W. D. 2000. The non-parameter method of recognizing two-types space target. Chinese Space Science and Technology, 3, 1--4.", "Dai Z.J. 2001. Discriminate of low orbit satellites 3-axes stabilization guise based on narrow-band radar. Aerospace Electronic Warfare. 4, 13--15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015203"}, {"title": "Heterogeneous Translated Hashing: A Scalable Solution Towards Multi-Modal Similarity Search", "authors": ["Ying Wei\n,", "Yangqiu Song\n,", "Yi Zhen\n,", "Bo Liu\n,", "Qiang Yang"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nMulti-modal similarity search has attracted considerable attention to meet the need of information retrieval across different types of media. To enable efficient multi-modal similarity search in large-scale databases recently, researchers start to study multi-modal hashing. Most of the existing methods are applied to search across multi-views among which explicit correspondence is provided. Given a multi-modal similarity search task, we observe that abundant multi-view data can be found on the Web which can serve as an auxiliary bridge. In this paper, we propose a Heterogeneous Translated Hashing (HTH) method with such auxiliary bridge incorporated not only to improve current multi-view search but also to enable similarity search across heterogeneous media which have no direct correspondence. HTH provides more flexible and discriminative ability by embedding heterogeneous media into different Hamming spaces, compared to almost all existing methods that map heterogeneous data in a common Hamming space. We formulate a joint optimization model to learn hash functions embedding heterogeneous media into different Hamming spaces, and a translator aligning different Hamming spaces. The extensive experiments on two real-world datasets, one publicly available dataset of Flickr, and the other MIRFLICKR-Yahoo Answers dataset, highlight the effectiveness and efficiency of our algorithm.", "references": ["A. Andoni and P. Indyk. 2006. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In FOCS. ACM, 459--468. DOI:http://dx.doi.org/10.1109/FOCS.2006.49", "Jon Louis Bentley. 1975. Multidimensional binary search trees used for associative searching. Commun. ACM 18, 9 (1975), 509--517.", "James C. Bezdek and Richard J. Hathaway. 2003. Convergence of alternating optimization. Neural, Parallel & Scientific Computations 11, 4 (2003), 351--368."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744204"}, {"title": "IMSS-E: An Intelligent Approach to Design of Adaptive Meta Search System for E Commerce Website Ranking", "authors": ["Dheeraj Malhotra\n,", "O. P. Rishi"], "publication": "AICTC '16: Proceedings of the International Conference on Advances in Information Communication Technology & Computing", "abstract": "ABSTRACT\nWith the continuous increase in frequent E Commerce users, online businesses must have more customer friendly websites to better satisfy the personalized requirements of online customer and hence improve their market share over competition; Different customers have different purchase requirements at different intervals of time and hence new strategies are often required to be deployed by online retailers in order to identify the current purchase requirements of customer. In this research work, we propose design of a tool called Intelligent Meta Search System for E-commerce (IMSS-E), which can be used to blend benefits of Apriori based Map Reduce framework supported by Intelligent technologies like back propagation neural network and semantic web with B2C E-commerce to assist the online user to easily search and rank various E Commerce websites which can better satisfy his/her personalized online purchase requirement. An extensive experimental evaluation shows that IMSS-E can better satisfy the personalized search requirements of E Commerce users than conventional meta search engines.", "references": ["Verma, N., Malhotra, D., Malhotra, M. and Singh, J. 2015. E-commerce website ranking using semantic web mining and neural computing. In Proceedings of International Conference on Advanced Computing Technologies and Applications (Mumbai, India, March 26-27, 2015). Procedia Computer Science, Science Direct. Elsevier, Vol. 45, 42--51. DOI = 10.1016/j.procs.2015.03.080", "Sugiyama, K. Hatano, K. and Yoshikawa, M. 2004. Adaptive Web Search Based on User Profile Constructed without any Effort from Users. In Proceedings of the 13th international conference on World Wide Web (New York, USA, May 17-22, 2004), ACM, 675--684. DOI= 10.1145/988672.988764", "Kuppusamy, K.S. and Aghila, G. 2014. CaSePer: An Efficient Model for Personalized Web Page Change Detection Based on Segmentation. Journal of King Saud University, Vol.26 (January 2014), Elsevier, 19--27. DOI = 10.1016/j.jksuci.2013.02.001"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2979779.2979782"}, {"title": "Pooling Objects for Recognizing Scenes without Examples", "authors": ["Svetlana Kordumova\n,", "Thomas Mensink\n,", "Cees G.M. Snoek"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper we aim to recognize scenes in images without using any scene images as training data. Different from attribute based approaches, we do not carefully select the training classes to match the unseen scene classes. Instead, we propose a pooling over ten thousand of off-the-shelf object classifiers. To steer the knowledge transfer between objects and scenes we learn a semantic embedding with the aid of a large social multimedia corpus. Our key contributions are: we are the first to investigate pooling over ten thousand object classifiers to recognize scenes without examples; we explore the ontological hierarchy of objects and analyze the influence of object classifiers from different hierarchy levels; we exploit object positions in scene images and we demonstrate new scene retrieval scenarios with complex queries. Finally, we outperform attribute representations on two challenging scene datasets, SUNAttributes and Places2.", "references": ["http://places2.csail.mit.edu/results2015.html.", "B. Alexe, T. Deselaers, and V. Ferrari. Measuring the objectness of image windows. PAMI, 34(11):2189--2202, 2012.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In MM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912007"}, {"title": "An Unsupervised Approach to Anomaly Detection in Music Datasets", "authors": ["Yen-Cheng Lu\n,", "Chih-Wei Wu\n,", "Chang-Tien Lu\n,", "Alexander Lerch"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper presents an unsupervised method for systematically identifying anomalies in music datasets. The model integrates categorical regression and robust estimation techniques to infer anomalous scores in music clips. When applied to a music genre recognition dataset, the new method is able to detect corrupted, distorted, or mislabeled audio samples based on commonly used features in music information retrieval. The evaluation results show that the algorithm outperforms other anomaly detection methods and is capable of finding problematic samples identified by human experts. The proposed method introduces a preliminary framework for anomaly detection in music data that can serve as a useful tool to improve data integrity in the future.", "references": ["C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). 2006.", "M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. Lof: identifying density-based local outliers. SIGMOD Record, 29(2):93--104, May 2000.", "V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. ACM Computer Survey, 41(3):15:1--15:58, July 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914700"}, {"title": "Performance evaluation measures for toponym resolution", "authors": ["Morteza Karimzadeh"], "publication": "GIR '16: Proceedings of the 10th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we point out to the shortcomings of precision and recall in evaluating the performance of geoparsing algorithms. We propose separate processes for evaluating toponym recognition and toponym resolution stages, and also propose new metrics that quantify the performance of toponym resolution.", "references": ["Gelernter, J. and Balaji, S. 2013. An algorithm for local geoparsing of microtext. GeoInformatica. 17, 4 (2013), 635--667.", "Leidner, J.L. 2007. Toponym resolution in text. (2007).", "Resnik, P. and Yarowsky, D. 1999. Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation. Nat. Lang. Eng. 5, 2 (Jun. 1999), 113--133."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003464.3003472"}, {"title": "Gray Sheep, Influential Users, User Modeling and Recommender System Adoption by Startups", "authors": ["Abhishek Srivastava"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis proposed thesis work explores two research areas in the domain of Recommender Systems [RS] , algorithms and their real world applications. First is related to identification of Gray Sheep [GS] users and Influential Users [IU] in any system using different personality models and also creating psychographic profile of such users. The second part of this work is an empirical study to find out the determinant of RS adoption in Start-ups context of developing nations, by using diffusion of innovation (DOI) theory and Technology-Organization-Environment (TOE) frameworks.", "references": ["M. Claypool, T. Miranda, A. Gokhale, P. Murnikov, D. Netes, and M. Sartin, \"Combining content-based and collaborative filters in an online newspaper,\" Proceedings of Recommender Systems Workshop at ACM SIGIR, pp. 40--48, 1999.", "M. A. Ghazanfar and A. Prügel-Bennett, \"Leveraging clustering approaches to solve the gray-sheep users problem in recommender systems,\" Expert Systems with Applications, vol. 41, no. 7, pp. 3261--3272, 2014.", "R. Burke, \"Hybrid recommender systems: Survey and experiments,\" User modeling and user-adapted interaction, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959103"}, {"title": "Smart City and Smart Government: Synonymous or Complementary?", "authors": ["Leonidas G. Anthopoulos\n,", "Christopher G. Reddick"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nSmart City is an emerging and multidisciplinary domain. It has been recently defined as innovation, not necessarily but mainly through information and communications technologies (ICT), which enhance urban life in terms of people, living, economy, mobility and governance. Smart government is also an emerging topic, which attracts increasing attention from scholars who work in public administration, political and information sciences. There is no widely accepted definition for smart government, but it appears to be the next step of e-government with the use of technology and innovation by governments for better performance. However, it is not clear whether these two terms co-exist or concern different domains. The aim of this paper is to investigate the term smart government and to clarify its meaning in relationship to the smart city. In this respect this paper performed a comprehensive literature review analysis and concluded that smart government is shown not to be synonymous with smart city. Our findings show that smart city has a dimension of smart government, and smart government uses smart city as an area of practice. The authors conclude that smart city is complimentary, part of larger smart government movement.", "references": ["Anthopoulos, L. 2015. Defining Smart City Architecture for Sustainability. In Tampouris, E. et al. (Eds) Proceedings of 14th Electronic Government and 7th Electronic Participation Conference (IFIP2015) (Thessaloniki, Greece, August 30-September 2, 2015), IOS Press, Amsterdam, 140--147. DOI= 10.3233/978--1--61499--570--8--140", "Rogers, E.M. 1996. Diffusion of Innovations. The Free Press, New York.", "Anthopoulos, L. and Reddick, Ch. 2015. Understanding electronic government research and smart city. Information Polity, Special Issue on \"Smartness in Governance, Government, Urban Spaces, and the Internet of Things?, 1, 1--19. DOI: 10.3233/IP-150371"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888615"}, {"title": "Biases in Automated Music Playlist Generation: A Comparison of Next-Track Recommending Techniques", "authors": ["Dietmar Jannach\n,", "Iman Kamehkhosh\n,", "Geoffray Bonnin"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nPlaylist generation is a special form of music recommendation where the problem is to create a sequence of tracks to be played next, given a number of seed tracks. In academia, the evaluation of playlisting techniques is often done by assessing with the help of information retrieval measures if an algorithm is capable of selecting those tracks that also a human would pick next. Such approaches however cannot capture other factors, e.g., the homogeneity of the tracks that can determine the quality perception of playlists. In this work, we report the results of a multi-metric comparison of different academic approaches and a commercial playlisting service. Our results show that all tested techniques generate playlists with certain biases, e.g., towards very popular tracks, and often create playlists continuations that are quite different from those that are created by real users.", "references": ["P. Adamopoulos and A. Tuzhilin. On Over-specialization and Concentration Bias of Recommendations:Probabilistic Neighborhood Selection in Collaborative Filtering Systems. In Proc. RecSys '14, pages 153--160, 2014.", "A. Andric and G. Haus. Automatic Playlist Generation based on Tracking User's ListeningHabits. Multimedia Tools and Applications, 29(2):127--151, 2006.", "J.-J. Aucouturier and F. Pachet. Scaling Up Music Playlist Generation. In Proc. ICME, volume 1, pages 105--108, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930283"}, {"title": "Selecting home appliances with smart glass based on contextual information", "authors": ["Quan Kong\n,", "Takuya Maekawa\n,", "Taiki Miyanishi\n,", "Takayuki Suyama"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nWe propose a method for selecting home appliances using a smart glass, which facilitates the control of network-connected appliances in a smart house. Our proposed method is image-based appliance selection and enables smart glass users to easily select a particular appliance by just looking at it. The main feature of our method is that it achieves high precision appliance selection using user contextual information such as position and activity, inferred from various sensor data in addition to camera images captured by the glass because such contextual information is greatly related in the home appliance that a user wants to control in her daily life. We design a state-of-the-art appliance selection method by fusing image features extracted by deep learning techniques and context information estimated by non-parametric Bayesian techniques within a framework of multiple kernel learning. Our experimental results, which use sensor data obtained in an actual house equipped with many network-connected appliances, show the effectiveness of our method.", "references": ["Ling Bao and Stephen S Intille. 2004. Activity recognition from user-annotated acceleration data. In Pervasive 2004. 1--17.", "Martin Berchtold, Matthias Budde, Dawud Gordon, Hedda Rahel Schmidtke, and Michael Beigl. 2010. ActiServ: Activity recognition service for mobile phones. In International Symposium on Wearable Computers (ISWC 2010). 1--8.", "Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology 2 (2011), 27:1--27:27. Issue 3."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971651"}, {"title": "Upcoming SIGWEB supported conferences", "authors": ["Hamman Samuel"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nThe Special Interest Group on Hypertext and the Web, SIGWEB was created in 1989 to support the community participating in the annual ACM Hypertext Conference. Now in its third decade, SIGWEB has grown considerably and now sponsors seven annual conferences of different size and covering a wide range of topics. SIGWEB supports several specialized conferences, short courses, and workshops, as well as the Annual Hypertext Conference. SIGWEB sponsored conferences focus on timely topics in applied and computational hypertext and Web disciplines and provide a place for members and the entire applied Hypermedia and Web community to exchange ideas and to meet with and expand their network of colleagues. In this article, we provide a brief overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SEGWEB. overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SIGWEB.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996442.2996449"}, {"title": "Frustratingly Easy Cross-Modal Hashing", "authors": ["Dekui Ma\n,", "Jian Liang\n,", "Xiangwei Kong\n,", "Ran He"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nCross-modal hashing has attracted considerable attention due to its low storage cost and fast retrieval speed. Recently, more and more sophisticated researches related to this topic are proposed. However, they seem to be inefficient computationally for several reasons. On one hand, learning coupled hash projections makes the iterative optimization problem challenging. On the other hand, individual collective binary codes for each content are also learned with a high computation complexity. In this paper we describe a simple yet effective cross-modal hashing approach that can be implemented in just three lines of code. This approach first obtains the binary codes for one modality via unimodal hashing methods (e.g., iterative quantization (ITQ)), then applies simple linear regression to project the other modalities into the obtained binary subspace. Obviously, it is non-iterative and parameter-free, which makes it more attractive for many real-world applications. We further compare our approach with other state-of-the-art methods on four benchmark datasets (i.e., the Wiki, VOC, LabelMe and NUS-WIDE datasets). Despite its extraordinary simplicity, our approach performs remarkably and generally well for these datasets under different experimental settings (i.e., large-scale, high-dimensional and multi-label datasets).", "references": ["M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In Proc. CVPR, pages 3594--3601, 2010.", "J. Costa Pereira, E. Coviello, G. Doyle, N. Rasiwasia, G. R. Lanckriet, R. Levy, and N. Vasconcelos. On the role of correlation and abstraction in cross-modal multimedia retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(3):521--535, 2014.", "G. Ding, Y. Guo, and J. Zhou. Collective matrix factorization hashing for multimodal data. In Proc. CVPR, pages 2083--2090, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967218"}, {"title": "Centroid Terms as Text Representatives", "authors": ["Mario M. Kubek\n,", "Herwig Unger"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nAlgorithms to topically cluster and classify texts rely on information about their semantic distances and similarities. Standard methods based on the bag-of-words model to determine this information return only rough estimations regarding the relatedness of texts. Moreover, they are per se unable to find generalising terms or abstractions describing the textual contents. A new method to determine centroid terms in texts and to evaluate their similarity using those representing terms will be introduced. In first experiments, its results and advantages will be discussed.", "references": ["J. Hawkins and S. Blakeslee. On Intelligence. Times Books, New York, NY, USA, 2004.", "R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "L. R. Dice. Measures of the amount of ecologic association between species. Ecology, 26(3):297--302, July 1945."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967150"}, {"title": "A Comparison of Primary and Secondary Relevance Judgements for Real-Life Topics", "authors": ["Simon Wakeling\n,", "Martin Halvey\n,", "Robert Villa\n,", "Laura Hasler"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThe notion of relevance is fundamental to the field of Information Retrieval. Within the field a generally accepted conception of relevance as inherently subjective has emerged, with an individual's assessment of relevance influenced by numerous contextual factors. In this paper we present a user study that examines in detail the differences between primary and secondary assessors on a set of \"real-world\" topics which were gathered specifically for the work. By gathering topics which are representative of the staff and students at a major university, at a particular point in time, we aim to explore differences between primary and secondary relevance judgements for real-life search tasks. Findings suggest that while secondary assessors may find the assessment task challenging in various ways (they generally possess less interest and knowledge in secondary topics and take longer to assess documents), agreement between primary and secondary assessors is high.", "references": ["Agosti, M., Fuhr, N., Toms, E., and Vakkari, P. 2014. Evaluation methodologies in information retrieval (Dagstuhl Seminar 13441). SIGIR Forum 48, 1, 36--41.", "Al-Harbi, A.L. and Smucker, M.D. 2014. A qualitative exploration of secondary assessor relevance judging behavior. In Proceedings of the 5th Information Interaction in Context Symposium (IIiX '14). ACM, New York, NY, USA, 195--204.", "Alonso, O. and Mizzaro, S. 2012. Using crowdsourcing for TREC relevance assessment. Inform. Process. Manag. 48, 6, 1053--1066."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854968"}, {"title": "Learning to Respond with Deep Neural Networks for Retrieval-Based Human-Computer Conversation System", "authors": ["Rui Yan\n,", "Yiping Song\n,", "Hua Wu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTo establish an automatic conversation system between humans and computers is regarded as one of the most hardcore problems in computer science, which involves interdisciplinary techniques in information retrieval, natural language processing, artificial intelligence, etc. The challenges lie in how to respond so as to maintain a relevant and continuous conversation with humans. Along with the prosperity of Web 2.0, we are now able to collect extremely massive conversational data, which are publicly available. It casts a great opportunity to launch automatic conversation systems. Owing to the diversity of Web resources, a retrieval-based conversation system will be able to find at least some responses from the massive repository for any user inputs. Given a human issued message, i.e., query, our system would provide a reply after adequate training and learning of how to respond. In this paper, we propose a retrieval-based conversation system with the deep learning-to-respond schema through a deep neural network framework driven by web data. The proposed model is general and unified for different conversation scenarios in open domain. We incorporate the impact of multiple data inputs, and formulate various features and factors with optimization into the deep learning framework. In the experiments, we investigate the effectiveness of the proposed deep neural network structures with better combinations of all different evidence. We demonstrate significant performance improvement against a series of standard and state-of-art baselines in terms of p@1, MAP, nDCG, and MRR for conversational purposes.", "references": ["Y. Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning, 2(1):1--127, 2009.", "F. Bessho, T. Harada, and Y. Kuniyoshi. Dialog system using real-time crowdsourcing and Twitter large-scale corpus. In SIGDIAL, pages 227--231, 2012.", "G. Cong, L. Wang, C.-Y. Lin, Y.-I. Song, and Y. Sun. Finding question-answer pairs from online forums. In SIGIR, pages 467--474."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911542"}, {"title": "Diversity-oriented Multimodal and Interactive Information Retrieval", "authors": ["Rodrigo Tripodi Calumby"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nInformation retrieval methods, especially considering multimedia data, have evolved towards the integration of multiple sources of evidence in the analysis of the relevance of the items considering a given user search task. In this context, for attenuating the semantic gap between low-level features extracted from the content of the digital objects and high-level semantic concepts (objects, categories, etc.) and making the systems adaptive to different user needs, interactive models have brought the user closer to the retrieval loop allowing user-system interaction mainly through implicit or explicit relevance feedback. Analogously, diversity promotion has emerged as an alternative for tackling ambiguous or underspecified queries. Additionally, several works have addressed the issue of minimizing the required user effort on providing relevance assessments while keeping an acceptable overall effectiveness\nThis thesis discusses, proposes, and experimentally analyzes multimodal and interactive diversity-oriented information retrieval methods. This work, comprehensively covers the interactive information retrieval literature and also discusses about recent advances, the great research challenges, and promising research opportunities. We have proposed and evaluated two relevancediversity trade-off enhancement work-flows, which integrate multiple information from images, such as: visual features, textual metadata, geographic information, and user credibility descriptors. In turn, as an integration of interactive retrieval and diversity promotion techniques, for maximizing the coverage of multiple query interpretations/aspects and speeding up the information transfer between the user and the system, we have proposed and evaluated a multimodal online learning-to-rank method trained with relevance feedback over diversified results\nOur experimental analysis shows that the joint usage of multiple information sources positively impacted the relevance-diversity balancing algorithms. Our results also suggest that the integration of multimodal-relevance-based filtering and reranking is effective on improving result relevance and also boosts diversity promotion methods. Beyond it, with a thorough experimental analysis we have investigated several research questions related to the possibility of improving result diversity and keeping or even improving relevance in interactive search sessions. Moreover, we analyze how much the diversification effort affects overall search session results and how different diversification approaches behave for the different data modalities. By analyzing the overall and per feedback iteration effectiveness, we show that introducing diversity may harm initial results whereas it significantly enhances the overall session effectiveness not only considering the relevance and diversity, but also how early the user is exposed to the same amount of relevant items and diversity", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964811"}, {"title": "Temporal Information Retrieval", "authors": ["Nattiya Kanhabua\n,", "Avishek Anand"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe study of temporal dynamics and its impact can be framed within the so-called temporal IR approaches, which explain how user behavior, document content and scale vary with time, and how we can use them in our favor in order to improve retrieval effectiveness.\nThis half-day tutorial will outline research issues with respect to temporal dynamics, and provide a comprehensive overview of temporal IR approaches, essentially regarding processing dynamic content, temporal information extraction, temporal query analysis, and time-aware retrieval and ranking. The tutorial is structured into two sessions. During the first session, we will explain the general and wide aspects associated to temporal dynamics by focusing on the web domain, from content and structural changes to variations of user behavior and interactions. We will begin with temporal indexing and query processing. Next step, we will explain current approaches to time-aware retrieval and ranking, which can be classified into different types based on two main notions of relevance with respect to time, namely, recency-based ranking, and time-dependent ranking.\nIn the latter session, we will describe research issues centered on determining the temporal intent of queries, and time-aware query enhancement, e.g., temporal relevance feedback, and time-aware query reformulation. In addition, we present applications in related research areas, e.g., exploration, summarization, and clustering of search results, as well as future event retrieval and prediction. To this end, we conclude our tutorial and outline future directions.\nThis tutorial targets graduate students, researchers and practitioners in the field of information retrieval. The goal is to provide an overview as well as an important context that enables further research on and practical applications within this area.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '98, pages 37--45, 1998.", "O. Alonso, M. Gertz, and R. A. Baeza-Yates. Clustering and exploring search results using timeline constructions. In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM '09, pages 97--106, 2009.", "O. Alonso, J. Strötgen, R. A. Baeza-Yates, and M. Gertz. Temporal information retrieval: Challenges and opportunities. In Proceedings of the 1st International Temporal Web Analytics Workshop (TWAW 2011), 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914805"}, {"title": "Volunteerism Tendency Prediction via Harvesting Multiple Social Networks", "authors": ["Xuemeng Song\n,", "Zhao-Yan Ming\n,", "Liqiang Nie\n,", "Yi-Liang Zhao\n,", "Tat-Seng Chua"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nVolunteers have always been extremely crucial and in urgent need for nonprofit organizations (NPOs) to sustain their continuing operations. However, it is expensive and time-consuming to recruit volunteers using traditional approaches. In the Web 2.0 era, abundant and ubiquitous social media data opens a door to the possibility of automatic volunteer identification. In this article, we aim to fully explore this possibility by proposing a scheme that is able to predict users’ volunteerism tendency from user-generated contents collected from multiple social networks based on a conceptual volunteering decision model. We conducted comprehensive experiments to investigate the effectiveness of our proposed scheme and further discussed its generalizibility and extendability. This novel interdisciplinary research will potentially inspire more promising and important human-centered applications.", "references": ["Fabian Abel, Eelco Herder, Geert-Jan Houben, Nicola Henze, and Daniel Krause. 2013. Cross-system user modeling and personalization on the social web. User Modeling and User-Adapted Interaction 23, 2--3 (2013), 169--209.", "Sibel Adali and Jennifer Golbeck. 2012. Predicting personality with social behavior. In Proceedings of the International Conference on Advances in Social Networks Analysis and Mining. IEEE Computer Society, 302--309.", "Shuotian Bai, Tingshao Zhu, and Li Cheng. 2012. Big-five personality prediction based on user behaviors at social network sites. arXiv:1204.4809 (2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832907"}, {"title": "Learning to Re-Rank Questions in Community Question Answering Using Advanced Features", "authors": ["Giovanni Da San Martino\n,", "Alberto Barrón Cedeño\n,", "Salvatore Romeo\n,", "Antonio Uva\n,", "Alessandro Moschitti"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study the impact of different types of features for question ranking in community Question Answering: bag-of-words models (BoW), syntactic tree kernels (TKs) and rank features. It should be noted that structural kernels have never been applied to the question reranking task, i.e., question to question similarity, where they have to model paraphrase relations. Additionally, the informal text, typically present in forums, poses new challenges to the use of TKs. We compare our learning to rank (L2R) algorithms against a strong baseline given by the Google rank (GR). The results show that (i) our shallow structures used in TKs are robust enough to noisy data and (ii) improving GR requires effective BoW features and TKs along with an accurate model of GR features in the used L2R algorithm.", "references": ["L. Allison and T. Dix. A bit-string longest-common-subsequence algorithm. Inf. Process. Lett., 23(6):305--310, Dec. 1986.", "A. Barrón-Cedeno, G. Da San Martino, S. Joty, A. Moschitti, F. Al-Obaidli, S. Romeo, K. Tymoshenko, and A. Uva. ConvKN at SemEval-2016 Task 3: Answer and question selection for question answering on arabic and english fora. In Proceedings of SemEval '16, pages 896--903, San Diego, California, June 2016. ACL.", "beginflushleftX. Cao, G. Cong, B. Cui, C. S. Jensen, and C. Zhang. The use of categorization information in language models for question retrieval. In CIKM, pages 265--274, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983893"}, {"title": "BLAST: a loosely schema-aware meta-blocking approach for entity resolution", "authors": ["Giovanni Simonini\n,", "Sonia Bergamaschi\n,", "H. V. Jagadish"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIdentifying records that refer to the same entity is a fundamental step for data integration. Since it is prohibitively expensive to compare every pair of records, blocking techniques are typically employed to reduce the complexity of this task. These techniques partition records into blocks and limit the comparison to records co-occurring in a block. Generally, to deal with highly heterogeneous and noisy data (e.g. semi-structured data of the Web), these techniques rely on redundancy to reduce the chance of missing matches.\nMeta-blocking is the task of restructuring blocks generated by redundancy-based blocking techniques, removing superfluous comparisons. Existing meta-blocking approaches rely exclusively on schema-agnostic features.\nIn this paper, we demonstrate how \"loose\" schema information (i.e., statistics collected directly from the data) can be exploited to enhance the quality of the blocks in a holistic loosely schema-aware (meta-)blocking approach that can be used to speed up your favorite Entity Resolution algorithm. We call it Blast (Blocking with Loosely-Aware Schema Techniques). We show how Blast can automatically extract this loose information by adopting a LSH-based step for efficiently scaling to large datasets. We experimentally demonstrate, on real-world datasets, how Blast outperforms the state-of-the-art unsupervised meta-blocking approaches, and, in many cases, also the supervised one.", "references": ["A. Agresti and M. Kateri. Categorical data analysis. In International Encyclopedia of Statistical Science, pages 206--208. 2011.", "S. Bergamaschi, D. Ferrari, F. Guerra, G. Simonini, and Y. Velegrakis. Providing insight into data source topics. Journal on Data Semantics, pages 1--18, 2016.", "C. Bizer, T. Heath, and T. Berners-Lee. Linked data-the story so far. Semantic Services, Interoperability and Web Applications: Emerging Concepts, 5(3):1--22, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2994509.2994533"}, {"title": "A Spatial-Temporal Topic Model for the Semantic Annotation of POIs in LBSNs", "authors": ["Tieke He\n,", "Hongzhi Yin\n,", "Zhenyu Chen\n,", "Xiaofang Zhou\n,", "Shazia Sadiq\n,", "Bin Luo"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nSemantic tags of points of interest (POIs) are a crucial prerequisite for location search, recommendation services, and data cleaning. However, most POIs in location-based social networks (LBSNs) are either tag-missing or tag-incomplete. This article aims to develop semantic annotation techniques to automatically infer tags for POIs. We first analyze two LBSN datasets and observe that there are two types of tags, category-related ones and sentimental ones, which have unique characteristics. Category-related tags are hierarchical, whereas sentimental ones are category-aware. All existing related work has adopted classification methods to predict high-level category-related tags in the hierarchy, but they cannot apply to infer either low-level category tags or sentimental ones.\nIn light of this, we propose a latent-class probabilistic generative model, namely the spatial-temporal topic model (STM), to infer personal interests, the temporal and spatial patterns of topics/semantics embedded in users’ check-in activities, the interdependence between category-topic and sentiment-topic, and the correlation between sentimental tags and rating scores from users’ check-in and rating behaviors. Then, this learned knowledge is utilized to automatically annotate all POIs with both category-related and sentimental tags in a unified way. We conduct extensive experiments to evaluate the performance of the proposed STM on a real large-scale dataset. The experimental results show the superiority of our proposed STM, and we also observe that the real challenge of inferring category-related tags for POIs lies in the low-level ones of the hierarchy and that the challenge of predicting sentimental tags are those with neutral ratings.", "references": ["Bruno Antunes, Ana Alves, and Francisco C. Pereira. 2008. Semantics of place: Ontology enrichment. In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI’08). 342--351.", "Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999. Modern Information Retrieval. Vol. 463. Addison Wesley Longman, Boston, MA.", "Grigory Begelman, Philipp Keller, and Frank Smadja. 2006. Automated tag clustering: Improving search and exploration in the tag space. In Proceedings of the Collaborative Web Tagging Workshop at WWW 2006. 15--33."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905373"}, {"title": "Explaining Sentiment Spikes in Twitter", "authors": ["Anastasia Giachanou\n,", "Ida Mele\n,", "Fabio Crestani"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTracking public opinion in social media provides important information to enterprises or governments during a decision making process. In addition, identifying and extracting the causes of sentiment spikes allows interested parties to redesign and adjust strategies with the aim to attract more positive sentiments. In this paper, we focus on the problem of tracking sentiment towards different entities, detecting sentiment spikes and on the problem of extracting and ranking the causes of a sentiment spike. Our approach combines LDA topic model with Relative Entropy. The former is used for extracting the topics discussed in the time window before the sentiment spike. The latter allows to rank the detected topics based on their contribution to the sentiment spike.", "references": ["X. An, R. A. Ganguly, Y. Fang, B. S. Scyphers, M. A. Hunter, and G. J. Dy. Tracking Climate Change Opinions from Twitter Data. In KDD'14: Workshop on Data Science for Social Good, 2014.", "K. Balog, G. Mishne, and M. de Rijke. Why are they excited?: Identifying and explaining spikes in blog mood levels. In EACL '06: Posters Demonstrations, pages 207--210, 2006.", "D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983678"}, {"title": "Recurrent Support Vector Machines for Audio-Based Multimedia Event Detection", "authors": ["Yun Wang\n,", "Florian Metze"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nMultimedia event detection (MED) is the task of detecting given events (e.g. parade, birthday party) in a large collection of video clips. While the most useful information comes from visual features and speech recognition, a lot can also be inferred from the non-speech audio content, either alone or in conjunction with visual and speech cues. This paper studies MED with non-speech audio information only. MED is usually performed in two stages. The first stage generates a representation for each clip in the form of either a single vector or a sequence of vectors, often by aggregating frame-level features; the second stage performs binary or multi-class classification to decide whether each target event occurs in each clip. Common classifiers used for the second stage include support vector machines (SVMs), feed-forward deep neural networks (DNNs), and recurrent neural networks (RNNs).\nIn this paper, we propose to classify clips for events using \"recurrent SVMs\". These models combine the kernel mapping and the large-margin optimization criterion of SVMs, and the ability to process sequences of variable lengths of RNNs. Reinforced with data augmentation, recurrent SVMs have achieved higher mean average precision (MAP) on the TRECVID 2011 MED task than both SVMs and RNNs.", "references": ["W. M. Campbell, D. E. Sturim, and D. A. Reynolds. Support vector machines using GMM supervectors for speaker verification. Signal Processing Letters, IEEE, 13(5):308--311, 2006.", "Q. Jin, P. F. Schulam, S. Rawat, S. Burger, D. Ding, and F. Metze. Event-based video retrieval using audio. In Proceedings of INTERSPEECH, page 2085, 2012.", "N. Dehak, P. Kenny, R. Dehak, P. Dumouchel, and P. Ouellet. Front-end factor analysis for speaker verification. Audio, Speech, and Language Processing, IEEE Transactions on, 19(4):788--798, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912048"}, {"title": "The CloudMdsQL Multistore System", "authors": ["Boyan Kolev\n,", "Carlyna Bondiombouy\n,", "Patrick Valduriez\n,", "Ricardo Jimenez-Peris\n,", "Raquel Pau\n,", "José Pereira"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nThe blooming of different cloud data management infrastructures has turned multistore systems to a major topic in the nowadays cloud landscape. In this demonstration, we present a Cloud Multidatastore Query Language (CloudMdsQL), and its query engine. CloudMdsQL is a functional SQL-like language, capable of querying multiple heterogeneous data stores (relational and NoSQL) within a single query that may contain embedded invocations to each data store's native query interface. The major innovation is that a CloudMdsQL query can exploit the full power of local data stores, by simply allowing some local data store native queries (e.g. a breadth-first search query against a graph database) to be called as functions, and at the same time be optimized. Within our demonstration, we focus on two use cases each involving four diverse data stores (graph, document, relational, and key-value) with its corresponding CloudMdsQL queries. The query execution flows are visualized by an embedded real-time monitoring subsystem. The users can also try out different ad-hoc queries, not necessarily in the context of the use cases.", "references": ["Bondiombouy, C., Kolev, B., Levchenko, O., Valduriez, P. 2015. Integrating Big Data and Relational Data with a Functional SQL-like Query Language. DEXA, 170--185.", "DeWitt, D., Halverson, A., Nehme, R., Shankar, S., Aguilar-Saborit J., Avanes, A., Flasza, M., Gramling, J. 2013. Split Query Processing in Polybase. In ACM SIGMOD (2013), 1255--1266.", "Duggan, J., Elmore, A. J., Stonebraker, M., Balazinska, M., Howe, B., Kepner, J., Madden, S., Maier, D., Mattson, T., Zdonik, S. 2015. The BigDAWG Polystore System. SIGMOD Rec. 44, 2 (August 2015), 11--16. DOI=http://dx.doi.org/10.1145/2814710.2814713"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2899400"}, {"title": "Using the Crowd to Improve Search Result Ranking and the Search Experience", "authors": ["Yubin Kim\n,", "Kevyn Collins-Thompson\n,", "Jaime Teevan"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nDespite technological advances, algorithmic search systems still have difficulty with complex or subtle information needs. For example, scenarios requiring deep semantic interpretation are a challenge for computers. People, on the other hand, are well suited to solving such problems. As a result, there is an opportunity for humans and computers to collaborate during the course of a search in a way that takes advantage of the unique abilities of each. While search tools that rely on human intervention will never be able to respond as quickly as current search engines do, recent research suggests that there are scenarios where a search engine could take more time if it resulted in a much better experience. This article explores how crowdsourcing can be used at query time to augment key stages of the search pipeline. We first explore the use of crowdsourcing to improve search result ranking. When the crowd is used to replace or augment traditional retrieval components such as query expansion and relevance scoring, we find that we can increase robustness against failure for query expansion and improve overall precision for results filtering. However, the gains that we observe are limited and unlikely to make up for the extra cost and time that the crowd requires. We then explore ways to incorporate the crowd into the search process that more drastically alter the overall experience. We find that using crowd workers to support rich query understanding and result processing appears to be a more worthwhile way to make use of the crowd during search. Our results confirm that crowdsourcing can positively impact the search experience but suggest that significant changes to the search process may be required for crowdsourcing to fulfill its potential in search systems.", "references": ["Omar Alonso, Daniel E. Rose, and Benjamin Stewart. 2008. Crowdsourcing for relevance evaluation. In ACM SIGIR Forum, Vol. 42. 9.", "Michael Bendersky and W. Bruce Croft. 2008. Discovering key concepts in verbose queries. In Proc. SIGIR. ACM, New York, NY, 491--498.", "Michael Bendersky and W. Bruce Croft. 2009. Analysis of long queries in a large scale search log. In Proc. WSCD. ACM, New York, NY, 8--14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897368"}, {"title": "Wandertroper: supporting aesthetic engagement with everyday surroundings through soundscape augmentation", "authors": ["Beatrice Monastero\n,", "David McGookin\n,", "Giuseppe Torre"], "publication": "MUM '16: Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia", "abstract": "ABSTRACT\nIn this paper we present the design and evaluation of Wandertroper, a mobile system designed to support reengagement with everyday surroundings during daily walks. Wandertroper generates real-time sound based on the spectromorphology of the inhabited soundscape, which is manipulated by how the user walks. Through an iterative participatory design process using semi-structured group discussions and 'in-the-wild' evaluations, we outline how design aspects, such as the degree of output abstraction and aesthetic personalisation of use, facilitated users' engagement with everyday surroundings. We discuss how Wandertroper turned daily walks into personally-meaningful aesthetic experiences.", "references": ["Mags Adams, Bruce Neil, William J. Davies, and Rebecca Cain. 2008. Soundwalking as a metholdology for understanding soundscapes. Proc. Institute of Acoustics Spring Conference. Retrieved from http://usir.salford.ac.uk/2461/1/Adams_etal_2008_Soundwalking_as_Methodology.pdf", "Gabriela Avram. 2014. Turning Spaces into Places. Weaving the Digital Double. NordiCHI '14, ACM, 26--30. Retrieved from http://futurecities.up.pt/site/wp-content/uploads/Turning-Spaces-into-Places-%E2%80%93Weaving-the-Digital-Double.pdf", "Liam Bannon. 2011. Reimagining HCI: toward a more human-centered perspective. Interactions 18, 4: 50--57. http://doi.org/10.1145/1978822.1978833"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012709.3012725"}, {"title": "APIBook: an effective approach for finding APIs", "authors": ["Haibo Yu\n,", "Wenhao Song\n,", "Tsunenori Mine"], "publication": "Internetware '16: Proceedings of the 8th Asia-Pacific Symposium on Internetware", "abstract": "ABSTRACT\nSoftware libraries have become more and more complex in recent years. Developers usually have to rely on search engines to find API documents and then select suitable APIs to do relevant development when working on unfamiliar functions. However, the traditional search engines do not focus on searching APIs that make this process inconvenient and time consuming. Although a lot of efforts have been made on API understanding and code search in industry and academia, work and tools that can recommend API methods to users based on their description of API's functionality are still very limited.\nIn this paper, we propose a search-based recommendation algorithm on API methods. We call the algorithm APIBook and implement an API method recommendation tool based on the proposed algorithm. The algorithm can recommend relevant API methods to users based on user input written in natural language. This algorithm combines semantic relevance, type relevance and the extent of degree that API method is used to sort these API methods and rank those that are highly relevant and widely used in the top positions. Examples of codes in real projects are also provided to help users to learn and to understand the API method recommended. The API recommendation tool selects the Java Standard Library as well as 100 popular open source libraries as API recommending material. Users can input the API description via the Web interface, and view the search results with sample codes on screen.\nThe evaluation experiment is performed and the result shows that APIBook is more effective for finding APIs than traditional search models and it takes on average 0.7 seconds for finding relevant API methods which we think to be reasonable for satisfying daily query requirements.", "references": ["Victor R. Basili, Lionel C. Briand and, Walcélio L. Melo. How Reuse Influences Productivity in Object-oriented Systems. Communications of the ACM, 1996, 39(10), 104--116. DOI=10.1145/236156.236184.", "William B. Frakes, Kyo Kang. Software reuse research: Status and future. IEEE transactions on Software Engineering. 2005(7):529--536. DOI=10.1109/TSE.2005.85", "Stefan Haefliger, Georg von Krogh, Sebastian Spaeth. Code reuse in open source software. Management Science, 2008, 54(1):180--193. DOI=10.1287/mnsc.1070.0748."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993717.2993727"}, {"title": "The Past, the Present, and the Future", "authors": ["Sandra Carberry"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nUser modeling and adaptation had its inception as a field at a workshop in Maria Laach, Germany in 1986. Most of the work at that time focused on applications in natural language processing, such as adapting explanations to the user's level of expertise. Since then, the field has grown tremendously and new applications are arising each year. As appropriate for the 30th anniversary of the first workshop, this talk will discuss how the field has evolved, novel work that we are pursuing on applying user modeling and adaptation to information retrieval, insights into where the field is headed and the hottest topics for exploration, and some thoughts on the conflict between the benefits of user modeling and its intrusion on people's lives.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930807"}, {"title": "Past, Present, and Future of Recommender Systems: An Industry Perspective", "authors": ["Xavier Amatriain\n,", "Justin Basilico"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWhen the Netflix Prize launched in 2006, it put a spotlight on the importance and use of recommender systems in real-world applications. The competition provided many lessons, and many more have been learned since the Grand Prize was awarded in 2009. The use of recommender systems in industry has continued to grow driven by the availability of many kinds of user data and the continued interest for the area within the research community. In this paper, we will describe what we see as the past, present, and future of recommender systems from an industry perspective.", "references": ["A. Ahmed, C. Teo, S.V.N. Vishwanathan, and A. Smola. Fair and balanced: Learning to present news stories. WSDM '12.", "X. Amatriain, J. M. Pujol, and N. Oliver. I Like It... I Like It Not: Evaluating User Ratings Noise in Recommender Systems. In UMAP '09. 2009.", "R. M. Bell and Y. Koren. Lessons from the Netflix Prize Challenge. SIGKDD Explor. Newsl., 9(2), December 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959144"}, {"title": "Solving sybil attacks using evolutionary game theory", "authors": ["Farah Saab\n,", "Ayman Kayssi\n,", "Imad Elhajj\n,", "Ali Chehab"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nRecommender systems have become quite popular recently. However, such systems are vulnerable to several types of attacks that target user ratings. One such attack is the Sybil attack where an entity masquerades as several identities with the intention of diverting user ratings. In this work, we propose evolutionary game theory as a possible solution to the Sybil attack in recommender systems. After modeling the attack, we use replicator dynamics to solve for evolutionary stable strategies. Our results show that under certain conditions that are easily achievable by a system administrator, the probability of an attack strategy drops to zero implying degraded fitness for Sybil nodes that eventually die out.", "references": ["Amazon {Online}. Available: http://www.amazon.com/(2014).", "Cui, H., Wei, G., Huang, Q. and Yu, Y. A game theoretic approach for power allocation with QoS constraints in wireless multimedia sensor networks. Multimedia Tools Appl, 51, 3 (2011), 983--996.", "Douceur, J. R. The Sybil Attack. In Proceedings of 1st International Workshop on Peer-to-Peer Systems (IPTPS). (2002)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851848"}, {"title": "Text Stemming: Approaches, Applications, and Challenges", "authors": ["Jasmeet Singh\n,", "Vishal Gupta"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nStemming is a process in which the variant word forms are mapped to their base form. It is among the basic text pre-processing approaches used in Language Modeling, Natural Language Processing, and Information Retrieval applications. In this article, we present a comprehensive survey of text stemming techniques, evaluation mechanisms, and application domains. The main objective of this survey is to distill the main insights and present a detailed assessment of the current state of the art. The performance of some well-known rule-based and statistical stemming algorithms in different scenarios has been analyzed. In the end, we highlighted some open issues and challenges related to unsupervised statistical text stemming. This research work will help the researchers to select the most suitable text stemming technique in a specific application and will also serve as a guide to identify the areas that need attention from the research community.", "references": ["Giorgos Adam, Konstantinos Asimakis, Christos Bouras, and Vassilis Poulopoulos. 2010. An efficient mechanism for stemming and tagging: the case of Greek language. In Proceedings of the 14th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems. 389--397.", "Farag Ahmed and Andreas Nürnberger. 2009. Evaluation of n-gram conflation approaches for Arabic text retrieval. J. Am. Soc. Inf. Sci. Technol. 60, 7, 1448--1465.", "Mohammed Akour, Sameer Abufardeh, Kenneth Magel, and Qasem Al-Radaideh. 2011. QArabPro: A rule based question answering system for reading comprehension tests in Arabic. Am. J. Appl Sci. 8, 6, 652."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975608"}, {"title": "A new thread-aware birthmark for plagiarism detection of multithreaded programs", "authors": ["Zhenzhou Tian\n,", "Ting Liu\n,", "Qinghua Zheng\n,", "Feifei Tong\n,", "Ming Fan\n,", "Zijiang Yang"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering Companion", "abstract": "ABSTRACT\nDynamic birthmarking used to be an effective approach to detecting software plagiarism. Yet the new trend towards multithreaded programming renders existing algorithms almost useless, due to the fact that thread scheduling nondeterminism severely perturbs birthmark generation and comparison. In this paper, we design a birthmark based on thread-related system calls. Such a birthmark is less susceptible to thread scheduling. The empirical study conducted on an open benchmark shows that the new birthmark is superior to existing birthmarks and is resilient against most state-of-the-art obfuscation techniques.", "references": ["W. Zhou, Y. Zhou, X. Jiang, and P. Ning, \"Detecting repackaged smartphone applications in third-party android marketplaces,\" in Proceedings of the second ACM conference on Data and Application Security and Privacy. ACM, 2012, pp. 317--326.", "C. Collberg, G. Myles, and A. Huntwork, \"Sandmark-a tool for software protection research,\" IEEE Secur Priv, vol. 1, no. 4, pp. 40--49, 2003.", "\"Dasho java obfuscator, http://www.cs.arizona.edu/collberg/teaching/620/2008/assignments/tools/dasho/index.html,\" 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2889160.2892653"}, {"title": "A Probabilistic Ranking Model for Audio Stream Retrieval", "authors": ["YoungHoon Jung\n,", "Jaehwan Koo\n,", "Karl Stratos\n,", "Luca P. Carloni"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nIn Audio Stream Retrieval (ASR) systems, clients periodically query an audio database with an audio segment taken from the input audio stream to keep track of the flow of the stream in the original content sources or to compare two differently edited streams. We recently developed a series of ASR applications such as broadcast monitoring systems, automatic caption fetching systems, and automatic media edit tracking systems. Based on this experience, we propose a probabilistic ranking model designed for ASR systems. In order to train and test the model, we create a new set of audio streams and make it publicly available. Our experiments with these new streams confirm that the proposed ranking model works effectively with the retrieved results and reduces the errors when used in various ASR applications.", "references": ["Google Play Sound Search: goo.gl/ahpvyO.", "M. Bartsch and G. Wakefield. Audio thumbnailing of popular music using chroma-based representations. Trans. on Multimedia, 7(1):96--104, Feb. 2005.", "L. E. Baum and T. Petrie. Statistical inference for probabilistic functions of finite state markov chains. The Annals of Mathematical Statistics, 37(6):1554--1563, 12 1966."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2927006.2927013"}, {"title": "Profiling the Potential of Web Tables for Augmenting Cross-domain Knowledge Bases", "authors": ["Dominique Ritze\n,", "Oliver Lehmberg\n,", "Yaser Oulabi\n,", "Christian Bizer"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nCross-domain knowledge bases such as DBpedia, YAGO, or the Google Knowledge Graph have gained increasing attention over the last years and are starting to be deployed within various use cases. However, the content of such knowledge bases is far from being complete, far from always being correct, and suffers from deprecation (i.e. population numbers become outdated after some time). Hence, there are efforts to leverage various types of Web data to complement, update and extend such knowledge bases. A source of Web data that potentially provides a very wide coverage are millions of relational HTML tables that are found on the Web. The existing work on using data from Web tables to augment cross-domain knowledge bases reports only aggregated performance numbers. The actual content of the Web tables and the topical areas of the knowledge bases that can be complemented using the tables remain unclear. In this paper, we match a large, publicly available Web table corpus to the DBpedia knowledge base. Based on the matching results, we profile the potential of Web tables for augmenting different parts of cross-domain knowledge bases and report detailed statistics about classes, properties, and instances for which missing values can be filled using Web table data as evidence. In order to estimate the potential quality of the new values, we empirically examine the Local Closed World Assumption and use it to determine the maximal number of correct facts that an ideal data fusion strategy could generate. Using this as ground truth, we compare three data fusion strategies and conclude that knowledge-based trust outperforms PageRank- and voting-based fusion.", "references": ["S. Balakrishnan, A. Y. Halevy, and B. Harb. Applying WebTables in Practice. In Proc. of the 7th Biennial Conference on Innovative Data Systems Research, CIDR '15, 2015.", "J. Bleiholder and F. Naumann. Data fusion. ACM Comput. Surv., 41(1):1--41, 2009.", "K. Braunschweig, M. Thiele, J. Eberius, and W. Lehner. Column-specific Context Extraction for Web Tables. In Proc. of the 30th Annual ACM Symposium on Applied Computing, SAC '15, pages 1072--1077, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883017"}, {"title": "Influence of the Programming Environment on Programming Education", "authors": ["Daisuke Saito\n,", "Hironori Washizaki\n,", "Yoshiaki Fukazawa"], "publication": "ITiCSE '16: Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education", "abstract": "ABSTRACT\nAlthough both visual and text environments have been used to teach programming, the most appropriate method for beginners is unknown. Herein we research the most suitable programming environment to introduce programming to beginners using Minecraft to provide different programming learning environments (Visual or Text) via ComputerCraftEdu as an extended function. The learning effects between these two environments are compared using a lecture course. The results show that a visual environment is more suitable to introduce programming to beginners.", "references": ["Zorn, C., Wingrave, C. A., Charbonneau, E., & LaViola Jr, J. J, \"Exploring Minecraft as a conduit for increasing interest in programming\", The 8th International Conference on the Foundations of Digital Games, pp. 352--359, 2013", "Wilkinson, B., Williams, N., & Armstrong, P. Improving Student Understanding, Application and Synthesis of Computer Programming Concepts with Minecraft, The European Conference on Technology in the Classroom 2013"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899415.2925477"}, {"title": "Estimating Time Models for News Article Excerpts", "authors": ["Arunav Mishra\n,", "Klaus Berberich"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIt is often difficult to ground text to precise time intervals due to the inherent uncertainty arising from either missing or multiple expressions at year, month, and day time granularities. We address the problem of estimating an excerpt-time model capturing the temporal scope of a given news article excerpt as a probability distribution over chronons. For this, we propose a semi-supervised distribution propagation framework that leverages redundancy in the data to improve the quality of estimated time models. Our method generates an event graph with excerpts as nodes and models various inter-excerpt relations as edges. It then propagates empirical excerpt-time models estimated for temporally annotated excerpts, to those that are strongly related but miss annotations. In our experiments, we first generate a test query set by randomly sampling 100 Wikipedia events as queries. For each query, making use of a standard text retrieval model, we then obtain top-10 documents with an average of 150 excerpts. From these, each temporally annotated excerpt is considered as gold standard. The evaluation measures are first computed for each gold standard excerpt for a single query, by comparing the estimated model with our method to the empirical model from the original expressions. Final scores are reported by averaging over all the test queries. Experiments on the English Gigaword corpus show that our method estimates significantly better time models than several baselines taken from the literature.", "references": ["O. Alonso, J. Strötgen, R. A. Baeza-Yates, and M. Gertz. Temporal information retrieval: Challenges and opportunities. TWAW 2011.", "I. Arikan, S. Bedathur, and K. Berberich. Time will tell: Leveraging temporal expressions in ir. In WSDM 2009.", "R. Barzilay, N. Elhadad, and K. R. McKeown. Inferring strategies for sentence ordering in multidocument newssummarization. Journal of Artificial Intelligence Research, 17(1),2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983802"}, {"title": "DDTA 2016: The Workshop on Data-Driven Talent Acquisition", "authors": ["Yi Fang\n,", "Maarten de Rijke\n,", "Huangming Xie"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nExpertise search is a well-established field in information retrieval. In recent years, the increasing availability of data enables accumulation of evidence of talent and expertise from a wide range of domains. The availability of big data significantly benefits employers and recruiters. By analyzing the massive amounts of structured and unstructured data, organizations may be able to find the exact skill sets and talent they need to grow their business. The aim of this workshop is to provide a forum for industry and academia to discuss the recent progress in talent search and management, and how the use of big data and data-driven decision making can advance talent acquisition and human resource management.", "references": ["K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Foundations and Trends in Information Retrieval, 6(2--3):127--256, 2012.", "N. Craswell, A. P. de Vries, and I. Soboroff. Overview of the trec 2005 enterprise track. In Trec, volume 5, pages 199--205, 2005.", "B. Fecheyr-Lippens, B. Schaninger, and K. Tanner. Power to the new people analytics. McKinsey Quarterly, 51(1):61--63, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2988538"}, {"title": "A Methodology to Evaluate Triple Confidence and Detect Incorrect Triples in Knowledge Bases", "authors": ["Haihua Xie\n,", "Xiaoqing Lu\n,", "Zhi Tang\n,", "Mao Ye"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe accuracy of the contents of a knowledge base determines the effectiveness of knowledge service applications, thus, it is necessary to evaluate the confidence of triples when a knowledge base is built. This study introduces a generic computational methodology to compute the confidence values of triples in knowledge bases and detect potentially incorrect ones for further verification. The major contributions of the proposed methodology are as follows: (1) A process to compute the confidence values of triples is designed; (2) New algorithms are proposed to adjust the term frequency and inverse document frequency values of each triple; (3) A method to build a support vector machine (SVM) classifier based on the selected triples used for incorrect triple detection is presented.", "references": ["Edward A. Fox. 2015. Introduction to Digital Libraries. In Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries (Knoxville, TN, June 21--24, 2015). JCDL '15. ACM New York, NY, USA, Pages 291--291. DOI = http://doi.acm.org/10.1145/2756406.2756927.", "Maximilian Nickel, Volker Tresp, Hans-Peter Kriegel. 2011. A Three-Way Model for Collective Learning on Multi-Relational Data. In Proceedings of ICML. DOI = 10.1.1.231.6909.", "H. C. Wu, R. W. P. Luk, K. F. Wong, K. L Kwok. 2008. Interpreting TF-IDF term weights as making relevance decisions. ACM Transactions on Information Systems 26 (3): 1. DOI = 10.1145/1361684.1361686."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925456"}, {"title": "Nswap2L: Transparently Managing Heterogeneous Cluster Storage Resources for Fast Swapping", "authors": ["Tia Newhall\n,", "E. Ryerson Lehman-Borer\n,", "Benjamin Marks"], "publication": "MEMSYS '16: Proceedings of the Second International Symposium on Memory Systems", "abstract": "ABSTRACT\nTo support data intensive cluster computing, it is increasingly important that node virtual memory (VM) systems make effective use of available fast storage devices for swap or temporary file space. Nswap2L is a novel system that transparently manages a heterogeneous set of storage options commonly found in clusters, including node RAM, disk, flash SSD, PCM, or network storage devices. Nswap2L implements a two-level device driver interface. At the top level, it appears to node operating systems (OSs) as a single, fast, random access device that can be added as a swap partition on cluster nodes. It transparently manages the underlying heterogeneous storage devices, including its own implementation of Network RAM, to which swapped out data are stored. It implements data placement, migration, and prefetching policies that choose which underlying physical devices store swapped-out page data. Its policies incorporate information about device capacity, system load, and the strengths of different physical storage media. By moving device-specific knowledge into Nswap2L, VM policies in the OS can be based solely on typical application access patterns and not on characteristics of underlying physical storage media. Nswap2L's policy decisions are abstracted from the OS, freeing the OS from having to implement specialized policies for different combinations of cluster storage---Nswap2L requires no changes to the OS's VM system. Results of our benchmark tests show that data-intensive applications perform up to 6 times faster on Nswap2L-enabled clusters, and show that our two-level device driver design adds minimal I/O latency to the underlying devices that Nswap2L manages. In addition, we found that even though Nswap2L's Network RAM is faster than any other backing store, its prefetching policy that distributes data over multiple devices results in increased I/O parallelism and can lead to better performance than swapping only to a single underlying device.", "references": ["Device mapper, red hat inc. http://sources.redhat.com/dm.", "A. Acharya and S. Setia. Availability and Utility of Idle Memory on Workstation Clusters. In ACM SIGMETRICS Conference on Measuring and Modeling of Computer Systems, pages 35--46, May 1999.", "T. Anderson, D. E. Culler, D. A. Patterson, and the NOW Team. A case for NOW (networks of workstations). IEEE Micro, Febuary 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2989081.2989107"}, {"title": "Session details: Main Track - Intelligent Systems (III)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255985"}, {"title": "Remote and Continuous Monitoring of Electrical Quantities Using Web of Things and Cloud Computing", "authors": ["Marcelo Dornbusch L.\n,", "Leonardo R.P. Rauta\n,", "Paulo H. Silva\n,", "Rodrigo C. Silva\n,", "Adriano M. Irigoite\n,", "Michelle S. Wangham"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe remote monitoring and control of machines are essential in industrial environments. Emerging communication technologies such as Web of Things and Machine to Machine Communication can meet this demand for automation. This paper aims to introduce a solution, called Smart Meter, for continuous and remote monitoring of electrical quantities, in smart industrial environments with three-phase systems. The proposed solution uses a resource-oriented architecture and makes use of a Smart Gateway for communication, RESTful web services and cloud computing. The solution was integrated with a real case study and evaluated by software testing. The results obtained demonstrate the feasibility of the solution, and the correctness of measurements persisted in the cloud.", "references": ["Ieee standard definitions for the measurement of electric power quantities under sinusoidal, nonsinusoidal, balanced, or unbalanced conditions. IEEE Std 1459-2010 (Revision of IEEE Std 1459-2000), pages 1-50, March 2010", "C. Anton-Haro and M. Dohler. 1 - introduction to machine-to-machine (m2m) communications. In C. A.-H. Dohler, editor, Machine-to-machine (M2M) Communications, pages 1 - 23. Woodhead Publishing, Oxford, 2015", "A. Biral, M. Centenaro, A. Zanella, L. Vangelista, and M. Zorzi. The challenges of {M2M} massive access in wireless cellular networks. Digital Communications and Networks, 1(1):1 - 19, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022022"}, {"title": "Investigation of the Subjective Asymmetry of Social Interrelationship with Interactive Language", "authors": ["Bo Wang\n,", "Yanshu Yu\n,", "Peng Zhang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nInstead of studying the properties of social relationship from an objective view, in this paper, we focus on the two individuals' subjective and asymmetric opinions on their interrelationships. The sociolinguistics theories propose to characterize the individuals' opinions of their interrelationship with interactive language features. With this inspiration, we investigate the subjective asymmetry of the interrelationship with the asymmetry of the interactive language features including the frequency, quantity, quality and emotion. Experimental results with Enron email corpus provide suggestive evidences and thus reveal that the pair-wise language styles on an interrelationship are asymmetric, and this asymmetry can be a joint effect of the individuals' opinions of the interrelationship and their personal language habits. The results also indicate that the degree of the asymmetry could be related to the individuals' personality traits.", "references": ["Habermas, J. 1981. The Theory of Communicative Action. Beacon Press.", "Holmes, J. 2013. An introduction to sociolinguistics (4 edition). Routledge, London and New York.", "Sapir, E. 1929. The Status of Linguistics as a Science. Linguistic Society of America."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889379"}, {"title": "Investigating Cluster Stability when Analyzing Transaction Logs", "authors": ["Daniel Grech\n,", "Paul Clough"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nData-driven approaches have become increasingly popular as a means for analyzing transaction logs from web search engines and digital libraries, for example using cluster analysis to identify common patterns of search and navigation behavior. However, steps must be taken to ensure that results are reliable and repeatable. Although clustering patterns of user interaction behavior has been previously explored, one aspect that has received less attention is cluster stability that can be used to aid cluster validation. In this paper we compute stability based on the Jaccard coefficient to investigate the cluster stability when using different subsets of transaction log data from WorldCat.org. Results provide insights into different types of search behaviors and highlight that clusters of varying degrees of stability will result from the clustering process. However, we show that additional investigation beyond the results of cluster stability is required to fully validate the resulting clusters.", "references": ["Silvestri, F.: Mining query logs: Turning search usage data into knowledge. Found. Trends Inf. Retr.textbf4 (2010) 1--174", "Agosti, M., Crivellari, F., Di Nunzio, G.M.: Web log analysis: A review of a decade of studies about information acquisition, inspection and interpretation of user interaction. Data Min. Knowl. Discov.textbf24 (2012) 663--696", "Wolfram, D., Wang, P., Zhang, J.: Identifying web search session patterns using cluster analysis: A comparison of three search environments. Journal of the American Society for Information Science and Technologytextbf60 (2009) 896--910"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910923"}, {"title": "Early Prediction of Scholar Popularity", "authors": ["Masoumeh Nezhadbiglari\n,", "Marcos André Gonçalves\n,", "Jussara M. Almeida"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nPrediction of scholar popularity has become an important research topic for a number of reasons. In this paper, we tackle the problem of predicting the popularity {\\it trend} of scholars by concentrating on making predictions both as earlier and accurate as possible. In order to perform the prediction task, we first extract the popularity trends of scholars from a training set. To that end, we apply a time series clustering algorithm called K-Spectral Clustering (K-SC) to identify the popularity trends as cluster centroids. We then predict trends for scholars in a test set by solving a classification problem. Specifically, we first compute a set of measures for individual scholars based on the distance between earlier points in her particular popularity curve and the identified centroids. We then combine those distance measures with a set of academic features (e.g., number of publications, number of venues, etc) collected during the same monitoring period, and use them as input to a classification method. One aspect that distinguishes our method from other approaches is that the monitoring period, during which we gather information on each scholar popularity and academic features, is determined on a per scholar basis, as part of our approach. Using total citation count as measure of scientific popularity, we evaluate our solution on the popularity time series of more than 500,000 Computer Science scholars, gathered from Microsoft Azure Marketplace (https://datamarket.azure.com/dataset/mrc/microsoftacademic). The experimental results show that the our prediction method outperforms other alternative prediction methods. We also show how to apply our method jointly with regression models to improve the prediction of scholar popularity values (e.g., number of citations) at a given future time.", "references": ["D. E. Acuna, S. Allesina, and K. P. Kording. Future impact: Predicting scientific success. Nature, 489(7415):201--202, 2012.", "M. Ahmed, S. Spagna, F. Huici, and S. Niccolini. A peek into the future: Predicting the evolution of popularity in user generated content. In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, pages 607--616. ACM, 2013.", "G. E. Batista, E. J. Keogh, O. M. Tataw, and V. M. de Souza. Cid: An efficient complexity-invariant distance for time series. Data Mining and Knowledge Discovery, 28(3):634--669, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910905"}, {"title": "Adaptation of Word Vectors using Tree Structure for Visual Semantics", "authors": ["Nakamasa Inoue\n,", "Koichi Shinoda"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe propose a framework of word-vector adaptation, which makes vectors of visually similar concepts close to each other. Here, word vectors are real-valued vector representation of words, e.g., word2vec representation. Our basic idea is to assume that each concept has some hypernyms that are important to determine its visual features. For example, for a concept Swallow with hypernyms Bird, Animal and Entity, we believe Bird is the most important since birds have common visual features with their feathers etc. Adapted word vectors are obtained for each word by taking a weighted sum of a given original word vector and its hypernym word vectors. Our weight optimization makes vectors of visually similar concepts close to each other, by giving a large weight for such important hypernyms. We apply the adapted word vectors to zero-shot learning on the TRECVID 2014 semantic indexing dataset. We achieved 0.083 of Mean Average Precision, which is the best performance without using TRECVID training data to the best of our knowledge.", "references": ["A.W.M. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-Based Image Retrieval at the End of the Early Years. In IEEE Transactions on PAMI, vol.22, no.12, pp.1349--1380, 2000.", "T. Mensink, E. Gavves, and C.G.M. Snoek. Costa: Co-occurrence Statistics for Zero-shot Classification. Proc. CVPR, 2014.", "M. Norouzi, T. Mikolov, S. Bengio, Y. Singer, J. Shlens, A. Frome, G. Corrado, and J. Dean. Zero-shot Learning by Convex Combination of Semantic Embeddings. Proc. ICLR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967226"}, {"title": "Characterizing Diseases from Unstructured Text: A Vocabulary Driven Word2vec Approach", "authors": ["Saurav Ghosh\n,", "Prithwish Chakraborty\n,", "Emily Cohn\n,", "John S. Brownstein\n,", "Naren Ramakrishnan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTraditional disease surveillance can be augmented with a wide variety of real-time sources such as, news and social media. However, these sources are in general unstructured and, construction of surveillance tools such as taxonomical correlations and trace mapping involves considerable human supervision. In this paper, we motivate a disease vocabulary driven word2vec model (Dis2Vec) to model diseases and constituent attributes as word embeddings from the HealthMap news corpus. We use these word embeddings to automatically create disease taxonomies and evaluate our model against corresponding human annotated taxonomies. We compare our model accuracies against several state-of-the art word2vec methods. Our results demonstrate that Dis2Vec outperforms traditional distributed vector representations in its ability to faithfully capture taxonomical attributes across different class of diseases such as endemic, emerging and rare.", "references": ["M. Baroni, G. Dinu, and G. Kruszewski. Don't count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the ACL, pages 238--247, 2014.", "M. Baroni and A. Lenci. Distributional memory: A general framework for corpus-based semantics. Computational Linguistics, 36(4):673--721, 2010.", "Y. Bengio, H. Schwenk, J.-S. Senécal, F. Morin, and J.-L. Gauvain. Neural probabilistic language models. In Innovations in Machine Learning, pages 137--186. Springer, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983362"}, {"title": "BIBSURF: Discover Bibliographic Entities by Searching for Units of Interest, Ranking and Filtering", "authors": ["Trond Aalberg\n,", "Tanja Merčun\n,", "Maja Žumer"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nBIBSURF is a system demonstrating search, ranking and filtering of bibliographic RDF data that is organized in form of entities representing intellectual endeavor at different levels of abstraction: item, manifestation, expression, work.", "references": ["Li Ding, Tim Finin, Yun Peng, Paulo Pinheiro da Silva, and Deborah L. McGuinness. Tracking RDF Graph Provenance using RDF Molecules. Technical Report TR-05-06, UMBC, 2005.", "Zorana Ercegovac. Multiple-Version Resources in Digital Libraries: Towards User-Centered Displays. JASIST, 57(8):1023--1032, 2006.", "Wangchao Le, Feifei Li, Anastasios Kementsietsidis, and Songyun Duan. Scalable Keyword Search on Large RDF Data. IEEE Transactions on knowledge and data engineering, 26(11), November 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925434"}, {"title": "Event-based MultiMedia Search and Retrieval for Question Answering", "authors": ["Benoit Huet"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nUser generated content, available in massive amounts on the Internet, comes in many \"flavors\" (i.e. micro messages, text documents, images and videos) and is receiving increasing attention due to its many potential applications. One important applications is the automatic generation of multimedia enrichments concerning users topic of interests and in particular the creation of event summaries using multimedia data [1]. In this talk, an event-based cross media question answering system, which retrieves and summarizes events on a given user generated query topic is proposed. A framework for leveraging social media data to extract and illustrate social events automatically on any given query will be presented. The system operates in three stages. First, the input query is parsed semantically to identify the topic, location, and time information related to the event of interest (News in this scenario presented here). Then, we use the parsed information to mine the latest and hottest related News from social news web services. Third, to identify a unique event, we model the News content by latent Dirichlet Allocation and cluster the News using the DBSCAN algorithm. In the end, for each event, we retrieve both textual and visual content of News that refer the same event [2,3]. The resulting documents are shown within a vivid interface featuring both event description, tag cloud and photo collage [4]. Popular question answering systems (i.e. YahooAnswers) and search engines retrieve documents on the basis of text information. The integration the visual information within the text-based search for video and image retrieval is still a hot research topic. In the second part of this talk, we propose to use visual information to enrich the classic text-based search for video retrieval [5]. With the proposed framework, we endeavor to show experimentally, on a set of real world scenarios, that visual cues can effectively contribute to significant quality improvement of image/video retrieval. Experimental results show that mapping text-based queries to visual concepts improves the performance of the search system. Moreover, when appropriately selecting the relevant visual concepts for a query, a very substantial improvement of the system's performance is achieved [6]. Based on the various results presented in this talk we argue that question answering (among other application) can greatly leverage from cross media analysis to the benefit of users.", "references": ["Xueliang Liu and Benoit Huet. 2016. Event-based cross media question answering. Multimedia Tools and Applications. 75, 3 (February 2016), 1495--1508. DOI=http://dx.doi.org/10.1007/s11042-014--2085-0", "Xueliang Liu and Benoit Huet. 2013. Event Representation and Visualization from Social Media. In Proceedings of the 14th Pacific-Rim Conference on Advances in Multimedia Information Processing -- PCM 2013 -- Volume 8294, Benoit Huet, Chong-Wah Ngo, Jinhui Tang, Zhi-Hua Zhou, Alexander Hauptmann, and Shuicheng Yan (Eds.), Vol. 8294. Springer-Verlag New York, Inc., New York, NY, USA, 740--749. DOI=http://dx.doi.org/10.1007/978--3--319-03731--8_69", "Xueliang Liu and Benoit Huet. 2013. Heterogeneous features and model selection for event-based media classification. In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval (ICMR '13). ACM, New York, NY, USA, 151--158. DOI=http://dx.doi.org/10.1145/2461466.2461493"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2927006.2927015"}, {"title": "Balanced Supervised Non-Negative Matrix Factorization for Childhood Leukaemia Patients", "authors": ["Ali Braytee\n,", "Daniel R. Catchpoole\n,", "Paul J. Kennedy\n,", "Wei Liu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSupervised feature extraction methods have received considerable attention in the data mining community due to their capability to improve the classification performance of the unsupervised dimensionality reduction methods. With increasing dimensionality, several methods based on supervised feature extraction are proposed to achieve a feature ranking especially on microarray gene expression data. This paper proposes a method with twofold objectives: it implements a balanced supervised non-negative matrix factorization (BSNMF) to handle the class imbalance problem in supervised non-negative matrix factorization techniques. Furthermore, it proposes an accurate gene ranking method based on our proposed BSNMF for microarray gene expression datasets. To the best of our knowledge, this is the first work to handle the class imbalance problem in supervised feature extraction methods. This work is part of a Human Genome project at The Children's Hospital at Westmead (TB-CHW), Australia. Our experiments indicate that the factorized components using supervised feature extraction approach have more classification capability than the unsupervised one, but it drastically fails at the presence of class imbalance problem. Our proposed method outperforms the state-of-the-art methods and shows promise in overcoming this concern.", "references": ["GenePattern Database. http://broadinstitute.org/cgi-bin/cancer/datasets.cgi.", "X. Chen, L. Wang, J. D. Smith, and B. Zhang. Supervised principal component analysis for gene set enrichment of microarray data with continuous or survival outcomes. Bioinformatics, 24(21):2474--2481, 2008.", "K. Devarajan. Nonnegative matrix factorization: an analytical and interpretive tool in computational biology. PLoS Comput Biol, 4(7):e1000029, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983375"}, {"title": "N-gram over Context", "authors": ["Noriaki Kawamae"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nOur proposal, $N$-gram over Context (NOC), is a nonparametric topic model that aims to help our understanding of a given corpus, and be applied to many text mining applications. Like other topic models, NOC represents each document as a mixture of topics and generates each word from one topic. Unlike these models, NOC focuses on both a topic structure as an internal linguistic structure, and N-gram as an external linguistic structure. To improve the quality of topic specific N-grams, NOC reveals a tree of topics that captures the semantic relationship between topics from a given corpus as context, and forms $N$-gram by offering power-law distributions for word frequencies on this topic tree. To gain both these linguistic structures efficiently, NOC learns them from a given corpus in a unified manner. By accessing this entire tree at the word level in the generative process of each document, NOC enables each document to maintain a thematic coherence and form $N$-grams over context. We develop a parallelizable inference algorithm, D-NOC, to support large data sets. Experiments on review articles/papers/tweet show that NOC is useful as a generative model to discover both the topic structure and the corresponding N-grams, and well complements human experts and domain specific knowledge. D-NOC can process large data sets while preserving full generative model performance, by the help of an open-source distributed machine learning framework.", "references": ["A. Ahmed, L. Hong, and A. J. Smola. Hierarchical geographical modeling of user locations from social media post. In WWW, pages 25--36, 2013.", "D. Aldous. Exchangeability and related topics, volume 1117 of Lecture Notes in Math. Springer, Berlin, 1985.", "D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882981"}, {"title": "Reducing expenses of top-k monitoring in sensor cloud services", "authors": ["Kamalas Udomlamlert\n,", "Takahiro Hara"], "publication": "DEBS '16: Proceedings of the 10th ACM International Conference on Distributed and Event-based Systems", "abstract": "ABSTRACT\nIn sensor cloud services, the expense is charged based on the amount of resource usage, e.g. data requests. This paper originally presents an expense-minimizing framework for top-k monitoring in sensor cloud services where the expense is denoted by the costs of data requests. Instead of fetching all the latest data in each timestamp, we propose a novel ε-top-k query delivering approximate top-k answers with a probabilistic guarantee on the selectively-fetched dataset which is a combination of certain and uncertain data (modelled by their age). In addition, using a cloud environment as well as our proposed method to process ε-top-k queries can alleviate the computing-intensive computations, so it is not only cheaper but even faster than an ordinary top-k calculation method. The extensive experiments on the real-world climate datasets demonstrate that our methods can reduce the expense by more than half with desirable accuracy.", "references": ["S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Madden, and I. Stoica. BlinkDB: queries with bounded errors and bounded response times on very large data. In Eurosys, pages 29--42, 2013.", "C. C. Aggarwal and P. S. Yu. A survey of uncertain data algorithms and applications. KDE, 21(5):609--623, 2009.", "I. Bartolini, P. Ciaccia, and M. Patella. Efficient sort-based skyline evaluation. TODS, 33(4):31, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933267.2935090"}, {"title": "Accessibility to Patients' Own Health Information: A Case in Rural Eastern Cape, South Africa", "authors": ["Simlindile Abongile Bantom\n,", "Retha de la Harpe\n,", "Nkqubela Ruxwana"], "publication": "SAICSIT '16: Proceedings of the Annual Conference of the South African Institute of Computer Scientists and Information Technologists", "abstract": "ABSTRACT\nAccess to healthcare is regarded as a basic and essential human right. It is generally acknowledged that Information and Communication Technology solutions have potential to improve access to healthcare, reduce healthcare cost, reduce medical errors, and bridge the digital divide between rural and urban healthcare centres. The access to personal healthcare records is however, an astounding challenge for both patients and healthcare professionals alike, particularly within resource-restricted environments, such as rural communities. Most rural healthcare institutions have limited or non-existent access to electronic patient healthcare records. This paper explored the accessibility of personal healthcare records by patients and healthcare professionals within a rural community hospital in the Eastern Cape Province of South Africa. A case study was conducted, where semi-structured interviews, observations, and interactive co-design sessions and focus groups were employed as the primary data collection methods in this study. The data was qualitatively interpreted using thematic analysis approach. A number of recommendations for improved access to personal healthcare records are discussed.", "references": ["Archer, N. et al., 2011. Personal health records: a scoping review. Journal of the American Medical Informatics Association: JAMIA, 18(4), pp. 515--522.", "Adão, W., 2013 Technology enabled self-care to overhaul healthcare industry.", "Al-nassar, B., Abdullah, M. & Osman, S., 2011. Overcoming challenges to use Electronic Medical Records System ( EMRs ) in Jordan Hospitals., 11(8), pp. 51--58."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987491.2987505"}, {"title": "Large-Scale Analysis of Viewing Behavior: Towards Measuring Satisfaction with Mobile Proactive Systems", "authors": ["Qi Guo\n,", "Yang Song"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRecently, proactive systems such as Google Now and Microsoft Cortana have become increasingly popular in reforming the way users access information on mobile devices. In these systems, relevant content is presented to users based on their context without a query in the form of information cards that do not require a click to satisfy the users. As a result, prior approaches based on clicks cannot provide reliable measurements of user satisfaction with such systems. It is also unclear how much of the previous findings regarding good abandonment with reactive Web searches can be applied to these proactive systems due to the intrinsic difference in user intent, the greater variety of content types and their presentations. In this paper, we present the first large-scale analysis of viewing behavior based on the viewport (the visible fraction of a Web page) of the mobile devices, towards measuring user satisfaction with the information cards of the mobile proactive systems. In particular, we identified and analyzed a variety of factors that may influence the viewing behavior, including biases from ranking positions, the types and attributes of the information cards, and the touch interactions with the mobile devices. We show that by modeling the various factors we can better measure user satisfaction with the mobile proactive systems, enabling stronger statistical power in large-scale online A/B testing.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR '06, pages 19--26, 2006.", "G. Buscher, A. Dengel, and L. van Elst. Eye movements as implicit relevance feedback. In CHI '08: CHI '08 extended abstracts on Human factors in computing systems, pages 2991--2996, 2008.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In WWW '09, pages 1--10, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983846"}, {"title": "Compute Job Memory Recommender System Using Machine Learning", "authors": ["Taraneh Taghavi\n,", "Maria Lupetini\n,", "Yaron Kretchmer"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThis paper presents a machine learning approach to predict the amount of compute memory needed by jobs which are submitted to Load Sharing Facility (LSF® ) with a high level of accuracy. LSF® is the compute resource manager and job scheduler for Qualcomm chip design process. It schedules the jobs based on available resources: CPU, memory, storage, and software licenses. Memory is one of the key resources and its proper utilization leads to a substantial improvement in saving machine resources which in turn results in a significant reduction in overall job pending time. In addition, efficient memory utilization helps to reduce the operations cost by decreasing the number of servers needed for the end-to-end design process. In this paper, we explored a suite of statistical and machine learning techniques to develop a Compute Memory Recommender System for the Qualcomm chip design process with over 90% accuracy in predicting the amount of memory a job needs. Moreover, it demonstrates the potential to significantly reduce job pending time.", "references": ["Lavagno, L., Martin, G., Scheffer, L., 2006. Electronic Design Automation for Integrated Circuits Handbook, Taylor & Francis.", "Goering, Richard, March 8, 1999. Load Sharing Brings Kudos, EE Times Online.", "Haykin, S., 2007. Neural Networks, a Comprehensive Foundation, Second edition, Prentice Hall of India."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939717"}, {"title": "Leveraging User Interaction Signals for Web Image Search", "authors": ["Neil O'Hare\n,", "Paloma de Juan\n,", "Rossano Schifanella\n,", "Yunlong He\n,", "Dawei Yin\n,", "Yi Chang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUser interfaces for web image search engine results differ significantly from interfaces for traditional (text) web search results, supporting a richer interaction. In particular, users can see an enlarged image preview by hovering over a result image, and an `image preview' page allows users to browse further enlarged versions of the results, and to click-through to the referral page where the image is embedded. No existing work investigates the utility of these interactions as implicit relevance feedback for improving search ranking, beyond using clicks on images displayed in the search results page. In this paper we propose a number of implicit relevance feedback features based on these additional interactions: hover-through rate, 'converted-hover' rate, referral page click through, and a number of dwell time features. Also, since images are never self-contained, but always embedded in a referral page, we posit that clicks on other images that are embedded on the same referral webpage as a given image can carry useful relevance information about that image. We also posit that query-independent versions of implicit feedback features, while not expected to capture topical relevance, will carry feedback about the quality or attractiveness of images, an important dimension of relevance for web image search. In an extensive set of ranking experiments in a learning to rank framework, using a large annotated corpus, the proposed features give statistically significant gains of over 2% compared to a state of the art baseline that uses standard click features.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, pages 19--26, New York, NY, USA, 2006. ACM.", "P. Andre, E. Cutrell, D. S. Tan, and G. Smith. Designing novel image search interfaces by understanding unique characteristics and usage. In INTERACT 2009, pages 340--353. Springer-Verlag, 2009.", "M. Bilenko and R. W. White. Mining the search trails of surfing crowds: Identifying relevant websites from user activity. In Proceedings of the 17th International Conference on World Wide Web, WWW '08, pages 51--60, New York, NY, USA, 2008. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911532"}, {"title": "Recurrent Coevolutionary Latent Feature Processes for Continuous-Time Recommendation", "authors": ["Hanjun Dai\n,", "Yichen Wang\n,", "Rakshit Trivedi\n,", "Le Song"], "publication": "DLRS 2016: Proceedings of the 1st Workshop on Deep Learning for Recommender Systems", "abstract": "ABSTRACT\nMatching users to the right items at the right time is a fundamental task in recommender systems. As users interact with different items over time, users' and items' feature may drift, evolve and co-evolve over time. Traditional models based on static latent features or discretizing time into epochs can become ineffective for capturing the fine-grained temporal dynamics in the user-item interactions. We propose a coevolutionary latent feature process model that accurately captures the coevolving nature of users' and items' feature. We use a recurrent neural network to automatically learn a representation of influences from drift, evolution and co-evolution of user and item features. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Experiments on diverse real-world datasets demonstrate significant improvements in user behavior prediction compared to state-of-the-arts.", "references": ["O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view. Springer, 2008.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In J. Elder, F. Fogelman-Soulié, P. Flach, and M. Zaki, editors, KDD, pages 19--28. ACM, 2009.", "L. Charlin, R. Ranganath, J. McInerney, and D. M. Blei. Dynamic poisson factorization. In RecSys, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988450.2988451"}, {"title": "Introduction to Creating Musical Interfaces", "authors": ["Michael J. Lyons\n,", "Sidney Fels"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis course provides a general, gentle, and fun introduction to the theory and practice of interface design for creating and performing music. Participants will learn key aspects of the theory and practice of musical interface design by studying case studies and live demonstrations mostly sourced from the leading conference in this area, \"New Interfaces for Musical Expression\" (NIME).", "references": ["Bevilacqua, F., Fels, S., Jensenius, A. R., Lyons, M. J., Schnell, N., and Tanaka, A. Sig nime: music, technology, and human-computer interaction. In Extended Abstracts CHI'13, ACM (2013), 2529--2532.", "Fels, S., and Lyons, M. Creating new interfaces for musical expression: introduction to NIME. In SIGGRAPH 2009 Courses, ACM Press (2009).", "Fels, S., and Lyons, M. Interaction and music technology. In Human-Computer Interaction-INTERACT 2011. Springer, 2011, 691--692."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2856665"}, {"title": "A Semantic Graph based Topic Model for Question Retrieval in Community Question Answering", "authors": ["Long Chen\n,", "Joemon M. Jose\n,", "Haitao Yu\n,", "Fajie Yuan\n,", "Dell Zhang"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nCommunity Question Answering (CQA) services, such as Yahoo! Answers and WikiAnswers, have become popular with users as one of the central paradigms for satisfying users' information needs. The task of question retrieval aims to resolve one's query directly by finding the most relevant questions (together with their answers) from an archive of past questions. However, as the text of each question is short, there is usually a lexical gap between the queried question and the past questions. To alleviate this problem, we present a hybrid approach that blends several language modelling techniques for question retrieval, namely, the classic (query-likelihood) language model, the state-of-the-art translation-based language model, and our proposed semantics-based language model. The semantics of each candidate question is given by a probabilistic topic model which makes use of local and global semantic graphs for capturing the hidden interactions among entities (e.g., people, places, and concepts) in question-answer pairs. Experiments on two real-world datasets show that our approach can significantly outperform existing ones.", "references": ["Yang Bao, Nigel Collier, and Anindya Datta. A partially supervised cross-collection topic model for cross-domain text classification. CIKM '13, pages 239--248.", "Christian Bizer, Jens Lehmann, Kobilarov, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. Dbpedia - a crystallization point for the web of data. volume 7, pages 154--165.", "David M. Blei, Andrew Y. Ng, Michael I. Jordan, and John Lafferty. Latent dirichlet allocation. volume 3, pages 459--565."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835809"}, {"title": "FIN10K: A Web-based Information System for Financial Report Analysis and Visualization", "authors": ["Yu-Wen Liu\n,", "Liang-Chih Liu\n,", "Chuan-Ju Wang\n,", "Ming-Feng Tsai"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this demonstration, we present FIN10K, a web-based information system that facilitates the analysis of textual information in financial reports. The proposed system has three main components: (1) a 10-K Corpus, including an inverted index of financial reports on Form 10-K, several numerical finance measures, and pre-trained word embeddings; (2) an information retrieval system; and (3) two data visualizations of the analyzed results. The system can be of great help in revealing valuable insights within large amounts of textual information. The system is now online available at http: //clip.csie.org/10K/.", "references": ["M. T. Billett, M. J. Flannery, and J. A. Garfinkel. The effect of lender identity on a borrowing firm's equity return. The Journal of Finance, 50(2):699--718, 1995.", "A. K. Dittmar. Why do firms repurchase stock*. The Journal of Business, 73(3):331--355, 2000.", "R. Feldman. Techniques and applications for sentiment analysis. Communications of the ACM, 56(4):82--89, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983328"}, {"title": "Hierarchical N-gram Algorithm for extracting Arabic Entities", "authors": ["Eslam Amer\n,", "Heba M. Khalil\n,", "Tarek El-shistawy"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nEntities Extraction becomes very important for developing many applications of Natural Language Processing (NLP). In this paper, we present a new algorithm to extract entities from Arabic text. The approach uses the semi-structured knowledge source: Arabic Wikipedia to predict the words that constitutes an Arabic entity. Our method is generic and can be applied directly to other languages to extract entities. The proposed method has been designed to analyze Arabic text hierarchically with variable length N-gram. The experimental results have proven that the proposed system is very efficient in detecting entities from large set of Arabic news.", "references": ["R. Kosala and H. Blockeel.2000. Web mining research: a survey. SIGKDD Explor. Newsl. vol. 2. pp. 1--15.", "S. A. Babar and P. D. Patil.2015. Improving Performance of Text Summarization. Procedia Computer Science, (vol. 46). pp. 354--363.", "I. Boujelben, S. Jamoussi, and A. Ben Hamadou.2014. A hybrid method for extracting relations between Arabic named entities. Journal of King Saud University - Computer and Information Sciences, vol. 26, pp. 425--440, 12."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908449"}, {"title": "The exploration of objective task difficulty and domain knowledge effects on users' query formulation", "authors": ["Chang Liu\n,", "Xiangmin Zhang\n,", "Wei Huang"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nIn this paper, we explore the effects of objective task difficulty and domain knowledge on users' query formulation behaviors. The dataset from a user experiment was used in this research, which focused on the medical domain. The objective difficulty was measured by the precision level of search topics (as queries) in the search system, and searchers' domain knowledge was assessed by a self-reported rating on the familiarity with MeSH terms that were related to the search topics in the study. We compared expert searchers' and novice searchers' query similarity and query features between easy and difficult tasks. The results showed that there was no significant difference between domain experts and novices in query similarity, but there existed an opposite pattern of task difficulty effects on query similarity for searchers with different domain knowledge levels. Domain expert searchers had more diverse vocabulary in difficult tasks than in easy tasks, whereas novice searchers had to rely heavily on task descriptions to formulate their queries. Task difficulty had also influenced searchers' performance, especially the precision measure. Novice searchers' recall was relatively low in both easy and difficult tasks. The findings in this study help us further understand users' query formulation process, and have implication for the design of query suggestion functions in search systems.", "references": ["Allen, B. (1991). Topic Knowledge and Online Catalog Search Formulation. The Library Quarterly, 61(2), 188--213.", "Aula, A., Khan, R. & Guan, Z. (2010). How does search behavior change as search becomes more difficult? Proceedings of CHI'10, 35--44.", "Belkin, N.J. (1990). The cognitive viewpoint in information science. Journal of Information Science, vol. 16: 11--15."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017510"}, {"title": "Session details: Technical Session: Memory Management", "authors": ["John Criswell"], "publication": "ACM SIGPLAN Notices", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3263411"}, {"title": "ASSISTments Dataset from Multiple Randomized Controlled Experiments", "authors": ["Douglas Selent\n,", "Thanaporn Patikorn\n,", "Neil Heffernan"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nIn this paper, we present a dataset consisting of data generated from 22 previously and currently running randomized controlled experiments inside the ASSIStments online learning platform. This dataset provides data mining opportunities for researchers to analyze ASSISTments data in a convenient format across multiple experiments at the same time. The data preprocessing steps are explained in detail to inform researchers about how this dataset was generated. A list of column descriptions is provided to define the columns in the dataset and a set of summary statistics are presented to briefly describe the dataset.", "references": ["ASSISTmentsTestBed (2015) The ASSISTmentsTestBed. A website that supports researchers funded via the Heffernan (2014) grant. Retrieved from www.assistmentstestbed.org", "Heffernan (2014) \"SI2-SSE: Adding Research Accounts to the ASSISTments' Platform: Helping Researchers Do Randomized Controlled Studies with Thousands of Students.\" An NSF proposal abstract", "Lang, C., Heffernan, N., Ostrow, K., & Wang, Y. (2015). The Impact of Incorporating Student Confidence Items into an Intelligent Tutor: A Randomized Controlled Trial. In Santos, et al. (eds.) Proceedings of the 8th Int Conf on EDM. pp. 144--149."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893409"}, {"title": "A combination of simple models by forward predictor selection for job recommendation", "authors": ["Dávid Zibriczky"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nThe present paper introduces a solution for the RecSys Challenge 2016. The principle of the proposed technique is to define various models capturing the specificity of the dataset and then to subsequently find the optimal combinations of these by considering different user categories. The approach follows a practical way for the fine-tuning of recommender algorithms, highlighting their components, training-and prediction time. Based on forward predictor selection, it can be shown that item-neighbor methods and the recommendation of already shown or interacted items have great potential in improving the offline accuracy. The best composition consists of 11 predictor instances that achieved the third place with 665,592 leaderboard score and 2,005,263 final score.", "references": ["Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30--37, 2009.", "M. J. Pazzani and D. Billsus. Content-Based Recommendation Systems, pages 325--341. Springer Berlin Heidelberg, Berlin, Heidelberg, 2007.", "B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based collaborative filtering recommendation algorithms. In Proceedings of WWW 2001, pages 285--295. ACM, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987548"}, {"title": "Frequent Multi-Byte Character Subtring Extraction using a Succinct Data Structure", "authors": ["Phanucheep Chotnithi\n,", "Atsuhiro Takasu"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nFrequent string mining is widely used in text processing to extract text features. Most researchers have focused on text using single-byte characters. Consequently, their applications have problems when applied to text represented with multibyte characters such as Japanese and Chinese text. The main drawback is huge memory us-age for treating multibyte character strings. To solve this problem,we use wavelet tree-based compressed suffix arrays instead of the normal suffix array to reduce the memory usage, and a novel technique that utilizes the rank operation to improve runtime efficiency.Our experimental evaluation shows that the proposed method reduces the processing time by 45% compared with a method usingonly compressed suffix arrays. The proposed method also reduces the memory usage by 75%.", "references": ["M. Burrows and D. Wheeler. A block-sorting lossless data compression algorithm. In DIGITAL SRC RESEARCH REPORT. Citeseer, 1994.", "L. De Raedt, M. Jaeger, S. D. Lee, and H. Mannila. A theory of inductive query answering. In Data Mining, 2002. ICDM2003. Proceedings. 2002 IEEE International Conference on,pages 123--130. IEEE, 2002.", "P. Ferragina and G. Manzini. Opportunistic data structures with applications. In Foundations of Computer Science,2000. Proceedings. 41st Annual Symposium on, pages 390--398. IEEE, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967161"}, {"title": "An Architecture of an Academic Search Engine with Personalized Search Result Ranking Mechanism", "authors": ["Worasit Choochaiwattana"], "publication": "ICNCC '16: Proceedings of the Fifth International Conference on Network, Communication and Computing", "abstract": "ABSTRACT\nA rapid increasing of information on the Internet and World Wide Web causes information overloaded problem. Thus, search engines become important tools to help WWW users to discover the information they need. With an exponentially increasing of published research paper, community-based research paper sharing systems and academic search engines become indispensable tools for researchers to search for any research papers in their fields of expertise and related fields according to their interests. To improve a quality of research paper searching, an academic search engines' capability should be enhanced. This paper proposed an architecture of an academic search engine with personalized search result ranking mechanism. To evaluate the performance of personalized search result ranking mechanism, twenty-five graduate students were invited to be participants in this research study. As a criterion, the participants were asked to use a prototype of academic search engine to find and bookmark any research papers according to their interests. This would guarantee that each participants' list of interesting research paper could be recorded. The Normalized Discounted Cumulative Gain (NDCG) was used as a metric to determine that performance of personalized search result ranking mechanism. During the experiment, each participant was asked to search for research papers according to their interests. The result of the experiment suggested that the personalized search result ranking mechanism outperformed the original search result ranking. Hence, the proposed architecture of the academic search engine with personalized search engine mechanism does benefit a tasks of research paper discovery. It improves the quality of research paper searching.", "references": ["Choochaiwattana, W. and Spring, M.B. 2009. Applying Social Annotations to Retrieve and Re-rank Web Resources. In Proceedings of the International Conference on Information Management and Engineering (Kuala Lumpur, Malaysia, April 03-05, 2009). ICIME '09. 215--219.", "Brin, S. and Page, L. 1998, The anatomy of a large-scale hypertextual Web search engine. Journal of Computer Networks and ISDN Systems. 30, 1-7 (Apr. 1998), 107--117.", "Craswell, N., Hawking, D. and Robertson, S. 2001. Effective site finding using link anchor information. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval (New Orleans, Louisiana, USA, September 09-12, 2001). SIGIR '01. 250--257."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3033288.3033314"}, {"title": "Anytime Algorithms for Recommendation Service Providers", "authors": ["David Ben-Shimon\n,", "Lior Rokach\n,", "Guy Shani\n,", "Bracha Shapira"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nRecommender systems (RS) can now be found in many commercial Web sites, often presenting customers with a short list of additional products that they might purchase. Many commercial sites do not typically have the ability and resources to develop their own system and may outsource the RS to a third party. This had led to the growth of a recommendation as a service industry, where companies, referred to as RS providers, provide recommendation services. These companies must carefully balance the cost of building recommendation models and the payment received from the e-business, as these payments are expected to be low. In such a setting, restricting the computational time required for model building is critical for the RS provider to be profitable.\nIn this article, we propose anytime algorithms as an attractive method for balancing computational time and the recommendation model performance, thus tackling the RS provider problem. In an anytime setting, an algorithm can be stopped after any amount of computational time, always ensuring that a valid, although suboptimal, solution will be returned. Given sufficient time, however, the algorithm should converge to an optimal solution. In this setting, it is important to evaluate the quality of the returned solution over time, monitoring quality improvement. This is significantly different from traditional evaluation methods, which mostly estimate the performance of the algorithm only after its convergence is given sufficient time.\nWe show that the popular item-item top-N recommendation approach can be brought into the anytime framework by smartly considering the order by which item pairs are being evaluated. We experimentally show that the time-accuracy trade-off can be significantly improved for this specific problem.", "references": ["F. Aiolli. 2013. Efficient top-n recommendation for very large scale binary rated datasets. In Proceedings of the 7th ACM Conference on Recommender Systems. ACM, New York, NY, 273--280.", "D. Agarwal and M. Gurevich. 2012. Fast top-k retrieval for model based recommendation. In Proceedings of the 5th ACM International Conference on Web Search and Data Mining. ACM, New York, NY, 483--492.", "R. Anil, T. Dunning, and E. Friedman. 2011. Clustering algorithms in Mahout. In Mahout in Action, S. Owen, R. Anil, T. Dunning, and E. Friedman (Eds.). Manning, Shelter Island, NY, 145--183."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835496"}, {"title": "Gender Differences in the Use of Portuguese in Social Networks: Evidence from LIWC", "authors": ["Gustavo Paiva Guedes\n,", "Eduardo Bezerra\n,", "Lilian Ferrari\n,", "Fellipe Duarte"], "publication": "Webmedia '16: Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThis work aims at highlighting gender differences in the use of Brazilian Portuguese by users of a Brazilian social network. We perform this study by using a dictionary of a text analysis program named LIWC. Experimental results indicate that males and females differ with respect to the most used word classes. Our results are consistent with studies performed in other languages.", "references": ["Pedro Paulo Balage Filho, Thiago Pardo, and Sandra Aluısio. An evaluation of the Brazilian Portuguese LIWC dictionary for sentiment analysis. In Sandra Maria Aluısio and Valéria Delisandra Feltrim, editors, Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology (STIL), pages 215--219, Fortaleza-CE, Brazil, 21--23 October 2013. Sociedade Brasileira de Computaçao.", "Federica Barbieri. Patterns of age-based linguistic variation in american english. Journal of Sociolinguistics, 12(1):58--88, 2008.", "Dasha Bogdanova, Paolo Rosso, and Thamar Solorio. On the impact of sentiment and emotion based features in detecting online sexual predators. In Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis, pages 110--118. Association for Computational Linguistics, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2976796.2988188"}, {"title": "Leveraging Query Sensitivity for Practical Private Web Search", "authors": ["Antoine Boutet\n,", "Albin Petit\n,", "Sonia Ben Mokhtar\n,", "Léa Laporte"], "publication": "Middleware Posters and Demos '16: Proceedings of the Posters and Demos Session of the 17th International Middleware Conference", "abstract": "ABSTRACT\nSeveral private Web search solutions have been proposed to preserve the user privacy while querying search engines. However, most of these solutions are costly in term of processing, network overhead and latency as they mostly rely on cryptographic techniques and/or the generation of fake requests. Furthermore, all these solutions protect all queries similarly, ignoring whether the original request contains sensitive content (e.g., religious, political or sexual orientation) or not. Based on an analysis of a real dataset of Web search requests, we show that queries related to sensitive matters are in practice a minority. As a consequence, protecting all queries similarly results in poor performance as a large number of queries get overprotected.\nIn this paper, we propose a request sensitivity assessment module that we use for improving the practicability of existing private web search solutions. We assess the sensitivity of a request in two phases: a semantic sensitivity analysis (based on the topic of the query) and a request linkability analysis (based on the similarity between the current query and the query history of the requester). Finally, the sensitivity assessment is used to adapt the level of protection of a given query according to its identified degree of sensitivity: the more sensitive a query is, the more protected it will be.\nExperiments with a real dataset show that our approach can improve the performance of state-of-the-arts private Web search solutions by reducing the number of queries overprotected, while ensuring a similar level of privacy to the users, making them more likely to be used in practice.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007592.3007595"}, {"title": "Adaptive Cluster Tendency Visualization and Anomaly Detection for Streaming Data", "authors": ["Dheeraj Kumar\n,", "James C. Bezdek\n,", "Sutharshan Rajasegarar\n,", "Marimuthu Palaniswami\n,", "Christopher Leckie\n,", "Jeffrey Chan\n,", "Jayavardhana Gubbi"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nThe growth in pervasive network infrastructure called the Internet of Things (IoT) enables a wide range of physical objects and environments to be monitored in fine spatial and temporal detail. The detailed, dynamic data that are collected in large quantities from sensor devices provide the basis for a variety of applications. Automatic interpretation of these evolving large data is required for timely detection of interesting events. This article develops and exemplifies two new relatives of the visual assessment of tendency (VAT) and improved visual assessment of tendency (iVAT) models, which uses cluster heat maps to visualize structure in static datasets. One new model is initialized with a static VAT/iVAT image, and then incrementally (hence inc-VAT/inc-iVAT) updates the current minimal spanning tree (MST) used by VAT with an efficient edge insertion scheme. Similarly, dec-VAT/dec-iVAT efficiently removes a node from the current VAT MST. A sequence of inc-iVAT/dec-iVAT images can be used for (visual) anomaly detection in evolving data streams and for sliding window based cluster assessment for time series data. The method is illustrated with four real datasets (three of them being smart city IoT data). The evaluation demonstrates the algorithms’ ability to successfully isolate anomalies and visualize changing cluster structure in the streaming data.", "references": ["C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. 2003. A framework for clustering evolving data streams. In Proceedings of the International Conference on Very Large Data Bases (VLDB). 81--92.", "E. Anderson. 1935. The irises of the Gaspe peninsula. Bulletin of American Iris Society 59 (1935), 2--5.", "P. Angelov. 2010. Evolving Takagi-Sugeno fuzzy systems from streaming data (eTS+). In Evolving Intelligent Systems: Methodology and Applications. IEEE Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2997656"}, {"title": "String deduplication during garbage collection in virtual machines", "authors": ["Konstantin Nasartschuk\n,", "Marcel Dombrowski\n,", "Kenneth B. Kent\n,", "Aleksandar Micic\n,", "Dane Henshall\n,", "Charlie Gracie"], "publication": "CASCON '16: Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nMemory management is a significant topic in virtual machine research. As allocation and deallocation of objects is performed automatically, garbage collection (GC) has become an important field of research. It aims to speed up and optimize the execution of applications developed in languages such as Java, C#, Python and others. Even though GC techniques have become more sophisticated, automatic memory management is not optimal. Garbage collection techniques, such as reference counting, mark-sweep, mark-compact, copying collection and generational garbage collection build the base of most automated memory management environments. Most GC policies include a stop-the-world phase that is used to detect live objects.The research presented in this paper aims to improve the automatic memory management and application execution by investigating an optimization of the memory layout. The goal of the approach described is to utilize the stop-the-world phase of the garbage collector in order to detect duplicate strings and to deduplicate them before copying them to a different region. The goal of this algorithm is to reduce memory duplication, as well as copying of memory, in order to decrease the heap size and therefore the number of garbage collections required to execute the client application.", "references": ["S. M. Blackburn, R. Garner, C. Hoffmann, A. M. Khang, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, et al. The DaCapo benchmarks: Java benchmarking development and analysis. In ACM Sigplan Notices, volume 41, pages 169--190. ACM, 2006.", "C. J. Cheney. A nonrecursive list compacting algorithm. Communications of the ACM, 13(11):677--678, 1970.", "G. E. Collins. A method for overlapping and erasure of lists. Communications of the ACM, 3(12):655--657, 1960."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3049877.3049904"}, {"title": "Information Retrieval Behaviors among EBM Practitioners when performing Evidence Based Medicine", "authors": ["Vinesha Selvarajah"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThis paper reveals the preliminary analysis of how EBM practitioners retrieve EBM related information during their clinical rounds at a public teaching hospital in Malaysia. We focused on studying EBM practitioners' searching behaviors during EBM process. However, in this paper we only present analysis for query issuing pattern and result viewing behavior of the retrieval process. We collected our preliminary data using Morae's Key-Logging software that captures participants' information searching behavior. We recorded 30 preliminary search sessions via convenience sampling and analyzed our data using descriptive statistics. Our findings indicate that 90% of the search sessions successfully returned results that the participants searched for. Among the queries issued, 24.47% were ineffective queries. Result viewing behaviors revealed 56 online sources were clicked where 33.33% belonged to PubMed, Medscape and UpToDate. Our result shows higher average query length and the number of medical terms used in queries compared to previous studies. We also found that result viewing behavior using multiple tabs confuses the participants and are more likely to cause overlooking of online resources on some of the opened tabs. The outcome of our study leads to better initiatives on query issuing and result viewing strategies for EBM related searches to improve the EBM process among practitioners.", "references": ["Boruff, J.T. and Storie, D., 2014. Mobile devices in medicine: a survey of how medical students, residents, and faculty use smartphones and other mobile devices to find information. Journal of the Medical Library Association : JMLA 102, 1 (02//received08//accepted), 22--30. DOI= http://dx.doi.org/10.3163/1536-050.102.1.006.", "Chinnock, P., Siegfried, N., and Clarke, M., 2005. Is Evidence-Based Medicine Relevant to the Developing World? PLoS Med 2, 5, e107. DOI= http://dx.doi.org/10.1371/journal.pmed.0020107.", "Dans, A.L. and Dans, L.F., 2000. The need and means for evidence-based medicine in developing countries. Evidence Based Medicine 5, 4 (July 1, 2000), 100--101. DOI= http://dx.doi.org/10.1136/ebm.5.4.100."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854949"}, {"title": "An Eye-Tracking Study: Implication to Implicit Critiquing Feedback Elicitation in Recommender Systems", "authors": ["Li Chen\n,", "Feng Wang"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThe critiquing-based recommender system (CBRS) stimulates users to critique the recommended item in terms of its attribute values. It has been shown that such critiquing feedback can effectively improve users' decision quality, especially in complex decision environments such as e-commerce, tourism, and finance. However, because its explicit elicitation process unavoidably demands extra user efforts, the application in real situations is limited. In this paper, we report an eye-tracking experiment with the objective of studying the relationship between users' eye gazes as laid on recommended items and their critiquing feedback. The results indicate the feasibility of inferring users' feedback based on their eye movements. It hence points out a promising roadmap to developing unobtrusive eye-based feedback elicitation for recommender systems.", "references": ["R. D. Burke, K. J. Hammond, and B. Young. The FindMe approach to assisted browsing. IEEE Expert: Intelligent Systems and Their Applications, 12(4):32--40, July 1997.", "S. Castagnos, N. Jones, and P. Pu. Eye-tracking product recommenders' usage. In Proceedings of the 4th ACM Conference on Recommender Systems, RecSys '10, pages 29--36. ACM, 2010.", "L. Chen. User Decision Improvement and Trust Building in Product Recommender Systems. PhD thesis, Ecole Polytechnique Federale De Lausanne (EPFL), Lausanne, Switzerland, August 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930286"}, {"title": "Fast and adaptive indexing of multi-dimensional observational data", "authors": ["Sheng Wang\n,", "David Maier\n,", "Beng Chin Ooi"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nSensing devices generate tremendous amounts of data each day, which include large quantities of multi-dimensional measurements. These data are expected to be immediately available for real-time analytics as they are streamed into storage. Such scenarios pose challenges to state-of-the-art indexing methods, as they must not only support efficient queries but also frequent updates. We propose here a novel indexing method that ingests multi-dimensional observational data in real time. This method primarily guarantees extremely high throughput for data ingestion, while it can be continuously refined in the background to improve query efficiency. Instead of representing collections of points using Minimal Bounding Boxes as in conventional indexes, we model sets of successive points as line segments in hyperspaces, by exploiting the intrinsic value continuity in observational data. This representation reduces the number of index entries and drastically reduces \"over-coverage\" by entries. Experimental results show that our approach handles real-world workloads gracefully, providing both low-overhead indexing and excellent query efficiency.", "references": ["S. Alsubaiee, A. Behm, V. Borkar, Z. Heilbron, Y. Kim, M. J. Carey, M. Dreseler, and C. Li. Storage management in AsterixDB. Proc. of VLDB Endow., 7(10), June 2014.", "A. M. Baptista et al. Infrastructure for collaborative science and societal applications in the columbia river estuary. Frontiers of Earth Science, 2015.", "N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. The R*-tree: an efficient and robust access method for points and rectangles. SIGMOD Rec., 19(2), May 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007328.3007334"}, {"title": "Explaining Reviews and Ratings with PACO: Poisson Additive Co-Clustering", "authors": ["Chao-Yuan Wu\n,", "Alex Beutel\n,", "Amr Ahmed\n,", "Alexander J. Smola"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nUnderstanding a user's motivations provides valuable information beyond the ability to recommend items. Quite often this can be accomplished by perusing both ratings and review texts. Unfortunately matrix factorization approaches to recommendation result in large, complex models that are difficult to interpret. In this paper, we attack this problem through succinct additive co-clustering on both ratings and reviews. Our model yields accurate and interpretable recommendations.", "references": ["A. Beutel, A. Ahmed, and A. J. Smola. ACCAMS: Additive Co-Clustering to Approximate Matrices Succinctly. In World Wide Web, pages 119--129, 2015.", "Q. Diao, M. Qiu, C.-Y. Wu, A. J. Smola, J. Jiang, and C. Wang. Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars). In Knowledge Discovery and Data Mining, pages 193--202. ACM, 2014.", "J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. In ACM Recommender Systems, pages 165--172. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889400"}, {"title": "ActivePointers: a case for software address translation on GPUs", "authors": ["Sagi Shahar\n,", "Shai Bergman\n,", "Mark Silberstein"], "publication": "ISCA '16: Proceedings of the 43rd International Symposium on Computer Architecture", "abstract": "ABSTRACT\nModern discrete GPUs have been the processors of choice for accelerating compute-intensive applications, but using them in large-scale data processing is extremely challenging. Unfortunately, they do not provide important I/O abstractions long established in the CPU context, such as memory mapped files, which shield programmers from the complexity of buffer and I/O device management. However, implementing these abstractions on GPUs poses a problem: the limited GPU virtual memory system provides no address space management and page fault handling mechanisms to GPU developers, and does not allow modifications to memory mappings for running GPU programs.\nWe implement ActivePointers, a software address translation layer and paging system that introduces native support for page faults and virtual address space management to GPU programs, and enables the implementation of fully functional memory mapped files on commodity GPUs. Files mapped into GPU memory are accessed using active pointers, which behave like regular pointers but access the GPU page cache under the hood, and trigger page faults which are handled on the GPU. We design and evaluate a number of novel mechanisms, including a translation cache in hardware registers and translation aggregation for deadlock-free page fault handling of threads in a single warp.\nWe extensively evaluate ActivePointers on commodity NVIDIA GPUs using microbenchmarks, and also implement a complex image processing application that constructs a photo collage from a subset of 10 million images stored in a 40GB file. The GPU implementation maps the entire file into GPU memory and accesses it via active pointers. The use of active pointers adds only up to 1% to the application's runtime, while enabling speedups of up to 3.9× over a combined CPU+GPU implementation and 2.6× over a 12-core CPU-only implementation which uses AVX vector instructions.", "references": ["M. Silberstein, B. Ford, I. Keidar, and E. Witchel, \"GPUfs: integrating file systems with GPUs,\" in ASPLOS'13. ACM, 2013.", "S. Kim, S. Huh, X. Z. Yige Hu, A. Wated, E. Witchel, and M. Silberstein, \"GPUnet: Networking Abstractions for GPU Programs,\" in OSDI'14. USENIX, 2014, pp. 6--8.", "GPUDirect, \"GPUDirect RDMA,\" http://docs.nvidia.com/cuda/gpudirect-rdma/index.html, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/ISCA.2016.58"}, {"title": "Enhancing First Story Detection using Word Embeddings", "authors": ["Sean Moran\n,", "Richard McCreadie\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we show how word embeddings can be used to increase the effectiveness of a state-of-the art Locality Sensitive Hashing (LSH) based first story detection (FSD) system over a standard tweet corpus. Vocabulary mismatch, in which related tweets use different words, is a serious hindrance to the effectiveness of a modern FSD system. In this case, a tweet could be flagged as a first story even if a related tweet, which uses different but synonymous words, was already returned as a first story. In this work, we propose a novel approach to mitigate this problem of lexical variation, based on tweet expansion. In particular, we propose to expand tweets with semantically related paraphrases identified via automatically mined word embeddings over a background tweet corpus. Through experimentation on a large data stream comprised of 50 million tweets, we show that FSD effectiveness can be improved by 9.5% over a state-of-the-art FSD system.", "references": ["J. Fiscus Overview of of the TDT 2001 evaluation and results. In Proc. TDT, 2001.", "J. Allan. Introduction to topic detection and tracking. In Proc. TDT, 2002.", "C. Callison-Burch Syntactic constraints onparaphrases extracted from parallel corpora. In Proc. EMNLP, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914719"}, {"title": "Desiderata for Exploratory Search Interfaces to Web Archives in Support of Scholarly Activities", "authors": ["Andrew Jackson\n,", "Jimmy Lin\n,", "Ian Milligan\n,", "Nick Ruest"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWeb archiving initiatives around the world capture ephemeral web content to preserve our collective digital memory. In this paper, we describe initial experiences in providing an exploratory search interface to web archives for humanities scholars and social scientists. We describe our initial implementation and discuss our findings in terms of desiderata for such a system. It is clear that the standard organization of a search engine results page (SERP), consisting of an ordered list of hits, is inadequate to support the needs of scholars. Shneiderman's mantra for visual information seeking (\"overview first, zoom and filter, then details-on-demand\") provides a nice organizing principle for interface design, to which we propose an addendum: \"Make everything transparent\". We elaborate on this by highlighting the importance of the temporal dimension of web pages as well as issues surrounding metadata and veracity.", "references": ["Y. AlNoamany, M. Weigle, and M. Nelson. Access patterns for robots and humans in web archives. JCDL, 2013.", "K. Berberich, S. Bedathur, T. Neumann, and G. Weikum. A time machine for text search. SIGIR, 2007.", "G. Buchanan, S. J. Cunningham, A. Blandford, J. Rimmer, and C. Warwick. Information seeking by humanities scholars. ECDL, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910912"}, {"title": "Experimental evaluation of method for driving route recommendation and learning drivers' route selection preferences", "authors": ["Keisuke Hamada\n,", "Shinsuke Nakajima\n,", "Daisuke Kitayama\n,", "Kazutoshi Sumiya"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nRecent years have witnessed a rapid increase in the use of car navigation systems, which provide drivers with directions to their destinations. However, such systems do not always recommend a route that perfectly matches a driver's intent. Even when drivers intentionally change the driving route from the recommended one to another, most car navigation systems keep recommending or lead them back to the original recommended route. Such recommendations may not adequately reflect a driver's intent. We previously proposed a route recommendation method based on the estimation of a driver's intent by comparing the characteristics of a route selected by a driver and a route not selected by the driver but recommended by the car navigation system. In this study, we propose a method that can consider multiple costs and learn a driver's concept of the values for each cost; in brief, it represents an effective method for learning drivers' route selection preferences. In addition, we describe experimental evaluation results of our proposed method for driving route recommendations and learning drivers' route selection preferences.", "references": ["Road Bureau of Ministry of Land, Infrastructure, Transport and Tourism: \"Shipments of car navigation system and VICS\", 2015.", "National Center for Industrial Property Information and Training: \"Route search technology by car navigation system\", 2005.", "S. Nakajima, S. Kinoshita, and K. Tanaka: \"Amplifying the Differences between Your Positive Samples and Neighbors\", IEEE International Conference on Multimedia & EXPO (ICME2003) vol. I, pp. 441--444, July 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011150"}, {"title": "Streaming of Kinect Data for Interactive In-Browser Audio Performances", "authors": ["Emmanouil Potetsianakis\n,", "Jean Le Feuvre"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nDistributed audio applications typically follow a server-client model, in which the server produces an audio stream that is sent to the client for consumption. Then, if any modification of the content is needed, it is a product of audio post-processing on the client side, which is computationally expensive. We tackle these challenges by separating the creative (input), from the sound processing (output) part. As a result, the application becomes lightweight in networking and computational metrics, while an extra level of control over the final output is added on the client. In order to demonstrate our solution, we present the architecture of a sample audio application that supports visualizations and uses Kinect as a controller.", "references": ["Paul Adenot, Chris Wilson, and Chris Rogers. 2013. Web Audio API. W3C, October 10 (2013).", "Demosthenes Akoumianakis, George Vellis, Ioannis Milolidakis, Dimitrios Kotsalis, and Chrisoula Alexandraki. 2008. Distributed Collective Practices in Collaborative Music Performance. In Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts. ACM, 368--375.", "Cyril Concolato, Jean Le Feuvre, and Romain Bouqueau. 2011. Usages of DASH for Rich Media Services. In Proceedings of the Second Annual ACM Conference on Multimedia Systems (MMSys '11). ACM, New York, NY, USA, 265--270. DOI: http://dx.doi.org/10.1145/1943552.1943587"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986438"}, {"title": "Continuous Experience-aware Language Model", "authors": ["Subhabrata Mukherjee\n,", "Stephan Günnemann\n,", "Gerhard Weikum"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nOnline review communities are dynamic as users join and leave, adopt new vocabulary, and adapt to evolving trends. Recent work has shown that recommender systems benefit from explicit consideration of user experience. However, prior work assumes a fixed number of discrete experience levels, whereas in reality users gain experience and mature continuously over time. This paper presents a new model that captures the continuous evolution of user experience, and the resulting language model in reviews and other posts. Our model is unsupervised and combines principles of Geometric Brownian Motion, Brownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal progression of user experience and language model respectively. We develop practical algorithms for estimating the model parameters from data and for inference with our model (e.g., to recommend items). Extensive experiments with five real-world datasets show that our model not only fits data better than discrete-model baselines, but also outperforms state-of-the-art methods for predicting item ratings.", "references": ["David M. Blei and John D. Lafferty. Dynamic topic models. ICML '06, 2006.", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3, 2003.", "Cristian Danescu-Niculescu-Mizil, Robert West, Dan Jurafsky, Jure Leskovec, and Christopher Potts. No country for old members: User lifecycle and linguistic change in online communities. WWW, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939780"}, {"title": "Exploiting the Bipartite Structure of Entity Grids for Document Coherence and Retrieval", "authors": ["Christina Lioma\n,", "Fabien Tarissan\n,", "Jakob Grue Simonsen\n,", "Casper Petersen\n,", "Birger Larsen"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nDocument coherence describes how much sense text makes in terms of its logical organisation and discourse flow. Even though coherence is a relatively difficult notion to quantify precisely, it can be approximated automatically. This type of coherence modelling is not only interesting in itself, but also useful for a number of other text processing tasks, including Information Retrieval (IR), where adjusting the ranking of documents according to both their relevance and their coherence has been shown to increase retrieval effectiveness [37].\nThe state of the art in unsupervised coherence modelling represents documents as bipartite graphs of sentences and discourse entities, and then projects these bipartite graphs into one--mode undirected graphs. However, one--mode projections may incur significant loss of the information present in the original bipartite structure. To address this we present three novel graph metrics that compute document coherence on the original bipartite graph of sentences and entities. Evaluation on standard settings shows that: (i) one of our coherence metrics beats the state of the art in terms of coherence accuracy; and (ii) all three of our coherence metrics improve retrieval effectiveness because, as closer analysis reveals, they capture aspects of document quality that go undetected by both keyword-based standard ranking and by spam filtering. This work contributes document coherence metrics that are theoretically principled, parameter-free, and useful to IR.", "references": ["R. Barzilay and M. Lapata. Modeling local coherence: An entity-based approach. ACL, 34(1):1--34, 2008.", "R. Barzilay and L. Lee. Catching the drift: Probabilistic content models, with applications to generation and summarization. In HLT-NAACL, pages 113--120, 2004.", "S. M. Beitzel, O. Frieder, E. C. Jensen, D. Grossman, A. Chowdhury, and N. Goharian. Disproving the fusion hypothesis. In SAC, pages 823--827, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970413"}, {"title": "A Unified Index for Spatio-Temporal Keyword Queries", "authors": ["Tuan-Anh Hoang-Vu\n,", "Huy T. Vo\n,", "Juliana Freire"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nFrom tweets to urban data sets, there has been an explosion in the volume of textual data that is associated with both temporal and spatial components. Efficiently evaluating queries over these data is challenging. Previous approaches have focused on the spatial aspect. Some used separate indices for space and text, thus incurring the overhead of storing separate indices and joining their results. Others proposed a combined index that either inserts terms into a spatial structure or adds a spatial structure to an inverted index. These benefit queries with highly-selective constraints that match the primary index structure but have limited effectiveness and pruning power otherwise. We propose a new indexing strategy that uniformly handles text, space and time in a single structure, and is thus able to efficiently evaluate queries that combine keywords with spatial and temporal constraints. We present a detailed experimental evaluation using real data sets which shows that not only our index attains substantially lower query processing times, but it can also be constructed in a fraction of the time required by state-of-the-art approaches.", "references": ["Lucene. http://lucene.apache.org, 2014.", "nanoflann: Approximate Nearest Neighbor. https://code.google.com/p/nanoflann/, 2014.", "Spatial C++ Library. http://spatial.sourceforge.net, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983751"}, {"title": "Nonlinear Composite Search Results", "authors": ["Horatiu Bota"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nModern search engines aggregate information from a variety of sources (e.g. images, videos) and return this information to users, merged into a single results page. Various novel interface elements have been added to the results page to help users access diverse content, from interactive aggregated search blocks to contextual entity cards. These novel elements merge various types of media into coherent objects displayed on the results page. We define these elements as composite search results and study methods to construct them, as well as their effect on user search behaviour. Our findings suggest that result composition can be an effective search paradigm and that nonlinear composite results can positively impact search behaviour in certain contexts.", "references": ["S. Amer-Yahia, F. Bonchi, C. Castillo, E. Feuerstein, I. Méndez-Díaz, and P. Zabala. Complexity and algorithms for composite retrieval. In Proceedings of the 22nd international conference on World Wide Web companion, pages 79--80. International World Wide Web Conferences Steering Committee, 2013.", "J. Arguello and R. Capra. The effect of aggregated search coherence on search behavior. ACM CIKM '12, pages 1293--1302.", "J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. ACM CIKM '14, pages 539--548, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854956"}, {"title": "\"Searching for inspiration\": user needs and search architecture in europeana collections", "authors": ["Timothy Hill\n,", "Valentine Charles\n,", "Juliane Stiller\n,", "Antoine Isaac"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nDrawing upon research and current development work at Europeana, this paper discusses search functionality in the Cultural Heritage sector, focusing in particular on the question of 'inspiration-oriented' search, in which users seek out previously-unknown items to serve as creative stimulus. Inspiration-oriented search is identified as a variant of the more widely-studied problem of serendipitous retrieval, and defined as an information-seeking behavior in which users consciously search for items that are related to known items in ways that are recognizable once seen, but that are nevertheless unpredictable at search-time. Various strategies for the maximization of both the recognisability and unpredictability of related items are then described, including user-interface and user-experience changes and the reconceptualization of datastores as knowledge graphs. Directions for further research are then outlined - including, most importantly, possible metrics for inspiration-oriented search and their potential for use in machine-learning ranking frameworks.", "references": ["Apache Software Foundation (2016), \"MoreLikeThis\". In Apache Solr Reference Guide, retrieved 2016.04.15 from https://cwiki.apache.org/confluence/display/solr/MoreLikeThis.", "Arts Council of Northern Ireland (2014), \"Museums and Creative Industries join forces\", retrieved 2016.04.15 from http://www.artscouncil-ni.org/news/museums-and-creativeindustries-join-forces.", "Bates, M. J. (1989), The design of browsing and berrypicking techniques for the online search interface. Online Review, 13 (5), 407--431."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017490"}, {"title": "Identifying Careless Workers in Crowdsourcing Platforms: A Game Theory Approach", "authors": ["Yashar Moshfeghi\n,", "Alvaro F. Huertas-Rosero\n,", "Joemon M. Jose"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we introduce a game scenario for crowdsourcing (CS) using incentives as a bait for careless (gambler) workers, who respond to them in a characteristic way. We hypothesise that careless workers are risk-inclined and can be detected in the game scenario by their use of time, and test this hypothesis in two steps: first, we formulate and prove a theorem stating that a risk-inclined worker will react to competition with shorter Task Completion Time (TCT) than a risk-neutral or risk-averse worker. Second, we check if the game scenario introduces a link between TCT and performance, by performing a crowdsourced evaluation using 35 topics from the TREC-8 collection. Experimental evidence confirms our hypothesis, showing that TCT can be used as a powerful discrimination factor to detect careless workers. This is a valuable result in the quest for quality assurance in CS-based micro tasks such as relevance assessment.", "references": ["O. Alonso. Implementing crowdsourcing-based relevance experimentation: an industrial perspective. Inf. Retr., pages 1--20, 2013.", "B. Carterette and I. Soboroff. The Effect of Assessor Error on IR System Evaluation. In SIGIR '10, pages 539--546, 2010.", "C. Eickhoff, C. G. Harris, A. P. de Vries, and P. Srinivasan. Quality through flow and immersion: gamifying crowdsourced relevance assessments. In SIGIR '12, pages 871--880, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914756"}, {"title": "A system for region search and exploration", "authors": ["Kaiyu Feng\n,", "Kaiqi Zhao\n,", "Yiding Liu\n,", "Gao Cong"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith the increasing popularity of mobile devices and location based services, massive amount of geo-textual data (e.g., geo-tagged tweets) is being generated everyday. Compared with traditional spatial data, the textual dimension of geo-textual data greatly enriches the data. Meanwhile, the spatial dimension of geo-textual data also adds a semantically rich new aspect to textual data. The large volume, together with its rich semantics, calls for the need for data exploration. First, it has many applications to retrieve a region for exploration that satisfies user-specified conditions (e.g., the size and shape of the region) while maximizing some other conditions (e.g., the relevance to the query keywords of the objects in the region). Second, it is useful to mine and explore the topics of the geo-textual data within a (specified or retrieved) region and perhaps a timespan. This demonstration proposal presents the main ideas of our system, the <u>R</u>eg<u>I</u>on <u>S</u>earch and <u>E</u>xploration System (RISE), for efficiently supporting region search and exploration, and our demonstration plan.", "references": ["L. AlSumait, D. Barbar, and C. Domeniconi. On-line lda: Adaptive topic models for mining text streams with applications to topic detection and tracking. In ICDM, pages 3--12, 2008.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "K. Feng, G. Cong, S. S. Bhowmick, W.-C. Peng, and C. Miao. Towards best region search for data exploration. SIGMOD. ACM, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007306"}, {"title": "Parallel Ratio Based CF for Recommendation System", "authors": ["Vishwas Patel\n,", "Mosin Hasan"], "publication": "ICCCNT '16: Proceedings of the 7th International Conference on Computing Communication and Networking Technologies", "abstract": "ABSTRACT\nWith the increase in E-commerce, Recommendation Systems are getting popular to provide recommendations of various items (movies, books, music) to users. To build the Recommendation System (RS), Collaborative Filtering (CF) techniques are proven efficient. From the main two Collaborative Filtering techniques i.e. User-Based and Item-Based, survey suggest that Item-Based CF provides better recommendations. A novel approach, Ratio-Based CF provides recommendation depending upon the item's ratio is more accurate comparatively but face scalability problem. To overcome this problem a parallel approach can be used instead of sequential. Our experiments shows that Ratio Based CF techniques have more accuracy comparatively as well as Parallel (Hadoop) implementation of Ratio Based CF Techniques have drastically reduce the training time (i.e. ratio calculating time between each pair of items) from 90 minutes in Java to 5 minutes in Hadoop for sub-data of MovieLens 100K dataset.", "references": ["Su, Xiaoyuan, and Taghi M. Khoshgoftaar. \"A survey of collaborative filtering techniques.\" Advances in artificial intelligence 2009 (2009): 4.", "Walunj, Sachin Gulabrao, and Kishor Sadafale. \"An online recommendation system for e-commerce based on apache mahout framework.\" InProceedings of the 2013 annual conference on Computers and people research, pp. 153--158. ACM, 2013.", "Chen, DanEr. \"The collaborative filtering recommendation algorithm based on BP neural networks.\" In Intelligent Ubiquitous Computing and Education, 2009 International Symposium on, pp. 234--236. IEEE, 2009.."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967878.2967916"}, {"title": "As Time Goes By: Comprehensive Tagging of Textual Phrases with Temporal Scopes", "authors": ["Erdal Kuzey\n,", "Vinay Setty\n,", "Jannik Strötgen\n,", "Gerhard Weikum"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nTemporal expressions (TempEx's for short) are increasingly important in search, question answering, information extraction, and more. Techniques for identifying and normalizing explicit temporal expressions work well, but are not designed for and cannot cope with textual phrases that denote named events, such as \"Clinton's term as secretary of state\". This paper addresses the problem of detecting such temponyms, inferring their temporal scopes, and mapping them to events in a knowledge base if present there.\nWe present methods for this kind of temponym resolution, using an entity- and TempEx-oriented document model and the Yago knowledge base for distant supervision. We develop a family of Integer Linear Programs for jointly inferring temponym mappings to the timeline and knowledge base. This enriches the document representation and also extends the knowledge base by obtaining new alias names for events. Experiments with three different corpora demonstrate the viability of our methods.", "references": ["O. Alonso, M. Gertz, and R. Baeza-Yates. Enhancing Document Snippets Using Temporal Information. In SPIRE, 2011.", "O. Alonso and K. Khandelwal. Kondenzer: Exploration and Visualization of Archived Social Media. In ICDE, 2014.", "O. Alonso, J. Strötgen, R. Baeza-Yates, and M. Gertz. Temporal Information Retrieval: Challenges and Opportunities. In TWAW, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883055"}, {"title": "Increasing the Trustworthiness of Recommendations by Exploiting Social Media Sources", "authors": ["Catalin-Mihai Barbu"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nCurrent recommender systems mostly do not take into account as well as they might the wealth of information available in social media, thus preventing the user from obtaining a broad and reliable overview of different opinions and ratings on a product. Furthermore, there is a lack of user control over the recommendation process-which is mostly fully automated and does not allow the user to influence the sources and mechanisms by which recommendations are produced-as well as over the presentation of recommended items. Consequently, recommendations are often not transparent to the user, are considered to be less trustworthy, or do not meet the user's situational needs. This work will investigate the theoretical foundations for user-controllable, interactive methods of recommending, will develop techniques that exploit social media data in conjunction with other sources, and will validate the research empirically in the area of e-commerce product recommendations. The methods developed are intended to be applicable in a wide range of recommending and decision support scenarios.", "references": ["Betzalel, N. D., Shapira, B., & Rokach, L. \"Please, not now!\" A model for timing recommendations. In Proc. RecSys '15, ACM (2015), 297--300.", "Bollen, D., Knijnenburg, B. P., Willemsen, M. C., & Graus, M. Understanding choice overload in recommender systems. In Proc. RecSys '10, ACM (2010), 63--70.", "Bostandjiev, S., O'Donovan, J., & Höllerer, T. Tasteweights: a visual interactive hybrid recommender system. In Proc. RecSys '12, ACM (2012), 35--42."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959104"}, {"title": "ConnectUP: An Academic Social Networking Application Developed Using University Ontology", "authors": ["Ricardo Pablo de Leon\n,", "Michelle Ann Nazario\n,", "Ma. Rowena Solamo\n,", "Rommel Feria"], "publication": "SIGITE '16: Proceedings of the 17th Annual Conference on Information Technology Education", "abstract": "ABSTRACT\nConnectUP is the proposed academic social networking application for the University of the Philippines (UP) System. This application may be used by students and employees of UP as an avenue for communication and finding possible collaborators with regards to their fields and topics of interest for their works. The application has been subjected to a user acceptance test, which has rendered generally positive feedback from respondents and given such, the researchers deem that ConnectUP is ready for operational use.", "references": ["Sang-Kyun Kim, Jeong-Min Han, and Mi-Young Song. A social network system based on an Ontology in the Korea Institute of Oriental Medicine. Lecture Notes in Computer Science Recent Trends and Developments in Social Software, pages 46--51, 2010.", "Lehigh University Benchmark Ontology. http://swat.cse.lehigh.edu/onto/univ-bench.owl. (Accessed on 06/10/2016).", "Usability evaluation checklist for web sites. http://infodesign.com.au/wp-content/uploads/WebCheck.pdf."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2978192.2978246"}, {"title": "AceMap: A Novel Approach towards Displaying Relationship among Academic Literatures", "authors": ["Zhaowei Tan\n,", "Changfeng Liu\n,", "Yuning Mao\n,", "Yunqi Guo\n,", "Jiaming Shen\n,", "Xinbing Wang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nA large number of papers are being published every year, which makes it difficult for researchers to grasp the relationship among the scientific literatures and the big picture of academic fields. The new challenges have thus been raised, such as analyzing the complicated citation and author network, mining valuable scientific knowledge, and visualizing big scholarly data. The existing academic systems, such as Google Scholar and DBLP have mainly adopted text-based methods, while some other systems make attempts to better navigate the literatures, for example, AMiner and Science Navigation Map. Although these systems show improvements, they fail to present the academic data in a holistic way, and also have limited functions. Therefore, we need to develop new tools which can realize more modules and further explore the academic literatures.\nIn this paper, we conceptualize and design a novel academic system, AceMap, to analyze the big scholarly data and present the results through a ``map'' approach. AceMap integrates several algorithms in the field of network analysis and data mining, and then displays the information in a clear and intuitive way, aiming to help the researchers facilitate their work. After describing the big picture, we present achieved results and our work in progress. By far, AceMap has implemented the following functions: dynamic citation network display, paper clustering, academic genealogy, author and conference homepage, etc. We have also designed and performed distributed network analysis algorithms in a cutting-edge Spark system and utilized modern visualization tools to present the results. Finally, we conclude our paper by proposing the future outlooks.", "references": ["Apache solr. http://lucene.apache.org/solr/. The Apache Software Foundation.", "Apache spark. http://spark.apache.org/. The Apache Software Foundation.", "D3.js. http://d3js.org/. Mike Bostock."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890514"}, {"title": "The Effect of Embodied Interaction in Visual-Spatial Navigation", "authors": ["Ting Zhang\n,", "Yu-Ting Li\n,", "Juan P. Wachs"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nThis article aims to assess the effect of embodied interaction on attention during the process of solving spatio-visual navigation problems. It presents a method that links operator's physical interaction, feedback, and attention. Attention is inferred through networks called Bayesian Attentional Networks (BANs). BANs are structures that describe cause-effect relationship between attention and physical action. Then, a utility function is used to determine the best combination of interaction modalities and feedback. Experiments involving five physical interaction modalities (vision-based gesture interaction, glove-based gesture interaction, speech, feet, and body stance) and two feedback modalities (visual and sound) are described. The main findings are: (i) physical expressions have an effect in the quality of the solutions to spatial navigation problems; (ii) the combination of feet gestures with visual feedback provides the best task performance.", "references": ["Lisa Aziz-Zadeh, Stephen M. Wilson, Giacomo Rizzolatti, and Marco Iacoboni. 2006. Congruent embodied representations for visually presented actions and linguistic phrases describing actions. Curr. Biol. CB 16, 18 (September 2006), 1818--1823.", "Pierre Baldi and Søren Brunak. 2001. Bioinformatics: The Machine Learning Approach, MIT Press.", "Pierre Baldi and Anthony D. Long. 2001. A Bayesian framework for the analysis of microarray expression data: regularized t-test and statistical inferences of gene changes. Bioinformatics 17, 6 (June 2001), 509--519."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2953887"}, {"title": "Estimating Retrieval Performance Bound for Single Term Queries", "authors": ["Peilin Yang\n,", "Hui Fang"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nVarious information retrieval models have been studied for decades. Most traditional retrieval models are based on bag-of-termrepresentations, and they model the relevance based on various collection statistics. Despite these efforts, it seems that the performance of \"bag-of-term\" based retrieval functions has reached plateau, and it becomes increasingly difficult to further improve the retrieval performance. Thus, one important research question is whether we can provide any theoretical justifications on the empirical performance bound of basic retrieval functions.\nIn this paper, we start with single term queries, and aim to estimate the performance bound of retrieval functions that leverage only basic ranking signals such as document term frequency, inverse document frequency and document length normalization. Specifically, we demonstrate that, when only single-term queries are considered, there is a general function that can cover many basic retrieval functions. We then propose to estimate the upper bound performance of this function by applying a cost/gain analysis to search for the optimal value of the function.", "references": ["C. Burges, R. Ragno, and Q. Le. Learning to rank with non-smooth cost functions. In Advances in Neural Information Processing Systems 19. MIT Press, Cambridge, MA, January 2007.", "C. J. Burges. From ranknet to lambdarank to lambdamart: An overview. Technical Report MSR-TR-2010-82, June 2010.", "P. Donmez, K. M. Svore, and C. J. Burges. On the local optimality of lambdarank. In SIGIR. Association for Computing Machinery, Inc., July 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970428"}, {"title": "Developing Benchmarks: The Importance of the Process and New Paradigms", "authors": ["Roeland J.F. Ordelman"], "publication": "MMCommons '16: Proceedings of the 2016 ACM Workshop on Multimedia COMMONS", "abstract": "ABSTRACT\nThe value and importance of Benchmark Evaluations is widely acknowledged. Benchmarks play a key role in many research projects. It takes time, a well-balanced team of domain specialists preferably with links to the user community and industry, and a strong involvement of the research community itself to establish a sound evaluation framework that includes (annotated) data sets, well-defined tasks that reflect the needs in the 'real world', a proper evaluation methodology, ground-truth, including a strategy for repetitive assessments, and last but not least, funding. Although the benefits of an evaluation framework are typically reviewed from a perspective of 'research output' --e.g., a scientific publication demonstrating an advance of a certain methodology-- it is important to be aware of the value of the process of creating a benchmark itself: it increases significantly the understanding of the problem we want to address and as a consequence also the impact of the evaluation outcomes. In this talk I will overview the history of a series of tasks focusing on audiovisual search emphasizing its 'multimodal' aspects, starting in 2006 with the workshop on 'Searching Spontaneous Conversational Speech' that led to tasks in CLEF and MediaEval (\"Search and Hyperlinking\"), and recently also TRECVid (\"Video Hyperlinking\"). The focus of my talk will be on the process rather than on the results of these evaluations themselves, and will address cross-benchmark connections, and new benchmark paradigms, specifically the integration of benchmarking in industrial 'living labs' that are becoming popular in some domains.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983554.2983562"}, {"title": "THUMP: Semantic Analysis on Trajectory Traces to Explore Human Movement Pattern", "authors": ["Shreya Ghosh\n,", "Soumya K. Ghosh"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nExploring human movement pattern from raw GPS traces is an interesting and challenging task. This paper aims at analysing a large volume of GPS data in spatio-temporal context, clustering trajectories using geographic and semantic location information and identifying different categories of people. It tries to exploit the fact that human moves with an intent. The proposed framework yields encouraging results using a large scale GPS dataset of Microsoft GeoLife.", "references": ["S. Shang, R. Ding, K. Zheng, C. S. Jensen, P. Kalnis, and X. Zhou. Personalized trajectory matching in spatial networks. In The VLDB Journal, The International Journal on Very Large Data Bases, 23(3):449--468, 2014.", "Y. Zheng, L. Zhang, X. Xie, and W.-Y. Ma. Mining interesting locations and travel sequences from gps trajectories. In Proceedings of the 18th international conference on World wide web, pages 791--800, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2893188"}, {"title": "A Novel Embedding Distortion for Motion Vector-Based Steganography Considering Motion Characteristic, Local Optimality and Statistical Distribution", "authors": ["Peipei Wang\n,", "Hong Zhang\n,", "Yun Cao\n,", "Xianfeng Zhao"], "publication": "IH&MMSec '16: Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security", "abstract": "ABSTRACT\nThis paper presents an effective motion vector (MV)-based steganography to cope with different steganalytic models. The main principle is to define a distortion scale expressing the multi-level embedding impact of MV modification. Three factors including motion characteristic of video content, MV's local optimality and statistical distribution are considered in distortion definition. For every embedding location, the contributions of three factors are dynamically adjusted according to MV's property. Based on the defined distortion function, two layered syndrome-trellis codes (STCs) are utilized to minimize the overall embedding impact in practical embedding implementation. Experimental results demonstrate that the proposed method achieves higher level of security compared with other existing MV-based approaches, especially for high quality videos.", "references": ["F. JORDAN. Proposal of a watermarking technique for hiding/retrieving data in compressed and decompressed video. ISO/IEC Doc. JTC1/SC 29/QWG 11 MPEG 97/M 2281, 1997.", "Changyong Xu, Xijian Ping, and Tao Zhang. Steganography in compressed video stream. In Innovative Computing, Information and Control, 2006. ICICIC '06. First International Conference on, volume 1, pages 269--272, Aug 2006.", "H.A. Aly. Data hiding in motion vectors of compressed video based on their associated prediction error. Information Forensics and Security, IEEE Transactions on, 6(1):14--18, March 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909827.2930801"}, {"title": "The Effect of Synonym Substitution on Search Results", "authors": ["Michael Antunovic\n,", "Ivan Lee\n,", "Helen Ashman"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nSynonyms or other semantic associations can be used in web search in query substitution to improve or augment the query to retrieve more relevant search results. The value of substitution depends on how well the synonyms preserve semantic meaning, as any attrition in meaning can result in semantic drift of query results. Many synonyms are not synonyms in the traditional, thesaurus sense, but are semantic associations discovered automatically from online data, with the risk of semantic drift in substitution. This discovery of synonyms or other semantic associations arises from different methods applied over web search logs, and in this paper we review the candidate synonym pairs of words or phrases generated from three different methods applied over the same web search logs. The suitability of the candidate synonym pairs for the purpose of query substitution is evaluated in an experiment where 68 subjects assessed the search results generated by both the original query and the substituted query. It was found that two of the discovery methods returned significantly worse results with the substitution than were returned by the original query for the majority of queries, with only around 20-22% of substituted queries generating either improved or equally-relevant results. The third method however returned a very similar level of superior results as the original query, and saw over 71% of substituted queries generating either improved or equally-relevant results. These results indicate that even when candidate synonym pairs are confirmed as being semantically associated using other methods, they still may not be suitable for query substitution, depending on the method of synonym discovery.", "references": ["Michael Antunovic, Glyn Caon, Mark Truran, and Helen Ashman. Discovering semantic associations from web search interactions. In HT '13: Proceedings of the 24th ACM conference on Hypertext and hypermedia. ACM, New York, USA, May 2013.", "S Cucerzan and E Brill. Spelling correction as an iterative process that exploits the collective knowledge of web users. In Proceedings of EMNLP 2004, pages 293--300, July 2004.", "Mirella Lapata and Frank Keller. An Information Retrieval Approach to Sense Ranking. In Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 348--355, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914635"}, {"title": "Real-time sound synthesis for paper material based on geometric analysis", "authors": ["Camille Schreck\n,", "Damien Rohmer\n,", "Doug L. James\n,", "Stefanie Hahmann\n,", "Marie-Paule Cani"], "publication": "SCA '16: Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation", "abstract": "ABSTRACT\nIn this article, we present the first method to generate plausible sounds while animating crumpling virtual paper in real time. Our method handles shape-dependent friction and crumpling sounds which typically occur when manipulating or creasing paper by hand. Based on a run-time geometric analysis of the deforming surface, we identify resonating regions characterizing the sound being produced. Coupled to a fast analysis of the surrounding elements, the sound can be efficiently spatialized to take into account nearby wall or table reflectors. Finally, the sound is synthesized in real time using a pre-recorded database of frequency- and time-domain sound sources. Our synthesized sounds are evaluated by comparing them to recordings for a specific set of paper deformations.", "references": ["{Adr91} Adrien J.-M.: The missing link: Modal synthesis. In Representations of Musical Signals, De Poli G., Piccialli A., Roads C., (Eds.). MIT Press, Cambridge, MA, USA, 1991, pp. 269--298. 2", "{AJM12} An S. S., James D. L., Marschner S.: Motion-driven concatenative synthesis of cloth sounds. ACM Transactions on Graphics (Proc. SIGGRAPH) (2012). 2, 3, 4", "{BDT*08} Bonneel N., Drettakis G., Tsingos N., Viauddelmon I. L., James D.: Fast modal sounds with scalable frequency-domain synthesis. ACM Transactions on Graphics (Proc. SIGGRAPH) 27, 3 (2008). 2"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2982818.2982847"}, {"title": "A semantic security framework and context-aware role-based access control ontology for smart spaces", "authors": ["Shohreh Hosseinzadeh\n,", "Seppo Virtanen\n,", "Natalia Díaz-Rodríguez\n,", "Johan Lilius"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nSmart Spaces are composed of heterogeneous sensors and devices that collect and share information. This information may contain personal information of the users. Thus, securing the data and preserving the privacy are of paramount importance. In this paper, we propose techniques for information security and privacy protection for Smart Spaces based on the Smart-M3 platform. We propose a) a security framework, and b) a context-aware role-based access control scheme. We model our access control scheme using ontological techniques and Web Ontology Language (OWL), and implement it via CLIPS rules. To evaluate the efficiency of our access control scheme, we measure the time it takes to check the access rights of the access requests. The results demonstrate that the highest response time is approximately 0.2 seconds in a set of 100000 triples. We conclude that the proposed access control scheme produces low overhead and is therefore, an efficient approach for Smart Spaces.", "references": ["OWL for Services: http://www.ai.sri.com/daml/services/owls/security.html.", "F. Abel, J. L. De Coi, N. Henze, A. W. Koesling, D. Krause, and D. Olmedilla. Enabling advanced and context-dependent access control in RDF stores. volume 4825 of Lecture Notes in Computer Science, pages 1--14. Springer, 2007.", "S. Al-Rabiaah and J. Al-Muhtadi. ConSec: Context-Aware Security Framework for Smart Spaces. In Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), Sixth International Conference on, pages 580--584, Palermo, 2012. IEEE."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928300"}, {"title": "Topic Set Size Design and Power Analysis in Practice", "authors": ["Tetsuya Sakai"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nTopic set size design methods provide principles and procedures for test collection builders to decide on the number of topics to create. These methods can then help us keep improving the test collection design based on accumulated data. Simple Excel tools are available for such purposes. Post-hoc power analysis tools, available as simple R scripts, can help IR researchers examine the achieved power of a reported experiment and determine future sample sizes for ensuring high power. Thus, for example, underpowered user experiments can be detected, and a larger sample size can be proposed. If used appropriately, these Excel and R tools should be able to provide the IR community with better experimentation practices. The main objective of this tutorial is to let IR researchers familiarise themselves with these tools and understand the basic ideas behind them.", "references": ["Y. Nagata. How to Design the Sample Size (in Japanese). Asakura Shoten, 2003.", "T. Sakai. Information Access Evaluation Methodology: For the Progress of Search Engines (in Japanese). Coronasha, 2015.", "T. Sakai. Topic set size design. Information Retrieval Journal, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970443"}, {"title": "SSD Technology Enables Dynamic Maintenance of Persistent High-Dimensional Indexes", "authors": ["Björn Þór Jónsson\n,", "Laurent Amsaleg\n,", "Herwig Lejsek"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn today's world of ever-increasing multimedia collections, dynamically and persistently maintaining high-dimensional indexes is imperative for industrial applications. Since HDD performance is the main bottleneck in index maintenance, we investigate the impact of SSD technology. We use the NV-tree to drive our analysis, as the only high-dimensional index in the literature which has seriously addressed updates. Our simulation model indicates that an index of 1.5 billion descriptors can be built dynamically on a high-end SSD in just over four hours of disk time, which is more than 500x faster than using a high-end HDD. Relatively small investment in the new SSD technology can thus make dynamic and persistent high-dimensional indexes very feasible.", "references": ["M. Douze, H. Jégou, H. Sandhawalia, L. Amsaleg, and C. Schmid. Evaluation of GIST descriptors for web-scale image search. In Proc. CIVR, Santorini, Greece, 2009.", "H. Jégou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. TPAMI, 33(1), 2011.", "H. Jégou, F. Perronnin, M. Douze, J. Sánchez, P. Pérez, andC. Schmid. Aggregating local image descriptors into compact codes. TPAMI, 34(9), 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912065"}, {"title": "AutoG: a visual query autocompletion framework for graph databases", "authors": ["Peipei Yi\n,", "Byron Choi\n,", "Sourav S Bhowmick\n,", "Jianliang Xu"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nComposing queries is evidently a tedious task. This is particularly true of graph queries as they are typically complex and prone to errors, compounded by the fact that graph schemas can be missing or too loose to be helpful for query formulation. Despite the great success of query formulation aids, in particular, automatic query completion, graph query autocompletion has received much less research attention. In this demonstration, we present a novel interactive visual subgraph query autocompletion framework called AutoG which alleviates the potentially painstaking task of graph query formulation. Specifically, given a large collection of small or medium-sized graphs and a visual query fragment q formulated by a user, AutoG returns top-k query suggestions Q′ as output at interactive time. Users may choose a query from Q′ and iteratively apply AutoG to compose their queries. We demonstrate various features of AutoG and its superior ability to generate high quality suggestions to aid visual subgraph query formulation.", "references": ["W.-S. Han, J. Lee, M.-D. Pham, and J. X. Yu. iGraph: A framework for comparisons of disk-based graph indexing techniques. PVLDB, pages 449--459, 2010.", "M. Herschel, Y. Tzitzikas, K. S. Candan, and A. Marian. Exploratory search: New name for an old hat? http://wp.sigmod.org/?p=1183, 2014.", "H. H. Hung, S. S. Bhowmick, B. Q. Truong, B. Choi, and S. Zhou. QUBLE: blending visual subgraph query formulation with query processing on large networks. In SIGMOD, pages 1097--1100, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007295"}, {"title": "Unified Analysis of Semi-Blind Spectrum Sensing Techniques under Low-SNR for CRNWs", "authors": ["Muhammad Karam Shehzad\n,", "Abbirah Ahmed"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nSpectrum sensing (signal detection) under low signal to noise ratio is a fundamental problem in cognitive radio networks. In this paper, we have analyzed maximum eigenvalue detection (MED) and energy detection (ED) techniques known as semi-blind spectrum sensing techniques. Simulations are performed by using independent and identically distributed (iid) signals to verify the results. Maximum eigenvalue detection algorithm exploits correlation in received signal samples and hence, performs same as energy detection algorithm under high signal to noise ratio. Energy detection performs well under low signal to noise ratio for iid signals and its performance reaches maximum eigenvalue detection under high signal to noise ratio. Both algorithms don't need any prior knowledge of primary user signal for detection and hence can be used in various applications.", "references": ["A. Preet and A. Kaur, \"Review paper on Cognitive Radio Networking and Communications,\" vol. 5, no. 4, pp. 5508--5511, 2014.", "J. Mitola and G. Q. Maguire, \"Cognitive radio: making software radios more personal,\" IEEE Pers. Commun., vol. 6, no. 4, pp. 13--18, 1999.", "Fcc, \"FCC 05-57: Report and Order In the Matter of Facilitating Opportunities for Flexible, Efficient and Reliable Spectrum Use Employing Cognitive Radio Technologies,\" pp. 1--42, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015205"}, {"title": "Learning to Rank with Labeled Features", "authors": ["Fernando Diaz"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nClassic learning to rank algorithms are trained using a set of labeled documents, pairs of documents, or rankings of documents. Unfortunately, in many situations, gathering such labels requires significant overhead in terms of time and money. We present an algorithm for training a learning to rank model using a set of labeled features elicited from system designers or domain experts. Labeled features incorporate a system designer's belief about the correlation between certain features and relative relevance. We demonstrate the efficacy of our model on a public learning to rank dataset. Our results show that we outperform our baselines even when using as little as a single feature label.", "references": ["S. Amershi, M. Chickering, S. M. Drucker, B. Lee, P. Simard, and J. Suh. Modeltracker: Redesigning performance analysis tools for machine learning. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, 2015.", "J. A. Aslam, E. Kanoulas, V. Pavlu, S. Savev, and E. Yilmaz. Document selection methodologies for efficient and effective learning-to-rank. In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2009.", "J. A. Aslam, V. Pavlu, and E. Yilmaz. A statistical method for system evaluation using incomplete judgments. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970435"}, {"title": "G-SQL: fast query processing via graph exploration", "authors": ["Hongbin Ma\n,", "Bin Shao\n,", "Yanghua Xiao\n,", "Liang Jeff Chen\n,", "Haixun Wang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nA lot of real-life data are of graph nature. However, it is not until recently that business begins to exploit data's connectedness for business insights. On the other hand, RDBMSs are a mature technology for data management, but they are not for graph processing. Take graph traversal, a common graph operation for example, it heavily relies on a graph primitive that accesses a given node's neighborhood. We need to join tables following foreign keys to access the nodes in the neighborhood if an RDBMS is used to manage graph data. Graph exploration is a fundamental building block of many graph algorithms. But this simple operation is costly due to a large volume of I/O caused by the massive amount of table joins. In this paper, we present G-SQL, our effort toward the integration of a RDBMS and a native in-memory graph processing engine. G-SQL leverages the fast graph exploration capability provided by the graph engine to answer multi-way join queries. Meanwhile, it uses RDBMSs to provide mature data management functionalities, such as reliable data storage and additional data access methods. Specifically, G-SQL is a SQL dialect augmented with graph exploration functionalities and it dispatches query tasks to the in-memory graph engine and its underlying RDMBS. The G-SQL runtime coordinates the two query processors via a unified cost model to ensure the entire query is processed efficiently. Experimental results show that our approach greatly expands capabilities of RDBMs and delivers exceptional performance for SQL-graph hybrid queries.", "references": ["M. Chen, H. Hsiao, and P. S. Yu. On applying hash filters to improving the execution of multi-join queries. VLDB J., 6(2):121--131, 1997.", "P. S. Yu, M. syan Chen, H. ulrich Heiss, and S. Lee. On workload characterization of relational database environments. IEEE TSE, 18:347--355, 1992.", "M. Pöss, R. O. Nambiar, and D. Walrath. Why you should run TPC-DS: A workload analysis. In VLDB, pages 1138--1149, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2994509.2994510"}, {"title": "Joint Recognition and Linking of Fine-Grained Locations from Tweets", "authors": ["Zongcheng Ji\n,", "Aixin Sun\n,", "Gao Cong\n,", "Jialong Han"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nMany users casually reveal their locations such as restaurants, landmarks, and shops in their tweets. Recognizing such fine-grained locations from tweets and then linking the location mentions to well-defined location profiles (e.g., with formal name, detailed address, and geo-coordinates etc.) offer a tremendous opportunity for many applications. Different from existing solutions which perform location recognition and linking as two sub-tasks sequentially in a pipeline setting, in this paper, we propose a novel joint framework to perform location recognition and location linking simultaneously in a joint search space. We formulate this end-to-end location linking problem as a structured prediction problem and propose a beam-search based algorithm. Based on the concept of multi-view learning, we further enable the algorithm to learn from unlabeled data to alleviate the dearth of labeled data. Extensive experiments are conducted to recognize locations mentioned in tweets and link them to location profiles in Foursquare. Experimental results show that the proposed joint learning algorithm outperforms the state-of-the-art solutions, and learning from unlabeled data improves both the recognition and linking accuracy.", "references": ["S. Abney. Bootstrapping. In ACL, pages 360--367, 2002.", "E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-where: Geotagging Web Content. In SIGIR, pages 273--280, 2004.", "A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In COLT, pages 92--100, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883067"}, {"title": "Measuring semantic distance for linked open data-enabled recommender systems", "authors": ["Guangyuan Piao\n,", "John G. Breslin"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe Linked Open Data (LOD) initiative has been quite successful in terms of publishing and interlinking data on the Web. On top of the huge amount of interconnected data, measuring relatedness between resources and identifying their relatedness could be used for various applications such as LOD-enabled recommender systems. In this paper, we propose various distance measures, on top of the basic concept of Linked Data Semantic Distance (LDSD), for calculating Linked Data semantic distance between resources that can be used in a LOD-enabled recommender system. We evaluated the distance measures in the context of a recommender system that provides the top-N recommendations with baseline methods such as LDSD. Results show that the performance is significantly improved by our proposed distance measures incorporating normalizations that use both of the resources and global appearances of paths in a graph.", "references": ["D. Brickley and R. V. Guha. {RDF vocabulary description language 1.0: RDF schema}. 2004.", "T. Di Noia, I. Cantador, and V. C. Ostuni. Linked open data-enabled recommender systems: ESWC 2014 challenge on book recommendation. In Semantic Web Evaluation Challenge, pages 129--143. Springer, 2014.", "T. Di Noia, R. Mirizzi, V. C. Ostuni, and D. Romito. Exploiting the web of data in model-based recommender systems. In Proceedings of the sixth ACM conference on Recommender systems, pages 253--256. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851839"}, {"title": "A privacy-preserving Proximity Detection Method in social network", "authors": ["Qiuling Chen\n,", "Ayong Ye\n,", "Li Xu"], "publication": "ICC '16: Proceedings of the International Conference on Internet of things and Cloud Computing", "abstract": "ABSTRACT\nProximity detection is a fundamental service in social network. Most of traditional proximity detection methods need users' locations for location server to find their neighbors by calculating relative distance among them. However, this mechanism has caused similarly serious concerns on the potential privacy leakage if server is untrusted. To solve this problem, we propose a proximity detection method which is based on wireless APs (Access Point). Each request user only needs to submit a nearby AP list to social network server, which called SNS in this paper. After that, the SNS finds neighbors of request users by judging whether their nearby AP lists have a common item. In addition, since most existing APs may be uneven distribution and have risks of the location leakage, we also present a distributed Beacon Node Rotating Mechanism---each user acts as a beacon node, which is similar to AP to be a reference of neighbor discovery in proximity detection. Our method works well without requiring user's location information, which enhances the security of location privacy. Finally, we experimentally demonstrate the effectiveness and feasibility of the method.", "references": ["Brandes, U., Pfeffer, J., Mergel, I. 2012. Studying Social Networks: A Guide to Empirical Research, 2012: Campus Verlag Gmbh.", "Viswanath, B., Mislove, A., Cha, M., and Gummadi, K.P. 2009. On the Evolution of User Interaction in Facebook. Proc. Second ACM Workshop Online Social Networks (WOSN '09), pp. 37--42.", "KWAK, H., LEE, C., PARK H, et al. 2010. What is Twitter, a social network or a news media? Proceedings of the 19th International Conference on World Wide Web{C}. Raleigh, NC, USA. 591--600."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896387.2900320"}, {"title": "A personality-based adaptive system for visualizing classical music performances", "authors": ["Markus Schedl\n,", "Mark Melenhorst\n,", "Cynthia C. S. Liem\n,", "Agustín Martorell\n,", "Óscar Mayor\n,", "Marko Tkalčič"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nTo enhance the experience of listening to classical orchestra music, either in the concert hall or at home, we present a personalized system that integrates three visualization/interaction concepts: Score Follower (points to the current position in the score), Orchestra Layout (illustrates instruments that are currently playing and their dynamics), and Structure Visualization (visualizes structural elements such as themes or motifs). Motivated by previous literature that found evidence for connections between personality and music consumption and preference, we first assessed in a user study to which extent personality traits and music visualization preferences correlate. Measuring preference via pragmatic quality and personality traits according to the Big Five Inventory (BFI) questionnaire, we found substantial interconnections between them. These translate into rules relating certain personality traits (e.g., extraversion or agreeableness) to preference rankings of the visualizations.\nIn the proposed personality-based system, users are grouped into four clusters according to their answers to the most significant personality questions determined in the study. The order of the visualizations for a given user is adapted with respect to the ranking preferred by other users in the same cluster. Evaluation of the system was carried out by a second user study that showed a significantly higher normalized discounted cumulative gain (NDCG) for the personalized system in comparison to a system with randomized order of the visualizations.", "references": ["A. Arzt and G. Widmer. Real-time Music Tracking using Multiple Performances as a Reference. In Proceedings of the 16th International Society for Music Information Retrieval Conference (ISMIR), Malaga, Spain, October 2015.", "T. Chamorro-Premuzic and A. Furnham. Personality and Music: Can Traits Explain How People Use Music in Everyday Life? British Journal of Psychology, 98:175--185, May 2007.", "B. Ferwerda, E. Yang, M. Schedl, and M. Tkalčič. Personality Traits Predict Music Taxonomy Preferences. In ACM CHI '15 Extended Abstracts on Human Factors in Computing Systems, Seoul, Republic of Korea, April 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910604"}, {"title": "Modeling clicks using document popularity", "authors": ["Xenophon Evangelopoulos\n,", "Christos Makris"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nIt is commonly believed, that implicit user feedback such as clicks from search logs, can be a strong indicator of user preferences during web search. Moreover, proper click log data analysis can lead to accurate document relevance estimation. As a result, an effective approach to properly interpret users' search behaviour was the development of user click models, designed to reduce position bias and produce more attractive users' search needs.\nHere, in this paper we present a novel click model based on a Bayesian network, for estimating document relevance from click-through data. In contrast with previous works, our model focuses only on the estimation of actual document relevance and not on perceived relevance, which we take to be inferred directly from document popularity. We design the model to be scalable and incremental according to modern computational needs and experiments show that our proposed model achieves better scores in log-likelihood and predicts relevance more accurately than current state-of-the-art.", "references": ["E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, pages 3--10, New York, NY, USA, 2006. ACM.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th International Conference on World Wide Web, WWW '09, pages 1--10, New York, NY, USA, 2009. ACM.", "A. Chuklin, P. Serdyukov, and M. de Rijke. Using intent information to model user behavior in diversified search. In Proceedings of the 35th European Conference on Advances in Information Retrieval, ECIR'13, pages 1--13, Berlin, Heidelberg, 2013. Springer-Verlag."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851691"}, {"title": "Graph-Based Multi-Modality Learning for Clinical Decision Support", "authors": ["Ziwei Zheng\n,", "Xiaojun Wan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe task of clinical decision support (CDS) involves retrieval and ranking of medical journal articles for medical records of diagnosis, test or treatment. Previous studies on this task are based on bag-of-words representations of document texts and general retrieval models. In this paper, we propose to use the paragraph vector technique to learn the latent semantic representation of texts and treat the latent semantic representations and the original bag-of-words representations as two different modalities. We then propose to use the graph-based multi-modality learning algorithm for document re-ranking. Experimental results on two TREC-CDS benchmark datasets demonstrate the excellent performance of our proposed approach.", "references": ["Asma Ben Abacha and Saoussen Khelifi. LIST at TREC 2015 Clinical Decision Support Track: Question Analysis and Unsupervised Result Fusion. In Proceedings of TREC 2015.", "Chengxiang Zhai. Notes on the Lemur TFIDF model. http://www.cs.cmu.edu/~lemur/1.0/tfidf.ps", "D. Zhou, J. Weston, A. Gretton, O. Bousquet and B. SchÖlkopf. Ranking on data manifolds. In Proceedings of NIPS-03."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983880"}, {"title": "RecTour 2016: Workshop on Recommenders in Tourism", "authors": ["Daniel R. Fesenmaier\n,", "Tsvi Kuflik\n,", "Julia Neidhardt"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this paper, we summarize RecTour 2016 -- a workshop on recommenders in tourism co-located with RecSys 2016. There was a great variety of submissions, i.e., research papers, demo papers and position papers, addressing fundamental challenges of recommender systems in the tourism domain. The main topics included group recommendations, context-aware recommenders, choice-based recommenders and event recommendations.", "references": ["Dareddy, M.R., 2016. Challenges in Recommender Systems for Tourism. In Proceedings of RecTour 2016.", "Delic, A., Neidhardt, J., Nguyen, T.N., and F. Ricci, 2016. Research Methods for Group Recommender Systems. In Proceedings of RecTour 2016.", "Donohue, S., Dragovic, N., and Pera, M.S., 2016. Anything Fun Going On? A Simple Wizard to Avoid the Cold-Start Problem for Event Recommenders. In Proceedings of RecTour 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959205"}, {"title": "Web Video Popularity Prediction using Sentiment and Content Visual Features", "authors": ["Giulia Fontanini\n,", "Marco Bertini\n,", "Alberto Del Bimbo"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nHundreds of hours of videos are uploaded every minute on YouTube and other video sharing sites: some will be viewed by millions of people and other will go unnoticed by all but the uploader. In this paper we propose to use visual sentiment and content features to predict the popularity of web videos. The proposed approach outperforms current state-of-the-art methods on two publicly available datasets.", "references": ["Cisco visual networking index: Forecast and methodology, 2014--2019. Technical report, Cisco, 2015.", "Cross-platform video trends roundup. Technical report, eMarketer, 2015.", "Y. Borghol, S. Ardon, N. Carlsson, D. Eager, and A. Mahanti. The untold story of the clones: Content-agnostic factors that impact YouTube video popularity. In Proc. of KDD, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912053"}, {"title": "Interest forwarding in vehicular information centric networks: a survey", "authors": ["Muhammad Azfar Yaqub\n,", "Syed Hassan Ahmed\n,", "Safdar H. Bouk\n,", "Dongkyun Kim"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nVehicular Ad hoc Networks (VANETs) have been providing promising solutions for both the safety and non-safety requirements of 21st century drivers. Since, the number of vehicles are increasing, the current host centric communication approach faces various challenges. On the other hand, the Information Centric Networking (ICN) concept in vehicular communications aims to achieve content retrieval in the dynamic and error prone environment. Recently, the concept Vehicular ICN (VICN), has been explored extensively by researchers, leading to a number of open challenges such as, content naming, name resolution, Interest forwarding strategies, content store, forwarding information base and pending interest table management, security and trust issues, etc. In this paper, we therefore discuss the recent advancements in different VICN approaches with more focus on the Interest forwarding strategies which have been applied during the content retrieval process.", "references": ["S. H. Ahmed, S. H. Bouk, and Dongkyun Kim. 2015. \"Target RSU Selection with Low Scanning Latency in WiMAX-enabled Vehicular Networks\". Mob. Netw. Appl. 20, 2 (April 2015), 239--250.", "D. Cheriton and M. Gritter. \"Triad: A new next-generation internet architecture,\" 2000.", "T. Koponen, M. Chawla, B.-G. Chun, A. Ermolinskiy, K. H. Kim, S. Shenker, and I. Stoica. \"A data-oriented (and beyond) network architecture,\" SIGCOMM Comput. Commun. Rev., 37(4):181--192, Aug. 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851857"}, {"title": "Object injection vulnerability discovery based on latent semantic indexing", "authors": ["Hossain Shahriar\n,", "Hisham Haddad"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nObject Injection Vulnerability (OIV) is an emerging threat for web applications. It involves accepting external inputs during deserialization operation and use the inputs for sensitive operations such as file access, modification, and deletion. The challenge is the automation of the detection process. When the application size is large, it becomes hard to perform traditional approaches such as data flow analysis. Recent approaches fall short of narrowing down the list of source files to aid developers in discovering OIV and the flexibility to check for the presence of OIV through various known APIs. In this work, we address these limitations by exploring a concept borrowed from the information retrieval domain called Latent Semantic Indexing (LSI) to discover OIV. The approach analyzes application source code and builds an initial term document matrix which is then transformed systematically using singular value decomposition to reduce the search space. The approach identifies a small set of documents (source files) that are likely responsible for OIVs. We apply the LSI concept to three open source PHP applications that have been reported to contain OIVs. Our initial evaluation results suggest that the proposed LSI-based approach can identify OIVs and identify new vulnerabilities.", "references": ["E. Romano, PHP Object Injection Vulnerability, https://www.owasp.org/index.php/PHP_Object_Injection", "The Open Web Application Security Project (OWASP) Top 10, www.owasp.org/index.php/Top_10_2013-Top 10, 2013.", "C. Kern, \"Securing the Tangled Web,\" Communications of the ACM, Vol. 57 No. 9, 2014, pp 38--47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851865"}, {"title": "Digesting Multilingual Reader Comments via Latent Discussion Topics with Commonality and Specificity", "authors": ["Bei Shi\n,", "Wai Lam\n,", "Lidong Bing\n,", "Yinqing Xu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMany news websites from different regions in the world allow readers to write comments in their own languages about an event. Digesting such enormous amount of comments in different languages is difficult. One elegant way to digest and organize these comments is to detect latent discussion topics with the consideration of language attributes. Some discussion topics are common topics shared between languages whereas some topics are specifically dominated by a particular language. To tackle this task of discovering discussion topics that exhibit commonality or specificity from news reader comments written in different languages, we propose a new model called TDCS based on graphical models, which can cope with the language gap and detect language-common and language-specific latent discussion topics simultaneously. Our TDCS model also exploits comment-oriented clues via a scalable Dirichlet Multinomial Regression method. To learn the model parameters, we develop an inference method which alternates between EM and Gibbs sampling. Experimental results show that our proposed TDCS model can provide an effective way to digest multilingual news reader comments.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of Machine Learning Research, 3:993--1022, 2003.", "J. Boyd-Graber and D. M. Blei. Multilingual topic models for unaligned text. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, pages 75--82, 2009.", "M. K. Das, T. Bansal, and C. Bhattacharyya. Going beyond corr-lda for detecting specific comments on news & blogs. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining, pages 483--492, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983683"}, {"title": "Affective Computing of Image Emotion Perceptions", "authors": ["Sicheng Zhao"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nNo abstract available.", "references": ["X. Lu, P. Suryanarayan, R. B. Adams Jr, J. Li, M. G. Newman, and J. Z. Wang. On shape and the computability of emotions. In ACM MM, 2012.", "J. Machajdik and A. Hanbury. Affective image classification using features inspired by psychology and art theory. In ACM MM, 2010.", "A. B. Warriner, V. Kuperman, and M. Brysbaert. Norms of valence, arousal, and dominance for 13,915 english lemmas. Behavior Research Methods, 45(4):1191--1207, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855082"}, {"title": "Exploiting Entity Linking in Queries for Entity Retrieval", "authors": ["Faegheh Hasibi\n,", "Krisztian Balog\n,", "Svein Erik Bratsberg"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThe premise of entity retrieval is to better answer search queries by returning specific entities instead of documents. Many queries mention particular entities; recognizing and linking them to the corresponding entry in a knowledge base is known as the task of entity linking in queries. In this paper we make a first attempt at bringing together these two, i.e., leveraging entity annotations of queries in the entity retrieval model. We introduce a new probabilistic component and show how it can be applied on top of any term-based entity retrieval model that can be emulated in the Markov Random Field framework, including language models, sequential dependence models, as well as their fielded variations. Using a standard entity retrieval test collection, we show that our extension brings consistent improvements over all baseline methods, including the current state-of-the-art. We further show that our extension is robust against parameter settings.", "references": ["K. Balog and R. Neumayer. A test collection for entity search in DBpedia. In Proc. of SIGIR, pages 737--740, 2013.", "K. Balog, L. Azzopardi, and M. de Rijke. Formal models for expert finding in enterprise corpora. In Proc. of SIGIR, pages 43--50, 2006.", "K. Balog, A. P. de Vries, P. Serdyukov, P. Thomas, and T. Westerveld. Overview of the TREC 2009 entity track. In Proc. of TREC, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970406"}, {"title": "A Digital World to Thrive In: How the Internet of Things Can Make the \"Invisible Hand\" Work", "authors": ["Dirk Helbing"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nManaging data-rich societies wisely and reaching sustainable development are among the greatest challenges of the 21st century. We are faced with existential threats and huge opportunities. If we don't act now, large parts of our society will not be able to economically benefit from the digital revolution. This could lead to mass unemployment and social unrest. It is time to create the right framework for the digital society to come.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2984749"}, {"title": "Gaze Prediction for Recommender Systems", "authors": ["Qian Zhao\n,", "Shuo Chang\n,", "F. Maxwell Harper\n,", "Joseph A. Konstan"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAs users browse a recommender system, they systematically consider or skip over much of the displayed content. It seems obvious that these eye gaze patterns contain a rich signal concerning these users' preferences. However, because eye tracking data is not available to most recommender systems, these signals are not widely incorporated into personalization models. In this work, we show that it is possible to predict gaze by combining easily-collected user browsing data with eye tracking data from a small number of users in a grid-based recommender interface. Our technique is able to leverage a small amount of eye tracking data to infer gaze patterns for other users. We evaluate our prediction models in MovieLens -- an online movie recommender system. Our results show that incorporating eye tracking data from a small number of users significantly boosts accuracy as compared with only using browsing data, even though the eye-tracked users are different from the testing users (e.g. AUC=0.823 vs. 0.693 in predicting whether a user will fixate on an item). We also demonstrate that Hidden Markov Models (HMMs) can be applied in this setting; they are better than linear models in predicting fixation probability and capturing the interface regularity through Bayesian inference (AUC=0.823 vs. 0.757).", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR'06, pages 19--26. ACM, 2006.", "G. Buscher, E. Cutrell, and M. R. Morris. What do you see when you're surfing?: using eye tracking to predict salient regions of web pages. In CHI'09, pages 21--30. ACM, 2009.", "G. Buscher, L. van Elst, and A. Dengel. Segment-level display time as implicit feedback: a comparison to eye tracking. In SIGIR'09, pages 67--74. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959150"}, {"title": "Message Significance in Multilingual Blogs using Topic-based Aspect Clusters", "authors": ["Kavita S. Asnani\n,", "Jyoti D. Pawar"], "publication": "WIR '16: Proceedings of the ACM Symposium on Women in Research 2016", "abstract": "ABSTRACT\nSocial networking forums like Twitter, Facebook and other blogs are easy to access and are highly popular. The growth in such rich social media content has led to the generation of petabytes of data on the web. The social media content has renewed interest in research as the trend of using multiple languages in routine communication is getting rapidly popular. Such large chat content repositories of multilingual data are usually noisy and are represented in highly sparse structures. This situation is generating increasing interest in automatically extracting and clustering aspects from multi-lingual data. The proposed research offers a novel method based on probabilistic topic model for aspect identification and extraction of aspects (explicit as well as implicit) and aspect clustering for multilingual blog data. The words in multiple languages may randomly occur within and across the blog messages. We have experimentally proved that it is possible to use this strategy to discover aspect clusters comprising of semantically implicit themes. We tested our system using FIRE 2014 dataset.", "references": ["B. Liu. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1--167, 2012.", "Gerard Salton, Anita Wong, and Chung-Shu Yang. A vector space model for automatic indexing. Communications of the ACM, 18(11):613 620, 1975.", "Scott C. Deerwester, Susan T Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. Indexing by latent semantic analysis. JAsIs, 41(6):391 407, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909067.2909096"}, {"title": "WhoLoDancE: Towards a methodology for selecting Motion Capture Data across different Dance Learning Practice", "authors": ["Antonio Camurri\n,", "Katerina El Raheb\n,", "Oshri Even-Zohar\n,", "Yannis Ioannidis\n,", "Amalia Markatzi\n,", "Jean-Marc Matos\n,", "Edwin Morley-Fletcher\n,"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nIn this paper we present the objectives and preliminary work of WhoLoDancE a Research and Innovation Action funded under the European Union's Horizon 2020 programme, aiming at using new technologies for capturing and analyzing dance movement to facilitate whole-body interaction learning experiences for a variety of dance genres. Dance is a diverse and heterogeneous practice and WhoLoDancE will develop a protocol for the creation and/or selection of dance sequences drawn from different dance styles for different teaching and learning modalities. As dance learning practice lacks standardization beyond dance genres and specific schools and techniques, one of the first project challenges is to bring together a variety of dance genres and teaching practices and work towards a methodology for selecting the appropriate shots for motion capturing, to acquire kinetic material which will provide a satisfying proof of concept for Learning scenarios of particular genres. The four use cases we are investigating are 1) classical ballet, 2) contemporary dance, 3) flamenco and 4) Greek folk dance.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948912"}, {"title": "Quark-X: An Efficient Top-K Processing Framework for RDF Quad Stores", "authors": ["Jyoti Leeka\n,", "Srikanta Bedathur\n,", "Debajyoti Bera\n,", "Medha Atre"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThere is a growing trend towards enriching the RDF content from its classical Subject-Predicate-Object triple form to an annotated representation which can model richer relationships such as including fact provenance, fact confidence, higher-order relationships and so on. One of the recommended ways to achieve this is to use reification and represent it as N-Quads \"or simply quads\" where an additional identifier is associated with the entire RDF statement which can then be used to add further annotations. A typical use of such annotations is to have quantifiable confidence values to be attached to facts. In such settings, it is important to support efficient top-k queries, typically over user-defined ranking functions containing sentence level confidence values in addition to other quantifiable values in the database. In this paper, we present Quark-X, an RDF-store and SPARQL processing system for reified RDF data represented in the form of quads. This paper presents the overall architecture of our system -- illustrating the modifications which need to be made to a native quad store for it to process top-k queries. In Quark-X, we propose indexing and query processing techniques for making top-k querying efficient. In addition, we present the results of a comprehensive empirical evaluation of our system over Yago2S and DBpedia datasets. Our performance study shows that the proposed method achieves one to two order of magnitude speed-up over baseline solutions.", "references": ["D. J. Abadi et al. Scalable Semantic Web Data Management using vertical partitioning. In Proc. of VLDB, 2007.", "G. Aluç et al. Diversified Stress Testing of RDF Data Management Systems. In ISWC. 2014.", "C. Bizer et al. DBpedia - A Crystallization Point for the Web of Data. J. Web Sem., 7(3), 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983727"}, {"title": "Heap bounds protection with low fat pointers", "authors": ["Gregory J. Duck\n,", "Roland H. C. Yap"], "publication": "CC 2016: Proceedings of the 25th International Conference on Compiler Construction", "abstract": "ABSTRACT\nHeap buffer overflow (underflow) errors are a common source of security vulnerabilities. One prevention mechanism is to add object bounds meta information and to instrument the program with explicit bounds checks for all memory access. The so-called \"fat pointers\" approach is one method for maintaining and propagating the meta information where native machine pointers are replaced with \"fat\" objects that explicitly store object bounds. Another approach is \"low fat pointers\", which encodes meta information within a native pointer itself, eliminating space overheads and also code compatibility issues. This paper presents a new low-fat pointer encoding that is fully compatible with existing libraries (e.g. pre-compiled libraries unaware of the encoding) and standard hardware (e.g. x86_64). We show that our approach has very low memory overhead, and competitive with existing state-of-the-art bounds instrumentation solutions.", "references": ["P. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy Bounds Checking: An Efficient and Backwards-Compatible Defense Against Out-of-Bounds Errors. In USENIX Security. USENIX, 2009.", "T. Austin, S. Breach, and G. Sohi. Efficient Detection of All Pointer and Array Access Errors. In Programming Language Design and Implementation. ACM, 1994.", "B. Ding, Y. He, Y. Wu, A. Miller, and J. Criswell. Baggy Bounds with Accurate Checking. In Software Reliability Engineering Workshops, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2892208.2892212"}, {"title": "SEL: A Unified Algorithm for Entity Linking and Saliency Detection", "authors": ["Salvatore Trani\n,", "Diego Ceccarelli\n,", "Claudio Lucchese\n,", "Salvatore Orlando\n,", "Raffaele Perego"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nThe Entity Linking task consists in automatically identifying and linking the entities mentioned in a text to their URIs in a given Knowledge Base, e.g., Wikipedia. Entity Linking has a large im- pact in several text analysis and information retrieval related tasks. This task is very challenging due to natural language ambiguity. However, not all the entities mentioned in a document have the same relevance and utility in understanding the topics being dis- cussed. Thus, the related problem of identifying the most relevant entities present in a document, also known as Salient Entities, is attracting increasing interest. In this paper we propose SEL, a novel supervised two-step algo- rithm comprehensively addressing both entity linking and saliency detection. The first step is based on a classifier aimed at identi- fying a set of candidate entities that are likely to be mentioned in the document, thus maximizing the precision of the method with- out hindering its recall. The second step is still based on machine learning, and aims at choosing from the previous set the entities that actually occur in the document. Indeed, we tested two dif- ferent versions of the second step, one aimed at solving only the entity linking task, and the other that, besides detecting linked en- tities, also scores them according to their saliency. Experiments conducted on two different datasets show that the proposed algo- rithm outperforms state-of-the-art competitors, and is able to detect salient entities with high accuracy.", "references": ["R. Blanco, H. Halpin, D. M. Herzig, P. Mika, J. Pound, H. S. Thompson, and T. Tran Duc. Repeatable and reliable search system evaluation using crowdsourcing. In Proceedings of SIGIR, pages 923--932. ACM, 2011.", "X. Cheng and D. Roth. Relational inference for wikification. Urbana, 51:61801, 2013.", "J. Dunietz and D. Gillick. A new entity salience task with millions of training examples. EACL 2014, page 205, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2960819"}, {"title": "Significant Words Representations of Entities", "authors": ["Mostafa Dehghani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTransforming the data into a suitable representation is the first key step of data analysis, and the performance of any data oriented method is heavily depending on it. We study questions on how we can best learn representations for textual entities that are: 1) precise, 2) robust against noisy terms, 3) transferable over time, and 4) interpretable by human inspection. Inspired by the early work of Luhn, we propose significant words language models of a set of documents that capture all, and only, the significant shared terms from them. We adjust the weights of common terms that are already well explained by the document collection as well as the weight of incidental rare terms that are only explained by specific documents, which eventually results in having only the significant terms left in the model.", "references": ["M. Dehghani, H. Azarbonyad, J. Kamps, and M. Marx. Generalized group profiling for content customization. In CHIIR '16, pages 245--248, 2016.", "M. Dehghani, H. Azarbonyad, J. Kamps, and M. Marx. Two-way parsimonious classification models for evolving hierarchies. In CLEF'16, 2016.", "S. H. Hashemi, M. Dehghani, and J. Kamps. Parsimonious user and group profiling in venue recommendation. In TREC 2015. NIST, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911474"}, {"title": "Improving Music Recommendation Using Distributed Representation", "authors": ["Dongjing Wang\n,", "Shuiguang Deng\n,", "Songguo Liu\n,", "Guandong Xu"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn this paper, a music recommendation approach based on distributed representation is presented. The proposed approach firstly learns the distributed representations of music pieces and acquires users' preferences from listening records. Then, it recommends appropriate music pieces whose distributed representations are in accordance with target users' preferences. Experiments on a real world dataset demonstrate that the proposed approach outperforms the state-of-the-art methods.", "references": ["T. Mikolov, I. Sutskever, K. Chen, G.S. Corrado, and J. Dean, Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, 3111--3119, 2013.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, 452--461, 2009.", "S. Kabbur, X. Ning, and G. Karypis, Fism: factored item similarity models for top-n recommender systems. In Proceedings of the 19th ACM international conference on Knowledge discovery and data mining, 659--667, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889399"}, {"title": "Agree to disagree: on labelling helpful app reviews", "authors": ["Andrew Simmons\n,", "Leonard Hoon"], "publication": "OzCHI '16: Proceedings of the 28th Australian Conference on Computer-Human Interaction", "abstract": "ABSTRACT\nMobile apps designers seek to prioritise and refine app features so as to optimise user experience across the ensemble of possible situations and contexts in which the app is used. App reviews---some helpful, others irrelevant---can be analysed for feedback on this user experience. However, few studies have specifically examined the helpfulness of app reviews. In this paper, we surveyed users and developers to rate 167 reviews for helpfulness, obtaining a total of 2,558 helpfulness ratings captured on a 5 point Likert scale. We found only slight agreement (nominal Krippendorff's alpha = 0.039) between participants on the helpfulness of reviews. Differences between reviews become evident when we summarise all the helpfulness ratings per review. We conclude that the disagreement among users limits the potential of mobile app review recommender systems.", "references": ["Danescu-Niculescu-Mizil, C., Kossinets, G., Kleinberg, J., and Lee, L. How opinions are received by online communities: a case study on amazon. com helpfulness votes. In Proceedings of the 18th international conference on World wide web (2009) 141--150.", "Ha, S. Assessing Quality of Consumer Reviews in Mobile Application Markets: A Principal Component Analysis Approach. In PACIS 2015 Proceedings (2015) Paper 252.", "Hallgren, K. A. Computing Inter-Rater Reliability for Observational Data: An Overview and Tutorial. Tutor Quant Methods Psychol, 8, 1 (2012) 23--34."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010915.3010976"}, {"title": "API recommendation system for software development", "authors": ["Ferdian Thung"], "publication": "ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nNowadays, software developers often utilize existing third party libraries and make use of Application Programming Interface (API) to develop a software. However, it is not always obvious which library to use or whether the chosen library will play well with other libraries in the system. Furthermore, developers need to spend some time to understand the API to the point that they can freely use the API methods and putting the right parameters inside them. In this work, I plan to automatically recommend relevant APIs to developers. This API recommendation can be divided into multiple stages. First, we can recommend relevant libraries provided a given task to complete. Second, we can recommend relevant API methods that developer can use to program the required task. Third, we can recommend correct parameters for a given method according to its context. Last but not least, we can recommend how different API methods can be combined to achieve a given task.\nIn effort to realize this API recommendation system, I have published two related papers. The first one deals with recommending additional relevant API libraries given known useful API libraries for the target program. This system can achieve recall rate@5 of 0.852 and recall rate@10 of 0.894 in recommending additional relevant libraries. The second one deals with recommending relevant API methods a given target API and a textual description of the task. This system can achieve recall-rate@5 of 0.690 and recallrate@10 of 0.779. The results for both system indicate that the systems are useful and capable in recommending the right API/library reasonably well. Currently, I am working on another system which can recommend web APIs (i.e., libraries) given a description of the task. I am also working on a system that recommends correct parameters given an API method. In the future, I also plan to realize API composition recommendation for the given task", "references": ["M. Asaduzzaman, C. K. Roy, S. Monir, and K. A. Schneider, “Exploring api method parameter recommendations,” in Software Maintenance and Evolution (ICSME), 2015 IEEE International Conference on. IEEE, 2015, pp. 271–280.", "V. Bauer, L. Heinemann, and F. Deissenboeck, “A structured approach to assess third-party library usage,” in ICSM, 2012, pp. 483–492.", "D. Bianchini, V. De Antonellis, and M. Melchiori, “Advanced web API search patterns adding collective knowledge to public repository facets,” in Proceedings of the International Conference on Information Integration and Web-based Applications &amp; Services, vol. 211, 2013, pp. 211–219."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970276.2975940"}, {"title": "On the Automatic Construction of Regular Expressions from Examples (GP vs. Humans 1-0)", "authors": ["Alberto Bartoli\n,", "Andrea De Lorenzo\n,", "Eric Medvet\n,", "Fabiano Tarlao"], "publication": "GECCO '16 Companion: Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion", "abstract": "ABSTRACT\nRegular expressions are systematically used in a number of different application domains. Writing a regular expression for solving a specific task is usually quite difficult, requiring significant technical skills and creativity. We have developed a tool based on Genetic Programming capable of constructing regular expressions for text extraction automatically, based on examples of the text to be extracted.\nWe have recently demonstrated that our tool is human-competitive in terms of both accuracy of the regular expressions and time required for their construction. We base this claim on a large-scale experiment involving more than 1700 users on 10 text extraction tasks of realistic complexity. The F-measure of the expressions constructed by our tool was almost always higher than the average F-measure of the expressions constructed by each of the three categories of users involved in our experiment (Novice, Intermediate, Experienced). The time required by our tool was almost always smaller than the average time required by each of the three categories of users. The experiment is described in full detail in \"Can a machine replace humans? A case study. IEEE Intelligent Systems, 2016\"", "references": ["A. Bartoli, G. Davanzo, A. De Lorenzo, M. Mauri, E. Medvet, and E. Sorio. Automatic generation of regular expressions from examples with genetic programming. In Proceedings of the 14th Annual Conference Companion on Genetic and Evolutionary Computation, GECCO '12, pages 1477--1478, New York, NY, USA, 2012. ACM.", "A. Bartoli, G. Davanzo, A. De Lorenzo, E. Medvet, and E. Sorio. Automatic synthesis of regular expressions from examples. Computer, 47(12):72--80, Dec 2014.", "A. Bartoli, A. De Lorenzo, E. Medvet, and F. Tarlao. Playing regex golf with genetic programming. In Proceedings of the 2014 Conference on Genetic and Evolutionary Computation, GECCO '14, pages 1063--1070, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908961.2930946"}, {"title": "Report on ECIR 2016: 38th European Conference on Information Retrieval", "authors": ["Nicola Ferro\n,", "Fabio Crestani\n,", "Marie-Francine Moens\n,", "Josiane Mothe\n,", "Fabrizio Silvestri\n,", "Jaana Kekäläinen\n,", "Paolo Rosso\n,"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThe 38th European Conference on Information Retrieval took place from the 20th to the 23rd of March 2016 in Padua, Italy. This report summarizes the conference in terms of the presented keynotes, scientific and social programme, industry day, tutorials, workshops and student support.", "references": ["G. Amati, C. Carpineto, and G. Romano. Query Difficulty, Robustness, and Selective Application of Query Expansion. In S. McDonald and J. Tait, editors, Advances in Information Retrieval. Proc. 26th European Conference on IR Research (ECIR 2004), pages 127--137. Lecture Notes in Computer Science (LNCS) 2997, Springer, Heidelberg, Germany, 2004.", "L. Braunstain, O. Kurland, D. Carmel, I. Szpektor, and A: Shtok. Supporting Human Answers for Advice-Seeking Questions in CQA Sites. In Ferro et al. {4}, pages 129--141.", "A. Fang, C. Macdonald, I. Ounis, and P. Habel. Topics in Tweets: A User Study of Topic Coherence Metrics for Twitter Data. In Ferro et al. {4}, pages 492--504."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964801"}, {"title": "Web search behaviors for software development", "authors": ["Keitaro Nakasai\n,", "Masateru Tsunoda\n,", "Hideaki Hata"], "publication": "CHASE '16: Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering", "abstract": "ABSTRACT\nSoftware developers often use a web search engine to improve work efficiency. However, web search skill (i.e., efficiency to find an appropriate web site) is different for each developer. In this research, we try to clarify better web search behavior. To analyze web search behavior in programming, we made some questions about programming, and subjects solved the questions. The questions are based on Java language. Based on our experiment, to enhance the effectiveness of the web search, we suggest (1) do not read many search result pages without changing the key phrase, (2) read search result pages or the destination web pages linked to the search results carefully, before making new search, (3) Use new keywords which are not used before, when making a new key phrase.", "references": ["Bloch, J. and Gafter, N. 2005. Java Puzzlers: Traps, Pitfalls, and Corner Cases, Addison-Wesley Professional.", "Bajracharya, S. and Lopes, C. 2012. Analyzing and mining a code search engine usage log, Empirical Software Engineering, 17, 4, 424--466.", "Nakasai, K. and Tsunoda, M. 2015. Analysis of web search action in software development, Fundamentals of software engineering (FOSE) (in Japanese)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897586.2897614"}, {"title": "A Machine learning Filter for Relation Extraction", "authors": ["Kevin Lange Di Cesare\n,", "Michel Gagnon\n,", "Amal Zouaq\n,", "Ludovic Jean-Louis"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe TAC KBP English slot filling track is an evaluation campaign that targets the extraction of 41 pre-identified relations related to specific named entities. In this work, we present a machine learning filter whose aim is to enhance the precision of relation extractors while minimizing the impact on recall. Our approach aims at filtering relation extractors' output using a binary classifier based on a wide array of features including syntactic, lexical and statistical features. We experimented the classifier on 14 of the 18 participating systems in the TAC KBP English slot filling track 2013. The results show that our filter is able to improve the precision of the best 2013 system by nearly 20\\% and improve the F1-score for 17 relations out of 33 considered.", "references": ["R. Agrawal, R. Srikant, et al. Fast Algorithms for Mining Association Rules. In 20th VLDB, 1994.", "M.-C. De Marneffe, B. MacCartney, C. D. Manning, et al. Generating Typed Dependency Parses from Phrase Structure Parses. In LREC, 2006.", "M. Hall, E. Frank, G. Holmes, and al. The Weka Data Mining Software: An Update. ACM SIGKDD, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889397"}, {"title": "The Factoid Queries Collection", "authors": ["Ido Guy\n,", "Dan Pelleg"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present a collection of over 15,000 queries, issued to commercial web search engines, whose answer is a single fact. The collection was produced based on queries landing on questions within a large community question answering website, each with a best answer no longer than 3 words and an explicit reference to a Wikipedia page. We describe the collection generation process and provide a variety of descriptive characteristics, demonstrating the collection?s uniqueness compared to existing datasets and its potential use for research of factoid question answering and retrieval.", "references": ["L. A. Adamic, J. Zhang, E. Bakshy, and M. S. Ackerman. Knowledge sharing and Yahoo Answers: Everyone knows something. In Proc. WWW, pages 665--674, 2008.", "H. Bast and E. Haussmann. More accurate question answering on freebase. In Proc. CIKM, pages 1431--1440, 2015.", "J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on freebase from question-answer pairs. In Proc. EMNLP, pages 1533?--1544, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914676"}, {"title": "Scaling up Dynamic Topic Models", "authors": ["Arnab Bhadury\n,", "Jianfei Chen\n,", "Jun Zhu\n,", "Shixia Liu"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nDynamic topic models (DTMs) are very effective in discovering topics and capturing their evolution trends in time series data. To do posterior inference of DTMs, existing methods are all batch algorithms that scan the full dataset before each update of the model and make inexact variational approximations with mean-field assumptions. Due to a lack of a more scalable inference algorithm, despite the usefulness, DTMs have not captured large topic dynamics. This paper fills this research void, and presents a fast and parallelizable inference algorithm using Gibbs Sampling with Stochastic Gradient Langevin Dynamics that does not make any unwarranted assumptions. We also present a Metropolis-Hastings based $O(1)$ sampler for topic assignments for each word token. In a distributed environment, our algorithm requires very little communication between workers during sampling (almost embarrassingly parallel) and scales up to large-scale applications. We are able to learn the largest Dynamic Topic Model to our knowledge, and learned the dynamics of 1,000 topics from 2.6 million documents in less than half an hour, and our empirical results show that our algorithm is not only orders of magnitude faster than the baselines but also achieves lower perplexity.", "references": ["A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In International Conference on Web Search and Data Mining (WSDM). ACM, 2012.", "S. Ahn, B. Shahbaba, and M. Welling. Distributed stochastic gradient mcmc. In International Conference on Machine Learning (ICML), 2014.", "D. Blei and J. Lafferty. Correlated topic models. Advances in Neural Information Processing Systems (NIPS), 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883046"}, {"title": "Things of Interest Recommendation by Leveraging Heterogeneous Relations in the Internet of Things", "authors": ["Lina Yao\n,", "Quan Z. Sheng\n,", "Anne H. H. Ngu\n,", "Xue Li"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nThe emerging Internet of Things (IoT) bridges the gap between the physical and the digital worlds, which enables a deeper understanding of user preferences and behaviors. The rich interactions and relations between users and things call for effective and efficient recommendation approaches to better meet users’ interests and needs. In this article, we focus on the problem of things recommendation in IoT, which is important for many applications such as e-Commerce and health care. We discuss the new properties of recommending things of interest in IoT, and propose a unified probabilistic factor based framework by fusing relations across heterogeneous entities of IoT, for example, user-thing relations, user-user relations, and thing-thing relations, to make more accurate recommendations. Specifically, we develop a hypergraph to model things’ spatiotemporal correlations, on top of which implicit things correlations can be generated. We have built an IoT testbed to validate our approach and the experimental results demonstrate its feasibility and effectiveness.", "references": ["Karl Aberer, Manfred Hauswirth, and Ali Salehi. 2006. A middleware for fast and flexible sensor network deployment. In Proceedings of the 32nd International Conference on Very Large Data Bases. VLDB Endowment, 1199--1202.", "Deepak Agarwal and Bee-Chung Chen. 2009. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 19--28.", "Sameer Agarwal, Kristin Branson, and Serge Belongie. 2006. Higher order learning with graphs. In Proceedings of the 23rd International Conference on Machine Learning. ACM, 17--24."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837024"}, {"title": "The retrieval of moving images at spanish film archives: the oversight of content analysis", "authors": ["Rubén Domínguez-Delgado\n,", "María-Ángeles López Hernández"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nIn the field of library and information science, content analysis is a crucial task for an effective retrieval of information by users at an archive. In this research, we analyse the current state of this task and the possibilities of retrieval of film information at six Spanish important film archives, interviewing their responsible librarians for film cataloguing and comparing the content fields inside their film cataloguing records used by each one of these six organizations.", "references": ["Agirreazaldegi, T. (2007). Claves y retos de la documentación digital en televisión\". In El profesional de la información, vol. 16, n. 5 (pp. 433--442).", "Aguilar-Gutiérrez, M. & López-De-Solís, I. (2010). Nuevos modos de trabajo de una redacción digital integrada: el caso de los servicios informativos de TVE. In El profesional de la información, v. 19, n. 4 (pp. 395--403).", "Caldera-Serrano, J. & Sánchez-Jiménez, R. (2009). Recuperación de secuencias de información audiovisual con rdf y smil. In El profesional de la información, v. 18, n. 3 (pp. 291--299)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017587"}, {"title": "A deep learning framework for book search", "authors": ["Thi Thanh Sang Nguyen"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nIn this paper, we propose a novel framework using the word2vec model, a deep learning method, integrated with a book ontology in order to enhance semantically searching books. The idea starts from constructing a book ontology for reasoning book information efficiently. A deep learning method, namely the word2vec model, is then utilized to represent vectors of words occurring on book descriptions. These vectors would help finding most relevant books given a query string. The integration of the word2vec model and the book ontology is able to achieve high performance in searching books. A database of Amazon books is taken into account examining the proposed method, compared with an advanced keyword matching method. The experimental results show that the proposed method can produce more accurate searching results.", "references": ["Christophe, J., et al., eds. Next Generation Search Engines: Advanced Models for Information Retrieval. 2012, IGI Global: Hershey, PA, USA. 560.", "Li, H. and J. Xu, Semantic Matching in Search. Foundations and Trends in Information Retrieval, 2014. 7(5): p. 343--469.", "Blanco, R., et al., Entity Recommendations in Web Search, in The Semantic Web - ISWC 2013, H. Alani, et al., Editors. 2013, Springer Berlin Heidelberg. p. 33--48."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011195"}, {"title": "Amazon Search: The Joy of Ranking Products", "authors": ["Daria Sorokina\n,", "Erick Cantu-Paz"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAmazon is one of the world's largest e-commerce sites and Amazon Search powers the majority of Amazon's sales. As a consequence, even small improvements in relevance ranking both positively influence the shopping experience of millions of customers and significantly impact revenue. In the past, Amazon's product search engine consisted of several hand-tuned ranking functions using a handful of input features. A lot has changed since then. In this talk we are going to cover a number of relevance algorithms used in Amazon Search today. We will describe a general machine learning framework used for ranking within categories, blending separate rankings in All Product Search, NLP techniques used for matching queries and products, and algorithms targeted at unique tasks of specific categories --- books and fashion.", "references": ["J. Friedman. Greedy Function Approximation: a Gradient Boosting Machine. Annals of Statistics, 29:1189--1232, 2001.", "F. James. Modified Kneser-Ney Smoothing of N-gram Models. Technical report, 2000.", "W. V. Zhang and R. Jones. Comparing click logs and editorial labels for training query rewriting. In WWW'07 workshops."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926725"}, {"title": "MAPS: A Multi Aspect Personalized POI Recommender System", "authors": ["Ramesh Baral\n,", "Tao Li"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe evolution of the World Wide Web (WWW) and the smart-phone technologies have played a key role in the revolution of our daily life. The location-based social networks (LBSN) have emerged and facilitated the users to share the check-in information and multimedia contents. The Point of Interest (POI) recommendation system uses the check-in information to predict the most potential check-in locations. The different aspects of the check-in information, for instance, the geographical distance, the category, and the temporal popularity of a POI; and the temporal check-in trends, and the social (friendship) information of a user play a crucial role in an efficient recommendation. In this paper, we propose a fused recommendation model termed MAPS (Multi Aspect Personalized POI Recommender System) which will be the first in our knowledge to fuse the categorical, the temporal, the social and the spatial aspects in a single model. The major contribution of this paper are: (i) it realizes the problem as a graph of location nodes with constraints on the category and the distance aspects (i.e. the edge between two locations is constrained by a threshold distance and the category of the locations), (ii) it proposes a multi-aspect fused POI recommendation model, and (iii) it extensively evaluates the model with two real-world data sets.", "references": ["R. Baral, D. Wang, T. Li, and S. C. Chen. Geotecs: Exploiting geographical, temporal, categorical and social aspects for personalized poi recommendation. In Information Reuse & Integration, 2016. IRI'16. IEEE International Conference on, page In Press. IEEE, 2016.", "S. Brin, R. Motwani, L. Page, and T. Winograd. What can you do with a web in your pocket? IEEE Data Eng. Bull., 21(2):37--47, 1998.", "T. H. Haveliwala. Topic-sensitive pagerank. In Proceedings of the 11th international conference on World Wide Web, pages 517--526. ACM, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959187"}, {"title": "WoTSF: A Framework for Searching in the Web of Things", "authors": ["Mina Younan\n,", "Sherif Khattab\n,", "Reem Bahgat"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nA key challenge in the emerging Web of Things (WoT) paradigm is how the human users and machines look for meaningful and readable information in huge and dynamic datasets in real-time, whereby the datasets are presented in different formats. This paper presents a technique to construct efficient, hierarchical web indices that are efficiently kept up-to-date. Also, a framework for searching in the WoT, namely WoTSF, is proposed and experimentally evaluated using a prototype. The proposed framework was shown to present a tradeoff between search speed and result accuracy as compared to the Dyser WoT search engine.", "references": ["M. Younan, S. Khattab, and R. Bahgat, \"An Integrated Testbed Environment for the Web of Things,\" in ICNS 2015-The Eleventh International Conference on Networking and Services, ISBN: 978-1-61208-404-6, Rome, Italy, May, 2015, pp. 69--78.", "C. Pfister, Getting Started with the Internet of Things, First Edition ed., B. Jepson, Ed. United States of America.: O'Reilly Media, Inc., May 2011.", "B. Ostermaier, K. Romery, F. Mattern, M. Fahrmairz, and W. Kellererz, \"A Real-Time Search Engine for the Web of Things,\" in The 2nd IEEE International Conference on the Internet of Things (IoT), Tokyo,Japan, Nov. 2010, pp. 1--8."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908496"}, {"title": "PatchWork, a scalable density-grid clustering algorithm", "authors": ["Frank Gouineau\n,", "Tom Landry\n,", "Thomas Triplet"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nClustering is a fundamental task in Knowledge Discovery and Data mining. It aims to discover the unknown nature of data by grouping together data objects that are more similar. While hundreds of clustering algorithms have been proposed, many are complex and do not scale well as more data become available, making then inadequate to analyze very large datasets. In addition, many clustering algorithms are sequential, thus inherently difficult to parallelize. We propose PatchWork, a novel clustering algorithm to address those issues. PatchWork is a distributed density clustering algorithm with linear computational complexity and linear horizontal scalability. It presents several desirable characteristics in knowledge discovery, in particular, it does not require a priori the number of clusters to identify, and offers a natural protection against outliers and noise. In addition, PatchWork makes it possible to discover spatially large clusters instead of dense clusters only. PatchWork relies on the map/reduce paradigm to parallelize computations and was implemented using Apache Spark, the distributed computation framework. As a result, PatchWork can cluster a billion points in a few minutes only, a 40x improvement over the distributed implementation of k-means in Spark MLLib.", "references": ["B. Bahmani, B. Moseley, A. Vattani, R. Kumar, and S. Vassilvitskii. Scalable K-Means ++. Proceedings of the VLDB Endowment (PVLDB), 5:622--633, 2012.", "H. Chang and D. Y. Yeung. Robust path-based spectral clustering. Pattern Recognition, 41(1):191--203, 2008.", "H. Dai and H. Su. Approximation and analytical studies of inter-clustering performances of space-filling curves. In C. Banderier and C. Krattenthaler, editors, Discrete Random Walks, DRW'03, Paris, France, September 1-5, 2003, volume AC of Discrete Mathematics and Theoretical Computer Science Proceedings, pages 53--68. DMTCS, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851643"}, {"title": "R-Susceptibility: An IR-Centric Approach to Assessing Privacy Risks for Users in Online Communities", "authors": ["Joanna Asia Biega\n,", "Krishna P. Gummadi\n,", "Ida Mele\n,", "Dragan Milchevski\n,", "Christos Tryfonopoulos\n,", "Gerhard Weikum"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPrivacy of Internet users is at stake because they expose personal information in posts created in online communities, in search queries, and other activities. An adversary that monitors a community may identify the users with the most sensitive properties and utilize this knowledge against them (e.g., by adjusting the pricing of goods or targeting ads of sensitive nature). Existing privacy models for structured data are inadequate to capture privacy risks from user posts.\nThis paper presents a ranking-based approach to the assessment of privacy risks emerging from textual contents in online communities, focusing on sensitive topics, such as being depressed. We propose ranking as a means of modeling a rational adversary who targets the most afflicted users. To capture the adversary's background knowledge regarding vocabulary and correlations, we use latent topic models. We cast these considerations into the new model of R-Susceptibility, which can inform and alert users about their potential for being targeted, and devise measures for quantitative risk assessment. Experiments with real-world data show the feasibility of our approach.", "references": ["L. A. Adamic et al. Knowledge sharing and yahoo answers: Everyone knows something. WWW'08.", "E. Adar. User 4xxxxx9: anonymizing query logs. Workshop on Query Log Analysis, WWW'07.", "E. Bertino, D. Lin, W. Jiang:A Survey of Quantification of Privacy Preserving Data Mining Algorithms. In: Privacy-Preserving Data Mining, Springer 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911533"}, {"title": "Extending Faceted Search to the Open-Domain Web", "authors": ["Weize Kong"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nFaceted search enables users to navigate a multi-dimensional information space by combining keyword search with drill-down options in each facets. For example, when searching \"computer monitor\" in an e-commerce site, users can select brands and monitor types from the the provided facets {\"Samsung\", \"Dell\", \"Acer\", ...} and {\"LET-Lit\", \"LCD\", \"OLED\",...}. It has been used successfully for many vertical applications, including e-commerce and digital libraries. However, this idea is not well explored for general web search in an opendomain setting, even though it holds great potential for assisting multi-faceted queries and exploratory search.\nThe goal of this work is to explore this potential by extending faceted search into the opendomain web setting, which we call Faceted Web Search. We address three fundamental issues in Faceted Web Search, namely: how to automatically generate facets (facet generation); how to re-organize search results with users' selections on facets (facet feedback); and how to evaluate generated facets and entire Faceted Web Search systems.\nIn conventional faceted search, facets are generated in advance for an entire corpus either manually or semi-automatically, and then recommended for particular queries in most of the previous work. However, this approach is difficult to extend to the entire web due to the web's large and heterogeneous nature. We instead propose a query-dependent approach, which extracts facets for queries from their web search results. We further improve our facet generation model under a more practical scenario, where users care more about precision of presented facets than recall.\nThe dominant facet feedback method in conventional faceted search is Boolean filtering, which filters search results by users' selections on facets. However, our investigation shows Boolean filtering is too strict when extended to the open-domain setting. Thus, we propose soft ranking models for Faceted Web Search, which expand original queries with users' selections on facets to re-rank search results. Our experiments show that the soft ranking models are more effective than Boolean filtering models for Faceted Web Search.\nTo evaluate Faceted Web Search, we propose both intrinsic evaluation, which evaluates facet generation on its own, and extrinsic evaluation, which evaluates an entire Faceted Web Search system by its utility in assisting search clarification. We also design a method for building reusable test collections for such evaluations. Our experiments show that using the Faceted Web Search interface can significantly improve the original ranking if allowed sufficient time for user feedback on facets.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964814"}, {"title": "A Semantic and Content-Based Search User Interface for Browsing Large Collections of Foley Sounds", "authors": ["Gabriel Urbain\n,", "Christian Frisson\n,", "Alexis Moinet\n,", "Thierry Dutoit"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nSound designers select the sounds they use among massive collections of recordings. They usually rely on text-based queries to narrow down a subset from these collections when looking for specific content. However, when it comes to unknown collections, this approach can fail to precisely retrieve files according to their content. We investigate an audio search engine that associates content-based features and semantic meta-data using Apache Solr deployed in a fully integrated server architecture. In order to facilitate the task of browsing the sounds, we also propose a search user interface in which the user can perform both text-based queries and visual browsing in a window where sounds are organized according to their audio features. A preliminary evaluation of the performances helped to optimize the parameters of the system.", "references": ["Giuseppe Becchi, Marco Bertini, Lorenzo Cioni, Alberto Del Bimbo, Andrea Ferracani, Daniele Pezzatini, and Mathias Lux. 2014. Loki+ Lire: a framework to create web-based multimedia search engines. In Proceedings of the ACM International Conference on Multimedia. 691--694.", "Adam Berenzweig, Beth Logan, Daniel PW Ellis, and Brian Whitman. 2004. A large-scale evaluation of acoustic and subjective music-similarity measures. Computer Music Journal 28, 2 (2004), 63--76.", "Michael Bostock, Vadim Ogievetsky, and Jeffrey Heer. 2011. D3 Data-Driven Documents. IEEE Transactions on Visualization and Computer Graphics 17, 12 (Dec. 2011), 2301--2309. DOI: http://dx.doi.org/10.1109/TVCG.2011.185"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986436"}, {"title": "Design and learnability of vortex whistles for managing chronic lung function via smartphones", "authors": ["Spencer Kaiser\n,", "Ashley Parks\n,", "Patrick Leopard\n,", "Charlie Albright\n,", "Jake Carlson\n,", "Mayank Goel\n,", "Damoun Nassehi\n,", "Eric C. Larson"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nSpirometry is the gold standard for managing and diagnosing obstructive lung diseases. Clinical spirometers, however, are expensive and have limited portability. Vortex whistles have shown promise as a potential substitute for clinical spirometers. While vortex whistles are low-cost and are highly portable, only a subset of common spirometry measurements can be measured reliably. Moreover, no research studies have evaluated characteristics of human interaction with vortex whistles, such as maneuver learnability and mental effort. We present a modified 3D-printed vortex whistle design that enables estimation of spirometry measures not previously attainable with traditional vortex whistles. We evaluate the whistle using a pulmonary waveform generator (a commercial standard) and map parameters of the whistle construction to spirometry test endpoints. Through a human subjects trial we evaluate how to personalize whistle parameters for different subjects and assess cognitive workload while using a vortex whistle. We show that, with personalization, vortex whistles are as effective as clinical spirometers for identifying moderate airway obstruction and require similar cognitive load to use.", "references": ["2006. NASA TLX: Task Load Index. (2006). http://humansystems.arc.nasa.gov/groups/tlx/", "Gregory Abowd. 2016. Beyond Weiser: From Ubiquitous to Collective Computing. IEEE Computer Magazine (2016), 17--23.", "Christina Baggott, Faith Gibson, Beatriz Coll, Richard Kletter, Paul Zeltzer, and Christine Miaskowski. 2012. Initial evaluation of an electronic symptom diary for adolescents with cancer. JMIR research protocols 1, 2 (2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971726"}, {"title": "An Approach to identify semantic relations between user's queries in text retrieval", "authors": ["Kamlesh Makvana\n,", "Patel Jay\n,", "Parth Shah\n,", "Amit Thakkar"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nThe one size fits the all approach of commercial search engines is that whatever might be the context of the query, the same results are returned to different users. The problem arises as the existing methods concentrate more on the long-term interest which reduce the effectiveness of personalized web search to provide accurate predictions of the query context. Information overload is ongoing obstacle that loses the quality of data among the huge web by providing irrelevant results. To compute the semantic similarity between the query words is challenging task due to insufficient amount of information available in ambiguous keywords submitted by the users. This paper proposes an approach to that works in 2 stages. First from the user web log file, personalized ontology is created. Second, semantic mapper is used to identify semantic relation between query context/topic that improves evaluation measures used for computing semantic relatedness between words.", "references": ["Patel Jay, Pinal Shah, Makvana Kamlesh and Parth Shah. \"Review on web search personalization through semantic data\" Electrical, Computer and communication Technologies (ICECCT), 2015 International Conference on IEEE, 2015.", "Makvana Kamlesh, Pinal Shah and Parth Shah. \"A novel approach to personalize web search through user profiling and query reformulation\" Data Mining and Intelligent Computing (ICDMIC), 2014 International Conference on IEEE, 2014.", "Pannu, Mandeep, RachidAnane, and Anne James. \"Hybrid profiling in information retrieval.\" Computer Supported Cooperative Work in Design (CSCWD), 2013 IEEE 17th International Conference on. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905271"}, {"title": "Using a Dictionary and n-gram Alignment to Improve Fine-grained Cross-Language Plagiarism Detection", "authors": ["Nava Ehsan\n,", "Frank Wm. Tompa\n,", "Azadeh Shakery"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nThe Web offers fast and easy access to a wide range of documents in various languages, and translation and editing tools provide the means to create derivative documents fairly easily. This leads to the need to develop effective tools for detecting cross-language plagiarism. Given a suspicious document, cross-language plagiarism detection comprises two main subtasks: retrieving documents that are candidate sources for that document and analyzing those candidates one by one to determine their similarity to the suspicious document. In this paper we focus on the second subtask and introduce a novel approach for assessing cross-language similarity between texts for detecting plagiarized cases. Our proposed approach has two main steps: a vector-based retrieval framework that focuses on high recall, followed by a more precise similarity analysis based on dynamic text alignment. Experiments show that our method outperforms the methods of the best results in PAN-2012 and PAN-2014 in terms of plagdet score. We also show that aligning n-gram units, instead of aligning complete sentences, improves the accuracy of detecting plagiarism.", "references": ["A. Barrón-Cedeno. On the mono-and cross-language detection of text reuse and plagiarism. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 914--914. ACM, 2010.", "A. Barrón-Cedeno, P. Gupta, and P. Rosso. Methods for cross-language plagiarism detection. Knowledge-Based Systems, 45(1):45--62, 2013.", "A. Barrón-Cedeno, P. Rosso, and J.-M. Benedı. Reducing the plagiarism detection search space on the basis of the Kullback-Leibler distance. In Computational Linguistics and Intelligent Text Processing, pages 523--534. Springer, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2960817"}, {"title": "Representation of Gestures in Syntactic Analysis: a Systematic Literature Review", "authors": ["Ricardo A. Feitosa\n,", "Sarajane M. Peres\n,", "Clodoaldo A.M. Lima"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nGestures analysis systems have been getting attention for their ability to contribute to the interaction between humans, humans and machines, and humans and environments. In such systems, the establishment of an efficient data representation for gestures is a critical task. The chosen representation as well as its combination with techniques for analysis can or can not favor the solution being developed. In this systematic review we identify and discuss the strategies of representation of gestures used in 21 studies published in the last five years in the context of syntactic gesture analysis.", "references": ["M. Abid, E. Petriu, and E. Amjadian. Dynamic sign language recognition for smart home interactive application using stochastic linear formal grammar. IEEE Trans. on Inst. and Measurement, 64(3):596-605, mar. 2015.", "J. Biolchini, P. G. Mian, A. C. C. Natali, and G. H. Travassos. Systematic rev. in soft. eng. Technical report, System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES-679-05, 2005.", "B. Caramiaux, M. M. Wanderley, and F. Bevilacqua. Segmenting and parsing instrumentalists' gestures. J. of New Music Research, 41(1):13-29, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022040"}, {"title": "Deep-based Ingredient Recognition for Cooking Recipe Retrieval", "authors": ["Jingjing Chen\n,", "Chong-wah Ngo"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nRetrieving recipes corresponding to given dish pictures facilitates the estimation of nutrition facts, which is crucial to various health relevant applications. The current approaches mostly focus on recognition of food category based on global dish appearance without explicit analysis of ingredient composition. Such approaches are incapable for retrieval of recipes with unknown food categories, a problem referred to as zero-shot retrieval. On the other hand, content-based retrieval without knowledge of food categories is also difficult to attain satisfactory performance due to large visual variations in food appearance and ingredient composition. As the number of ingredients is far less than food categories, understanding ingredients underlying dishes in principle is more scalable than recognizing every food category and thus is suitable for zero-shot retrieval. Nevertheless, ingredient recognition is a task far harder than food categorization, and this seriously challenges the feasibility of relying on them for retrieval. This paper proposes deep architectures for simultaneous learning of ingredient recognition and food categorization, by exploiting the mutual but also fuzzy relationship between them. The learnt deep features and semantic labels of ingredients are then innovatively applied for zero-shot retrieval of recipes. By experimenting on a large Chinese food dataset with images of highly complex dish appearance, this paper demonstrates the feasibility of ingredient recognition and sheds light on this zero-shot problem peculiar to cooking recipe retrieval.", "references": ["K. Aizawa and M. Ogawa. Foodlog: Multimedia tool for healthcare applications. IEEE MultiMedia, 22(2):4--8, 2015.", "O. Beijbom, N. Joshi, D. Morris, S. Saponas, and S. Khullar. Menu-match: Restaurant-specific food logging from images. In Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on, pages 844--851. IEEE, 2015.", "V. Bettadapura, E. Thomaz, A. Parnami, G. D. Abowd, and I. Essa. Leveraging context to support automated food recognition in restaurants. In Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on, pages 580--587. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964315"}, {"title": "Tutorial On The Cognitive-Behavioral Implications Of Driving With Music", "authors": ["Warren Brodsky"], "publication": "AutomotiveUI '16 Adjunct: Adjunct Proceedings of the 8th International Conference on Automotive User Interfaces and Interactive Vehicular Applications", "abstract": "ABSTRACT\nThe traffic psychology literature targeting driver behavior has scarcely investigated music as a source of inattention or distraction. There is great confusion regarding what is music, and the difference between 'music' versus 'auditory' stimuli is not always clear. Unfortunately, traffic and automotive researchers employing music in their investigations demonstrate little knowledge about musical structures (i.e., the actual complex of sound, rhythm, harmony), and further exhibit a total disregard for the level of rigor necessary to incorporate music stimuli within empirical frameworks. For the most part, exemplars selected as stimuli for studies have been contaminated, and conditions of exposure have been flawed. In general, hypotheses about in-car music listening are based on intuition without scientific grounding. It is no wonder that findings have typically inferred that 'music causes little, if any, effects'. This tutorial attempts to fill that gap and expose researchers of the automotive sciences to the effects of music on driver behavior. The session will offer guidelines for implementing future studies incorporating music.", "references": ["Brodsky, W. 2002. The effects of music tempo on simulated driving performance and vehicular control. Transportation Research Part F: Traffic Psychology And Behavior, 4, 219--241.", "Brodsky, W. 2015. Driving With Music: Cognitive-Behavioural Implications. Surry, UK.: Ashgate Publishing Ltd.", "Brodsky, W. and Kizner, M. 2012. Exploring an alternative in-car music background designed for driver safety. Transportation Research Part F: Traffic Psychology And Behavior, 15, 162--173."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3004323.3005684"}, {"title": "Read/write-optimized tree indexing for solid-state drives", "authors": ["Peiquan Jin\n,", "Chengcheng Yang\n,", "Christian S. Jensen\n,", "Puyuan Yang\n,", "Lihua Yue"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nFlash-memory-based solid-state drives (SSDs) are used widely for secondary storage. To be effective for SSDs, traditional indices have to be redesigned to cope with the special properties of flash memory, such as asymmetric read/write latencies (fast reads and slow writes) and out-of-place updates. Previous flash-optimized indices focus mainly on reducing random writes to SSDs, which is typically accomplished at the expense of a substantial number of extra reads. However, modern SSDs show a narrowing gap between read and write speeds, and read operations on SSDs increasingly affect the overall performance of indices on SSDs. As a consequence, how to optimize SSD-aware indices by reducing both write and read costs is a pertinent and open challenge. We propose a new tree index for SSDs that is able to reduce both writes and extra reads. In particular, we use an update buffer and overflow pages to reduce random writes, and we further exploit Bloom filters to reduce the extra reads to the overflow nodes in the tree. With this mechanism, we construct a read/write-optimized index that is capable of offering better overall performance than previous flash-aware indices. In addition, we present an analysis of the proposed index and show that the read and write costs of the operations on the index can be balanced by only tuning the false-positive rate of the Bloom filters. Our experimental results suggest that our proposal is efficient and represents an improvement over existing methods.", "references": ["Agrawal, D., Ganesan, D., Sitaraman, R., Diao, Y., Singh, S.: Lazy-adaptive tree: An optimized index structure for flash devices. In: Proceedings of the VLDB Endowment, vol. 2(1), pp. 361---372 (2009)", "Ahn, J.S., Kang, D., Jung, D., Kim, J.S., Maeng, S.: $$\\mu $$μ*-Tree: an ordered index structure for nand flash memory with adaptive page layout scheme. IEEE Trans. Comput. 62(4), 784---797 (2013)", "Athanassoulis, M., Ailamaki, A.: BF-Tree: approximate tree indexing. In: Proceedings of the VLDB Endowment vol. 7(14), pp. 1881---1892 (2014)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0406-1"}, {"title": "Assessing the Navigational Effects of Click Biases and Link Insertion on the Web", "authors": ["Florian Geigl\n,", "Kristina Lerman\n,", "Simon Walk\n,", "Markus Strohmaier\n,", "Denis Helic"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nWebsites have an inherent interest in steering user navigation in order to, for example, increase sales of specific products or categories, or to guide users towards specific information. In general, website administrators can use the following two strategies to influence their visitors' navigation behavior. First, they can introduce click biases to reinforce specific links on their website by changing their visual appearance, for example, by locating them on the top of the page. Second, they can utilize link insertion to generate new paths for users to navigate over. In this paper, we present a novel approach for measuring the potential effects of these two strategies on user navigation. Our results suggest that, depending on the pages for which we want to increase user visits, optimal link modification strategies vary. Moreover, simple topological measures can be used as proxies for assessing the impact of the intended changes on the navigation of users, even before these changes are implemented.", "references": ["S. Al-Saffar and G. Heileman. Experimental bounds on the usefulness of personalized and topic-sensitive pagerank. In Web Intelligence, ACM International Conference on, pages 671--675. IEEE, 2007.", "L. Bian and H. Holtzman. Online friend recommendation through personality matching and collaborative filtering. Proc. of UBICOMM, pages 230--235, 2011.", "M. Bianchini, M. Gori, and F. Scarselli. Inside pagerank. ACM Trans. Internet Technol., 5(1):92--128, Feb. 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914594"}, {"title": "When a Knowledge Base Is Not Enough: Question Answering over Knowledge Bases with External Text Data", "authors": ["Denis Savenkov\n,", "Eugene Agichtein"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOne of the major challenges for automated question answering over Knowledge Bases (KBQA) is translating a natural language question to the Knowledge Base (KB) entities and predicates. Previous systems have used a limited amount of training data to learn a lexicon that is later used for question answering. This approach does not make use of other potentially relevant text data, outside the KB, which could supplement the available information. We introduce a new system, Text2KB, that enriches question answering over a knowledge base by using external text data. Specifically, we revisit different phases in the KBQA process and demonstrate that text resources improve question interpretation, candidate generation and ranking. Building on a state-of-the-art traditional KBQA system, Text2KB utilizes web search results, community question answering and general text document collection data, to detect question topic entities, map question phrases to KB predicates, and to enrich the features of the candidates derived from the KB. Text2KB significantly improves performance over the baseline KBQA method, as measured on a popular WebQuestions dataset. The results and insights developed in this work can guide future efforts on combining textual and structured KB data for question answering.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "K. Barker. Combining structured and unstructured knowledge sources for question answering in watson. In DILS, Lecture Notes in Computer Science. Springer, 2012.", "H. Bast and E. Haussmann. More accurate question answering on freebase. Proceedings of CIKM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911536"}, {"title": "LODVader: An Interface to LOD Visualization, Analyticsand DiscovERy in Real-time", "authors": ["Ciro Baron Neto\n,", "Kay Müller\n,", "Martin Brümmer\n,", "Dimitris Kontokostas\n,", "Sebastian Hellmann"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe Linked Open Data (LOD) cloud is in danger of becoming a black box. Simple questions such as \"What kind of datasets are in the LOD cloud?\", \"In what way(s) are these datasets connected?\" -- albeit frequently asked -- are at the moment still difficult to answer due to the lack of proper tooling support. The infrequent update of the static LOD cloud diagram adds to the current dilemma, since there is neither reliable nor timely-updated information to perform an interactive search, analysis or in particular visualization in order to gain insight into the current state of Linked Open Data. In this paper, we propose a new hybrid system which combines LOD Visualisation, Analytics and DiscovERy (LODVader) to aid in answering the above questions. LODVader is equipped with (1) a multi-layer LOD cloud visualization component comprising datasets, subsets and vocabularies, (2) dataset analysis components that extend the state of the art with new similarity measures and efficient link extracting techniques and (3) a fast search index that is an entry point for dataset discovery. At its core, LODVader employs a timely-updated index using a complex cluster of Bloom filters as a fast search index with low memory footprint. This BF cluster is able to efficiently perform analysis on link and dataset similarities based on stored predicate and object information, which -- once inverted -- can be employed to discover invalid links by displaying the Dark LOD Cloud. By combining all these features, we allow for an up-to-date, multi-dimensional LOD cloud analysis, which -- to the best of our knowledge -- was not possible before.", "references": ["B. H. Bloom. Space/Time Trade-offs in Hash Coding with Allowable Errors. Commun. ACM, 13(7):422--426, July 1970.", "M. Brümmer, C. Baron, I. Ermilov, M. Freudenberg, D. Kontokostas, and S. Hellmann. DataID: Towards Semantically Rich Metadata for Complex Datasets. In Proceedings of the 10th International Conference on Semantic Systems, SEM'14, pages 84--91. ACM, 2014.", "M. Grobe. RDF, Jena, SparQL and the \"Semantic Web\". In Proceedings of the 37th Annual ACM SIGUCCS Fall Conference, SIGUCCS'09, pages 131--138, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890545"}, {"title": "Factorization Meets the Item Embedding: Regularizing Matrix Factorization with Item Co-occurrence", "authors": ["Dawen Liang\n,", "Jaan Altosaar\n,", "Laurent Charlin\n,", "David M. Blei"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMatrix factorization (MF) models and their extensions are standard in modern recommender systems. MF models decompose the observed user-item interaction matrix into user and item latent factors. In this paper, we propose a co-factorization model, CoFactor, which jointly decomposes the user-item interaction matrix and the item-item co-occurrence matrix with shared item latent factors. For each pair of items, the co-occurrence matrix encodes the number of users that have consumed both items. CoFactor is inspired by the recent success of word embedding models (e.g., word2vec) which can be interpreted as factorizing the word co-occurrence matrix. We show that this model significantly improves the performance over MF models on several datasets with little additional computational overhead. We provide qualitative results that explain how CoFactor improves the quality of the inferred factors and characterize the circumstances where it provides the most significant improvements.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD, pages 19--28, 2009.", "A. Almahairi, K. Kastner, K. Cho, and A. Courville. Learning distributed representations from reviews for collaborative filtering. In Proceedings of the 9th ACM Conference on Recommender Systems, pages 147--154, 2015.", "T. Bertin-Mahieux, D. P. W. Ellis, B. Whitman, and P. Lamere. The million song dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference, pages 591--596, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959182"}, {"title": "Know your customer: computing k-most promising products for targeted marketing", "authors": ["Md. Saiful Islam\n,", "Chengfei Liu"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe advancement of World Wide Web has revolutionized the way the manufacturers can do business. The manufacturers can collect customer preferences for products and product features from their sales and other product-related Web sites to enter and sustain in the global market. For example, the manufactures can make intelligent use of these customer preference data to decide on which products should be selected for targeted marketing. However, the selected products must attract as many customers as possible to increase the possibility of selling more than their respective competitors. This paper addresses this kind of product selection problem. That is, given a database of existing products P from the competitors, a set of company's own products Q, a dataset C of customer preferences and a positive integer k, we want to find k-most promising products (k-MPP) from Q with maximum expected number of total customers for targeted marketing. We model k-MPP query and propose an algorithmic framework for processing such query and its variants. Our framework utilizes grid-based data partitioning scheme and parallel computing techniques to realize k-MPP query. The effectiveness and efficiency of the framework are demonstrated by conducting extensive experiments with real and synthetic datasets.", "references": ["Arvanitis, A., Deligiannakis, A., Vassiliou, Y.: Efficient influence-based processing of market research queries. In: CIKM, pp. 1193---1202 (2012)", "Börzsönyi, S., Kossmann, D., Stocker, K.: The skyline operator. In: ICDE, pp. 421---430 (2001)", "Chang, K.C., Hwang, S.: Minimal probing: supporting expensive predicates for top-k queries. In: Proceedings of the 2002 ACM SIGMOD International Conference on Management of Data, Madison, Wisconsin, June 3---6, 2002, pp. 346---357 (2002)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0428-3"}, {"title": "Towards Conversational Recommender Systems", "authors": ["Konstantina Christakopoulou\n,", "Filip Radlinski\n,", "Katja Hofmann"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nPeople often ask others for restaurant recommendations as a way to discover new dining experiences. This makes restaurant recommendation an exciting scenario for recommender systems and has led to substantial research in this area. However, most such systems behave very differently from a human when asked for a recommendation. The goal of this paper is to begin to reduce this gap. In particular, humans can quickly establish preferences when asked to make a recommendation for someone they do not know. We address this cold-start recommendation problem in an online learning setting. We develop a preference elicitation framework to identify which questions to ask a new user to quickly learn their preferences. Taking advantage of latent structure in the recommendation space using a probabilistic latent factor model, our experiments with both synthetic and real world data compare different types of feedback and question selection strategies. We find that our framework can make very effective use of online user feedback, improving personalized recommendations over a static model by 25% after asking only 2 questions. Our results demonstrate dramatic benefits of starting from offline embeddings, and highlight the benefit of bandit-based explore-exploit strategies in this setting.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In KDD, 19--28, 2009.", "N. Ailon, Z. Karnin, and T. Joachims. Reducing dueling bandits to cardinal bandits. In ICML, 856--864, 2014.", "P. Auer. Using confidence bounds for exploitation-exploration trade-offs. In JMLR, 3:397--422, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939746"}, {"title": "Observing Group Decision Making Processes", "authors": ["Amra Delic\n,", "Julia Neidhardt\n,", "Thuy Ngoc Nguyen\n,", "Francesco Ricci\n,", "Laurens Rook\n,", "Hannes Werthner\n,", "Markus Zanker"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMost research on group recommender systems relies on the assumption that individuals have conflicting preferences; in order to generate group recommendations the system should identify a fair way of aggregating these preferences. Both empirical studies and theoretical frameworks have tried to identify the most effective preference aggregation techniques without coming to definite conclusions. In this paper, we propose to approach group recommendation from the group dynamics perspective and analyze the group decision making process for a particular task (in the travel domain). We observe several individual and group properties and correlate them to choice satisfaction. Supported by these initial results we therefore advocate for the development of new group recommendation techniques that consider group dynamics and support the full group decision making process.", "references": ["L. Ardissono, A. Goy, G. Petrone, M. Segnan, and P. Torasso. Intrigue: personalized recommendation of tourist attractions for desktop and hand held devices. Applied Artificial Intelligence, 17(8--9):687--714, 2003.", "R. F. Bales. A set of categories for the analysis of small group interaction. American Sociological Review, 15:257--263, 1950.", "L. Baltrunas, T. Makcinskas, and F. Ricci. Group recommendations with rank aggregation and collaborative filtering. In Proceedings of the fourth ACM conference on Recommender systems, RecSys'10, pages 119--126, Barcelona, Spain, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959168"}, {"title": "LocationSpark: a distributed in-memory data management system for big spatial data", "authors": ["Mingjie Tang\n,", "Yongyang Yu\n,", "Qutaibah M. Malluhi\n,", "Mourad Ouzzani\n,", "Walid G. Aref"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe present LocationSpark, a spatial data processing system built on top of Apache Spark, a widely used distributed data processing system. LocationSpark offers a rich set of spatial query operators, e.g., range search, kNN, spatio-textual operation, spatial-join, and kNN-join. To achieve high performance, LocationSpark employs various spatial indexes for in-memory data, and guarantees that immutable spatial indexes have low overhead with fault tolerance. In addition, we build two new layers over Spark, namely a query scheduler and a query executor. The query scheduler is responsible for mitigating skew in spatial queries, while the query executor selects the best plan based on the indexes and the nature of the spatial queries. Furthermore, to avoid unnecessary network communication overhead when processing overlapped spatial data, We embed an efficient spatial Bloom filter into LocationSpark's indexes. Finally, LocationSpark tracks frequently accessed spatial data, and dynamically flushes less frequently accessed data into disk. We evaluate our system on real workloads and demonstrate that it achieves an order of magnitude performance gain over a baseline framework.", "references": ["Geotrellis. https://github.com/geotrellis/geotrellis.", "Magellan. https://github.com/harsha2010/magellan.", "Spatialspark. http://simin.me/projects/spatialspark/."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007310"}, {"title": "Evaluating the credibility of english web sources as a foreign-language searcher", "authors": ["Alyson L. Young\n,", "Anita Komlodi\n,", "Gyöngyi Rózsa\n,", "Peng Chu"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nIn this paper, we present preliminary findings from an exploratory mixed-methods study of foreign-language searchers' credibility assessment of web documents when searching in English. Findings highlight a set of criteria used by these searchers to assess the credibility and accuracy of English web sources, the most frequent of which relates to source reputation. Foreign language searchers are more likely to trust an English language source if it is familiar or if it is the official source of information. Design aesthetics and functionality also have an impact on credibility. Findings have implications for the design of online sources that better support credibility assessments of foreign-language searchers.", "references": ["Berendt, B. and Kralisch, A. (2009). A user-centric approach to identifying best deployment strategies for language tools: the impact of content and access language on Web user behaviour and attitudes. Information Retrieval, 12(3), 380--399.", "Dochterman, M. A., & Stamp, G. H. (2010). Part 2: The Determination of Web Credibility: A Theoretical Model Derived From Qualitative Data. Qualitative Research Reports in Communication, 11(1), 44--50.", "Flanagin, A. J., Metzger, M. J., Pure, R., Markov, A., & Hartsell, E. (2014). Mitigating risk in ecommerce transactions: perceptions of information credibility and the role of user-generated ratings in product quality and purchase intention. Electronic Commerce Research, 14(1), 1--23."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017489"}, {"title": "Intellectualizing TRUST for Medical Websites", "authors": ["Himani Singal\n,", "Shruti Kohli"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nWith the plethora of options available, people have become doctors 'on their own' as they have started disease diagnosis and symptom analysis using help of online medical websites. In such a situation, it becomes utmost important to measure the TRUST value of these sources of online help as it can be toll taking to refer wrong information. This paper aims to improve, validate, and substantiate Fuzzy Based Trust Measures for assessing websites that provide functionalities like Online Medical Diagnosis & Symptoms Analysis.", "references": ["S. Fox and M. Duggan (2013) \"Pew internet and American life Project\", Helathonline, http://pewinternet.org/reports/2013/health-online.aspx.", "R. W. White and E. Horvitz (2009) \"Cyberchondria: Studies of the escalation of medical concerns in Web search\", ACM Transactions on Information Systems (TOIS), v. 27 n. 4, p. 1--37.", "Laurian Vega; Enid Montague; Tom DeHart(2010). Trust in health websites: A review of an emerging field, IHI'10 - Proceedings of the 1st ACM International Health Informatics Symposium 700--709."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905293"}, {"title": "Matching User Photos to Online Products with Robust Deep Features", "authors": ["Xi Wang\n,", "Zhenfeng Sun\n,", "Wenqiang Zhang\n,", "Yu Zhou\n,", "Yu-Gang Jiang"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper focuses on a practically very important problem of matching a real-world product photo to exactly the same item(s) in online shopping sites. The task is extremely challenging because the user photos (i.e., the queries in this scenario) are often captured in uncontrolled environments, while the product images in online shops are mostly taken by professionals with clean backgrounds and perfect lighting conditions. To tackle the problem, we study deep network architectures and training schemes, with the goal of learning a robust deep feature representation that is able to bridge the domain gap between the user photos and the online product images. Our contributions are two-fold. First, we propose an alternative of the popular contrastive loss used in siamese deep networks, namely robust contrastive loss, where we \"relax\" the penalty on positive pairs to alleviate over-fitting. Second, a multi-task fine-tuning approach is introduced to learn a better feature representation, which not only incorporates knowledge from the provided training photo pairs, but also explores additional information from the large ImageNet dataset to regularize the fine-tuning procedure. Experiments on two challenging real-world datasets demonstrate that both the robust contrastive loss and the multi-task fine-tuning approach are effective, leading to very promising results with a time cost suitable for real-time retrieval.", "references": ["S. Bell and K. Bala. Learning visual similarity for product design with convolutional neural networks. ACM Transactions on Graphics, 34(4):98, 2015.", "G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. The Journal of Machine Learning Research, 11:1109--1135, 2010.", "S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 539--546. IEEE, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912002"}, {"title": "10 Optimizations on Linear Search", "authors": ["Thomas A. Limoncelli"], "publication": "Queue", "abstract": "Abstract\nThe operations side of the story", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.2984631"}, {"title": "Attention Based Recurrent Neural Networks for Online Advertising", "authors": ["Shuangfei Zhai\n,", "Keng-hao Chang\n,", "Ruofei Zhang\n,", "Zhongfei Zhang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe investigate the use of recurrent neural networks (RNNs) in the context of online advertising, where we use RNNs to map both query and ads to real valued vectors. In addition, we propose an attention network that assigns scores to different word locations according to their intent importance. The vector output is computed by a weighted sum of the vectors at each word. We perform end-to-end training of both the RNN and attention network under the guidance of user click logs. We show that the attention network improves the quality of learned vector representations evaluated by AUC on a manually labeled dataset. Moreover, we show that keywords extracted according to the attention scores are easy to interpret and significantly outperform the state-of-the-art query intent extraction methods.", "references": ["P.-S. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck. Learning deep structured semantic models for web search using clickthrough data. In CIKM 2013.", "P. Liu, J. Azimi, and R. Zhang. Contextual query intent extraction for paid search selectio. In WWW 2015.", "K. T. Maxwell and W. B. Croft. Compact query term selection using topically related text. In SIGIR 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889373"}, {"title": "BotOrNot: A System to Evaluate Social Bots", "authors": ["Clayton Allen Davis\n,", "Onur Varol\n,", "Emilio Ferrara\n,", "Alessandro Flammini\n,", "Filippo Menczer"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWhile most online social media accounts are controlled by humans, these platforms also host automated agents called social bots or sybil accounts. Recent literature reported on cases of social bots imitating humans to manipulate discussions, alter the popularity of users, pollute content and spread misinformation, and even perform terrorist propaganda and recruitment actions. Here we present BotOrNot, a publicly-available service that leverages more than one thousand features to evaluate the extent to which a Twitter account exhibits similarity to the known characteristics of social bots. Since its release in May 2014, BotOrNot has served over one million requests via our website and APIs.", "references": ["Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. Design and analysis of a social botnet. Computer Networks, 57(2):556--578, 2013.", "E. Ferrara, O. Varol, C. Davis, F. Menczer, and A. Flammini. The rise of social bots. Commun. ACM, in press. Preprint arXiv:1407.5225.", "K. Lee, B. D. Eoff, and J. Caverlee. Seven months with the devils: A long-term study of content polluters on Twitter. In Proc. 5th AAAI Intl. Conf. on Web and Social Media (ICWSM), pages 185--192, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889302"}, {"title": "Ranking Health Web Pages with Relevance and Understandability", "authors": ["Joao Palotti\n,", "Lorraine Goeuriot\n,", "Guido Zuccon\n,", "Allan Hanbury"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe propose a method that integrates relevance and understandability to rank health web documents. We use a learning to rank approach with standard retrieval features to determine topical relevance and additional features based on readability measures and medical lexical aspects to determine understandability. Our experiments measured the effectiveness of the learning to rank approach integrating understandability on a consumer health benchmark. The findings suggest that this approach promotes documents that are at the same time topically relevant and understandable.", "references": ["M. Benigeri and P. Pluye. Shortcomings of health information on the internet. Health Prom. Inter., 2003.", "K. Collins-Thompson, P. N. Bennett, R. W. White, S. de la Chica, and D. Sontag. Personalizing web search results by reading level. In Proc. of CIKM, 2011.", "W. H. Dubay. The principles of readability. Costa Mesa, CA: Impact Information, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914741"}, {"title": "User Intent in Multimedia Search: A Survey of the State of the Art and Future Challenges", "authors": ["Christoph Kofler\n,", "Martha Larson\n,", "Alan Hanjalic"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nToday's multimedia search engines are expected to respond to queries reflecting a wide variety of information needs from users with different goals. The topical dimension (“what” the user is searching for) of these information needs is well studied; however, the intent dimension (“why” the user is searching) has received relatively less attention. Specifically, intent is the “immediate reason, purpose, or goal” that motivates a user to query a search engine. We present a thorough survey of multimedia information retrieval research directed at the problem of enabling search engines to respond to user intent. The survey begins by defining intent, including a differentiation from related, often-confused concepts. It then presents the key conceptual models of search intent. The core is an overview of intent-aware approaches that operate at each stage of the multimedia search engine pipeline (i.e., indexing, query processing, ranking). We discuss intent in conventional text-based search wherever it provides insight into multimedia search intent or intent-aware approaches. Finally, we identify and discuss the most important future challenges for intent-aware multimedia search engines. Facing these challenges will allow multimedia information retrieval to recognize and respond to user intent and, as a result, fully satisfy the information needs of users.", "references": ["Rakesh Agrawal, Sreenivas Gollapudi, Alan Halverson, and Samuel Ieong. 2009. Diversifying search results. In Proceedings of the 2nd ACM International Conference on Web Search and Data Mining (WSDM'09). ACM, 5--14.", "Morgan Ames and Mor Naaman. 2007. Why we tag: Motivations for annotation in mobile and online media. In Proceedings of the SIGCHI Conference on Human Factors in Computer Systems (CHI'07). ACM, 971--980.", "Paul André, Edward Cutrell, Desney S. Tan, and Greg Smith. 2009. Designing novel image search interfaces by understanding unique characteristics and usage. In Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II (INTERACT'09). Springer-Verlag, 340--353."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2954930"}, {"title": "Exploiting Item Representations for Soft Clustering Recommendation", "authors": ["Rafael M. D'Addio\n,", "Marcelo G. Manzato"], "publication": "Webmedia '16: Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nRecommender systems help dealing with the information overload problem since they provide personalized content for users. There are two major paradigms in recommendation: content-based and collaborative filtering. Regardless of the paradigm, there has been a great effort into finding additional information to better describe items and/or users, which in turn helps to increase the personalization power of the system. User's reviews turn out to be a great source of information, since they provide information about the characteristics of the items as well as insights about the opinion of the user towards them. In previous works, we explored some techniques for extracting information from reviews in order to generate items' representations and applied them into an item k-NN algorithm. In this work, we explore the impact that those representations, alongside with rating and genre-based representations, can cause into a soft clustering-based recommender system. We compare our findings with the item k-NN algorithm and observe that they are better in some cases, but the soft clustering recommender has lower computational cost.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734--749, 2005.", "C. C. Aggarwal and C. X. Zhai. Mining Text Data. Springer Publishing Company, Incorporated, 2012.", "J. C. Bezdek. Pattern Recognition with Fuzzy Objective Function Algorithms. Kluwer Academic Publishers, Norwell, MA, USA, 1981."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2976796.2976858"}, {"title": "A Payment Protocol of the Web, for the Web: Or, Finally Enabling Web Micropayments with the Interledger Protocol", "authors": ["Evan Schwartz"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe history of the Web is full of attempts to enable micropayments for content and services. All have failed to achieve widespread adoption. This has fueled recurring debates about the merits or fundamental flaws of the concept of asking users to pay small amounts for what they use online. As a result, however, of the Web's lack of native payment infrastructure, the only viable business models concentrate earnings and power in a small group of content and advertising aggregators and increase demand for privacy-infringing technologies. We need to learn from the failures of previous micropayment schemes and we need to create a payment protocol that is of the Web, for the Web.\nWe present a demo browser extension that uses the new Interledger Protocol (ILP) to demonstrate how payments and micropayments can be seamlessly built into the Web. ILP is an open payment protocol for payments across different payment networks that is being developed in the W3C Interledger Community Group. It enables new possibilities for developers and a better experience for users of the Open Web Platform.", "references": ["W3C interledger community group. https://www.w3.org/community/interledger.", "D. Ariely. Predictably irrational. Harper, 2008.", "S. Nakamoto. Bitcoin: A peer-to-peer electronic cash system. Consulted, 1(2012):28, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889305"}, {"title": "Classifying Data to Reduce Long-Term Data Movement in Shingled Write Disks", "authors": ["Stephanie N. Jones\n,", "Ahmed Amer\n,", "Ethan L. Miller\n,", "Darrell D. E. Long\n,", "Rekha Pitchumani\n,", "Christina R. Strong"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nShingled magnetic recording (SMR) is a means of increasing the density of hard drives that brings a new set of challenges. Due to the nature of SMR disks, updating in place is not an option. Holes left by invalidated data can only be filled if the entire band is reclaimed, and a poor band compaction algorithm could result in spending a lot of time moving blocks over the lifetime of the device. We propose using write frequency to separate blocks to reduce data movement and develop a band compaction algorithm that implements this heuristic. We demonstrate how our algorithm results in improved data management, resulting in an up to 45% reduction in required data movements when compared to naive approaches to band management.", "references": ["Abutalib Aghayev and Peter Desnoyers. 2015. Skylight-A window on shingled disk operation. In Proceedings of the 13th USENIX Conference on File and Storage Technologies. 135--149.", "Ahmed Amer, Darrell D. E. Long, Ethan L. Miller, J.-F. Paris, and S. J. Thomas Schwarz. 2010. Design issues for a shingled write disk system. In Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST’10). IEEE, Los Alamitos, CA, 1--12.", "Medha Bhadkamkar, Jorge Guerra, Luis Useche, Sam Burnett, Jason Liptak, Raju Rangaswami, and Vagelis Hristidis. 2009. BORG: Block-reORGanization for self-optimizing storage systems. In Proceedings of the 7th USENIX Conference on File and Storage Technologies (FAST’09)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851505"}, {"title": "An Evaluation Methodology of the Relation Between Personality Profiles and Academic Performance in Students of Information Systems", "authors": ["Giovanni Stroppa Faquin\n,", "Maria L.F. Falci\n,", "Marco Antonio P. Araujo"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe purpose of this article is to understand how different personality profiles can be related to different academic performances and skill levels in management, computing and mathematics disciplines in graduation students in Information Systems. With an interdisciplinary methodological approach, the research uses the theory of psychological types of C. G. Jung to evaluate how personality predispositions can be connected to the various skills required of an academic in Information Systems.", "references": ["Aires, N. B., Sales, P., Lopes, L. V., van Vessen Jr, M., Machado, E. F., e da Silva, C. F. (2015). Proposta do Uso de Analise de Sentimento no Desenvolvimento de uma nova Metrica de Sustentabilidade. In: Simposio Brasileiro de Sistemas de Informacao. SBC. p. 455-458.", "Ardini, Amalia et al. 2014. Social computing for software engineering: A mapping study. In: Computer Science Review, v. 13, p. 75-93.", "Ardis, Mark et al. 2015. SE 2014: Curriculum Guidelines for Undergraduate Degree Programs in Software Engineering. Computer, v. 48, n. 11, p. 106-109."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022003"}, {"title": "Robust Method for Detecting Target-like Signals in Training Samples in STAP", "authors": ["Sudan Han\n,", "Chongyi Fan\n,", "Xiaotao Huang"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nHeterogeneous environment has a severely deteriorative impact on the performance of STAP, among which target-like signals in training samples (TTS) always tend to be the most serious. Traditional detectors for TSS such as generalized inner product (GIP) and adaptive power residue (APR) employ sample covariance matrix to estimate the interference covariance matrix in the cell under test (CUT), which may suffer large performance degradation in heterogeneous environments due to estimation error. This paper proposes two modified detectors based on subaperture smoothing technique which only exploits the sample in CUT to estimate the interference covariance matrix. The proposed method can estimate the interference covariance matrix more accurately and identify TSS more effectively. Simulation and measured results confirm the effectiveness and robustness of the proposed method.", "references": ["Ward, J. 1994. Space-time adaptive processing for airborne radar, MIT Lincoln Laboratory.", "Reed, I.S., Mallett, J.D., and Brennan, L.E. 1974. Rapid convergence rate in adaptive arrays. IEEE Transactions on Aerospace and Electronic Systems, 853--863.", "Klemm, R. 2004. Principles of Space-Time Adaptive Processing, London, UK: The Institution of Electrical Engineers."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015173"}, {"title": "Sentiment classification for unlabeled dataset using Doc2Vec with JST", "authors": ["Sangheon Lee\n,", "Xiangdan Jin\n,", "Wooju Kim"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nSupervised learning require sentiment labeled corpus for training. But it is hard to apply automatic sentiment classification system to new domain because labeled dataset construction costs a lot of time. Meanwhile, researches using Doc2vec based document representation beat out other sentiment classification researches. However, these document representation methods only represent documents' context or sentiment. In this paper, we proposed supervised learning scheme for unlabeled corpus and also proposed document representation method which can simultaneously represent documents' context and sentiment.", "references": ["B. Pang and L. Lee. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In ACL '04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, Morristown, NJ, USA, 2004, Association for Computational Linguistics, 271--278.", "B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?: sentiment classification using machine learning techniques. In EMNLP '02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing, Morristown, NJ, USA, 2002, Association for Computational Linguistics, 79--86.", "Blei, D. M., Ng, A. Y., and Jordan, M. I. Latent dirichlet allocation. The Journal of machine Learning research, 3(Jan), 2003, 993--1022."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971631"}, {"title": "Investigating Information Search Behavior using Personal and Social Contextual Signals", "authors": ["Dongho Choi"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nPeople have their behavioral patterns, through which they determine how to use, seek and share information. Also, the patterns interact with a person's intrinsic and extrinsic characteristics such as values, attitudes, social and cognitive capitals, affecting behaviors in different contexts and situations. Meanwhile, the emerging trends of smartphones and wearable computing allow for the creation of a rich user behavioral profile. Such a behavioral (personal, social, mobile, and cognitive) profile goes beyond traditional browser-based context and allows one's personality type and social capital to become pivotal indicators of search behavior. Through the multi-modal data analysis, I want to identify the correlations between different signal types as observed in everyday life information seeking contexts and predict individuals' search behavior using personal and social contextual signals.", "references": ["P. P. Biemer, R. M. Groves, L. E. Lyberg, N. A. Mathiowetz, and S. Sudman. Measurement errors in surveys, volume 173. John Wiley & Sons, 2011.", "P. Bourdieu. Distinction: A Social Critique of the Judgement of Taste. Harvard University Press, 1984.", "T. A. Burdick. Success and Diversity in Information Seeking: Gender and the Information Search Styles Model. School Library Media Quarterly, 25(1):19--26, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854953"}, {"title": "Semi-Automatic Semantic Based Natural Images Retrieval System", "authors": ["Doaa M. Alebiary\n,", "Noura A. Semary\n,", "Hala H. Zayed"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nContent-based Image Retrieval (CBIR) is a term referring to looking for digital images by analyzing content of images rather than its metadata. CBIR system retrieves the image via low-level features such as color, texture and shape. In this work, we propose an improved CBIR system that retrieves images from a database based on the semantic features of them. The methodology that divide image and extracts low-level features from each region and label each one with the suitable concept (Sky, Sand, Water, trunks, foliage, rocks,..., and Grass). The results of the paper reflects the efficiency of the system for retrieving images with up to 98% recognition ratio.", "references": ["T. Fawcett. An introduction to roc analysis. Pattern recognition letters, 27(8):861--874, 2006.", "Y. Liu, D. Zhang, G. Lu, and W.-Y. Ma. A survey of content-based image retrieval with high-level semantics. Pattern Recognition, 40(1):262--282, 2007.", "H. Müller, N. Michoux, D. Bandon, and A. Geissbuhler. A review of content-based image retrieval systems in medical applicationsâĂŤclinical benefits and future directions. International journal of medical informatics, 73(1):1--23, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908503"}, {"title": "Learning Global Term Weights for Content-based Recommender Systems", "authors": ["Yupeng Gu\n,", "Bo Zhao\n,", "David Hardtke\n,", "Yizhou Sun"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecommender systems typically leverage two types of signals to effectively recommend items to users: user activities and content matching between user and item profiles, and recommendation models in literature are usually categorized into collaborative filtering models, content-based models and hybrid models. In practice, when rich profiles about users and items are available, and user activities are sparse (cold-start), effective content matching signals become much more important in the relevance of the recommendation. The de-facto method to measure similarity between two pieces of text is computing the cosine similarity of the two bags of words, and each word is weighted by TF (term frequency within the document) x IDF (inverted document frequency of the word within the corpus). In general sense, TF can represent any local weighting scheme of the word within each document, and IDF can represent any global weighting scheme of the word across the corpus. In this paper, we focus on the latter, i.e., optimizing the global term weights, for a particular recommendation domain by leveraging supervised approaches. The intuition is that some frequent words (lower IDF, e.g. ``database'') can be essential and predictive for relevant recommendation, while some rare words (higher IDF, e.g. the name of a small company) could have less predictive power. Given plenty of observed activities between users and items as training data, we should be able to learn better domain-specific global term weights, which can further improve the relevance of recommendation.\nWe propose a unified method that can simultaneously learn the weights of multiple content matching signals, as well as global term weights for specific recommendation tasks. Our method is efficient to handle large-scale training data generated by production recommender systems. And experiments on LinkedIn job recommendation data justify the effectiveness of our approach.", "references": ["G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Trans. on Information Systems (TOIS), 23(1):103--145, 2005.", "G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender Systems Handbook, pages 217--253. Springer, 2011.", "D. Agarwal and B.-C. Chen. flda: matrix factorization through latent dirichlet allocation. In Proc. of the third ACM Int. Conf. on Web Search and Data Mining, pages 91--100, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883069"}, {"title": "Multi-Protocol Video Delivery with Late Trans-Muxing", "authors": ["Rufael Mekuria\n,", "Jelte Fennema\n,", "Dirk Griffioen"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn practice, video delivery using multiple protocols is needed to support the wide range of clients in the digital media ecosystem. Naive approaches increase backhaul traffic and cache storage requirements proportional to the number of protocols in use. To reduce this overhead, we present an efficient multi-protocol video delivery architecture. It exploits the fact that media segments in different protocols are often based on the same raw encoded media data. Instead of caching and distributing near duplicate media segments for each protocol throughout the content delivery network, we push their generation towards the edge. We call this Late Trans-Muxing (LTM). We implement LTM in a smart edge cache that can request and cache media byte ranges and generate protocol specific media segments on the fly. Experiments in an emulation testbed show that backhaul traffic and cache storage are reduced up to 85% and 50% respectively compared to CDN based approaches. This shows the benefit of LTM in multi-protocol DASH based video delivery.", "references": ["H. Schulzrinne et al., \"RFC 3550 RTP: A Transport Protocol for Real-Time Applications,\" IETF, 2003.", "Apple, \"HTTP Live Streaming,\" 3 2016. {Online}. Available: https://developer.apple.com/streaming/.", "Microsoft, \"Microsoft Smooth Streaming,\" {Online}. Available: http://www.iis.net/downloads/microsoft/smooth-streaming."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967189"}, {"title": "First Person View Video Summarization Subject to the User Needs", "authors": ["Ana Garcia del Molino"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nOur life is becoming heavily documented and expressed on the digital substrate. This booming flow of consumer video has lead to an increasing demand of multimedia analysis tools to organize and summarize those visual memories. Due to the personal nature of such videos, though, the summarization needs to be adapted to the user needs and preferences. Yet, most summarization systems rely solely on pre-defined criteria, e.g. story-coherence or interestingness pre-trained classifiers. I propose a system which is capable of finding relevant digital memories to a given semantic query, and then summarize them on a customized manner. The proposed framework includes a wide set of tools to match a user's needs, from retrieval using multimodal queries to summarization striving to his/her preferences, both provided passively and actively. Preliminary results show the high potential of such a framework, with over 70% retrieval accuracy. More importantly, as seen from the user study, the summaries generated achieve an unprecedented compromise between usability and quality.", "references": ["K. Aizawa, K. Ishijima, and M. Shiina. Summarizing wearable video. In International Conference on Image Processing, volume 3, pages 398--401. IEEE, 2001.", "V. Chandrasekhar, W. Min, X. Li, C. Tan, B. Mandal, L. Li, and J. H. Lim. Efficient retrieval from large-scale egocentric visual data using a sparse graph representation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 527--534, 2014.", "A. G. del Molino, B. Mandal, L. Li, and J. H. Lim. Organizing and retrieving episodic memories from first person view. In International Conference on Multimedia and Expo Workshops, pages 1--6. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2971474"}, {"title": "Evaluation of Musical Creativity and Musical Metacreation Systems", "authors": ["Kat Agres\n,", "Jamie Forth\n,", "Geraint A. Wiggins"], "publication": "Computers in Entertainment", "abstract": "Abstract\nThe field of computational creativity, including musical metacreation, strives to develop artificial systems that are capable of demonstrating creative behavior or producing creative artefacts. But the claim of creativity is often assessed, subjectively only on the part of the researcher and not objectively at all. This article provides theoretical motivation for more systematic evaluation of musical metacreation and computationally creative systems and presents an overview of current methods used to assess human and machine creativity that may be adapted for this purpose. In order to highlight the need for a varied set of evaluation tools, a distinction is drawn among three types of creative systems: those that are purely generative, those that contain internal or external feedback, and those that are capable of reflection and self-reflection. To address the evaluation of each of these aspects, concrete examples of methods and techniques are suggested to help researchers (1) evaluate their systems' creative process and generated artefacts, and test their impact on the perceptual, cognitive, and affective states of the audience, and (2) build mechanisms for reflection into the creative system, including models of human perception and cognition, to endow creative systems with internal evaluative mechanisms to drive self-reflective processes. The first type of evaluation can be considered external to the creative system and may be employed by the researcher to both better understand the efficacy of their system and its impact and to incorporate feedback into the system. Here we take the stance that understanding human creativity can lend insight to computational approaches, and knowledge of how humans perceive creative systems and their output can be incorporated into artificial agents as feedback to provide a sense of how a creation will impact the audience. The second type centers around internal evaluation, in which the system is able to reason about its own behavior and generated output. We argue that creative behavior cannot occur without feedback and reflection by the creative/metacreative system itself. More rigorous empirical testing will allow computational and metacreative systems to become more creative by definition and can be used to demonstrate the impact and novelty of particular approaches.", "references": ["Dilshat Abla, Kentaro Katahira, and Kazuo Okanoya. 2008. On-line assessment of statistical learning by event-related potentials. J. Cogn. Neurosci. 20, 6 (2008), 952--964.", "Kat Agres, Samer Abdallah, and Marcus Pearce. 2013. An information-theoretic account of musical expectation and memory. In Proceedings of the 35th Annual Conference of the Cognitive Science Society, M. Knauff, M. Pauen, N. Sebanz, and I. Wachsmuth (Eds.). Cognitive Science Society, Austin, TX, 127--132.", "Kimmo Alho, Carles Escera, Rosa Díaz, Elena Yago, and Josep M. Serra. 1997. Effects of involuntary auditory attention on visual task performance and brain activity. Neuroreport 8, 15 (1997), 3233--3237."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967506"}, {"title": "Joint Behavioural Control of Autonomous Multi-Robot Systems for Lead-Follower Formation to Improve Human-Robot Interaction", "authors": ["M. Udochu Nnennaya\n,", "Etse-Oghena Akpaibor\n,", "Akash P. Borate\n,", "Aakash G. Deshpande\n,", "Frank Lewis"], "publication": "PETRA '16: Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nThe effective autonomous cooperation between unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) has led to an increase in research and development for improving human robot interaction, due to their high potential for achieving successful missions in challenging environments. In this paper, a voice command system is developed to control a UAV and a vision-based approach system controls the UGV in a lead-follower formation to enhance human-robot teams for military defence and rescue missions in urban areas. The proposed voice control framework is executed using open source interface, Robot Operating System (ROS), for aerial vehicle communication supported by spoken dialogues using a wireless microphone, while the UGV detects and tracks a target image captured by the on board low-cost camera from the height of the UAV, using the proposed vision-based approach. The lead-follower formation is based on communication and visibility between the UAV and UGV in a given environment. In addition, a speech recognition module translates voice input to text and the published text is then mapped to the control input of the UAV in order to execute corresponding voice commands. The relative distance and position between the UAV and UGV is estimated from the image received via laptop. UGVs and UAVs have sophisticated design features such as network device communication, navigation, vision sensors and obstacle detection sensors. The UAV is a quad-copter that leads the UGV to accessible areas, while the UGV plays the role of the follower with wheel activators to track and locate the target image on the UAV, given a defined geographic path. The joint behavioural control system of the proposed voice command and vision-based approach is verified by experimental setups that show the UAV has a high voice recognition response and the UGV autonomously tracks the moving UAV in real time operation. As a consequence of the experimental tests, it is expected that the voice control system and vision-based approach developed play an important role in future combat fields.", "references": ["Aghaeeyan, A.; Abdollahi, F.; Talebi, H.A., \"Robust cooperative control in the presence of obstacles,\" Electrical Engineering (ICEE), 2013 21st Iranian Conference on, vol., no., pp. 1,6, 14-16 May 2013", "Grocholsky, B.; Keller, J.; Kumar, V.; Pappas, G., \"Cooperative air and ground surveillance,\" Robotics & Automation Magazine, IEEE, vol.13, no.3, pp. 16,25, Sept. 2006", "Phan, C.; Liu, H.H.T., \"A cooperative UAV/UGV platform for wildfire detection and fighting,\" System Simulation and Scientific Computing, 2008. ICSC 2008. Asia Simulation Conference - 7th International Conference on, vol., no., pp. 494,498, 10-12 Oct. 2008"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910674.2910676"}, {"title": "Evaluating Document Retrieval Methods for Resource Selection in Clustered P2P IR", "authors": ["Rami Suleiman Alkhawaldeh\n,", "Joemon M. Jose\n,", "Deepak P"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nResource Selection (or Query Routing) is an important step in P2P IR. Though analogous to document retrieval in the sense of choosing a relevant subset of resources, resource selection methods have evolved independently from those for document retrieval. Among the reasons for such divergence is that document retrieval targets scenarios where underlying resources are semantically homogeneous, whereas peers would manage diverse content. We observe that semantic heterogeneity is mitigated in the clustered 2-tier P2P IR architecture resource selection layer by way of usage of clustering, and posit that this necessitates a re-look at the applicability of document retrieval methods for resource selection within such a framework. This paper empirically benchmarks document retrieval models against the state-of-the-art resource selection models for the problem of resource selection in the clustered P2P IR architecture, using classical IR evaluation metrics. Our benchmarking study illustrates that document retrieval models significantly outperform other methods for the task of resource selection in the clustered P2P IR architecture. This indicates that clustered P2P IR framework can exploit advancements in document retrieval methods to deliver corresponding improvements in resource selection, indicating potential convergence of these fields for the clustered P2P IR architecture.", "references": ["R. S. Alkhawaldeh and J. M. Jose. Experimental study on semi-structured peer-to-peer information retrieval network. In In CLEF 2015, Toulouse, France, September 8--11, 2015, Proceedings, pages 3--14. 2015.", "R. Aly, D. Hiemstra, and T. Demeester. Taily: Shard selection using the tail of score distributions. In SIGIR, 2013.", "G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM TOIS, 20(4):357--389, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983912"}, {"title": "Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering", "authors": ["Ruining He\n,", "Julian McAuley"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nBuilding a successful recommender system depends on understanding both the dimensions of people's preferences as well as their dynamics. In certain domains, such as fashion, modeling such preferences can be incredibly difficult, due to the need to simultaneously model the visual appearance of products as well as their evolution over time. The subtle semantics and non-linear dynamics of fashion evolution raise unique challenges especially considering the sparsity and large scale of the underlying datasets. In this paper we build novel models for the One-Class Collaborative Filtering setting, where our goal is to estimate users' fashion-aware personalized ranking functions based on their past feedback. To uncover the complex and evolving visual factors that people consider when evaluating products, our method combines high-level visual features extracted from a deep convolutional neural network, users' past feedback, as well as evolving trends within the community. Experimentally we evaluate our method on two large real-world datasets from Amazon.com, where we show it to outperform state-of-the-art personalized ranking measures, and also use it to visualize the high-level fashion trends across the 11-year span of our dataset.", "references": ["D. W. Aha, D. Kibler, and M. K. Albert. Instance-based learning algorithms. Machine learning, 1991.", "R. M. Bell, Y. Koren, and C. Volinsky. The bellkor solution to the netflix prize, 2007.", "R. Bellman. On the approximation of curves by line segments using dynamic programming. Communications of the ACM, 1961."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883037"}, {"title": "Semantic Graph based Pseudo Relevance Feedback for Biomedical Information Retrieval", "authors": ["Yuanyuan Zhang\n,", "James Z. Wang\n,", "Pradip K. Srimani"], "publication": "CSBio '16: Proceedings of the 7th International Conference on Computational Systems-Biology and Bioinformatics", "abstract": "ABSTRACT\nThis paper proposed a novel pseudo relevance feedback strategy to facilitate the retrieval of more relevant biomedical documents by improving the quality of both feedback documents and expansion terms. Firstly, an ontology-graph based query expansion technique is applied to retrieve more relevant feedback documents. Secondly, useful expansion terms are extracted from the feedback documents based on a semantic graph based ranking approach. We add the expansion terms to the user query to retrieve more relevant documents. We use 10-fold cross validation technique to evaluate the performance of the proposed pseudo relevance feedback strategy over OHSUMED test collection. The experimental results demonstrate that the proposed strategy improves the retrieval performance by 33.8% over free-text based query in 11-point average precision. The proposed strategy also achieves better retrieval performance than two representative pseudo relevance feedback approaches. We have integrated this new strategy into G-Bean, a graph-based biomedical search engine. G-Bean is available at: http://bioinformatics.clemson.edu:8080/G-Bean/index.jsp", "references": ["S. Abdou, J. Savoy, and P. Ruch. Evaluation of stemming, query expansion and manual indexing approaches for the genomic task. In Proceedings of the Fourteenth Text REtrieval Conference (TREC 2005), pages 15--18, Gaithersburg, Maryland, November 2005.", "A. R. Aronson and F. M. Lang. An overview of MetaMap: historical perspec-tive and recent advances. Journal of the American Medical Informatics Association, 17(3):229--236, 2010.", "L. Dong, P. K. Srimani, and J. Z. Wang. Ontology graph based query expansion for biomedical information retrieval. In Proceedings of the 5th IEEE International Conference on Bioinformatics and Biomedicine, pages 488--493, Atlanta, GA, November 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3029375.3029381"}, {"title": "Scalable Auto-Tuning of Synthesis Parameters for Optimizing High-Performance Processors", "authors": ["Matthew M. Ziegler\n,", "Hung-Yi Liu\n,", "Luca P. Carloni"], "publication": "ISLPED '16: Proceedings of the 2016 International Symposium on Low Power Electronics and Design", "abstract": "ABSTRACT\nModern logic and physical synthesis tools provide numerous options and parameters that can drastically impact design quality; however, the large number of options leads to a complex design space difficult for human designers to navigate. By employing intelligent search strategies and parallel computing we can tackle this parameter tuning problem, thus automating one of the key design tasks conventionally performed by a human designer. In this paper we present a novel learning-based algorithm for synthesis parameter optimization. This new algorithm has been integrated into our existing autonomous parameter-tuning system, which was used to design multiple 22nm industrial chips and is currently being used for 14nm chips. These techniques show, on average, over 40% reduction in total negative slack and over 10% power reduction across hundreds of 14nm industrial processor macros while reducing overall human design effort. We also present a new higher-level system that manages parameter tuning of multiple designs in a scalable way. This new system addresses the needs of large design teams by prioritizing the tuning effort to maximize returns given the available compute resources.", "references": ["L. Trevillyan, et al., \"An Integrated Environment for Technology Closure of Deep-Submicron IC Designs,\" IEEE Design & Test of Computers, vol. 21:1, 2004.", "M. M. Ziegler, et al., \"A Synthesis-Parameter Tuning System for Autonomous Design-Space Exploration,\" DATE 2016.", "J. D. Warnock, et al., \"22nm Next-Generation IBM System z Microprocessor,\" ISSCC 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934583.2934620"}, {"title": "A Video Scene Detection of the Instantaneous Motion by Farmed Fry", "authors": ["Koji Abe\n,", "Ryota Shimizu\n,", "Hitoshi Habe\n,", "Yoshiaki Taniguchi\n,", "Nobukazu Iguchi"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nAs a method for supporting fish farming, this paper presents a video scene detection when farmed fry start instantaneously in a tank due to environmental stimuli. Although some environmental stimuli such as sound noises or lighting startle the fry and the stimuli bring about the instantaneous response, actual situations around the tanks in which the stimuli occur are unclear in detail. From the fact the fry often die due to crashes to the tank's wall and between the fry by the response, a monitoring system for the fry and situation around the pool could find causes of the stimuli, and it could result in decrease of the death number of the fry. In this research, the fry which swim in a tank are monitored by a video camera and the video scenes at the response are detected by a SVM with a feature value which represents fry's acceleration using sequential frames of the moving image. Preparing the moving images which include scenes of the response by fish in a tank, performances of the proposed method were examined. From experimental results, accuracy ratios of the recall and the precision for the scene detection have shown more than 80% on average and 100% under normal illuminances (108.5 lux on average), respectively.", "references": ["Y. Sawada, T. Okada, S. Miyashita, O. Murata, and H. Kumai. Completion of the pacific bluefin tuna thunnus orientalis (temminck et schlegel) life cycle. Aquaculture Research, 36(5):413--421, March 2005.", "W. Zeng, W. Gao, and D. Zhao. Automatic moving object extraction in mpeg video. In IEEE Int. Symp. Circ. Syst., pages 524--527, May 2003.", "M. Chuang, J. Hwang, K. Williams, and R. Towler. Tracking live fish from low-contrast and low-frame-rate stereo videos. IEEE Trans. Circ. Syst. Video Tech., 25(1):167--179, Jan 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015191"}, {"title": "Poster: Approximate Memoization for Perception-based Mobile Applications", "authors": ["Utsav Drolia\n,", "Katherine Guo\n,", "Rajeev Gandhi\n,", "Priya Narasimhan"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nNo abstract available.", "references": ["P. Bahl, R. Y. Han, L. E. Li, and M. Satyanarayanan. Advancing the state of mobile cloud computing. In ACM Workshop on Mobile Cloud Computing and Services, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2938594"}, {"title": "Tag-Enhanced Collaborative Filtering for Increasing Transparency and Interactive Control", "authors": ["Tim Donkers\n,", "Benedikt Loepp\n,", "Jürgen Ziegler"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nTo increase transparency and interactive control in Recommender Systems, we extended the Matrix Factorization technique widely used in Collaborative Filtering by learning an integrated model of user-generated tags and latent factors derived from user ratings. Our approach enables users to manipulate their preference profile expressed implicitly in the (intransparent) factor space through explicitly presented tags. Furthermore, it seems helpful in cold-start situations since user preferences can be elicited via meaningful tags instead of ratings. We evaluate this approach and present a user study that to our knowledge is the most extensive empirical study of tag-enhanced recommending to date. Among other findings, we obtained promising results in terms of recommendation quality and perceived transparency, as well as regarding user experience, which we analyzed by Structural Equation Modeling.", "references": ["Bollen, D., Knijnenburg, B. P., Willemsen, M. C., and Graus, M. P. 2010. Understanding choice overload in recommender systems. In Proc. RecSys '10. ACM, 63--70.", "Bostandjiev, S., O'Donovan, J., and Höllerer, T. 2012. TasteWeights: A visual interactive hybrid recommender system. In Proc. RecSys '12. ACM, 35--42.", "Brooke. J. 1996. SUS -- A quick and dirty usability scale. In Usability Evaluation in Industry, Taylor & Francis, 189--194."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930287"}, {"title": "Understanding User Behavior From Online Traces", "authors": ["Elad Kravi"], "publication": "SIGMOD'16 PhD: Proceedings of the 2016 on SIGMOD'16 PhD Symposium", "abstract": "ABSTRACT\nPeople nowadays share large amounts of data online, explicitly or implicitly. Analysis of such data can detect useful behavior patterns of varying natures and scales, from mass immigration between continents to trendy venues in a city in turn. Detecting these patterns can be used for improving online services. However, capturing behavior patterns may be challenging, since such patterns are often of a specialized essence, no benchmark or labeled data exist, and it is not even clear how to formulate them to enable computation. Moreover, it is often unclear how recognition of these patterns can be translated into concrete service improvement. We analyzed major datasets of three common types of online traces: microbloging, social networking, and web search. We detected online behavior patterns and utilized them toward novel services and improvement of traditional services. In this paper we describe our studies and findings, and offer a vision for future development.", "references": ["K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. Collaborative personalized tweet recommendation. In SIGIR, 2012.", "J. Cranshaw, R. Schwartz, J. I. Hong, and N. Sadeh. The livehoods project: Utilizing social media to understand the dynamics of a city. In AAAI, 2012.", "I. Grabovitch-Zuyev, Y. Kanza, E. Kravi, and B. Pat. On the correlation between textual content and geospatial locations in microblogs. In GeoRich, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926693.2929901"}, {"title": "Behaviorism is Not Enough: Better Recommendations through Listening to Users", "authors": ["Michael D. Ekstrand\n,", "Martijn C. Willemsen"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nBehaviorism is the currently-dominant paradigm for building and evaluating recommender systems. Both the operation and the evaluation of recommender system applications are most often driven by analyzing the behavior of users. In this paper, we argue that listening to what users say about the items and recommendations they like, the control they wish to exert on the output, and the ways in which they perceive the system and not just observing what they do will enable important developments in the future of recommender systems. We provide both philosophical and pragmatic motivations for this idea, describe the various points in the recommendation and evaluation processes where explicit user input may be considered, and discuss benefits that may result from considered incorporation of user preferences at each of these points. In particular, we envision recommender applications that aim to support users' better selves: helping them live the life that they desire to lead. For example, recommender-assisted behavior change requires algorithms to predict not what users choose or do now, inferable from behavioral data, but what they should choose or do in the future to become healthier, fitter, more sustainable, or culturally aware. We hope that our work will spur useful discussion and many new ideas for recommenders that empower their users.", "references": ["Amatriain, X. 2016. Past, Present, and Future of Recom-mender Systems: An Industry Perspective.", "Anand, S.S. and Mobasher, B. 2007. Contextual Recommendation. From Web to Social Web: Discovering and Deploying User and Content Profiles. B. Berendt, A. Hotho, D. Mladenic, and G. Semeraro, eds. Springer Berlin Heidelberg. 142--160.", "Cialdini, R.B. 2001. Influence: Science and Practice. Allyn and Bacon."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959179"}, {"title": "T-RecS: A Framework for a Temporal Semantic Analysis of the ACM Recommender Systems Conference", "authors": ["Fedelucio Narducci\n,", "Pierpaolo Basile\n,", "Pasquale Lops\n,", "Marco De Gemmis\n,", "Giovanni Semeraro"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis paper presents T-RecS (Temporal analysis of Recommender Systems conference proceedings), a framework that supplies services to analyze the Recommender Systems Conference proceedings from the first edition, held in 2007, to the last one, held in 2015, under a temporal point of view. The idea behind T-RecS is to identify linguistic phenomena that reflect some interesting variations for the research community, such as topic drift, or how the correlation between two terms changed over time, or how similarity between two authors evolved over time.", "references": ["T. L. Griffiths and M. Steyvers, \"Finding scientific topics,\" Proceedings of the National Academy of Sciences, vol. 101, no. suppl 1, pp. 5228--5235, 2004.", "D. Hall, D. Jurafsky, and C. D. Manning, \"Studying the history of ideas using topic models,\" in Proceedings of the conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2008, pp. 363--371.", "A. Anderson, D. McFarland, and D. Jurafsky, \"Towards a computational history of the ACL: 1980--2008,\" in phProceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics, 2012, pp. 13--21."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959113"}, {"title": "Requirements Elicitation from Business Process Model in BPMN: A Systematic Review", "authors": ["Arystelene S. Bitencourt\n,", "Debora M.B. Paiva\n,", "Maria Istela Cagnin"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe requirements elicitation is a complexity phase of the Requirement Engineering, being necessary methods and techniques to execute it. Many researchers emphasized that the software system must fully meet the peculiarities of the company's business. Then, with the intention to elicit rightly the requirements of the software, there are techniques and methods in the literature that perform the requirements extraction from business process models. Such models can be represented in different types of notations, being the Business Process Model and Notation (BPMN) the standard notation. In this context, this paper describes a systematic review to identify primary studies that perform the extraction of functional and non functional requirements from business process model represented in BPMN notation. From the results obtained through the systematic review, we observed that there are few studies about the subject and most of them take in account only the functional requirements extraction. Thus, it was possible to outline future research to contribute to the advancement in this research area.", "references": ["F. Aburub, M. Odeh, and I. Beeson. Modelling non-functional requirements of business processes. Information Software Technology, 49(11-12):1162-1171, 2007", "A. L. Araujo, L. M. Cysneiros, and V. M. B. Werneck. Ndr-tool: Uma ferramenta de apoio ao reuso de conhecimento em requisitos nao funcionais. In Workshop de Engenharia de Software. WER, 2014", "A. Armando and S. E. Ponta. Model checking authorization requirements in business processes. Computers e Security, 40(0):1 - 22, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021989"}, {"title": "CiteSeerX data: semanticizing scholarly papers", "authors": ["Jian Wu\n,", "Chen Liang\n,", "Huaiyu Yang\n,", "C. Lee Giles"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nScholarly big data is, for many, an important instance of Big Data. Digital library search engines have been built to acquire, extract, and ingest large volumes of scholarly papers. This paper provides an overview of the scholarly big data released by CiteSeerX, as of the end of 2015, and discusses various aspects such as how the data is acquired, its size, general quality, data management, and accessibility. Preliminary results on extracting semantic entities from body text of scholarly papers with Wikifier show biases towards general terms appearing in Wikipedia and against domain specific terms. We argue that the latter will play a more important role in extracting important facts from scholarly papers.", "references": ["B. Aleman-Meza, F. Hakimpour, I. B. Arpinar, and A. P. Sheth. Swetodblp ontology of computer science publications. Web Semantics: Science, Services and Agents on the World Wide Web, 5(3):151--155, 2007.", "Y. An, J. Janssen, and E. E. Milios. Characterizing and mining the citation graph of the computer science literature. Knowledge and Information Systems, 6(6):664--678, 2004.", "C. Caragea, J. Wu, S. D. Gollapalli, and C. L. Giles. Document Type Classification in Online Digital Libraries. Phoenix, Arizona USA, 2016. AAAI."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928306"}, {"title": "A new readability measure for web documents and its evaluation on an effective web search engine", "authors": ["Yume Sasaki\n,", "Takuya Komatsuda\n,", "Atsushi Keyaki\n,", "Jun Miyazaki"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nIn this study, we propose a readability measure for Web documents and an information retrieval system that considers readability. Previous information retrieval systems aim to identify documents that are relevant to a given query; however, as information requirements of search system users becomes increasingly diverse and complicated, systems that take such new criteria into account are constantly being introduced. In particular, the focus of our present paper is on readability. Given that the population of non-native English speakers exceeds that of native English speakers, incorporating readability into an information retrieval system is crucial. Therefore, we propose (1) a readability measure that considers document simplicity and document structure as new features for readability and (2) a score fusion method that combines relevance and readability scores. In our experimental results, we found that our proposed readability measure outperformed an existing readability measure. Moreover, we found score fusion methods using a statistical framework called a copula improved overall accuracy as compared to such existing methods as linear combination.", "references": ["John Bormuth. Readability: A new approach. In Readabing Researh Quarterly, volume 1, pages 79--132, 1966.", "Jean-Philippe Bouchaud and Marc Potters. Theory of Financial Risk and Derivative Pricing. Theory of Financial Risk and Derivative Pricing From Statistical Physics to Risk Management, page 379, 2003.", "W. Breymann, A. Dias, and Paul Embrechts. Dependence structures for multivariate high-frequency data in finance. Quantitative Finance, 3(1):1--14, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011172"}, {"title": "Mining hidden constrained streams in practice: informed search in dynamic filter spaces", "authors": ["Nikolaos Panagiotou\n,", "Ioannis Katakis\n,", "Dimitrios Gunopulos\n,", "Vana Kalogeraki\n,", "Elizabeth Daly\n,", "Jia Yuan Yu\n,", "Brendan O Brien"], "publication": "ASONAM '16: Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "abstract": "ABSTRACT\nIn this paper we tackle the recently proposed problem of hidden streams. In many situations, the data stream that we are interested in, is not directly accessible. Instead, part of the data can be accessed only through applying filters (e.g. keyword filtering). In fact this is the case of the most discussed social stream today, Twitter. The problem in this case is how to retrieve as many relevant documents as possible by applying the most appropriate set of filters to the original stream and, at the same time, respect a number of constrains (e.g. maximum number of filters that can be applied). In this work we introduce a search approach on a dynamic filter space. We utilize heterogeneous filters (not only keywords) making no assumptions about the attributes of the individual filters. We advance current research by considering realistically hard constraints based on real-world scenarios that require tracking of multiple dynamic topics. We demonstrate the effectiveness of our approaches on a set of topics of static and dynamic nature.\nThe development of the approach was motivated by a real application. Our system is deployed in Dublin City's Traffic Management Center and allows the city officers to analyze large sources of heterogeneous data and identify events related to traffic as well as emergencies.", "references": ["E. M. Daly, F. Lecue, and V. Bicer. Westland row why so slow?: fusing social media and linked data sources for understanding real-time traffic conditions. In Proc of the 2013 int conf on Intelligent user interfaces, pages 203--212. ACM, 2013.", "O. Dan, J. Feng, and B. D. Davison. A bootstrapping approach to identifying relevant tweets for social tv. In ICWSM, 2011.", "Y. Duan, F. Wei, M. Zhou, and H.-Y. Shum. Graph-based collective classification for tweets. In Proc of the 21st ACM Int Conf on Information and Knowledge Management, CIKM '12, pages 2323--2326, New York, NY, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3192424.3192532"}, {"title": "Automatic Selection of Test Cases for Regression Testing", "authors": ["Cláudio Magalhães\n,", "Flávia Barros\n,", "Alexandre Mota\n,", "Eliot Maia"], "publication": "SAST: Proceedings of the 1st Brazilian Symposium on Systematic and Automated Software Testing", "abstract": "ABSTRACT\nRegression testing is a safety measure to attest that changes made on a system preserve prior accepted behavior. Identifying which test cases must compose a regression test suite in a certain development stage is tricky, particularly when one only has test cases and change requests described in natural language, and the execution of the test suite will be performed manually. That is the case of our industrial partner. We propose a selection of regression test cases based on information retrieval and implement as a web-service. In performed experiments, we show that we can improve the creation of regression test suites of our industrial partner by providing more effective test cases based on keywords analysis in an automatic way.", "references": ["Cláudio Magalh aes, Alexandre Mota, and Eliot Maia. Automatically finding hidden industrial criteria used in test selection. In 28th International Conference on Software Engineering and Knowledge Engineering, SEKE'16, San Francisco, USA, pages 1--4, 2016.", "G. Canfora and L. Cerulo. Impact Analysis by Mining Software and Change Request Repositories. In 11th IEEE International Software Metrics Symposium (METRICS'05), page 29. IEEE, 2005.", "Paolo Tonella Cu D. Nguyen, Alessandro Marchetto. Model based regression test reduction using dependence analysis. In In Proceedings of the International IEEE Conference on Software Maintenance, pages 214--223. IEEE, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993288.2993299"}, {"title": "Makalu: fast recoverable allocation of non-volatile memory", "authors": ["Kumud Bhandari\n,", "Dhruva R. Chakrabarti\n,", "Hans-J. Boehm"], "publication": "OOPSLA 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nByte addressable non-volatile memory (NVRAM) is likely to supplement, and perhaps eventually replace, DRAM. Applications can then persist data structures directly in memory instead of serializing them and storing them onto a durable block device. However, failures during execution can leave data structures in NVRAM unreachable or corrupt. In this paper, we present Makalu, a system that addresses non-volatile memory management. Makalu offers an integrated allocator and recovery-time garbage collector that maintains internal consistency, avoids NVRAM memory leaks, and is efficient, all in the face of failures.\nWe show that a careful allocator design can support a less restrictive and a much more familiar programming model than existing persistent memory allocators. Our allocator significantly reduces the per allocation persistence overhead by lazily persisting non-essential metadata and by employing a post-failure recovery-time garbage collector. Experimental results show that the resulting online speed and scalability of our allocator are comparable to well-known transient allocators, and significantly better than state-of-the-art persistent allocators.", "references": ["NVDIMM special interest group.", "Pmem.io: Persistent memory programming.", "NVM programming technical work group."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983990.2984019"}, {"title": "Semi-supervised Multi-Label Topic Models for Document Classification and Sentence Labeling", "authors": ["Hossein Soleimani\n,", "David J. Miller"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nExtracting parts of a text document relevant to a class label is a critical information retrieval task. We propose a semi-supervised multi-label topic model for jointly achieving document and sentence-level class inferences. Under our model, each sentence is associated with only a subset of the document's labels (including possibly none of them), with the label set of the document the union of the labels of all of its sentences. For training, we use both labeled documents, and, typically, a larger set of unlabeled documents. Our model, in a semisupervised fashion, discovers the topics present, learns associations between topics and class labels, predicts labels for new (or unlabeled) documents, and determines label associations for each sentence in every document. For learning, our model does not require any ground-truth labels on sentences. We develop a Hamiltonian Monte Carlo based algorithm for efficiently sampling from the joint label distribution over all sentences, a very high-dimensional discrete space. Our experiments show that our approach outperforms several benchmark methods with respect to both document and sentence-level classification, as well as test set log-likelihood. All code for replicating our experiments is available from https://github.com/hsoleimani/MLTM.", "references": ["K Nigam, A McCallum, and T Mitchell. Semi-supervised text classification using EM. Semi-Supervised Learning, pp. 33--56, 2006.", "D J Miller and H S Uyar. A mixture of experts classifier with learning based on both labelled and unlabelled data. In NIPS, pp. 571--577, 1997.", "D M Blei, L Carin, and D Dunson. Probabilistic Topic Models. Comm. of the ACM, 55(4):77--84, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983752"}, {"title": "Bayesian Personalized Ranking with Multi-Channel User Feedback", "authors": ["Babak Loni\n,", "Roberto Pagano\n,", "Martha Larson\n,", "Alan Hanjalic"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPairwise learning-to-rank algorithms have been shown to allow recommender systems to leverage unary user feedback. We propose Multi-feedback Bayesian Personalized Ranking (MF-BPR), a pairwise method that exploits different types of feedback with an extended sampling method. The feedback types are drawn from different \"channels\", in which users interact with items (e.g., clicks, likes, listens, follows, and purchases). We build on the insight that different kinds of feedback, e.g., a click versus a like, reflect different levels of commitment or preference. Our approach differs from previous work in that it exploits multiple sources of feedback simultaneously during the training process. The novelty of MF-BPR is an extended sampling method that equates feedback sources with \"levels\" that reflect the expected contribution of the signal. We demonstrate the effectiveness of our approach with a series of experiments carried out on three datasets containing multiple types of feedback. Our experimental results demonstrate that with a right sampling method, MF-BPR outperforms BPR in terms of accuracy. We find that the advantage of MF-BPR lies in its ability to leverage level information when sampling negative items.", "references": ["Alejandro Bellogin, Pablo Castells, and Ivan Cantador. Precision-oriented evaluation of recommender systems: An algorithmic comparison. In RecSys '11, pages 333--336, 2011.", "Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. Performance of recommender algorithms on top-n recommendation tasks. In ACM RecSys '10, pages 39--46, 2010.", "Zeno Gantner, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-Thieme. Bayesian personalized ranking for non-uniformly sampled items. JMLR W&CP, Jan, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959163"}, {"title": "ALMA: GC-assisted JVM Live Migration for Java Server Applications", "authors": ["Rodrigo Bruno\n,", "Paulo Ferreira"], "publication": "Middleware '16: Proceedings of the 17th International Middleware Conference", "abstract": "ABSTRACT\nLive migration of Java Virtual Machines (JVMs) consumes significant amounts of time and resources, imposing relevant application performance overhead. This problem is specially hard when memory modified by applications changes faster than it can be transferred through the network (to a remote host). Current solutions to this problem resort to several techniques which depend on high-speed networks and application throttling, require lots of CPU time to compress memory, or need explicit assistance from the application. We propose a novel approach, Garbage Collector (GC) assisted JVM Live Migration for Java Server Applications (ALMA). ALMA makes a snapshot to be migrated containing a minimal amount of application state, by taking into account the amount of reachable memory (i.e. live data) detected by the GC. The main novelty of ALMA is the following: ALMA analyzes the JVM heap looking for regions in which a collection phase is advantageous w.r.t. the network bandwidth available (i.e. it pays to collect because a significant amount of memory will not be part of the snapshot). ALMA is implemented on OpenJDK 8 and extends CRIU (a Linux disk-based process checkpoint/restore tool) to support process live migration over the network. We evaluate ALMA using well-known JVM performance benchmarks (SPECjvm2008 and DaCapo), and by comparing it to other previous approaches. ALMA shows very good performance results.", "references": ["A. W. Appel. Simple generational garbage collection and fast allocation. Software: Practice and Experience, 19(2):171--183, 1989.", "J. Armstrong and R. Virding. One pass real-time generational mark-sweep garbage collection. In Memory Management, pages 313--322. Springer, 1995.", "S. M. Blackburn et al. The DaCapo benchmarks: Java benchmarking development and analysis."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988336.2988341"}, {"title": "A three-dimensional view of reuse in Service Oriented Architecture", "authors": ["Joyce Aline Oliveira\n,", "Jose J.L.D. Junior"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe reuse in Service Oriented Architecture (SOA) has been used strategically in organizations to reduce development costs and increase the quality of applications. This article reports a qualitative research realized with experts in order to identify goals, barriers, facilitators, strategies, metrics and benefits associated with reuse in SOA. The results were summarized in three dimensions (management, architecture, operation) and represented by a conceptual model that can serve as a preliminary roadmap to manage the reuse in SOA.", "references": ["Alferez, G. H. e Pelechano, V. Systematic reuse of web services through software product line engineering. 9th IEEE European Conference on Web Services (ECOWS). (2011)", "Baskerville, R., Cavallari, M., Hjort-Madsen, K., Pries-Heje, J., Sorrentino, M., Virili, F. Extensible architectures: the strategic value of service-oriented architecture in banking. In: Proceedings of the 13th European Conference on Information Systems (ECIS). Regensburg, Germany.(2005)", "Bieberstein, N., Bose, S., Walker, L., Lynch, A. Impact of service-oriented architecture on enterprise systems, organizational structures, and individuals. IBM Systems Journal 44 (4), 691-708. (2005)"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022024"}, {"title": "Dynamic mapping of dense geo-tweets and web pages based on spatio-temporal analysis", "authors": ["Yuanyuan Wang\n,", "Goki Yasui\n,", "Yukiko Kawai\n,", "Toyokazu Akiyama\n,", "Kazutoshi Sumiya\n,", "Yoshiharu Ishikawa"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nTwitter evidently stirred a popular trend of personal update sharing. Twitter users can be kept up to date with current information from Twitter; however, users cannot obtain the most recent information, while they browse web pages since these are not updated in real time. Meanwhile, Twitter users are difficult to gain useful information about their current locations since these are often posted on web pages. To solve them, it is important to enrich traditional web pages with real time tweets. Therefore, we developed a novel tweet mapping system to support web and Twitter user communication through both the contents of tweets and web pages based on spatio-temporal analysis. Our system maps geo-tagged tweets to web pages by matching their location names, and categorizes tweets based on category names of floors from web pages according to different time frames. Thus, our system can effectively present the most related tweets and their summary to help users easily gain more detailed current situation in different time periods, and it also can effectively present messages from web users to help Twitter users immediately obtain useful information. In this paper, we discuss our proposed mapping method's effectiveness with our prototype system using dense tweets in urban areas.", "references": ["Z. Cheng, J. Caverlee, and K. Lee. You are where you tweet: a content-based approach to geo-locating twitter users. In CIKM 2010.", "N. Fallah, I. Apostolopoulos, K. Bekris, and E. Folmer. Indoor human navigation systems: A survey. Interacting with Computers, 25(1):21--33, 2013.", "M. Musleh. Spatio-temporal visual analysis for event-specific tweets. In SIGMOD 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851985"}, {"title": "Evaluating Touch-Based Interactions in an Image Search Task", "authors": ["Roberto González-Ibáñez\n,", "Carlos Barrera-Pulgar\n,", "José Luis Varela-Otárola"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nCurrent technologies provide users different ways to interact with digital content, nevertheless, a physical gap between these two interaction components exists. In particular, touch-based interfaces enable users to use their own fingers to manipulate and interact with digital objects in a more direct fashion than mouse-based interactions. However, it is not clear yet to what extent, if any, this type of interaction could help bridge the gap between users and the digital world in particular information-related contexts such as information search. In this paper we report preliminary results of a user study designed to compare mouse and touch-based interactions in the context of an image search task. This study is part of a larger research project focused on immersive interaction with digital information objects. Our results show that in spite of the novelty, high adoption rates, and tangible nature of touch-based interfaces, no significant differences exist with prevalent technology (i.e., mouse) in terms of performance; nevertheless, user experience was found to better in touch-based interactions.", "references": ["Meyyarasu, N., Dalton, G. and Abinaya, S. 2015. A review on touch sensor screen system. National conference on recent trends in communication & information technologies. Tamilnadu, India, 1--12.", "Ostroff, D. and Shneiderman, B. 1988. Selection devices for user of an electronic encyclopedia: an empirical comparison of four possibilities. IP&M. 24, 6, 665--680.", "Liming Luke Chen, D.R.M., Dr Matthias Steinbauer, P., Travis, C. and Murano, P. 2014. A comparative study of the usability of touch-based and mouse-based interaction. International Journal of Pervasive Computing and Communications. 10, 1, 115--134."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854999"}, {"title": "Query-Less: Predicting Task Repetition for NextGen Proactive Search and Recommendation Engines", "authors": ["Yang Song\n,", "Qi Guo"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWeb search has been a reactive scenario for decades which often starts by users issuing queries. By studying the user behavior in search engine logs, we have discovered that many of the search tasks such as stock-price checking, news reading exhibit strong repeated patterns from day to day. In addition, users exhibit even stronger repetition on mobile devices. This provides us chances to perform proactive recommendations without user issuing queries. In this work, we aim at discovering and characterizing these types of tasks so that we can automatically predict when and what types of tasks will be repeated by the users in the future, through analyzing search logs from a commercial Web search engine and user interaction logs from a mobile App that offers proactive recommendations. We first introduce a set of novel features that can accurately capture task repetition. We then propose a novel deep learning framework that learns user preferences and makes automatic predictions. Our framework is capable of learning both user-independent global models as well as catering personalized models via model adaptation. The model we developed significantly outperforms other state-of-the-art predictive models by large margins. We also demonstrate the power of our model and features through an application to improve the recommendation quality of the mobile App. Results indicate a significant relevance improvement over the current production system.", "references": ["E. Adar, J. Teevan, and S. T. Dumais. Large scale analysis of web revisitation patterns. In CHI '08, pages 1197--1206.", "E. Adar, J. Teevan, and S. T. Dumais. Resonance on the web: Web dynamics and revisitation patterns. In CHI '09, pages 1381--1390, New York, NY, USA, 2009. ACM.", "E. Agichtein, R. W. White, S. T. Dumais, and P. N. Bennet. Search, interrupted: Understanding and predicting search task continuation. In SIGIR '12, pages 315--324."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883020"}, {"title": "Effect of portable fine-grained locality on energy efficiency and performance in concurrent search trees", "authors": ["Ibrahim Umar\n,", "Otto J. Anshus\n,", "Phuong H. Ha"], "publication": "PPoPP '16: Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming", "abstract": "ABSTRACT\nRecent research has suggested that improving fine-grained data-locality is one of the main approaches to improving energy efficiency and performance. However, no previous research has investigated the effect of the approach on these metrices in the case of concurrent data structures.\nThis paper investigates how fine-grained data locality influences energy efficiency and performance in concurrent search trees, a crucial data structure that is widely used in several important systems. We conduct a set of experiments on three lock-based concurrent search trees: DeltaTree, a portable fine-grained locality-aware concurrent search tree; CBTree, a coarse-grained locality-aware B+tree; and BST-TK, a locality-oblivious concurrent search tree. We run the experiments on a commodity x86 platform and an embedded ARM platform. The experimental results show that DeltaTree has 13--25% better energy efficiency and 10--22% more operations/second on the x86 and ARM platforms, respectively. The results confirm that portable fine-grained locality can improve energy efficiency and performance in concurrent search trees.", "references": ["P. van Emde Boas. Preserving order in a forest in less than logarithmic time. In Proc. 16th Annual Symp. Foundations of Computer Science, SFCS '75, pages 75--84, 1975.", "B. Dally. Power and programmability: The challenges of exascale computing. In DoE Arch-I presentation, 2011.", "T. David, R. Guerraoui, and V. Trigonakis. Asynchronized concurrency: The secret to scaling concurrent search data structures. In Proc. Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS '15, pages 631--644, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851141.2851186"}, {"title": "MuSme: A Tangible Skin Suit for Music Creation", "authors": ["Amal Tidjani\n,", "Eileen Cho\n,", "Priscilla Lee"], "publication": "TEI '16: Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction", "abstract": "ABSTRACT\nMusic is a beautiful medium through which children can artistically communicate and express themselves. The complexity associated with operating traditional instruments, however, often discourages young children from playing music. In an effort to democratize music-making, we propose MuSme, a tangible skin suit that reimagines a user's limbs and organs as metaphoric representations of different instruments. By eliminating the nuanced technicalities associated with music-making, MuSme empowers children so that they may creatively express themselves with their very own bodies. With MuSme, children don't just play music. They become music.", "references": ["DigInfo TV. 2011. Ningen Gakki. Video. (6 Feb 2011.). Retrieved September 16, 2015 from https://www.youtube.com/watch?v=iJQrZas25hE", "William W. Gourley. Marshall Music Company Dropout Survey: Factors influencing beginning students' decisions to discontinue band or orchestra. Retrieved October 28, 2015 from https://www.marshallmusic.com/newsletter/archive%20pdf/Marshall%20Music%20Company%20Dropout%20Survey.pdf", "Hiroshi Ishii, Ali Mazalek, and Jay Lee. 2011. Bottles as a Minimal Interface to Access Digital Information. In Extended Abstracts on Human Factors in Computing Systems (CHI '01), 187--188."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2839462.2872960"}, {"title": "What Makes a Query Temporally Sensitive?", "authors": ["Craig Willis\n,", "Garrick Sherman\n,", "Miles Efron"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis work takes an in-depth look at the factors that affect manual classifications of 'temporally sensitive' information needs. We use qualitative and quantitative techniques to analyze 660 topics from the Text Retrieval Conference (TREC) previously used in the experimental evaluation of temporal retrieval models. Regression analysis is used to identify factors in previous manual classifications. We explore potential problems with the previous classifications, considering principles and guidelines for future work on temporal retrieval models.", "references": ["W. Dakka, L. Gravano, and P. Ipeirotis. Answering General Time-Sensitive Queries. IEEE Transactions on Knowledge and Data Engineering, 24(2):220--235, 2012.", "M. Efron and G. Golovchinsky. Estimation methods for ranking recent information. SIGIR 2011, 2011.", "Q. He, K. Chang, and E.-P. Lim. Analyzing feature trajectories for event detection. SIGIR 2007, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914703"}, {"title": "Convolutional Matrix Factorization for Document Context-Aware Recommendation", "authors": ["Donghyun Kim\n,", "Chanyoung Park\n,", "Jinoh Oh\n,", "Sungyoung Lee\n,", "Hwanjo Yu"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nSparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.", "references": ["F. Chollet. Keras. https://github.com/fchollet/keras, 2015.", "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research (JMLR), 12:2493--2537,Nov. 2011.", "M. Deshpande and G. Karypis. Item-based top-n recommendation algorithms. ACM Transactions on Information Systems, 22(1):143--177, Jan.2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959165"}, {"title": "Graph databases in the browser: using levelgraph to explore new delhi", "authors": ["Antonio Maccioni\n,", "Matteo Collina"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe pervasiveness of graphs on the Web is growing; however, the difficulty of managing complex graph structures curbs the development of web-oriented applications that embed network data. The open source project, LevelGraph, aims to overcome the obstacles that web developers face with graph data management. LevelGraph is an easy-to-use graph database layer for web applications.\nTo demonstrate various capabilities of the system, we developed a web-based application that utilizes a graph database of a tourist network in New Delhi. The application allows users to move around the city while LevelGraph executes graph queries on the underlying database. In this demonstration, we show how LevelGraph's features facilitate development and maintainance of web applications that embed graph data.", "references": ["G. Fourny, M. Pilman, D. Florescu, D. Kossmann, T. Kraska, and D. McBeath. XQuery in the browser. In WWW, pages 1011--1020, 2009.", "N. Mehta, J. Sicking, E. Graff, A. Popescu, J. Orlow, and J. Bell. Indexed database API. Technical Report W3C Recommendation, World Wide Web Consortium, January 2015.", "T. Neumann and G. Weikum. The RDF-3X engine for scalable management of RDF data. VLDB J., 19(1):91--113, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007286"}, {"title": "Bias in technology", "authors": ["Gregory Mone"], "publication": "Communications of the ACM", "abstract": "Abstract\nAs leading companies release troubling diversity statistics, experts search for solutions.", "references": ["Diversity in High Tech, U.S. Equal Employment Opportunity Commission, 2015. http://www.eeoc.gov/eeoc/statistics/reports/hightech.", "Hewlett, S.A., Luce, C.B., Servon, L.J., et. al. The Athena Factor: Reversing the Brain Drain in Science, Engineering, and Technology, a Harvard Business Review Research Report, 2008.", "Intel Corporation & Dalberg Global Investment Advisors Decoding Diversity: The Financial and Economic Returns to Diversity in Tech, 2016. http://bit.ly/2bHEFuN."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3014388"}, {"title": "Predicting Popularity of Twitter Accounts through the Discovery of Link-Propagating Early Adopters", "authors": ["Daichi Imamori\n,", "Keishi Tajima"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we propose a method of ranking recently created Twitter accounts according to their prospective popularity. Early detection of new promising accounts is useful for trend prediction, viral marketing, user recommendation, and so on. New accounts are, however, difficult to evaluate because they have not yet established the reputation they deserve, and we cannot apply existing link-based or other popularity-based account evaluation methods. Our method first finds early adopters, i.e., users who often find new good information sources earlier than others. Our method then regards new accounts followed by good early adopters as promising, even if they do not have many followers now. In order to find good early adopters, we estimate the frequency of link propagation from each account, i.e., how many times the follow links from the account have been copied by its followers. If the frequency is high, the account must be a good early adopter who often find good information sources earlier than its followers. We develop a method of inferring which links are created by copying which links. One important advantage of our method is that our method only uses information that can be easily obtained only by crawling neighbors of the target accounts in the current Twitter graph. We evaluated our method by an experiment on Twitter data. We chose then-new accounts from an old snapshot of Twitter, compute their ranking by our method, and compare it with the ranking based on the number of followers the accounts currently have. The result shows that our method produces better rankings than various baseline methods, especially for very new accounts that have only a few followers.", "references": ["L. Adamic and E. Adar. Friends and neighbors on the web. Social Networks, 25:211--230, 2001.", "L. M. Aiello, R. Schifanella, and B. State. Reading the source code of social ties. In Proc. of ACM WebSci, pages 139--148, 2014.", "E. Bakshy, B. Karrer, and L. A. Adamic. Social influence and the diffusion of user-created content. In Proc. of ACM EC, pages 325--334, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983859"}, {"title": "Supervised Recurrent Hashing for Large Scale Video Retrieval", "authors": ["Yun Gu\n,", "Chao Ma\n,", "Jie Yang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nHashing for large-scale multimedia is a popular research topic, attracting much attention in computer vision and visual information retrieval. Previous works mostly focus on hashing the images and texts while the approaches designed for videos are limited. In this paper, we propose a \\textit{Supervised Recurrent Hashing} (SRH) that explores the discriminative representation obtained by deep neural networks to design hashing approaches. The long-short term memory (LSTM) network is deployed to model the structure of video samples. The max-pooling mechanism is introduced to embedding the frames into fixed-length representations that are fed into supervised hashing loss. Experiments on UCF-101 dataset demonstrate that the proposed method can significantly outperforms several state-of-the-art methods.", "references": ["M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 3594--3601. IEEE, 2010.", "L. Cao, Z. Li, Y. Mu, and S.-F. Chang. Submodular video hashing: a unified framework towards video pooling and indexing. In Proceedings of the 20th ACM international conference on Multimedia, pages 299--308. ACM, 2012.", "M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In Proceedings of the twentieth annual symposium on Computational geometry, pages 253--262. ACM, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967225"}, {"title": "A Scalable Record Retrieval Methodology Using Relational Keyword Search System", "authors": ["Naveen Kumar\n,", "Jaya Kumar\n,", "Rishikesh B. Salunkhe\n,", "Aniket D. Kadam"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nInformation on web is growing exponential in powers of terabytes and out casting technology to absorb. Decades back lack of availability of information was issue but today filtering irrelevant data is challenge.\nKeyword words having higher weight describe a document or record is summarized way. Keywords are mostly preferred search technique as they eliminate use of specialized queries. Almost every day 1 billion search are made on Google which presents effectiveness of keyword search and success of search engine like Google Bing. Web portals contain hidden data in databanks of websites which aforesaid home of data containing all forms of info. This large data cannot be indexed and need sophisticated techniques to search in them. Extending this keyword search to Relational database would eliminate use of specialized language like sql and database records would search easily and at hands even by layman.\nDatabase system function on core of precise and accurate query and retrieve non redundant data. Whereas IR system function on core of retrieving and searching a view of information faster which might contain redundant information. Rank and user experience are focus of IR system and retrieve in general cluster of documents associated to same query i.e keyword weight are highest in document, whereas Database system relate to retrieveal of records related to particular user or entity.\nAlthough a merge of keyword from IR system to Relational Database System is required as large information is deposited on web and even the relational database created on this are huge and larger than static web size which definitely needs integration of keyword and ranking Function to eliminate use of integrated query which are hard to lean and master by every individual. This Paper presents Framework which evaluates Existing keyword search on Relational Database System and Evaluation parameters used. Proposed System presents Two Prototype System and Comparative analysis with their evaluation parameters. System presents concluding work on hybrid algorithm development for extending better keyword search on Relational Database Systems.", "references": ["Ku Qin, Jeffrey Xu Yu, Lijun Chang, \"Keyword Search in Databases: The Power of RDBMS, Published by ACM 2009.", "Hao He, Haixun Wang, Jun Yang, Philip S. Yu, \"BLINKS: Ranked Keyword Search on Graphs, Published by ACM 2007.", "Bhavana Bharat Dalvi, Meghana Kshirsagar, S. Sudarshan,\" Keyword Search on External Memory Data Graphs, Published by ACM 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905090"}, {"title": "New Product Diffusion: The Role of Sentiment Content", "authors": ["Tung Cu\n,", "Helmut Schneider\n,", "James Van Scotter"], "publication": "SIGMIS-CPR '16: Proceedings of the 2016 ACM SIGMIS Conference on Computers and People Research", "abstract": "ABSTRACT\nThe current study is focusing on diffusion and adoption of new digital artifacts. The goal is to explore the social role of user-generated content (UGC) during the diffusion process of digital products in the context of online social networks. Data collection is conducted on 154 new digital products during a two-year timeframe. Results of the study provide a deeper insight into the influence of textual UGC sentiment on new product diffusion and how such a web system (i.e.: online social networks) can help to enable a process of value co-creation. The overall finding shows that Volume of Post and UGC Sentiment have a dynamic impact on Diffusion (Adoption Rate) of digital products.\nThe study sheds light on the crowding power and the long-tail effect in online social networks. Findings also offer valuable implications for organizations to set up their strategic vision in terms of digital marketing, customer relationship management, and information dissemination.", "references": ["Abbasi, A. and Chen, H. Cybergate: A Design Framework and System For Text Analysis of Computer-Mediated Communication. MIS Quarterly, 32, 4 2008), 811--837.", "Agarwal, R. and Prasad, J. The role of innovation characteristics and perceived voluntariness in the acceptance of information technologies. Decision Sciences, 28, 3 1997), 557--582.", "Andrade, E. B. Behavioral Consequences of Affect: Combining Evaluative and Regulatory Mechanisms. Journal of Consumer Research, 32, 3 2005), 355--362."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2890602.2890627"}, {"title": "Explainable User Clustering in Short Text Streams", "authors": ["Yukun Zhao\n,", "Shangsong Liang\n,", "Zhaochun Ren\n,", "Jun Ma\n,", "Emine Yilmaz\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUser clustering has been studied from different angles: behavior-based, to identify similar browsing or search patterns, and content-based, to identify shared interests. Once user clusters have been found, they can be used for recommendation and personalization. So far, content-based user clustering has mostly focused on static sets of relatively long documents. Given the dynamic nature of social media, there is a need to dynamically cluster users in the context of short text streams. User clustering in this setting is more challenging than in the case of long documents as it is difficult to capture the users' dynamic topic distributions in sparse data settings. To address this problem, we propose a dynamic user clustering topic model (or UCT for short). UCT adaptively tracks changes of each user's time-varying topic distribution based both on the short texts the user posts during a given time period and on the previously estimated distribution. To infer changes, we propose a Gibbs sampling algorithm where a set of word-pairs from each user is constructed for sampling. The clustering results are explainable and human-understandable, in contrast to many other clustering algorithms. For evaluation purposes, we work with a dataset consisting of users and tweets from each user. Experimental results demonstrate the effectiveness of our proposed clustering model compared to state-of-the-art baselines.", "references": ["K. Balog and M. de Rijke. Finding similar experts. In SIGIR, pages 821--822. ACM, 2007.", "D. M. Blei and J. D. Lafferty. Dynamic topic models. In ICML, pages 113--120, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Machine Learning research, 3 (4--5): 993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911522"}, {"title": "CNN-based Style Vector for Style Image Retrieval", "authors": ["Shin Matsuo\n,", "Keiji Yanai"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper, we have examined the effectiveness of \"style matrix\" which is used in the works on style transfer and texture synthesis by Gatys et al. in the context of image retrieval as image features. A style matrix is presented by Gram matrix of the feature maps in a deep convolutional neural network. We proposed a style vector which are generated from a style matrix with PCA dimension reduction. In the experiments, we evaluate image retrieval performance using artistic images downloaded from Wikiarts.org regarding both artistic styles ans artists. We have obtained 40.64% and 70.40% average precision for style search and artist search, respectively, both of which outperformed the results by common CNN features. In addition, we found PCA-compression boosted the performance.", "references": ["K. D. Painter identification using local features and naive bayes. In Proc. of IAPR International Conference on Pattern Recognition, 2002.", "L. A. Gatys, A. S. Ecker, and M. Bethge. A neural algorithm of artistic style. In arXiv:1508.06576, 2015.", "L. A. Gatys, A. S. Ecker, and M. Bethge. Texture synthesis and the controlled generation of natural stimuli using convolutional neural networks. In Advances in Neural Information Processing Systems, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912057"}, {"title": "Answering Arabic Why-Questions: Baseline vs. RST-Based Approach", "authors": ["Aqil M. Azmi\n,", "Nouf A. Alshenaifi"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nA Question Answering (QA) system is concerned with building a system that automatically answer questions posed by humans in a natural language. Compared to other languages, little effort was directed towards QA systems for Arabic. Due to the difficulty of handling why-questions, most Arabic QA systems tend to ignore it. In this article, we specifically address the why-question for Arabic using two different approaches and compare their performance and the quality of their answer. The first is the baseline approach, a generic method that is used to answer all types of questions, including factoid; and for the second approach, we use Rhetorical Structure Theory (RST). We evaluate both schemes using a corpus of 700 textual documents in different genres collected from Open Source Arabic Corpora (OSAC), and a set of 100 question-answer pairs. Overall, the performance measures of recall, precision, and c@1 was 68% (all three measures) for the baseline approach, and 71%, 78%, and 77.4%, respectively, for the RST-based approach. The recently introduced extension of the accuracy, the c@1 measure, rewards unanswered questions over those wrongly answered.", "references": ["L. Abouenour, K. Bouzoubaa, and P. Rosso. 2008. Improving Q/A using Arabic wordnet. In The 2008 International Arab Conference on Information Technology (ACIT’08).", "L. Abouenour, K. Bouzoubaa, and P. Rosso. 2013a. An evaluated semantic query expansion and structure-based approach for enhancing Arabic question/answering. International Journal on Information and Communication Technologies 3, 3 (2013), 37--51.", "L. Abouenour, K. Bouzoubaa, and P. Rosso. 2013b. On the evaluation and improvement of Arabic WordNet coverage and usability. Language Resources & Evaluation 47, 3 (2013), 891--917."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2950049"}, {"title": "Intrusion Alert Correlation to Support Security Management", "authors": ["Claudio Toshio Kawakani\n,", "Sylvio Barbon Junior\n,", "Rodrigo Sanches Miani"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nTo support information security, organizations deploy Intrusion Detection Systems (IDS) that monitor information systems and networks, generating alerts for every suspicious behavior. However, the huge amount of alerts that an IDS triggers and their low-level representation make the alerts analysis a challenging task. In this paper, we propose a new approach based on hierarchical clustering that supports intrusion alert analysis in two main steps. First, it correlates historical alerts to identify the most typical strategies attackers have used. Then, it associates upcoming alerts in real time according to the strategies discovered in the first step. The experiments were performed using a real data set from the University of Maryland. The results show that the proposed approach can provide useful information for security administrators and may reduce the time between a security event and the response.", "references": ["A. Ahmad, J. Hadgkiss, and A. B. Ruighaver. Incident response teams - challenges in supporting the organisational security function. Comput. Secur., 31(5):643-652, July 2012.", "M. GhasemiGol and A. Ghaemi-Bafghi. E-correlator: an entropy-based alert correlation system. Security and Communication Networks, 8(5):822-836, 2015.", "A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: A review. ACM Comput. Surv., 31(3):264-323, Sept. 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022009"}, {"title": "Region Trajectories for Video Semantic Concept Detection", "authors": ["Yuancheng Ye\n,", "Xuejian Rong\n,", "Xiaodong Yang\n,", "YIngli Tian"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nRecently, with the advent of the convolutional neural network (CNN), many CNN-based object detection algorithms have been proposed and achieved encouraging results. In this paper, we introduce an algorithm based on region trajectories to establish the connections between object localizations in individual frames and video sequences. To detect object regions in the individual frames of a video, we enhance the region-based convolutional neural network (R-CNN), by incorporating EdgeBox with the Selective Search to generate candidate region proposals and combining the GoogLeNet with the AlexNet to improve the discriminability of the feature representations. The DeepMatching algorithm is employed in our proposed region trajectory method to track the points in the detected object regions. The experiments are conducted on the validation split of the TRECVID 2015 Localization dataset. As demonstrated by the experimental results, our proposed approach improves the object detection accuracy in both temporal and spatial measurements.", "references": ["B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. In Proceedings of the fth annual workshop on Computational learning theory, pages 144--152. ACM, 1992.", "N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition (CVPR), volume 1, pages 886--893. IEEE, 2005.", "M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International Journal of Computer Vision (IJCV), 88(2):303--338, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912046"}, {"title": "Profiling Household Consumption with Clustering Algorithms", "authors": ["Eduardo O. Andrade\n,", "Igor G.B. Sampaio\n,", "Jose Viterbo\n,", "Joao M.M. Silva\n,", "Clodis Boscarioli"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe measurement of energy consumption by smart devices is growing rapidly. Studies of such measures is in the interest of governments and companies around the world. With the identification of user profiles by energy consumption, there Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SBSI 2016, May 17th-20th, 2016, Florianopolis, Santa Catarina, Brazil Copyright SBC 2016. are plenty of opportunities that arise every time. This article presents an approach to the electric energy consumption in a home, and seeks to identify patterns. This is done on a database with many devices that have had their power consumption measured regularly. Through a clustering algorithm used on these data, we tried to establish consumer profiles that contribute to a better use of energy. They yielded results that identified energy consumption patterns on conditions such as temperature and time.", "references": ["Monacchi, A., Egarter, D., Elmenreich, W., D'Alessandro, S., Tonello, A.M. GREEND: An energy consumption dataset of households in Italy and Austria. In Smart Grid Communications (SmartGridComm), 2014 IEEE International Conference on, pages 511-516. IEEE, 2014.", "Kelly, J., and Knottenbelt, W. UK-DALE: A dataset recording UK domestic appliance-level electricity demand and whole-house demand. CoRR, abs/1404.0284, 2014.", "Want, R., Schilit, B.N., and Jenson, S. Enabling the Internet of Things. Computer, (1):28-35, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021964"}, {"title": "Recommender System for E-Learning through Content and Profile Based Approach", "authors": ["S. Venugopalan\n,", "M. V. Srinath\n,", "Paul Rodrigues"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nE-learning environments have become a way of life. The aim of the recommender systems is to suggest an optimal set of modules that satisfy the needs of the user on a particular topic. Recommender systems research has used advances in learning styles, personal preferences of the users and tests of ability to suggest content. These suffer from two problems: gap in content matching and lack of context. The domain of information retrieval has shown us that the gap between perceived results and intended results is significant. This is due to complexity of the content. Hence the recommender systems need advanced mechanisms for content tagging and management as a part of their repertoire. The content management aspects need to look beyond the document management style or the data management aspects, and instead, focus on the content tagging for modeling. This is a significant challenge. The second key challenge is to leverage the advances in context based information retrieval. Context is a key contributor in narrowing down the domain of search process. Context can be leveraged and harnessed in recommender systems. When integrated with the research in learning styles and the tests of ability, the recommender systems can show significant results. The objective of this paper is to outline a pedagogical model for recommender systems that leverage the advances in query expansion and context awareness for narrowing down the learning objects that are closest to the user's query. This set of learning objects is now personalized using learning style research and the tests of aptitude for better match. The applicability of the method for a range of courses is tested and the results are bench marked against existing methods.", "references": ["Aghaee, N and Hansson, H. 2013. Peer Portal: Quality enhancement in thesis writing using self-managed peer review on a mass scale. In The International Review of Research in Open and Distance Learning, 14, 1, 186--203.", "Abe, H and Yamaguchi, T. 2006. A Constructive Meta-Level Feature Selection Method based on Method Repositories. Journal of Computers, 13, 20--26.", "Bossewitch, J and Preston, DM. 2011. Teaching and Learning with Video Annotations. Mobility Shifts: an International Future of Learning Summit. Retrieved March."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905103"}, {"title": "Right inflight?: a dataset for exploring the automatic prediction of movies suitable for a watching situation", "authors": ["Michael Riegler\n,", "Martha Larson\n,", "Concetto Spampinato\n,", "Pål Halvorsen\n,", "Mathias Lux\n,", "Jonas Markussen\n,", "Konstantin Pogorelov\n,"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nIn this paper, we present the dataset Right Inflight developed to support the exploration of the match between video content and the situation in which that content is watched. Specifically, we look at videos that are suitable to be watched on an airplane, where the main assumption is that that viewers watch movies with the intent of relaxing themselves and letting time pass quickly, despite the inconvenience and discomfort of flight. The aim of the dataset is to support the development of recommender systems, as well as computer vision and multimedia retrieval algorithms capable of automatically predicting which videos are suitable for inflight consumption. Our ultimate goal is to promote a deeper understanding of how people experience video content, and of how technology can support people in finding or selecting video content that supports them in regulating their internal states in certain situations. Right Inflight consists of 318 human-annotated movies, for which we provide links to trailers, a set of pre-computed low-level visual, audio and text features as well as user ratings. The annotation was performed by crowdsourcing workers, who were asked to judge the appropriateness of movies for inflight consumption.", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender systems handbook, pages 217--253. Springer, 2011.", "Y. Baveye, E. Dellandréa, C. Chamaret, and L. Chen. Liris-accede: A video database for affective content analysis. IEEE Transactions on Affective Computing, 6(1):43--55, 2015.", "A. Borowiak and U. Reiter. Long duration audiovisual content: Impact of content type and impairment appearance on user quality expectations over time. In Quality of Multimedia Experience (QoMEX), 2013 Fifth International Workshop on, pages 200--205. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910619"}, {"title": "User scheduling algorithm for mmWave FDMA Massive MU-MIMO system with hybrid beamforming", "authors": ["Jiang Jing\n,", "Kong Deting\n,", "Lu Guangyue\n,", "Wang Junxuan\n,", "Yang Wujun"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn millimeter wave (mmWave) cellular system, the multipath nature of wireless channels and large bandwidth ensure the existence of frequency selective channels. This paper proposes user scheduling for downlink orthogonal frequency division multiple access (OFDMA) massive multi-user multiple input multiple output (MU-MIMO) system with hybrid beamforming (HB) algorithm. The analog beamforming is implemented by employing same phase shifters in the entire frequency band. Therefore the optimization of the wideband analog beamforming should consider the beam direction of multiple OFDMA users scheduled in different frequency resources. For user scheduling, firstly the users with correlated channels constitute an OFDMA user group. For a same OFDMA user group, BS allocates these frequency resources to the user with the best channel gain. Finally, spatial multiplexing users are selected to adequately utilize multiple RF chains. The proposed user scheduling algorithm can adapt to various HB algorithms. Simulation results show that the proposed user scheduling with HB can highly improve the performance of mmWave OFDMA massive MU-MIMO system.", "references": ["L. Lily Yang. 60GHz: Opportunity for Gigabit WPAN and WLAN Convergence. ACM SIGCOMM Computer Communication Review. 39, 1(Jan. 2009), 56--61.", "J. W. Shin, J. S. Kim, and et al. Performance Analysis with Dynamic Beam Control Using Millimeter-wave Band on 5G Mobile Communications. In Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication, IMCOM '15. ACM New York, NY, USA.", "Niu Y, Li Y, Jin D P, and et al. A survey of millimeter wave communications (mmWave) for 5G: opportunities and Challenges. Wireless Networks. 21, 8(2015), 2657--2676."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015172"}, {"title": "SolidNoise: Tools For Making Musical Robots", "authors": ["Jiffer Harriman\n,", "Matthew Bethancourt\n,", "Abhishek Narula\n,", "Michael Theodore\n,", "Mark Gross"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis Interactivity Demonstration submission describes new tools and techniques aimed to simplify the development and use of musical robots. We describe these tools and techniques as utilized to produce an event known as SolidNoise. The event showcased a series of automated instruments and musical compositions created for the robotic ensemble. Our developments are motivated by historical examples of automated instruments and our vision for musical robots in the future. We will demonstrate our musical robots and the platform used to make them, at CHI.", "references": ["Doyle, Tom. \"Pat Metheny's Orchestrion.\" Sound On Sound. April, 2010.", "Harriman, Jiffer, Michael Theodore, and Mark Gross. \"The Kitsch-Instrument: Hackable Robotic Music.\" Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction. ACM, 2015.", "Long, Jason, et al. \"A methodology for evaluating robotic striking mechanisms for musical contexts.\" International Conference on New Interfaces for Musical Expression. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2890271"}, {"title": "Indoor localization via multi-modal sensing on smartphones", "authors": ["Han Xu\n,", "Zheng Yang\n,", "Zimu Zhou\n,", "Longfei Shangguan\n,", "Ke Yi\n,", "Yunhao Liu"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nIndoor localization is of great importance to a wide range of applications in shopping malls, office buildings and public places. The maturity of computer vision (CV) techniques and the ubiquity of smartphone cameras hold promise for offering sub-meter accuracy localization services. However, pure CV-based solutions usually involve hundreds of photos and pre-calibration to construct image database, a labor-intensive overhead for practical deployment. We present ClickLoc, an accurate, easy-to-deploy, sensor-enriched, image-based indoor localization system. With core techniques rooted in semantic information extraction and optimization-based sensor data fusion, ClickLoc is able to bootstrap with few images. Leveraging sensor-enriched photos, ClickLoc also enables user localization with a single photo of the surrounding place of interest (POI) with high accuracy and short delay. Incorporating multi-modal localization with Manifold Alignment and Trapezoid Representation, ClickLoc not only localizes efficiently, but also provides image-assisted navigation. Extensive experiments in various environments show that the 80-percentile error is within 0.26m for POIs on the floor plan, which sheds light on sub-meter level indoor localization.", "references": ["https://get.google.com/tango/. Accessed: 2016-6-18.", "Bonin-Font, F., Ortiz, A., and Oliver, G. Visual Navigation for Mobile Robots: A Survey. Journal of Intelligent and Robotic Systems 53, 3 (2008), 263--296.", "Chen, S., Li, M., Ren, K., Fu, X., and Qiao, C. Rise of the Indoor Crowd: Reconstruction of Building Interior View via Mobile Crowdsourcing. In Proc. of ACM SenSys (2015), 59--71."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971668"}, {"title": "IT company atlas upper Franconia: a practical application of expert search techniques", "authors": ["Daniel Blank\n,", "Sebastian Boosz\n,", "Andreas Henrich"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nIdentifying a competent service provider or contractor is not an easy task. This is especially true in the IT sector with its short-lived trends and products. In this context an\"IT Company Atlas\" giving substantiated information about the IT companies in a certain region seems to be a promising idea. However, a B2B directory administered manually for this purpose is expensive to establish and to maintain. An alternative approach discussed in this paper is to apply expert search techniques and provide a search engine searching for companies instead of documents.\nWe propose a system searching for companies with expertise in a given field sketched by a keyword query. The system exploits the websites of the companies and covers all aspects: determining and representing the expertise of the companies, query processing and retrieval models, as well as query formulation and result presentation. In addition to the theoretical background and a system description we present experimental results comparing the effectiveness of different retrieval models adopted from expert search in the scenario we call \"company search\".", "references": ["P. Bailey, A. P. De Vries, N. Craswell, and I. Soboroff. Overview of the TREC-2007 enterprise track. In The Sixteenth Text REtrieval Conference (TREC 2007) Proceedings. NIST Special Publication: SP 500--274, 2007.", "K. Balog, L. Azzopardi, and M. de Rijke. Formal models for expert finding in enterprise corpora. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, pages 43--50, New York, NY, USA, 2006. ACM.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Found. Trends Inf. Retr., 6(2--3):127--256, Feb. 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851695"}, {"title": "Incorporating information extraction in the relational database model", "authors": ["Yoav Nahshon\n,", "Liat Peterfreund\n,", "Stijn Vansummeren"], "publication": "WebDB '16: Proceedings of the 19th International Workshop on Web and Databases", "abstract": "ABSTRACT\nModern information extraction pipelines are typically constructed by (1) loading textual data from a database into a special-purpose application, (2) applying a myriad of text-analytics functions to the text, which produce a structured relational table, and (3) storing this table in a database. Obviously, this approach can lead to laborious development processes, complex and tangled programs, and inefficient control flows. Towards solving these deficiencies, we embark on an effort to lay the foundations of a new generation of text-centric database management systems. Concretely, we extend the relational model by incorporating into it the theory of document spanners which provides the means and methods for the model to engage the Information Extraction (IE) tasks. This extended model, called Spannerlog, provides a novel declarative method for defining and manipulating textual data, which makes possible the automation of the typical work method described above. In addition to formally defining Spannerlog and illustrating its usefulness for IE tasks, we also report on initial results concerning its expressive power.", "references": ["S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases. Addison-Wesley, 1995.", "M. Benedikt, L. Libkin, T. Schwentick, and L. Segoufin. Definable relations and first-order query languages over strings. J. ACM, 50(5):694--751, 2003.", "A. J. Bonner and G. Mecca. Sequences, datalog, and transducers. J. CSS, 57(3):234--259, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2932194.2932200"}, {"title": "Identifying Earmarks in Congressional Bills", "authors": ["Ellery Wulczyn\n,", "Madian Khabsa\n,", "Vrushank Vora\n,", "Matthew Heston\n,", "Joe Walsh\n,", "Christopher Berry\n,", "Rayid Ghani"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nEarmarks are legislative provisions that direct federal funds to specific projects, circumventing the competitive grant-making process of federal agencies. Identifying and cataloging earmarks is a tedious, time-consuming process carried out by experts from public interest groups. In this paper, we present a machine learning system for automatically extracting earmarks from congressional bills and reports. We first describe a table-parsing algorithm for extracting budget allocations from appropriations tables in congressional bills. We then use machine learning classifiers to identify budget allocations as earmarked objects with an out of sample ROC AUC score of 0.89. Using this system, we construct the first publicly available database of earmarks dating back to 1995. Our machine learning approach adds transparency, accuracy, and speed to the congressional appropriations process.", "references": ["Anonymous Republican Lobbyist. Interview. Washington, D.C., October 30 2014.", "D. A. Austin and M. R. Levit. Mandatory spending since 1962. Congressional Research Service, March 23 2012.", "A. Bonica. Mapping the ideological marketplace. American Journal of Political Science, 58(2):367--386, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939711"}, {"title": "FuhSen: A Platform for Federated, RDF-based Hybrid Search", "authors": ["Diego Collarana\n,", "Christoph Lange\n,", "Sören Auer"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe increasing amount of structured and semi-structured information available on the Web and in distributed information systems, as well as the Web's diversification into different segments such as the Social Web, the Deep Web, or the Dark Web, requires new methods for horizontal search. FuhSen is a federated, RDF-based, hybrid search platform that searches, integrates and summarizes information about entities from distributed heterogeneous information sources using Linked Data. As a use case, we present scenarios where law enforcement institutions search and integrate data spread across these different Web segments to identify cases of organized crime. We present the architecture and implementation of FuhSen and explain the queries that can be addressed with this new approach.", "references": ["J. Iturrioz, I. Azpeitia, and O. Díaz. YQL as a Platform for Linked-Data Wrapper Development\". In: Engineering the Web in the Big Data Era. Springer, 2015.", "V. Lopez et al. PowerAqua: Supporting users in querying and exploring the semantic web\". In: Semantic Web 3.3 (2011), pp. 249{265.", "G. Montoya et al. Semlav: Local-as-view mediation for SPARQL queries\". In: Transactions on Large-Scale Data-and Knowledge-Centered Systems XIII. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890535"}, {"title": "Modelling User Search Behaviour Based on Process", "authors": ["Mengdie Zhuang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTypically, interactive information retrieval (IIR) system evaluations assess search processes and outcomes using a combination of two types of measures: 1. user perception (e.g. users? attitudes of the search experience and outcome); 2. user behaviour (e.g. time and counts of various actions including mouse and keyboard clicks). In general, we assume that they are indicative of the search outcomes (e.g. performance, opinion). However, search is a dynamic process with changing outcomes. Therefore, neither measure solely provides a holistic way of evaluating search. On one hand, user behaviour measures are only descriptive of the outcome, and are not interpretive of the process. That is to say, they lack the rationale behind why those behaviours occurred. Another problem is that some mental activities may not reflect on user behaviour [1]. The challenge with logfiles, which contain behaviour data, is the voluminous number of data points and the need to find a reliable approach to define groups or sets based on behavioural patterns. Not all users are alike and nor do they all take the same approach to search for the same things, as evidenced by the TREC, INEX and CLEF interactive tracks. On the other hand, user perception measures are acquired in such small samples that do not scale to large participant populations, and are rarely measured constantly due to the laborious and time consuming data collection methods (e.g. questionnaire, interview). Moreover, not enough emphasis is put on assessing the reliability of individual perception measures, and the wide usage of likert-type scale limits the interpretation of answers. For a holistic understanding of the search process, we need both perception and behaviour measures. I speculate that user behaviour may predict user perception, and thus we should be able to analyse large-scale files for a greater understanding of the likely human responses.", "references": ["Barreda-Ángeles, M., Arapakis, I., Bai, X., Cambazoglu, B.B., and Pereda-Baños, A., 2015. Unconscious Physiological Effects of Search Latency on Users and Their Click Behaviour. Proc. SIGIR'15, 203--212.", "Bishop, C.M., 2006. Pattern Recognition. Machine Learning.", "Marchionini, G., 1995. Information seeking in electronic environments. Cambridge University Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911486"}, {"title": "Modeling Optimal Switching Behavior", "authors": ["Mark D. Smucker\n,", "Charles L.A. Clarke"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nRecently developed retrieval effectiveness measures have incorporated models of user behavior, but have limited themselves to predicting user performance over a single query and response. Accurate prediction of user performance with search systems must incorporate a means to model how users switch between different information sources. For example, a search session may consist of multiple queries with the user making decisions of when to switch from evaluating the current result list to a new result list produced by a query reformulation. Likewise, users may switch to a result list produced by a query suggestion or other interaction mechanism that produces a new search result list. In this paper, we simulate user behavior and investigate optimal switching behavior for a user who must decide when and if to issue their current query to another search engine. As a first step in understanding the problem space, we restrict our investigation and discussion to two top performing runs submitted to the TREC 2005 Robust track. We find four classes of switching behavior that a user would be faced with in making a decision about whether to switch from one result list to another.", "references": ["J. Allan, B. Croft, A. Moffat, and M. Sanderson. Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne. SIGIR Forum, 46(1):2--32, May 2012.", "E. L. Charnov. Optimal foraging, the marginal value theorem. Theor. Population Biology, 9(2):129--136, 1976.", "W.-T. Fu and P. Pirolli. SNIF-ACT: A cognitive model of user navigation on the world wide web. Human-Computer Interaction, 22(4):355--412, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854981"}, {"title": "Are you a local or a visitor?: an exploratory study on consumer behavior in online group buying commerce", "authors": ["Jiyuan Wang\n,", "Jiayin Qi\n,", "Seongmin Jeon\n,", "Xiangling Fu"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nWith the rapid growth of online daily deals, the behaviors of consumers in such online group buying commerce have become popular research topics. We examine the effects of the period, price, discount rate and product category on sales in the context that local consumers and visitors purchase the restaurant coupons in a group buying electronic marketplace. Applying the conjoint analysis algorithm, we study the actual transactional data sets on the Dianping.com, one of the largest online group buying commerce businesses. The results show that there is a clear discrepancy between the preferences of the two consumer groups. The local consumers tend to think high of discounts while the visitors likely care more on product category. In addition, the behaviors of two groups are different in product attribute selections. The findings could be useful to the businesses in terms of understanding the customers' purchasing and product designs.", "references": ["Tuan800, Statistical Report of China Group Buying Market, 2014{EB/OL}. http://zixun.tuan800.com/a/tuangoushujubaogao/20150122/50434.html.", "China Internet Network Information Center, The 35th Statistical Report of Development Status of China's Internet{EB/OL}. http://www.cnnic.net.cn/hlwfzyj/hlwxzbg/hlwtjbg/201502/t20150203_51634.htm.", "McHugh J. Consumer collusion! {J}. Forbes, 1999, 6."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971628"}, {"title": "Network-Efficient Distributed Word2vec Training System for Large Vocabularies", "authors": ["Erik Ordentlich\n,", "Lee Yang\n,", "Andy Feng\n,", "Peter Cnudde\n,", "Mihajlo Grbovic\n,", "Nemanja Djuric\n,", "Vladan Radosavljevic\n,", "Gavin Owens"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWord2vec is a popular family of algorithms for unsupervised training of dense vector representations of words on large text corpuses. The resulting vectors have been shown to capture semantic relationships among their corresponding words, and have shown promise in reducing a number of natural language processing (NLP) tasks to mathematical operations on these vectors. While heretofore applications of word2vec have centered around vocabularies with a few million words, wherein the vocabulary is the set of words for which vectors are simultaneously trained, novel applications are emerging in areas outside of NLP with vocabularies comprising several 100 million words. Existing word2vec training systems are impractical for training such large vocabularies as they either require that the vectors of all vocabulary words be stored in the memory of a single server or suffer unacceptable training latency due to massive network data transfer. In this paper, we present a novel distributed, parallel training system that enables unprecedented practical training of vectors for vocabularies with several 100 million words on a shared cluster of commodity servers, using far less network traffic than the existing solutions. We evaluate the proposed system on a benchmark data set, showing that the quality of vectors does not degrade relative to non-distributed training. Finally, for several quarters, the system has been deployed for the purpose of matching queries to ads in Gemini, the sponsored search advertising platform at Yahoo, resulting in significant improvement of business metrics.", "references": ["A. Abadi, et. al., TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. http://tensorflow.org/", "A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy and A.J. Smola, Scalable Inference in Latent Variable Models, WSDM '12", "Apache Hadoop, http://hadoop.apache.org."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983361"}, {"title": "From Ecological Sounding Artifacts Towards Sonic Artifact Ecologies", "authors": ["Cumhur Erkut\n,", "Stefania Serafin"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThe discipline of sonic interaction design has been focused on the interaction between a single user and an artifact. This strongly limits one of the fundamental aspects of music as a social and interactive experience. In this paper we propose sonic artifact ecologies as a mean to examine interactions between one or many users with one or many artifacts. Case studies from a recently run workshop on product sound design are examined.", "references": ["Valter Nelson Noronha Alves and Licinio Roque. 2010. A pattern language for sound design in games.Proceedings of the AudioMostly Conference(AM'10), 88-95. http://doi.org/10.1145/1859799.1859811", "Erling Björgvinsson, Pelle Ehn, and Per-Anders Hillgren. 2012. Agonistic participatory design: working with marginalised social movements. CoDesign 8, 2-3: 127-144. http://doi.org/10.1080/15710882.2012.672577", "Eli Blevis, Ilpo K Koskinen, Kun-Pyo Lee, et al. 2015. Transdisciplinary Interaction Design in Design Education. Proceedings of the SIGCHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI'15), 833-838. http://doi.org/10.1145/2702613.2724726"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892583"}, {"title": "Search and Breast Cancer: On Episodic Shifts of Attention over Life Histories of an Illness", "authors": ["Michael J. Paul\n,", "Ryen W. White\n,", "Eric Horvitz"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nWe seek to understand the evolving needs of people who are faced with a life-changing medical diagnosis based on analyses of queries extracted from an anonymized search query log. Focusing on breast cancer, we manually tag a set of Web searchers as showing patterns of search behavior consistent with someone grappling with the screening, diagnosis, and treatment of breast cancer. We build and apply probabilistic classifiers to detect these searchers from multiple sessions and to identify the timing of diagnosis using temporal and statistical features. We explore the changes in information seeking over time before and after an inferred diagnosis of breast cancer by aligning multiple searchers by the estimated time of diagnosis. We employ the classifier to automatically identify 1,700 candidate searchers with an estimated 90% precision, and we predict the day of diagnosis within 15 days with an 88% accuracy. We show that the geographic and demographic attributes of searchers identified with high probability are strongly correlated with ground truth of reported incidence rates. We then analyze the content of queries over time for inferred cancer patients, using a detailed ontology of cancer-related search terms. The analysis reveals the rich temporal structure of the evolving queries of people likely diagnosed with breast cancer. Finally, we focus on subtypes of illness based on inferred stages of cancer and show clinically relevant dynamics of information seeking based on the dominant stage expressed by searchers.", "references": ["John W. Ayers, Benjamin M. Althouse, Jon-Patrick Allem, Daniel E. Ford, Kurt M. Ribisl, and Joanna E. Cohen. 2012. A novel evaluation of world no tobacco day in latin America. J. Med. Internet Res. 14, 3 (2012).", "Stephanie L. Ayers and Jennie Jacobs Kronenfeld. 2007. Chronic illness and health-seeking information on the internet. Health 11, 3 (2007).", "Mike Benigeri and Pierre Pluye. 2003. Shortcomings of health information on the internet. Health Promot. Int. 18, 4 (2003)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2893481"}, {"title": "A Complete & Comprehensive Movie Review Dataset (CCMR)", "authors": ["Xuezhi Cao\n,", "Weiyue Huang\n,", "Yong Yu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline review sites are widely used for various domains including movies and restaurants. These sites now have strong influences towards users during purchasing processes. There exist plenty of research works for review sites on various aspects, including item recommendation, user behavior analysis, etc. However, due to the lack of complete and comprehensive dataset, there are still problems that remain to be solved. Therefore, in this paper we assemble and publish such dataset (CCMR) for the community. CCMR outruns existing datasets in terms of completeness, comprehensiveness and scale. Besides describing the dataset and its collecting methodology, we also propose several potential research topics that are made possible by having this dataset. Such topics include: (i) a statistical approach to reduce the impacts from fake reviews and (ii) analyzing and modeling the influences of public opinions towards users during rating actions. We further conduct preliminary analysis and experiments for both directions to show that they are promising.", "references": ["J. Bennett and S. Lanning. The netflix prize. In Proceedings of KDD cup and workshop, volume 2007, page 35, 2007.", "N. Jindal, B. Liu, and E.-P. Lim. Finding unusual review patterns using unexpected rules. In CIKM, pages 1549--1552. ACM, 2010.", "Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, (8):30--37, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914669"}, {"title": "Leveraging Crowdsourcing for the Thematic Annotation of the Qur'an", "authors": ["Amna Basharat\n,", "I. Budak Arpinar\n,", "Khaled Rasheed"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn this paper, we illustrate how we leverage crowdsourcing to create workflows for knowledge engineering in specialized and knowledge intensive domains. We undertake the special case of the Arabic script of the Qur'an, a widely studied manuscript, and attempt to employ crowdsourcing methods for its thematic annotation at the sub-verse level, for which, there is no standardized knowledge model available to date. We demonstrate that our proposed method presents feasibility to achieve reliable annotations in an efficient and scalable manner. The proposed methodology and framework is meant to be generalizable to other knowledge intensive and specialized domains.", "references": ["A. Basharat, I. B. Arpinar, S. Dastgheib, U. Kursuncu, K. Kochut, and E. Dogdu. Semantically enriched task and workflow automation in crowdsourcing for linked data management. International Journal of Semantic Computing, 8(04):415--439, 2014.", "M. A. Sherif and A.-C. N. Ngomo. Semantic Quran - a multilingual resource for natural-language processing. Semantic Web, 6(4):339--345, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889409"}, {"title": "Semantic Documents Relatedness using Concept Graph Representation", "authors": ["Yuan Ni\n,", "Qiong Kai Xu\n,", "Feng Cao\n,", "Yosi Mass\n,", "Dafna Sheinwald\n,", "Hui Jia Zhu\n,", "Shao Sheng Cao"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nWe deal with the problem of document representation for the task of measuring semantic relatedness between documents. A document is represented as a compact concept graph where nodes represent concepts extracted from the document through references to entities in a knowledge base such as DBpedia. Edges represent the semantic and structural relationships among the concepts. Several methods are presented to measure the strength of those relationships. Concepts are weighted through the concept graph using closeness centrality measure which reflects their relevance to the aspects of the document. A novel similarity measure between two concept graphs is presented. The similarity measure first represents concepts as continuous vectors by means of neural networks. Second, the continuous vectors are used to accumulate pairwise similarity between pairs of concepts while considering their assigned weights. We evaluate our method on a standard benchmark for document similarity. Our method outperforms state-of-the-art methods including ESA (Explicit Semantic Annotation) while our concept graphs are much smaller than the concept vectors generated by ESA. Moreover, we show that by combining our concept graph with ESA, we obtain an even further improvement.", "references": ["C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. Dbpedia { a crystallization point for the web of data. Web Semantics, 2009.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research (JMLR), 2003.", "S. P. Borgatti. Centrality and network ow. Social Networks 27, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835801"}, {"title": "Assessing Concept Weighting in Integer Linear Programming based Single-document Summarization", "authors": ["Hilário Oliveira\n,", "Rinaldo Lima\n,", "Rafael Dueire Lins\n,", "Fred Freitas\n,", "Marcelo Riss\n,", "Steven J. Simske"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nSome of the recent state-of-the-art systems for Automatic Text Summarization rely on the concept-based approach using Integer Linear Programming (ILP), mainly for multi-document summarization. A study on the suitability of such an approach to single-document summarization is still missing, however. This work presents an assessment of several methods of concept weighing for a concept-based ILP approach on the single-document summarization scenario. The unigram and bigram representations for concepts are also investigated. The experimental results obtained on the DUC 2001-2002 and the CNN corpora show that bigrams are more suitable than unigrams for the representation of concepts. Among the concept scoring methods investigated, the sentence position method presented the best performance on all evaluation corpora.", "references": ["F. Boudin, H. Mougard, and B. Favre. Concept-based summarization using integer linear programming: From concept pruning to multiple optimal solutions. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1914--1918, Lisbon, Portugal, September 2015.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1--7):107--117, Apr. 1998.", "Z. Cao, F. Wei, L. Dong, S. Li, and M. Zhou. Ranking with recursive neural networks and its application to multi-document summarization. In Proceedings of the Twenty-Ninth Conference on Artificial Intelligence, pages 2153--2159, Austin, USA, January 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967160"}, {"title": "Latent Factor Representations for Cold-Start Video Recommendation", "authors": ["Sujoy Roy\n,", "Sharath Chandra Guntuku"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommending items that have rarely/never been viewed by users is a bottleneck for collaborative filtering (CF) based recommendation algorithms. To alleviate this problem, item content representation (mostly in textual form) has been used as auxiliary information for learning latent factor representations. In this work we present a novel method for learning latent factor representation for videos based on modelling the emotional connection between user and item. First of all we present a comparative analysis of state-of-the art emotion modelling approaches that brings out a surprising finding regarding the efficacy of latent factor representations in modelling emotion in video content. Based on this finding we present a method visual-CLiMF for learning latent factor representations for cold start videos based on implicit feedback. Visual-CLiMF is based on the popular collaborative less-is-more approach but demonstrates how emotional aspects of items could be used as auxiliary information to improve MRR performance. Experiments on a new data set and the Amazon products data set demonstrate the effectiveness of visual-CLiMF which outperforms existing CF methods with or without content information.", "references": ["L. Baltrunas, B. Ludwig, and F. Ricci. Matrix factorization techniques for context aware recommendation. In Proceedings of the 2011 ACM Conference on Recommender Systems, RecSys 2011, Chicago, IL, USA, October 23--27, 2011, pages 301--304. ACM, 2011.", "D. Borth, T. Chen, R. Ji, and S.-F. Chang. Sentibank: large-scale ontology and classifiers for detecting sentiment and emotions in visual content. In Proceedings of the 21st ACM international conference on Multimedia, pages 459--460. ACM, 2013.", "E. Cambria, J. Fu, F. Bisio, and S. Poria. Affectivespace 2: Enabling affective intuition for concept-level sentiment analysis. In AAAI, pages 508--514, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959172"}, {"title": "Modeling of Geographic Dependencies for Real Estate Ranking", "authors": ["Yanjie Fu\n,", "Hui Xiong\n,", "Yong Ge\n,", "Yu Zheng\n,", "Zijun Yao\n,", "Zhi-Hua Zhou"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nIt is traditionally a challenge for home buyers to understand, compare, and contrast the investment value of real estate. Although a number of appraisal methods have been developed to value real properties, the performances of these methods have been limited by traditional data sources for real estate appraisal. With the development of new ways of collecting estate-related mobile data, there is a potential to leverage geographic dependencies of real estate for enhancing real estate appraisal. Indeed, the geographic dependencies of the investment value of an estate can be from the characteristics of its own neighborhood (individual), the values of its nearby estates (peer), and the prosperity of the affiliated latent business area (zone). To this end, in this paper, we propose a geographic method, named ClusRanking, for real estate appraisal by leveraging the mutual enforcement of ranking and clustering power. ClusRanking is able to exploit geographic individual, peer, and zone dependencies in a probabilistic ranking model. Specifically, we first extract the geographic utility of estates from geography data, estimate the neighborhood popularity of estates by mining taxicab trajectory data, and model the influence of latent business areas. Also, we fuse these three influential factors and predict real estate investment value. Moreover, we simultaneously consider individual, peer and zone dependencies, and derive an estate-specific ranking likelihood as the objective function. Furthermore, we propose an improved method named CR-ClusRanking by incorporating checkin information as a regularization term which reduces the performance volatility of real estate ranking system. Finally, we conduct a comprehensive evaluation with the real estate-related data of Beijing, and the experimental results demonstrate the effectiveness of our proposed methods.", "references": ["M. Bailey, R. Muth, and H. Nourse. 1963. A regression method for real estate price index construction. J. Am. Stat. Assoc. 58 (1963), 933--942.", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. J. Mach. Learn. Res. 3 (2003), 993--1022.", "C. J. C. Burges, R. Ragno, and Q. V. Le. 2007. Learning to rank with non-smooth cost functions. In Advances in Neural Information Processing Systems, Volume 19. MIT Press, Cambridge, MA. http://research.microsoft.com/apps/pubs/default.aspx?id&equals;68133."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934692"}, {"title": "Parameterized Fielded Term Dependence Models for Ad-hoc Entity Retrieval from Knowledge Graph", "authors": ["Fedor Nikolaev\n,", "Alexander Kotov\n,", "Nikita Zhiltsov"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAccurate projection of terms in free-text queries onto structured entity representations is one of the fundamental problems in entity retrieval from knowledge graphs. In this paper, we demonstrate that existing retrieval models for ad-hoc structured and unstructured document retrieval fall short of addressing this problem, due to their rigid assumptions. According to these assumptions, either all query concepts of the same type (unigrams and bigrams) are projected onto the fields of entity representations with identical weights or such projection is determined based only on one simple statistic, which makes it sensitive to data sparsity. To address this issue, we propose the Parametrized Fielded Sequential Dependence Model (PFSDM) and the Parametrized Fielded Full Dependence Model (PFFDM), two novel models for entity retrieval from knowledge graphs, which infer the user's intent behind each individual query concept by dynamically estimating its projection onto the fields of structured entity representations based on a small number of statistical and linguistic features. Experimental results obtained on several publicly available benchmarks indicate that PFSDM and PFFDM consistently outperform state-of-the-art retrieval models for the task of entity retrieval from knowledge graph.", "references": ["J. Bai, Y. Chang, H. Cui, Z. Zheng, G. Sun, and X. Li. Investigation of Partial Query Proximity in Web Search. In Proceedings of the 17th WWW, pages 1183--1184, 2008.", "K. Balog and R. Neumayer. A Test Collection for Entity Search in DBpedia. In Proceedings of the 36th ACM SIGIR, pages 737--740, 2013.", "M. Bendersky and W. B. Croft. Discovering Key Concepts in Verbose Queries. In Proceedings of the 31st ACM SIGIR, pages 491--498, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911545"}, {"title": "Top-N Recommendation on Graphs", "authors": ["Zhao Kang\n,", "Chong Peng\n,", "Ming Yang\n,", "Qiang Cheng"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRecommender systems play an increasingly important role in online applications to help users find what they need or prefer. Collaborative filtering algorithms that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. To alleviate this problem, this paper proposes a simple recommendation algorithm that fully exploits the similarity information among users and items and intrinsic structural information of the user-item matrix. The proposed method constructs a new representation which preserves affinity and structure information in the user-item rating matrix and then performs recommendation task. To capture proximity information about users and items, two graphs are constructed. Manifold learning idea is used to constrain the new representation to be smooth on these graphs, so as to enforce users and item proximities. Our model is formulated as a convex optimization problem, for which we need to solve the well known Sylvester equation only. We carry out extensive empirical evaluations on six benchmark datasets to show the effectiveness of this approach.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, 2005.", "P. Benner, R.-C. Li, and N. Truhar. On the adi method for sylvester equations. Journal of Computational and Applied Mathematics, 233(4):1035--1045, 2009.", "F. Cacheda, V. Carneiro, D. Fernández, and V. Formoso. Comparison of collaborative filtering algorithms: Limitations of current techniques and proposals for scalable, high-performance recommender systems. ACM Transactions on the Web, 5(1):2, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983649"}, {"title": "Semantic question answering on big data", "authors": ["Marta Tatu\n,", "Steven Werner\n,", "Mithun Balakrishna\n,", "Tatiana Erekhinskaya\n,", "Dan Moldovan"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nThis article describes a high-precision semantic question answering (SQA) engine for large datasets. We employ an RDF store to index the semantic information extracted from large document collections and a natural language to SPARQL conversion module to find desired information. In order to be able to find answers to complex questions in structured/unstructured data resources, our system produces rich semantic structures from the data resources and then transforms the extracted knowledge into an RDF representation. In order to facilitate easy access to the information stored in the RDF semantic index, our system accepts a user's natural language questions, translates them into SPARQL queries and returns a precise answer back to the user. Our improvements in performance over a regular free text search index-based question answering engine prove that SQA can benefit greatly from the addition and consumption of deep semantic information.", "references": ["E. Blanco and D. I. Moldovan. Unsupervised learning of semantic relation composition. In Proceedings of HLT-2011, pages 1456--1465, 2011.", "A. Bouziane, D. Bouchiha, N. Doumi, and M. Malki. Question Answering Systems: Survey and Trends. Procedia Computer Science, 73:366--375, 2015. AWICT 2015.", "D. Damljanovic, M. Agatonovic, and H. Cunningham. FREyA: An Interactive Way of Querying Linked Data Using Natural Language. In Proceedings of ESWC'11, pages 125--138, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928302"}, {"title": "Checking app user interfaces against app descriptions", "authors": ["Konstantin Kuznetsov\n,", "Vitalii Avdiienko\n,", "Alessandra Gorla\n,", "Andreas Zeller"], "publication": "WAMA 2016: Proceedings of the International Workshop on App Market Analytics", "abstract": "ABSTRACT\nDoes the advertised behavior of apps correlate with what a user sees on a screen? In this paper, we introduce a technique to statically extract the text from the user interface definitions of an Android app. We use this technique to compare the natural language topics of an app’s user interface against the topics from its app store description. A mismatch indicates that some feature is exposed by the user interface, but is not present in the description, or vice versa. The popular Twitter app, for instance, spots UI elements that al- low to make purchases; however, this feature is not mentioned in its description. Likewise, we identified a number of apps whose user interface asks users to access or supply sensitive data; but this “feature” is not mentioned in the description. In the long run, analyzing user interface topics and comparing them against external descriptions opens the way for checking general mismatches between requirements and implementation.", "references": ["A. A. Al-Subaihin, F. Sarro, S. Black, L. Capra, M. Harman, Y. Jia, and Y. Zhang. Clustering mobile apps based on mined textual descriptions. In Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), ESEM ’16, 2016.", "V. Avdiienko, K. Kuznetsov, P. Calciati, J. C. C. Román, A. Gorla, and A. Zeller. CALAPPA: a toolchain for mining android applications. In Proceedings of the 1st International Workshop on App Market Analytics, WAMA 2016, pages –. ACM, 11 2016.", "A. Gorla, I. Tavecchia, F. Gross, and A. Zeller. Checking app behavior against app descriptions. In Proceedings of the 36th International Conference on Software Engineering, ICSE 2014, pages 1025–1035, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993259.2993265"}, {"title": "The Hilbert PDC-tree: A High-Velocity Structure for Many-Dimensional Data", "authors": ["David Robillard\n,", "Frank Dehne\n,", "Andrew Rau-Chaplin\n,", "Neil Burke"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nFast aggregation of data with many dimensions is a key component of many applications. The R-tree is the traditional data structure for indexing multi-dimensional data, but even the best R-tree variants suffer from performance degradation as the number of dimensions increases. The DC-tree addressed this issue by replacing Minimum Bounding Rectangle (MBR) keys with Minimum Describing Subsets (MDSs), which are less susceptible to overlap. This technique dramatically improves query performance with many dimensions, but at the cost of reduced insertion performance. Like most R-tree variants, this insertion overhead comes from expensive geometric comparisons while selecting the best child for insertion, or splitting over-full nodes. DC-trees, including the parallel PDC-tree, suffer even more from this overhead since MDSs are typically much more expensive to compare and manipulate than MBRs. This paper introduces the Hilbert PDC-tree, a parallel index structure for many-dimensional data that supports high-velocity data ingestion. This is achieved by avoiding geometric comparisons during insertion by instead inserting records based on the Hilbert index of their keys. This approach is similar to that of the Hilbert R-tree, but with special considerations for efficiently supporting many hierarchical dimensions. Additionally, a new node splitting algorithm significantly reduces overlap and improves query performance. Experiments show that the Hilbert PDC-tree scales well to a high number of dimensions, while supporting a much higher rate of ingestion and better query performance than the PDC-tree.", "references": ["N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. The R*-tree: An efficient and robust access method for points and rectangles. ACM SIGMOD Record, 19(2):322--331, May 1990.", "N. Beckmann and B. Seeger. A revised R*-tree in comparison with related index structures. In Proc. 2009 SIGMOD Int. Conf. on Management of Data, page 799. ACM, 2009.", "S. Berchtold, D. A. Keim, and H.-P. Kriegel. The X-tree: An index structure for high-dimensional data. In Proc. 22th Int. Conf. on Very Large Data Bases, pages 28--39. Morgan Kaufmann."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938549"}, {"title": "Retrievability in API-Based \"Evaluation as a Service\"", "authors": ["Jiaul H. Paik\n,", "Jimmy Lin"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\n\"Evaluation as a service\" (EaaS) refers to a family of related evaluation methodologies that enables community-wide evaluations and the construction of test collections on documents that cannot be easily distributed. In the API-based approach, the basic idea is that evaluation organizers provide a service API through which the evaluation task can be completed, without providing access to the raw collection. One concern with this evaluation approach is that the API introduces biases and limits the diversity of techniques that can be brought to bear on the problem. In this paper, we tackle the question of API bias using the concept of retrievability. The raw data for our analyses come from a naturally-occurring experiment where we observed the same groups completing the same task with the API and also with access to the raw collection. We find that the retrievability bias of runs generated in both cases are comparable. Moreover, the fraction of relevant tweets retrieved through the API by the participating groups is at least as high as when they had access to the raw collection.", "references": ["L. Azzopardi and V. Vinay. Retrievability: An evaluation measure for higher order information access tasks. CIKM, 2008.", "D. Harman. Information Retrieval Evaluation. Morgan & Claypool Publishers, 2011.", "F. Hopfgartner, A. Hanbury, H. Müller, N. Kando, S. Mercer, J. Kalpathy-Cramer, M. Potthast, T. Gollub, A. Krithara, J. Lin, K. Balog, and I. Eggel. Report on the Evaluation-as-a-Service (EaaS) Expert Workshop. SIGIR Forum, 49(1):57--65, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970427"}, {"title": "NERank: Ranking Named Entities in Document Collections", "authors": ["Chengyu Wang\n,", "Rong Zhang\n,", "Xiaofeng He\n,", "Aoying Zhou"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWhile most of the entity ranking research focuses on Web corpora with user queries as input, little has been done to rank entities directly from documents. We propose a ranking algorithm NERank to address this issue. NERank employs a random walk process on a weighted tripartite graph mined from the document collection. We evaluate NERank over real-life document datasets and compare it with baselines. Experimental results show the effectiveness of our method.", "references": ["V. Jijkoun, M. A. Khalid, M. Marx, and M. de Rijke. Named entity normalization in user generated content. In AND, pages 23--30, 2008.", "R. Mihalcea and P. Tarau. Textrank: Bringing order into text. In EMNLP, pages 404--411, 2004.", "W. Shen, J. Wang, P. Luo, and M. Wang. LINDEN: linking named entities with knowledge base via semantic knowledge. In WWW, pages 449--458, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889348"}, {"title": "Comparing efficacy of web design of university websites: mixed methodology and first results for Russia and the USA", "authors": ["Svetlana S. Bodrunova\n,", "Alexandr V. Yakunin\n,", "Artyom A. Smolin"], "publication": "EGOSE '16: Proceedings of the International Conference on Electronic Governance and Open Society: Challenges in Eurasia", "abstract": "ABSTRACT\nUnderstanding the mechanisms of visual perception is important in the context of both media research and its applications in design practice. Within the functional approach to interface design, eye tracking is an established method to analyze interface efficacy. At the same time, in today's media design, many rules have been established by practitioners and remain untested. In this mixed-method study, we combine web crawling, web analytics and heat map analysis based on eye tracking, and qualitative usability analysis of composite-graphic model of a website. We check whether eye tracking test results (numeric data and heat map analysis) correlate to usability of key pages of a large website, as measured qualitatively according to recommendations of leading design literature. Among large web spaces, university website clusters represent a special type and suit well for our analysis, as they unite very different publics and are multi-task. We elaborate and pre-test the methodology on three sites of leading universities in the USA and Russia (Harvard University, Moscow State University and St.Petersburg State University). Our results suggest that there is no direct link between design-based elements of page usability and numeric eye tracking data, but heat maps show correlation with design quality; this means we need to continue checking the suggested methodology on larger number of assessors.", "references": ["I. Ashmanov, and A. Ivanov. 2009. Optimization and promotion of websites in search engines. St.Petersburg: Piter.", "J. Nielsen. 2006. \"F-shaped pattern for reading web content\", Jacob Nielsen's Alertbox, April 17, 2006. Retrieved from: http://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/.", "R.S. Bazhanov. 2014. \"Basic metrics of web-analytical instruments as the ground for web assessment\", Almanac for modern science and education, 7(85), 27--30."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3014087.3014113"}, {"title": "Detection of Nonzero Doppler Targets Using Complementary Waveforms in Reed-Muller Sequences", "authors": ["Jiahua Zhu\n,", "Xuezhi Wang\n,", "Xiaotao Huang\n,", "Sofia Suvorova\n,", "Bill Moran"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nReed-Muller codes were used in radar signal processing to determine the sequence transmitting order of Golay complementary waveforms for radar illumination to get an improved detection performance on atargetofnonzero Doppler. In this paper, we consider the detection case where multiple targets with nonzero Doppler are present. We propose a signal processing procedure which achieves an enhanced illumination performance by applying the combination of the Reed-Muller codes and the Binominal Designto the Golay omplementary waveform transmission sequences. The procedure consists of two processes. A Reed-Muller sequence is selected according to a weighted average Doppler algorithm. In the meantime, the Binominal Design algorithmis used to the receiving weights of Golay complementary waveforms as well. After match filtering, the minimum output values of the two processes are point-wisely operated as thefinal output. Simulated results show that the proposed signal processing procedure has a better detection performance in the sense of lower sidelobes and higher Doppler resolution for nonzero Doppler targets against the existing methods.", "references": ["R. Calderbank, S. D. Howard and W. Moran, \"Waveformdiversity in radar signal processing,\" IEEE Signal Process. Mag., vol. 26, no. 1, pp. 32--41, 2009.", "J. Li, L. Xu, P. Stoica, K. W. Forsythe and D. W. Bliss, \"Rangecompression and waveform optimization for MIMO radar: ACramer-Rao bound based study,\" IEEE Trans. Signal Process., vol. 56, no. 1, pp. 218--232, Jan. 2008.", "B. Friedlander, \"Waveform design for MIMO radars,\" IEEETrans. Aeros. Elctr. Systems, vol. 43, no. 3, pp. 1227--1238, Jul. 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015179"}, {"title": "Black box replication: Breaking the latency limits", "authors": ["Assaf Natanzon\n,", "Alex Winokur\n,", "Eitan Bachmat"], "publication": "SYSTOR '16: Proceedings of the 9th ACM International on Systems and Storage Conference", "abstract": "ABSTRACT\nSynchronous replication is critical for today's enterprise IT organization. It is mandatory by regulation in several countries for some types of organizations, including banks and insurance companies. The technology has been available for a long period of time, but due to speed of light and maximal latency limitations, it is usually limited to a distance of 50-100 miles. Flight data recorders, also known as black boxes, have long been used to record the last actions which happened in airplanes at times of disasters. We present an integration between an Enterprise Data Recorder and an asynchronous replication mechanism, which allows breaking the functional limits that light speed imposes on synchronous replication.", "references": ["A. Azagury, M. Factor, and W. Micka, Advanced functions for storage subsystems: Supporting continuous availability. An IBM SYSTEM Journal, 2003.", "EMC Symmetrix Remote Data Facility. http://www.emc.com/.", "FDR http://en.wikipedia.org/wiki/Flight data recorder/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928275.2928277"}, {"title": "BathDrum2: Percussion Instruments on a Bathtub Edge with Low-Latency Tap Tone Identification", "authors": ["Tomoyuki Sumida\n,", "Shigeyuki Hirai"], "publication": "ACE '16: Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nIn order to create a smart bathroom with entertainment features, we propose a playable system that can identify several tap tones on the top of a bathtub edge from differences in hand posture. BathDrum2 is a specific implementation of this system; it utilizes nonnegative matrix factorization (NMF), a kind of machine learning technique, for low-latency tap tone identification and for playing assigned percussion sounds. This paper describes the system design and tap tone identifier with its signal processing and NMF. The performance evaluation of the current BathDrum2 implementation is also described.", "references": ["Stephen S Intille, Kent Larson, J Beaudin, E Munguia Tapia, Pallavi Kaushik, Jason Nawyn, and Thomas J McLeish. 2005. The PlaceLab: A live-in laboratory for pervasive computing research (video). Proceedings of PERVASIVE 2005 Video Program (2005).", "B De Ruyter, E Aarts, P Markopoulos, and W Ijsselsteijn. 2005. Ambient intelligence research in homelab: Engineering the user experience. In Ambient Intelligence. Springer, 49--61.", "Chia-Hsun Jackie Lee, Leonardo Bonanni, Jose H Espinosa, Henry Lieberman, and Ted Selker. 2006. Augmenting kitchen appliances with a shared context using knowledge about daily events. In Proc. of IUI2006, 348--350."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001773.3001816"}, {"title": "GKSH: Graph based Image Retrieval using Supervised Kernel Hashing", "authors": ["Bo Wu\n,", "Bo Lang\n,", "Yang Liu"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThe explosive growth of the massive image database brings great challenge to the fast and accurate image retrieval. To address this issue, we propose a kind of supervised hashing method based on the graph representation of the images, which translates images into representative attribute structural graphs. Compared with the traditional supervised methods, this kind of structural graphs can consider the spatial relations among regions in the image, and integrate unsupervised properties of images and supervised information of labels by adopting hashing with graph kernel based on random walks. The learnt hash codes can be a good tradeoff among retrieval speed, memory requirements and retrieval accuracy. The experiments on three image datasets PASCAL, MNIST and HOLIDAY demonstrate that, with the hash codes of the same length, the proposed supervised hashing method can achieve a higher precision and a better efficiency.", "references": ["Gudivada V N, Raghavan V V. Content based image retrieval systems. Computer, 28(9), pp. 18--22 (1995)", "Raveaux R, Burie J C, Ogier J M. Structured representations in a content based image retrieval context. JVCIR, 24(8), pp. 1252--1268 (2013)", "He H, Singh A K. Closure-tree: An index structure for graph queries. IEEE ICDE. pp. 38--38 (2006)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007722"}, {"title": "Discovering Entities with Just a Little Help from You", "authors": ["Jaspreet Singh\n,", "Johannes Hoffart\n,", "Avishek Anand"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLinking entities like people, organizations, books, music groups and their songs in text to knowledge bases (KBs) is a fundamental task for many downstream search and mining applications. Achieving high disambiguation accuracy crucially depends on a rich and holistic representation of the entities in the KB. For popular entities, such a representation can be easily mined from Wikipedia, and many current entity disambiguation and linking methods make use of this fact. However, Wikipedia does not contain long-tail entities that only few people are interested in, and also at times lags behind until newly emerging entities are added. For such entities, mining a suitable representation in a fully automated fashion is very difficult, resulting in poor linking accuracy.\nWhat can automatically be mined, though, is a high-quality representation given the context of a new entity occurring in any text. Due to the lack of knowledge about the entity, no method can retrieve these occurrences automatically with high precision, resulting in a chicken-egg problem. To address this, our approach automatically generates candidate occurrences of entities, prompting the user for feedback to decide if the occurrence refers to the actual entity in question. This feedback gradually improves the knowledge and allows our methods to provide better candidate suggestions to keep the user engaged. We propose novel human-in-the-loop retrieval methods for generating candidates based on gradient interleaving of diversification and textual relevance approaches.\nWe conducted extensive experiments on the FACC dataset, showing that our approaches convincingly outperform carefully selected baselines in both intrinsic and extrinsic measures while keeping users engaged.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14. ACM, 2009.", "H. Bast, F. Bäurle, B. Buchhold, and E. Haußmann. Semantic Full-Text Search with Broccoli. In SIGIR, 2014.", "R. Bunescu and M. Pasca. Using Encyclopedic Knowledge for Named Entity Disambiguation. In PEACL, Trento, Italy, pages 9--16, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983798"}, {"title": "Discovering What You're Known For: A Contextual Poisson Factorization Approach", "authors": ["Haokai Lu\n,", "James Caverlee\n,", "Wei Niu"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nDiscovering what people are known for is valuable to many important applications such as recommender systems. Unlike an individual's personal interests, what a user is known for is reflected by the views of others, and is often not easily discerned for a long-tail of the vast majority of users. In this paper, we tackle the problem of discovering what users are known for through a probabilistic model called Bayesian Contextual Poisson Factorization. Moving beyond just modeling user's content, it naturally models and integrates additional contextual factors, concretely, user's geo-spatial footprints and social influence, to overcome noisy online activities and social relations. Through GPS-tagged social media datasets, we find that the proposed method can improve known-for prediction performance by 17.5% in precision and 20.9% in recall on average, and that it can capture the implicit relationships between a user's known-for profile and her content, geo-spatial and social influence.", "references": ["A. Ahmed, Y. Low, M. Aly, V. Josifovski, and A. J. Smola. Scalable distributed inference of dynamic user interests for behavioral targeting. In SIGKDD, 2011.", "X. Amatriain, N. Lathia, J. M. Pujol, H. Kwak, and N. Oliver. The wisdom of the few: a collaborative filtering approach based on expert opinions from the web. In SIGIR, 2009.", "P. Bhattacharya, S. Ghosh, J. Kulshrestha, M. Mondal, M. B. Zafar, N. Ganguly, and K. P. Gummadi. Deep twitter diving: Exploring topical groups in microblogs at scale. In CSCW, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959146"}, {"title": "Linked Open Vocabulary Ranking and Terms Discovery", "authors": ["Ioannis Stavrakantonakis\n,", "Anna Fensel\n,", "Dieter Fensel"], "publication": "SEMANTiCS 2016: Proceedings of the 12th International Conference on Semantic Systems", "abstract": "ABSTRACT\nSearching among the existing 500 and more vocabularies was never easier than today with the Linked Open Vocabularies (LOV) curated directory list. The LOV search provides one central point to explore the vocabulary terms space. However, it can be still cumbersome for non-experts or semantic annotation experts to discover the appropriate terms for the description of given website content. In this direction, the proposed approach is the cornerstone part of a methodology that aims to facilitate the selection of the highest ranked terms from the abundance of the registered vocabularies based on a keyword search. Moreover, it introduces for the first time the role of the contributors' background, which is retrieved from the LOV repository, in the ranking of the vocabularies. With this addition, we aim to address the issue of very low scores for the newly published vocabularies. The paper underlines the difficulty of selecting vocabulary terms through a survey and describes the approach that enables the ranking of vocabularies within the above mentioned methodology.", "references": ["G. A. Atemezing and R. Troncy. Information content based ranking metric for Linked Open Vocabularies. In Proceedings of the 10th International Conference on Semantic Systems, pages 53--56. ACM, 2014.", "S. Auer, J. Demter, M. Martin, and J. Lehmann. Lodstats--an extensible framework for high-performance dataset analytics. In Knowledge Engineering and Knowledge Management, pages 353--362. Springer, 2012.", "C. Bizer, K. Eckert, R. Meusel, H. Mühleisen, M. Schuhmacher, and J. Völker. Deployment of RDFa, microdata, and microformats on the Web -- a quantitative analysis. In The Semantic Web--ISWC 2013, pages 17--32. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993318.2993338"}, {"title": "Describing Lifelogs with Convolutional Neural Networks: A Comparative Study", "authors": ["Ana Garcia del Molino\n,", "Qianli Xu\n,", "Joo-Hwee Lim"], "publication": "LTA '16: Proceedings of the first Workshop on Lifelogging Tools and Applications", "abstract": "ABSTRACT\nLife-logging technologies, e.g. wearable cameras taking pictures at a fixed interval, can be used as a means of memory preservation (in digital form), caregiver monitoring and even cognitive therapy to train our brains. Yet, such large amount of data needs to be processed and edited to be of use. Automatic summarization of the life-logs into short story boards is a possible solution. But how good are these summaries? Are the selected key-frames informative and representative enough as to be good memory cues? The proposed approach (i) filters uninformative images by analyzing their ratio of edges and (ii) describes the images using the available Convolutional Neural Networks (CNN) models for objects and places with egocentric-driven data augmentation. We perform a comparative study to evaluate different summarization methods in terms of coverage, informativeness and representativeness in two different datasets, both with annotated ground truth and an on-line user study. Results show that filtering uninformative images improves the user satisfaction: users would request to change less frames from the original summary than without filtering. Moreover, the proposed egocentric image descriptor generates more diverse content than the standard cropping strategy used by most CNN-based approaches.", "references": ["M. Bolanos, M. Dimiccoli, and P. Radeva. Towards storytelling from visual lifelogging: An overview. arXiv preprint arXiv:1507.06120, 2015.", "M. Bolanos, R. Mestre, E. Talavera, X. Giró-i Nieto, and P. Radeva. Visual summary of egocentric photostreams by representative keyframes. In Multimedia & Expo Workshops (ICMEW), 2015 IEEE International Conference on, pages 1--6. IEEE, 2015.", "M. Bola\\ nos and P. Radeva. Ego-object discovery. arXiv preprint arXiv:1504.01639, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983576.2983579"}, {"title": "Recommendations beyond the ratings matrix", "authors": ["Eirini Ntoutsi\n,", "Kostas Stefanidis"], "publication": "DDI '16: Proceedings of the Workshop on Data-Driven Innovation on the Web", "abstract": "ABSTRACT\nRecommender systems have become indispensable for several Web sites, such as Amazon, Netflix and Google News, helping users navigate through the abundance of available choices. Although the field has advanced impressively in the last years with respect to models, usage of heterogeneous information, such as ratings and text reviews, and recommendations for modern applications beyond purchases, almost all of the approaches rely on the data that exist within the recommender and on user explicit input. In a rapidly connected world, though, information is not isolated and does not necessarily lie in the database of a single recommender. Rather, Web offers tremendous amount of information on almost everything, from items to users and their tendency to certain items, but also information on general trends and demographics. We envision an out-of-the-box recommender system that exploits the existing information in a recommender, namely, items, users and ratings, but also explores new sources of information out of the database, like user online traces and online discussions about data items, and exploits them for better and innovative recommendations. We discuss the challenges that such an out-of-the-box approach effects and how it reshapes the field of recommenders.", "references": ["G. Adomavicius, N. Manouselis, and Y. Kwon. Multi-criteria recommender systems. In Recommender Systems Handbook. 2011.", "G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Trans. Inf. Syst., 23(1):103--145, 2005.", "G. Chen and L. Chen. Recommendation based on contextual opinions. In UMAP, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911187.2914580"}, {"title": "Session details: Main Track - Security Management", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255991"}, {"title": "TAPS: A MOSS Extension for Detecting Software Plagiarism at Scale", "authors": ["Dana Sheahen\n,", "David Joyner"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nCheating in computer science classes can damage the reputation of institutions and their students. It is therefore essential to routinely authenticate student submissions with available software plagiarism detection algorithms such as Measure of Software Similarity (MOSS). Scaling this task for large classes where assignments are repeated each semester adds complexity and increases the instructor workload. The MOSS Tool for Addressing Plagiarism at Scale (MOSS-TAPS), organizes the MOSS submission task in courses that repeat coding assignments. In a recent use-case in the Online Master of Science in Computer Science (OMSCS) program at the Georgia Institute of Technology, the instructor time spent was reduced from 50 hours to only 10 minutes using the managed submission tool design presented here. MOSS-TAPS provides persistent configuration, supports a mixture of software languages and file organizations, and is implemented in pure Java for cross-platform compatibility.", "references": ["Alex Aiken. 2014. Moss - A System for Detecting Software Plagiarism. Retrieved January 8, 2016 from https://theory.stanford.edu/~aiken/moss/", "Charlie Daly and Jane Horgan. 2005. Patterns of plagiarism. SIGCSE Bull. 37, 1 (February 2005), 383--387.", "Ashok Goel and David Joyner. 2014. CS7637: Knowledge-Based AI:Cognitive Systems {Online Course}. Retrieved January 8, 2016 from https://www.udacity.com/course/knowledge-based-ai-cognitive-systems--ud409"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893435"}, {"title": "Bayesian Low-Rank Determinantal Point Processes", "authors": ["Mike Gartrell\n,", "Ulrich Paquet\n,", "Noam Koenigstein"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nDeterminantal point processes (DPPs) are an emerging model for encoding probabilities over subsets, such as shopping baskets, selected from a ground set, such as an item catalog. They have recently proved to be appealing models for a number of machine learning tasks, including product recommendation. DPPs are parametrized by a positive semi-definite kernel matrix. Prior work has shown that using a low-rank factorization of this kernel provides scalability improvements that open the door to training on large-scale datasets and computing online recommendations, both of which are infeasible with standard DPP models that use a full-rank kernel. A low-rank DPP model can be trained using an optimization-based method, such as stochastic gradient ascent, to find a point estimate of the kernel parameters, which can be performed efficiently on large-scale datasets. However, this approach requires careful tuning of regularization parameters to prevent overfitting and provide good predictive performance, which can be computationally expensive. In this paper we present a Bayesian method for learning a low-rank factorization of this kernel, which provides automatic control of regularization. We show that our Bayesian low-rank DPP model can be trained efficiently using stochastic gradient Hamiltonian Monte Carlo (SGHMC). Our Bayesian model generally provides better predictive performance on several real-world product recommendation datasets than optimization-based low-rank DPP models trained using stochastic gradient ascent, and better performance than several state-of-the art recommendation methods in many cases.", "references": ["R. H. Affandi, E. Fox, R. Adams, and B. Taskar. Learning the parameters of determinantal point process kernels. In ICML, pages 1224--1232, 2014.", "R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In Proc. of SIGMOD 1993, pages 207--216, 1993.", "T. Brijs. Retail market basket data set. In Workshop on Frequent Itemset Mining Implementations (FIMI'03), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959178"}, {"title": "Interactive generic learning method (IGLM): a new approach to interactive short text classification", "authors": ["Ameni Bouaziz\n,", "Célia da Costa Pereira\n,", "Christel Dartigues Pallez\n,", "Frédéric Precioso"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nWe propose a method to improve the performance of Random Forests for classifying short texts interactively. In short text classification, the principle of learning algorithms is to build a static model using a training dataset, then to use this model to classify new texts. Many works concentrate on improving the representation of the data as a way to build better models. We intend to tackle the problem in two ways: first by abstracting data to solve the problem of sparseness, and second by taking benefit from already classified data to continuously improve the model. Besides, in order to alleviate the amount of manual annotation, we propose an interactive method in which a manual correct annotation is required only for some misclassified texts, which are then incorporated into the training data to build an updated model. An important challenge is then to determine when to trigger this operation and how to perform the update. Applied on the standard search-snippets dataset, our method allowed a significant improvement.", "references": ["H. Abdulsalam, D. B. Skillicorn, and P. Martin. Streaming random forests. In Database Engineering and Applications Symposium, 2007. IDEAS 2007. 11th International, pages 225--232. IEEE, 2007.", "A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavaldà. New ensemble methods for evolving data streams. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 139--148. ACM, 2009.", "A. Bouaziz, C. Dartigues-Pallez, C. da Costa Pereira, F. Precioso, and P. Lloret. Short text classification using semantic random forest. In DAWAK, pages 288--299. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851646"}, {"title": "Search Engine Evaluation", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915041"}, {"title": "Preliminary Exploration of the Effect of Time Constraint on Search Interactions on Webpages", "authors": ["Chang Liu\n,", "Tao Xu"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis study explored the effect of time constraint on searchers' interactions during two kinds of tasks through conducting a user experiment. The results demonstrated users' did not tend to accelerate their reading or decision speed given time constraint, but to select fewer pages to read, i.e. visit fewer content pages and search result pages (SERPs); and they had more mouse clicks but fewer keystrokes per page when searching with time constraint. The results also showed the different effects of time constraint on search interactions on pages for two types of tasks. The results have implications for the design of digital library systems that take account users' time constraint or time pressure.", "references": ["Borlund, P. (2003). The IIR evaluation model: A framework-for evaluation of interactive information retrieval systems. Information Research, 8(3): 1--34.", "Crescenzi, A., Capra, R., & Arguello, J. (2013). Time Pressure, User Satisfaction and Task Difficulty. Proceedings of ASIS&T 13--.", "Crescenzi, A., Kelly, D., and Azzopardi, L. (2015). Time Pressure and System Delays in Information Search. SIGIR '15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925463"}, {"title": "First Story Detection using Multiple Nearest Neighbors", "authors": ["Jeroen B.P. Vuurens\n,", "Arjen P. de Vries"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFirst Story Detection (FSD) systems aim to identify those news articles that discuss an event that was not reported before. Recent work on FSD has focussed almost exclusively on efficiently detecting documents that are dissimilar from their nearest neighbor. We propose a novel FSD approach that is more effective, by adapting a recently proposed method for news summarization based on 3-nearest neighbor clustering. We show that this approach is more effective than a baseline that uses dissimilarity of an individual document from its nearest neighbor.", "references": ["J. Allan, V. Lavrenko, D. Malin, and R. Swan. Detections, bounds, and timelines: Umass and TDT-3. In Proceedings of TDT-3 Workshop, pages 167--174, 2000.", "J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. In Proceedings of SIGIR 1998, pages 37--45. ACM, 1998.", "M. Karkali, F. Rousseau, A. Ntoulas, and M. Vazirgiannis. Efficient online novelty detection in news streams. In WISE 2013, pages 57--71. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914761"}, {"title": "Exploiting CPU SIMD Extensions to Speed-up Document Scoring with Tree Ensembles", "authors": ["Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Raffaele Perego\n,", "Nicola Tonellotto\n,", "Rossano Venturini"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nScoring documents with learning-to-rank (LtR) models based on large ensembles of regression trees is currently deemed one of the best solutions to effectively rank query results to be returned by large scale Information Retrieval systems. This paper investigates the opportunities given by SIMD capabilities of modern CPUs to the end of efficiently evaluating regression trees ensembles. We propose V-QuickScorer (vQS), which exploits SIMD extensions to vectorize the document scoring, i.e., to perform the ensemble traversal by evaluating multiple documents simultaneously. We provide a comprehensive evaluation of vQS against the state of the art on three publicly available datasets. Experiments show that vQS provides speed-ups up to a factor of 3.2x.", "references": ["N. Asadi, J. Lin, and A. P. de Vries. Runtime optimizations for tree-based machine learning models. IEEE Transactions on Knowledge and Data Engineering, 26(9):2281--2292, 2014.", "G. Capannini, D. Dato, C. Lucchese, M. Mori, F. M. Nardini, S. Orlando, R. Perego, and N. Tonellotto. Quality versus Efficiency in Document Scoring with Learning-to-Rank Models. Information Processing and Management, 2016.", "J. H. Friedman. Greedy function approximation: a gradient boosting machine. Annals of Statistics, pages 1189--1232, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914758"}, {"title": "A Model for Data Integration and Availability in Health Government Area", "authors": ["Ana C.C. Ferronato\n,", "Fernanda Ramos Pires\n,", "Flavia Cristina Bernardini"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nOne of the evolution paths of smart cities go towards a strong integration of all intelligence dimensions --- human intelligence, collective and artificial --- available in a city. In pursuit of helping this evolution,this paper presents the mapping of a data model in order to create an ontology for Brazilian smart cities in government health care, by applying Semantic Web concepts and data integration, to seek solutions to alignment problems between databases", "references": ["Bernardini, F., Ferronato, A., Pires, P. Modelo rdf-schema para a area de saude governamental, 2016. Disponivel em http://www.pxsti.com.br/artigo/ Modelo_FinalSaude.pdf. Acessado em 01 de fevereiro de 2016.", "BERNERS-LEE, T., HENDLER, J., and LASSILA, O. The semantic web. Scientific American (2001).", "CHUNG, T., XU, B., ZHANG, P., TAN, Y., ZHU, P., and WUBULIHASIMU, A. Semantic Technology, vol. 8388 --- LNCS. Springer, 2014, ch. Constructing City Ontology from Expert for Smart City Management, pp. 187-194."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021977"}, {"title": "Terms over LOAD: Leveraging Named Entities for Cross-Document Extraction and Summarization of Events", "authors": ["Andreas Spitz\n,", "Michael Gertz"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nReal world events, such as historic incidents, typically contain both spatial and temporal aspects and involve a specific group of persons. This is reflected in the descriptions of events in textual sources, which contain mentions of named entities and dates. Given a large collection of documents, however, such descriptions may be incomplete in a single document, or spread across multiple documents. In these cases, it is beneficial to leverage partial information about the entities that are involved in an event to extract missing information. In this paper, we introduce the LOAD model for cross-document event extraction in large-scale document collections. The graph-based model relies on co-occurrences of named entities belonging to the classes locations, organizations, actors, and dates and puts them in the context of surrounding terms. As such, the model allows for efficient queries and can be updated incrementally in negligible time to reflect changes to the underlying document collection. We discuss the versatility of this approach for event summarization, the completion of partial event information, and the extraction of descriptions for named entities and dates. We create and provide a LOAD graph for the documents in the English Wikipedia from named entities extracted by state-of-the-art NER tools. Based on an evaluation set of historic data that include summaries of diverse events, we evaluate the resulting graph. We find that the model not only allows for near real-time retrieval of information from the underlying document collection, but also provides a comprehensive framework for browsing and summarizing event data.", "references": ["A. Abujabal and K. Berberich. Important events in the past, present, and future. In WWW, 2015.", "B. Adams, G. McKenzie, and M. Gahegan. Frankenplace: Interactive thematic mapping for ad hoc exploratory search. In WWW, 2015.", "O. Alonso and K. Shiells. Timelines as summaries of popular scheduled events. In TempWeb, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911529"}, {"title": "Third International Workshop on Gamification for Information Retrieval (GamifIR'16)", "authors": ["Michael Meder\n,", "Frank Hopfgartner\n,", "Gabriella Kazai\n,", "Udo Kruschwitz"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nStronger engagement and greater participation is often crucial to reach a goal or to solve an issue. Issues like the emerging employee engagement crisis, insufficient knowledge sharing, and chronic procrastination. In many cases we need and search for tools to beat procrastination or to change people's habits. Gamification is the approach to learn from often fun, creative and engaging games. In principle, it is about understanding games and applying game design elements in a non-gaming environments. This offers possibilities for wide area improvements. For example more accurate work, better retention rates and more cost effective solutions by relating motivations for participating as more intrinsic than conventional methods. In the context of Information Retrieval (IR) it is not hard to imagine that many tasks could benefit from gamification techniques. Besides several manual annotation tasks of data sets for IR research, user participation is important in order to gather implicit or even explicit feedback to feed the algorithms. Gamification, however, comes with its own challenges and its adoption in IR is still in its infancy. Given the enormous response to the first and second GamifIR workshops that were both co-located with ECIR, and the broad range of topics discussed, we now organized the third workshop at SIGIR 2016 to address a range of emerging challenges and opportunities.", "references": ["S. Deterding, D. Dixon, R. Khaled, and L. Nacke. From game design elements to gamefulness: defining gamification. Proceeding of the 15th International Academic MindTrek Conference, pages 9--15, 2011.", "J. Hamari, J. Koivisto, and H. Sarsa. Does gamification work? - a literature review of empirical studies on gamification. In proceedings of the 47th Hawaii International Conference on System Sciences, 2014.", "F. Hopfgartner, G. Kazai, U. Kruschwitz, and M. Meder, editors. GamifIR '14: Proceedings of the First International Workshop on Gamification for Information Retrieval, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917759"}, {"title": "Generalizing Translation Models in the Probabilistic Relevance Framework", "authors": ["Navid Rekabsaz\n,", "Mihai Lupu\n,", "Allan Hanbury\n,", "Guido Zuccon"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA recurring question in information retrieval is whether term associations can be properly integrated in traditional information retrieval models while preserving their robustness and effectiveness. In this paper, we revisit a wide spectrum of existing models (Pivoted Document Normalization, BM25, BM25 Verboseness Aware, Multi-Aspect TF, and Language Modelling) by introducing a generalisation of the idea of the translation model. This generalisation is a de facto transformation of the translation models from Language Modelling to the probabilistic models. In doing so, we observe a potential limitation of these generalised translation models: they only affect the term frequency based components of all the models, ignoring changes in document and collection statistics. We correct this limitation by extending the translation models with the 15 statistics of term associations and provide extensive experimental results to demonstrate the benefit of the newly proposed methods. Additionally, we compare the translation models with query expansion methods based on the same term association resources, as well as based on Pseudo-Relevance Feedback (PRF). We observe that translation models always outperform the first, but provide complementary information with the second, such that by using PRF and our translation models together we observe results better than the current state of the art.", "references": ["G. Amati, C. Carpineto, G. Romano, and F. U. Bordoni. Query difficulty, robustness, and selective application of query expansion. In Proc. of ECIR, 2004.", "G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. TOIS, 2002.", "A. Berger and J. Lafferty. Information Retrieval As Statistical Translation. In Proc. of SIGIR, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983833"}, {"title": "Improving Search Results with Prior Similar Queries", "authors": ["Yashar Moshfeghi\n,", "Kristiyan Velinov\n,", "Peter Triantafillou"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper describes a novel approach to re-ranking search engine result pages (SERP): Its fundamental principle is to re-rank results to a given query, based on exploiting evidence gathered from past similar search queries. Our approach is inspired by collaborative filtering, with the main challenge being to find the set of similar queries, while also taking efficiency into account. In particular, our approach aims to address this challenge by proposing a combination of a similarity graph and a locality sensitive hashing scheme. We construct a set of features from our similarity graph and build a prediction model using the Hoeffding decision tree algorithm. We have evaluated the effectiveness of our model in terms of P@1, MAP@10, and nDCG@10, using the Yandex Data Challenge data set. We have compared the performance of our model against two baselines, namely, the Yandex initial ranking and the decision tree model learnt on the same set of features when extracted based on query repetition (i.e. excluding the evidence of similar queries in our approach). Our results reveal that the proposed approach consistently and (statistically) significantly outperforms both baselines.", "references": ["R. Baeza-Yates. Graphs from Search Engine Queries. In SOFSEM '07, pages 1--8, 2007.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query Recommendation using Query Logs in Search Engines. In Current Trends in Database Technology-EDBT' 04 Workshops, pages 588--596, 2004.", "D. Beeferman and A. Berger. Agglomerative Clustering of a Search Engine Query Log. In KDD '00, pages 407--416, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983890"}, {"title": "Error prooving and sensorimotor feedback for singing voice", "authors": ["K. Kokkinidis\n,", "A. Stergiaki\n,", "A. Tsagaris"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nThis paper presents a sensorimotor system for Byzantine Music. The main goal of this research is to detect some pre-defined errors in singing performance. After error-detection, the system uses a pre-defined error-dictionary in order to feedback. Through these feedbacks the potential chanter is being able to correct his performance. The system is being trained via experts MFCC features from a corpus of anthems. The recognition also takes place via MFCC but form student. The developed system is being able to evaluate in real time the pitch distance and furthermore the duration of two musician's performances, expert and student. The system may also evaluate the distance between two sequential musical gestures by which we may find the tempo of the hymn. After the pitch of these two hymns are being compared any identified errors will cause a feedback action to the student. This feedback corresponds to an error dictionary.", "references": ["A. Potamianos and P. Maragos. Speech formant frequency and bandwidth tracking using multiband energy demodulation. Journal of Acoustical Society of America, 99:3795--3806, June 1996.", "S. Davis and P. Mermelstein. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Transactions on Acoustics, Speech and Signal Processing, 28(4):357--366, August 1980.", "M. B. Siafarikas, Speaker and speech recognition with the use of wavelets. Phd thesis, June 2015, nemertes.lis.upatras.gr"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948952"}, {"title": "Improving performance and lifetime of NAND storage systems using relaxed program sequence", "authors": ["Jisung Park\n,", "Jaeyong Jeong\n,", "Sungjin Lee\n,", "Youngsun Song\n,", "Jihong Kim"], "publication": "DAC '16: Proceedings of the 53rd Annual Design Automation Conference", "abstract": "ABSTRACT\nWe propose a new system-level solution that improves both the performance and lifetime of NAND storage systems by exploiting the performance asymmetry of NAND devices. At the device level, we propose a new program sequence, called relaxed program sequence (RPS), which allows more flexible page allocations in a block without compromising NAND reliability. By combining RPS with per-block parity pages, we can improve the write bandwidth and eliminate expensive paired page backup operations. Experimental results show that the proposed technique can increase IOPS by up to 56% and reduce the number of block erasures by up to 30% over an existing RPS-oblivious FTL.", "references": ["G. Naso et al. A 128Gb 3b/Cell NAND Flash Design Using 20nm Planar-Cell Technology. In Proc. IEEE Int. Solid-State Circuits Conf., 2013.", "C. Kim et al. A 21 nm High Performance 64 Gb MLC NAND Flash Memory with 400 MB/s Asynchronous Toggle DDR Interface. IEEE J. Solid-State Circuits, 47(4):981--989, 2012.", "H.-W. Tseng et al. Understanding the Impact of Power Loss on Flash Memory. In Proc. Design Automation Conf., 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897937.2898032"}, {"title": "HubPPR: effective indexing for approximate personalized pagerank", "authors": ["Sibo Wang\n,", "Youze Tang\n,", "Xiaokui Xiao\n,", "Yin Yang\n,", "Zengxiang Li"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nPersonalized PageRank (PPR) computation is a fundamental operation in web search, social networks, and graph analysis. Given a graph G, a source s, and a target t, the PPR query Π(s, t) returns the probability that a random walk on G starting from s terminates at t. Unlike global PageRank which can be effectively pre-computed and materialized, the PPR result depends on both the source and the target, rendering results materialization infeasible for large graphs. Existing indexing techniques have rather limited effectiveness; in fact, the current state-of-the-art solution, BiPPR, answers individual PPR queries without pre-computation or indexing, and yet it outperforms all previous index-based solutions.\nMotivated by this, we propose HubPPR, an effective indexing scheme for PPR computation with controllable tradeoffs for accuracy, query time, and memory consumption. The main idea is to pre-compute and index auxiliary information for selected hub nodes that are often involved in PPR processing. Going one step further, we extend HubPPR to answer top-k PPR queries, which returns the k nodes with the highest PPR values with respect to a source s, among a given set T of target nodes. Extensive experiments demonstrate that compared to the current best solution BiPPR, HubPPR achieves up to 10x and 220x speedup for PPR and top-k PPR processing, respectively, with moderate memory consumption. Notably, with a single commodity server, HubPPR answers a top-k PPR query in seconds on graphs with billions of edges, with high accuracy and strong result quality guarantees.", "references": ["https://sites.google.com/site/hubpprtr2016/.", "http://snap.stanford.edu/data.", "R. Andersen, C. Borgs, J. T. Chayes, J. E. Hopcroft, V. S. Mirrokni, and S. Teng. Local computation of pagerank contributions. In WAW, pages 150--165, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3021924.3021936"}, {"title": "A DNA-Based Archival Storage System", "authors": ["James Bornholt\n,", "Randolph Lopez\n,", "Douglas M. Carmean\n,", "Luis Ceze\n,", "Georg Seelig\n,", "Karin Strauss"], "publication": "ASPLOS '16: Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems", "abstract": "ABSTRACT\nDemand for data storage is growing exponentially, but the capacity of existing storage media is not keeping up. Using DNA to archive data is an attractive possibility because it is extremely dense, with a raw limit of 1 exabyte/mm3 (109 GB/mm3), and long-lasting, with observed half-life of over 500 years. This paper presents an architecture for a DNA-based archival storage system. It is structured as a key-value store, and leverages common biochemical techniques to provide random access. We also propose a new encoding scheme that offers controllable redundancy, trading off reliability for density. We demonstrate feasibility, random access, and robustness of the proposed encoding with wet lab experiments involving 151 kB of synthesized DNA and a 42 kB random-access subset, and simulation experiments of larger sets calibrated to the wet lab experiments. Finally, we highlight trends in biotechnology that indicate the impending practicality of DNA storage for much larger datasets.", "references": ["L. Adleman. Molecular computation of solutions to combinatorial problems. Science, 266 (5187): 1021--1024, 1994.", "M. E. Allentoft, M. Collins, D. Harker, J. Haile, C. L. Oskam, M. L. Hale, P. F. Campos, J. A. Samaniego, M. T. P. Gilbert, E. Willerslev, G. Zhang, R. P. Scofield, R. N. Holdaway, and M. Bunce. The half-life of DNA in bone: measuring decay kinetics in 158 dated fossils. Proceedings of the Royal Society of London B: Biological Sciences, 279 (1748): 4724--4733, 2012.", "C. Bancroft, T. Bowler, B. Bloom, and C. T. Clelland. Long-term storage of information in DNA. Science, 293 (5536): 1763--1765, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872362.2872397"}, {"title": "Personal Information Manager to Capture and Re-Access What We See on Computers", "authors": ["Zaher Hinbarji\n,", "Moohamad Hinbarji\n,", "Rami Albatal\n,", "Cathal Gurrin"], "publication": "LTA '16: Proceedings of the first Workshop on Lifelogging Tools and Applications", "abstract": "ABSTRACT\nNowadays we live in a world where many of us engage with computers more than humans as a result of spending a major part of our life in front of a range of computing devices. Consequently, it's becoming important to shed more light on our interactions with computing devices, which we see as a special domain of lifelogging (information-lifelogging), where capturing and archiving what we see on our computer screens can be utilised for several useful applications such as user profiling, personalization and memory support. In this work, we present a tool that allows us to passively capture the digital content we see on our screens for later re-access. It can be considered as a type of digital memory that stores user's computer usage to recall a user's information creation and access activities. This has potential to assist users to better achieve their daily tasks by having access to a digital backup where their previous content and experience can be recalled as required.", "references": ["A. Cockburn and S. Greenberg. Issues of page representation and organisation in web browser's revisitation tools. Australasian Journal of Information Systems, 7(2), 2000.", "J. Gemmell, G. Bell, R. Lueder, S. Drucker, and C. Wong. Mylifebits: Fulfilling the memex vision. In Proceedings of the Tenth ACM International Conference on Multimedia, pages 235--238, New York, NY, USA, 2002. ACM.", "C. Gurrin, R. Albatal, H. Joho, and K. Ishii. A privacy by design approach to lifelogging. In O Hara, K. and Nguyen, C. and Haynes, P., (eds.) Digital Enlightenment Yearbook 2014, pages 49--73. IOS Press, The Netherlands, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983576.2983580"}, {"title": "A Test Collection for Matching Patients to Clinical Trials", "authors": ["Bevan Koopman\n,", "Guido Zuccon"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present a test collection to study the use of search engines for matching eligible patients (the query) to clinical trials (the document). Clinical trials are experiments conducted in the development of new medical treatments, drugs or devices. Recruiting candidates for a trial is often a time-consuming and resource intensive effort, and imposes delays or even the cancellation of trials.\nThe collection described in this paper provides: i) a large corpus of clinical trials; ii) 60 patient case reports used as topics; iii) multiple query representations for a single topic (long, short and ad-hoc); iv) a user provided estimate of how many trials they expect each patient topic would be eligible for; and v) relevance assessments by medical professionals. The availability of such a collection allows researchers to investigate, among other questions: i) the effectiveness of retrieval methods for this task, ii) how multiple representations of an information affect retrieval iii) what influences relevance assessments in this context, iv) whether automated matching of patients to trials improves patient recruitment. The collection is available at http://doi.org/10.4225/08/5714557510C17.", "references": ["C. Buckley and J. A. Walz. The TREC-8 Query Track. In TREC, 1999.", "B. Koopman and G. Zuccon. Relevation!: An open source system for information retrieval relevance assessment. In SIGIR, Gold Coast, Australia, July 2014.", "B. Koopman and G. Zuccon. Why assessing relevance in medical IR is demanding. In MedIR at SIGIR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914672"}, {"title": "Towards an Integration System for Artifact-centric Processes", "authors": ["Maroun Abi Assaf"], "publication": "SIGMOD'16 PhD: Proceedings of the 2016 on SIGMOD'16 PhD Symposium", "abstract": "ABSTRACT\nThe last few years have seen a growing interest in the artifact-centric process modeling approach across database and business process management communities. Artifact-centric processes not only unify databases and how data tuples are processed through their lifecycles but they also provide business people with a paradigm to easily express the way business activities should evolve towards achieving business goals. This PhD thesis focuses on integrating heterogeneous artifacts from different sources in order to provide unified views for managing them. Since artifacts are complex entities composed of information models, state-based lifecycles, tasks and business rules, their integration poses a challenge and requires combining several approaches from different domains like data integration and business process merging. In this paper, we propose a design for an artifact-centric process integration system, in addition to a graphical artifact modeling notation, and an artifact query language that support the artifact integration.", "references": ["M. Abi Assaf, Y. Badr, K. Barbar, and Y. Amghar. On the Integration of Artifact Lifecycles. In Proceedings of the 7th International Conference on Management of Computational and Collective Intelligence in Digital Ecosystems. ACM, 59--63, 2015.", "K. Bhattacharya, C. Gerede, R. Hull, R. Liu, and J. Su. Towards Formal Analysis of Artifact-Centric Business Process Models. Business Process Management. Springer Berlin Heidelberg, 288--304, 2007.", "D. Calvanese, G. De Giacomo, R. Hull, and J. Su. Artifact-Centric Workflow Dominance. In Service-Oriented Computing, Springer Berlin Heidelberg, 130--143, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926693.2929904"}, {"title": "Context & Semantics in News & Web Search", "authors": ["Daan Odijk"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThis thesis presents research towards a core aim of information retrieval (IR): providing users with easy access to information. Three research themes guide the research presented in this thesis, contributing to three aspects of IR research: the domain in which an IR system is used, the users interacting with the system, and the different access scenarios in which these users engage with an IR system. Central to these research themes is the aim to gain insights into the behavior of searchers and develop algorithms to support them in their quest, whether it is a researcher exploring or studying a large collection, a web searcher struggling to find something, or a television viewer searching for related content.\nThe first research theme is motivated by the information seeking tasks of researchers exploring and studying large collections. To enable their search on a larger scale, we propose computational methods to connect collections and to infer the perspective offered in a news story. Motivated by how historians select documents for close reading, we propose novel methods for connecting collections using automatically extracted temporal references. To illustrate how these algorithms can be used to automatically create connections between collections, we introduce a novel search interface to explore and analyze the connected collections. The interface highlights different perspectives and requires little domain knowledge. Based on how communication scientists study framing in news, we propose an automatic thematic content analysis approach.\nThe second research theme is addressed in a mixed-methods study on how web searchers behave when they cannot find what they are looking for. Based on large-scale log analysis, crowd-sourced labeling, and predictive modeling we show behavioral differences given task success and failure. Based on these findings we propose ways in which systems can reduce struggling in search. To support searchers, we propose and evaluate algorithms that accurately predict the nature of future actions and their anticipated impact on search outcomes. Our findings have implications for the design of search systems that help searchers struggle less and succeed more.\nIn the third and final research theme, we consider a pro-active search scenario, specifically in a live television setting. We propose algorithms that leverage contextual information to retrieve diverse related content for a leaned-back TV viewer. While watching television, people increasingly consume additional content related to what they are watching. Two methods to automatically retrieve content based on subtitles are introduced, one using entity linking, and one that uses reinforcement learning to generate effective queries for finding related content. Both methods are highly efficient and are currently used in a live television setting in near real time.\nEach research chapter in this thesis provides insights and algorithms that help searchers when using IR applications. For varying domains, users, and access scenarios, the research presented in this thesis improves the ease of access to information.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964816"}, {"title": "SimRank and its variants in academic literature data: measures and evaluation", "authors": ["Masoud Reyhani Hamedani\n,", "Sang-Wook Kim"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nSimRank is a well-known link-based similarity measure that can be applied on a citation graph to compute similarity of academic literature data. The intuition behind SimRank is that two objects are similar if they are referenced by similar objects. SimRank has attracted a growing interest in the areas of data mining and information retrieval recently. Despite of the current success of SimRank, it has some problems that negatively affect its effectiveness in similarity computation. In this paper, we discuss the three existing problems of SimRank, present SimRank variants that have been proposed to solve those problems, and evaluate the effectiveness of SimRank and its variants in similarity computation for academic literature data by conducting extensive experiments on a real-world dataset.", "references": ["I. Antonellis, H. G. Molina, and C. C. Chang. Simrank++: Query Rewriting Through Link Analysis of the Click Graph. PVLDB, 1(1):408--421, 2008.", "Y. Cai, P. Li, H. Liu, J. He, and X. Du. S-SimRank: Combining Content and Link Information to Cluster Papers Effectively and Efficiently. In Lecture Notes in Computer Science, pages 317--329, 2008.", "D. Fogaras and B. Racz. Scaling Link-based Similarity Search. In WWW, pages 641--650, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851811"}, {"title": "Direct measurement of training query quality for learning to rank", "authors": ["Qingli Ma\n,", "Ben He\n,", "Jungang Xu"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe conventional application of learning to rank algorithms tends to use as many training queries as possible to leverage the benefit brought by a large amount of labeled data. However, the use of all training queries available may also include the low quality ones, and consequently, degrades the retrieval effectiveness, hence the need for selecting training queries. Existing training query selection approaches incorporate a variety of indirect indicators of the training queries such as the query performance predictors and the relevance scores into a classification or regression based approach. In this paper, we propose to select training queries by the direct measurement of the training query quality, namely the resulting retrieval performance on a subset of validation queries, instead of the indirect indicators that may not have strong correlations with a training query's quality. Evaluation on the standard LETOR 4.0 dataset shows that our proposed approach outperforms the state-of-the-art baselines.", "references": ["Javed A. Aslam, Evangelos Kanoulas, Virgil Pavlu, Stefan Savev, and Emine Yilmaz. Document selection methodologies for efficient and effective learning-to-rank. In Proc, SIGIR '09, pages 468--475, New York, NY, USA, 2009. ACM.", "Ricardo A. Baeza-Yates and Berthier Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "Mustafa Bilgic and Paul N. Bennett. Active query selection for learning rankers. In Poster-Paper in Proc ACM, August 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851693"}, {"title": "Privacy Preserving Disease Treatment & Complication Prediction System (PDTCPS)", "authors": ["Qinghan Xue\n,", "Mooi Choo Chuah\n,", "Yingying Chen"], "publication": "ASIA CCS '16: Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security", "abstract": "ABSTRACT\nAffordable cloud computing technologies allow users to efficiently store, and manage their Personal Health Records (PHRs) and share with their caregivers or physicians. This in turn improves the quality of healthcare services, and lower health care cost. However, serious security and privacy concerns emerge because people upload their personal information and PHRs to the public cloud. Data encryption provides privacy protection of medical information but it is challenging to utilize encrypted data. In this paper, we present a privacy-preserving disease treatment, complication prediction scheme (PDTCPS), which allows authorized users to conduct searches for disease diagnosis, personalized treatments, and prediction of potential complications. $PDTCPS$ uses a tree-based structure to boost search efficiency, a wildcard approach to support fuzzy keyword search, and a Bloom-filter to improve search accuracy and storage efficiency. In addition, our design also allows health care providers and the public cloud to collectively generate aggregated training models for disease diagnosis, personalized treatments and complications prediction. Moreover, our design provides query unlinkability and hides both search & access patterns. Finally, our evaluation results using two UCI datasets show that our scheme is more efficient and accurate than two existing schemes.", "references": ["Patientslikeme, https://www.patientslikeme.com/.", "NHIN, http://www.hhs.gov/healthit/healthnetwork.", "UCI Machine Learning Repository, https://archive.ics.uci.edu/ml/datasets.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897845.2897893"}, {"title": "Deepening the Role of the User: Neuro-Physiological Evidence as a Basis for Studying and Improving Search", "authors": ["Javed Mostafa\n,", "Jacek Gwizdka"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nIn this paper, the potential for expanding the set of scientific evidence and insights associated with the users' role during the search process is explored. As it is intended to be a position paper and not a systematic survey, a comprehensive review of literature is not presented here. However, the authors draw on some early stage research, in this emerging area, to describe and explain the generation of neuro-physiological evidence using three types of modalities. The modalities and the associated methods described here, presented in order of increasing complexity, include Eye-tracking, EEG, and fMRI. The paper concludes with a few critical observations regarding the promises and perils of using neuro-physiological approaches in studying search and search behavior.", "references": ["Ajanki, A. et al. 2009. Can eyes reveal interest? Implicit queries from gaze patterns. User Modeling and User-Adapted Interaction. 19, 4 (2009), 307--339.", "Ajanki, A. 2013. Inference of relevance for proactive information retrieval. (2013).", "Allegretti, M. et al. 2015. When Relevance Judgement is Happening?: An EEG-based Study. Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (New York, NY, USA, 2015), 719--722."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854979"}, {"title": "Ensemble Learned Vaccination Uptake Prediction using Web Search Queries", "authors": ["Niels Dalum Hansen\n,", "Christina Lioma\n,", "Kåre Mølbak"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe present a method that uses ensemble learning to combine clinical and web-mined time-series data in order to predict future vaccination uptake. The clinical data is official vaccination registries, and the web data is query frequencies collected from Google Trends. Experiments with official vaccine records show that our method predicts vaccination uptake effectively (4.7 Root Mean Squared Error). Whereas performance is best when combining clinical and web data, using solely web data yields comparative performance. To our knowledge, this is the first study to predict vaccination uptake using web data (with and without clinical data).", "references": ["E. H. Chan, V. Sahai, C. Conrad, and J. S. Brownstein. Using web search query data to monitor dengue epidemics: A new model for neglected tropical disease surveillance. PLoS Negl Trop Dis, 5(5):e1206, 2011.", "C. Chatfield. The analysis of time series: An introduction. CRC press, 2013.", "R. Chunara, J. R. Andrews, and J. S. Brownstein. Social and news media enable estimation of epidemiological patterns early in the 2010 Haitian cholera outbreak. The American Journal of Tropical Medicine and Hygiene, 86(1):39--45, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983882"}, {"title": "DBtrends: Exploring Query Logs for Ranking RDF Data", "authors": ["Edgard Marx\n,", "Amrapali Zaveri\n,", "Diego Moussallem\n,", "Sandro Rautenberg"], "publication": "SEMANTiCS 2016: Proceedings of the 12th International Conference on Semantic Systems", "abstract": "ABSTRACT\nMany ranking methods have been proposed for RDF data. These methods often use the structure behind the data to measure its importance. Recently, some of these methods have started to explore information from other sources such as the Wikipedia page graph for better ranking RDF data. In this work, we propose DBtrends, a ranking function based on query logs. We extensively evaluate the application of different ranking functions for entities, classes, and properties across two different countries as well as their combination. Thereafter, we propose MIXED-RANK, a ranking function that combines DBtrends with the best-evaluated entity ranking function. We show that: (i) MIXED-RANK outperforms state-of-the-art entity ranking functions, and; (ii) query logs can be used to improve RDF ranking functions.", "references": ["M. Alsarem, P.-E. Portier, S. Calabretto, and H. Kosch. Ranking entities in the age of two webs, an application to semantic snippets. In The Semantic Web. Latest Advances and New Domains, volume 9088 of Lecture Notes in Computer Science, pages 541--555. Springer International Publishing, 2015.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In Proceedings of the Seventh International Conference on World Wide Web 7, WWW7, pages 107--117, Amsterdam, The Netherlands, The Netherlands, 1998. Elsevier Science Publishers B. V.", "G. Cheng, T. Tran, and Y. Qu. RELIN: Relatedness and Informativeness-based Centrality for Entity Summarization. In Proceedings of the 10th International Conference on The Semantic Web -Volume Part I, ISWC'11, pages 114--129, Berlin, Heidelberg, 2011. Springer-Verlag."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993318.2993322"}, {"title": "Evaluation and Comparison of Entity based search Implied by SVM and Neural Network", "authors": ["Anant Kumar Malani\n,", "Mukesh Kumar"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nWith the increasing amounts of data generated in the cyber world the need for an efficient and robust technique has been felt. Keyword based search provides a solution for the problems mentioned before. Keyword search has been proven an effective information discovery method for unstructured data (e.g. textual documents), semi-structured data (e.g. XML databases), and structured data (e.g. relational databases). The power of keyword based search lies in the fact that the user needs not to know the working and technicalities of the data structure in which the data has been stored. This paper discusses the differences between two types of search engine i.e. Entity based search engine and keyword based search engine. Then the paper goes on and discusses the working and disadvantages of the two.", "references": ["D. Tumer, M. A. Shah and Y. Bitirim \"An Empirical Evaluation on Semantic Search Performance of Keyword-Based and Semantic Search Engines: Google, Yahoo, Msn and Hakia,\" Fourth International Conference on Internet Monitoring and Protection, pp. 51--55, May 2009.", "M. Tang and Y. Sun, \"Evaluation of Web-Based Search Engines Using User Effort Measures,\" Library and Information Science Research Electronic Journal 13(2), 2003.", "M. Andago, P.L Phoebe and A. M Thanoun, \"Evaluation of a SemanticSearch Engine against a Keyword Search Engine Using First 20 Precision,\" In Proceedings of the 29th Annual International Conference on Research and Development in Information Retrieval, ACM Press, pp. 735--746, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905153"}, {"title": "Investigating Multimodal Audiovisual Event Detection and Localization", "authors": ["N. Vryzas\n,", "R. Kotsakis\n,", "C. A. Dimoulas\n,", "G. Kalliris"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nThe current paper investigates a multisensory speaker tracking approach, combining sound localization with visual object detection and tracking. The sound localization module estimates the position of the speaker whenever a new spatial audio event is detected (i.e. sound source position /speaker alteration). Besides localization, spatial audio events can be detected /verified through various decision-making systems utilizing multichannel audio features. Visual object detection and tracking is also considered, either in parallel with the sound system or subsequently, after the initial sound localization. The case scenario examined in this paper consists of energy-based sound localization using a core cross-shaped coincident microphone array combined with state of the art machine vision, such as the OpenCV face detection pre-trained classifiers and the Open Tracking and Learning Detection (openTLD) framework. A modular multi-sensory architecture is involved, allowing microphone array(s) to be combined with multi-camera sequences and other signals (i.e. depth /motion imaging). The proposed approach is presented and demonstrated in focused real-world scenarios (i.e. cultural /theatrical shows capturing and live-streaming, meetings and press-conferences, recording and broadcast of video lectures, teleconferences, etc.).", "references": ["Stowell, D., Giannoulis, D., Benetos, E., Lagrange, M., Plumbley, M.D. 2015. Detection and Classification of Acoustic Scenes and Events. IEEE Trans. Multimedia. 17, 10 (Oct. 2015), 1733--1746.", "Dimoulas, C., Symeonidis, A. 2015. Syncing Shared Multimedia through Audiovisual Bimodal Segmentation, IEEE MultiMedia. 22,3. 26-42, DOI:10.1109/MMUL.2015.33 2015.", "Popescu-Belis, A., Lalanne, D., Bourlard, H. 2012. Finding information in multimedia meeting records. IEEE Multimedia. 19, 2 (2012), 48--57."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986426"}, {"title": "A Novel Evidence-Based Bayesian Similarity Measure for Recommender Systems", "authors": ["Guibing Guo\n,", "Jie Zhang\n,", "Neil Yorke-Smith"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nUser-based collaborative filtering, a widely used nearest neighbour-based recommendation technique, predicts an item’s rating by aggregating its ratings from similar users. User similarity is traditionally calculated by cosine similarity or the Pearson correlation coefficient. However, both of these measures consider only the direction of rating vectors, and suffer from a range of drawbacks. To overcome these issues, we propose a novel Bayesian similarity measure based on the Dirichlet distribution, taking into consideration both the direction and length of rating vectors. We posit that not all the rating pairs should be equally counted in order to accurately model user correlation. Three different evidence factors are designed to compute the weights of rating pairs. Further, our principled method reduces correlation due to chance and potential system bias. Experimental results on six real-world datasets show that our method achieves superior accuracy in comparison with counterparts.", "references": ["G. Adomavicius and J. Zhang. 2012. Impact of data characteristics on recommender systems performance. ACM Transactions on Management Information Systems 3, 1, 3.", "H. J. Ahn. 2008. A new similarity measure for collaborative filtering to alleviate the new user cold-starting problem. Information Sciences 178, 1, 37--51.", "A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec. 2012. Effects of user similarity in social media. In Proceedings of the 5th ACM International Conference on Web Search and Data Mining (WSDM’12). 703--712."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856037"}, {"title": "Semantic SPARQL similarity search over RDF knowledge graphs", "authors": ["Weiguo Zheng\n,", "Lei Zou\n,", "Wei Peng\n,", "Xifeng Yan\n,", "Shaoxu Song\n,", "Dongyan Zhao"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nRDF knowledge graphs have attracted increasing attentions these years. However, due to the schema-free nature of RDF data, it is very difficult for users to have full knowledge of the underlying schema. Furthermore, the same kind of information can be represented in diverse graph fragments. Hence, it is a huge challenge to formulate complex SPARQL expressions by taking the union of all possible structures.\nIn this paper, we propose an effective framework to access the RDF repository even if users have no full knowledge of the underlying schema. Specifically, given a SPARQL query, the system could return as more answers that match the query based on the semantic similarity as possible. Interestingly, we propose a systematic method to mine diverse semantically equivalent structure patterns. More importantly, incorporating both structural and semantic similarities we are the first to propose a novel similarity measure, semantic graph edit distance. In order to improve the efficiency performance, we apply the semantic summary graph to summarize the knowledge graph, which supports both high-level pruning and drill-down pruning. We also devise an effective lower bound based on the TA-style access to each of the candidate sets. Extensive experiments over real datasets confirm the effectiveness and efficiency of our approach.", "references": ["R. Angles and C. Gutiérrez. Querying RDF data from a graph database perspective. In ESWC, 2005.", "J. Cheng, X. Zeng, and J. X. Yu. Top-k graph pattern matching over large graphs. In ICDE, 2013.", "A. Fader, S. Soderland, and O. Etzioni. Identifying relations for open information extraction. In EMNLP, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2983200.2983201"}, {"title": "Session details: Volume I: Artificial intelligence and agents, distributed systems, and information systems: Information access and retrieval track", "authors": ["Gabriella Pasi\n,", "Gloria Bordogna"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252794"}, {"title": "Decoupling light reflex from pupillary dilation to measure emotional arousal in videos", "authors": ["Pallavi Raiturkar\n,", "Andrea Kleinsmith\n,", "Andreas Keil\n,", "Arunava Banerjee\n,", "Eakta Jain"], "publication": "SAP '16: Proceedings of the ACM Symposium on Applied Perception", "abstract": "ABSTRACT\nPredicting the exciting portions of a video is a widely relevant problem because of applications such as video summarization, searching for similar videos, and recommending videos to users. Researchers have proposed the use of physiological indices such as pupillary dilation as a measure of emotional arousal. The key problem with using the pupil to measure emotional arousal is accounting for pupillary response to brightness changes. We propose a linear model of pupillary light reflex to predict the pupil diameter of a viewer based only on incident light intensity. The residual between the measured pupillary diameter and the model prediction is attributed to the emotional arousal corresponding to that scene. We evaluate the effectiveness of this method of factoring out pupillary light reflex for the particular application of video summarization. The residual is converted into an exciting-ness score for each frame of a video. We show results on a variety of videos, and compare against ground truth as reported by three independent coders.", "references": ["Arapakis, I., Konstas, I., and Jose, J. M. 2009. Using facial expressions and peripheral physiological signals as implicit indicators of topical relevance. In ACM International Conference on Multimedia (MM), 461--470.", "Bailey, B. P., and Iqbal, S. T. 2008. Understanding changes in mental workload during execution of goal-directed tasks and its application for interruption management. ACM Transactions on Computer-Human Interaction (TOCHI) 14, 4, 21.", "Bradley, M. M., Miccoli, L., Escrig, M. A., and Lang, P. J. 2008. The pupil as a measure of emotional arousal and autonomic activation. Psychophysiology 45, 4, 602--607."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2931002.2931009"}, {"title": "Mining User Intentions from Medical Queries: A Neural Network Based Heterogeneous Jointly Modeling Approach", "authors": ["Chenwei Zhang\n,", "Wei Fan\n,", "Nan Du\n,", "Philip S. Yu"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nText queries are naturally encoded with user intentions. An intention detection task tries to model and discover intentions that user encoded in text queries. Unlike conventional text classification tasks where the label of text is highly correlated with some topic-specific words, words from different topic categories tend to co-occur in medical related queries. Besides the existence of topic-specific words and word order, word correlations and the way words organized into sentence are crucial to intention detection tasks.\nIn this paper, we present a neural network based jointly modeling approach to model and capture user intentions in medical related text queries. Regardless of the exact words in text queries, the proposed method incorporates two types of heterogeneous information: 1) pairwise word feature correlations and 2) part-of-speech tags of a sentence to jointly model user intentions. Variable-length text queries are first inherently taken care of by a fixed-size pairwise feature correlation matrix. Moreover, convolution and pooling operations are applied on feature correlations to fully exploit latent semantic structure within the query. Sentence rephrasing is finally introduced as a data augmentation technique to improve model generalization ability during model training. Experiment results on real world medical queries have shown that the proposed method is able to extract complete and precise user intentions from text queries.", "references": ["James F Allen and C Raymond Perrault. Analyzing intention in utterances. Artificial intelligence, 15(3):143--178, 1980.", "Yiming Yang and Xin Liu. A re-examination of text categorization methods. In SIGIR, 1999.", "Charu C Aggarwal and ChengXiang Zhai. Mining text data. Springer Science & Business Media, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2874810"}, {"title": "Relationship Queries on Extended Knowledge Graphs", "authors": ["Mohamed Yahya\n,", "Denilson Barbosa\n,", "Klaus Berberich\n,", "Qiuyue Wang\n,", "Gerhard Weikum"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nEntity search over text corpora is not geared for relationship queries where answers are tuples of related entities and where a query often requires joining cues from multiple documents. With large knowledge graphs, structured querying on their relational facts is an alternative, but often suffers from poor recall because of mismatches between user queries and the knowledge graph or because of weakly populated relations.\nThis paper presents the TriniT search engine for querying and ranking on extended knowledge graphs that combine relational facts with textual web contents. Our query language is designed on the paradigm of SPO triple patterns, but is more expressive, supporting textual phrases for each of the SPO arguments. We present a model for automatic query relaxation to compensate for mismatches between the data and a user's query. Query answers -- tuples of entities -- are ranked by a statistical language model. We present experiments with different benchmarks, including complex relationship queries, over a combination of the Yago knowledge graph and the entity-annotated ClueWeb'09 corpus.", "references": ["S. Amer-Yahia, N. Koudas, A. Marian, D. Srivastava, D. Toman: Structure and Content Scoring for XML. VLDB 2005.", "K. Balog, M. Bron, M. de Rijke: Query Modeling for Entity Search Based on Terms, Categories, and Examples. TOIS 29(4), 2011.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, L. Si: Expertise Retrieval. Foundations and Trends in Information Retrieval 6(2--3), 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835795"}, {"title": "SOGOU-2012-CRAWL: A Crawl of Search Results in the Sogou 2012 Chinese Query Log", "authors": ["Stewart Whiting\n,", "Joemon M. Jose\n,", "Omar Alonso"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn 2012, Sogou, a major Chinese web search engine released a large-scale query log containing 43.5M user interactions, including submitted queries and clicked web page search results. This query log offers a deep sample of queries over a two day period from 30th December 2011 to 1st January 2012. In August 2013, we identified 1.4M predominantly Chinese language unique search result URLs that were clicked at least three times in this query log. We crawled the HTML content of these URLs to construct the supplementary SOGOU-2012-CRAWL dataset, which we release in this work. A real large-scale query log with accompanying crawl such as this offers several opportunities for reproducible information retrieval (IR) research, including query classification, intent modelling and indexing strategy. In this paper we first detail the query log and crawl dataset construction and characteristics. Following this, to demonstrate potential applications we use the crawl to indicatively analyse various time-based patterns in web content and search behaviour. In particular, we study the distribution of language-independent date expressions in the crawled web content. Based on this, we propose a simple approach for modelling the past/present/future temporal intent of queries based on the date the query was submitted by the user, and the dates appearing in the clicked search results. We observe several prominent temporal patterns which may lead to novel time-aware IR approaches.", "references": ["S. M. Beitzel, E. C. Jensen, A. Chowdhury, O. Frieder, and D. Grossman. Temporal analysis of a very large topically categorized web query log. J. Am. Soc. Inf. Sci. Technol., 58(2):166--178, January 2007.", "K. Berberich, S. Bedathur, O. Alonso, and G. Weikum. A language modeling approach for temporal information needs. ECIR'2010, pages 13--25, Berlin, Heidelberg, 2010. Springer-Verlag.", "N. Craswell, R. Jones, G. Dupret, and E. Viegas. Wscd '09: Proceedings of the 2009 workshop on web search click data. New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914668"}, {"title": "Transportation Mode Detection on Mobile Devices Using Recurrent Nets", "authors": ["Toan H. Vu\n,", "Le Dung\n,", "Jia-Ching Wang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present an approach to the use of Recurrent Neural Networks (RNN) for transportation mode detection (TMD) on mobile devices. The proposed model, called Control Gate-based Recurrent Neural Network (CGRNN), is an end-to-end model that works directly with raw signals from an embedded accelerometer. As mobile devices have limited computational resources, we evaluate the model in terms of accuracy, computational cost, and memory usage. Experiments on the HTC transportation mode dataset demonstrate that our proposed model not only exhibits remarkable accuracy, but also is efficient with low resource consumption.", "references": ["K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724--1734, 2014.", "J. Chung,c C. Gülc cehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. Technical Report Arxiv report 1412.3555, Université de Montréal, 2014. Presented at the Deep Learning workshop at NIPS2014.", "A. Graves, A.-R. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6645--6649, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967249"}, {"title": "Improving Language Estimation with the Paragraph Vector Model for Ad-hoc Retrieval", "authors": ["Qingyao Ai\n,", "Liu Yang\n,", "Jiafeng Guo\n,", "W. Bruce Croft"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIncorporating topic level estimation into language models has been shown to be beneficial for information retrieval (IR) models such as cluster-based retrieval and LDA-based document representation. Neural embedding models, such as paragraph vector (PV) models, on the other hand have shown their effectiveness and efficiency in learning semantic representations of documents and words in multiple Natural Language Processing (NLP) tasks. However, their effectiveness in information retrieval is mostly unknown. In this paper, we study how to effectively use the PV model to improve ad-hoc retrieval. We propose three major improvements over the original PV model to adapt it for the IR scenario: (1) we use a document frequency-based rather than the corpus frequency-based negative sampling strategy so that the importance of frequent words will not be suppressed excessively; (2) we introduce regularization over the document representation to prevent the model overfitting short documents along with the learning iterations; and (3) we employ a joint learning objective which considers both the document-word and word-context associations to produce better word probability estimation. By incorporating this enhanced PV model into the language modeling framework, we show that it can significantly outperform the state-of-the-art topic enhanced language models.", "references": ["A. M. Dai, C. Olah, Q. V. Le, and G. S. Corrado. Document embedding with paragraph vectors. In NIPS Deep Learning Workshop, 2014.", "D. Ganguly, D. Roy, M. Mitra, and G. J. Jones. Word embedding based generalized language model for information retrieval. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 795--798. ACM, 2015.", "S. Huston and W. B. Croft. A comparison of retrieval models using term dependencies. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 111--120. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914688"}, {"title": "Measuring Engagement with Online Forms", "authors": ["Paul Thomas\n,", "Heather O'Brien\n,", "Tom Rowlands"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nOnline form-filling and transactions are extremely common, both for industry and government; and it is important to provide a satisfying user experience during these tasks if customers or citizens are to continue using online channels. However, reliable measures of experience in these cases are limited. Other areas of information interaction, e.g., online search, news, and shopping, are increasingly exploring and attempting to measure the concept of user engagement (UE). In this study, we ask whether UE is an appropriate outcome for the utilitarian activities of online form-filling and transactions.\nWe describe work in progress which measures UE using the User Engagement Scale (UES) with utilitarian tasks, and which looks for behaviours which correlate with the UES. Early results suggest that, first, the UES can be adapted to such situations; and second, that readily observable user behaviours including time on site, mouse movements, and keypresses correlate with UES sub-scales and can, to some extent, predict users' responses.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behaviour information. In Proc. SIGIR, pages 19--26, August 2006.", "H. Akaike. A new look at the statistical model identification. IEEE Trans. Automatic Control, 19 (6): 716--723, 1974.", "I. Arapakis, M. Lalmas, and G. Valkanas. Understanding within-content engagement through pattern analysis of mouse gestures. In Proc. CIKM, pages 1439--1448, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854988"}, {"title": "Modeling Document Novelty with Neural Tensor Network for Search Result Diversification", "authors": ["Long Xia\n,", "Jun Xu\n,", "Yanyan Lan\n,", "Jiafeng Guo\n,", "Xueqi Cheng"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch result diversification has attracted considerable attention as a means to tackle the ambiguous or multi-faceted information needs of users. One of the key problems in search result diversification is novelty, that is, how to measure the novelty of a candidate document with respect to other documents. In the heuristic approaches, the predefined document similarity functions are directly utilized for defining the novelty. In the learning approaches, the novelty is characterized based on a set of handcrafted features. Both the similarity functions and the features are difficult to manually design in real world due to the complexity of modeling the document novelty. In this paper, we propose to model the novelty of a document with a neural tensor network. Instead of manually defining the similarity functions or features, the new method automatically learns a nonlinear novelty function based on the preliminary representation of the candidate document and other documents. New diverse learning to rank models can be derived under the relational learning to rank framework. To determine the model parameters, loss functions are constructed and optimized with stochastic gradient descent. Extensive experiments on three public TREC datasets show that the new derived algorithms can significantly outperform the baselines, including the state-of-the-art relational learning to rank models.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of ACM WSDM '09, pages 5--14, 2009.", "S. Bhatia. Multidimensional search result diversification: Diverse search results for diverse users. In Proceedings of ACM SIGIR '11, pages 1331--1332, 2011.", "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of ACM SIGIR '98, pages 335--336, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911498"}, {"title": "Demand-adaptive Clothing Image Retrieval Using Hybrid Topic Model", "authors": ["Zhengzhong Zhou\n,", "Jingjin Zhou\n,", "Liqing Zhang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper proposes a novel approach to meet users' multi-dimensional requirements in clothing image retrieval. It enables users to add search conditions by modifying the color, texture, shape and attribute descriptors of the query images to further refine their requirements. We propose the Hybrid Topic (HT) model to learn the intricate semantic representation of the descriptors above. The model provides an effective multi-dimensional representation of clothes and is able to perform automatic image annotation by probabilistic reasoning from image search. Furthermore, we develop a demand-adaptive retrieval strategy which refines users' specific requirements and removes users' unwanted features. Our experiments show that the HT method significantly outperforms the deep neural network methods. The accuracy could be further improved in cooperation with image annotation and demand-adaptive retrieval strategy.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "R. B. Girshick, P. F. Felzenszwalb, and D. Mcallester. Object detection with grammar models. NIPS, 33:442--450, 2010.", "J. Huang, R. S. Feris, Q. Chen, and S. Yan. Cross-domain image retrieval with a dual attribute-aware ranking network. In ICCV, pages 1062--1070, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967270"}, {"title": "A bottom-up approach to job recommendation system", "authors": ["Sonu K. Mishra\n,", "Manoj Reddy"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nRecommendation Systems are omnipresent on the web nowadays. Most websites today are striving to provide quality recommendations to their customers in order to increase and retain their customers. In this paper, we present our approaches to design a job recommendation system for a career based social networking website - XING. We take a bottom up approach: we start with deeply understanding and exploring the data and gradually build the smaller bits of the system. We also consider traditional approaches of recommendation systems like collaborative filtering and discuss its performance. The best model that we produced is based on Gradient Boosting algorithm. Our experiments show the efficacy of our approaches. This work is based on a challenge organized by ACM RecSys conference 2016. We achieved a final full score of 1,411,119.11 with rank 20 on the official leader board.", "references": ["RecSys Challenge 2016 Official Website. Available at: http://2016.recsyschallenge.com/", "RecSys Challenge 2016 GitHub. Available at: https://github.com/recsyschallenge/2016", "J. B. Schafer, D. Frankowski, J. Herlocker and S. Sen. Collaborative filtering recommender systems. In The adaptive web 2007, pp. 291--324. Springer Berlin Heidelberg."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987546"}, {"title": "Bags of Local Convolutional Features for Scalable Instance Search", "authors": ["Eva Mohedano\n,", "Kevin McGuinness\n,", "Noel E. O'Connor\n,", "Amaia Salvador\n,", "Ferran Marques\n,", "Xavier Giro-i-Nieto"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis work proposes a simple instance retrieval pipeline based on encoding the convolutional features of CNN using the bag of words aggregation scheme (BoW). Assigning each local array of activations in a convolutional layer to a visual word produces an assignment map, a compact representation that relates regions of an image with a visual word. We use the assignment map for fast spatial reranking, obtaining object localizations that are used for query expansion. We demonstrate the suitability of the BoW representation based on local CNN features for instance retrieval, achieving competitive performance on the Oxford and Paris buildings benchmarks. We show that our proposed system for CNN feature aggregation with BoW outperforms state-of-the-art techniques using sum pooling at a subset of the challenging TRECVid INS benchmark.", "references": ["R. Arandjelović, P. Gronat, A. Torii, T. Pajdla, and J. Sivic. NetVLAD: CNN architecture for weakly supervised place recognition. arXiv:1511.07247, 2015.", "A. Babenko and V. Lempitsky. Aggregating local deep features for image retrieval. In International Conference on Computer Vision (ICCV), December 2015.", "A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. In Computer Vision--ECCV 2014. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912061"}, {"title": "Write-Aware Management of NVM-based Memory Extensions", "authors": ["Amro Awad\n,", "Sergey Blagodurov\n,", "Yan Solihin"], "publication": "ICS '16: Proceedings of the 2016 International Conference on Supercomputing", "abstract": "ABSTRACT\nEmerging Non-Volatile Memory (NVM) technologies, such as 3D XPoint, are expected to be in production as early as 2016. Emerging NVMs are very attractive for several reasons. First, they are non-volatile and hence incur no refresh power. Second, they are dense and promising for scaling down further. Finally, they are fast and have latencies comparable to DRAM. On the other side, using emerging NVMs as direct replacement for DRAM as the main memory is challenging. Compared to DRAM, emerging NVMs can endure a very limited number of writes per cell. Furthermore, their write latency is typically much slower and more energy consuming than DRAM, e.g., Phase Change Memory (PCM) writes are multiple of times slower than that of DRAM. An important use case for emerging NVMs is using them as fast memory extensions. Memory extensions are hidden from programmers and managed by the Operating System (OS). Any access to pages held in the memory extension will cause a page fault. Later, the memory manager moves the faulting page to DRAM and maps the page. While similar in concept to the swap file, memory extensions bypass the file system. Furthermore, memory extensions are dedicated for being used as memory and hence avoid contention with the file system.\nIn this paper, we emulate an NVM-based memory extension and study its impact on performance on a real system. We also study how to improve its performance using OS-level prefetching. We show the importance of having the system software and the NVM controller work in concert for reducing the number of writes. Our best scheme where the system software and the NVM controller work in concert could reduce the number of writes to only 5% of the original baseline (increasing its lifetime by 20x).", "references": ["A. Huan. NVM Express, Revision 1.0c. Intel Corporation, 2012.", "Huai, Yiming, et al. Observation of spin-transfer switching in deep submicron-sized and low-resistance magnetic tunnel junctions. Applied Physics Letters 84.16: 3118--3120, 2004.", "Hydrodynamics Challenge Problem, Lawrence Livermore National Laboratory. Technical Report LLNL-TR-490254."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2925426.2926284"}, {"title": "Ranking Relevance in Yahoo Search", "authors": ["Dawei Yin\n,", "Yuening Hu\n,", "Jiliang Tang\n,", "Tim Daly\n,", "Mianwei Zhou\n,", "Hua Ouyang\n,", "Jianhui Chen\n,", "Changsung Kang\n,", "Hongbo Deng\n,"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nSearch engines play a crucial role in our daily lives. Relevance is the core problem of a commercial search engine. It has attracted thousands of researchers from both academia and industry and has been studied for decades. Relevance in a modern search engine has gone far beyond text matching, and now involves tremendous challenges. The semantic gap between queries and URLs is the main barrier for improving base relevance. Clicks help provide hints to improve relevance, but unfortunately for most tail queries, the click information is too sparse, noisy, or missing entirely. For comprehensive relevance, the recency and location sensitivity of results is also critical. In this paper, we give an overview of the solutions for relevance in the Yahoo search engine. We introduce three key techniques for base relevance -- ranking functions, semantic matching features and query rewriting. We also describe solutions for recency sensitive relevance and location sensitive relevance. This work builds upon 20 years of existing efforts on Yahoo search, summarizes the most recent advances and provides a series of practical relevance solutions. The performance reported is based on Yahoo's commercial search engine, where tens of billions of urls are indexed and served by the ranking system.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR '06.", "A. Broder, M. Fontoura, V. Josifovski, and L. Riedel. A semantic approach to contextual advertising. In SIGIR '07.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML '05."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939677"}, {"title": "Analyzing MOOC Entries of Professionals on LinkedIn for User Modeling and Personalized MOOC Recommendations", "authors": ["Guangyuan Piao\n,", "John G. Breslin"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThe main contribution of this work is the comparison of three user modeling strategies based on job titles, educational fields and skills in LinkedIn profiles, for personalized MOOC recommendations in a cold start situation. Results show that the skill-based user modeling strategy performs best, followed by the job- and edu-based strategies.", "references": ["S. B. Aher and L. Lobo. Combination of machine learning algorithms for recommendation of courses in E-Learning System based on historical data. Knowledge-Based Systems, 51:1--14, oct 2013.", "R. G. Apaza, E. V. Cervantes, L. C. Quispe, and J. O. Luna. Online Courses Recommendation based on LDA. In SIMBig, pages 42--48. Citeseer, 2014.", "G. Christensen, A. Steinmetz, B. Alcorn, A. Bennett, D. Woods, and E. J. Emanuel. The MOOC phenomenon: who takes massive open online courses and why? Available at SSRN 2350964, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930264"}, {"title": "Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting", "authors": ["Yehao Li\n,", "Ting Yao\n,", "Rui Hu\n,", "Tao Mei\n,", "Yong Rui"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe demonstrate a video chatbot, which can generate human-level emotional comments referring to the videos shared by users and trigger a conversation with users. Our video chatbot performs a large-scale similar video search to find visually similar videos w.r.t. a given video using approximate nearest-neighbor search. Then, the comments associated with the searched similar videos are ranked by learning a deep multi-view embedding space for modeling video content, visual sentiment and textual comments. The top ranked comments are selected as responses to the given video and trigger the succeeding text-based chat between users and the chatbot. The demonstration is conducted on a newly collected dataset with over 102K videos and 10.6M comments. Moreover, our video chatbot has great potential to increase live social interactions.", "references": ["Y. Pan, T. Mei, T. Yao, H. Li, and Y. Rui. Jointly modeling embedding and translation to bridge video and language. In CVPR, 2016.", "K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.", "D. Tran, L. D. Bourdev, R. Fergus, L. Torresani, and M. Paluri. C3d: generic features for video analysis. In ICCV, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973835"}, {"title": "An Information System for Genetic Improvement of Goats and Sheep", "authors": ["Thasciano Carvalho\n,", "Natanael Santos\n,", "Werney Lira\n,", "Pedro Amir Oliveira\n,", "Pedro Santos Neto\n,", "Jose Lindenberg Sarmento\n,", "Ricardo Rabelo"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis work describes an information system created to genetical enhancement of sheep and goats, with the goal to maximize weight gain and minimize the degree of kinship of the herd. The genetic enhancement was developed using animal science literature and implemented by using computational intelligence algorithms. The system was applied in a pilot project, with few animals, in order to evaluate the results. The observed result was considered a success, so, the information system is being used in an experimental purpose in a higher education institution. From its use is possible to predict the best couples to mate in order to generate better descendants in terms of weight gain minimizing the degree of kinship of the herd for future generations.", "references": ["CANCHIM. O que e dep? http://www.abccan.com.br/canchim/index.php/ sumario-de-touros/o-que-e-dep.html, 2015. ultimo acesso em 10/06/2015.", "R. Carvalheiro, S. A. d. Queiroz, and B. Kinghorn. Optimum contribution selection using differential evolution. Revista Brasileira de Zootecnia, 39(7):1429-1436, 2010.", "K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2):182-197, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021973"}, {"title": "On Horizontal and Vertical Separation in Hierarchical Text Classification", "authors": ["Mostafa Dehghani\n,", "Hosein Azarbonyad\n,", "Jaap Kamps\n,", "Maarten Marx"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nHierarchy is an effective and common way of organizing data and representing their relationships at different levels of abstraction. However, hierarchical data dependencies cause difficulties in the estimation of \"separable\" models that can distinguish between the entities in the hierarchy. Extracting separable models of hierarchical entities requires us to take their relative position into account and to consider the different types of dependencies in the hierarchy. In this paper, we present an investigation of the effect of separability in text-based entity classification and argue that in hierarchical classification, a separation property should be established between entities not only in the same layer, but also in different layers.\nOur main findings are the followings. First, we analyse the importance of separability on the data representation in the task of classification and based on that, we introduce \"Strong Separation Principle\" for optimizing expected effectiveness of classifiers decision based on separation property. Second, we present Significant Words Language Models (SWLM) which capture all, and only, the essential features of hierarchical entities according to their relative position in the hierarchy resulting in horizontally and vertically separable models. Third, we validate our claims on real world data and demonstrate that how SWLM improves the accuracy of classification and how it provides transferable models over time. Although discussions in this paper focus on the classification problem, the models are applicable to any information access tasks on data that has, or can be mapped to, a hierarchical structure.", "references": ["Feature generation and selection for information retrieval. Workshop of SIGIR, 2010.", "A. Arampatzis and A. van Hameran. The score-distributional threshold optimization for adaptive binary classification tasks. In SIGIR '01, pages 285--293, 2001.", "A. Arampatzis, J. Kamps, and S. Robertson. Where to stop reading a ranked list?: Threshold optimization using truncated score distributions. In SIGIR '09, pages 524--531, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970408"}, {"title": "Report on the First International Workshop on the Evaluation on Collaborative Information Seeking and Retrieval (ECol'2015)", "authors": ["Laure Soulier\n,", "Lynda Tamine\n,", "Tetsuya Sakai\n,", "Leif Azzopardi\n,", "Jeremy Pickens"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThe workshop on the evaluation of collaborative information retrieval and seeking (ECol) was held in conjunction with the 24th Conference on Information and Knowledge Management (CIKM) in Melbourne, Australia. The workshop featured three main elements. First, a keynote on the main dimensions, challenges, and opportunities in collaborative information retrieval and seeking by Chirag Shah. Second, an oral presentation session in which four papers were presented. Third, a discussion based on three seed research questions: (1) In what ways is collaborative search evaluation more challenging than individual interactive information retrieval (IIIR) evaluation? (2) Would it be possible and/or useful to standardise experimental designs and data for collaborative search evaluation? and (3) For evaluating collaborative search, can we leverage ideas from other tasks such as diversified search, subtopic mining and/or e-discovery? The discussion was intense and raised many points and issues, leading to the proposition that a new evaluation track focused on collaborative information retrieval/seeking tasks, would be worthwhile.", "references": ["ECol '15: Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking, New York, NY, USA, 2015. ACM.", "L. Azzopardi. Modelling interaction with economic models of search. In Proceedings of the 37th International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR '14, pages 3--12, 2014.", "P. Borlund. The iir evaluation model: a framework for evaluation of interactive information retrieval systems. Information research, 8(3), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964805"}, {"title": "Quantifying Query Ambiguity with Topic Distributions", "authors": ["Yuki Yano\n,", "Yukihiro Tagami\n,", "Akira Tajima"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuery ambiguity is a useful metric for search engines to understand users' intents. Existing methods quantify query ambiguity by calculating an entropy of clicks. These methods assign each click to a one-hot vector corresponding to some mutually exclusive groups. However, they cannot incorporate non-obvious structures such as similarity among documents. In this paper, we propose a new approach for quantifying query ambiguity using topic distributions. We show that it is a natural extension of an existing entropy-based method. Further, we use our approach to achieve topic-based extensions of major existing entropy-based methods. Through an evaluation using e-commerce search logs combined with human judgments, our approach successfully extended existing entropy-based methods and improved the quality of query ambiguity measurements.", "references": ["R. Artstein and M. Poesio. Inter-coder agreement for computational linguistics. Comput. Linguist., 34(4):555--596, 2008.", "P. N. Bennett, K. Svore, and S. T. Dumais. Classification-enhanced ranking. In Proceedings of WWW '10, pages 111--120, 2010.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983863"}, {"title": "A Cross-Platform Collection of Social Network Profiles", "authors": ["Maria Han Veiga\n,", "Carsten Eickhoff"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe proliferation of Internet-enabled devices and services has led to a shifting balance between digital and analogue aspects of our everyday lives. In the face of this development there is a growing demand for the study of privacy hazards, the potential for unique user deanonymization and information leakage between the various social media profiles many of us maintain. To enable the structured study of such adversarial effects, this paper presents a dedicated dataset of cross-platform social network personas (i.e., the same person has accounts on multiple platforms). The corpus comprises 850 users who generate predominantly English content. Each user object contains the online footprint of the same person in three distinct social networks: Twitter, Instagram and Foursquare. In total, it encompasses over 2.5M tweets, 340k check-ins and 42k Instagram posts. We describe the collection methodology, characteristics of the dataset, and how to obtain it. Finally, we discuss a common use case, cross-platform user identification.", "references": ["CrossOSN-crawler code repository. https://github.com/hanveiga/CrossOSN-crawler.", "R. O. et al. Of Pins and Tweets: Investigating how users behave across image- and text-based social networks. In ICWSM 2014.", "Foursquare. Foursquare API overview, 2015 (accessed May 2, 2015). https://developer.foursquare.com/overview/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914666"}, {"title": "Counterfactual Evaluation and Learning for Search, Recommendation and Ad Placement", "authors": ["Thorsten Joachims\n,", "Adith Swaminathan"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline metrics measured through A/B tests have become the gold standard for many evaluation questions. But can we get the same results as A/B tests without actually fielding a new system? And can we train systems to optimize online metrics without subjecting users to an online learning algorithm? This tutorial summarizes and unifies the emerging body of methods on counterfactual evaluation and learning. These counterfactual techniques provide a well-founded way to evaluate and optimize online metrics by exploiting logs of past user interactions. In particular, the tutorial unifies the causal inference, information retrieval, and machine learning view of this problem, providing the basis for future research in this emerging area of great potential impact. Supplementary material and resources are available online at http://www.cs.cornell.edu/~adith/CfactSIGIR2016.", "references": ["S. Athey and G. Imbens. Recursive Partitioning for Heterogeneous Causal Effects. ArXiv e-prints, 2015.", "A. Beygelzimer and J. Langford. The offset tree for learning with partial labels. In KDD, pages 129--138, 2009.", "L. Bottou, J. Peters, J. Q. Candela, D. X. Charles, M. Chickering, E. Portugaly, D. Ray, P. Y. Simard, and E. Snelson. Counterfactual reasoning and learning systems: The example of computational advertising. Journal of Machine Learning Research, 14(1):3207--3260, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914803"}, {"title": "Contacts Deduplication in Mobile Devices Using Textual Similarity and Machine Learning", "authors": ["Rafael F. Machado\n,", "Rafael F. Pinheiro\n,", "Karina S. Machado\n,", "Eduardo N. Borges"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis paper presents a method that identifies duplicate contacts, i.e., records representing the same person or organization, automatically collected from multiple data sources. Contacts are compared using several similarity functions, of which scores are combined by a classification model based on decision trees, which eliminates the need for an expert to manually configure similarity thresholds. The experiments show that the proposed method correctly identified up to 92% of duplicate contacts.", "references": ["W. F. Ableson, R. Sen, C. King, and C. Ortiz. Android em acao. Campus, Rio de janeiro, 2012.", "A. Accaci. Duplicate contacts. http://play.google. com/store/apps/details?id=com.accaci, 2015. Acesso: julho de 2015.", "M. Bilenko and R. J. Mooney. Adaptive duplicate detection using learnable string similarity measures. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 39-48, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021983"}, {"title": "Research Publication Recommendation System based on a Hybrid Approach", "authors": ["Anastasios Tsolakidis\n,", "Evangelia Triperina\n,", "Cleo Sgouropoulou\n,", "Nikos Christidis"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nRecommendations systems have become an important tool for scientists because they simplify the process of discovering related work, without getting distracted by the enormous amount of research publications. Academic research on recommendations systems can be classified on two main categories: the content-based filtering approach, where the papers published by the authors are indexed and the TF-IDF algorithm is applied to calculate the weights for each one of the indexed terms and the collaboration filtering, in which authors are considered to prefer similar publications with authors with akin behavior. In the proposed method, we present a hybrid approach using both of the before mentioned approaches. We contribute to the collaborative filtering by implementing graph based analysis in order to define the importance of each indexed term.", "references": ["N. Lao and W. W. Cohen, \"Relational retrieval using a combination of pathconstrained random walks,\" Machine learning, vol. 81, no. 1, pp. 53--67, 2010.", "L. Rokach, P. Mitra, S. Kataria, W. Huang, and L. Giles, \"A Supervised Learning Method for Context-Aware Citation Recommendation in a Large Corpus,\" in 52 Proceedings of the Large-Scale and Distributed Systems for Information Retrieval Workshop (LSDS-IR), 2013, pp. 17--22.", "Q. He, J. Pei, D. Kifer, P. Mitra, and L. Giles, \"Context-aware citation recommendation,\" in Proceedings of the 19th international conference on World wide web, 2010, pp. 421--430."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003805"}, {"title": "Multimodal Event Detection and Summarization in Large Scale Image Collections", "authors": ["Manos Schinas\n,", "Symeon Papadopoulos\n,", "Georgios Petkos\n,", "Yiannis Kompatsiaris\n,", "Pericles A. Mitkas"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper describes a multimodal graph-based approach to address the problem of event detection and summarization in large scale image collections. A first version of our system was presented in the Yahoo-Flickr Event Summarization Challenge of ACM Multimedia 2015 [6]. The objective of the approach is to automatically detect events within millions of photos and summarizing them efficiently for user consumption. The presented approach uses a moving time window over the collection of multimedia items to build a same-event image graph and applies graph clustering to detect events. In addition, it makes use of a graph-based diversity-oriented ranking algorithm to summarize instances of the detected events. A demo of the system is online at: http://mklab.iti.gr/acmmm2015-gc/.", "references": ["W. Dong, C. Moses, and K. Li. Efficient k-nearest neighbor graph construction for generic similarity measures. In Proceedings of the 20th international conference on World wide web, pages 577--586. ACM, 2011.", "Q. Mei, J. Guo, and D. Radev. Divrank: The interplay of prestige and diversity in information networks. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '10, pages 1009--1018, NY, USA, 2010. ACM.", "G. Petkos, S. Papadopoulos, and Y. Kompatsiaris. Social event detection using multimodal clustering and integrating supervisory signals. In Proceedings of the 2nd ACM International Conference on Multimedia Retrieval, ICMR '12, pages 23:1--23:8, New York, NY, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912031"}, {"title": "Which Information Sources are More Effective and Reliable in Video Search", "authors": ["Zhiyong Cheng\n,", "Xuanchong Li\n,", "Jialie Shen\n,", "Alexander G. Hauptmann"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIt is common that users are interested in finding video segments, which contain further information about the video contents in a segment of interest. To facilitate users to find and browse related video contents, video hyperlinking aims at constructing links among video segments with relevant information in a large video collection. In this study, we explore the effectiveness of various video features on the performance of video hyperlinking, including subtitle, metadata, content features (i.e., audio and visual), surrounding context, as well as the combinations of those features. Besides, we also test different search strategies over different types of queries, which are categorized according to their video contents. Comprehensive experimental studies have been conducted on the dataset of TRECVID 2015 video hyperlinking task. Results show that (1) text features play a crucial role in search performance, and the combination of audio and visual features cannot provide improvements; (2) the consideration of contexts cannot obtain better results; and (3) due to the lack of training examples, machine learning techniques cannot improve the performance.", "references": ["G. Amati. Frequentist and bayesian approach to information retrieval. In Proc. of ECIR, 2006.", "G. Amati, G. Amodeo, M. Bianchi, Ca. Gaibisso, and G. Gambosi. Fub, iasi-cnr and university of tor vergata at trec 2008 blog track. In Proc. of TREC 2008, 2008.", "C. Bhatt, N. Pappas, M. Habibi, and A. Popescu-Belis. Multimodal reranking of content-based recommendations for hyperlinking video snippets. In Proc. of ACM ICMR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914765"}, {"title": "A Piggyback System for Joint Entity Mention Detection and Linking in Web Queries", "authors": ["Marco Cornolti\n,", "Paolo Ferragina\n,", "Massimiliano Ciaramita\n,", "Stefan Rüd\n,", "Hinrich Schütze"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper we study the problem of linking open-domain web-search queries towards entities drawn from the full entity inventory of Wikipedia articles. We introduce SMAPH-2, a second-order approach that, by piggybacking on a web search engine, alleviates the noise and irregularities that characterize the language of queries and puts queries in a larger context in which it is easier to make sense of them. The key algorithmic idea underlying SMAPH-2 is to first discover a candidate set of entities and then link-back those entities to their mentions occurring in the input query. This allows us to confine the possible concepts pertinent to the query to only the ones really mentioned in it. The link-back is implemented via a collective disambiguation step based upon a supervised ranking model that makes one joint prediction for the annotation of the complete query optimizing directly the F1 measure. We evaluate both known features, such as word embeddings and semantic relatedness among entities, and several novel features such as an approximate distance between mentions and entities (which can handle spelling errors). We demonstrate that SMAPH-2 achieves state-of-the-art performance on the ERD@SIGIR2014 benchmark. We also publish GERDAQ (General Entity Recognition, Disambiguation and Annotation in Queries), a novel, public dataset built specifically for web-query entity linking via a crowdsourcing effort. SMAPH-2 outperforms the benchmarks by comparable margins also on GERDAQ.", "references": ["A. Alasiry, M. Levene, A. Poulovassilis. Detecting candidate named entities in search queries. In SIGIR, 1049--1050, 2012.", "M. Bendersky, W.B. Croft, D.A. Smith. Joint Annotation of Search Queries. In ACL-HLT, 1:102--111, 2011.", "R. Blanco, G. Ottaviano, E. Meij. Fast and Space-Efficient Entity Linking for Queries. In WSDM, 179--188, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883061"}, {"title": "An Experimental Study in Cross-Representation Mediation of User Models", "authors": ["Federica Cena\n,", "Cristina Gena\n,", "Claudia Picardi"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThe paper presents the result on cross-representation mediation of user models in the context of movie recommendation. We analyze the possibility of initializing the user models for a content-based recommender starting from movie ratings provided by users in other social applications. We focus in particular on (i) an approach for inferring user model preferences from rating and (ii) the experimentation of several methods to solve the missing value problem exploiting community-based ratings. We tested different variations of the proposed approach exploiting a subset of the MovieLens 10M Dataset, computing rating predictions, and MAE.", "references": ["S. Berkovsky, T. Kuflik, and F. Ricci. Cross-representation mediation of user models. User Model. User-Adapt. Interact., 19(1--2):35--63, 2009.", "J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, UAI'98, pages 43--52, San Francisco, CA, USA, 1998. Morgan Kaufmann Publishers Inc.", "P. Brusilovsky. Social information access: The other side of the social web. In V. Geffert, J. Karhum\\\"aki, A. Bertoni, B. Preneel, P. Návrat, and M. Bieliková, editors, SOFSEM 2008: Theory and Practice of Computer Science: 34th Conference on Current Trends in Theory and Practice of Computer Science, Nový Smokovec, Slovakia, January 19--25, 2008. Proceedings, pages 5--22, Berlin, Heidelberg, 2008. Springer Berlin Heidelberg."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930263"}, {"title": "PowerWalk: Scalable Personalized PageRank via Random Walks with Vertex-Centric Decomposition", "authors": ["Qin Liu\n,", "Zhenguo Li\n,", "John C.S. Lui\n,", "Jiefeng Cheng"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMost methods for Personalized PageRank (PPR) precompute and store all accurate PPR vectors, and at query time, return the ones of interest directly. However, the storage and computation of all accurate PPR vectors can be prohibitive for large graphs, especially in caching them in memory for real-time online querying. In this paper, we propose a distributed framework that strikes a better balance between offline indexing and online querying. The offline indexing attains a fingerprint of the PPR vector of each vertex by performing billions of ``short'' random walks in parallel across a cluster of machines. We prove that our indexing method has an exponential convergence, achieving the same precision with previous methods using a much smaller number of random walks. At query time, the new PPR vector is composed by a linear combination of related fingerprints, in a highly efficient vertex-centric decomposition manner. Interestingly, the resulting PPR vector is much more accurate than its offline counterpart because it actually uses more random walks in its estimation. More importantly, we show that such decomposition for a batch of queries can be very efficiently processed using a shared decomposition. Our implementation, PowerWalk, takes advantage of advanced distributed graph engines and it outperforms the state-of-the-art algorithms by orders of magnitude. Particularly, it responses to tens of thousands of queries on graphs with billions of edges in just a few seconds.", "references": ["R. Andersen, F. Chung, and K. Lang. Local Graph Partitioning using PageRank Vectors. In FOCS, pages 475--486, 2006.", "J. Attenberg and R. Baeza-yates. Batch Query Processing for Web Search Engines. In WSDM, pages 137--146, 2011.", "K. Avrachenkov, N. Litvak, D. Nemirovsky, and N. Osipova. Monte Carlo Methods in PageRank Computation: When One Iteration is Sufficient. SINUM, 45(2):890--904, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983713"}, {"title": "An Automatic Calorie Estimation System of Food Images on a Smartphone", "authors": ["Koichi Okamoto\n,", "Keiji Yanai"], "publication": "MADiMa '16: Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management", "abstract": "ABSTRACT\nIn recent years, due to a rise in healthy thinking on eating, many people take care of their eating habits, and some people record daily diet regularly. To assist them, many mobile applications for recording everyday meals have been released so far. Some of them employ food image recognition which can estimate not only food names but also food calorie. However, most of such applications have some problems especially on their usability. Then, in this paper, we propose a novel single-image-based food calorie estimation system which runs on a smartphone as a standalone application without external recognition servers. The proposed system carries out food region segmentation, food region categorization, and calorie estimation automatically. By the experiments and the user study on the proposed system, the effectiveness of the proposed system was confirmed.", "references": ["T. Miyazaki, De. S. G. Chamin, and K. Aizawa, \"Image-based calorie content estimation for dietary assessment,\" in IEEE International Symposium on Multimedia, pp. 363--368, 2011.", "M. Chen, Y. Yang, C. Ho, S. Wang, S. Liu, E. Chang, C. Yeh, and M. Ouhyoung, \"Automatic chinese food identification and quantity estimation,\" in Proc. of SIGGRAPH Asia Technical Briefs, p. 29, 2012.", "F. Kong and J. Tan, \"Dietcam: Automatic dietary assessment with mobile camera phones,\" in Proc. of Pervasive and Mobile Computing, pp. 147--163, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986035.2986040"}, {"title": "A Hybrid Book Recommender System Based on Table of Contents (ToC) and Association Rule Mining", "authors": ["Zafar Ali\n,", "Shah Khusro\n,", "Irfan Ullah"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nRecommender systems are used to access appropriate items and information by personalized suggestions based on user previous preferences and their likes & dislikes. These systems are used in different domains including products, videos, images, articles, news and books. Several recommender systems have been designed for recommending books. However, the available book recommenders face several issues in making relevant book recommendations because most of these do not take into account the book contents at deeper level and process only the mere descriptions about books on web pages along with metadata and other rating information. In order to cope with this issue, we present a hybrid book recommender that recommends books by using book table of contents (TOC) along with association rule mining and opinions of similar users.", "references": ["Almazro, D., Shahatah, G., Albdulkarim, L., Kherees, M., Martinez, R., and Nzoukou, W., 2010. A survey paper on recommender systems. arXiv preprint arXiv:1006.5278.", "Balabanovi, M., #263, and Shoham, Y., 1997. Fab: content-based, collaborative recommendation. Commun. ACM 40, 3, 66--72. DOI= http://dx.doi.org/10.1145/245108.245124.", "Burke, R., 2002. Hybrid recommender systems: Survey and experiments. User modeling and user-adapted interaction 12, 4, 331--370."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908481"}, {"title": "Flash storage disaggregation", "authors": ["Ana Klimovic\n,", "Christos Kozyrakis\n,", "Eno Thereska\n,", "Binu John\n,", "Sanjeev Kumar"], "publication": "EuroSys '16: Proceedings of the Eleventh European Conference on Computer Systems", "abstract": "ABSTRACT\nPCIe-based Flash is commonly deployed to provide datacenter applications with high IO rates. However, its capacity and bandwidth are often underutilized as it is difficult to design servers with the right balance of CPU, memory and Flash resources over time and for multiple applications. This work examines Flash disaggregation as a way to deal with Flash overprovisioning. We tune remote access to Flash over commodity networks and analyze its impact on workloads sampled from real datacenter applications. We show that, while remote Flash access introduces a 20% throughput drop at the application level, disaggregation allows us to make up for these overheads through resource-efficient scale-out. Hence, we show that Flash disaggregation allows scaling CPU and Flash resources independently in a cost effective manner. We use our analysis to draw conclusions about data and control plane issues in remote storage.", "references": ["Amazon. Amazon Elastic Block Store. https://aws.amazon.com/ebs/, 2016.", "G. Ananthanarayanan, A. Ghodsi, S. Shenker, and I. Stoica. Disk-locality in datacenter computing considered irrelevant. In Proc. of USENIX Hot Topics in Operating Systems, HotOS' 13, pages 12--12, 2011.", "D. G. Andersen, J. Franklin, M. Kaminsky, A. Phanishayee, L. Tan, and V. Vasudevan. FAWN: a fast array of wimpy nodes. In Proc. of ACM SIGOPS Symposium on Operating Systems Principles, SOSP '09, pages 1--14. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901318.2901337"}, {"title": "Improving Local Search with Open Geographic Data", "authors": ["Chuankai An\n,", "Dan Rockmore"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nLocal search helps users find certain types of business units (restaurant, gas stations, hospitals, etc.) in the surrounding area. However, some merchants might not have much online content (e.g. customer reviews, business descriptions, opening hours, telephone numbers, etc.). This can pose a problem for traditional local search algorithms such as vector space based approaches. With this difficulty in mind, in this paper we present an approach to local search that incorporates geographic open data. Using the publicly available {\\em Yelp} dataset we are able to uncover patterns that link geographic features and user preferences. From this, we propose a model to infer user preferences that integrates geographic parameters. Through this model and estimation of user preference, we develop a new framework for ``local'' (in the sense of geography) search that offsets the absence of contexts regarding physical business units. Our initial analysis points to the meaningful integration of open geographic data in local search and points out several directions for further research.", "references": ["Ahlers, D. Business entity retrieval and data provision for yellow pages by local search. In IRPS Workshop (2013).", "Berberich, K., König, A. C., Lymberopoulos, D., and Zhao, P. Improving local search ranking through external logs. In Proc. of the SIGIR (2011), ACM, pp. 785--794.", "Church, K., and Smyth, B. Who, what, where & when: a new approach to mobile search. In Proceedings of the 13th international conference on Intelligent user interfaces (2008), ACM, pp. 309--312."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890482"}, {"title": "Complex Patterns in Dynamic Attributed Graphs", "authors": ["Rina Singh\n,", "Jeffrey A. Graves\n,", "Douglas A. Talbert"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn recent years, there has been huge growth in the amount of graph data generated from various sources. These types of data are often represented by vertices and edges in a graph with real-valued attributes, topological properties, and temporal information associated with the vertices. Until recently, most pattern mining techniques focus solely on vertex attributes, topological properties, or a combination of these in a static sense; mining attribute and topological changes simultaneously over time has largely been overlooked. In this work-in-progress paper, we propose to extend an existing state-of-the-art technique to mine for patterns in dynamic attributed graphs which appear to trigger changes in attribute values.", "references": ["E. Desmier, M. Plantevit, C. Robardet, and J.-F. Boulicaut. Cohesive co-evolution patterns in dynamic attributed graphs. In Discovery Science, pages 110--124. Springer, 2012.", "E. Desmier, M. Plantevit, C. Robardet, and J.-F. Boulicaut. Trend mining in dynamic attributed graphs. In Machine Learning and Knowledge Discovery in Databases, pages 654--669. Springer, 2013.", "M. Kaytoue, Y. Pitarch, M. Plantevit, and C. Robardet. Triggering patterns of topology changes in dynamic graphs. In Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on, pages 158--165. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889374"}, {"title": "Emerging opportunities in Domain Specific Search", "authors": ["Vekhande Neha Eknath\n,", "Gogate Uttara Dhananjay"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nThe cyber space is exploding in rapidity that nobody has ever imagined, it becomes very essential to search the web of cyber space efficiently and effectively. One solution came up as an resolution to this problem is search engines. By now a lot of commercial business search engines have been put on the market. The web has grown up a lot in terms of search engines. However these search engines sometimes respond with awkward and bulky results, this was unbearable for domain specific experts. Numerous domain specific search engines are being developed using a dedicate hardware and a commercial software. These engines are widely used for variety of purposes and topic specific searches. A domain specific search engine is different from a general web search engine; the domain specific search focuses on a specific segment of online content. They are also called specialty or topical search engines. The domain specific content area may be based on different topics i.e. topicality based, type of media, or type of content. General verticals include shopping, the automotives, legal information, medical, literature, and travel. In this paper we will be studying the changing nature of web search in context to domain specific search[1].", "references": ["B. Geng, L. Yang, C. Xu, and X.-S. Hua, ---Ranking Model Adaptation for Domain-Specific Search,|| IEEE, 2012", "Jiawei Han and Micheline Kamber, ---Data Mining: Concepts and Techniques, Second Edition,|| Issue Date: 2006.", "A. McCallum, K. Nigam, J. Rennie, and K. Seymore, ---A machine learning approach to building domain-specific search engines,|| IJCAI-99, p. 662--667, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905222"}, {"title": "Image Annotation using Multi-scale Hypergraph Heat Diffusion Framework", "authors": ["Venkatesh N. Murthy\n,", "Avinash Sharma\n,", "Visesh Chari\n,", "R. Manmatha"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe task of automatic image annotation involves assigning relevant multiple labels/tags to query images based on their visual content. One of the key challenge in multi-label image annotation task is the class imbalance problem where frequently occurring labels suppress the participation of rarely occurring labels. In this paper, we propose to exploit the multi-scale behavior in hypergraph heat diffusion framework for the automatic image annotation task. The proposed novel technique enables to model the higher order relationship among images in the feature space and provides a multi-scale label diffusion mechanism to address the class imbalance problem in the data.", "references": ["K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In British Machine Vision Conference, 2014.", "M. Chen, A. X. Zheng, and K. Q. Weinberger. Fast image tagging. In International Conference on Machine Learning, pages 1274--1282, 2013.", "S. L. Feng, R. Manmatha, and V. Lavrenko. Multiple bernoulli relevance models for image and video annotation. In Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR'04, pages 1002--1009, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912055"}, {"title": "VisTrees: fast indexes for interactive data exploration", "authors": ["Muhammad El-Hindi\n,", "Zheguang Zhao\n,", "Carsten Binnig\n,", "Tim Kraska"], "publication": "HILDA '16: Proceedings of the Workshop on Human-In-the-Loop Data Analytics", "abstract": "ABSTRACT\nVisualizations are arguably the most important tool to explore, understand and convey facts about data. As part of interactive data exploration, visualizations might be used to quickly skim through the data and look for patterns. Unfortunately, database systems are not designed to efficiently support these workloads. As a result, visualizations often take very long to produce, creating a significant barrier to interactive data analysis.\nIn this paper, we focus on the interactive computation of histograms for data exploration. To address this issue, we present a novel multi-dimensional index structure called VisTree. As a key contribution, this paper presents several techniques to better align the design of multi-dimensional indexes with the needs of visualization tools for data exploration. Our experiments show that the VisTree achieves a speed increase of up to three orders of magnitude compared to traditional multi-dimensional indexes and enables an interactive speed of below 500ms even on large data sets.", "references": ["A. Guttman. R-trees: A dynamic index structure for spatial searching. In Proceedings of the 1984 ACM SIGMOD International Conference on Management of Data, SIGMOD '84, 1984.", "P. Hanrahan. Analytic database technologies for a new kind of user: The data enthusiast. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, SIGMOD '12, 2012.", "J. M. Hellerstein et al. Online Aggregation. In Proceedings of the 1997 ACM SIGMOD International Conference on Management of Data, SIGMOD '97, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939502.2939507"}, {"title": "KCF.js: A Javascript Library for Knowledge Cards Fusion", "authors": ["Haofen Wang\n,", "Zhijia Fang\n,", "Tong Ruan"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nRecently Web search engines have built knowledge graphs to support entity search and to provide structural summaries called \\emph{knowledge cards} for entities mentioned in queries. Different knowledge cards might be complementary or even have conflicts on values of the equivalent property. Thus, it is essential to achieve a more comprehensive fused card from those individual cards representing the same entity. In this paper, we present a system with technical details of card disambiguation, property alignment, value deduplication and card ranking to fuse knowledge cards from various search engines. We further develop a Javascript library called KCF.js based on the card fusion engine and demonstrates its usability via three possible applications.", "references": ["X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In KDD, pages 601--610, 2014.", "E. Gabrilovich and S. Markovitch. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In IJCAI, pages 1606--1611, 2007.", "D. M. Herzig, P. Mika, R. Blanco, and T. Tran. Federated entity search using on-the-fly consolidation. In ISWC, pages 167--183. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890556"}, {"title": "Towards Embedded Markup of Learning Resources on the Web: An Initial Quantitative Analysis of LRMI Terms Usage", "authors": ["Davide Taibi\n,", "Stefan Dietze"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nEmbedded markup of Web pages have emerged as a significant source of structured data on the Web. In this context, the LRMI initiative has provided a set of vocabulary terms, now part of the schema.org vocabulary, to enable the markup of resources of educational value. In this paper we present a preliminary analysis of the use of LRMI terms on the Web by assessing LRMI-based statements extracted from the Web Data Commons dataset.", "references": ["Meusel R., Petrovski P., and Bizer C. 2014. The WebDataCommons Microdata, RDFa and Microformat Dataset Series. In Proc. of the 13th International Semantic Web Conference (ISWC '14), Mika P., Tudorache T., Bernstein A., Welty C., Knoblock C., VrandeǄić D., Groth P., Noy N., Janowicz K., and Goble C. (Eds.). Springer-Verlag New York, Inc., New York, NY, USA, 277--292.", "Meusel R., Paulheim H. 2015. Heuristics for fixing common errors in deployed schema.org microdata. In Proc. of the ESWC 2015 Conference - The Semantic Web. Latest Advances and New Domains. Springer, 2015. 152--168.", "d'Aquin, M., Adamou, A., Dietze, S. 2013. Assessing the Educational Linked Data Landscape. In Proceedings of ACM Web Science 2013 (WebSci2013), Paris, France, May 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890464"}, {"title": "Using the web to support political analysis: identifying legislative bill ideology in the chilean parliament", "authors": ["Pablo Loyola\n,", "Francisco Szederkenyi\n,", "Yutaka Matsuo"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nIn this work we propose a Web-centric approach for estimating legislative bill tendency. Our main assumption is that the current state of the Web represents a complex system that reflects human thinking and behavior. Today's Web services are characterized by user generated content, allowing everyone to interact and share their view about almost any topic, in the form of posts, comments, reviews, etc. If that data is extracted and efficiently aggregated, it could be possible to obtain a general estimation or view of a given phenomenon or event. We perform semi supervised classification of legislative bill by generating vector representations using three methods, Term Frequency vectors, Topic Models and Word Embeddings with the goal of estimating the tendency of a bill to favor corporations and industries over common good. The output, which can be seen as an estimation of the ideology of a bill, is then used to support political analysis, specifically, to study the relationship between campaign funding and voting behavior.", "references": ["A. Aizawa. An information-theoretic perspective of tf--idf measures. Information Processing & Management, 39(1):45--65, 2003.", "Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1798--1828, 2013.", "J. Bernauer and T. Bräuninger. Intra-party preference heterogeneity and faction membership in the 15th german bundestag: a computational text analysis of parliamentary speeches. German Politics, 18(3):385--402, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908166"}, {"title": "Towards a Patterns Catalog for Data Stream Processing Architectures", "authors": ["Osman de O. L. Junior\n,", "Jorge Fonseca\n,", "Kiev Gama"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nAs a result of technological advances, many computerized devices are communicating over the internet, and with that comes a growing number of distributed applications that require continuous processing of large data stream source, geographically distributed in unpredictable volumes, requiring quick answers for complex queries. These applications, able to process large amounts of information in a timely manner, fit in the category of Information Flow Processing (IFP) [1]. Although they have a common object, these systems differ in many aspects, including the architecture, data models, and rules language processing mechanisms. Recently, much effort was put in the attempt to define a common background for the IFP systems. However, these initiatives are still incipient and no real, standardized and unified model has been proposed so far to describe and classify the elements that compose those types of systems. The purpose of this article is to propose a pattern catalog to capture the different aspects of IFP systems, specifically focusing on complex event processing. Such catalog can be used as a reference for architects of information systems that have realtime data processing as a requirement.", "references": ["G. Cugola and A. Margara. Processing flows of information: From data stream to complex event processing. ACM Computing Surveys, 2012.", "Bass, T. Mythbusters: Event stream processing v. complex event processing. Keynote speech at the 1st International Confrence on Distributed Event-Based Systems (DEBS'07), 2007.", "Babcock, B., Babu, S., Datar, M., Motwani, R.,and Widom, J. Models and issues in data stream systems. In Proceedings of the 21st ACM SIGMOD/PODS Symposium on Principles of Database Systems (PODS'02). ACM, New York, NY, 1- 16, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022033"}, {"title": "Iterative Search using Query Aspects", "authors": ["Manmeet Singh\n,", "W. Bruce Croft"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPseudo-relevance feedback (PRF) via query expansion has proven to be effective in many information retrieval tasks. In most existing work, the top-ranked documents from an initial search are assumed to be relevant and used for feedback. There are some drawbacks to this approach. One limitation is that there might be other relevant documents which were not retrieved or considered for the the feedback process. Another issue is one or more of the top retrieved documents may be non-relevant, which can introduce noise into the feedback mechanism. Term-level diversification, on the other hand, uses an effective technique for identifying terms associated with query aspects or subtopics. We propose a new iterative feedback method that combines PRF with aspect generation to improve feedback effectiveness. In our experiments, we discovered a new property of convergence of feedback terms that was incorporated into the PRF process. We show that the resulting method significantly outperforms the baseline relevance model.", "references": ["V. Dang and W. B. Croft. Diversity by proportionality: An election-based approach to search result diversi cation. In 35th International ACM SIGIR Conference on Research and Development in IR, SIGIR '12, pages 65--74, NY, USA, 2012. ACM.", "D. Harman and C. Buckley. The nrrc reliable information access (ria) workshop. In ACM SIGIR Conference, '04, pages 528--529, NY, USA, 2004. ACM.", "J. He, M. Li, Z. Li, H.-J. Zhang, H. Tong, and C. Zhang. Advances in Multimedia Information Processing - PCM 2004, Part II, chapter PRF Based on Iterative Probabilistic One-Class SVMs in Web Image Retrieval, pages 213--220. Springer Berlin Heidelberg, Berlin, Heidelberg, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983903"}, {"title": "Real-time Wearable Computer Vision System for Improved Museum Experience", "authors": ["Giovanni Taverriti\n,", "Stefano Lombini\n,", "Lorenzo Seidenari\n,", "Marco Bertini\n,", "Alberto Del Bimbo"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe goal of this work is to implement a real-time computer vision system that can run on wearable devices to perform object classification and artwork recognition, to improve the experience of a museum visit through understanding the interests of users. Object classification helps to understand the context of the visit, e.g. differentiating when a visitor is talking with people, or just wandering through the museum, or if he is looking at an exhibit that interests him. Artwork recognition allows to provide automatically information of the observed item or to create a user profile based on what and how long a user has observed artworks.", "references": ["J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973813"}, {"title": "Self-managed and blockchain-based vehicular ad-hoc networks", "authors": ["Benjamin Leiding\n,", "Parisa Memarmoshrefi\n,", "Dieter Hogrefe"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nCombining Vehicle Ad-hoc Networks (VANETs) and Ethereum's blockchain-based application concepts enables transparent, self-managed and decentralized system which are self-regulating and in no need of a central managing authority.", "references": ["Al-Sultan, Saif and Al-Doori, Moath M and Al-Bayatti, Ali H and Zedan, Hussien. 2014. A Comprehensive Survey on Vehicular Ad Hoc Network. Journal of Network and Computer Applications 37 (2014), 380--392.", "Roberto Baldessari, Bert Bödekker, Matthias Deegener, Andreas Festag, Walter Franz, C Christopher Kellum, Timo Kosch, Andras Kovacs, Massimiliano Lenardi, Cornelius Menig, and others. 2007. Car-2-Car Communication Consortium - Manifesto. (2007).", "Buterin, Vitalik. 2014. Ethereum: A Next-Generation Smart Contract and Decentralized Application Platform. URL: https://github.com/ethereum/wiki/wiki/%5BEnglish%5D-White-Paper. (2014). (Accessed May 06, 2016)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2971409"}, {"title": "Session details: Main Track - Education in IS", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3256000"}, {"title": "A Meta-Framework for Modeling the Human Reading Process in Sentiment Analysis", "authors": ["Ramy Baly\n,", "Roula Hobeica\n,", "Hazem Hajj\n,", "Wassim El-Hajj\n,", "Khaled Bashir Shaban\n,", "Ahmad Al-Sallab"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nThis article introduces a sentiment analysis approach that adopts the way humans read, interpret, and extract sentiment from text. Our motivation builds on the assumption that human interpretation should lead to the most accurate assessment of sentiment in text. We call this automated process Human Reading for Sentiment (HRS). Previous research in sentiment analysis has produced many frameworks that can fit one or more of the HRS aspects; however, none of these methods has addressed them all in one approach. HRS provides a meta-framework for developing new sentiment analysis methods or improving existing ones. The proposed framework provides a theoretical lens for zooming in and evaluating aspects of any sentiment analysis method to identify gaps for improvements towards matching the human reading process. Key steps in HRS include the automation of humans low-level and high-level cognitive text processing. This methodology paves the way towards the integration of psychology with computational linguistics and machine learning to employ models of pragmatics and discourse analysis for sentiment analysis. HRS is tested with two state-of-the-art methods; one is based on feature engineering, and the other is based on deep learning. HRS highlighted the gaps in both methods and showed improvements for both.", "references": ["Ahmed Abbasi, Hsinchun Chen, and Arab Salem. 2008. Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums. ACM Trans. Inform. Syst. 26, 3 (2008), 12.", "Ahmed Abbasi, Stephen France, Zhu Zhang, and Hsinchun Chen. 2011. Selecting attributes for sentiment classification using feature relation networks. IEEE Trans. Knowl. Data Eng. 23, 3 (2011), 447--462.", "Alan Baddeley and Graham Hitch. 2010. Working memory. (2010). http://www.scholarpedia.org/article/Working_memory."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2950050"}, {"title": "Succinct Data Structures in Information Retrieval: Theory and Practice", "authors": ["Simon Gog\n,", "Rossano Venturini"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSuccinct data structures are used today in many information retrieval applications, e.g., posting lists representation, language model representation, indexing (social) graphs, query auto-completion, document retrieval and indexing dictionary of strings, just to mention the most recent ones. These new kind of data structures mimic the operations of their classical counterparts within a comparable time complexity but require much less space. With the availability of several libraries for basic succinct structures - like SDSL, Succinct, Facebook?s Folly, and Sux - it is relatively easy to directly profit from advances in this field. In this tutorial we will introduce this field of research by presenting the most important succinct data structures to represent set of integers, set of points, trees, graphs and strings together with their most important applications to Information Retrieval problems. The introduction of the succinct data structures will be sustained with a practical session with programming handouts to solve. This will allow the attendees to directly experiment with implementations of these solutions on real datasets and understand the potential benefits they can bring on their own projects.", "references": ["J. Barbay. Succinct and compressed data structures for permutations and integer functions. In Encyclopedia of Algorithms. 2015.", "J. Barbay and J. I. Munro. Succinct encoding of permutations: Applications to text indexing. In Encyclopedia of Algorithms. 2008.", "D. Benoit, E. Demaine, J. I. Munro, R. Raman, V.Raman, and S. S. Rao. Representing trees of higher degree. Algorithmica, 43(4):275--292, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914802"}, {"title": "New Frontiers of Large Scale Multimedia Information Retrieval", "authors": ["Shih-Fu Chang"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nMultimedia information retrieval aims to automatically extract useful information from large collection of images, videos, and combinations with other data like text and speech. As reported in recent news, it's now possible to search information over millions or more of products with just an example image on the mobile phone. Intelligent apps are being deployed by major companies to automatically generate keywords or even captions of an image at a sophistication level that could not be imagined before. In this talk, I will review core technologies involved and discuss challenges and opportunities ahead. First, to address the complexity bottleneck when scaling up the data size, I will present extremely compact hash codes and deep learning image classification models that can reduce complexity by orders of magnitude while preserving approximate accuracy. Second, to support easy extension of recognition systems to new domains, instead of relying on fixed image categories, we introduce a new paradigm to automatically discover unique multimodal concepts and structures using large amounts of multimedia data available. Last, to support emerging applications beyond basic image categorization, I will discuss on-going efforts in understanding how images are used in expressing sentiments and emotions in online social media and how languages/cultures may influence such online multimedia communication.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2930063"}, {"title": "GeTCo: an ontology-based approach for patent classification search", "authors": ["Hoang-Minh Nguyen\n,", "Cong-Phuoc Phan\n,", "Hong-Quang Nguyen"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThe main contribution of this paper is a method for creating a Graph-Embedded-Tree-based ontology, which utilizes domain knowledge from a patent classification scheme, for a patent classification process. Our contribution is twofold. First, we propose a novel definition of GeTCo ontology, which consists of four types of concept: Class, Document, Phrase, and Term. Depending on relationships of each pair of concepts, we further define their semantic information to give our classifier better reasoning capability whenever the semantic ambiguation occurs. Second, we propose a novel method to construct our ontology based on the United State Patent Classification Scheme (USPC) without relying on a rule-based method for concept extraction and thus, it can negate intensive-manual efforts in traditional ontology construction. We developed a prototype application on top of Rocchio classifier, called the GeTCo-enabled Rocchio classifier, to evaluate our proposed ontology. Our experiments with filtered 9703 single-class patents showed that the GeTCo-enabled Rocchio classifier, backed by our proposed directed-graph ontology, yields higher F1-score (i.e., +7%) than original Rocchio classifier without GeTCo supports.", "references": ["Patent Scope - International Patent Cooperation Treaty Database.", "L. S. Larkey. A patent search and classification system. In Proceedings of the Fourth ACM Conference on Digital Libraries, DL '99, pages 179--187, New York, NY, USA, 1999. ACM.", "Z. Li and D. Tate. Automatic ontology generation from patents using a pre-built library, wordnet and a class-based n-gram model. International Journal of Product Development (IJPD), 20:142--172, Nov. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011205"}, {"title": "Boosting Video Description Generation by Explicitly Translating from Frame-Level Captions", "authors": ["Yuan Liu\n,", "Zhongchao Shi"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nAutomatically describing video content with natural language is a fundamental challenge of computer vision. The recent advanced technique that approaches this problem is Recurrent Neural Networks (RNN). The need to train RNN on large-scale complex and diverse videos and their associated language, however, makes the task human-labeling intensive and computationally expensive. Moreover, the results can suffer from robustness problem, especially when there are rich of temporal dynamics in the sequence of video frames. We demonstrate in this paper that the above two limitations can be mitigated by jointly exploring the largely available data from image domain and representing each frame by high-level attributes rather than visual features. The former leverages the learnt models on image captioning benchmark to generate caption for each video frame, while the latter explicitly incorporates the obtained captions which are regarded as the attributes of each frame. Specifically, we propose a novel sequence to sequence architecture to generate descriptions for videos, in a sense that the inputs are the captions of sequential frames and it outputs words sequentially. On a widely used YouTube2Text dataset, our proposal is shown to be powerful with superior performance over several state-of-the-art methods including both architectures that are purely developed on video data and RNN-based models which translate directly from visual features to language.", "references": ["D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.", "D. L. Chen and W. B. Dolan. Collecting highly parallel data for paraphrase evaluation. In ACL, 2011.", "M. Denkowski and A. Lavie. Meteor universal: Language specific translation evaluation for any target language. In EACL, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967298"}, {"title": "On mapping emotional states and implicit gestures to sonification output from the 'Intangible Musical Instrument'", "authors": ["Christina Volioti\n,", "Stelios Hadjidimitriou\n,", "Sotiris Manitsaris\n,", "Leontios Hadjileontiadis\n,", "Vasileios Charisis\n,", "Athanasios Manitsaris"], "publication": "MOCO '16: Proceedings of the 3rd International Symposium on Movement and Computing", "abstract": "ABSTRACT\nSonification is an interdisciplinary field of research, aiming at generating sound from data based on systematic, objective and reproducible transformations. Towards this direction, expressive gestures play an important role in music performances facilitating the artistic perception by the audience. Moreover, emotions are linked with music, as sound has the ability to evoke emotions. In this vein, a combinatory approach which aims at gesture and emotion sonification in the context of music composition and performance is presented here. The added value of the proposed system is that both gesture and emotion are able to continuously manipulate the reproduced sound in real-time.", "references": ["Frédéric Bevilacqua, Norbert Schnell, Nicolas Rasamimanana, Bruno Zamborlin and Fabrice Guédy. 2011. Online gesture analysis and control of audio processing. In Musical Robots and Interactive Multimodal Systems (Springer Tracts in Advanced Robotics), J. Solis and K.C. Ng (eds.). Springer, Berlin, Heidelberg, 127--142.", "Antonio Camurri, Gualtiero Volpe, Giovanni De Poli and Marc Leman. 2005. Communicating Expressiveness and Affect in Multimodal Interactive Systems. IEEE MultiMedia, 12, 1:43--53.", "Baptiste Caramiaux, Nicola Montecchio, Atau Tanaka and Frederic Bevilacqua. 2015. Adaptive Gesture Recognition with Variation Estimation for Interactive Systems. ACM TiiS, 4, 4."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948910.2948950"}, {"title": "Share-and-Chat: Achieving Human-Level Video Commenting by Search and Multi-View Embedding", "authors": ["Yehao Li\n,", "Ting Yao\n,", "Tao Mei\n,", "Hongyang Chao\n,", "Yong Rui"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nVideo has become a predominant social media for the booming live interactions. Automatic generation of emotional comments to a video has great potential to significantly increase user engagement in many socio-video applications (e.g., chat bot). Nevertheless, the problem of video commenting has been overlooked by the research community. The major challenges are that the generated comments are to be not only as natural as those from human beings, but also relevant to the video content. We present in this paper a novel two-stage deep learning-based approach to automatic video commenting. Our approach consists of two components. The first component, similar video search, efficiently finds the visually similar videos w.r.t. a given video using approximate nearest-neighbor search based on the learned deep video representations, while the second dynamic ranking effectively ranks the comments associated with the searched similar videos by learning a deep multi-view embedding space. For modeling the emotional view of videos, we incorporate visual sentiment, video content, and text comments into the learning of the embedding space. On a newly collected dataset with over 102K videos and 10.6M comments, we demonstrate that our approach outperforms several state-of-the-art methods and achieves human-level video commenting.", "references": ["S. Antol, A. Agrawal, J. Lu, M. Mitchell, , D. Batra, C. Lawrence Zitnick, and D. Parikh. Vqa: Visual question answering. In ICCV, 2015.", "D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In ACM MM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964320"}, {"title": "ChordRipple: Adaptively Recommending and Propagating Chord Changes for Songwriters", "authors": ["Cheng-Zhi Anna Huang"], "publication": "IUI '16 Companion: Companion Publication of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nSongwriting is the interplay of a composer's creative intent and an idiom's language. This language both facilitates and poses stylistic constraints on a composer's expressivity. Novice composers often find it difficult to go beyond common chord progressions, to find the chords that realize their intentions. To make it easier for composers to experiment with radical chord choices and to prototype \"what-if\" ideas, we are building a creativity support tool, ChordRipple, which (1) makes chord recommendations that aim to be both diverse and appropriate to the current context, (2) infers a composer's intention to help her more quickly prototype ideas. Composers can use it to help select the next chord, to replace sequences of chords in an internally consist manner, or to edit one part of a sequence and see the whole sequence change in that direction. To make such recommendations, we adapt neural-network models such as Word2Vec to the music domain as Chord2Vec. This model learns chord embeddings from a corpus of chord sequences, placing chords nearby when they are used in similar contexts. The learned embeddings support creative substitutions between chords, and also exhibit topological properties that correspond to musical structure. For example, the major and minor chords are both arranged in the latent space in shapes corresponding to the circle-of-fifths. To support the dynamic nature of the creative process, we propose to infer a composer's intentions for adaptive recommendation. As a composer makes chord changes, she is moving in the embedding space. We can infer a composer's intention from the gradient of her edits' trace and use this gradient to help her fine-tune her current changes or to project the sequence into the future to give recommendations on how the sequence could look like if more edits in that direction were performed.", "references": ["Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Jozefowicz, R., and Bengio, S. Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349 (2015).", "Huang, C.-Z. A., Duvenaud, D., and Gajos, K. Z. Chordripple: Recommending chords to help novice composers go beyond the ordinary. In Proceedings of the Conference on Intelligent User Interfaces (2016).", "Kingma, D. P., and Welling, M. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876456.2876465"}, {"title": "Functional at Scale", "authors": ["Marius Eriksen"], "publication": "Queue", "abstract": "Abstract\nApplying functional programming principles to distributed computing projects", "references": ["Barroso, L. A., Clidaras, J., Hölzle, U. 2013. The datacenter as a computer: an introduction to the design of warehouse-scale machines. Synthesis Lectures on Computer Architecture 8(3): 1-154.", "Dean, J., Barroso, L. A. 2013. The tail at scale. Communications of the ACM 56(2): 74-80.", "Dijkstra, E. W. 1965. Solution of a problem in concurrent programming control. Communications of the ACM 8(9): 569."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.3001119"}, {"title": "Perceptions of accessibility and usability by blind or visually impaired persons: a pilot study", "authors": ["Shannon M. Tomlinson"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis pilot study utilizes qualitative interviews to explore perceptions of accessibility and usability from the perspective of blind or visually impaired (BVI) persons. Using the frameworks of everyday life information seeking (ELIS) and the sense-making approach, this research addresses a gap in the literature; most studies with this population are either quantitative, outdated, or task-based observations. Through five in-depth interviews, this study provides a more nuanced understanding of the perceptions, experiences, and opinions of BVI persons who use screen readers with a voice synthesizer as a primary modality of interaction with web content. Understanding the information needs and information behavior of BVI persons is important for proper web design, since technical accessibility does not ensure usability. In particular, it is the perception of accessibility and usability that affects information behavior. Design must be informed by empirical research in order for it to be effective in assisting a variety of users to accomplish their information goals.", "references": ["Berry, J. (1999). Apart or a part? Access to the Internet by visually impaired and blind people, with particular emphasis on assistive enabling technology and user perceptions. Information Technology and Disabilities, 6(3--4).", "Booth, C. (2012). Introduction: Why accessibility?. Library Technology Reports, 48(7), 5--6.", "Brophy, P., & Craven, J. (2007). Web accessibility. Library Trends, 55(4), 950--972."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017567"}, {"title": "Behaviour Mining for Automatic Task-Keeping and Visualisations for Task-Refinding", "authors": ["Charlie Abela\n,", "Chris Staff"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWhen people perform some tasks on their desktop, they tend to spend a considerable amount of time looking back, establishing past references and remembering. A task contains an evolving collection of documents to which the user is referring and that are relevant to the task. In the case of Web documents people tend to rely on their organisational skills and use a variety of \"keeping\" and \"re-finding\" tools which traditionally include bookmarks, history and search, amongst others. This paper reports the results of surveys conducted to investigate the way that people keep and re-find Web based tasks. As tasks can be interrupted or conducted over different sessions a user needs to keep, re-find, and resume them. A prototype called PiMxT is also presented, which uses an incremental density-based clustering approach to automatically generate and keep task-clusters by considering the user's window and tab switching, and re-visitation behaviour. The algorithm attempts to identify those documents that pertain to the same task-cluster, and also when a switch between two documents is effectively a task-switch. PiMxT allows for searching and filtering across the task-clusters as well as task-resumption through different visualisations. This tool was evaluated through a usability study and a questionnaire, and it was found that the time taken by the 15 participants to re-find and resume tasks was on average 44% less in 77% of the cases. Furthermore, although the participants expected PiMxT to be more complete and accurate they all recognised its usefulness.", "references": ["C. Abela, C. Staff, and S. Handschuh. Automatic task-cluster generation based on document switching and revisitation. In Proceedings of the 1st Workshop on Deep Content Analytics Technqiues for Personalized and Intelligent Services, DECAT'15, UMAP'15, 2015.", "C. Abela, C. Staff, and S. Handschuh. Collecting and analysing personal information management data. In Proceedings of the First DIACHRON Workshop on Managing the Evolution and Preservation of the Data Web co-located with 12th European Semantic Web Conference, ESWC'15, pages 22--27, 2015.", "A. Balmin, V. Hristidis, and Y. Papakonstantinou. Objectrank: Authority-based keyword search in databases. In Proceedings of the Thirtieth International Conference on Very Large Data Bases - Volume 30, VLDB '04, pages 564--575. VLDB Endowment, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854966"}, {"title": "Retrieval Models", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915038"}, {"title": "Approximate graph distance with imagisation", "authors": ["Bo Hu"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nGraph similarity can contribute to the solutions of a wide variety of real-life problems. Effective graph similarity measures, therefore, are in high demand in areas such as communication network, biology, medicine, finance, etc. Existing similarity methods present key shortcomings including high run-time computational cost and/or strong dependence on feature selection and feature engineering. Many of existing methods also suffer from ambiguity in the interpretation of resultant measurement.\nIn this paper, we propose a fast approximation of graph similarity grounded on convolutional neural network based image embedding. Graph similarity (distance) is, therefore, translated into the quantitative comparison of the corresponding images faithfully encoding structural information of the graphs. The proposed method is validated with purposely built test data. In addition, we have also carried out a preliminary evaluation, that has demonstrated highly promising results: confirming the viability of proposed \"imagisation\" based graph distance measure.", "references": ["O. Abdel-Hamid, A. rahman Mohamed, H. Jiang, and G. Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In ICASSP, pages 4277--4280. IEEE, 2012.", "S. Basak, V. Magnuson, G. Niemi, and R. Regal. Determining structural similarity of chemicals using graph-theoretic indices. Discrete Applied Mathematics, 19(1):17 -- 44, 1988.", "G. Csardi and T. Nepusz. The igraph software package for complex network research. InterJournal, Complex Systems:1695, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011163"}, {"title": "Who are growth users?: analyzing and predicting intended Twitter user growth", "authors": ["Shuhei Yamamoto\n,", "Kei Wakabayashi\n,", "Noriko Kando\n,", "Tetsuji Satoh"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nTwitter reflects events and trends in users' real lives because many of them post tweets related to their experiences. Many studies have succeeded in detecting events such as earthquakes and influenza epidemics, along with real-life information from a large amount of tweets, by assuming users as social sensors. On the other hand, inactive users who don't engage in posting activity, are increasing according as time progresses. To collect a large amount of tweets based on specific users for successful Twitter studies, we have to know the characteristics of users who are active over long periods of time. In this paper, we clarify the characteristics of growth users over a long time to strategically collect a large amount of specific users' tweets. We explore the status of users who were active in 2012, and classify users into three statuses of Dead, Lock, and Alive. Based on the differences between the numbers of tweets in 2012 and 2016, we further classify alive users into three types of Eraser, Slumber, and Growth. We analyze the characteristic feature values observed in each user behavior and provide interesting findings with each status/type based on GMM clustering and point-wise mutual information. Finally, we propose a growth user prediction method by a simple formula consisting of feature values and evaluate the effectiveness. We found that active users more easily dropped out than inactive users, and users who engaged in reciprocal communications by replies and retweets often became Growth type.", "references": ["J. Prosser, \"Twitter to announce fourth quarter and fiscal year 2015 results.\" https://investor.twitterinc.com/releasedetail.cfm?ReleaseID=948875, Jan. 2016.", "T. Sakaki, M. Okazaki, and Y. Matsuo, \"Earthquake shakes twitter users: Real-time event detection by social sensors,\" in Proc. of WWW2010, pp. 851--860, 2010.", "E. Aramaki, S. Maskawa, and M. Morita, \"Twitter catches the flu: Detecting influenza epidemics using twitter,\" in Proc. of EMNLP2011, pp. 1568--1576, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011145"}, {"title": "Beyond Collaborative Filtering: The List Recommendation Problem", "authors": ["Oren Sar Shalom\n,", "Noam Koenigstein\n,", "Ulrich Paquet\n,", "Hastagiri P. Vanchinathan"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nMost Collaborative Filtering (CF) algorithms are optimized using a dataset of isolated user-item tuples. However, in commercial applications recommended items are usually served as an ordered list of several items and not as isolated items. In this setting, inter-item interactions have an effect on the list's Click-Through Rate (CTR) that is unaccounted for using traditional CF approaches. Most CF approaches also ignore additional important factors like click propensity variation, item fatigue, etc. In this work, we introduce the list recommendation problem. We present useful insights gleaned from user behavior and consumption patterns from a large scale real world recommender system. We then propose a novel two-layered framework that builds upon existing CF algorithms to optimize a list's click probability. Our approach accounts for inter-item interactions as well as additional information such as item fatigue, trendiness patterns, contextual information etc. Finally, we evaluate our approach using a novel adaptation of Inverse Propensity Scoring (IPS) which facilitates off-policy estimation of our method's CTR and showcases its effectiveness in real-world settings.", "references": ["J. Bennett and S. Lanning. The Netflix Prize. In Proc. KDD Cup and Workshop, 2007.", "Haibin Cheng and Erick Cantú-Paz. Personalized click prediction in sponsored search. In Proceedings of the Third ACM International Conference on Web Search and Data Mining, WSDM '10, pages 351--360, 2010.", "Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the 4th ACM Conference on Recommender Systems, pages 39--46, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883057"}, {"title": "Minimizing Legal Exposure of High-Tech Companies through Collaborative Filtering Methods", "authors": ["Bo Jin\n,", "Chao Che\n,", "Kuifei Yu\n,", "Yue Qu\n,", "Li Guo\n,", "Cuili Yao\n,", "Ruiyun Yu\n,", "Qiang Zhang"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nPatent litigation not only covers legal and technical issues, it is also a key consideration for managers of high-technology (high-tech) companies when making strategic decisions. Patent litigation influences the market value of high-tech companies. However, this raises unique challenges. To this end, in this paper, we develop a novel recommendation framework to solve the problem of litigation risk prediction. We will introduce a specific type of patent-related litigation, that is, Section 337 investigations, which prohibit all acts of unfair competition, or any unfair trade practices, when exporting products to the United States. To build this recommendation framework, we collect and exploit a large amount of published information related to almost all Section 337 investigation cases. This study has two aims: (1) to predict the litigation risk in a specific industry category for high-tech companies and (2) to predict the litigation risk from competitors for high-tech companies. These aims can be achieved by mining historical investigation cases and related patents. Specifically, we propose two methods to meet the needs of both aims: a proximal slope one predictor and a time-aware predictor. Several factors are considered in the proposed methods, including the litigation risk if a company wants to enter a new market and the risk that a potential competitor would file a lawsuit against the new entrant. Comparative experiments using real-world data demonstrate that the proposed methods outperform several baselines with a significant margin.", "references": ["S. Bashir and A. Rauber. Improving retrievability of patents in prior-art search. In Advances in Information Retrieval, pages 457--470. Springer, 2010.", "Y. Cao, J. Fan, and G. Li. A user-friendly patent search paradigm. Knowledge and Data Engineering, IEEE Transactions on, 25(6):1439--1443, 2013.", "C. V. Chien. Patent assertion and startup innovation. New America Foundation, Open Technology Institute White Paper, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939708"}, {"title": "Local Item-Item Models For Top-N Recommendation", "authors": ["Evangelia Christakopoulou\n,", "George Karypis"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nItem-based approaches based on SLIM (Sparse LInear Methods) have demonstrated very good performance for top-N recommendation; however they only estimate a single model for all the users. This work is based on the intuition that not all users behave in the same way -- instead there exist subsets of like-minded users. By using different item-item models for these user subsets, we can capture differences in their preferences and this can lead to improved performance for top-N recommendations. In this work, we extend SLIM by combining global and local SLIM models. We present a method that computes the prediction scores as a user-specific combination of the predictions derived by a global and local item-item models. We present an approach in which the global model, the local models, their user-specific combination, and the assignment of users to the local models are jointly optimized to improve the top-N recommendation performance. Our experiments show that the proposed method improves upon the standard SLIM model and outperforms competing top-N recommendation approaches.", "references": ["Cluto clustering toolkit. http://glaros.dtc.umn.edu/gkhome/cluto/cluto/overview.", "Flixster dataset. http://http://www.cs.sfu.ca/~sja25/personal/datasets/.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959185"}, {"title": "InfoScout: An Interactive, Entity Centric, Person Search Tool", "authors": ["Sean McKeown\n,", "Martynas Buivys\n,", "Leif Azzopardi"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIndividuals living in highly networked societies publish a large amount of personal, and potentially sensitive, information online. Web investigators can exploit such information for a variety of purposes, such as in background vetting and fraud detection. However, such investigations require a large number of expensive man hours and human effort. This paper describes InfoScout, a search tool which is intended to reduce the time it takes to identify and gather subject centric information on the Web. InfoScout collects relevance feedback information from the investigator in order to re-rank search results, allowing the intended information to be discovered more quickly. Users may still direct their search as they see fit, issuing ad-hoc queries and filtering existing results by keywords. Design choices are informed by prior work and industry collaboration.", "references": ["E. J. Appel. Internet Searches for Vetting, Investigations, and Open-source Intelligence. Taylor and Francis Group, 2011.", "S. Attfield and A. Blandford. Improving the cost structure of sensemaking tasks: Analysing user concepts to inform information system design. In Proc. of INTERACT '09, page 532--545, 2009.", "Department of Homeland Security. DHS terrorist use of social networking facebook case study bar public intelligence, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911468"}, {"title": "Do Textual Descriptions Help Action Recognition?", "authors": ["Matteo Bruni\n,", "Tiberio Uricchio\n,", "Lorenzo Seidenari\n,", "Alberto Del Bimbo"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present a novel method to improve action recognition by leveraging a set of captioned videos. By learning linear projections to map videos and text onto a common space, our approach shows that improved results on unseen videos can be obtained. We also propose a novel structure preserving loss that further ameliorates the quality of the projections. We tested our method on the challenging, realistic, Hollywood2 action recognition dataset where a considerable gain in performance is obtained. We show that the gain is proportional to the number of training samples used to learn the projections.", "references": ["L. Ballan, T. Uricchio, L. Seidenari, and A. Del Bimbo. A cross-media model for automatic image annotation. In Proc. of ICMR. ACM, 2014.", "P. Das, C. Xu, R. Doell, and J. Corso. A thousand frames in just a few words: Lingual description of videos through latent topics and sparse object stitching. In Proc. of the CVPR, pages 2634--2641, 2013.", "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967301"}, {"title": "Audio Blind Watermarking Robust Against HE-AAC", "authors": ["Donghwan Shin\n,", "Yiyu Hong\n,", "Jongweon Kim\n,", "Jonguk Choi"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn this paper, we propose a replica based audio blind watermarking algorithm which is robust against High Efficiency Advanced Audio Coding (HE-AAC). The algorithm embeds watermarks by modulating normalized correlation of original signal and its delayed version. The modulation can be done by adding modulated replica signal at a specified delay to the host signal. The watermark embedding strength is determined by signal-to-noise ratio (SNR) before and after HE-AAC compression. And a feedback process is implemented to ensure the watermark embedding strength has achieved. Experimental results show the proposed watermarking algorithm highly robust to HE-AAC compression while maintaining good imperceptibility.", "references": ["Herre, J., and Dietz, M. 2008. Standards in a nutshell: MPEG-4 high-efficiency AAC coding. IEEE Signal Processing Magazine. 25, 3 (May. 2008), 137--142.", "Cox, I., Kilian, J., Leighton, T., and Shamoon, T. 1997. Secure Spread Spectrum Watermarking for Multimedia. IEEE Transactions on Image Processing. 6, 12 (Dec. 1997), 1673--1687.", "Senbin, Y., Wei T., Yanpu C., and Wenjun, M. 2010. Quantization-Based Digital Audio Watermarking in Discrete Fourier Transform Domain. Journal of Multimedia. 5, 2(Apr. 2010), 151--158."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015189"}, {"title": "Calls from the Wild: Engaging Citizen Scientist with Animal Sounds", "authors": ["Jessica L. Cappadonna\n,", "Margot Brereton\n,", "David M. Watson\n,", "Paul Roe"], "publication": "DIS '16 Companion: Proceedings of the 2016 ACM Conference Companion Publication on Designing Interactive Systems", "abstract": "ABSTRACT\nSound allows people to intimately relate to nature. When people search for wildlife they often rely on their expert knowledge to recognise animal calls. The process of learning these calls involves social engagement and repeated identification in situ. Rare, cryptic, and migratory animals, however, are difficult to hear when people are only at a given location for minutes or hours. This makes many species difficult to study on a large scale, further confounded because human presence may disturb individual animals and reduce their likelihood of detection.\nAcoustic monitoring has great potential to engage people with animal calls. It can reveal hidden subtleties of animal lives and allow the health of populations to be monitored over long periods. Here, we explore new ways to engage people with natural sounds. We begin with an exploration of the artefacts and practices of birdwatchers, and then online citizen scientists (voluntary contributors to scientific research). Next, we consider how these practices can extend to design novel, interactive user interfaces for people to listen to calls from the wild and make ecological discoveries. \\", "references": ["Joe Cox, Eun Young Oh, Brooke Simmons, Chris Lintott, Karen Masters, Anita Greenhill, Gary Graham and Kate Holmes. 2015. Defining and Measuring Success in Online Citizen Science: A Case Study of Zooniverse Projects. Computing in Science & Engineering, 17, 4: 28--41.", "Mark Cottman-Fields, Margot Brereton, and Paul Roe. 2013. Virtual birding: extending an environmental pastime into the virtual world for citizen science. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13), 2029--2032. http://dx.doi.org/10.1145/2470654.2466268", "Elizabeth R. Ellwood, Betty A. Dunckel, Paul Flemons, Robert Guralnick, Gil Nelson, Greg Newman, Sarah Newman, Deborah Paul, Greg Riccardi, Nelson Rios, Katja C. Seltmann, and Austin R. Mast. 2015. Accelerating the Digitization of Biodiversity Research Specimens through Online Public Participation. BioScience, 65, 4: 383--396."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908805.2909413"}, {"title": "CBufs: efficient, system-wide memory management and sharing", "authors": ["Yuxin Ren\n,", "Gabriel Parmer\n,", "Teo Georgiev\n,", "Gedare Bloom"], "publication": "ISMM 2016: Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management", "abstract": "ABSTRACT\nModern systems are composed of many different protection domains separating privilege levels, subsystems, users, clients, and software of differing levels of assurance. System-wide memory management must consider not only allocation to single processes, but also efficient sharing of data across protection domains, and the allocation of memory based on the performance of applications that span multiple protection domains. This paper introduces the CBuf system for the global management of virtual and physical memory, including zero-copy sharing between protection domains. We present the design and implementation of both garbage collection techniques to enable efficient sharing, and policies that balance memory between protection domains specifically to satisfy system and application constraints such as quality of service. We show that a CBuf-enabled webserver achieves over a factor of 2.5 throughput speedup while using less processing time than Apache on Linux, and that the system can intentionally control system throughput through intelligent memory allocation.", "references": ["G. Banga, P. Druschel, and J. C. Mogul. Resource containers: a new facility for resource management in server systems. In Proceedings of the third symposium on Operating systems design and implementation (OSDI), 1999.", "A. Baumann, C. Hawblitzel, K. Kourtis, T. Harris, and T. Roscoe. Cosh: Clear os data sharing in an incoherent world. In 2014 Conference on Timely Results in Operating Systems (TRIOS 14), 2014.", "A. Belay, G. Prekas, A. Klimovic, S. Grossman, C. Kozyrakis, and E. Bugnion. Ix: A protected dataplane operating system for high throughput and low latency. In Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926697.2926703"}, {"title": "Improving change recommendation using aggregated association rules", "authors": ["Thomas Rolfsnes\n,", "Leon Moonen\n,", "Stefano Di Alesio\n,", "Razieh Behjati\n,", "Dave Binkley"], "publication": "MSR '16: Proceedings of the 13th International Conference on Mining Software Repositories", "abstract": "ABSTRACT\nPast research has proposed association rule mining as a means to uncover the evolutionary coupling from a system's change history. These couplings have various applications, such as improving system decomposition and recommending related changes during development. The strength of the coupling can be characterized using a variety of interestingness measures. Existing recommendation engines typically use only the rule with the highest interestingness value in situations where more than one rule applies. In contrast, we argue that multiple applicable rules indicate increased evidence, and hypothesize that the aggregation of such rules can be exploited to provide more accurate recommendations.\nTo investigate this hypothesis we conduct an empirical study on the change histories of two large industrial systems and four large open source systems. As aggregators we adopt three cumulative gain functions from information retrieval. The experiments evaluate the three using 39 different rule interestingness measures. The results show that aggregation provides a significant impact on most measure's value and, furthermore, leads to a significant improvement in the resulting recommendation.", "references": ["R. Agrawal, T. Imielinski, and A. Swami. \"Mining association rules between sets of items in large databases\". In: ACM SIGMOD International Conference on Management of Data. ACM, 1993, pp. 207--216.", "T. Ball, J. Kim, and H. P. Siy. \"If your version control system could talk\". In: ICSE Workshop on Process Modelling and Empirical Studies of Software Engineering. 1997.", "E. Baralis et al. \"Generalized association rule mining with constraints\". In: Information Sciences 194 (2012), pp. 68--84."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901739.2901756"}, {"title": "High Enough?: Explaining and Predicting Traveler Satisfaction Using Airline Reviews", "authors": ["Emanuel Lacic\n,", "Dominik Kowald\n,", "Elisabeth Lex"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nAir travel is one of the most frequently used means of transportation in our every-day life. Thus, it is not surprising that an increasing number of travelers share their experiences with airlines and airports in form of online reviews on the Web. In this work, we thrive to explain and uncover the features of airline reviews that contribute most to traveler satisfaction. To that end, we examine reviews crawled from the Skytrax air travel review portal. Skytrax provides four review categories to review airports, lounges, airlines and seats. Each review category consists of several five-star ratings as well as free-text review content. In this paper, we conduct a comprehensive feature study and we find that not only five-star rating information such as airport queuing time and lounge comfort highly correlate with traveler satisfaction but also inferred features in the form of the review text sentiment. Based on our findings, we create classifiers to predict traveler satisfaction using the best performing rating features. Our results reveal that given our methodology, traveler satisfaction can be predicted with high accuracy. Additionally, we find that training a model on the sentiment of the review text provides a competitive alternative when no five-star rating information is available. We believe that our work is of interest for researchers in the area of modeling and predicting user satisfaction based on available review data on the Web.", "references": ["L. Breiman, J. Friedman, C. J. Stone, and R. A. Olshen. Classification and regression trees. CRC press, 1984.", "P. Chatterjee. Online reviews: do consumers use them? Advances in Consumer Research, 2001.", "P.-Y. Chen, S.-y. Wu, and J. Yoon. The impact of online recommendations and consumer feedback on sales. ICIS 2004 Proceedings, page 58, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914629"}, {"title": "Opinion retrieval in Twitter: is proximity effective?", "authors": ["Anastasia Giachanou\n,", "Fabio Crestani"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nTwitter has become an important communication tool for people to share information and opinions. Although Twitter contains a large amount of opinions on various topics, it is very difficult to extract useful information from the vast amount of available data. The aim of this study is twofold. First, we make an analysis of the topical distribution of tweets with the aim to investigate if an individual tweet deals with a single or multiple topics. This information is very useful for addressing Twitter opinion retrieval. Second, we examine if proximity-based opinion retrieval is effective when it is applied in Twitter. The result of our study shows that the majority of tweets deal with a single topic, which is reasonable considering the short length of a tweet. Also, we show that proximity-based method for Twitter opinion retrieval is not so effective as in blogs since it performs similarly to less sophisticated opinion retrieval methods.", "references": ["D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "S. Gerani, M. Carman, and F. Crestani. Aggregation methods for proximity-based opinion retrieval. ACM Transactions on Information Systems (TOIS), 30(4):1--36, Nov. 2012.", "T. Hofmann. Probabilistic Latent Semantic Indexing. In SIGIR'99, pages 50--57, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851818"}, {"title": "Memory Power Management for Java Processors Using Heap Partitioning and Power Gating", "authors": ["Ricardo Gomez\n,", "Flavius Gruian\n,", "Liang Liu"], "publication": "JTRES '16: Proceedings of the 14th International Workshop on Java Technologies for Real-Time and Embedded Systems", "abstract": "ABSTRACT\nPower consumption is an important design parameter for battery operated devices, and an especially sensitive issue in embedded Java systems. This paper presents a solution to reduce leakage power consumption of the heap memory characteristic of Java processors. By partitioning the heap into several memory banks and taking advantage of a compacting garbage collector, our method dynamically powers off inactive regions.\nThe technique has been designed and evaluated for JOP, a Java Optimized Processor [14], and further implemented and verified in a 65nm CMOS technology using STM low-power high Vt (LPHVT) [16] standard cell libraries. Experiments show that our method accurately follows the memory utilization profile in powering on and off banks, achieving at least 50% leakage power reduction. The performance, area and power penalty introduced by the additional hardware are negligible.", "references": ["G. Chen, R. Shetty, M. Kandemir, N. Vijaykrishnan, M. J. Irwin, and M. Wolczko. Tuning garbage collection in an embedded java environment. In High-Performance Comp. Arch., 2002. Proc. Eighth Int. Symp. on, pages 92--103, Feb. 2002.", "C. J. Cheney. A nonrecursive list compacting algorithm. Commun. ACM, 13(11):677--678, Nov. 1970.", "V. Delaluz, M. Kandemir, N. Vijaykrishnan, A. Sivasubramaniam, and M. J. Irwin. Dram energy management using software and hardware directed power mode control. In High-Performance Comp. Arch., 2001. HPCA. The Seventh Int. Symp. on, pages 159--169, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2990509.2990514"}, {"title": "Sentiment analysis from textual to multimodal features in digital environments", "authors": ["Maria Chiara Caschera\n,", "Fernando Ferri\n,", "Patrizia Grifoni"], "publication": "MEDES: Proceedings of the 8th International Conference on Management of Digital EcoSystems", "abstract": "ABSTRACT\nWhen social networks actors are involved in the production, consumption and exchange of content and information by texts, images, audios, videos, they act in a shared digital environment that can be considered as a digital ecosystem. On the increasing size of produced data, an open issue is the understanding of the real sentiment and emotion from texts, but also from images, audios and videos. This issue is particularly relevant for monitoring and identifying critical situations and suspicious behaviours. This paper is an attempt to review and evaluate the various techniques used for sentiment and emotion analysis from text, audio and video, and to discuss the main challenges addressed in extracting sentiment from multimodal data. The paper concludes the discussion by proposing a method that combines a machine learning approach with a language-based formalization in order to extract sentiment from multimodal data formalized through a multimodal language.", "references": ["Saleh, M., Abel, M.-H., Misseri, V. 2015. Investigating the similarity between collaboration systems and digital ecosystems. 2015 IEEE 19th International Conference on Computer Supported Cooperative Work in Design (CSCWD 2015). 30--35.", "Yates, D. and Paquette, S. 2011. Emergency knowledge management and social media technologies: A case study of the 2010 haitian earthquake. International Journal of Information Management. vol. 31, no. 1. 6--13.", "Singh P. K., and Husain, M. S. 2014. Methodological study of opinion mining and sentiment analysis techniques. International Journal on Soft Computing (IJSC). Vol. 5, No. 1. 11--21."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012071.3012089"}, {"title": "Knowledge exploration using tables on the web", "authors": ["Fernando Chirigati\n,", "Jialu Liu\n,", "Flip Korn\n,", "You (Will) Wu\n,", "Cong Yu\n,", "Hao Zhang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe increasing popularity of mobile device usage has ushered in many features in modern search engines that help users with various information needs. One of those needs is Knowledge Exploration, where related documents are returned in response to a user query, either directly through right-hand side knowledge panels or indirectly through navigable sections underneath individual search results. Existing knowledge exploration features have relied on a combination of Knowledge Bases and query logs.\nIn this paper, we propose Knowledge Carousels of two modalities, namely sideways and downwards, that facilitate exploration of IS-A and HAS-A relationships, respectively, with regard to an entity-seeking query, based on leveraging the large corpus of tables on the Web. This brings many technical challenges, including associating correct carousels with the search entity, selecting the best carousel from the candidates, and finding titles that best describe the carousel. We describe how we address these challenges and also experimentally demonstrate through user studies that our approach produces better result sets than baseline approaches.", "references": ["G. Agarwal, G. Kabra, and K. C.-C. Chang. Towards Rich Query Interpretation: Walking Back and Forth for Mining Query Templates. In WWW, 2010.", "S. Balakrishnan, A. Y. Halevy, B. Harb, H. Lee, J. Madhavan, A. Rostamizadeh, W. Shen, K. Wilder, F. Wu, and C. Yu. Applying WebTables in Practice. In CIDR, 2015.", "S. Bergsma and Q. I. Wang. Learning Noun Phrase Query Segmentation. In EMNLP, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3021924.3021935"}, {"title": "Sentiment analysis in tickets for IT support", "authors": ["Cássio Castaldi Araujo Blaz\n,", "Karin Becker"], "publication": "MSR '16: Proceedings of the 13th International Conference on Mining Software Repositories", "abstract": "ABSTRACT\nSentiment analysis has been adopted in software engineering for problems such as software usability and sentiment of developers in open-source projects. This paper proposes a method to evaluate the sentiment contained in tickets for IT (Information Technology) support.IT tickets are broad in coverage (e.g. infrastructure, software), and involve errors, incidents, requests, etc. The main challenge is to automatically distinguish between factual information, which is intrinsically negative (e.g. error description), from the sentiment embedded in the description. Our approach is to automatically create a Domain Dictionary that contains terms with sentiment in the IT context, used to filter terms in ticket for sentiment analysis. We experiment and evaluate three approaches for calculating the polarity of terms in tickets. Our study was developed using 34,895 tickets from five organizations, from which we randomly selected 2,333 tickets to compose a Gold Standard. Our best results display an average precision and recall of 82.83% and 88.42%, which outperforms the compared sentiment analysis solutions.", "references": ["S. Baccianella, A. Esuli, and F. Sebastiani. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proc. of the International Conference on Language Resources and Evaluation (LREC), Valletta, Malta, 2010.", "A. Balahur, R. Steinberger, M. Kabadjov, V. Zavarella, E. Van Der Goot, M. Halkia, B. Pouliquen, and J. Belyaeva. Sentiment analysis in the news. In Proc. of the International Conference on Language Resources and Evaluation (LREC), 2010, Valletta, Malta, volume 10, page 2216, 2010.", "A. Balahur and M. Turchi. Comparative experiments using supervised learning and machine translation for multilingual sentiment analysis. Computer Speech & Language, 28(1):56--75, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901739.2901781"}, {"title": "Session details: Main Track - Methodologies and Approaches for IS (II)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255990"}, {"title": "An Approach to Generate Process-oriented Text from Natural Language", "authors": ["Renato C.B. Ferreira\n,", "Lucineia H. Thom"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nIn organizations, the business process modeling is of big importance to report, understand and automate processes. These organizations usually come unstructured documents and difficult to understand by analysts. The extraction models or fragments process from textual descriptions may contribute to minimizing the effort required to process modeling. In this context, this paper proposes an approach to generate text-oriented process from the text in natural language. This paper proposes to investigate the structure of a text in natural language must show to from this one can extract fragments or process models. Based on the study of grammar classes accomplished in the context of this research, there is no established or standardized order in which the grammar classes should be shown in the text in natural language. Thus, preliminary results of this research show that by mapping rules and correlations between words represent the grammatical classes indicate a process element, through keywords and/or verb tenses.", "references": ["W. M. Coalition. Wfmc: Process definition language: Xpdl 2.0. page 164, 2005.", "M. Dumas, M. L. Rosa, J. Mendling, and H. A. Reijers. Fundamentals of Business Process Management. Springer, 2013.", "F. Friedrich, J. Mendling, and F. Puhlmann. Process model generation from natural language text. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022054"}, {"title": "Comparison of Frequency Selective Extrapolation and Patch Matching Algorithm for Error Concealment in Spatial Domain", "authors": ["P. K. Rajani\n,", "Arti Khaparde"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nError Concealment (EC) is a popular technique at the decoder side to removing the transmission errors. It is done analyzing the spatial or temporal information from available image regions. Many researches are going on based on this due to its application in different fields such as video-telephone, video-conference, TV, DVD, internet video etc. According to literature survey, there are various types of spatial error concealment techniques such as tensor voting based, interpolation based, stochastic based, etc. In this paper exemplar based error concealment algorithm is compared with Frequency Selective Extrapolation algorithm. Both the works are based on concealment of manually created images or error video frames as input. The parameter used for objective quality measurement was PSNR (Peak Signal to Noise Ratio). The test frame with different error patches are compared with both the Error concealment algorithms. According to simulation results, Frequency Selective Extrapolation is better than patch matching algorithm in terms of both subjective and objective quality of the images or error video frames.", "references": ["Agus Zainal Ari_n, Akira Asano, \"Image segmentation by histogram thresholding using hierarchical cluster analysis\", in Pattern Recognition, in science direct., 2006.", "Jiaya Jia, Chi-Keung Tang, \"Inference of Segmented Color and Texture Description by Tensor Voting.\", in IEEE Transactions on pattern analysis and machine intelligence, Vol. no. 26, 6 June 2004.", "Katrin Meisinger and Andre Kaup, \"Spatial Error Concealment of Corrupted Image Data Using Frequency Selective Extrapolation\", in Acostics, Speech and Signal Processing, Proceedings(ICASSP04) IEEE conference 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015202"}, {"title": "Session details: Main Track - Intelligent Systems (I)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255981"}, {"title": "Cross-supervised synthesis of web-crawlers", "authors": ["Adi Omari\n,", "Sharon Shoham\n,", "Eran Yahav"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering", "abstract": "ABSTRACT\nA web-crawler is a program that automatically and systematically tracks the links of a website and extracts information from its pages. Due to the different formats of websites, the crawling scheme for different sites can differ dramatically. Manually customizing a crawler for each specific site is time consuming and error-prone. Furthermore, because sites periodically change their format and presentation, crawling schemes have to be manually updated and adjusted. In this paper, we present a technique for automatic synthesis of web-crawlers from examples. The main idea is to use hand-crafted (possibly partial) crawlers for some websites as the basis for crawling other sites that contain the same kind of information. Technically, we use the data on one site to identify data on another site. We then use the identified data to learn the website structure and synthesize an appropriate extraction scheme. We iterate this process, as synthesized extraction schemes result in additional data to be used for re-learning the website structure. We implemented our approach and automatically synthesized 30 crawlers for websites from nine different categories: books, TVs, conferences, universities, cameras, phones, movies, songs, and hotels.", "references": ["An, Y. J., Geller, J., Wu, Y.-T., and Chun, S. Semantic deep web: automatic attribute extraction from the deep web data sources. In Proceedings of the 2007 ACM symposium on Applied computing (2007), ACM, pp. 1667--1672.", "Arasu, A., and Garcia-Molina, H. Extracting structured data from web pages. In Proceedings of the 2003 ACM SIGMOD international conference on Management of data (2003), ACM, pp. 337--348.", "Chang, C.-H., and Lui, S.-C. IEPAD: Information extraction based on pattern discovery. In Proceedings of the 10th International Conference on World Wide Web (2001), WWW '01, pp. 681--688."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2884781.2884842"}, {"title": "Cross-modal Retrieval with Label Completion", "authors": ["Xing Xu\n,", "Fumin Shen\n,", "Yang Yang\n,", "Heng Tao Shen\n,", "Li He\n,", "Jingkuan Song"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nCross-modal retrieval has been attracting increasing attention because of the explosion of multi-modal data, e.g., texts and images. Most supervised cross-modal retrieval methods learn discriminant common subspaces minimizing the heterogeneity of different modalities by exploiting the label information. However, these methods neglect the fact that, in practice, the given labels of training data might be incomplete (i.e., some of their labels are missing). The low-quality labels result in less effective subspace and consequent unsatisfactory retrieval performance. To tackle this, we propose a novel model that simultaneously performs label completion and cross-modal retrieval. Specifically, we assume the to-be-learned common subspace can be jointly derived through two aspects: 1) linear projection from modality-specific features and 2) enriching mapping from the incomplete labels. We thus formulate the subspace learning problem as a co-regularized learning framework based on multi-modal features and incomplete labels. Extensive experiments on two large-scale multi-modal datasets demonstrate the superiority of our model for both label completion and cross-modal retrieval over the state-of-the-arts.", "references": ["D. M. Blei and M. I. Jordan. Modeling annotated data. In ACM SIGIR, pages 127--134, 2003.", "M. Chen, A. Zheng, and K. Weinberger. Fast image tagging. In ICML, pages 1274--1282, 2013.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In CIVR, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967231"}, {"title": "A Computational Approach to Finding Facial Patterns of a Babyface", "authors": ["Zi-Yi Ke\n,", "Mei-Chen Yeh"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nFacial babyishness has a strong impact on social perceptions and interactions; however, the components constituting a babyface remain unclear. In this paper, we present a computational approach for identifying important but less apparent facial patterns of a babyface, using voluminous face images on the web. The proposed approach is built upon computationally efficient data mining techniques. A new image set with ground truth data collected from users and an evaluation approach based on age estimation are presented in the experiment. The results show that the mined patterns are effective for understanding and determining babyfaces. The findings of this study should provide information for future investigations on the prediction and analysis of trait impressions using the patterns.", "references": ["R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In Proc. of ACM Intfl Conf. SIGMOD, 1993.", "D. S. Berry and L. Z. McArthur. Some components and consequences of a babyface. Journal of Personality and Social Psychology, 48:312--323, 1985.", "T. Horprasert, Y. Yacoob, and L. Davis. Computing 3-d head orientation from a monocular image sequence. In Proc. of IEEE Intfl Conf. Automatic Face and Gesture Recognition, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912042"}, {"title": "Leveraging a Graph-Powered, Real-Time Recommendation Engine to Create Rapid Business Value", "authors": ["Adam Anthony\n,", "Yu-Keng Shih\n,", "Ruoming Jin\n,", "Yang Xiang"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nDeployment of open source recommendation systems has been shown to be an effective way to increase sale conversions on a variety of e-commerce sites. However, there remains a large gap between deploying the core algorithm provided by these systems and delivering an application-quality recommendation system, specifically tailored to address complex and dynamically changing business needs. We will present a real-time recommendation engine built on our graph data platform that provides the following extensions to a basic recommendation model: True real-time recommendation algorithms: We provide a simple framework for customers to author and deploy real-time recommendation algorithms with no pre-computation required. Streaming updates of user behavior and product information: As quickly as data are generated, the recommendation engine applies the updates and can serve updated results. Support for offline recommendation algorithms}: Users with existing investment in a quality recommendation program can import their pre-computed results into the graph database for efficient, unified service of results. Tools for Business-centric requirements: The engine offers a range of weighting, sorting, and filtering options to tailor recommendation algorithms to business needs. For example, the engine can eliminate products that are out of stock or favor products that are known to perform well in different real-time contexts. Multiple algorithm ensemble support: There is rarely a case where one algorithm is sufficient to identify the best items to recommend to a user. Integrating points 1 through 4, the engine provides intuitive methods for specifying and combining the results of multiple recommendation algorithms to achieve the highest-performing results. Recommendation feedback tools: Pre- and Post-analysis tools, built around a business' logic, are used to generate reports to assess the value of both potential and currently deployed algorithms.\nOf particular interest to RecSys attendees, we will discuss the technical aspects of a graph-based implementation of the recommendation engine and how it facilitates the rapid design and deployment of an efficient real-time recommendation system under a single service. We will briefly discuss the architecture of our graph database system to show how it can efficiently serve a large user base even from a single server shared-memory architecture. Attendees will also learn about graph-based data modeling and how viewing data from this perspective can lead to new types of business insights and applications that are not easily implemented using traditional relational and/or NoSQL platforms. We will conclude with a brief demonstration of a real deployed application UI to demonstrate the ease by which recommendation systems can be implemented and deployed using the engine.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959126"}, {"title": "Visualizing co-authorship networks for actionable insights: action design research experiment", "authors": ["Jukka Huhtamäki"], "publication": "AcademicMindtrek '16: Proceedings of the 20th International Academic Mindtrek Conference", "abstract": "ABSTRACT\nIncreasing interest has been expressed in lowering the barrier for research access. Several approaches exist, including more active communication on research, the use of social computing-oriented networking tools for researchers, parallel publishing of research publications, and the use of research management systems for collecting, managing, and publishing bibliographical data. In this paper, we target the first step of research access, namely the use of publication metadata available in current research information systems. More specifically, we will take an action design research approach to experiment how visual network analytics could be used to create additional value for bibliographical data. We will tap into the current research information system of a selected university to develop a prototype of a self-service co-authorship network visualization and engage with four researchers to identify the key requirements for taking such an approach and to explore the potential value that could be created with visual analytics of bibliographical data. We contribute a set of design guidelines to support the development of computational visual network analytics tools for research collaboration analyses using bibliographical data.", "references": ["R. C. Basole. Visualization of interfirm relations in a converging mobile ecosystem. Journal of Information Technology, 24(2):144--159, June 2009.", "M. Bastian, S. Heymann, and M. Jacomy. Gephi: An Open Source Software for Exploring and Manipulating Networks. In Proceedings of International AAAI Conference on Weblogs and Social Media, San Jose, California, USA, May 2009.", "T. Berners-Lee. Linked Data - Design Issues, July 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994310.2994340"}, {"title": "Profiling MOOC Course Returners: How Does Student Behavior Change Between Two Course Enrollments?", "authors": ["Vitomir Kovanović\n,", "Srećko Joksimović\n,", "Dragan Gašević\n,", "James Owers\n,", "Anne-Marie Scott\n,", "Amy Woodgate"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nMassive Open Online Courses represent a fertile ground for examining student behavior. However, due to their openness MOOC attract a diverse body of students, for the most part, unknown to the course instructors. However, a certain number of students enroll in the same course multiple times, and there are records of their previous learning activities which might provide some useful information to course organizers before the start of the course. In this study, we examined how student behavior changes between subsequent course offerings. We identified profiles of returning students and also interesting changes in their behavior between two enrollments to the same course. Results and their implications are further discussed.", "references": ["Doug Clow. 2013. MOOCs and the Funnel of Participation. Proceedings of the Third International Conference on Learning Analytics and Knowledge, ACM, 185--189.", "R.F.a Kizilcec and E.b Schneider. 2015. Motivation as a lens to understand online learners: Toward data-driven design with the OLEI scale. ACM Transactions on Computer-Human Interaction 22, 2.", "Vitomir Kovanović, Dragan Gašević, Sreško Joksimović, Marek Hatala, and Olusola Adesope. 2015. Analytics of communities of inquiry: Effects of learning technology use on cognitive presence in asynchronous online discussions. The Internet and Higher Education 27: 74--89."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893431"}, {"title": "Time Series Analysis Using NOC", "authors": ["Noriaki Kawamae"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe present a time series analysis employing natural language processing (NLP) techniques, and show the effect of N-gram over Context (NOC), that is a one of topic models that enjoy success in NLP, in this analysis.", "references": ["D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "D. A. Huffman. A method for the construction of minimum-redundancy codes. In Proceedings of the Institution of Radio Engineers, pages 1098--1101, 1952.", "S. Jameel and W. Lam. An unsupervised topic segmentation model incorporating word order. In SIGIR, pages 203--312, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889396"}, {"title": "Identifying Web Queries with Question Intent", "authors": ["Gilad Tsur\n,", "Yuval Pinter\n,", "Idan Szpektor\n,", "David Carmel"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nVertical selection is the task of predicting relevant verticals for a Web query so as to enrich the Web search results with complementary vertical results. We investigate a novel variant of this task, where the goal is to detect queries with a question intent. Specifically, we address queries for which the user would like an answer with a human touch. We call these CQA-intent queries, since answers to them are typically found in community question answering (CQA) sites. A typical approach in vertical selection is using a vertical's specific language model of relevant queries and computing the query-likelihood for each vertical as a selective criterion. This works quite well for many domains like Shopping, Local and Travel. Yet, we claim that queries with CQA intent are harder to distinguish by modeling content alone, since they cover many different topics. We propose to also take the structure of queries into consideration, reasoning that queries with question intent have quite a different structure than other queries. We present a supervised classification scheme, random forest over word-clusters for variable length texts, which can model the query structure. Our experiments show that it substantially improves classification performance in the CQA-intent selection task compared to content-oriented based classification, especially as query length grows.", "references": ["J. Arguello, J. Callan, and F. Diaz. Classification-based resource selection. In Proceedings of CIKM'09, pages 1277--1286. ACM, 2009.", "J. Arguello, F. Diaz, J. Callan, and J.-F. Crespo. Sources of evidence for vertical selection. In Proceedings of SIGIR'09, pages 315--322. ACM, 2009.", "J. Arguello, F. Diaz, and J.-F. Paiement. Vertical selection in the presence of unlabeled verticals. In Proceedings of SIGIR'10, pages 691--698. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883058"}, {"title": "Automated Intrinsic Text Classification for Component Content Management Applications in Technical Communication", "authors": ["Jan Oevermann\n,", "Wolfgang Ziegler"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nClassification models are used in component content management to identify content components for retrieval, reuse and distribution. Intrinsic metadata, such as the assigned information class, play an important role in these tasks. With the increasing demand for efficient classification of content components, the sector of technical documentation needs mechanisms that allow for an automation of such tasks. Vector space model based approaches can lead to sufficient results, while maintaining good performance, but they must be adapted to the peculiarities that characterize modular technical documents.\nIn this paper we will present domain specific differences, as well as characteristics, that are special to the field of technical documentation and derive methods to adapt widespread classification and retrieval techniques for these tasks. We verify our approach with data provided from companies in the sector of manufacturing and mechanical engineering and use it for supervised learning and automated classification.", "references": ["2006/42/EC. Machinery Directive of the European Parliament and of the Council, 2006.", "ANSI Z535.6. American National Standard for Product Safety Information in Product Manuals, Instructions, and Other Collateral Materials, 2006.", "C. H. Caldas, L. Soibelman, and J. Han. Automated Classification of Construction Project Documents. Journal of Computing in Civil Engineering, 16(4):234--243, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967153"}, {"title": "RecSys Challenge 2016: job recommendations based on preselection of offers and gradient boosting", "authors": ["Andrzej Pacuk\n,", "Piotr Sankowski\n,", "Karol Węgrzycki\n,", "Adam Witkowski\n,", "Piotr Wygocki"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nWe present the Mim-Solution's approach to the RecSys Challenge 2016, which ranked 2nd. The goal of the competition was to prepare job recommendations for the users of the website Xing.com.\nOur two phase algorithm consists of candidate selection followed by the candidate ranking. We ranked the candidates by the predicted probability that the user will positively interact with the job offer. We have used Gradient Boosting Decision Trees as the regression tool.", "references": ["T. Chen and C. Guestrin. Xgboost: A scalable tree boosting system. CoRR, abs/1603.02754, 2016.", "P. Romov and E. Sokolov. Recsys challenge 2015: Ensemble learning with categorical features. In Proceedings of the 2015 International ACM Recommender Systems Challenge, RecSys '15 Challenge, pages 1:1--1:4, New York, NY, USA, 2015. ACM.", "M. Volkovs. Two-stage approach to item recommendation from user sessions. In Proceedings of the 2015 International ACM Recommender Systems Challenge, RecSys '15 Challenge, pages 3:1--3:4, New York, NY, USA, 2015. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987544"}, {"title": "Low-cost Semantic Enhancement to Digital Library Metadata and Indexing: Simple Yet Effective Strategies", "authors": ["Annika Hinze\n,", "David Bainbridge\n,", "Sally Jo Cunningham\n,", "J. Stephen Downie"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nMost existing digital libraries use traditional lexically-based retrieval techniques. For established systems, completely replacing, or even making significant changes to the document retrieval mechanism (document analysis, indexing strategy, query processing and query interface) would require major technological effort, and would most likely be disruptive. In this paper, we describe ways to use the results of semantic analysis and disambiguation, while retaining an existing keyword-based search and lexicographic index. We engineer this so the output of semantic analysis (performed off-line) is suitable for import directly into existing digital library metadata and index structures, and thus incorporated without the need for architecture modifications.", "references": ["H. B. Guppy. Coral islands and savage myths. Victoria Institute and Philosophical Society of Great Britain, London, 1889.", "A. Hinze, M. Coleman, S. J. Cunningham, and D. Bainbridge. A semantic bookworm: mining literary resources revisited. In JCDL '16. ACM, 2016.", "A. Hinze, C. Taube-Schock, D. Bainbridge, R. Matamua, and J. S. Downie. Improving access to large-scale digital libraries through semantic-enhanced search and disambiguation. In JCDL '15, pages 147--156. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910910"}, {"title": "Towards linked open data enabled ontology learning from text", "authors": ["Meisam Booshehri\n,", "Peter Luksch"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThe artifacts produced by current (semi-)automatic methods of ontology learning from text have yet to be improved so that they can provide significant support in creating rich and expressive ontologies. Hence, it is our goal in this study to explore ways to create much more enriched ontologies. In this short paper, we discuss the hypotheses of a PhD work, which addresses the problem of how to reuse the freely available knowledge in Linked Open Data as background knowledge beside text in order to extract new ontological or assertional knowledge for creating a more enriched ontology. In other words, we hypothesize that by using the extra knowledge in large RDF datasets in Linked Open Data cloud, the functions associated with the layers of Ontology Learning Stack could be improved, resulting in more enriched ontologies.", "references": ["Vrandečić, D. Ontology Evaluation. PhD Thesis, Karlsruhe Institute of Technology (KIT), 2010.", "Völker, J., Haase, P. and Hitzler, P. Learning expressive ontologies. IOS Press, 2009.", "Buitelaar, P. and Cimiano, P. Ontology learning and population: bridging the gap between text and knowledge. IOS Press, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011184"}, {"title": "CompanyDepot: Employer Name Normalization in the Online Recruitment Industry", "authors": ["Qiaoling Liu\n,", "Faizan Javed\n,", "Matt Mcnair"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nEntity linking links entity mentions in text to the corresponding entities in a knowledge base (KB) and has many applications in both open domain and specific domains. For example, in the recruitment domain, linking employer names in job postings or resumes to entities in an employer KB is very important to many business applications. In this paper, we focus on this employer name normalization task, which has several unique challenges: handling employer names from both job postings and resumes, leveraging the corresponding location context, and handling name variations, irrelevant input data, and noises in the KB. We present a system called CompanyDepot which contains a machine learning based approach CompanyDepot-ML and a heuristic approach CompanyDepot-H to address these challenges in three steps: (1) searching for candidate entities based on a customized search engine for the KB; (2) ranking the candidate entities using learning-to-rank methods or heuristics; and (3) validating the top-ranked entity via binary classification or heuristics. While CompanyDepot-ML shows better extendability and flexibility, CompanyDepot-H serves as a strong baseline and useful way to collect training data for CompanyDepot-ML. The proposed system achieves 2.5%-21.4% higher coverage at the same precision level compared to an existing system used at CareerBuilder over multiple real-world datasets. Applying the system to a similar task of academic institution name normalization further shows the generalization ability of the method.", "references": ["4ICU. Top universities in the united kingdom. http://www.4icu.org/gb/. accessed 2014-01.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD '08, pages 1247--1250, New York, NY, USA, 2008. ACM.", "A. Borkovsky. Item name normalization, Apr. 29 2003. US Patent 6,556,991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939727"}, {"title": "Post-Learning Optimization of Tree Ensembles for Efficient Ranking", "authors": ["Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Raffaele Perego\n,", "Fabrizio Silvestri\n,", "Salvatore Trani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLearning to Rank (LtR) is the machine learning method of choice for producing high quality document ranking functions from a ground-truth of training examples. In practice, efficiency and effectiveness are intertwined concepts and trading off effectiveness for meeting efficiency constraints typically existing in large-scale systems is one of the most urgent issues. In this paper we propose a new framework, named CLEaVER, for optimizing machine-learned ranking models based on ensembles of regression trees. The goal is to improve efficiency at document scoring time without affecting quality. Since the cost of an ensemble is linear in its size, CLEaVER first removes a subset of the trees in the ensemble, and then fine-tunes the weights of the remaining trees according to any given quality measure. Experiments conducted on two publicly available LtR datasets show that CLEaVER is able to prune up to 80% of the trees and provides an efficiency speed-up up to 2.6x without affecting the effectiveness of the model.", "references": ["N. Asadi and J. Lin. Training efficient tree-based models for document ranking. In Advances in Information Retrieval, pages 146--157. Springer, 2013.", "N. Asadi, J. Lin, and A. P. de Vries. Runtime optimizations for tree-based machine learning models. IEEE Transactions on Knowledge and Data Engineering, 26(9):2281--2292, 2014.", "G. Capannini, D. Dato, C. Lucchese, M. Mori, F. M. Nardini, S. Orlando, R. Perego, and N. Tonellotto. QuickRank: a C"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914763"}, {"title": "Contrasting Offline and Online Results when Evaluating Recommendation Algorithms", "authors": ["Marco Rossetti\n,", "Fabio Stella\n,", "Markus Zanker"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMost evaluations of novel algorithmic contributions assess their accuracy in predicting what was withheld in an offline evaluation scenario. However, several doubts have been raised that standard offline evaluation practices are not appropriate to select the best algorithm for field deployment. The goal of this work is therefore to compare the offline and the online evaluation methodology with the same study participants, i.e. a within users experimental design. This paper presents empirical evidence that the ranking of algorithms based on offline accuracy measurements clearly contradicts the results from the online study with the same set of users. Thus the external validity of the most commonly applied evaluation methodology is not guaranteed.", "references": ["Paolo Cremonesi, Franca Garzotto, and Roberto Turrin. Investigating the persuasion potential of recommender systems from a quality perspective: An empirical study. ACM Trans. Interact. Intell. Syst., 2(2):11:1--11:41, June 2012.", "Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the fourth ACM conference on Recommender systems, RecSys '10, pages 39--46, New York, NY, USA, 2010. ACM.", "Michael D. Ekstrand, F. Maxwell Harper, Martijn C. Willemsen, and Joseph A. Konstan. User perception of differences in recommender algorithms. In Proceedings of the 8th ACM Conference on Recommender Systems, RecSys '14, pages 161--168, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959176"}, {"title": "Behavior Driven Topic Transition for Search Task Identification", "authors": ["Liangda Li\n,", "Hongbo Deng\n,", "Yunlong He\n,", "Anlei Dong\n,", "Yi Chang\n,", "Hongyuan Zha"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nSearch tasks in users' query sequences are dynamic and interconnected. The formulation of search tasks can be influenced by multiple latent factors such as user characteristics, product features and search interactions, which makes search task identification a challenging problem. In this paper, we propose an unsupervised approach to identify search tasks via topic membership along with topic transition probabilities, thus it becomes possible to interpret how user's search intent emerges and evolves over time. Moreover, a novel hidden semi-Markov model is introduced to model topic transitions by considering not only the semantic information of queries but also the latent search factors originated from user search behaviors. A variational inference algorithm is developed to identify remarkable search behavior patterns, typical topic transition tracks, and the topic membership of each query from query logs. The learned topic transition tracks and the inferred topic memberships enable us to identify both small search tasks, where a user searches the same topic, and big search tasks, where a user searches a series of related topics. We extensively evaluate the proposed approach and compare with several state-of-the-art search task identification methods on both synthetic and real-world query log data, and experimental results illustrate the effectiveness of our proposed model.", "references": ["E. Agichtein, R. W. White, S. T. Dumais, and P. N. Bennet. Search, interrupted: understanding and predicting search task continuation. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pages 315--324. ACM, 2012.", "L. M. Aiello, D. Donato, U. Ozertem, and F. Menczer. Behavior-driven clustering of queries into topics. In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM '11, pages 1373--1382, New York, NY, USA, 2011. ACM.", "AOL. http://gregsadetsky.com/aol-data/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883047"}, {"title": "An Interactive Data Repository with Visual Analytics", "authors": ["Ryan A. Rossi\n,", "Nesreen K. Ahmed"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nScientific data repositories have historically made data widely accessible to the scientific community, and have led to better research through comparisons, reproducibility, as well as further discoveries and insights. Despite the growing importance and utilization of data repositories in many scientific disciplines, the design of existing data repositories has not changed for decades. In this paper, we revisit the current design and envision interactive data repositories, which not only make data accessible, but also provide techniques for interactive data exploration, mining, and visualization in an easy, intuitive, and free-flowing manner.", "references": ["N. K. Ahmed, J. Neville, and R. Kompella. Network sampling: From static to streaming graphs. Transactions on Knowledge Discovery from Data (TKDD), 8(2):7:1--7:56, June 2014.", "N. K. Ahmed and R. A. Rossi. Interactive visual graph analytics on the web. In ICWSM, pages 566--569, 2015.", "A. Brazma, H. Parkinson, U. Sarkans, M. Shojatalab, J. Vilo, N. Abeygunawardena, E. Holloway, M. Kapushesky, P. Kemmeren, G. G. Lara, et al. Arrayexpress--a public repository for microarray gene expression data at the EBI. Nucleic acids research, 31(1):68--71, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897350.2897355"}, {"title": "A Case for Protecting Huge Pages from the Kernel", "authors": ["Ashish Panwar\n,", "Naman Patel\n,", "K. Gopinath"], "publication": "APSys '16: Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems", "abstract": "ABSTRACT\nControlling memory fragmentation is critical for leveraging the benefits of huge page support offered by modern architectures. The division of free memory into non-contiguous regions over time restricts huge page allocations in long run. Compaction is a popular mechanism to recover contiguous blocks of free memory on demand. However, its success rate of accumulating free regions at huge page granularity (e.g., 2MB in x86_64) is low in most situations due to the presence of unmovable kernel memory. Hence, a prudent page placement algorithm is required to control fragmentation and protect huge pages against kernel memory allocations, in order to sustain system performance over long periods of time.\nIn this work, we explore the interaction of kernel pages with fragmentation avoidance and recovery mechanism in Linux. Our analysis shows that stock kernel memory layout thwarts the progress of memory compaction. Furthermore, compaction can potentially induce more fragmentation depending on where kernel memory was placed by the underlying page allocator. We discuss the scope of optimization in current Linux framework and show how an effective fragmentation management can yield up to 20% performance improvement and up to 27% energy savings with the help of additional huge pages.", "references": ["Specjvm2008, 2008. URL https://www.spec.org/jvm2008/. https://www.spec.org/jvm2008/.", "V. Babka. Fighting physical memory fragmentation with memory compaction, 2014. URL http://labs.suse.cz/vbabka/compaction.pdf. http://labs.suse.cz/vbabka/compaction.pdf.", "A. Basu, J. Gandhi, J. Chang, M. D. Hill, and M. M. Swift. Efficient virtual memory for big memory servers. In Proceedings of the 40th Annual International Symposium on Computer Architecture, ISCA '13, pages 237--248, New York, NY, USA, 2013. ACM. ISBN 978-1-4503-2079-5. doi: 10.1145/2485922.2485943. URL http://doi.acm.org/10.1145/2485922.2485943."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967360.2967371"}, {"title": "Knowledge Sharing Through E-Government Portal", "authors": ["Hoor Dali\n,", "Khaled Shaalan"], "publication": "KMO '16: Proceedings of the The 11th International Knowledge Management in Organizations Conference on The changing face of Knowledge Management Impacting Society", "abstract": "ABSTRACT\nThe advent of technology has changed the way of government to communicate with its stakeholders by incorporating the notion of e-government based on web-portal. These web-portals whereas identified successful in communicating with the stakeholders also played a vital role in sharing and managing knowledge. Based on this notion, this article is concerned with the role of e-government portal in sharing knowledge and the way through which this portal increases the efficiency of entire public sector. In the same instance, the K-ACT model of internet portal is analyzed to identify the features that make a web-portal best and perfect. In this article, we conducted a literature review and focused our attention on analyzing the e-government portals of four countries i.e. China, Hong Kong, Beijing and Turkish Municipalities. For the analysis and comparison purposes, the checklist of K-ACT model is used. The findings revealed that the e-government portal of these countries is not fully matched with the features as described in K-ACT, which ultimately affect the knowledge management and sharing practices in the region. Therefore, recommendations are made to improve the existing portal for knowledge sharing so that citizens can take more knowledge benefits from the e-government portals.", "references": ["D. S. Carstens, L. Bean, and J. Barlow, \"Knowledge Management in E-Government,\" 2009.", "S. Y. Hung, C. M. Chang, and T. J. Yu, \"Determinants of user acceptance of the e-Government services: The case of online tax filing and payment system,\" Government Information Quarterly, vol. 23, no. 1, pp. 97--122, 2006.", "K. Metaxiotis and J. Psarras, \"A conceptual analysis of knowledge management in e-government,\" Electronic Government - An International Journal, vol. 2, no. 1, pp. 77--86, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2925995.2926009"}, {"title": "Joint Image-Text Representation by Gaussian Visual-Semantic Embedding", "authors": ["Zhou Ren\n,", "Hailin Jin\n,", "Zhe Lin\n,", "Chen Fang\n,", "Alan Yuille"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nHow to jointly represent images and texts is important for tasks involving both modalities. Visual-semantic embedding models have been recently proposed and shown to be effective. The key idea is that by learning a mapping from images into a semantic text space, the algorithm is able to learn a compact and effective joint representation. However, existing approaches simply map each text concept to a single point in the semantic space. Mapping instead to a density distribution provides many interesting advantages, including better capturing uncertainty about each text concept, and enabling better geometric interpretation of concepts such as inclusion, intersection, etc. In this work, we present a novel Gaussian Visual-Semantic Embedding (GVSE) model, which leverages the visual information to model text concepts as Gaussian distributions in semantic space. Experiments in two tasks, image classification and text-based image retrieval on the large scale MIT Places205 dataset, have demonstrated the superiority of our method over existing approaches, with higher accuracy and better robustness.", "references": ["J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei. Imagenet: a large-scale hierachical image database. In CVPR, 2009.", "A. Frome, G. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, and T. Mikolov. Devise: A deep visual-semantic embedding model. In NIPS, 2013.", "Y. Gong, Y. Jia, T. K. Leung, A. Toshev, and S. Ioffe. Deep convolutional ranking for multilabel image annotation. In ICLR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967212"}, {"title": "A Study of Information Seeking Behavior Using Physical and Online Explorations", "authors": ["Dongho Choi"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPeople have their behavioral patterns, through which they determine how to seek and use information. People also exhibit established mobility pattern in their everyday lives. Meanwhile, the modern technologies such as smartphones, wearable devices, and eye trackers have allowed researchers to collect personal, contextual, and cognitive information of users, and create behavioral models from different perspectives. Considering the analogy between information exploration and geographical exploration, I want to identify the interconnections between these behaviors and predict individuals? search behavior using personal and contextual signals. The proposal uses a mixed-method approach that involves a four-week field study, a game study, and a lab study, collecting data from 40 participants through mobile device, eye tracker, online logs, and weekly diary.", "references": ["M. Allaby. exploratory behavior, 1999.", "M. J. Bates. The design of browsing and berrypicking techniques for the online search interface. Online review, 13(5):407--424, 1989.", "D. Bawden. Information systems and the stimulation of creativity. Journal of Information Science, 12(5):203--216, 1986."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911482"}, {"title": "Efficient remote image-based situational queries through mobile devices", "authors": ["Xiaoming Leng\n,", "Ying Yan\n,", "Yang Chen\n,", "Börje F. Karlsson\n,", "Thomas Moscibroda"], "publication": "SA '16: SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications", "abstract": "ABSTRACT\nThis paper presents ThereNow, a LBS[Junglas and Watson 2008] mobile application designed to get close-to-real-time answers for situational queries about real-world locations. Two key issues in this scenario are: extracting information from existing data to answer user queries; and easily acquiring more data or information, if it doesn't exist yet in the system. This can be problematic due to the format and semantics of the data or to the cost (time or resources) of collecting it. ThereNow takes a unique design approach where it relies on images/photos as data and in the actual users looking at those images to 'see' if they provide enough information to answer their queries. This approach can both bypass the difficulties in information extraction from data available on the Internet and make collecting more data as easy as just taking a picture. Thus, by leveraging mobile phones being everywhere and the \"an image is worth a thousand words\" effect, users can easily request and quickly receive information about what is happening now at a certain location. Moreover, ThereNow makes use of an image crawler to bootstrap the system with location-tagged images and utilizes computer vision techniques to extract additional potentially useful information from images.", "references": ["Alt, F., Shirazi, A. S., Schmidt, A., Kramer, U., and Nawaz, Z. 2010. Location-based crowdsourcing: extending crowdsourcing to the real world. In Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, ACM, 13--22.", "Balkić, Z., Š oštarić, D., and Horvat, G. 2012. Geohash and uuid identifier for multi-agent systems. In Proceedings of the KES International Symposium on Agent and Multi-Agent Systems: Technologies and Applications, Springer, 290--298.", "Brunsdon, C. 2013. Computing with spatial trajectories, edited by yu zheng. International Journal of Geographical Information Science 27, 1, 208--209."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2999508.2999524"}, {"title": "Cubrick: indexing millions of records per second for interactive analytics", "authors": ["Pedro Pedreira\n,", "Chris Croswhite\n,", "Luis Bona"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThis paper describes the architecture and design of Cubrick, a distributed multidimensional in-memory DBMS suited for interactive analytics over highly dynamic datasets. Cubrick has a strictly multidimensional data model composed of cubes, dimensions and metrics, supporting sub-second OLAP operations such as slice and dice, roll-up and drill-down over terabytes of data. All data stored in Cubrick is range partitioned by every dimension and stored within containers called bricks in an unordered and sparse fashion, providing high data ingestion rates and indexed access through any combination of dimensions. In this paper, we describe details about Cubrick's internal data structures, distributed model, query execution engine and a few details about the current implementation. Finally, we present results from a thorough experimental evaluation that leveraged datasets and queries collected from a few internal Cubrick deployments at Facebook.", "references": ["D. Abadi and M. Stonebraker. C-store: Looking back and looking forward. Talk at VLDB'15 - International Conference on Very Large Databases, 2015.", "D. J. Abadi, S. R. Madden, and N. Hachem. Column-Stores vs. Row-Stores: How Different Are They Really? In SIGMOD, Vancouver, Canada, 2008.", "L. Abraham et al. Scuba: Diving into data at facebook. Proc. VLDB Endow., 6(11):1057--1067, Aug. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007269"}, {"title": "Ear Ball for Empathy: To Realize the Sensory Experience of People with Autism Apectrum Disorder", "authors": ["Taisuke Murakami"], "publication": "HAI '16: Proceedings of the Fourth International Conference on Human Agent Interaction", "abstract": "ABSTRACT\nAutism spectrum disorder (ASD) are characterized by difficulties in sensory integration and a body image which differs from the normal, healthy one. In order to enable healthy people to experience and thus develop a deeper understanding of the different body image that people with developmental disorders possess the author is pursuing research into the simulation of sensory experiences common to ASD. This study focuses on a particular sensory characteristic of ASD where difficulty is experienced in locating the source of sound in an environment and the development of a device for simulating the sense of hearing experienced in such a disorder. Workshops for children were carried out using the developed device, with interviews indicating that the majority of participants experienced feelings of ambiguity in relation to their own senses. Such a feeling in one's sensory boundaries is a phenomenon which is common in ASD research. It was concluded that the device developed in this study allowed people to vicariously experience the senses of people with ASD.", "references": ["AXEL BRAUNS, Buntschatten und Fledermause, Hamburg: Hoffmann und Campe Verlag, 2002.", "NAOKI HIGASHIDA, The Reason I Jump, London: SCEPTRE, 2013.", "TEMPLE GRANDIN, Thinking in Pictures, New York: Doubleday, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2974804.2980516"}, {"title": "Table Modelling, Extraction and Processing", "authors": ["Max Göbel\n,", "Tamir Hassan\n,", "Ermelinda Oro\n,", "Giorgio Orsi\n,", "Roya Rastan"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nThis tutorial is targeted at academics and practitioners, both within and outside of the Document Engineering community, who are confronted with table processing tasks such as information extraction and conversion, or have an interest in the topic, and wish to deepen their understanding of the state-of-the-art in this field.", "references": ["C. S. Bhagavatula, T. Noraset, and D. Downey. TabEL: entity linking in web tables. In Proceedings of the International Semantic Web Conference (ISWC), pages 425--441, 2015.", "D. W. Embley, M. Hurst, D. Lopresti, and G. Nagy. Table-processing paradigms: a research survey. International Journal on Document Analysis and Recognition (IJDAR), 8:66--86, 2006.", "D. W. Embley, M. S. Krishnamoorthy, G. Nagy, and S. Seth. Converting heterogeneous statistical tables on the web to searchable databases. International Journal on Document Analysis and Recognition (IJDAR), 19(2):119--138, 2016.", "C. S. Bhagavatula, T. Noraset, and D. Downey. TabEL: entity linking in web tables. In Proceedings of the International Semantic Web Conference (ISWC), pages 425--441, 2015.", "D. W. Embley, M. Hurst, D. Lopresti, and G. Nagy. Table-processing paradigms: a research survey. International Journal on Document Analysis and Recognition (IJDAR), 8:66--86, 2006.", "D. W. Embley, M. S. Krishnamoorthy, G. Nagy, and S. Seth. Converting heterogeneous statistical tables on the web to searchable databases. International Journal on Document Analysis and Recognition (IJDAR), 19(2):119--138, 2016.", "M. Göbel, T. Hassan, E. Oro, and G. Orsi. A methodology for evaluating algorithms for table understanding in PDF documents. In Proceedings of the ACM Symposium on Document Engineering (DocEng), pages 45--48, 2012.", "M. Göbel, T. Hassan, E. Oro, and G. Orsi. ICDAR 2013 Table Competition. In Proceedings of the 12th International Conference on Document Analysis and Recognition (ICDAR), pages 1449--1453, 2013.", "D. P. Lopresti and G. Nagy. A tabular survey of automated table processing. In Selected Papers from the Third International Workshop on Graphics Recognition (GREC '99), Recent Advances, pages 93--120, published 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967173"}, {"title": "Efficient Similarity Search across Top-k Lists under the Kendall's Tau Distance", "authors": ["Koninika Pal\n,", "Sebastian Michel"], "publication": "SSDBM '16: Proceedings of the 28th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nWe consider the problem of similarity search in a set of top-k lists under the generalized Kendall's Tau distance. This distance describes how related two rankings are in terms of discordantly ordered items. We consider pair- and triplets-based indices to counter the shortcomings of naive inverted indices and derive efficient query schemes by relating the proposed index structures to the concept of locality sensitive hashing (LSH). Specifically, we devise four different LSH schemes for Kendall's Tau using two generic hash families over individual elements or pairs of them. We show that each of these functions has the desired property of being locality sensitive. Further, we discuss the selection of hash functions for the proposed LSH schemes for a given query ranking, called query-driven LSH and derive bounds for the required number of hash functions to use in order to achieve a predefined recall goal. Experimental results, using two real-world datasets, show that the devised methods outperform the SimJoin method---the state of the art method to query for similar sets---and are far superior to a plain inverted-index--based approach.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. FOCS, 2006.", "V. Athitsos, M. Potamias, P. Papapetrou, and G. Kollios. Nearest neighbor retrieval using distance-based hashing. ICDE, 2008.", "M. Bawa, T. Condie, and P. Ganesan. LSH forest: self-tuning indexes for similarity search. WWW, 2005.", "J. L. Bentley. K-d trees for semidynamic point sets. Symp. on Comp. Geometry, 1990.", "B. Carterette. On rank correlation and the distance between rankings. SIGIR, 2009.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. CIKM, 2009.", "P. Ciaccia, M. Patella, and P. Zezula. M-tree: An efficient access method for similarity search in metric spaces. VLDB, 1997.", "M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. Symp. on Comp. Geometry, 2004.", "W. Dong, Z. Wang, W. Josephson, M. Charikar, and K. Li. Modeling lsh for performance tuning. CIKM, 2008.", "C. Dwork, R. Kumar, M. Naor, and D. Sivakumar. Rank aggregation methods for the web. WWW, 2001.", "R. Fagin, R. Kumar, and D. Sivakumar. Comparing top k lists. SIAM J. Discrete Math., 17(1), 2003.", "J. Gao, H. V. Jagadish, W. Lu, and B. C. Ooi. DSH: data sensitive hashing for high-dimensional k-nnsearch. SIGMOD, 2014.", "A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. VLDB, 1999.", "A. Guttman. R-trees: A dynamic index structure for spatial searching. SIGMOD, 1984.", "S. Helmer and G. Moerkotte. A performance study of four index structures for set-valued attributes of low cardinality. VLDB J., 12(3), 2003.", "E. Ilieva, S. Michel, and A. Stupar. The essence of knowledge (bases) through entity rankings. CIKM, 2013.", "P. Indyk and R. Motwani. Approximate nearest neighbors: Towards removing the curse of dimensionality. STOC, 1998.", "K. Järvelin and J. Kekäläinen. Cumulated gain-based evaluation of IR techniques. ACM TOIS, 20(4).", "H. Jegou, L. Amsaleg, C. Schmid, and P. Gros. Query adaptative locality sensitive hashing. In ICASSP 2008.", "R. Kumar and S. Vassilvitskii. Generalized distances between rankings. WWW, 2010.", "Q. Lv, W. Josephson, Z. Wang, M. Charikar, and K. Li. Multi-probe LSH: efficient indexing for high-dimensional similarity search. VLDB, 2007.", "E. Milchevski, A. Anand, and S. Michel. The sweet spot between inverted indices and metric-space indexing for top-k-list similarity search. EDBT, 2015.", "K. Pal and S. Michel. An LSH index for computing kendall's tau over top-k lists. CoRR, abs/1409.0651, 2014.", "H. Samet. Foundations of Multidimensional and Metric Data Structures. Morgan Kaufmann, 2006.", "V. Satuluri and S. Parthasarathy. Bayesian locality sensitive hashing for fast similarity search. PVLDB, 5(5), 2012.", "F. Schalekamp and A. van Zuylen. Rank aggregation: Together we're strong. ALENEX, 2009.", "The New York Times Annotated Corpus. http://corpus.nytimes.com.", "J. Wang, G. Li, and J. Feng. Can we beat the prefix filtering?: an adaptive framework for similarity join and search. SIGMOD, 2012.", "R. Weber, H. Schek, and S. Blott. A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces. VLDB, 1998.", "P. Zezula, P. Savino, G. Amato, and F. Rabitti. Approximate similarity retrieval with m-trees. VLDB J., 7(4), 1998.", "J. Zobel and A. Moffat. Inverted files for text search engines. ACM Comput. Surv., 38(2), 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2949689.2949709"}, {"title": "Effect of Spam on Hashtag Recommendation for Tweets", "authors": ["Surendra Sedhai\n,", "Aixin Sun"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nPresence of spam tweets in a dataset may affect the choices of feature selection, algorithm formulation, and system evaluation for many applications. However, most existing studies have not considered the impact of spam tweets. In this paper, we study the impact of spam tweets on hashtag recommendation for hyperlinked tweets (i.e., tweets containing URLs) in HSpam14 dataset. HSpam14 is a collection of 14 million tweets with annotations of being spam and ham (i.e., non-spam). In our experiments, we observe that it is much easier to recommend \"correct\" hashtags for spam tweets than ham tweets, because of the near duplicates in spam tweets. Simple approaches like recommending most popular hashtags achieves very good accuracy on spam tweets. On the other hand, features that are highly effective on ham tweets may not be effective on spam tweets. Our findings suggest that without removing spam tweets from the data collection (as in most studies), the results obtained could be misleading for hashtag recommendation tasks.", "references": ["C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The underground on 140 characters or less. In CCS, pages 27--37, 2010.", "T. Jones, D. Hawking, P. Thomas, and R. Sankaranarayana. Relative effect of spam and irrelevant documents on user interaction with search engines. In CIKM, pages 2113--2116, 2011.", "S. Sedhai and A. Sun. Hashtag recommendation for hyperlinked tweets. In SIGIR, pages 831--834, 2014.", "S. Sedhai and A. Sun. Hspam14: A collection of 14 million tweets for hashtag-oriented spam research. In SIGIR, pages 223--232, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889404"}, {"title": "Hierarchical Random Walk Inference in Knowledge Graphs", "authors": ["Qiao Liu\n,", "Liuyi Jiang\n,", "Minghao Han\n,", "Yao Liu\n,", "Zhiguang Qin"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRelational inference is a crucial technique for knowledge base population. The central problem in the study of relational inference is to infer unknown relations between entities from the facts given in the knowledge bases. Two popular models have been put forth recently to solve this problem, which are the latent factor models and the random-walk models, respectively. However, each of them has their pros and cons, depending on their computational efficiency and inference accuracy. In this paper, we propose a hierarchical random-walk inference algorithm for relational learning in large scale graph-structured knowledge bases, which not only maintains the computational simplicity of the random-walk models, but also provides better inference accuracy than related works. The improvements come from two basic assumptions we proposed in this paper. Firstly, we assume that although a relation between two entities is syntactically directional, the information conveyed by this relation is equally shared between the connected entities, thus all of the relations are semantically bidirectional. Secondly, we assume that the topology structures of the relation-specific subgraphs in knowledge bases can be exploited to improve the performance of the random-walk based relational inference algorithms. The proposed algorithm and ideas are validated with numerical results on experimental data sampled from practical knowledge bases, and the results are compared to state-of-the-art approaches.", "references": ["A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In Proc. of the 27th NIPS, pages 2787--2795, 2013.", "A. Bordes, J. Weston, R. Collobert, and Y. Bengio. Learning structured embeddings of knowledge bases. In Proc. of the 25th AAAI Conference on Artificial Intelligence, pages 301--306, 2011.", "J. Cheng, T. Yuan, J. Wang, and H. Lu. Group latent factor model for recommendation with multiple user behaviors. In Proc. of the 37th ACM SIGIR, pages 995--998, 2014.", "M. Gardner, P. Talukdar, J. Krishnamurthy, and T. Mitchell. Incorporating vector space similarity in random walk inference over knowledge bases. In Proc. of the 2014 EMNLP, pages 397--406, 2014.", "L. Getoor and L. Mihalkova. Learning statistical models from relational data. In Proc. of the 2011 ACM SIGMOD, pages 1195--1198, 2011.", "L. Getoor and B. Taskar. Introduction to Statistical Relational Learning. The MIT Press, 2007.", "N. Lao and W. W. Cohen. Relational retrieval using a combination of path-constrained random walks. Machine Learning, 81(1):53--67, 2010.", "N. Lao, T. Mitchell, and W. W. Cohen. Random walk inference and learning in a large scale knowledge base. In Proc. of the 2011 EMNLP, pages 529--539, 2011.", "Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation embeddings for knowledge graph completion. In Proc. of the 29th AAAI Conference on Artificial Intelligence, pages 2181--2187, 2015.", "T. M. Mitchell, W. W. Cohen, E. R. H. Jr., P. P. Talukdar, J. Betteridge, A. Carlson, B. D. Mishra, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. A. Platanios, A. Ritter, M. Samadi, B. Settles, R. C. Wang, D. T. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. Never-ending learning. In Proc. of the 29th AAAI Conference on Artificial Intelligence, pages 2302--2310, 2015.", "S. Natarajan, T. Khot, K. Kersting, B. Gutmann, and J. Shavlik. Gradient-based boosting for statistical relational learning: The relational dependency network case. Machine Learning, 86(1):25--56, 2011.", "A. Neelakantan, B. Roth, and A. McCallum. Compositional vector space models for knowledge base inference. In Proc. of the 53rd ACL-IJCNLP 2015, pages 156--166, 2015.", "T. V. Nguyen, A. Karatzoglou, and L. Baltrunas. Gaussian process factorization machines for context aware recommendations. In Proc. of the 37th ACM SIGIR, pages 63--72, 2014.", "M. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 104(1):11--33, 2016.", "M. Nickel, V. Tresp, and H.-P. Kriegel. A three-way model for collective learning on multi-relational data. In Proc. of the 28th ICML, pages 809--816, 2011.", "M. Nickel, V. Tresp, and H.-P. Kriegel. Factorizing yago: Scalable machine learning for linked data. In Proc. of the 21st International Conference on World Wide Web, pages 271--280, 2012.", "F. Niu, C. Zhang, C. Re, and J. Shavlik. Scaling inference for markov logic via dual decomposition. In Proc. of the 12th IEEE ICDM, pages 1032--1037, 2012.", "M. Richardson and P. Domingos. Markov logic networks. Machine Learning, 62(1):107--136, 2006.", "S. Schoenmackers, O. Etzioni, D. S. Weld, and J. Davis. Learning first-order horn clauses from web text. In Proc. of the EMNLP, pages 1088--1098, 2010.", "C. Wang, Y. Song, A. El-Kishky, D. Roth, M. Zhang, and J. Han. Incorporating world knowledge to document clustering via heterogeneous information networks. In Proc. of the 21th ACM SIGKDD, pages 1215--1224, 2015.", "Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding by translating on hyperplanes. In Proc. of the 28th AAAI Conference on Artificial Intelligence, pages 1112--1119, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911509"}, {"title": "Bayesian Non-Exhaustive Classification A Case Study: Online Name Disambiguation using Temporal Record Streams", "authors": ["Baichuan Zhang\n,", "Murat Dundar\n,", "Mohammad Al Hasan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe name entity disambiguation task aims to partition the records of multiple real-life persons so that each partition contains records pertaining to a unique person. Most of the existing solutions for this task operate in a batch mode, where all records to be disambiguated are initially available to the algorithm. However, more realistic settings require that the name disambiguation task be performed in an online fashion, in addition to, being able to identify records of new ambiguous entities having no preexisting records. In this work, we propose a Bayesian non-exhaustive classification framework for solving online name disambiguation task. Our proposed method uses a Dirichlet process prior with a Normal x Normal x Inverse Wishart data model which enables identification of new ambiguous entities who have no records in the training data. For online classification, we use one sweep Gibbs sampler which is very efficient and effective. As a case study we consider bibliographic data in a temporal stream format and disambiguate authors by partitioning their papers into homogeneous groups. Our experimental results demonstrate that the proposed method is better than existing methods for performing online name disambiguation task.", "references": ["F. Akova, M. Dundar, V. J. Davisson, E. D. Hirleman, A. K. Bhunia, J. P. Robinson, and B. Rajwa. A machine-learning approach to detecting unknown bacterial serovars. Statistical Analysis and Data Mining, pages 289--301, 2010.", "D. Aldous. Exchangeability and related topics. 1985.", "T. W. Anderson, editor. An Introduction to Multivariate Statistical Analysis. 1984.", "R. Bunescu and M. Pasca. Using encyclopedic knowledge for named entity disambiguation. In European Chapter of the Association for Comp. Linguistics, pages 9--16, 2006.", "L. Cen, E. C. Dragut, L. Si, and M. Ouzzani. Author disambiguation by hierarchical agglomerative clustering with adaptive stopping criterion. In SIGIR, pages 741--744, 2013.", "P.-Y. Chen, B. Zhang, M. A. Hasan, and A. O. Hero. Incremental method for spectral clustering of increasing orders. KDD Workshop on Mining and Learning with Graphs, 2016.", "S. Choudhury, K. Agarwal, S. Purohit, B. Zhang, M. Pirrung, W. Smith, and M. Thomas. Nous: Construction and querying of dynamic knowledge graphs. arXiv preprint arXiv:1606.02314, 2016.", "A. Davis, A. Veloso, A. S. da Silva, W. Meira, Jr., and A. H. F. Laender. Named entity disambiguation in streaming data. In ACL, 2012.", "A. P. de Carvalho, A. A. Ferreira, A. H. F. Laender, and M. A. Goncalves. Incremental unsupervised name disambiguation in cleaned digital libraries. JIDM, pages 289--304, 2011.", "M. Dundar, F. Akova, A. Qi, and B. Rajwa. Bayesian nonexhaustive learning for online discovery and modeling of emerging classes. In ICML, pages 113--120, 2012.", "T. S. Ferguson. A bayesian analysis of some nonparametric problems. Ann. Statist., pages 209--230, 1973.", "T. Greene and W. S.Rayens. Partially pooled covariance matrix estimation in discriminant analysis. Communications in Statistics - Theory and Methods, pages 3679--3702, 1989.", "H. Han, L. Giles, H. Zha, C. Li, and K. Tsioutsiouliklis. Two supervised learning approaches for name disambiguation in author citations. In Joint Conf. on Digital Libraries, 2004.", "H. Han, H. Zha, and C. L. Giles. Name disambiguation in author citations using a k-way spectral clustering method. In ACM Joint Conf. on Digital Libraries, pages 334--343, 2005.", "L. Hermansson, T. Kerola, F. Johansson, V. Jethava, and D. Dubhashi. Entity disambiguation in anonymized graphs using graph kernels. In CIKM, pages 1037--1046, 2013.", "J. Hoffart, Y. Altun, and G. Weikum. Discovering emerging entities with ambiguous names. In WWW, 2014.", "M. Khabsa, P. Treeratpituk, and C. L. Giles. Online person name disambiguation with constraints. JCDL, 2015.", "D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In NIPS, pages 556--562. 2001.", "D. Li and M. Becchi. Deploying graph algorithms on gpus: An adaptive solution. In IPDPS, 2013.", "D. J. Michaud. Adventures in computer forensics. SANS Institute, 2001.", "D. J. Miller and J. Browning. A mixture model and em-based algorithm for class discovery, robust classification, and outlier rejection in mixed labeled/unlabeled data sets. IEEE Transactions on PAMI, pages 1468--1483, 2003.", "Y. Qian, Q. Zheng, T. Sakai, J. Ye, and J. Liu. Dynamic author name disambiguation for growing digital libraries. Journal of Inf. Retr., pages 379--412, 2015.", "T. K. Saha, B. Zhang, and M. Al Hasan. Name disambiguation from link data in a collaboration graph using temporal and topological features. Social Network Analysis and Mining, pages 1--14, 2015.", "G. Salton and M. J. McGill. Introduction to Modern Information Retrieval. 1986.", "J. Sethuraman. A constructive definition of dirichlet priors. Statistica Sinica, pages 639--650, 1994.", "Y. Song, J. Huang, I. G. Councill, J. Li, and C. L. Giles. Efficient topic-based unsupervised name disambiguation. In JCDL, pages 342--351, 2007.", "J. Tang, A. C. M. Fong, B. Wang, and J. Zhang. A unified probabilistic framework for name disambiguation in digital library. IEEE TKDE, pages 975--987, 2012.", "A. Veloso, A. A. Ferreira, M. A. Goncalves, A. H. F. Laender, and W. M. Jr. Cost-effective on-demand associative author name disambiguation. Inf. Process. Manage., 2012.", "X. Wang, J. Tang, H. Cheng, and P. S. Yu. Adana: Active name disambiguation. In ICDM, pages 794--803, 2011.", "B. Zhang, S. Choudhury, M. A. Hasan, X. Ning, K. Agarwal, S. Purohit, and P. G. P. Cabrera. Trust from the past: Bayesian personalized ranking based link prediction in knowledge graphs. SDM Workshop on Mining Networks and Graphs, 2016.", "B. Zhang, N. Mohammed, V. Dave, and M. A. Hasan. Feature selection for classification under anonymity constraint. arXiv preprint arXiv:1512.07158, 2015.", "B. Zhang, T. K. Saha, and M. A. Hasan. Name disambiguation from link data in a collaboration graph. In ASONAM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983714"}, {"title": "STCAPLRS: A Spatial-Temporal Context-Aware Personalized Location Recommendation System", "authors": ["Quan Fang\n,", "Changsheng Xu\n,", "M. Shamim Hossain\n,", "G. Muhammad"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nNewly emerging location-based social media network services (LBSMNS) provide valuable resources to understand users’ behaviors based on their location histories. The location-based behaviors of a user are generally influenced by both user intrinsic interest and the location preference, and moreover are spatial-temporal context dependent. In this article, we propose a spatial-temporal context-aware personalized location recommendation system (STCAPLRS), which offers a particular user a set of location items such as points of interest or venues (e.g., restaurants and shopping malls) within a geospatial range by considering personal interest, local preference, and spatial-temporal context influence. STCAPLRS can make accurate recommendation and facilitate people’s local visiting and new location exploration by exploiting the context information of user behavior, associations between users and location items, and the location and content information of location items. Specifically, STCAPLRS consists of two components: offline modeling and online recommendation. The core module of the offline modeling part is a context-aware regression mixture model that is designed to model the location-based user behaviors in LBSMNS to learn the interest of each individual user, the local preference of each individual location, and the context-aware influence factors. The online recommendation part takes a querying user along with the corresponding querying spatial-temporal context as input and automatically combines the learned interest of the querying user, the local preference of the querying location, and the context-aware influence factor to produce the top-k recommendations. We evaluate the performance of STCAPLRS on two real-world datasets: Dianping and Foursquare. The results demonstrate the superiority of STCAPLRS in recommending location items for users in terms of both effectiveness and efficiency. Moreover, the experimental analysis results also illustrate the excellent interpretability of STCAPLRS.", "references": ["Gediminas Adomavicius, Ramesh Sankaranarayanan, Shahana Sen, and Alexander Tuzhilin. 2005. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Transactions on Information Systems 23, 1, 103--145.", "Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering 17, 6, 734--749.", "Linas Baltrunas and Francesco Ricci. 2009. Context-based splitting of item ratings in collaborative filtering. In Proceedings of the 3rd ACM Conference on Recommender Systems. ACM, New York, NY, 245--248.", "Jie Bao, Yu Zheng, and Mohamed F. Mokbel. 2012. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proceedings of the 20th International Conference on Advances in Geographic Information Systems (SIGSPATIAL’12). ACM, New York, NY, 199--208.", "Jie Bao, Yu Zheng, David Wilkie, and Mohamed F. Mokbel. 2015. Recommendations in location-based social networks: A survey. GeoInformatica 19, 3, 525--565. http://research.microsoft.com/apps/pubs/default.aspx?id&equals;191797.", "Justin Basilico and Thomas Hofmann. 2004. Unifying collaborative and content-based filtering. In Proceedings of the 21st International Conference on Machine Learning (ICML’04). DOI:http://dx.doi.org/10.1145/1015330.1015394", "Robert Bell, Yehuda Koren, and Chris Volinsky. 2007. Modeling relationships at multiple scales to improve accuracy of large recommender systems. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’07). ACM, New York, NY, 95--104. DOI:http://dx.doi.org/10.1145/1281192.1281206", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research 3, 993--1022.", "Toon De Pessemier, Simon Dooms, and Luc Martens. 2014. Context-aware recommendations through context and activity recognition in a mobile environment. Multimedia Tools and Applications 72, 3, 2925--2948.", "Christian Desrosiers and George Karypis. 2011. A comprehensive survey of neighborhood-based recommendation methods. In Recommender Systems Handbook, F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor (Eds.). Springer, 107--144. DOI:http://dx.doi.org/10.1007/978-0-387-85820-3_4", "Quan Fang, Jitao Sang, Changsheng Xu, and Yong Rui. 2014. Topic-sensitive influencer mining in interest-based social media networks via hypergraph learning. IEEE Transactions on Multimedia 16, 3, 796--812. DOI:http://dx.doi.org/10.1109/TMM.2014.2298216", "David Goldberg, David Nichols, Brian M. Oki, and Douglas Terry. 1992. Using collaborative filtering to weave an information tapestry. Communications of the ACM 35, 12, 61--70. DOI:http://dx.doi.org/10.1145/138859.138867", "Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences of the United States of America 101, Suppl 1, 5228--5235.", "Thomas Hofmann. 1999. Probabilistic latent semantic analysis. In Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence (UAI’99). 289--296.", "Tzvetan Horozov, Nitya Narasimhan, and Venu Vasudevan. 2006. Using location for personalized POI recommendations in mobile environments. In Proceedings of the International Symposium on Applications on Internet (SAINT’06). IEEE, Los Alamitos, CA, 124--129. DOI:http://dx.doi.org/10.1109/SAINT.2006.55", "Longke Hu, Aixin Sun, and Yong Liu. 2014. Your neighbors affect your ratings: On geographical neighborhood influence to rating prediction. In Proceedings of the 37th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’14). ACM, New York, NY, 345--354. DOI:http://dx.doi.org/10.1145/2600428.2609593", "Xin Jin, Yanzan Zhou, and Bamshad Mobasher. 2005. A maximum entropy Web recommendation system: Combining collaborative and content features. In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining (KDD’05). ACM, New York, NY, 612--617. DOI:http://dx.doi.org/10.1145/1081870.1081945", "Alexandros Karatzoglou, Xavier Amatriain, Linas Baltrunas, and Nuria Oliver. 2010. Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering. In Proceedings of the 2010 ACM Conference on Recommender Systems (RecSys’10). 79--86.", "Byeong Man Kim, Qing Li, Chang Seok Park, Si Gwan Kim, and Ju Yeon Kim. 2006. A new approach for combining content-based and collaborative filters. Journal of Intelligent Information Systems 27, 1, 79--91. DOI:http://dx.doi.org/10.1007/s10844-006-8771-2", "Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. IEEE Computer 42, 8, 30--37. DOI:http://dx.doi.org/10.1109/MC.2009.263", "Takeshi Kurashima, Tomoharu Iwata, Takahide Hoshide, Noriko Takaya, and Ko Fujimura. 2013. Geo topic model: Joint modeling of user’s activity area and interests for location recommendation. In Proceedings of the 6th ACM International Conference on Web Search and Data Mining (WSDM’13). ACM, New York, NY, 375--384. DOI:http://dx.doi.org/10.1145/2433396.2433444", "Daniel D. Lee and H. Sebastian Seung. 2000. Algorithms for non-negative matrix factorization. In Advances in Neural Information Processing Systems 13. 556--562.", "Justin J. Levandoski, Mohamed Sarwat, Ahmed Eldawy, and Mohamed F. Mokbel. 2012. LARS: A location-aware recommender system. In Proceedings of the 2012 IEEE 28th International Conference on Data Engineering (ICDE’12). IEEE, Los Alamitos, CA, 450--461. DOI:http://dx.doi.org/10.1109/ICDE.2012.54", "Defu Lian, Cong Zhao, Xing Xie, Guangzhong Sun, Enhong Chen, and Yong Rui. 2014. GeoMF: Joint geographical modeling and matrix factorization for point-of-interest recommendation. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’14). ACM, New York, NY, 831--840. DOI:http://dx.doi.org/10.1145/2623330.2623638", "Hao Ma, Irwin King, and Michael R. Lyu. 2009. Learning to recommend with social trust ensemble. In Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’09). ACM, New York, NY, 203--210. DOI:http://dx.doi.org/10.1145/1571941.1571978", "Alexandrin Popescul, Lyle H. Ungar, David M. Pennock, and Steve Lawrence. 2001. Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments. In Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence (UAI’01). 437--444. http://uai.sis.pitt.edu/displayArticleDetails.jsp?mmnu&equals;1&smnu&equals;&equals;2&article_id&equals;&equals;129&proceeding_id&equals;&equals;17", "Alexei Pozdnoukhov and Christian Kaiser. 2011. Space-time dynamics of topics in streaming text. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Location-Based Social Networks (LBSN’11). ACM, New York, NY, 1--8. DOI:http://dx.doi.org/10.1145/2063212.2063223", "Steffen Rendle. 2012. Factorization machines with libFM. ACM Transactions on Intelligent Systems and Technology 3, 3, Article No. 57.", "Steffen Rendle, Zeno Gantner, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011. Fast context-aware recommendations with factorization machines. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, New York, NY, 635--644.", "Ruslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems 20. 1--8.", "Andrew I. Schein, Alexandrin Popescul, Lyle H. Ungar, and David M. Pennock. 2002. Methods and metrics for cold-start recommendations. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’02). 253--260. DOI:http://dx.doi.org/10.1145/564376.564421", "Yue Shi, Martha Larson, and Alan Hanjalic. 2014. Collaborative filtering beyond the user-item matrix: A survey of the state of the art and future challenges. ACM Computing Surveys 47, 1, Article No. 3. DOI:http://dx.doi.org/10.1145/2556270", "Petros Venetis, Hector Gonzalez, Christian S. Jensen, and Alon Y. Halevy. 2011. Hyper-local, directions-based ranking of places. Proceedings of the VLDB Endowment 4, 5, 290--301. http://portal.acm.org/citation.cfm?id&equals;1952379&CFID&equals;&equals;12591584&CFTOKEN&equals;&equals;15173685", "Katrien Verbert, Nikos Manouselis, Xavier Ochoa, Martin Wolpers, Hendrik Drachsler, Ivana Bosnic, and Erik Duval. 2012. Context-aware recommender systems for learning: A survey and future challenges. IEEE Transactions on Learning Technologies 5, 4, 318--335.", "Liang Xiong, Xi Chen, Tzu-Kuo Huang, Jeff G. Schneider, and Jaime G. Carbonell. 2010. Temporal collaborative filtering with Bayesian probabilistic tensor factorization. In Proceedings of the 2010 SIAM International Conference on Data Mining (SDM’10). 211--222.", "Mao Ye, Peifeng Yin, Wang-Chien Lee, and Dik Lun Lee. 2011. Exploiting geographical influence for collaborative point-of-interest recommendation. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’11). 325--334.", "Mao Ye, Peifeng Yin, and Wang-Chien Lee. 2010. Location recommendation for location-based social networks. In Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems (GIS’10). ACM, New York, NY, 458--461. DOI:http://dx.doi.org/10.1145/1869790.1869861", "Hongzhi Yin, Yizhou Sun, Bin Cui, Zhiting Hu, and Ling Chen. 2013. LCARS: A location-content-aware recommender system. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’13). 221--229.", "Zhijun Yin, Liangliang Cao, Jiawei Han, Chengxiang Zhai, and Thomas Huang. 2011. Geographical topic discovery and comparison. In Proceedings of the 20th International Conference on World Wide Web (WWW’11). ACM, New York, NY, 247--256. DOI:http://dx.doi.org/10.1145/1963405.1963443", "Jing Yuan, Yu Zheng, and Xing Xie. 2012. Discovering regions of different functions in a city using human mobility and POIs. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’12). ACM, New York, NY, 186--194. DOI:http://dx.doi.org/10.1145/2339530.2339561", "Quan Yuan, Gao Cong, Zongyang Ma, Aixin Sun, and Nadia Magnenat-Thalmann. 2013. Time-aware point-of-interest recommendation. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’13). 363--372.", "Yi-Liang Zhao, Liqiang Nie, Xiangyu Wang, and Tat-Seng Chua. 2014. Personalized recommendations of locally interesting venues to tourists via cross-region community matching. ACM Transactions on Intelligent Systems and Technology 5, 3, Article No. 50.", "Vincent Wenchen Zheng, Yu Zheng, Xing Xie, and Qiang Yang. 2010. Collaborative location and activity recommendations with GPS history data. In Proceedings of the 19th International Conference on World Wide Web (WWW’10). 1029--1038. DOI:http://dx.doi.org/10.1145/1772690.1772795"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2842631"}, {"title": "Temporal Query Intent Disambiguation using Time-Series Data", "authors": ["Yue Zhao\n,", "Claudia Hauff"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUnderstanding temporal intents behind users' queries is essential to meet users' time-related information needs. In order to classify queries according to their temporal intent (e.g. Past or Future), we explore the usage of time-series data derived from Wikipedia page views as a feature source. While existing works leverage either proprietary search engine query logs or highly processed and aggregated data (such as Google Trends) for this purpose, we investigate the utility of a freely available data source for this purpose. Our experiments on the NTCIR-12 Temporalia-2 dataset show, that Wikipedia pageview-based time-series data can significantly improve the disambiguation of temporal intents for specific types of queries, in particular those without temporal expressions present in the query string.", "references": ["H. A. Carneiro and E. Mylonakis. Google trends: a web-based tool for real-time surveillance of disease outbreaks. Clinical infectious diseases, 49(10):1557--1564, 2009.", "P. Ferragina and U. Scaiella. Tagme: on-the-fly annotation of short text fragments. In CIKM '10, pages 1625--1628, 2010.", "C. C. Holt. Forecasting seasonals and trends by exponentially weighted moving averages. International journal of forecasting, 20(1):5--10, 2004.", "H. Joho, A. Jatowt, R. Blanco, H. Naka, and S. Yamamoto. Overview of NTCIR-11 temporal information access (temporalia) task. In Proceedings of the 11th NTCIR Conference on Evaluation of Information Access Technologies, 2014.", "H. Joho, A. Jatowt, R. Blanco, H. Yu, and S. Yamamoto. Overview of NTCIR-12 temporal information access (temporalia-2) task. In Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies, 2016.", "R. Jones and F. Diaz. Temporal profiles of queries. ACM Transactions on Information Systems, 25(3):14, 2007.", "N. Kanhabua, T. Ngoc Nguyen, and W. Nejdl. Learning to detect event-related queries for web search. In WWW '15, pages 1339--1344, 2015.", "A. Kulkarni, J. Teevan, K. M. Svore, and S. T. Dumais. Understanding temporal query dynamics. In WSDM '11, pages 167--176, 2011.", "S. Nunes, C. Ribeiro, and G. David. Use of temporal expressions in web search. In Advances in Information Retrieval, pages 580--584. Springer, 2008.", "K. Radinsky, E. Agichtein, E. Gabrilovich, and S. Markovitch. A word at a time: computing word relatedness using temporal semantic analysis. In WWW '11, pages 337--346, 2011.", "K. Radinsky, K. Svore, S. Dumais, J. Teevan, A. Bocharov, and E. Horvitz. Modeling and predicting behavioral dynamics on the web. In WWW '12, pages 599--608, 2012.", "M. Shokouhi. Detecting seasonal queries by time-series analysis. In SIGIR '11, pages 1171--1172, 2011.", "S. Whiting, J. M. Jose, and O. Alonso. Temporal dynamics of ambiguous queries. In TAIA2015 Workshop, volume 92, 2015.", "H. Yu, X. Kang, and F. Ren. Tuta1 at the ntcir-11 temporalia task. In Proceedings of the 11th NTCIR Conference on Evaluation of Information Access Technologies, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914767"}, {"title": "An Empirical Study on User Access Control in Online Social Networks", "authors": ["Minyue Ni\n,", "Yang Zhang\n,", "Weili Han\n,", "Jun Pang"], "publication": "SACMAT '16: Proceedings of the 21st ACM on Symposium on Access Control Models and Technologies", "abstract": "ABSTRACT\nIn recent years, access control in online social networks has attracted academia a considerable amount of attention. Previously, researchers mainly studied this topic from a formal perspective. On the other hand, how users actually use access control in their daily social network life is left largely unexplored. This paper presents the first large-scale empirical study on users' access control usage on Twitter and Instagram. Based on the data of 150k users on Twitter and 280k users on Instagram collected consecutively during three months in New York, we have conducted both static and dynamic analysis on users' access control usage. Our findings include: female users, young users and Asian users are more concerned about their privacy; users who enable access control setting are less active and have smaller online social circles; global events and important festivals can influence users to change their access control setting. Furthermore, we exploit machine learning classifiers to perform an access control setting prediction. Through experiments, the predictor achieves a fair performance with the AUC equals to 0.70, indicating whether a user enables her access control setting or not can be predicted to a certain extent.", "references": ["D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "G. Bruns, P. W. L. Fong, I. Siahaan, and M. Huth. Relationship-based access control: its expression and enforcement through hybrid logic. In Proc. 2nd ACM Conference on Data and Application Security and Privacy (CODASPY), pages 117--124. ACM, 2012.", "B. Carminati, E. Ferrari, R. Heatherly, M. Kantarcioglu, and B. Thuraisingham. A semantic web based framework for social network access control. In Proc. 14th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 177--186. ACM, 2009.", "B. Carminati, E. Ferrari, and A. Perego. Rule-based access control for social networks. In Proc. IFIP WG 2.12 and 2.14 Semantic Web Workshop (OTM), volume 4278 of LNCS, pages 1734--1744. Springer, 2006.", "M. Cha, H. Haddadi, and F. B. K. P. Gummadi. Measuring user influence in Twitter: The million follower fallacy. In Proc. 4th AAAI Conference on Weblogs and Social Media (ICWSM), pages 10--17. The AAAI Press, 2010.", "M. Cramer, J. Pang, and Y. Zhang. A logical approach to restricting access in online social networks. In Proc. 20th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 75--86. ACM, 2015.", "J. Crampton and J. Sellwood. Path conditions and principal matching: a new approach to access control. In Proc. 19th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 187--198. ACM, 2014.", "R. Dey, Z. Jelveh, and K. Ross. Facebook users have become much more private: A large-scale study. In Proc. 2012 IEEE International Conference on Pervasive Computing and Communications Workshops, pages 346--352. IEEE, 2012.", "P. W. L. Fong. Preventing sybil attacks by privilege attenuation: a design principle for social network systems. In Proc. 32nd IEEE Symposium on Security and Privacy (S&P), pages 263--278. IEEE CS, 2011.", "P. W. L. Fong, M. M. Anwar, and Z. Zhao. A privacy preservation model for Facebook-style social network systems. In Proc. 14th European Symposium on Research in Computer Security (ESORICS), volume 5789 of LNCS, pages 303--320. Springer, 2009.", "P. W. L. Fong and I. Siahaan. Relationship-based access control policies and their policy languages. In Proc. 16th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 51--60. ACM, 2011.", "Y. Liu, K. P. Gummadi, B. Krishnamurthy, and A. Mislove. Analyzing Facebook privacy settings: user expectations vs. reality. In Proc. 2011 ACM SIGCOMM conference on Internet measurement conference (IMC), pages 61--70. ACM, 2011.", "M. Mondal, Y. Liu, B. Viswanath, K. P. Gummadi, and A. Mislove. Understanding and specifying social access control lists. In Proc. 10th Symposium on Usable Privacy and Security (SOUPS), pages 271--283. USENIX Association, 2012.", "J. Pang and Y. Zhang. A new access control scheme for Facebook-style social networks. In Proc. 9th Conference on Availability, Reliability and Security (ARES), pages 1--10. IEEE CS, 2014.", "J. Pang and Y. Zhang. Cryptographic protocols for enforcing relationship-based access control policies. In Proc. 39th Annual IEEE Computers, Software & Applications Conference (COMPSAC), pages 484--493. IEEE CS, 2015.", "J. Pang and Y. Zhang. Location prediction: communities speak louder than friends. In Proc. 3rd ACM on Conference on Online Social Networks (COSN), pages 161--171. ACM, 2015.", "J. Pang and Y. Zhang. A new access control scheme for Facebook-style social networks. Computers & Security, 54:44--59, 2015.", "M. J. Paul and M. Dredze. You are what you tweet: Analyzing twitter for public health. In Proc. 5th AAAI Conference on Weblogs and Social Media (ICWSM), pages 265--272. The AAAI Press, 2011.", "M. Redi, D. Quercia, L. Graham, and S. Gosling. Like partying? your face says it all. Predicting the ambiance of places with profile pictures. In Proc. 9th AAAI Conference on Weblogs and Social Media (ICWSM), pages 347--356. The AAAI Press, 2015.", "F. Souza, D. de Las Casas, V. Flores, S. Youn, M. Cha, D. Quercia, and V. Almeida. Dawn of the selfie era: The whos, wheres, and hows of selfies on Instagram. In Proc. 3rd ACM on Conference on Online Social Networks (COSN), pages 221--231. ACM, 2015.", "F. Stutzman, R. Gross, and A. Acquisti. Silent listeners: The evolution of privacy and disclosure on Facebook. Journal of Privacy and Confidentiality, 4(2):2, 2013.", "E. Tarameshloo, P. W. L. Fong, and P. Mohassel. On protection in federated social computing systems. In Proc. 4th ACM Conference on Data and Application Security and Privacy (CODASPY), pages 75--86. ACM, 2014.", "J. W. Tukey. Exploratory Data Analysis. Pearson, 1977.", "W. X. Zhao, J. Jiang, J. Weng, J. He, E.-P. Lim, H. Yan, and X. Li. Comparing Twitter and traditional media using topic models. In Proc. 33rd European Conference on IR Research (ECIR), volume 6611 of LNCS, pages 338--349. Springer, 2011.", "Y. Zhong, N. J. Yuan, W. Zhong, F. Zhang, and X. Xie. You are where you go: Inferring demographic attributes from location check-ins. In Proc. 8th ACM International Conference on Web Search and Data Mining (WSDM), pages 295--304. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914642.2914644"}, {"title": "Exploiting SSDs in operational multiversion databases", "authors": ["Mohammad Sadoghi\n,", "Kenneth A. Ross\n,", "Mustafa Canim\n,", "Bishwaranjan Bhattacharjee"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nMultiversion databases store both current and historical data. Rows are typically annotated with timestamps representing the period when the row is/was valid. We develop novel techniques to reduce index maintenance in multiversion databases, so that indexes can be used effectively for analytical queries over current data without being a heavy burden on transaction throughput. To achieve this end, we re-design persistent index data structures in the storage hierarchy to employ an extra level of indirection. The indirection level is stored on solid-state disks that can support very fast random I/Os, so that traversing the extra level of indirection incurs a relatively small overhead. The extra level of indirection dramatically reduces the number of magnetic disk I/Os that are needed for index updates and localizes maintenance to indexes on updated attributes. Additionally, we batch insertions within the indirection layer in order to reduce physical disk I/Os for indexing new records. In this work, we further exploit SSDs by introducing novel DeltaBlock techniques for storing the recent changes to data on SSDs. Using our DeltaBlock, we propose an efficient method to periodically flush the recently changed data from SSDs to HDDs such that, on the one hand, we keep track of every change (or delta) for every record, and, on the other hand, we avoid redundantly storing the unchanged portion of updated records. By reducing the index maintenance overhead on transactions, we enable operational data stores to create more indexes to support queries. We have developed a prototype of our indirection proposal by extending the widely used generalized search tree open-source project, which is also employed in PostgreSQL. Our working implementation demonstrates that we can significantly reduce index maintenance and/or query processing cost by a factor of 3. For the insertion of new records, our novel batching technique can save up to 90 % of the insertion time. For updates, our prototype demonstrates that we can significantly reduce the database size by up to 80 % even with a modest space allocated for DeltaBlocks on SSDs.", "references": ["BioPostgres: Data management for computational biology. http://www.biopostgres.org/", "IBM DB2 Database for Linux, UNIX, and Windows. www.ibm.com/software/data/db2/linux-unix-windows/", "IBM DB2 with BLU Acceleration. www.ibm.com/software/data/db2/linux-unix-windows/db2-blu-acceleration/", "OpenFTS: Open source full text search engine. http://openfts.sourceforge.net/", "PostGIS: Geographic information systems. http://postgis.refractions.net/", "PostgreSQL: Open source object-relational database system. http://www.postgresql.org/", "YAGO2: High-quality knowledge base. http://www.mpi-inf.mpg.de/yago-naga/yago/", "Agrawal, D., Ganesan, D., Sitaraman, R.K., Diao, Y., Singh, S.: Lazy-adaptive tree: an optimized index structure for flash devices. PVLDB 2(1), 361---372 (2009)", "Ang, C.-H., Tan, K.-P.: The interval B-tree. Inf. Process. Lett. 53(2), 85---89 (1995)", "Arpaci-Dusseau, R., Arpaci-Dusseau, A.: Operating Systems: Three Easy Pieces. Arpaci-Dusseau Books, 0.5 edition (2012)", "Athanassoulis, M., Chen, S., Ailamaki, A., Gibbons, P.B., Stoica, R.: MaSM: efficient online updates in data warehouses. In: SIGMOD Conference, pp. 865---876 (2011)", "Becker, B., Gschwind, S., Ohler, T., Seeger, B., Widmayer, P.: An asymptotically optimal multiversion B-Tree. VLDB J. 5(4), 264---275 (1996)", "Bhattacharjee, B., Lim, L., Malkemus, T., Mihaila, G., Ross, K., Lau, S., McArthur, C., Toth, Z., Sherkat, R.: Efficient index compression in DB2 LUW. Proc. VLDB Endow. 2(2), 1462---1473 (2009)", "Bhattacharjee, B., Malkemus, T., Lau, S., Mckeough, S., Kirton, J.-A., Boeschoten, R.V., Kennedy, J.: Efficient bulk deletes for multi dimensionally clustered tables in DB2. In: VLDB, pp. 1197---1206 (2007)", "Bhattacharjee, B., Ross, K.A., Lang, C.A., Mihaila, G.A., Banikazemi, M.: Enhancing recovery using an SSD buffer pool extension. In: DaMoN, pp. 10---16 (2011)", "Bozkaya, T., Özsoyoğlu, M.: Indexing valid time intervals. Lect. Notes Comput. Sci. 1460, 541---550 (1998)", "Canim, M., Bhattacharjee, B., Mihaila, G.A., Lang, C.A., Ross, K.A.: An object placement advisor for DB2 using solid state storage. PVLDB 2(2), 1318---1329 (2009)", "Canim, M., Mihaila, G.A., Bhattacharjee, B., Ross, K.A., Lang, C.A.: SSD bufferpool extensions for database systems. PVLDB 3(2), 1435---1446 (2010)", "Chaudhuri, S., Narasayya, V.: Automating statistics management for query optimizers. IEEE Trans. Knowl. Data Eng 13(1), 7---20 (2001)", "Chaudhuri, S., Narasayya, V.R.: An efficient cost-driven index selection tool for microsoft SQL server. In: Proceedings of the 23rd International Conference on Very Large Data Bases, VLDB '97, pp. 146---155. Morgan Kaufmann Publishers Inc., San Francisco (1997)", "Chen, F., Luo, T., Zhang, X.: CAFTL: a content-aware flash translation layer enhancing the lifespan of flash memory based solid state drives. In: FAST, pp. 77---90 (2011)", "Chen, S.: Time travel query or bi-temporal. In: DB2 for z/OS Technical Forum (2010)", "Do, J., Zhang, D., Patel, J.M., DeWitt, D.J., Naughton, J.F., Halverson, A.: Turbocharging DBMS buffer pool using SSDs. In: Proceedings of the 2011 ACM SIGMOD International Conference on Management of data, SIGMOD '11, pp. 1113---1124. ACM, New York (2011)", "Dou, A.J., Lin, S., Kalogeraki, V.: Real-time querying of historical data in flash-equipped sensor devices. In: IEEE Real-Time Systems Symposium, pp. 335---344 (2008)", "Drossel, G.: Methodologies for calculating SSD usable life. In: Storage Developer Conference (2009)", "Elmasri, R., Wuu, G.T.J., Kouramajian, V.: The time index and the monotonic B+-tree. In: Temporal Databases, pp. 433---456 (1993)", "Fusion-io breaks one billion IOPS barrier. http://www.fusionio.com/press-releases/fusion-io-breaks-one-billion-iops-barrier/", "Garcia-Molina, H., Ullman, J.D., Widom, J.: Database Systems: The Complete Book, 2nd edn. Prentice Hall Press, Upper Saddle River, NJ (2008)", "The GiST indexing project. http://gist.cs.berkeley.edu/", "Gunadhi, H., Segev, A.: Efficient indexing methods for temporal relations. IEEE Trans. Knowl. Data Eng. 5(3), 496 (1993)", "Hellerstein, J.M., Naughton, J.F., Pfeffer, A.: Generalized search trees for database systems. In: Proceedings of the 21th International Conference on Very Large Data Bases, VLDB '95, pp. 562---573. Morgan Kaufmann Publishers Inc., San Francisco (1995)", "Hinshaw, F.D., Harris, C.S., Sarin, S.K.: Controlling visibility in multi-version database systems. US 7305386 Patent, Netezza Corporation (2007)", "Hitz, D., Lau, J., Malcolm, M.: File system design for an NFS file server appliance. In: Proceedings of the USENIX Winter 1994 Technical Conference, WTEC'94, pp. 19---19. USENIX Association, Berkeley (1994)", "DB2 10 for z/OS. ftp://public.dhe.ibm.com/software/systemz/whitepapers/DB210_for_zOS_Upgrade_ebook", "Inmon, W.H.: Building the Operational Data Store, 2nd edn. Wiley, New York (1999)", "Jouini, K., Jomier, G.: Indexing multiversion databases. In: Proceedings of the Sixteenth ACM Conference on Information and Knowledge Management, CIKM '07, pp. 915---918. ACM, New York (2007)", "Kang, W.-H., Lee, S.-W., Moon, B.: Flash-based extended cache for higher throughput and faster recovery. PVLDB 5(11), 1615---1626 (2012)", "Larson, P.-A., Blanas, S., Diaconu, C., Freedman, C., Patel, J.M., Zwilling, M.: High-performance concurrency control mechanisms for main-memory databases. Proc. VLDB Endow. 5(4), 298---309 (2011)", "Levandoski, J.J., Lomet, D.B., Sengupta, S.: The Bw-Tree: a B-tree for new hardware platforms. In: Proceedings of the 2013 IEEE 29th International Conference on Data Engineering, ICDE '13. IEEE Computer Society, Washington (2013)", "Leventhal, A.: Flash storage memory. Commun. ACM 51(7), 47---51 (2008)", "Li, Y., He, B., Luo, Q., Yi, K.: Tree indexing on flash disks. In: Proceedings of the 2009 IEEE International Conference on Data Engineering, ICDE '09, pp. 1303---1306. IEEE Computer Society, Washington (2009)", "Lomet, D., Barga, R., Mokbel, M.F., Shegalov, G., Wang, R., Zhu, Y.: Immortal DB: transaction time support for SQL server. In: Proceedings of the 2005 ACM SIGMOD international conference on Management of data, SIGMOD '05, pp. 939---941. ACM, New York (2005)", "Lomet, D., Hong, M., Nehme, R., Zhang, R.: Transaction time indexing with version compression. Proc. VLDB Endow. 1(1), 870---881 (2008)", "Menon, P., Rabl, T., Sadoghi, M., Jacobsen, H.: CaSSanDra: an SSD boosted key-value store. In: IEEE 30th International Conference on Data Engineering, Chicago, ICDE 2014, IL, USA, March 31---April 4, 2014, pp. 1162---1167 (2014)", "Murphy, G., Compher, D.: DB2 storage observations (2011)", "Omiecinski, E., Liu, W., Akyildiz, I.F.: Analysis of a deferred and incremental update strategy for secondary indexes. Inf. Syst. 16(3), 345---356 (1991)", "O'Neil, P.E., Cheng, E., Gawlick, D., O'Neil, E.J.: The log-structured merge-tree (LSM-Tree). Acta Inf. 33(4), 351---385 (1996)", "Oracle database 11g workspace manager overview. http://www.oracle.com/technetwork/database/twp-appdev-workspace-manager-11g-128289", "Oracle total recall/flashback data archive. http://www.oracle.com/technetwork/issue-archive/2008/08-jul/flashback-data-archive-whitepaper-129145", "Rabl, T., Gómez-Villamor, S., Sadoghi, M., Muntés-Mulero, V., Jacobsen, H.-A., Mankovskii, S.: Solving big data challenges for enterprise application performance management. Proc. VLDB Endow. 5(12), 1724---1735 (2012)", "Rosenblum, M., Ousterhout, J.K.: The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10(1), 26---52 (1992)", "Sadoghi, M., Canim, M., Bhattacharjee, B., Nagel, F., Ross, K.A.: Reducing database locking contention through multi-version concurrency. Proc. VLDB Endow. 7(13), 1331---1342 (2014)", "Sadoghi, M., Ross, K.A., Canim, M., Bhattacharjee, B.: Making updates disk-I/O friendly using SSDs. Proc. VLDB Endow. 6(11), 997---1008 (2013)", "Salzberg and Tsotras: Comparison of access methods for time-evolving data. CSURV. Comput. Surv. 31(2), 158---221 (1999). doi:10.1145/319806.319816", "Samy, V., Lu, W., Rada, A., Punit, S., Srinivasan, S.: Best practices physical database design for online transaction processing (OLTP) environments (2011)", "Saracco, C.M., Nicola, M., Gandhi, L.: A matter of time: temporal data management in DB2 for z/OS (2010)", "Sears, R., Ramakrishnan, R.: bLSM: a general purpose log structured merge tree. In: SIGMOD Conference, pp. 217---228 (2012)", "Shen, H., Chin, B., Lu, O.H.: The TP-Index: a dynamic and efficient indexing mechanism for temporal databases. In: Proceedings of the Tenth International Conference on Data Engineering, pp. 274---281. IEEE (1994)", "Snodgrass, R.T.: A case study of temporal data. Teradata Corporation, Dayton (2010)", "TPC-H, decision support benchmark. http://www.tpc.org/tpch/", "Vo, H.T., Wang, S., Agrawal, D., Chen, G., Ooi, B.C.: LogBase: a scalable log-structured database system in the cloud. PVLDB 5(10), 1004---1015 (2012)", "Volos, H., Tack, A.J., Swift, M.M.: Mnemosyne: lightweight persistent memory. In: Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XVI, pp. 91---104. ACM, New York (2011)", "Wu, C.-H., Kuo, T.-W., Chang, L.-P.: An efficient B-tree layer implementation for flash-memory storage systems. ACM Trans. Embedded Comput. Syst. 6(3) (2007). doi:10.1145/1275986.1275991"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0410-5"}, {"title": "Toward elastic memory management for cloud data analytics", "authors": ["Jingjing Wang\n,", "Magdalena Balazinska"], "publication": "BeyondMR '16: Proceedings of the 3rd ACM SIGMOD Workshop on Algorithms and Systems for MapReduce and Beyond", "abstract": "ABSTRACT\nWe present several key elements towards elastic memory management in modern big data systems. The goal of our approach is to avoid out-of-memory failures without over-provisioning but also to avoid garbage-collection overheads when possible.", "references": ["Tungsten: Memory management and binary processing on spark. https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html.", "Memory management in the Java HotSpot™virtual machine. http://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf, 2006.", "N. Anciaux et al. Memory requirements for query execution in highly constrained devices. In VLDB, 2003.", "K. P. Brown et al. Managing memory to meet multiclass workload response time goals. In VLDB, 1993.", "C. Chen et al. Adaptive database buffer allocation using query feedback. In VLDB, 1993.", "J. E. Cook et al. Semi-automatic, self-adaptive control of garbage collection rates in object databases. In SIGMOD, 1996.", "D. L. Davison et al. Dynamic resource brokering for multi-user query execution. In SIGMOD, 1995.", "C. Faloutsos et al. Predictive load control for flexible buffer allocation. In VLDB, 1991.", "M. N. Garofalakis et al. Parallel query scheduling and optimization with time- and space-shared resources. In VLDB, 1997.", "M. Hall et al. The weka data mining software: An update. 2009.", "D. Halperin et al. Demo of the Myria big data management service. In SIGMOD, 2014.", "H. Herodotou et al. No one (cluster) size fits all: automatic cluster sizing for data-intensive analytics. In SoCC, 2011.", "H. Herodotou et al. Starfish: A self-tuning system for big data analytics. In CIDR, 2011.", "B. Hindman et al. Mesos: A platform for fine-grained resource sharing in the data center. In NSDI, 2011.", "M. Kornacker et al. Impala: A modern, open-source SQL engine for hadoop. In CIDR, 2015.", "W. Lang et al. Towards multi-tenant performance slos. IEEE Trans. Knowl. Data Eng., 2014.", "J. Li et al. Resource bricolage for parallel database systems. Proc. of the VLDB Endow., 2014.", "Y. Low et al. Distributed GraphLab: a framework for machine learning and data mining in the cloud. In VLDB, 2012.", "D. G. Murray et al. Naiad: A timely dataflow system. In SOSP, 2013.", "V. R. Narasayya et al. Sharing buffer pool memory in multi-tenant relational database-as-a-service. Proc. of the VLDB Endow., 2015.", "R. T. Ng et al. Flexible buffer allocation based on marginal gains. In SIGMOD, 1991.", "H. Pang et al. Managing memory for real-time queries. In SIGMOD, 1994.", "T. A. Project. Apache Giraph, http://giraph.apache.org/.", "J. Schaffner et al. Predicting in-memory database performance for automating cluster management tasks. In ICDE, 2011.", "A. J. Storm et al. Adaptive self-tuning memory in DB2. In VLDB, 2006.", "P. Tembey et al. Merlin: Application- and platform-aware resource allocation in consolidated server systems. In SoCC, 2014.", "V. K. Vavilapalli et al. Apache hadoop YARN: yet another resource negotiator. In SoCC, 2013.", "M. Weimer et al. REEF: retainable evaluator execution framework. In SIGMOD, 2015.", "T. White. Hadoop: The Definitive Guide. 2009.", "M. Zaharia et al. Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing. In NSDI, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926534.2926541"}, {"title": "TweetSift: Tweet Topic Classification Based on Entity Knowledge Base and Topic Enhanced Word Embedding", "authors": ["Quanzhi Li\n,", "Sameena Shah\n,", "Xiaomo Liu\n,", "Armineh Nourbakhsh\n,", "Rui Fang"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nClassifying tweets into topic categories is necessary and important for many applications, since tweets are about a variety of topics and users are only interested in certain topical areas. Many tweet classification approaches fail to achieve high accuracy due to data sparseness issue. Tweet, as a special type of short text, in additional to its text, also has other metadata that can be used to enrich its context, such as user name, mention, hashtag and embedded link. In this demonstration, we present TweetSift, an efficient and effective real time tweet topic classifier. TweetSift exploits external tweet-specific entity knowledge to provide more topical context for a tweet, and integrates them with topic enhanced word embeddings for topic classification. The demonstration will show how TweetSift works and how it is incorporated with our social media event detection system.", "references": ["S. Banerjee, K. Ramanathan, and A. Gupta. Clustering short texts using Wikipedia. Proc. ACM SIGIR, 2007.", "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 2011", "Blei, D., Ng, A. and Jordan, M., Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993--1022, 2003", "Blei, D., Probabilistic topic models. Communication of ACM, 55(4):77--84, 2012", "Bollegala, D., Y. Matsuo, and M. Ishizuka, Measuring semantic similarity between words using Web search engines. WWW 2007", "P. Liu, X. Qiu and X. Huang, Learning Context-Sensitive Word Embeddings with Neural Tensor Skip-Gram Model, IJCAI 2015", "Y. Liu, Z. Liu, T. Chua and M. Sun, Topical Word Embeddings, AAAI 2015", "Mikolov, T.; Chen, K.; Corrado, G. and Dean J., Efficient Estimation of Word Representations in Vector Space. Workshop at ICLR, 2013", "A. Pal nad S. Counts, Identifying Topical Authorities in Microblogs, WSDM 2011", "Owoputi, O.; Connor, B.; Dyer, C., Gimpel, K., Schneider, N., and Smith, N., Improved part-of-speech tagging for online conversational text with word clusters. NAACL 2013.", "Sahami, M. & Heilman. T., A Web based kernel function for measuring the similarity of short text snippets. WWW 2006.", "Yang, S., Kolcz, A., Schlaikjer, A., and Gupta, P., Large-scale high-precision topic modeling on Twitter, KDD 2014", "W. Yih and C. Meek. Improving similarity measures for short segments of text. AAAI 2007"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983325"}, {"title": "Context Trees: Augmenting Geospatial Trajectories with Context", "authors": ["Alasdair Thomason\n,", "Nathan Griffiths\n,", "Victor Sanchez"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nExposing latent knowledge in geospatial trajectories has the potential to provide a better understanding of the movements of individuals and groups. Motivated by such a desire, this work presents the context tree, a new hierarchical data structure that summarises the context behind user actions in a single model. We propose a method for context tree construction that augments geospatial trajectories with land usage data to identify such contexts. Through evaluation of the construction method and analysis of the properties of generated context trees, we demonstrate the foundation for understanding and modelling behaviour afforded. Summarising user contexts into a single data structure gives easy access to information that would otherwise remain latent, providing the basis for better understanding and predicting the actions and behaviours of individuals and groups. Finally, we also present a method for pruning context trees for use in applications where it is desirable to reduce the size of the tree while retaining useful information.", "references": ["Saif Ahmad, Tugba Taskaya-Temizel, and Khurshid Ahmad. 2004. Summarizing time series: Learning Patterns in ‘volatile’ series. In Proceedings of the 5th International Conference on Intelligent Data Engineering and Automated Learning. Springer, Exeter, 523--532. DOI:http://dx.doi.org/ 10.1007/978-3-540-28651-6_77", "Juan Antonio Alvarez-Garcia, Juan Antonio Ortega, Luis Gonzalez-Abril, and Francisco Velasco. 2010. Trip destination prediction based on past GPS log using a hidden markov model. Expert Syst. Applic. 37, 12 (2010), 8166--8171. DOI:http://dx.doi.org/10.1016/j.eswa.2010.05.070", "Christos Anagnostopoulos, Athanasios Tsounis, and Stathes Hadjiefthymiades. 2006. Context awareness in mobile computing environments. Wireless Pers. Commun. 42, 3 (2006), 445--464. DOI:http://dx.doi.org/ 10.1007/s11277-006-9187-6", "Saif Ahmad, Tugba Taskaya-Temizel, and Khurshid Ahmad. 2004. Summarizing time series: Learning Patterns in ‘volatile’ series. In Proceedings of the 5th International Conference on Intelligent Data Engineering and Automated Learning. Springer, Exeter, 523--532. DOI:http://dx.doi.org/ 10.1007/978-3-540-28651-6_77", "Juan Antonio Alvarez-Garcia, Juan Antonio Ortega, Luis Gonzalez-Abril, and Francisco Velasco. 2010. Trip destination prediction based on past GPS log using a hidden markov model. Expert Syst. Applic. 37, 12 (2010), 8166--8171. DOI:http://dx.doi.org/10.1016/j.eswa.2010.05.070", "Christos Anagnostopoulos, Athanasios Tsounis, and Stathes Hadjiefthymiades. 2006. Context awareness in mobile computing environments. Wireless Pers. Commun. 42, 3 (2006), 445--464. DOI:http://dx.doi.org/ 10.1007/s11277-006-9187-6", "Gennady Andrienko, Natalia Andrienko, Christophe Hurter, Salvatore Rinzivillo, and Stefan Wrobel. 2011. From movement tracks through events to places: Extracting and characterizing significant places from mobility data. In Proceedings of the IEEE Conference on Visual Analytics Science and Technology. 161--170. DOI:http://dx.doi.org/10.1109/VAST.2011.6102454", "Daniel Ashbrook and Thad Starner. 2002. Learning significant locations and predicting user movement with GPS. In Proceedings of the 6th International Symposium on Wearable Computers. 101--108. DOI:http://dx.doi.org/10.1109/ISWC.2002.1167224", "Daniel Ashbrook and Thad Starner. 2003. Using GPS to learn significant locations and predict movement across multiple users. Pers. Ubiq. Comput. 7, 5 (2003), 275--286. DOI:http://dx.doi.org/10. 1007/s00779-003-0240-0", "Athanasios Bamis and Andreas Savvides. 2011. Exploiting human state information to improve GPS sampling. In Proceedings of the IEEE International Conference on Pervasive Computing and Communications Workshops. 32--37. DOI:http://dx.doi.org/10.1109/PERCOMW.2011.5766898", "Jie Bao, Yu Zheng, David Wilkie, and Mohamed Mokbel. 2015. Recommendations in location-based social networks: A survey. GeoInformatica 19, 3 (2015), 525--565. DOI:http://dx.doi.org/10.1007/s10707-014-0220-8", "Tengfei Bao, Huanhuan Cao, Enhong Chen, Jilei Tian, and Hui Xiong. 2011. An unsupervised approach to modelling personalized contexts of mobile users. Knowl. Inform. Syst. 31, 2 (2011), 345--370. DOI:http://dx.doi.org/ 10.1007/s10115-011-0417-1", "Huanhuan Cao, Tengfei Bao, Qiang Yang, Enhong Chen, and Jilei Tian. 2010. An effective approach for mining mobile user habits. In Proceedings of the 19th ACM International Conference on Information and Knowledge Management. 1677--1680. DOI:http://dx.doi.org/10.1145/1871437.1871702", "Huiping Cao, Nikos Mamoulis, and David Cheung. 2005. Mining frequent spatio-temporal sequential patterns. In Proceedings of the 5th IEEE International Conference on Data Mining. 82--89. DOI:http://dx.doi.org/10.1109/ICDM.2005.95", "Huiping Cao, Nikos Mamoulis, and David W. Cheung. 2007. Discovery of periodic patterns in spatiotemporal sequences. IEEE Trans. Knowl. Data Eng. 19, 4 (2007), 453--467. DOI:http://dx.doi.org/10. 1109/TKDE.2007.1002", "Qing Cao, Bouchra Bouqata, Patricia D. Mackenzie, Daniel Messier, and Josheph J. Salvo. 2009. A grid-based clustering method for mining frequent trips from large-scale, event-based telematics datasets. In Proceedings of the 2009 IEEE International Conference on Systems, Man and Cybernetics. 2996--3001. DOI:http://dx.doi.org/10.1109/ICSMC.2009.5345924", "Chao Chen, Daqing Zhang, Pablo Samuel Castro, Nan Li, Lin Sun, and Shijian Li. 2011. Real-time detection of anomalous taxi trajectories from GPS traces. In Proceedings of the 8th International ICST Conference on Mobile and Ubiquitous Systems. 63--74. DOI:http://dx.doi.org/10.1007/978-3-642-30973-1_6", "Ling Chen, Mingqi Lv, and Gencai Chen. 2010. A system for destination and future route prediction based on trajectory mining. Perv. Mobile Comput. 6, 6 (2010), 657--676. DOI:http://dx.doi.org/ 10.1016/j.pmcj.2010.08.004", "Peng Chen, Zhao Lu, and Junzhong Gu. 2009. Vehicle travel time prediction algorithm based on historical data and shared location. In Proceedings of the 5th International Joint Conference on INC, IMS and IDC. 1632--1637. DOI:http://dx.doi.org/10.1109/NCM.2009.138", "Yohan Chon, Elmurod Talipov, Hyojeong Shin, and Hojung Cha. 2011. Mobility prediction-based smartphone energy optimization for everyday location monitoring. In Proceedings of the 17th International Conference on World Wide Web. 82--85. DOI:http://dx.doi.org/10.1145/2070942.2070952", "Tanzeem Choudhury, Sunny Consolvo, Beverly Harrison, Jeffrey Hightower, Louis LeGrand, Ali Rahimi, Adam Rea, Gaetano Borriello, Bruce Hemingway, Predrag Klasnja, Karl Koscher, James A. Landay, Jonathan Lester, Danny Wyatt, and Dirk Haehnel. 2008. The mobile sensing platform: An embedded activity recognition system. Perv. Comput. 7, 2 (2008), 32--41. DOI:http://dx.doi.org/10.1109/MPRV.2008.39", "Anind Dey and Gregory Abowd. 1999. Towards a better understanding of context and context-awareness. In Proceedings of the 1st International Symposium on Handheld and Ubiquitous Computing. Karlsruhe, 304--307. DOI:http://dx.doi.org/10.1007/3-540-48157-5_29", "Nathan Eagle and Alex Sandy Pentland. 2009. Eigenbehaviors: Identifying structure in routine. Behav. Ecol. Sociobiol. 63, 7 (2009), 1057--1066. DOI:http://dx.doi.org/10.1007/s00265-009-0739-0", "Nathan Eagle and Alex Sandy Pentland. 2005. Reality mining: Sensing complex social systems. Pers. Ubiq. Comput. 10, 4 (2005), 255--268. DOI:http://dx.doi.org/10.1007/s00779-005-0046-3", "Mica R. Endsley. 1995. Toward a theory of situation awareness in dynamic systems. Hum. Factors: J. Hum. Factors Ergon. Soc. 37 (1995), 32--64. Issue 1.", "Mica R. Endsley. 2000. Theoretical underpinnings of situation awareness: A critical review. In Situation Awareness Analysis and Measurement, Mica R. Endsley and Daniel J. Garland (Eds.). Routledge, 3--32.", "Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proceedings of the 16th International Conference on Knowledge Discovery and Data Mining. 226--231.", "Katayoun Farrahi and Daniel Gatica-Perez. 2008. Daily routine classification from mobile phone data. In Proceedings of the 5th International Workshop on Machine Learning for Multimodal Interaction. 173--184. DOI:http://dx.doi.org/10.1007/978-3-540-85853-9_16", "Katayoun Farrahi and Daniel Gatica-Perez. 2010. Probabilistic mining of socio-geographic routines from mobile phone data. IEEE J. Select. Top. Sign. Process. 4, 4 (2010), 746--755. DOI:http://dx.doi.org/ 10.1109/JSTSP.2010.2049513", "Jun Fukano, Tomohiro Mashita, Takahiro Hara, and Kiyoshi Kiyokawa. 2013. A next location prediction method for smartphones using blockmodels. In Proceedings of the IEEE Conference on Virtual Reality. 1--4. DOI:http://dx.doi.org/10.1109/VR.2013.6549434", "Huiji Gao, Jiliang Tang, and Huan Liu. 2012. Mobile location prediction in spatio-temporal context. In Proceedings of the Nokia Mobile Data Challenge (MDC) Workshop in Conjunction with Pervasive.", "Fosca Giannotti, Mirco Nanni, Fabio Pinelli, and Dino Pedreschi. 2007. Trajectory pattern mining. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 330--339. DOI:http://dx.doi.org/10.1145/1281192.1281230", "Joachim Gudmundsson, Marc van Kreveld, and Bettina Speckmann. 2004. Efficient detection of motion patterns in spatio-temporal data sets. In Proceedings of the 12th Annual ACM International Workshop on Geographic Information Systems. 250--257. DOI:http://dx.doi.org/10.1145/1032222.1032259", "Riccardo Guidotti, Roberto Trasarti, and Mirco Nanni. 2015. TOSCA: TwO-steps clustering algorithm for personal locations detection. In Proceedings of the 23rd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems.", "Newton Howard. 2002. Theory of Intention Awareness in Tactical Military Intelligence: Reducing Uncertainty by Understanding the Cognitive Architecture of Intentions. AuthorHouse, Bloomington.", "Newton Howard and Erik Cambria. 2013. Intention awareness: Improving upon situation awareness in human-centric environments. Human-cent. Comput. Inform. Sci. 3, 1 (2013), 17. DOI:http://dx.doi.org/ 10.1186/2192-1962-3-9", "Baoxing Huai, Enhong Chen, Hengshu Zhu, Hui Xiong, Tengfei Bao, Qi Liu, and Jilei Tian. 2014. Toward personalized context recognition for mobile users: A semisupervised bayesian HMM approach. ACM Trans. Knowl. Discov. Data 9, 2 (2014), 10:1--10:29. DOI:http://dx.doi.org/10.1145/2629504", "Eunju Kim, Sumi Helal, and Diane Cook. 2010. Human activity recognition and pattern discovery. Perv. Comput. 9, 1 (2010), 48--53. DOI:http://dx.doi.org/10.1109/MPRV.2010.7", "Niko Kiukkonen, Jan Blom, Olivier Dousse, Daniel Gatica-Perez, and Juha Laurila. 2010. Towards rich mobile phone datasets: Lausanne data collection campaign. In Proceedings of the First Workshop on Modeling and Retrieval of Context. Berlin.", "John Krumm and Eric Horvitz. 2006. Predestination: Inferring destinations from partial trajectories. In Proceedings of the 13th International Conference on Ubiquitous Computing. 243--260. DOI:http://dx.doi.org/10.1007/11853565_15", "John Krumm and Dany Rouhana. 2013. Placer: Semantic place labels from diary data. In Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing. 163--172. DOI:http://dx.doi.org/10.1145/2493432.2493504", "Juha K. Laurila, Daniel Gatica-Perez, Imad Aad, Jan Blom, Olivier Bornet, Trinh Minh Tri Do, Olivier Dousse, Julien Eberle, and Markus Miettinen. 2012. The mobile data challenge: Big data for mobile computing research. In Proceedings of the Nokia Mobile Data Challenge (MDC) Workshop in Conjunction with Pervasive.", "Rikard Laxhammar and Goran Falkman. 2011. Sequential conformal anomaly detection in trajectories based on hausdorff distance. In Proceedings of the 14th International Conference on Information Fusion. 1--8.", "Rikard Laxhammar and Goran Falkman. 2014. Online learning and sequential anomaly detection in trajectories. IEEE Trans. Pattern Anal. Mach. Intell. 36, 6 (2014), 1158--1173. DOI:http://dx.doi.org/ 10.1109/TPAMI.2013.172", "Seon-Woo Lee and Kenji Mase. 2002. Activity and location recognition using wearable sensors. Perv. Comput. 1, 3 (2002), 24--32. DOI:http://dx.doi.org/10.1109/MPRV.2002.1037719", "Tayeb Lemlouma and Nabil Layaida. 2004. Context-aware adaptation for mobile devices. In Proceedings of the IEEE International Conference on Mobile Data Management. 106--111. DOI:http://dx.doi.org/ 10.1109/MDM.2004.1263048", "Jonathan Lester, Tanzeem Choudhury, Nicky Kern, Gaetano Borriello, and Blake Hannaford. 2005. A hybrid discriminative/generative approach for modeling human activities. In Proceedings of the 19th International Joint Conference on Artificial Intelligence. 766--772.", "Zhenhui Li, Bolin Ding, Jiawei Han, Roland Kays, and Peter Nye. 2010. Mining periodic behaviors for moving objects. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1099--1108. DOI:http://dx.doi.org/10.1145/1835804.1835942", "Lin Liao, Donald J. Patterson, Dieter Fox, and Henry Kautz. 2007. Learning and inferring transportation routines. Artif. Intell. 171, 5--6 (2007), 311--331. DOI:http://dx.doi.org/10.1016/j.artint.2007.01.006", "Siyuan Liu, Huanhuan Cao, L Li, and MengChu Zhou. 2013. Predicting stay time of mobile users with contextual information. IEEE Trans. Automat. Sci. Eng. 10, 4 (2013), 1026--1036. DOI:http://dx.doi.org/10.1109/TASE.2013.2259480", "James MacQueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the 5th Berkeley Symposium on Math, Statistics, and Probability. 281--297.", "George Miller. 1995. WordNet: A lexical database for English. Commun. ACM 38, 11 (1995), 39--41. DOI:http://dx.doi.org/10.1145/219717.219748", "Anna Monreale, Fabio Pinelli, Roberto Trasarti, and Fosca Giannotti. 2009. WhereNext: A location predictor on trajectory pattern mining. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 637--646. DOI:http://dx.doi.org/10.1145/1557019.1557091", "Raul Montoliu and Daniel Gatica-Perez. 2010. Discovering human places of interest from multimodal mobile phone data. In Proceedings of the 13th International Conference on Mobile and Ubiquitous Multimedia. 12:1--12:10. DOI:http://dx.doi.org/10.1145/1899475.1899487", "Brendan Tran Morris and Mohan Manubhai Trivedi. 2011. Trajectory learning for activity understanding: Unsupervised, multilevel, and long-term adaptive approach. IEEE Trans. Pattern Anal. Mach. Learn. 33, 11 (2011), 2287--2301. DOI:http://dx.doi.org/10.1109/TPAMI.2011.64", "Fumitaka Nakahara and Takahiro Murakami. 2012. A destination prediction method based on behavioral pattern analysis of nonperiodic position logs. In Proceedings of The 6th International Conference on Mobile Computing and Ubiquitous Networking. Okinawa, 32--39.", "Donald J. Patterson, Lin Liao, Dieter Fox, and Henry Kautz. 2003. Inferring high-level behavior from low-level sensors. In Proceedings of the 5th International Conference on Ubiqutous Computing. 73--89. DOI:http://dx.doi.org/10.1007/978-3-540-39653-6_6", "Susanna Pirttikangas, Kaori Fujinami, and Tatsuo Nakajima. 2006. Feature selection and activity recognition from wearable sensors. In Proceedings of the 3rd International Symposium on Ubiqutous Computing Systems. 516--527. DOI:http://dx.doi.org/10.1007/11890348_39", "Anand Rajaraman and David Ullman. 2011. Mining of Massive Datasets. Cambridge University Press.", "Nishkam Ravi, Nikhil Dandekar, Preetham Mysore, and Michael L. Littman. 2005. Activity recognition from accelerometer data. In Proceedings of the 17th Conference on Innovative Applications of Artificial Intelligence. 1541--1546.", "Philip Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. J. Artif. Intell. Res. 11 (1999), 95--130. DOI:http://dx.doi.org/10.1613/jair.514", "C. Carl Robusto. 1957. The cosine-haversine formula. Am. Math. Mon. 64, 1 (1957), 38--40.", "Olov Rosen and Alexander Medvedev. 2012. An on-line algorithm for anomaly detection in trajectory data. In Proceedings of the American Control Conference. 1117--1122. DOI:http://dx.doi.org/10.1109/ ACC.2012.6315346", "Bill Schilit, Norman Adams, and Roy Want. 1994. Context-aware computing applications. In Proceedings of the 1st Workshop on Mobile Computing Systems and Applications. 85--90. DOI:http://dx.doi.org/10.1109/WMCSA.1994.16", "Katarzyna Siła-Nowicka, Jan Vandrol, Taylor Oshan, Jed A. Long, Urška Demšar, and A. Stewart Fotheringham. 2015. Analysis of human mobility patterns from GPS trajectories and contextual information. Int. J. Geogr. Inform. Sci. (2015), 1--26. DOI:http://dx.doi.org/10.1080/13658816.2015.1100731", "Lu-An Tang, Yu Zheng, Jing Yuan, Jiawei Han, Alice Leung, Chih-Chieh Hung, and Wen-Chih Peng. 2012. On discovery of traveling companions from streaming trajectories. In Proceedings of the 28th IEEE International Conference on Data Engineering. 186--197. DOI:http://dx.doi.org/10.1109/ICDE.2012.33", "Alasdair Thomason, Nathan Griffiths, and Matthew Leeke. 2015a. Extracting meaningful user locations from temporally annotated geospatial data. In Internet of Things: IoT Infrastructures. LNICST, Vol. 151. Springer, 84--90. DOI:http://dx.doi.org/10.1007/978-3-319-19743-2_13", "Alasdair Thomason, Nathan Griffiths, and Victor Sanchez. 2015b. Parameter optimisation for location extraction and prediction applications. In Proceedings of the 2015 IEEE International Conference on Pervasive Intelligence and Computing. 2173--2180. DOI:http://dx.doi.org/10.1109/CIT/IUCC/DASC/PICOM.2015.322", "Alasdair Thomason, Nathan Griffiths, and Victor Sanchez. 2016. Identifying locations from geospatial trajectories. J. Comput. Syst. Sci. 82, 4 (2016), 566--581. DOI:http://dx.doi.org/10.1016/j.jcss.2015.10.005", "Alasdair Thomason, Matthew Leeke, and Nathan Griffiths. 2015. Understanding the impact of data sparsity and duration for location prediction applications. In Internet of Things: IoT Infrastructures. LNICST, Vol. 151. Springer, 192--197. DOI:http://dx.doi.org/10.1007/978-3-319-19743-2_29", "Alessandro Vinciarelli, Anna Esposito, Elisabeth André, Francesca Bonin, Mohamed Chetouani, Jeffrey F. Cohn, Marco Cristani, Ferdinand Fuhrmann, Elmer Gilmartin, Zakia Hammal, Dirk Heylen, Rene Kaiser, Maria Koutsombogera, Alexandros Potamianos, Steve Renals, Giuseppe Riccardi, and Albert Ali Salah. 2015. Open challenges in modelling, analysis and synthesis of human behaviour in human--human and human--machine interactions. Cogn. Comput. 7, 4 (2015), 397--413. DOI:http://dx.doi.org/10.1007/s12559-015-9326-z", "Jingjing Wang and Bhaskar Prabhala. 2012. Periodicity based next place prediction. In Proceedings of the Nokia Mobile Data Challenge (MDC) Workshop in Conjunction with Pervasive.", "Zhibiao Wu and Martha Palmer. 1994. Verb semantics and lexical selection. In Proceedings of the 32nd Annual Meeting on Association for Computational Linguistics. 133--138. DOI:http://dx.doi.org/10.3115/981732.981751", "Zhengwei Wu, Haishan Wu, and Tong Zhang. 2015. Predict user in-world activity via integration of map query and mobility trace. In Proceedings of the 4th International Workshop on Urban Computing.", "Xiangye Xiao, Yu Zheng, Qiong Luo, and Xing Xie. 2012. Inferring social ties between users with human location history. J. Amb. Intell. Hum. Comput. 5, 1 (2012), 3--19. DOI:http://dx.doi.org/10.1007/s12652-012-0117-z", "Zhixian Yan, Dipanjan Chakraborty, Christine Parent, Stefano Spaccapietra, and Karl Aberer. 2013. Semantic trajectories: Mobility data computation and annotation. ACM Trans. Intell. Syst. Technol. 4, 3, Article 49 (2013). DOI:http://dx.doi.org/10.1145/2483669.2483682", "Jiong Yang, Wang Wang, and Philip S. Yu. 2003. Mining asynchronous periodic patterns in time series data. IEEE Trans. Knowl. Data Eng. 15, 3 (2003), 613--628. DOI:http://dx.doi.org/10.1109/TKDE.2003.1198394", "Zhiwen Yu, Hui Wang, Bin Guo, Tao Gu, and Tao Mei. 2015. Supporting serendipitous social interaction using human mobility prediction. IEEE Trans. Hum.-Mach. Syst. 45, 6 (2015), 811--818. DOI:http://dx.doi.org/10.1109/THMS.2015.2451515", "Daqing Zhang, Nan Li, Zhi-Hua Zhou, Chao Chen, Lin Sun, and Shijian Li. 2011. iBAT: Detecting anomalous taxi trajectories from gps traces. In Proceedings of the 13th International Conference on Ubiquitous Computing. 99--108. DOI:http://dx.doi.org/10.1007/978-3-642-30973-1", "Kai Zheng, Yu Zheng, Xing Xie, and Xiaofang Zhou. 2012. Reducing uncertainty of low-sampling-rate trajectories. In Proceedings of the IEEE 28th International Conference on Data Engineering. 1144--1155. DOI:http://dx.doi.org/10.1109/ICDE.2012.42", "Yu Zheng, Quannan Li, Yukun Chen, Xing Xie, and Wei-Ying Ma. 2008a. Understanding mobility based on GPS data. In Proceedings of the 10th International Conference on Ubiquitous Computing. 312--321. DOI:http://dx.doi.org/10.1145/1409635.1409677", "Yu Zheng, Like Liu, Longhao Wang, and Xing Xie. 2008b. Learning transportation mode from raw GPS data for geographic applications on the web. In Proceedings of the 17th International Conference on World Wide Web. 247--256. DOI:http://dx.doi.org/10.1145/1367497.1367532", "Yu Zheng and Xing Xie. 2010. Learning travel recommendations from user-generated GPS traces. ACM Trans. Intell. Syst. Technol. 2, 2 (2010), 2:1--2:29. DOI:http://dx.doi.org/10.1145/1889681.1889683", "Yu Zheng, Xing Xie, and Wei-Ying Ma. 2010. GeoLife: A collaborative social networking service among user, location and trajectory. IEEE Database Eng. Bull. 33, 2 (2010), 32--39.", "Yu Zheng, Lizhu Zhang, Xing Xie, and Wei-Ying Ma. 2009. Mining interesting locations and travel sequences from GPS trajectories. In Proceedings of the 18th International Conference on World Wide Web. 791--800. DOI:http://dx.doi.org/10.1145/1526709.1526816"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2978578"}, {"title": "Analysis and Characterization of Gastronomic Recipes on the Web", "authors": ["Edwaldo S. Rodrigues\n,", "alvaro R.Pereira Junior"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nInternet has played nowadays an important role in society, being the means for services of diverse purposes to be delivered. One of the services that have gained attention on internet is the collaborative systems, in which multiple users create content based on their own personal experiences. An emerging class of collaborative systems is currently the gastronomical recipes sharing services. The area of Web Information Retrieval has grown interest in retrieving information in the recipes environment in order to discover new knowledge, such as the discovery of healthy recipes, which happens by employing textual data mining techniques. In this scope, this work analyzes features of gastronomic recipes present in specialized sites, taking into account characteristics of ingredients, comments, number of users, categories, among other information related to the recipes in the target sites.", "references": ["Y.-Y. Ahn, S. E. Ahnert, J. P. Bagrow, and A.-L. Barabasi. Flavor network and the principles of food pairing. Scientific reports, 1, 2011.", "W. M. Ferreira, A. P. C. da Silva, F. Benevenuto, and L. H. Merschmann. Comer, comentar e compartilhar: Analise de uma rede de ingredientes e receitas. In Proceedings of Brazilian Symposium on Collaborative Systems, page 120. Sociedade Brasileira de Computacao, 2013.", "T.-Y. Ko, C.-J. Tseng, H.-H. Chen, J.-J. Ding, and N. Babaguchi. Efficient dc term encoding scheme based on double prediction algorithms and pareto probability models. In Multimedia and Expo (ICME), 2013 IEEE International Conference on, pages 1-6. IEEE, 2013.", "H. Krishna and P. S. Pundir. Discrete burr and discrete pareto distributions. Statistical Methodology, 6(2):177-188, 2009.", "S. A. Mushtaq and A. A. Rizvi. Statistical analysis and mathematical modeling of network (segment) traffic. In Emerging Technologies, 2005. Proceedings of the IEEE Symposium on, pages 246-251. IEEE, 2005.", "M. Pimentel, M. A. Gerosa, D. Filippo, A. Raposo, H. Fuks, and C. J. P. Lucena. Modelo 3c de colaboracao para o desenvolvimento de sistemas colaborativos. Anais do III Simposio Brasileiro de Sistemas Colaborativos, pages 58-67, 2006.", "D. Schneider, J. de Souza, and K. Moraes. Multidoes: a nova onda do cscw. Proceedings of the SBSC e CRIWG-VIII Simposio Brasileiro de Sistemas Colaborativos. Paraty, Brazil, 2011.", "B. Sigurbjornsson and R. Van Zwol. Flickr tag recommendation based on collective knowledge. In Proceedings of the 17th international conference on World Wide Web, pages 327-336. ACM, 2008.", "M. A. Stephens. Asymptotic results for goodness-of-fit statistics with unknown parameters. The Annals of Statistics, 4(2):357-369, 03 1976", "M. Ueda, S. Asanuma, Y. Miyawaki, and S. Nakajima. Recipe recommendation method by considering the user's preference and ingredient quantity of target recipe. In Proceedings of the International MultiConference of Engineers and Computer Scientists, volume 1, 2014.", "M. Ueda, M. Takahata, and S. Nakajima. User's food preference extraction for personalized cooking recipe recommendation. In Proc. of the Second Workshop on Semantic Personalized Information Management: Retrieval and Recommendation, 2011.", "N. Yu, D. Zhekova, C. Liu, and S. Kubler. Do good recipes need butter? predicting user ratings of online recipes. In Proceedings of the Cooking with Computer workshop at the International Joint Conference on Artificial Intelligence (IJCAI2013), 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022027"}, {"title": "Understanding Human Language: Can NLP and Deep Learning Help?", "authors": ["Christopher Manning"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThere is a lot of overlap between the core problems of information retrieval (IR) and natural language processing (NLP). An IR system gains from understanding a user need and from understanding documents, and hence being able to determine whether a document has information that satisfies the user need. Much of NLP is about the same thing: Natural language understanding aims to understand the meaning of questions and documents and meaning relationships. The exciting recent application of deep learning approaches in NLP has brought new tools for effectively understanding language semantics. In principle, there should be a lot of synergy, though in practice the concerns of IR on large systems and macro-scale understanding have tended to contrast with the emphasis in NLP on language structure and micro-scale understanding. My talk will emphasize the two topics of how NLP can contribute to understanding textual relationships and how deep learning approaches substantially aid in this goal. One basic -- and very successful tool -- has been the new generation of distributed word representations: neural word embeddings. However, beyond just word meanings, we need to understand how to compose the meanings of larger pieces of text. Two requirements for that are good ways to understand the structure of human language utterances and ways to compose their meanings. Deep learning methods can help for both tasks. Finally, we need to understand relationships between pieces of text, to be able to do tasks such as Natural Language Inference (or Recognizing Textual Entailment) and Question Answering, and I will look at some of our recent work in these areas, both with and without the help of neural networks", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926732"}, {"title": "Exploring Deep Space: Learning Personalized Ranking in a Semantic Space", "authors": ["Jeroen B. P. Vuurens\n,", "Martha Larson\n,", "Arjen P. de Vries"], "publication": "DLRS 2016: Proceedings of the 1st Workshop on Deep Learning for Recommender Systems", "abstract": "ABSTRACT\nRecommender systems leverage both content and user interactions to generate recommendations that fit users' preferences. The recent surge of interest in deep learning presents new opportunities for exploiting these two sources of information. To recommend items we propose to first learn a user-independent high-dimensional semantic space in which items are positioned according to their substitutability, and then learn a user-specific transformation function to transform this space into a ranking according to the user's past preferences. An advantage of the proposed architecture is that it can be used to effectively recommend items using either content that describes the items or user-item ratings. We show that this approach significantly outperforms state-of-the-art recommender systems on the MovieLens 1M dataset.", "references": ["Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137--1155, Mar. 2003.", "K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is nearest neighbor meaningful? In Database theory -ICDT99, pages 217--235. Springer, 1999.", "A. M. Dai, C. Olah, and Q. V. Le. Document embedding with paragraph vectors. Proceedings of the NIPS DLRL Workshop, 2014.", "A. M. Elkahky, Y. Song, and X. He. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In Proceedings of WWW, pages 278--288. ACM, 2015.", "J. R. Firth. A synopsis of linguistic theory. 1957.", "D. Fleder and K. Hosanagar. Blockbuster culture's next rise or fall: The impact of recommender systems on sales diversity. Management science, 55(5):697--712, 2009.", "Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In Proceedings of ICMD, pages 263--272. Ieee, 2008.", "P.-S. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of CIKM, pages 2333--2338. ACM, 2013.", "Y. Koren. Collaborative filtering with temporal dynamics. Communications of the ACM, 53(4):89--97, 2010.", "Y. Koren, R. Bell, C. Volinsky, et al. Matrix factorization techniques for recommender systems. Computer, 42(8):30--37, 2009.", "T. K. Landauer and S. T. Dumais. A solution to plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2):211, 1997.", "Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. In Proceedings of ICML, pages 1188--1196, 2014.", "Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521(7553):436--444, 2015.", "P. Lops, M. De Gemmis, and G. Semeraro. Content-based recommender systems: State of the art and trends. In Recommender systems handbook, pages 73--105. Springer, 2011.", "W. Lowe. Towards a theory of semantic space. In Proceedings of CogSci, pages 576--581. Lawrence Erlbaum Associates, 2001.", "W. Lowe and S. McDonald. The direct route: Mediated priming in semantic space. In Proceedings of CogSci, pages 675--680, 2000.", "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pages 3111--3119, 2013.", "C. Musto, G. Semeraro, M. de Gemmis, and P. Lops. Learning word embeddings from wikipedia for content-based recommender systems. In Proceedings of ECIR, pages 729--734. Springer, 2016.", "B. Németh, G. Takács, I. Pilászy, and D. Tikk. Visualization of movie features in collaborative filtering. In Proceedings of SoMeT, pages 229--233. IEEE, 2013.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. In Proceedings of UAI, pages 452--461. AUAI Press, 2009.", "C. Wang and D. M. Blei. Collaborative topic modeling for recommending scientific articles. In Proceedings of SIGKDD, pages 448--456. ACM, 2011.", "W. Yao, J. He, H. Wang, Y. Zhang, and J. Cao. Collaborative topic ranking: Leveraging item meta-data for sparsity reduction. In Proceedings of AAAI, pages 374--380, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988450.2988457"}, {"title": "Supporting Information Search by Older Adults", "authors": ["Herre van Oostendorp\n,", "Saraschandra Karanam"], "publication": "ECCE '16: Proceedings of the European Conference on Cognitive Ergonomics", "abstract": "ABSTRACT\nUsing cognitive models of web-navigation to generate support has long been a topic of research. In this paper, we address two limitations in this area. First, these models have so far been used to generate support for navigation within a website and not for interaction with a search engine. Second, very few studies have looked at the usefulness of such model-generated support for older adults who are known to be less efficient than younger adults. An experiment with 24 younger and 24 older adults on six simple and six difficult information search tasks was conducted. Results showed that the semantic relevance of queries showed a decreasing trend across reformulations for older adults and remained constant for younger adults, indicating that as older adults reformulated, they produced queries that were further away from the target information, which could be the reason for their lower efficiency. Based on these outcomes, two types of model-generated support mechanisms for interaction with a search engine are proposed, one which visually highlights the most relevant search result given a query and the other which monitors the average semantic relevance of search results for a given query and warns the user if it falls below a threshold.", "references": ["M. H. Blackmon, D. R. Mandalia, P. G. Polson, and M. Kitajima. Automating usability evaluation: Cognitive walkthrough for the web puts lsa to work on real-world hci design problems. In T. K. Landauer, D. S. McNamara, S. Dennis, and W. Kintsch, editors, Handbook of Latent Semantic Analysis, pages 345--375. Lawrence Erlbaum Associates Mahwah, NJ, 2007.", "P. Borlund and P. Ingwersen. The development of a method for the evaluation of interactive information retrieval systems. Journal of documentation, 53(3):225--250, 1997.", "A. Chevalier, A. Dommes, and J.-C. Marquié. Strategy and accuracy during information search on the web: Effects of age and complexity of the search questions. Computers in Human Behavior, 53:305--315, 2015.", "J. Chin, E. Anderson, C.-L. Chin, and W.-T. Fu. Age differences in information search: An exploration-exploitation tradeoff model. In Proceedings of the Human Factors and Ergonomic Society (HFES 2015), pages 85--89, 2015.", "J. Chin and W.-T. Fu. Age differences in exploratory learning from a health information website. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 3031--3040. ACM, 2012.", "A. Dommes, A. Chevalier, and S. Lia. The role of cognitive flexibility and vocabulary abilities of younger and older users in searching for information on the web. Applied Cognitive Psychology, 25(5):717--726, 2011.", "J. L. Horn. The theory of fluid and crystallized intelligence in relation to concepts of cognitive psychology and aging in. In Aging and cognitive processes, volume 8, pages 237--278. Springer Science & Business Media, 2012.", "J. L. Horn and R. B. Cattell. Age differences in fluid and crystallized intelligence. Acta Psychologica, 26:107--129, 1967.", "I. Juvina and H. van Oostendorp. Modeling semantic and structural knowledge in web navigation. Discourse Processes, 45(4-5):346--364, 2008.", "S. Karanam, H. van Oostendorp, and W. T. Fu. Performance of computational cognitive models of web-navigation on real websites. Journal of Information Science, 42(1):94--113, 2016.", "S. Karanam, H. van Oostendorp, and B. Indurkhya. Towards a fully computational model of web-navigation. In Modern Approaches in Applied Intelligence, pages 327--337. Springer, 2011.", "S. Karanam, H. van Oostendorp, and B. Indurkhya. Evaluating colides+ pic: the role of relevance of pictures in user navigation behaviour. Behaviour & Information Technology, 31(1):31--40, 2012.", "S. Karanam, H. van Oostendorp, M. Sanchiz, A. Chevalier, J. Chin, and W. T. Fu. Modeling and predicting information search behavior. In Proceedings of the 5th International Conference on Web Intelligence, Mining and Semantics, page 7. ACM, 2015.", "W. Kintsch. Comprehension: A paradigm for cognition. Cambridge University Press, 1998.", "M. Kitajima, M. H. Blackmon, and P. G. Polson. A comprehension-based model of web navigation and its application to web usability analysis. People and Computers, pages 357--374, 2000.", "T. K. Landauer, P. W. Foltz, and D. Laham. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259--284, 1998.", "T. K. Landauer, D. S. McNamara, S. Dennis, and W. Kintsch. Handbook of Latent Semantic Analysis. Mahwah,NJ: Erlbaum, 2007.", "C. Olston and E. H. Chi. Scenttrails: Integrating browsing and searching on the web. ACM Transactions on Computer-Human Interaction (TOCHI), 10(3):177--197, 2003.", "R. Pak and M. M. Price. Designing an information search interface for younger and older adults. Human Factors: The Journal of the Human Factors and Ergonomics Society, 50(4):614--628, 2008.", "P. Pirolli and S. Card. Information foraging. Psychological Review, 106(4):643--675, 1999.", "T. L. Queen, T. M. Hess, G. E. Ennis, K. Dowd, and D. Grühn. Information search and decision making: Effects of age and complexity on strategy use. Psychology and Aging, 27(4):817--824, 2012.", "E. Strauss, E. M. Sherman, and O. Spreen. A compendium of neuropsychological tests: Administration, norms, and commentary. Oxford University Press, USA, 2006.", "H. van Oostendorp and S. Aggarwal. Modeling and supporting web-navigation. Journal of Interaction Science, 3(1):1--12, 2015.", "H. van Oostendorp and I. Juvina. Using a cognitive model to generate web navigation support. International Journal of Human-Computer Studies, 65(10):887--897, 2007.", "J.-J. Wang and A. S. Kaufman. Changes in fluid and crystallized intelligence across the 20-to 90-year age range on the k-bit. Journal of Psychoeducational Assessment, 11(1):29--37, 1993.", "R. J. Youmans, B. Bellows, C. A. Gonzalez, B. Sarbone, and I. J. Figueroa. Designing for the wisdom of elders: age related differences in online search strategies. In Universal Access in Human-Computer Interaction. User and Context Diversity, pages 240--249. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970930.2970943"}, {"title": "A geo-social user profile for a personalized information retrieval", "authors": ["Rafa Tahar\n,", "Kechid Samir"], "publication": "ICIME 2016: Proceedings of the 2016 8th International Conference on Information Management and Engineering", "abstract": "ABSTRACT\nSeveral works in user-centered personalized information retrieval treat independently the user's mobile and social contexts, and they develop and exploit separately the social and situational user profiles to improve the information access process. We propose, in this paper, a personalized information retrieval approach combining the social and situational user profiles to improve the search results relevance. We intend to improve two important phases of the research process, (i) user query expansion and (ii) adaptation of search results to the user profile.", "references": ["Kechid, S. 2009. integration du modèle utilisateur dans un système de recherche d'information distribuée. doctoral thesis. USTHB, algeria, 2009.", "Farida, A. and Rachid A. O. 2012. Modélisation d'évolution de profil utilisateur en recherche d'information personnalisée. CORIA 2012. 83--97.", "Zakaria, S., Samir, K., and Radia, A., 2014. Exploring Folksonomy Structure for Personalizing the Result Merging Process in Distributed Information Retrieval. in springer international publishing, Switzerland 2014. 42--50.", "Kechid, S. 2009. integration du modèle utilisateur dans un système de recherche d'information distribuée. doctoral thesis. USTHB, algeria, 2009.", "Farida, A. and Rachid A. O. 2012. Modélisation d'évolution de profil utilisateur en recherche d'information personnalisée. CORIA 2012. 83--97.", "Zakaria, S., Samir, K., and Radia, A., 2014. Exploring Folksonomy Structure for Personalizing the Result Merging Process in Distributed Information Retrieval. in springer international publishing, Switzerland 2014. 42--50.", "Bilel, M., Lynda, T. and Sadok, B. Y., 2014. Prise en compte des préférences des utilisateurs pour l'estimation de la pertinence multidimensionnelle d'un Document. INFORSID 2014. France. 42.", "Chahrazed, B., Mathias, G. and Christine, L. 2013. Modèle de Recherche d'Information Sociale Centré Utilisateur. (EGC'2013). France. Journal of new IT, &lt;ujm-00869337&gt;. 275--286.", "Lamjed, B. J., Lynda, T. and Mohand, B., 2011. Un modèle de recherche d'information sociale dans les microblogs: cas de Twitter. 2nd Conference on Models and Analysis of Networks: Approaches Mathematics and Computer Science, MARAMI 2011, Grenoble.", "Lynda, T. L., 2008. De la recherche d'information orientée système à la recherche d'information orientée contexte: Verrous, contributions et perspectives. HDR memory, Univ Paul Sabatier - Toulouse III, 2008.", "Imen, A., Mohand, B. and Rim, F., 2015. Une approche de recommandation proactive dans un environnement mobile. INFORSID 2015, France. 301--316.", "Ourdia, B., 2011. Accès contextuel à l'information dans un environnement mobile: approche basée sur l'utilisation d'un profil situationnel de l'utilisateur et d'un profil de localisation des requêtes. Phd thesis, Univ Toulouse III - Paul Sabatier, France 2011.", "Bila, N., Cao, J., Dinoff, R., Ho T., Hull R., Kumar B., Santos P. 2008. Mobile User Profile Acquisition Through Network Observables and Explicit User Queries. 9th Int'l conference on Mobile Data Management, 98--107, 2008.", "Lamjed, B. J., Lynda, T. and Mohand, B., 2010. A social model for Literature Access: Towards a weighted social network of authors. International Conference on Adaptivity, Personalization and Fusion of Heterogeneous Information (RIAO 2010), France.", "Abdelkrim, B., Mohamed, K. K. and Bich, L. D., 2010. PRESY: A Context Based Query Reformulation Tool for Information Retrieval on the Web. In Journal of Computer Science 6 (4): 470--477, 2010. ISSN: 1549-3636.", "Salton, G. and Buckley, C., 1988. Term Weighting Approaches in Automatic Text Retrival. Information Processing and Management. 513--523."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012258.3012270"}, {"title": "Web Data Extraction from Retailers' Site using Semantic Density and Case Based Reasoning", "authors": ["B. Umamageswari\n,", "R. Kalpana"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nDeep web or hidden web acts as a major source of information for many data analytical and data mining applications like product intelligence, competitive intelligence, online market intelligence etc. The web pages containing data from deep web are dynamic pages which are generated using server-side templates as a result of submission of query search form. They are not indexed to search engines and therefore cannot be retrieved using traditional keyword search. The web pages are designed to improve user experience but it makes automated processing, a unwieldy task. This makes WDE an on-going research area facing many challenges. Many solutions have been proposed over the past decades for WDE ranging from hand crafted rules to automatic template deduction and extraction. This paper explores a new framework for WDE which uses semantic density for data rich region detection and case based reasoning which helps in adapting the system to learn new templates and carry out extraction process even for unseen newly structured web pages.", "references": ["Arasu, A., and Garcia-Molina, H., Extracting structured data from Web pages. In Proceedings of the ACM SIGMOD International Conference on Management of Data, San Diego, California, pp. 337--348, 2003. DOI = http://doi.acm.org/10.1145/872757.872799.", "Chang, C.-H., & Kuo, S.-C. (2004). OLERA: A Semi-Supervised Approach for Web Data Extraction with Visual Support. IEEE Intelligent Systems, 19(6), pp. 56--64.", "Chang, C.-H., & Lui, S.-C. (2001). IEPAD: Information Extraction based on Pattern Discovery. In Proceedings of the Tenth International Conference on World Wide Web (WWW), Hong-Kong, pp. 223--231.", "Crescenzi, V., Mecca, G. Grammers have Exceptions. Information Systems 23, 8 (1998), 539--565.", "Crescenzi, V., Mecca, G., Merialdo, P., Roadrunner: Automatic Data Extraction from Data-Intensive Web Sites. SIGMOD, 624--624 (2002). DOI = http://doi.acm.org/10.1145/564691.564778.", "Embley, D. W., Campbell, D. M., Jiang, Y. S., Liddle, S. W., Lonsdale, D. W., Ng, Y.-K., and Smith, R. D. Conceptual model- based data extraction from multiple-record Web pages. Data & Knowledge Engineering, 31, 1999, 227--251.", "Etzioni, O., Cafarella, M., Downey, D., Popescu, A.-M., Shaked, T., Soderland, S., Weld, D. S., and Yates, A. Unsupervised named-entity extraction from the web: an experimental study. Artificial Intelligence, 165, 2005, 91--134.", "Grigalis, T., Radvilavicus, L., Cenys, A., Gordevicius, J. Clustering Visually Similar Web Page Elements for Structured Web Data Extraction. Springer Book Chapter Web Engineering, vol. 7387, pp. 435--438.", "Hammer, J., McHugh, J., & Gracia-Molina, H. (1997). Semistructured data: The TSIMISS experience. In Proceedings of the First East-Europen Symposium on Advances in Databases and Information Systems (St. Petersburg, Russia), pp. 1--8. (TSIMMIS)", "Hogue, A., & Karger, D. (2005). Thresher: Automating the Unwrapping of Semantic Content from the World Wide. In Proceedings of the 14th International Conference on World Wide Web (WWW), Japan, pp. 86--95.", "Hsu, C.-N., & Dung, M. (1998). Generating Finite-State Transducers for Semi-Structured Data Extraction from the Web. Journal of Information Systems, 23(8), pp. 521--538.", "Janosi-Rancz, K.-T., Lajos, A., Semantic Data Extraction. Elsevier Procedia Technology, Vol. 19, pp. 827--834, 2015.", "Kayed, M. and Chang, C.-H., FiVaTech: Page-level web data extraction from template pages. In IEEE Trans. Knowl. Data Eng., vol. 22, no. 2, pp. 249--263, Feb. 2010.", "Kushmerick, N., Weld, D., & Doorenbos, R. (1997), Wrapper Induction for Information Extraction. In Proceedings of the Fifteenth International Conference on Artificial Intelligence (IJCAI), pp. 729--735.", "Miao, G., Tatemura, J., Hsiung W.-P., Sawires, A., & Moser, L.E. (2009). Extracting Data Records from the Web using Tag Path Clustering. In Proceedings International Conference World Wide Web (WWW), pp. 981--990.", "Mihalcca, R., & Moldovan, D. (1998). Word sense disambiguation based on semantic density. In Proceedings of COLING/ACL Workshop on Usage of Wordnet in Natural Language Processing (pp. 16--22).", "Muslea, I., Minton, S., & Knoblock, C. (1999). A Hierarchical Approach to Wrapper Induction. In Proceedings of the Third International Conference on Autonomous Agents (AA-99).", "Sahuguet, A., Azavant, F. (2001). Building Intelligent Web Applications using Lightweight Wrappers. IEEE Transactions on Data and Knowledge Engineering, 36(3), pp. 283--316.", "Sleiman, H.-A., Corchuelo, R. Trinity: On Using Trinary Trees for Unsupervised Web Data Extraction. IEEE Transactions on Knowledge and Data Engineering, Vol. 26, No. 6, pp. 1544--1556, June 2014.", "Watson, I., Applying Case Based Reasoning: Techniques for Enterprise Systems, San Fransisco, Cal: Morgan Kaufmann Publishers (1997)", "Zhai, Y. and Liu, B., Web Data Extraction Based on Partial Tree Alignment. In Proceedings of the 14th International Conference on World Wide Web (WWW), Japan, pp. 76--85, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980265"}, {"title": "Augmenting API documentation with insights from stack overflow", "authors": ["Christoph Treude\n,", "Martin P. Robillard"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering", "abstract": "ABSTRACT\nSoftware developers need access to different kinds of information which is often dispersed among different documentation sources, such as API documentation or Stack Overflow. We present an approach to automatically augment API documentation with \"insight sentences\" from Stack Overflow---sentences that are related to a particular API type and that provide insight not contained in the API documentation of that type. Based on a development set of 1,574 sentences, we compare the performance of two state-of-the-art summarization techniques as well as a pattern-based approach for insight sentence extraction. We then present SISE, a novel machine learning based approach that uses as features the sentences themselves, their formatting, their question, their answer, and their authors as well as part-of-speech tags and the similarity of a sentence to the corresponding API documentation. With SISE, we were able to achieve a precision of 0.64 and a coverage of 0.7 on the development set. In a comparative study with eight software developers, we found that SISE resulted in the highest number of sentences that were considered to add useful information not found in the API documentation. These results indicate that taking into account the meta data available on Stack Overflow as well as part-of-speech tags can significantly improve unsupervised extraction approaches when applied to Stack Overflow data.", "references": ["D. Aha and D. Kibler. Instance-based learning algorithms. Machine Learning, 6:37--66, 1991.", "A. Bacchelli, L. Ponzanelli, and M. Lanza. Harnessing Stack Overflow for the IDE. In Proc. of the 3rd Int'l. Workshop on Recommendation Systems for Software Engineering, pages 26--30, 2012.", "D. Binkley, D. Lawrie, E. Hill, J. Burge, I. Harris, R. Hebig, O. Keszocze, K. Reed, and J. Slankas. Task-driven software summarization. In Proc. of the 29th Int'l. Conf. on Software Maintenance, pages 432--435, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2884781.2884800"}, {"title": "A Package Recommendation Framework for Trip Planning Activities", "authors": ["Idir Benouaret\n,", "Dominique Lenne"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nClassical recommender systems provide users with ranked lists of recommendations, where each one consists of a single item. However, these ranked lists are not suitable for applications such as trip planning, which deal with heterogeneous items. In this paper, we focus on the problem of recommending a set of packages to the user, where each package is constituted with a set of different Points of Interest that may constitute a tour. Given a collection of POIs, our goal is to recommend the most interesting packages for the user, where each package satisfies the budget constraints. We formally define the problem and we present a novel composite recommendation system, inspired from composite retrieval. Experimental evaluation of our proposed system, using a real-world dataset demonstrates its quality and its ability to improve both diversity and relevance of recommendations.", "references": ["S. Amer-Yahia, F. Bonchi, C. Castillo, E. Feuerstein, I. Mendez-Diaz, and P. Zabala. Composite retrieval of diverse and complementary bundles. Transactions on Knowledge and Data Engineering, 2014.", "A. Angel, S. Chaudhuri, G. Das, and N. Koudas. Ranking objects based on relationships and fixed associations. EDBT, 2009.", "L. Castillo, E. Armengol, E. Onaindıa, L. Sebastiá, J. González-Boticario, A. Rodrıguez, S. Fernández, J. D. Arias, and D. Borrajo. Samap: An user-oriented adaptive system for planning tourist visits. Expert Systems with Applications, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959183"}, {"title": "Service topic model with probability distance", "authors": ["Yu Lei\n,", "Philip S. Yu"], "publication": "UCC '16: Proceedings of the 9th International Conference on Utility and Cloud Computing", "abstract": "ABSTRACT\nThe number of Web services are growing rapidly on the Internet. Topics of services are becoming various. Semantic-based keyword search is used to retrieve proper services for service consumers. According to the semantic information implied in service database, we build a topic model to cluster and management related services. Our service recommendation approach can extract service patterns from correlated topics in semantic service descriptions. We use Latent Dirichlet Allocation to obtain the service patterns; and use Concept lattice to model the correlation between the extracted topics. Higher precision results are obtained in the experiments.", "references": ["De Roure, D., Goble, C. and Stevens, R. The Design and Realization of the myExperiment Virtual Research Environment for Social Sharing of Workflows. Future Generation Computer Systems, Vol 25, 2009, pp. 561--567.", "C. Li, R. Zhang, J. Huai, X. Guo, and H. Sun, \"A probabilistic approach for web service discovery,\" in Proceedings of the IEEE International Conference on Services Computing, 2013, pp. 49--56.", "J. Cao, W. Xu, L. Hu, J. Wang, and M. Li, \"A social-aware service recommendation approach for mashup creation,\" International Journal of Web Services Research, Vol. 10, pp. 53--72, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996890.3007863"}, {"title": "Efficient Processing of Relevant Nearest-Neighbor Queries", "authors": ["Christodoulos Efstathiades\n,", "Alexandros Efentakis\n,", "Dieter Pfoser"], "publication": "ACM Transactions on Spatial Algorithms and Systems", "abstract": "Abstract\nNovel Web technologies and resulting applications have led to a participatory data ecosystem that, when utilized properly, will lead to more rewarding services. In this work, we investigate the case of Location-Based Services, specifically how to improve the typical location-based Point-of-Interest (POI) request processed as a k-Nearest-Neighbor query. This work introduces Links-of-Interest (LOI) between POIs as a means to increase the relevance and overall result quality of such queries. By analyzing user-contributed content in the form of travel blogs, we establish the overall popularity of an LOI, that is, how frequently the respective POI pair was visited and is mentioned in the same context. Our contribution is a query-processing method for so-called k-Relevant Nearest Neighbor (k-RNN) queries that considers spatial proximity in combination with LOI information to retrieve close-by and relevant (as judged by the crowd) POIs. Our method is based on intelligently combining indices for spatial data (a spatial grid) and for relevance data (a graph) during query processing. Using landmarks as a means to prune the search space in the Relevance Graph, we improve the proposed methods. Using in addition A*-directed search, the query performance can be further improved. An experimental evaluation using real and synthetic data establishes that our approach efficiently solves the k-RNN problem.", "references": ["Nikos Armenatzoglou, Stavros Papadopoulos, and Dimitris Papadias. 2013. A general framework for geo-social query processing. Proceedings of the VLDB Conference 6, 10, 913--924.", "Norbert Beckmann, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. 1990. The R&ast;-tree: An efficient and robust access method for points and rectangles. In Proceedings of the SIGMOD Conference. 322--331.", "Xin Cao, Gao Cong, and Christian S. Jensen. 2010. Retrieving top-k prestige-based relevant spatial web objects. Proceedings of the VLDB Conference 3, 1--2, 373--384."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934675"}, {"title": "Generalized Group Profiling for Content Customization", "authors": ["Mostafa Dehghani\n,", "Hosein Azarbonyad\n,", "Jaap Kamps\n,", "Maarten Marx"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThere is an ongoing debate on personalization, adapting results to the unique user exploiting a user's personal history, versus customization, adapting results to a group profile sharing one or more characteristics with the user at hand. Personal profiles are often sparse, due to cold start problems and the fact that users typically search for new items or information, necessitating to back-off to customization, but group profiles often suffer from accidental features brought in by the unique individual contributing to the group. In this paper we propose a generalized group profiling approach that teases apart the exact contribution of the individual user level and the `abstract' group level by extracting a latent model that captures all, and only, the essential features of the whole group. Our main findings are the followings.\nFirst, we propose an efficient way of group profiling which implicitly eliminates the general and specific features from users' models in a group and takes out the abstract model representing the whole group.\nSecond, we employ the resulting models in the task of contextual suggestion. We analyse different grouping criteria and we find that group-based suggestions improves the customization. Third, we see that the granularity of groups affects the quality of group profiling. We observe that grouping approach should compromise between the level of customization and groups' size.", "references": ["S. Amer-Yahia, S. B. Roy, A. Chawlat, G. Das, and C. Yu. Group recommendation: Semantics and efficiency. VLDB, 2: 754--765, 2009.", "L. Ardissono, A. Goy, G. Petrone, M. Segnan, and P. Torasso. Intrigue: personalized recommendation of tourist attractions for desktop and hand held devices. Applied Artificial Intelligence, 17 (8--9): 687--714, 2003.", "B. Custers. Effects of unreliable group profiling by means of data mining. In Discovery Science, pages 291--296, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855003"}, {"title": "Learning to Rank Personalized Search Results in Professional Networks", "authors": ["Viet Ha-Thuc\n,", "Shakti Sinha"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLinkedIn search is deeply personalized - for the same queries, different searchers expect completely different results. This paper presents our approach to achieving this by mining various data sources available in LinkedIn to infer searchers' intents (such as hiring, job seeking, etc.), as well as extending the concept of homophily to capture the searcher-result similarities on many aspects. Then, learning-to-rank is applied to combine these signals with standard search features.", "references": ["D. Arya, V. Ha-Thuc, , and S. Sinha. Personalized federated search at linkedin. In ACM CIKM, 2015.", "V. Ha-Thuc, G. Venkataraman, M. Rodriguez, S. Sinha, S. Sundaram, and L. Guo. Personalized expertise search at linkedin. In IEEE Big Data, 2015.", "V. Ha-Thuc, Y. Xu, S. P. Kanduri, X. Wu, V. Dialani, Y. Yan, A. Gupta, and S. Sinha. Search by ideal candidates: Next generation of talent search at linkedin. In ACM WWW, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2927018"}, {"title": "What Affects Word Changes in Query Reformulation During a Task-based Search Session?", "authors": ["Jiepu Jiang\n,", "Chaoqun Ni"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThis paper performs an analysis on the influence of different factors on users' choices of specific word changes in query reformulation during a search session. We study three types of word changes: whether to remove or retain a word in the current query; whether or not to add a brand-new word to the query; whether or not to reuse a word (included in previous queries, but removed in the current query). Three types of factors are examined: session-level factors measuring task and user characteristics; query-level factors related to past user activities in a session; word-level factors for the characteristics of the examined word and its relation to the current query and search results. Statistical analysis suggests that: word-level factors strongly influence all three types of word changes; query-level factors only show a clear influence on retaining or removing a word; task-level factors exhibit limited direct influence on all three types of word changes. Analysis also disclose reasons for different word changes: users remove a word to stop exploring a subtask, or to correct bad performing queries; they look for related, unused words from recently viewed result summaries and add to queries; reusing a word usually indicates reverting from a subtask to the main task or another subtask.", "references": ["P. Anick. Using terminological feedback for web search refinement: A log-based study. In SIGIR '03, pages 88--95, 2003.", "L. Azzopardi. Modelling interaction with economic models of search. In SIGIR '14, pages 3--12, 2014.", "M. J. Bates. The design of browsing and berrypicking techniques for the online search interface. Online review, 13(5):407--424, 1989."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854978"}, {"title": "Using low-cost electroencephalography (EEG) sensor to identify perceived relevance on web search", "authors": ["Roberto González-Ibáñez\n,", "María Escobar-Macaya\n,", "Manuel Manriquez"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis poster presents preliminary results from a user study designed to evaluate the feasibility to use a low-cost EEG sensor in the identification of information relevance as perceived by users. The study involved 10 participants, both graduate and undergraduate students, performing a self-motivated exploratory search task contextualized on the literature review for their own thesis work. The study design comprised two stages that focus on (1) snippets collection and (2) explicit relevance assessments. In both stages, participants wore a low-cost electroencephalography (EEG) sensor that provides measures related to two mental states (i.e. attention and meditation). Analyses focused on comparing the presence and intensity of these mental states in the set of pages (both relevant and non-relevant) classified by the users themselves. Results showed that attention levels and blink intensity in relevant pages are significantly higher than in non-relevant ones.", "references": ["Agichtein, E., Brill, E., & Dumais, S. (2006). Improving web search ranking by incorporating user behavior information, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval (pp. 19--26). ACM.", "Arapakis, I., Konstas, I., Jose, J. M., & Kompatsiaris, I. (2009). Modeling facial expressions and peripheral physiological signals to predict topical relevance. Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval (pp. 728--729). ACM.", "Barral, O., Eugster, M. J., Ruotsalo, T., Spapé, M. M., Kosunen, I., Ravaja, N., Kaski, S., & Jacucci, G. (2015). Exploring peripheral physiology as a predictor of perceived relevance in information retrieval. Proceedings of the 20th International Conference on Intelligent User Interfaces (pp. 389--399). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017593"}, {"title": "LayerFolding: discovering creative links in word association networks", "authors": ["Ping Xiao\n,", "Hannu Toivonen"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nA frequent challenge in creative tasks such as advertising is finding novel and concrete representations of abstract concepts. We cast this problem as finding, in word association networks, the relevant indirect associations of a given node. We propose a novel approach, LayerFolding, which selects nodes at increasing distances from the given node, according to their relatedness to it. The relatedness is calculated based on the shortest paths that are potentially coherent. In a test against a small set of visual representations of abstract concepts found in real advertisements, LayerFolding provides a 79% recall, and outperforms other two popular semantic relatedness measures.", "references": ["C.-Y. Chang, S. Clark, and B. Harrington. Getting creative with semantic similarity. In IEEE 7th International Conference on Semantic Computing, ICSC '13, pages 330--333, 2013.", "T. H. Haveliwala. Topic-sensitive PageRank. In Proceedings of the 11th International Conference on World Wide Web, WWW '02, pages 517--526.", "G. R. Kiss, C. Armstrong, R. Milroy, and J. Piper. An associative thesaurus of English and its computer analysis. In A. J. Aitkin, R. W. Bailey, and N. Hamilton-Smith, editors, The Computer and Literary Studies, pages 153--165. 1973."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851883"}, {"title": "Which Answer is Best?: Predicting Accepted Answers in MOOC Forums", "authors": ["Maximilian Jenders\n,", "Ralf Krestel\n,", "Felix Naumann"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nMassive Open Online Courses (MOOCs) have grown in reach and importance over the last few years, enabling a vast userbase to enroll in online courses. Besides watching videos, user participate in discussion forums to further their understanding of the course material. As in other community-based question-answering communities, in many MOOC forums a user posting a question can mark the answer they are most satisfied with. In this paper, we present a machine learning model that predicts this accepted answer to a forum question using historical forum data.", "references": ["L. A. Adamic, J. Zhang, E. Bakshy, and M. S. Ackerman. Knowledge sharing and yahoo answers. In WWW. ACM Press, 2008.", "M. J. Blooma, A. Y.-K. Chua, and D. H.-L. Goh. Selection of the best answer in cqa services. In ITNG. IEEE, 2010.", "G. Burel, Y. He, and H. Alani. Automatic Identification of Best Answers in Online Enquiry Communities, volume 7295 of Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890567"}, {"title": "Information Extraction for Scholarly Digital Libraries", "authors": ["Kyle Williams\n,", "Jian Wu\n,", "Zhaohui Wu\n,", "C. Lee Giles"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nScholarly documents contain many data entities, such as titles, authors, affiliations, figures, and tables. These entities can be used to enhance digital library services through enhanced metadata and enable the development of new services and tools for interacting with and exploring scholarly data. However, in a world of scholarly big data, extracting these entities in a scalable, efficient and accurate manner can be challenging. In this tutorial, we introduce the broad field of information extraction for scholarly digital libraries. Drawing on our experience in running the CiteSeerX digital library, which has performed information extraction on over 7 million academic documents, we argue for the need for automatic information extraction, describe different approaches for performing information extraction, present tools and datasets that are readily available, and describe best practices and areas of research interest.", "references": ["M. Khabsa and C. L. Giles. The number of scholarly documents on the public web. PloS one, 9(5):e93949, 2014.", "The Science of Science Policy: A Federal Research Roadmap. Report on the Science of Science Policy. National Science and Technology Council, 2008.", "C. L. Giles. Scholarly big data: information extraction and data mining. In Proceedings of CIKM, pages 1--2, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925430"}, {"title": "A Simple Enhancement for Ad-hoc Information Retrieval via Topic Modelling", "authors": ["Fanghong Jian\n,", "Jimmy Xiangji Huang\n,", "Jiashu Zhao\n,", "Tingting He\n,", "Po Hu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTraditional information retrieval (IR) models, in which a document is normally represented as a bag of words and their frequencies, capture the term-level and document-level information. Topic models, on the other hand, discover semantic topic-based information among words. In this paper, we consider term-based information and semantic information as two features of query terms and propose a simple enhancement for ad-hoc IR via topic modeling. In particular, three topic-based hybrid models, LDA-BM25, LDA-MATF and LDA-LM, are proposed. A series of experiments on eight standard datasets show that our proposed models can always outperform significantly the corresponding strong baselines over all datasets in terms of MAP and most of datasets in terms of P@5 and P@20. A direct comparison on eight standard datasets also indicates our proposed models are at least comparable to the state-of-the-art approaches.", "references": ["L. Azzopardi, M. Girolami, and C. J. Van Rijsbergen. Topic Based Language Models for ad hoc Information Retrieval. In Proceedings of the International Joint Conference on Neural Networks, pages 3281--3286, 2004.", "M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker, and P. Williams. Okapi at TREC-5. In Proc. of TREC, pages 143--166, 1996.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914748"}, {"title": "\"Shall I Be Your Chat Companion?\": Towards an Online Human-Computer Conversation System", "authors": ["Rui Yan\n,", "Yiping Song\n,", "Xiangyang Zhou\n,", "Hua Wu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTo establish an automatic conversation system between human and computer is regarded as one of the most hardcore problems in computer science. It requires interdisciplinary techniques in information retrieval, natural language processing, and data management, etc. The challenges lie in how to respond like a human, and to maintain a relevant, meaningful, and continuous conversation. The arrival of big data era reveals the feasibility to create such a system empowered by data-driven approaches. We can now organize the conversational data as a chat companion. In this paper, we introduce a chat companion system, which is a practical conversation system between human and computer as a real application. Given the human utterances as queries, our proposed system will respond with corresponding replies retrieved and highly ranked from a massive conversational data repository. Note that 'practical' here indicates effectiveness and efficiency: both issues are important for a real-time system based on a massive data repository. We have two scenarios of single-turn and multi-turn conversations. In our system, we have a base ranking without conversational context information (for single-turn) and a context-aware ranking (for multi-turn). Both rankings can be conducted either by a shallow learning or deep learning paradigm. We combine these two rankings together in optimization. In the experimental setups, we investigate the performance between effectiveness and efficiency for the proposed methods, and we also compare against a series of baselines to demonstrate the advantage of the proposed framework in terms of p@1, MAP, and nDCG. We present a new angle to launch a practical online conversation system between human and computer.", "references": ["Y. Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning, 2(1):1--127, 2009.", "F. Bessho, T. Harada, and Y. Kuniyoshi. Dialog system using real-time crowdsourcing and twitter large-scale corpus. In SIGDIAL '12, pages 227--231, 2012.", "T. W. Bickmore and R. W. Picard. Establishing and maintaining long-term human-computer relationships. ACM Trans. Comput.-Hum. Interact., 12(2):293--327, June 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983360"}, {"title": "Category Oriented Task Extraction", "authors": ["Manisha Verma\n,", "Emine Yilmaz"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWith increasing amounts of digital content, users can accomplish complex tasks online, thus making task extraction from query logs an active area of research. Recently, some approaches have proposed entity based extraction of tasks, where they either use entities as features or construct task dictionaries that contain multiple tasks. While text based features do not exploit entities directly, task dictionaries do not provide concise or distinct representation of tasks. We overcome these shortcomings by extracting category oriented tasks by exploiting properties of an existing, publicly available category hierarchy. We evaluate quality of these tasks with implicit, explicit and application based evaluation. Empirical evaluation shows that category based task extraction results in more accurate and useful tasks.", "references": ["E. Agichtein, R. White, S. T. Dumais, and P. N. Bennett. Search, interrupted: Understanding and predicting search task continuation. In SIGIR 2012.", "A. H. Awadallah, R. W. White, P. Pantel, S. T. Dumais, and Y. Wang. Supporting complex search tasks. In CIKM 2014.", "D. Ceccarelli, C. Lucchese, S. Orlando, R. Perego, and S. Trani. Dexter: An open source framework for entity linking. ESAIR '13. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854997"}, {"title": "Scalability and Efficiency Challenges in Large-Scale Web Search Engines", "authors": ["B. Barla Cambazoglu\n,", "Ricardo Baeza-Yates"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCommercial web search engines need to process thousands of queries every second and provide responses to user queries within a few hundred milliseconds. As a consequence of these tight performance constraints, search engines construct and maintain very large computing infrastructures for crawling the Web, indexing discovered pages, and processing user queries. The scalability and efficiency of these infrastructures require careful performance optimizations in every major component of the search engine.\nThis tutorial aims to provide a fairly comprehensive overview of the scalability and efficiency challenges in large-scale web search engines. In particular, the tutorial provides an in-depth architectural overview of a web search engine, mainly focusing on the web crawling, indexing, and query processing components. The scalability and efficiency issues encountered in these components are presented at four different granularities: at the level of a single computer, a cluster of computers, a single data center, and a multi-center search engine. The tutorial also points out some open research problems and provides recommendations to researchers who are new to the field.", "references": ["S. Alici, I. S. Altingovde, R. Ozcan, B. B. Cambazoglu, and O. Ulusoy. Timestamp-based result cache invalidation for web search engines. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 973--982, 2011.", "I. S. Altingovde, R. Ozcan, and O. Ulusoy. Static index pruning in web search engines: Combining term and document popularities with query views. ACM Transactions on Information Systems, 30(1):2:1--2:28, 2012.", "I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proceedings of the 37th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 103--112, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914808"}, {"title": "Joint Coupled-Hashing Representation for Cross-Modal Retrieval", "authors": ["Yihan Liu\n,", "Zhaojia Chen\n,", "Cheng Deng\n,", "Xinbo Gao"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nCross-modal retrieval based on hashing has attracted much attention for its low storage cost and fast query speed. Most cross-modal hashing methods arbitrarily embed the heterogeneous features into a common Hamming space, which is unsuitable for many real-world applications and makes the search results unsatisfactory. In this paper, we propose a novel cross-modal hashing method, which embeds heterogeneous features into their respective Hamming spaces. The proposed method has two advantages: 1) reconstructive embedding in each individual modality represented by matrix decomposition is performed to enhance the discriminative ability of the binary codes; 2) the correlations between different modalities are maximized by joint coupled-hashing representation. Experimental results on two public datasets demonstrate that our method gains better retrieval performance than several state-of-the-art approaches.", "references": ["T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval, page 48. ACM, 2009.", "C. Deng, H. Deng, X. Liu, and Y. Yuan. Adaptive multi-bit quantization for hashing. Neurocomputing, 151:319--326, 2015.", "C. Deng, X. Tang, J. Yan, W. Liu, and X. Gao. Discriminative dictionary learning with common label alignment for cross-modal retrieval. IEEE Transactions on Multimedia, 18(2):208--218, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007716"}, {"title": "Scalable Semantic Matching of Queries to Ads in Sponsored Search Advertising", "authors": ["Mihajlo Grbovic\n,", "Nemanja Djuric\n,", "Vladan Radosavljevic\n,", "Fabrizio Silvestri\n,", "Ricardo Baeza-Yates\n,", "Andrew Feng\n,", "Erik Ordentlich\n,"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSponsored search represents a major source of revenue for web search engines. The advertising model brings a unique possibility for advertisers to target direct user intent communicated through a search query, usually done by displaying their ads alongside organic search results for queries deemed relevant to their products or services. However, due to a large number of unique queries, it is particularly challenging for advertisers to identify all relevant queries. For this reason search engines often provide a service of advanced matching, which automatically finds additional relevant queries for advertisers to bid on. We present a novel advance match approach based on the idea of semantic embeddings of queries and ads. The embeddings were learned using a large data set of user search sessions, consisting of search queries, clicked ads and search links, while utilizing contextual information such as dwell time and skipped ads. To address the large-scale nature of our problem, both in terms of data and vocabulary size, we propose a novel distributed algorithm for training of the embeddings. Finally, we present an approach for overcoming a cold-start problem associated with new ads and queries. We report results of editorial evaluation and online tests on actual search traffic. The results show that our approach significantly outperforms baselines in terms of relevance, coverage and incremental revenue. Lastly, as part of this study, we open sourced query embeddings that can be used to advance the field.", "references": ["R. Baeza-Yates and B. Ribeiro-Neto. Modern information retrieval, volume 463. ACM press, 1999.", "Y. Bengio, H. Schwenk, J.-S. Senécal, F. Morin, and J.-L. Gauvain. Neural probabilistic language models. In Innovations in Machine Learning pp. 137--186. 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911538"}, {"title": "PlaylistCreator: An Assisted Approach for Playlist Creation", "authors": ["Ricardo Dias\n,", "Daniel Gonçalves\n,", "Manuel J. Fonseca"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this demo paper we describe PlaylistCreator, an assisted approach for supporting the creation of music playlists. Our solution allows creators to express song selection and browsing through a visual representation of their intents in a unified view, which relies on a set-based model for representing sources of songs. Creators can convey their purposes by seamlessly combining criteria for song selection from either manual or automatic sources, such as artists and albums, or similarity measures between artists or songs.", "references": ["G. Bonnin and D. Jannach. Automated generation of music playlists: Survey and experiments. ACM Computing Surveys (CSUR), 47(2):26, 2015.", "R. Dachselt, M. Frisch, and M. Weiland. Facetzoom: a continuous multi-scale widget for navigating hierarchical metadata. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1353--1356. ACM, 2008.", "M. Kamalzadeh, D. Baur, and T. Möller. A survey on music listening and management behaviours. In Proceedings of the International Conference on Music Information Retrieval, pages 373--378, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973816"}, {"title": "Proactive Recommendation Delivery", "authors": ["Adem Sabic"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe main purpose of Recommender Systems is to minimize the effects of information/choice overload. Recommendations are usually prepared based on the estimation of what would be useful or interesting to users. Thus, it is important that they are relevant to users, whether to their information needs, current activity or emotional state. This requires deep understanding of users' context but also the knowledge of the history of previous users' interactions within the system (e.g. clicks, views, etc.). But even when the recommendations are highly relevant, their delivery to users can be very problematic. Many existing systems require active user participation (explicit interaction with the recommender system) and attention. Or, on other side of spectrum, there are RS that handle recommendation delivery without any consideration for users' preferences of when, where or how the recommendations are being delivered. Proactive Recommender Systems promise a more autonomous approach for recommendation delivery, by anticipating information needs in advance and acting on users' behalf with minimal efforts and without disturbance. This paper describes our work and interest in identifying and analyzing the factors that can influence acceptance and use of proactively delivered recommendations.", "references": ["P. D. Adamczyk and B. P. Bailey. If not now, when?: the effects of interruption at different moments within task execution. In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 271--278. ACM, 2004.", "N. K. Agarwal, Y. C. Xu, and D. C. Poo. A context-based investigation into source use by information seekers. Journal of the American Society for Information Science and Technology, 62(6):1087--1104, 2011.", "B. P. Bailey and J. A. Konstan. On the need for attention-aware systems: Measuring effects of interruption on task performance, error rate, and affective state. Computers in human behavior, 22(4):685--708, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959108"}, {"title": "Optimizing Search Interactions within Professional Social Networks", "authors": ["Nikita V. Spirin"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nTo help users cope with the scale and influx of new information, professional social networks (PSNs) provide a search functionality. However, most of the search engines within PSNs today only support keyword queries and basic faceted search capabilities overlooking serendipitous network exploration and search for relationships between entities. This results in siloed information and a limited search space. My thesis is that we must redesign all major elements of a search user interface, such as input, control, and informational, to enable more effective search interactions within PSNs. I will introduce new insights and algorithms supporting the thesis.", "references": ["N. Spirin and K. Karahalios. Unsupervised approach to generate informative structured snippets for job search engines. WWW '13.", "N. Spirin, M. Kuznetsov, J. Kiseleva, Y. Spirin, and P. Izhutov. Relevance-aware filtering of tuples sorted by an attribute value via direct optimization of search quality metrics. SIGIR'15.", "N. V. Spirin, J. He, M. Develin, K. G. Karahalios, and M. Boucher. People search within an online social network: Large scale analysis of facebook graph search query logs. CIKM '14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855092"}, {"title": "PLIERS: a popularity-based recommender system for content dissemination in online social networks", "authors": ["Valerio Arnaboldi\n,", "Mattia Giovanni Campana\n,", "Franca Delmastro\n,", "Elena Pagani"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nOnline social networks (OSNs) allow users to generate items and tag or rate them in order to help others in the identification of useful content. In this paper, we propose a novel tag-based recommender system called PLIERS, able to identify useful contents based on users' interests. It relies on the assumption that users are mainly interested in items and tags with similar popularity to those they already own. It reaches a good tradeoff between algorithmic complexity and the level of personalization of recommended items. To evaluate PLIERS, we performed a set of experiments on real OSN datasets, demonstrating that it outperforms the state-of-the-art solutions in terms of personalization, relevance, and novelty of recommendations.", "references": ["R. Dunbar, V. Arnaboldi, M. Conti, and A. Passarella. The structure of online social networks mirrors those in the offline world. Social Networks, 43:39--47, 2015.", "C. Liu and W.-X. Zhou. An improved heats+ probs hybrid recommendation algorithm based on heterogeneous initial resource configurations. arXiv preprint arXiv:1005.3124, 2010.", "G. Quattrone, E. Ferrara, P. De Meo, and L. Capra. Measuring similarity in large-scale folksonomies. In arXiv:1207.6037, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851940"}, {"title": "User Fatigue in Online News Recommendation", "authors": ["Hao Ma\n,", "Xueqing Liu\n,", "Zhihong Shen"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nMany aspects and properties of Recommender Systems have been well studied in the past decade, however, the impact of User Fatigue has been mostly ignored in the literature. User fatigue represents the phenomenon that a user quickly loses the interest on the recommended item if the same item has been presented to this user multiple times before. The direct impact caused by the user fatigue is the dramatic decrease of the Click Through Rate (CTR, i.e., the ratio of clicks to impressions). In this paper, we present a comprehensive study on the research of the user fatigue in online recommender systems. By analyzing user behavioral logs from Bing Now news recommendation, we find that user fatigue is a severe problem that greatly affects the user experience. We also notice that different users engage differently with repeated recommendations. Depending on the previous users' interaction with repeated recommendations, we illustrate that under certain condition the previously seen items should be demoted, while some other times they should be promoted. We demonstrate how statistics about the analysis of the user fatigue can be incorporated into ranking algorithms for personalized recommendations. Our experimental results indicate that significant gains can be achieved by introducing features that reflect users' interaction with previously seen recommendations (up to 15% enhancement on all users and 34% improvement on heavy users).", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender Systems Handbook, pages 217--253. 2011.", "D. Agarwal, B. Chen, and P. Elango. Spatio-temporal models for estimating click-through rate. In Proceedings of WWW 2009, pages 21--30, 2009.", "N. Buchbinder, M. Feldman, A. Ghosh, and J. Naor. Frequency capping in online advertising. Journal of Scheduling, 17(4):385--398, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2874813"}, {"title": "Lexical Query Modeling in Session Search", "authors": ["Christophe Van Gysel\n,", "Evangelos Kanoulas\n,", "Maarten de Rijke"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nLexical query modeling has been the leading paradigm for session search. In this paper, we analyze TREC session query logs and compare the performance of different lexical matching approaches for session search. Naive methods based on term frequency weighing perform on par with specialized session models. In addition, we investigate the viability of lexical query models in the setting of session search. We give important insights into the potential and limitations of lexical query modeling for session search and propose future directions for the field of session search.", "references": ["M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In SIGIR, pages 443--452. ACM, 2012.", "P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short- and long-term behavior on search personalization. In SIGIR, pages 185--194. ACM, 2012.", "B. Carterette, E. Kanoulas, M. M. Hall, and P. D. Clough. Overview of the trec 2014 session track. In TREC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970422"}, {"title": "HIA'16: The 2nd International Workshop on Heterogeneous Information Access at SIGIR 2016", "authors": ["Ke Zhou\n,", "Yiqun Liu\n,", "Roger Jie Luo\n,", "Joemon Jose"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation access is becoming increasingly heterogeneous. Especially when the user's information need is for exploratory purpose, returning a set of diverse results from different resources could benefit the user. For example, when a user is planning a trip to China, retrieving and showing results from vertical search engines like travel, flight information, map and Q2A sites can satisfy the user's rich and diverse information need. This heterogeneous search paradigm is useful in many contexts and brings many new challenges.", "references": ["J. Arguello, F. Diaz, J. Callan, and J.-F. Crespo. Sources of evidence for vertical selection. In SIGIR '09, pages 315--322.", "H. Bota, K. Zhou, J. Jose, and M. Lalmas. Composite retrieval of heterogeneous web search. In WWW'14, pages 119--130.", "T. Demeester, D. Trieschnigg, D. Nguyen, K. Zhou and D. Hiemstra. Overview of the TREC 2014 Federated Web Search Track. In TREC'14. Proceedings of Text REtrieval Conference."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917760"}, {"title": "A Novel Approach to Define and Model Contextual Features in Recommender Systems", "authors": ["Parisa Lak"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecommender Systems(RS) provide more accurate and more relevant recommendations using contextual feature(s). This accuracy improvement is at the cost of computational expenses. Therefore, finding and selecting the most relevant contextual features is an important problem. Moreover, modeling and incorporating the selected contextual features in RS algorithms has an impact on both the accuracy and computational cost. We are conducting a series of studies to detect, define, select, model and incorporate the most relevant contextual features for RS algorithms. The feature detection, definition and selection approach involves the evaluation of features derived from implicit and explicit information. The selected features from this approach can be modeled and incorporated in any selected RS algorithm.\nIn our recent works, we also propose a series of algorithms that incorporates multiple contextual features in the baseline matrix factorization (MF) algorithm. We use the selected contextual features to modify user biases and item biases in the baseline MF.", "references": ["G. Adomavicius and A. Tuzhilin. Extending recommender systems: A multidimensional approach. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-01), Workshop on Intelligent Techniques for Web Personalization (ITWP2001), Seattle, Washington, August, pages 4--6. Citeseer, 2001.", "P. Lak, B. Caglayan, and A. B. Bener. The impact of basic matrix factorization refinements on recommendation accuracy. In Proceedings of the 2014 IEEE/ACM International Symposium on Big Data Computing, pages 105--112. IEEE Computer Society, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911481"}, {"title": "Towards Machine Musicians Who Have Listened to More Music Than Us: Audio Database-Led Algorithmic Criticism for Automatic Composition and Live Concert Systems", "authors": ["Nick Collins"], "publication": "Computers in Entertainment", "abstract": "Abstract\nDatabases of audio can form the basis for new algorithmic critic systems, applying techniques from the growing field of music information retrieval to meta-creation in algorithmic composition and interactive music systems. In this article, case studies are described where critics are derived from larger audio corpora. In the first scenario, the target music is electronic art music, and two corpuses are used to train model parameters and then compared with each other and against further controls in assessing novel electronic music composed by a separate program. In the second scenario, a “real-world” application is described, where a “jury” of three deliberately and individually biased algorithmic music critics judged the winner of a dubstep remix competition. The third scenario is a live tool for automated in-concert criticism, based on the limited situation of comparing an improvising pianists' playing to that of Keith Jarrett; the technology overlaps that described in the other systems, though now deployed in real time. Alongside description and analysis of these systems, the wider possibilities and implications are discussed.", "references": ["R. Begleiter, R. El-Yaniv, and G. Yona. 2004. On prediction using variable order Markov models. J. Artif. Intell. Res. 22, 385--421.", "T. Bertin-Mahieux, D. Eck, and M. Mandel. 2010. Automatic tagging of audio: The state-of-the-art. Machine Audition: Principles, Algorithms and Systems. IGI Publishing", "J. A. Biles. 2007. Improvising with genetic algorithms: GenJam. In Evolutionary Computer Music, E. Miranda and A. Biles. (Eds.). Springer, London, 137--169."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967510"}, {"title": "Open Data in Scientific Settings: From Policy to Practice", "authors": ["Irene V. Pasquetto\n,", "Ashley E. Sands\n,", "Peter T. Darch\n,", "Christine L. Borgman"], "publication": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "abstract": "ABSTRACT\nOpen access to data is commonly required by funding agencies, journals, and public policy, despite the lack of agreement on the concept of \"open data.\" We present findings from two longitudinal case studies of major scientific collaborations, the Sloan Digital Sky Survey in astronomy and the Center for Dark Energy Biosphere Investigations in deep subseafloor biosphere studies. These sites offer comparisons in rationales and policy interpretations of open data, which are shaped by their differing scientific objectives. While policy rationales and implementations shape infrastructures for scientific data, these rationales also are shaped by pre-existing infrastructure. Meanings of the term \"open data\" are contingent on project objectives and on the infrastructures to which they have access.", "references": ["Astrophysical Research Consortium. 1989. Principles of Operation of the Sky Survey Project.", "Astrophysical Research Consortium. 1997. A Digital Sky Survey of the Northern Galactic Cap. Astrophysical Research Consortium. Retrieved from https://catalog.lib.uchicago.edu/vufind/Record/839388", "Astrophysical Research Consortium. 2000. Principles of operation for the Sloan Digital Sky Survey. Retrieved from http://classic.sdss.org/policies/sdss_poo.html"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2858036.2858543"}, {"title": "Research Challenges in Developing Multimedia Systems for Managing Emergency Situations", "authors": ["Mengfan Tang\n,", "Siripen Pongpaichet\n,", "Ramesh Jain"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith an increasing amount of diverse heterogeneous data and information, the methodology of multimedia analysis has become increasingly relevant in solving challenging societal problems such as managing emergency situations during disasters. Using cybernetic principles combined with multimedia technology, researchers can develop effective frameworks for using diverse multimedia (including traditional multimedia as well as diverse multimodal) data for situation recognition, and determining and communicating appropriate actions to people stranded during disasters. We present known issues in disaster management and then focus on emergency situations. We show that an emergency management problem is fundamentally a multimedia information assimilation problem for situation recognition and for connecting people's needs to available resources effectively, efficiently, and promptly. Major research challenges for managing emergency situations are identified and discussed. We also present a intelligently detecting evolving environmental situations, and discuss the role of multimedia micro-reports as spontaneous participatory sensing data streams in emergency responses. Given enormous progress in concept recognition using machine learning in the last few years, situation recognition may be the next major challenge for learning approaches in multimedia contextual big data. The data needed for developing such approaches is now easily available on the Web and many challenging research problems in this area are ripe for exploration in order to positively impact our society during its most difficult times.", "references": ["2011 thailand floods. https://en.wikipedia.org/wiki/2011 Thailand floods.", "Modelling better ood responses in port phillip bay. http://www.csiro.au/en/Research/D61/Areas/Data-for-decisions/Disaster-management/Flood-modelling. Accessed: 2016-07-23.", "A. Acar and Y. Muraki. Twitter for crisis communication: lessons learned from japan's tsunami disaster. International Journal of Web Based Communities, 7(3):392--402, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2976761"}, {"title": "Artificial neural networks applications in computer aided diagnosis: system design and use as an educational tool", "authors": ["Jorge Hernández Rodríguez\n,", "María José Rodríguez Conde\n,", "Francisco Javier Cabrero Fraile"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nThis paper describes the motivation, state-of-the-art, hypotheses and research objectives of the Doctoral Thesis \"Artificial Neural Networks applications in Computer Aided Diagnosis. System design and use as an educational tool\". A description of the investigation approaches and methodologies, the current dissertation status and expected contributions is also presented. At the time of writing, this dissertation is in its first year of development. Its central topic is Computer Aided Diagnosis and Detection (CAD), a valuable automated tool for specialists who interpret medical images, that provides information which can be used as a \"second opinion\" or supplementary data in their decision making process. Developing CAD schemes based in the machine learning models called Artificial Neural Networks (ANNs), which could be applied to different image modalities, is the main objective of the first phase of the dissertation. Their integration in a software environment that allows the user to handle and access to information efficiently is of key importance in the process. The validation of the system in clinical practice and the investigation of their possible uses as an educational tool for trainees during residency programs is the second phase.", "references": ["Giger, M., Chan H., and Boone, J. 2008. \"Anniversary Paper: History and status of CAD and quantitative image analysis: The role of Medical Physics and AAPM\". Medical Physics. Volume 35, Issue 12 (December 2008).", "Suzuki, K. 2012. \"A review of computer-aided diagnosis in thoracic and colonic imaging\". Quantitative Imaging in Medicine and Surgery. Volume 2, Number 3 (September 2012).", "Zenghao, S., He, L., Suzuki, K., Nakamura, H., and Itoh, H. 2009. \"Survey on neural networks used for medical image processing\". International Journal of Computational Science. Volume 3, Issue 1, pages 86--100 (February 2009). PMID: 26740861."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012670"}, {"title": "Nearest Neighbor Search Technique Using Keywords and Threshold", "authors": ["Pooja Shejawal\n,", "Jayshree R. Pansare"], "publication": "WIR '16: Proceedings of the ACM Symposium on Women in Research 2016", "abstract": "ABSTRACT\nToday's applications asking for finding spatial protests nearest to a predefined area in the meantime fulfill limitation of keywords. Best answer for such questions depends on the IR2-tree, which has some inadequacies that truly affect system s efficiency. To defeat those inadequacies another access strategy is produced called the Spatial-inverted Index (SI) that extends the modified file to adapt to multidimensional information, and accompanies calculations that can answer closest neighbor queries with keywords continuously. This new technique SI is produced broadens the capacities of routine modified record makes do with multidimensional information, alongside the arrangement of using so as to move reach queries replied SI results to calculation which tackles the issue continuously.", "references": ["Yufei Tao and Cheng Sheng Fast Nearest Neighbor Search with Keywords IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, 2014.", "S. Agrawal, S. Chaudhuri, and G. Das. Dbxplorer: A system for keyword-based search over relational databases. In Proc. Of International Conference on Data Engineering (ICDE), pages 5 16, 2002.", "G. Bhalotia, A. Hulgeri, C. Nakhe, S. Chakrabarti, and S. Sudarshan. Keyword searching and browsing in databases using banks. In Proc. of International Conference on Data Engineering (ICDE), pages 431 440, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2909067.2909070"}, {"title": "EventMiner: Mining Events from Annotated Documents", "authors": ["Dhruv Gupta\n,", "Jannik Strötgen\n,", "Klaus Berberich"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nEvents are central in human history and thus also in Web queries, in particular if they relate to history or news. However, ambiguity issues arise as queries may refer to ambiguous events differing in time, geography, or participating entities. Thus, users would greatly benefit if search results were presented along different events. In this paper, we present EventMiner, an algorithm that mines events from top-k pseudo-relevant documents for a given query. It is a probabilistic framework that leverages semantic annotations in the form of temporal expressions, geographic locations, and named entities to analyze natural language text and determine important events. Using a large news corpus, we show that using semantic annotations, EventMiner detects important events and presents documents covering the identified events in the order of their importance.", "references": ["A. Abujabal and K. Berberich. Important events in the past, present, and future. WWW 2015-Companion Volume.", "J. Allan, editor. Topic Detection and Tracking: Event-based Information Organization. Kluwer Academic Publishers, Norwell, MA, USA, 2002.", "O. Alonso et al. Clustering and exploring search results using timeline constructions. CIKM 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970411"}, {"title": "Bibliometrics and information retrieval: creating knowledge through research synergies", "authors": ["Judit Bar-Ilan\n,", "Rob Koopman\n,", "Shenghui Wang\n,", "Andrea Scharnhorst\n,", "Marcus John\n,", "Philipp Mayr\n,", "Dietmar Wolfram"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThis panel brings together experts in bibliometrics and information retrieval to discuss how each of these two important areas of information science can help to inform the research of the other. There is a growing body of literature that capitalizes on the synergies created by combining methodological approaches of each to solve research problems and practical issues related to how information is created, stored, organized, retrieved and used. The session will begin with an overview of the common threads that exist between IR and metrics, followed by a summary of findings from the BIR workshops and examples of research projects that combine aspects of each area to benefit IR or metrics research areas, including search results ranking, semantic indexing and visualization. The panel will conclude with an engaging discussion with the audience to identify future areas of research and collaboration.", "references": ["Bar-Ilan, J., & Levene, M. (2015). The hw-rank: An h-index variant for ranking web pages. Scientometrics, 102, 2247--2253.", "Hirsch, J. E. (2005). An index to quantify an individual's scientific research output. Proceedings of the National academy of Sciences of the United States of America, 102(46), 16569--16572.", "Mayr, P., Frommholz, I., & Cabanac, G. (2016). Bibliometric-Enhanced Information Retrieval: 3rd International BIR Workshop. In N. Ferro et al. (Eds.), Advances in Information Retrieval: 38th European Conference on IR Research, ECIR 2016 (pp. 865--868). Springer."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017470"}, {"title": "Multimodal Analysis of User-Generated Content in Support of Social Media Applications", "authors": ["Rajiv Ratn Shah"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe number of user-generated multimedia content (UGC) online has increased rapidly in recent years due to the ubiquitous availability of smartphones, cameras, and affordable network infrastructures. Thus, it attracts companies to provide diverse multimedia-related services such as preference-aware multimedia recommendations, multimedia-based e--learning, and event summarization from a large collection of multimedia content. However, a real-world UGC is complex and extracting semantics from only multimedia content is difficult because suitable concepts may be exhibited in different representations. Modern devices capture contextual information in conjunction with a multimedia content, which greatly facilitates in the semantics understanding of the multimedia content. Thus, it is beneficial to analyse UGC from multiple modalities such as multimedia content and contextual information (eg., spatial and temporal information). This doctoral research studies the multimodal analysis of UGC in support of above-mentioned social media problems. We present our proposed approaches, results, and works in progress on these problems.", "references": ["E. Cambria, J. Fu, F. Bisio, and S. Poria. AffectiveSpace 2: Enabling Affective Intuition for Concept-Level Sentiment Analysis. In AAAI Conference on Artificial Intelligence, pages 508--514, 2015.", "E. Cambria, D. Olsher, and D. Rajagopal. SenticNet 3: A Common and Common-Sense Knowledge Base for Cognition-Driven Sentiment Analysis. In AAAI Conference on Artificial Intelligence, pages 1515--1521, 2014.", "J. Choi, E. Kim, M. Larson, G. Friedland, and A. Hanjalic. Evento 360: Social Event Discovery from Web-scale Multimedia Collection. In ACM MM, pages 193--196, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912032"}, {"title": "Self-Paced Cross-Modal Subspace Matching", "authors": ["Jian Liang\n,", "Zhihang Li\n,", "Dong Cao\n,", "Ran He\n,", "Jingdong Wang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCross-modal matching methods match data from different modalities according to their similarities. Most existing methods utilize label information to reduce the semantic gap between different modalities. However, it is usually time-consuming to manually label large-scale data. This paper proposes a Self-Paced Cross-Modal Subspace Matching (SCSM) method for unsupervised multimodal data. We assume that multimodal data are pair-wised and from several semantic groups, which form hard pair-wised constraints and soft semantic group constraints respectively. Then, we formulate the unsupervised cross-modal matching problem as a non-convex joint feature learning and data grouping problem. Self-paced learning, which learns samples from 'easy' to 'complex', is further introduced to refine the grouping result. Moreover, a multimodal graph is constructed to preserve the relationship of both inter- and intra-modality similarity. An alternating minimization method is employed to minimize the non-convex optimization problem, followed by the discussion on its convergence analysis and computational complexity. Experimental results on four multimodal databases show that SCSM outperforms state-of-the-art cross-modal subspace learning methods.", "references": ["G. Andrew, R. Arora, J. Bilmes, and K. Livescu. Deep canonical correlation analysis. In ICML, pages 1247--1255, 2013.", "F. Bach and Z. Harchaoui. Diffrac: a discriminative and flexible framework for clustering. In NIPS, pages 49--56, 2008.", "S. Basu and J. Christensen. Teaching classification boundaries to humans. In AAAI, pages 109--115, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911527"}, {"title": "Pearson Rank: A Head-Weighted Gap-Sensitive Score-Based Correlation Coefficient", "authors": ["Ning Gao\n,", "Mossaab Bagdouri\n,", "Douglas W. Oard"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOne way of evaluating the reusability of a test collection is to determine whether removing the unique contributions of some system would alter the preference order between that system and others. Rank correlation measures such as Kendall's tau are often used for this purpose. Rank correlation measures are appropriate for ordinal measures in which only preference order is important, but many evaluation measures produce system scores in which both the preference order and the magnitude of the score difference are important. Such measures are referred to as interval. Pearson's rho offers one way in which correlation can be computed over results from an interval measure such that smaller errors in the gap size are preferred. When seeking to improve over existing systems, we care the most about comparisons among the best systems. For that purpose we prefer head-weighed measures such as tau_AP, which is designed for ordinal data. No present head weighted measure fully leverages the information present in interval effectiveness measures. This paper introduces such a measure, referred to as Pearson Rank.", "references": ["B. Carterette. Robust test collections for retrieval evaluation. In SIGIR, pages 55--62, 2007.", "N. Gao and D. Oard. A head-weighted gap-sensitive correlation coefficient. In SIGIR, pages 799--802, 2015.", "M. G. Kendall. A new measure of rank correlation. Biometrika, pages 81--93, 1938."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914728"}, {"title": "Retrieval of Multimedia Objects by Fusing Multiple Modalities", "authors": ["Ilias Gialampoukidis\n,", "Anastasia Moumtzidou\n,", "Theodora Tsikrika\n,", "Stefanos Vrochidis\n,", "Ioannis Kompatsiaris"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nEffective multimedia retrieval requires the combination of the heterogeneous media contained within multimedia objects and the features that can be extracted from them. To this end, we extend a unifying framework that integrates all well-known weighted, graph-based, and diffusion-based fusion techniques that combine two modalities (textual and visual similarities) to model the fusion of multiple modalities. We also provide a theoretical formula for the optimal number of documents that need to be initially selected, so that the memory cost in the case of multiple modalities remains the same as in the case of two modalities. Experiments using two test collections and three modalities (similarities based on visual descriptors, visual concepts, and textual concepts) indicate improvements in the effectiveness over bimodal fusion under the same memory complexity.", "references": ["J. Ah-Pine, S. Clinchant, and G. Csurka. Comparison of several combinations of multimodal and diversity seeking methods for multimedia retrieval. In Multilingual Information Access Evaluation II. Multimedia Experiments: Proceedings of the 10th Workshop of the Cross-Language Evaluation Forum (CLEF), pages 124--132. Springer, 2009.", "J. Ah-Pine, G. Csurka, and S. Clinchant. Unsupervised visual and textual information fusion in cbmir using graph-based methods. ACM Transactions on Information Systems (TOIS), 33(2):9, 2015.", "P. K. Atrey, M. A. Hossain, A. El Saddik, and M. S. Kankanhalli. Multimodal fusion for multimedia analysis: a survey. Multimedia systems, 16(6):345--379, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912068"}, {"title": "SAR automatic target recognition based on K-means and data augmentation", "authors": ["Yikui Zhai\n,", "Kaipin Liu\n,", "Vincenzo Piuri\n,", "Zilu Ying\n,", "Ying Xu"], "publication": "ICIIP '16: Proceedings of the 2016 International Conference on Intelligent Information Processing", "abstract": "ABSTRACT\nSynthetic aperture radar (SAR) automatic target recognition (ATR) has been receiving more and more attention in the past two decades. A lot of methods have been proposed and studied for radar target recognition. Among some of these methods, they use the supervised algorithms to extracts features. In this paper, we first use a unsupervised algorithm, K-means clustering, which can learn the features without known the class of training samples, for radar target recognition. As the unsupervised algorithm has a high demand on the scale of the data, so we proposed a method of data augmentation to get more data for the unsupervised algorithm, by which the K-means clustering algorithm can learn more unsupervised features. Experimental results on the MSTAR database show that the proposed method can achieve satisfying recognition accuracy compared with other state-of-the-art methods.", "references": ["Huan, R., Y. Pan.. 2011. Decision fusion strategies for SAR image target recognition, IET Radar, Sonar and Navigation, Vol. 5, No. 7, 747--755.", "Lee, J.H., S.W. Cho, S.H. Park, K.T. Kim. 2012. Performance analysis of radar target recognition using natural frequency: Frequency domain approach, Progress In Electromagnetics Research, Vol. 132, 315--345,.", "Varshney, K. R., M. Cetin, J. W. Fisher, A. S. Willsky. 2008. Sparse representation in structured dictionaries with application to synthetic aperture radar, IEEE Transactions on Signal Processing, Vol. 56, No. 8, 3548--3560."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3028842.3028894"}, {"title": "A Non-Parametric Topic Model for Short Texts Incorporating Word Coherence Knowledge", "authors": ["Yuhao Zhang\n,", "Wenji Mao\n,", "Daniel Zeng"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMining topics in short texts (e.g. tweets, instant messages) can help people grasp essential information and understand key contents, and is widely used in many applications related to social media and text analysis. The sparsity and noise of short texts often restrict the performance of traditional topic models like LDA. Recently proposed Biterm Topic Model (BTM) which models word co-occurrence patterns directly, is revealed effective for topic detection in short texts. However, BTM has two main drawbacks. It needs to manually specify topic number, which is difficult to accurately determine when facing new corpora. Besides, BTM assumes that two words in same term should belong to the same topic, which is often too strong as it does not differentiate two types of words (i.e. general words and topical words). To tackle these problems, in this paper, we propose a non-parametric topic model npCTM with the above distinction. Our model incorporates the Chinese restaurant process (CRP) into the BTM model to determine topic number automatically. Our model also distinguishes general words from topical words by jointly considering the distribution of these two word types for each word as well as word coherence information as prior knowledge. We carry out experimental studies on real-world twitter dataset. The results demonstrate the effectiveness of our method to discover coherent topics compared with the baseline methods.", "references": ["Belém, F., Santos, R., Almeida, J. and Gonçalves, M. 2013. Topic Diversity in Tag Recommendation. Proceedings of the 7th ACM Conference on Recommender Systems, 141--148.", "Blei, D.M., Ng, A.Y. and Jordan, M.I. 2003. Latent dirichlet allocation. The Journal of Machine Learning Research. 3, 993--1022.", "Chang, J., Gerrish, S., Wang, C., Boyd-graber, J.L. and Blei, D.M. 2009. Reading Tea Leaves: How Humans Interpret Topic Models. Advances in Neural Information Processing Systems 22, 288--296."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983898"}, {"title": "Field Effect Deep Networks for Image Recognition with Incomplete Data", "authors": ["Sheng-Hua Zhong\n,", "Yan Liu\n,", "Kien A. Hua"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nImage recognition with incomplete data is a well-known hard problem in computer vision and machine learning. This article proposes a novel deep learning technique called Field Effect Bilinear Deep Networks (FEBDN) for this problem. To address the difficulties of recognizing incomplete data, we design a novel second-order deep architecture with the Field Effect Restricted Boltzmann Machine, which models the reliability of the delivered information according to the availability of the features. Based on this new architecture, we propose a new three-stage learning procedure with field effect bilinear initialization, field effect abstraction and estimation, and global fine-tuning with missing features adjustment. By integrating the reliability of features into the new learning procedure, the proposed FEBDN can jointly determine the classification boundary and estimate the missing features. FEBDN has demonstrated impressive performance on recognition and estimation tasks in various standard datasets.", "references": ["André Aleman, Koen B. E. Böcker, Ron Hijman, Edward H. F. de Haanb, and René S. Kahna. 2003. Cognitive basis of hallucinations in schizophrenia: Role of top-down information processing. Schizophr. Res. 64, 2--3, 178--185.", "Pradeep K. Atrey, M. Anwar Hossain, Abdulmotaleb El Saddik, and Mohan S. Kankanhalli. 2010. Multimodal fusion for multimedia analysis: a survey. Multimedia Syst. 16, 345--379.", "Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N. Vapnik. 1992. A training algorithm for optimal margin classifiers. In COLT. ACM, New York, NY, 144--152."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957754"}, {"title": "Selective Cluster-Based Document Retrieval", "authors": ["Or Levi\n,", "Fiana Raiber\n,", "Oren Kurland\n,", "Ido Guy"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe address the long standing challenge of selective cluster-based retrieval; namely, deciding on a per-query basis whether to apply cluster-based document retrieval or standard document retrieval. To address this classification task, we propose a few sets of features based on those utilized by the cluster-based ranker, query-performance predictors, and properties of the clustering structure. Empirical evaluation shows that our method outperforms state-of-the-art retrieval approaches, including cluster-based, query expansion, and term proximity methods.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. UMASS at TREC 2004 -- novelty and hard. In Proc. of TREC-13, 2004.", "N. Balasubramanian and J. Allan. Learning to select rankers. In Proc. of SIGIR, pages 855--856, 2010.", "M. Bendersky, W. B. Croft, and Y. Diao. Quality-biased ranking of web documents. In Proc. of WSDM, pages 95--104, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983737"}, {"title": "Ingrams: A Neuropsychological Explanation For Why People Search", "authors": ["Peter Bailey\n,", "Nick Craswell"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhy do people start a search? Why do they stop? Why do they do what they do in-between? Our goal in this paper is to provide a simple yet general explanation for these acts that has its basis in neuropsychology and observed user behavior. We coin the term \"ingram\", as an information counterpart to Richard Semon's ?engram? or \"memory trace\". People search to create ingrams. People stop searching because they have created sufficient ingrams, or given up. We describe these acts through a pair of user models and use it to explain various user behaviors in search activity. Understanding people?s search acts in terms of ingrams may help us predict or model the interaction of people?s information needs, the queries they issue, and the information they consume. If we could observe certain decision-making acts within these activities, we might also gain new insight into the relationships between textual information and knowledge representation.", "references": ["Azzopardi, L. (2011). The economics in interactive information retrieval. Proc. SIGIR (pp. 15--24).", "Belkin, N. J., Oddy, R. N., & Brooks, H. M. (1982). ASK for information retrieval: Part I. Background and theory. Journal of Documentation, 38(2), 61--71.", "Broder, A. (2002). A taxonomy of web search. In ACM SIGIR Forum (Vol. 36, No. 2, pp. 3--10)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914712"}, {"title": "Towards a Multimedia Knowledge-Based Agent with Social Competence and Human Interaction Capabilities", "authors": ["Leo Wanner\n,", "Josep Blat\n,", "Stamatia Dasiopoulou\n,", "Mónica Domínguez\n,", "Gerard Llorach\n,", "Simon Mille\n,", "Federico Sukno\n,"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nWe present work in progress on an intelligent embodied conversation agent in the basic care and healthcare domain. In contrast to most of the existing agents, the presented agent is aimed to have linguistic cultural, social and emotional competence needed to interact with elderly and migrants. It is composed of an ontology-based and reasoning-driven dialogue manager, multimodal communication analysis and generation modules and a search engine for the retrieval of multimedia background content from the web needed for conducting a conversation on a given topic.", "references": ["M. Adda-Decker and L. Lamel. Pronunciation variants across systems, languages and speaking style. Modeling Pronunciation Variation for Automatic Speech Recognition, Netherlands, 1998.", "J. Agenjo, A. Evans, and J. Blat. Webglstudio: A pipeline for webgl scene creation. In Proceedings of the 18th International Conference on 3D Web Technology, pages 79--82, New York, NY, USA, 2013. ACM.", "E. André. Challenges for social embodiment. In Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research including Business Opportunities and Challenges, pages 35--37. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2927006.2927011"}, {"title": "Query-oriented Unsupervised Multi-document Summarization on Big Data", "authors": ["Sunaina\n,", "Sowmya Kamath S."], "publication": "ICCCNT '16: Proceedings of the 7th International Conference on Computing Communication and Networking Technologies", "abstract": "ABSTRACT\nReal time document summarization is a critical need nowadays, owing to the large volume of information available for our reading, and our inability to deal with this entirely due to limitations of time and resources. Oftentimes, information is available in multiple sources, offering multiple contexts and viewpoints on a single topic of interest. Automated multi-document summarization (MDS) techniques aim to address this problem. However, current techniques for automated MDS suffer from low precision and accuracy with reference to a given subject matter, when compared to those summaries prepared by humans and takes large time to create the summary when the input given is too huge. In this paper, we propose a hybrid MDS technique combining feature based algorithms and dynamic programming for generating a summary from multiple documents based on user provided query. Further, in real-world scenarios, Web search serves up a large number of URLs to users, and the work of making sense of these with reference to a particular query is left to the user. In this context, an efficient parallelized MDS technique based on Hadoop is also presented, for serving a concise summary of multiple Webpage contents for a given user query in reduced time duration.", "references": ["K.S. Jones, Automatic summarizing: the state of the art, Inf. Process. Manage.43 (6) (2007) 1449--1481.", "I. Mani, M.T. Maybury, Advances in Automatic Text Summarization, MIT Press,Cambridge, 1999, pp. 442.", "J. Tang, L. Yao, D. Chen, Multi-topic based query-oriented summarization, in:Proceedings of the 9th SIAM International Conference on Data Mining, Nevada, USA, 30 April-2 May, 2009, pp. 1148--1159."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967878.2967919"}, {"title": "Toward speech text recognition for comic books", "authors": ["Christophe Rigaud\n,", "Srikanta Pal\n,", "Jean-Christophe Burie\n,", "Jean-Marc Ogier"], "publication": "MANPU '16: Proceedings of the 1st International Workshop on coMics ANalysis, Processing and Understanding", "abstract": "ABSTRACT\nSpeech text in comic books is placed and written in a particular manner by the letterers which raises unusual challenges for text recognition. We first detail these challenges and present different approaches to solve them. We compare the performances of generic versus specifically trained OCR systems for typewritten and handwritten text lines from French comic books. This work is evaluated over a subset of public (eBDtheque) and private (Sequencity) datasets. We demonstrate that generic OCR systems perform best on typewritten-like and lowercase fonts while specifically trained OCR can be very powerful on skewed, uppercase and even cursive fonts.", "references": ["T. M. Breuel. The ocropus open source ocr system. In Proc. SPIE 6815, Document Recognition and Retrieval XV, pages 68150F--15, 2008.", "T. M. Breuel, A. Ul-Hasan, M. A. Al-Azawi, and F. Shafait. High-performance ocr for printed english and fraktur using lstm networks. In 2013 12th International Conference on Document Analysis and Recognition, pages 683--687. IEEE, 2013.", "M. R. Gaikwad and N. Pardeshi. Text extraction and recognition using median filter. International Research Journal of Engineering and Technology, 3(1):717--721, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011549.3011557"}, {"title": "Enhancing Scholarly Use of Digital Libraries: A Comparative Survey and Review of Bibliographic Metadata Ontologies", "authors": ["Jacob Jett\n,", "Terhi Nurmikko-Fuller\n,", "Timothy W. Cole\n,", "Kevin R. Page\n,", "J. Stephen Downie"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe HathiTrust Research Center (HTRC) is engaged in the development of tools that will give scholars the ability to analyze the HathiTrust digital library's 14 million volume corpus. A cornerstone of the HTRC's digital infrastructure is the workset -- a kind of scholar-built research collection intended for use with the HTRC's analytics platform. Because more than 66% of the digital corpus is subject to copyright restrictions, scholarly users remain dependent upon the descriptive accounts provided by traditional metadata records in order to identify and gather together bibliographic resources for analysis. This paper compares the MADSRDF/MODSRDF, Bibframe, schema.org, BIBO, and FaBiO ontologies by assessing their suitability for employment by the HTRC to meet scholars' needs. These include distinguishing among multiple versions of the same work; representing the complex historical and physical relationships among those versions; and identifying and providing access to finer grained bibliographic entities, e.g., poems, chapters, sections, and even smaller segments of content.", "references": ["T. Berners-Lee, J. Hendler, and O. Lassila. The semantic web. Scientific American, 284(5):28--37, 2001.", "M. Bowman, S. K. Debray, and L. L. Peterson. FRBR object-orientated definition and mapping from FRBRER, FRAD and FRSAD (version 2). International Working Group on FRBR and CIDOC CRM Harmonisation, 2013.", "K. Fenlon, M. Senseney, H. Green, S. Bhattacharyya, C. Willis, and J. Downie. Scholar-built collections: A study of user requirements for research in large-scale digital libraries. Proceedings of the American Society for Information Science and Technology, 51(1):1--10, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910903"}, {"title": "How to Get Them a Dream Job?: Entity-Aware Features for Personalized Job Search Ranking", "authors": ["Jia Li\n,", "Dhruv Arya\n,", "Viet Ha-Thuc\n,", "Shakti Sinha"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThis paper proposes an approach to applying standardized entity data to improve job search quality and to make search results more personalized. Specifically, we explore three types of entity-aware features and incorporate them into the job search ranking function. The first is query-job matching features which extract and standardize entities mentioned in queries and documents, then semantically match them based on these entities. The second type, searcher-job expertise homophily, aims to capture the fact that job searchers tend to be interested in the jobs requiring similar expertise as theirs. To measure the similarity, we use standardized skills in job descriptions and searchers' profiles as well as skills that we infer searchers might have but not explicitly list in their profiles. Third, we propose a concept of entity-faceted historical click-through-rates (CTRs) to capture job document quality. Faceting jobs by their standardized companies, titles, locations, etc., and computing historical CTRs at the facet level instead of individual job level alleviate sparseness issue in historical action data. This is particularly important in job search where job lifetime is typically short. Both offline and online experiments confirm the effectiveness of the features. In offline experiment, using the entity-aware features gives improvements of +20%, +12.1% and +8.3% on Precision@1, MRR and NDCG@25, respectively. Online A/B test shows that a new model with these features is +11.3% and +5.3% better than the baseline in terms of click-through-rate and apply rate.", "references": ["D. Arya, V. Ha-Thuc, and S. Sinha. Personalized federated search at linkedin. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM), pages 1699--1702, 2015.", "D. Buscaldi and P. Rosso. Using geowordnet for geographical information retrieval. In Evaluating Systems for Multilingual and Multimodal Information Access, pages 863--866, 2008.", "O. Chapelle and Y. Chang. Yahoo! learning to rank challenge overview. In Proceedings of the Yahoo Learning to Rank Challenge, held at ICML, pages 1--24, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939721"}, {"title": "Energy efficiency of large scale graph processing platforms", "authors": ["Kashif Nizam Khan\n,", "Mohammad Ashraful Hoque\n,", "Tapio Niemi\n,", "Zhonghong Ou\n,", "Jukka K. Nurminen"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nA number of graph processing platforms have emerged recently as a result of the growing demand on graph data analytics with complex and large-scale graph structured datasets. These platforms have been tailored for iterative graph computations and can offer an order of magnitude performance gain over generic data-flow frameworks like Apache Hadoop and Spark. Nevertheless, the increasing availability of such platforms and their functionality overlap necessitates a comparative study on various aspects of the platforms, including applications, performance and energy efficiency. In this work, we focus on the energy efficiency aspect of some large scale graph processing platforms. Specifically, we select two representatives, e.g., Apache Giraph and Spark GraphX, for the comparative study. We compare and analyze the energy consumption of these two platforms with PageRank, Strongly Connected Component and Single Source Shortest Path algorithms over five different realistic graphs. Our experimental results demonstrate that GraphX outperforms Giraph in terms of energy consumption. Specifically, Giraph consumes 1.71 times more energy than GraphX on average for the mentioned algorithms.", "references": ["Tom Bostoen, Sape Mullender, and Yolande Berbers. 2013. Power-reduction Techniques for Data-center Storage Systems. ACM Comput. Surv. 45, 3, Article 33 (July 2013), 38 pages.", "Mihai Capotă, Tim Hegeman, Alexandru Iosup, Arnau Prat-Pérez, Orri Erling, and Peter Boncz. 2015. Graphalytics: A Big Data Benchmark for Graph-Processing Platforms. In Proceedings of the GRADES'15 (GRADES'15). ACM, New York, NY, USA, Article 7, 6 pages.", "Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: Simplified Data Processing on Large Clusters. Commun. ACM 51, 1 (Jan. 2008), 107--113."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2968296"}, {"title": "Interacting with Financial Data using Natural Language", "authors": ["Vassilis Plachouras\n,", "Charese Smiley\n,", "Hiroko Bretz\n,", "Ola Taylor\n,", "Jochen L. Leidner\n,", "Dezhao Song\n,", "Frank Schilder"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFinancial and economic data are typically available in the form of tables and comprise mostly of monetary amounts, numeric and other domain-specific fields. They can be very hard to search and they are often made available out of context, or in forms which cannot be integrated with systems where text is required, such as voice-enabled devices. This work presents a novel system that enables both experts in the finance domain and non-expert users to search financial data with both keyword and natural language queries. Our system answers the queries with an automatically generated textual description using Natural Language Generation (NLG). The answers are further enriched with derived information, not explicitly asked in the user query, to provide the context of the answer. The system is designed to be flexible in order to accommodate new use cases without significant development effort, thus allowing fast integration of new datasets.", "references": ["B. Aditya, Gaurav Bhalotia, Soumen Chakrabarti, Arvind Hulgeri, Charuta Nakhe, Parag, and S. Sudarshan. BANKS: Browsing and keyword searching in relational databases. VLDB '02, pages 1083--1086, 2002.", "Sonia Bergamaschi, Elton Domnori, Francesco Guerra, Mirko Orsini, Raquel Trillo Lado, and Yannis Velegrakis. Keymantic: Semantic keyword-based searching in data integration systems. Proc. VLDB Endow., 3(1--2):1637--1640, 2010.", "Sina Fakhraee and Farshad Fotouhi. DBSemSXplorer: Semantic-based keyword search system over relational databases for knowledge discovery. KEYS '12, pages 54--62, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911457"}, {"title": "Estimating topical volume in social media streams", "authors": ["Praveen Bommannavar\n,", "Jimmy Lin\n,", "Anand Rajaraman"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThis paper tackles the problem of estimating the volume of social media posts (e.g., tweets) that pertain to a particular topic. This task differs from related filtering and event detection applications in that the filtered content isn't meant for direct human consumption, but rather we are primarily interested in estimating the cardinality of relevant posts. We present a simple yet effective technique for generating and curating keywords to create what we call \"overlap filters\", which can be applied to a stream of social media posts. Our approach leverages human labeling and thus a crucial element of the work involves minimizing the cost of human computation. On top of a \"day zero\" cold start algorithm, we describe a number of optimizations that take advantage of history to further reduce labeling costs. Experimental results show that our overlap filters produce accurate volume estimates at low costs, and our method is simple enough to deploy in practice.", "references": ["J. Allan. Topic Detection and Tracking: Event-Based Information Organization. Kluwer Academic Publishers, Dordrecht, The Netherlands, 2002.", "H. Becker, M. Naaman, and L. Gravano. Beyond trending topics: Real-world event identification on Twitter. In Proceedings of the 5th International AAAI Conference on Weblogs and Social Media (ICWSM 2011), pages 438--441, 2011.", "C. Buntain, J. Lin, and J. Golbeck. Learning to discover key moments in social media streams. In arXiv:1508.00488, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851810"}, {"title": "A scalable, high-performance Algorithm for hybrid job recommendations", "authors": ["Toon De Pessemier\n,", "Kris Vanhecke\n,", "Luc Martens"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nRecommender systems can be used as a tool to assist people in finding a job. However, this specific domain requires expert algorithms with domain knowledge to recommend jobs conformable to people's expertise and interests. This is the topic of the Recsys Challenge 2016, which aims for an algorithm that predicts the job postings that a user will positively interact with. Our solution is a hybrid algorithm combining a content-based and KNN approach. The content-based algorithm matches features of candidate recommendations and job postings of historical interactions. The KNN approach searches for the job postings that are the most similar to the postings the user interacted with in the past. The resulting combination is a lightweight algorithm that is fast and scalable, generating recommendations with a proper evaluation score.", "references": ["F. Abel, D. Kohlsdorf, and R. Pálovics. Training Data of the RecSys Challenge 2016, 2016. Online available at https://github.com/recsyschallenge/2016/blob/master/TrainingDataset.md.", "ACM - Xing. RecSys Challenge 2016, 2016. Online available at https://recsys.xing.com/.", "C. Johnston. Netflix Never Used Its $1 Million Algorithm Due Do Engineering Costs, 2016. Online available at http://www.wired.com/2012/04/netflix-prize-costs/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987539"}, {"title": "Item-Based Video Recommendation: An Hybrid Approach considering Human Factors", "authors": ["Andrea Ferracani\n,", "Daniele Pezzatini\n,", "Marco Bertini\n,", "Alberto Del Bimbo"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper we propose a method for video recommendation in Social Networks based on crowdsourced and automatic video annotations of salient frames. We show how two human factors, users' self-expression in user profiles and perception of visual saliency in videos, can be exploited in order to stimulate annotations and to obtain an efficient representation of video content features. Results are assessed through experiments conducted on a prototype of social network for video sharing. Several baseline approaches are evaluated and we show how the proposed method improves over them.", "references": ["M. Bertini, A. Del Bimbo, A. Ferracani, F. Gelli, D. Maddaluno, and D. Pezzatini. Socially-aware video recommendation using users' profiles and crowdsourced annotations. In Proc. of WSAM, 2013.", "K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In Proc. of BMVC, 2014.", "B. Craggs, M. Kilgallon Scott, and J. Alexander. ThumbReels: Query sensitive web video previews based on temporal, crowdsourced, semantic tagging. In Proc. of CHI, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912066"}, {"title": "MVC: A Dataset for View-Invariant Clothing Retrieval and Attribute Prediction", "authors": ["Kuan-Hsien Liu\n,", "Ting-Yen Chen\n,", "Chu-Song Chen"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nClothing retrieval and clothing style recognition are important and practical problems. They have drawn a lot of attention in recent years. However, the clothing photos collected in existing datasets are mostly of front- or near-front view. There are no datasets designed to study the influences of different viewing angles on clothing retrieval performance. To address view-invariant clothing retrieval problem properly, we construct a challenge clothing dataset, called Multi-View Clothing dataset. This dataset not only has four different views for each clothing item, but also provides 264 attributes for describing clothing appearance. We adopt a state-of-the-art deep learning method to present baseline results for the attribute prediction and clothing retrieval performance. We also evaluate the method on a more difficult setting, cross-view exact clothing item retrieval. Our dataset will be made publicly available for further studies towards view-invariant clothing retrieval.", "references": ["L. Bossard, M. Dantone, C. Leistner, C. Wengert, T. Quack, and L. Van Gool. Apparel classification with style. In Computer Vision--ACCV 2012, pages 321--335. Springer, 2013.", "H. Chen, A. Gallagher, and B. Girod. Describing clothing by semantic attributes. In Computer Vision--ECCV 2012, pages 609--623. Springer, 2012.", "H. Chen, Z. J. Xu, Z. Q. Liu, and S. C. Zhu. Composite templates for cloth modeling and sketching. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, volume 1, pages 943--950. IEEE, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912058"}, {"title": "Evaluation of Retrieval Algorithms for Expertise Search", "authors": ["Gaya K. Jayasinghe\n,", "Sarvnaz Karimi\n,", "Melanie Ayre"], "publication": "ADCS '16: Proceedings of the 21st Australasian Document Computing Symposium", "abstract": "ABSTRACT\nEvaluation of expertise search systems is a non-trivial task. While in a typical search engine the responses to user queries are documents, the search results for an expertise retrieval system are people. The relevancy scores indicate how knowledgeable they are on a given topic. Within an organisation, such a ranking of employees could potentially be difficult as well as controversial. We introduce an in-house capability search system built for an organisation with a diverse range of disciplines. We report on two attempts of evaluating six different ranking algorithms implemented for this system. Evaluating the system using relevance judgements produced in each of the two attempts leads to an understanding of how different methods of collecting judgements on people's expertise can lead to different effectiveness of algorithms.", "references": ["Peter Bailey, Nick Craswell, Arjen P. de Vries, and Ian Soboroff. Overview of the TREC 2007 enterprise track. In TREC, 2007.", "Krisztian Balog, Ian Soboroff, Paul Thomas, Peter Bailey, Nick Craswell, and Arjen P. de Vries. Overview of the TREC 2008 enterprise track. In TREC, 2008.", "Krisztian Balog, Yi Fang, Maarten de Rijke, Pavel Serdyukov, and Luo Si. Expertise retrieval. FTIR, 6(2-3):127--256, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015022.3015035"}, {"title": "Enriching How-to Guides by Linking Actionable Phrases", "authors": ["Alexandr Chernov\n,", "Nikolaos Lagos\n,", "Matthias Gallé\n,", "Ágnes Sándor"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe World Wide Web contains a large number of community created knowledge of instructional nature. Similarly, in a commercial setting, databases of instructions are used by customer-care providers to guide clients in the resolution of issues. Most of these instructions are expressed in natural language. Knowledge Bases including such information are valuable through the sum of their single entries. However, as each entry is created mostly independently, users (e.g. other community members) cannot take advantage of the accumulated knowledge that can be developed via the aggregation of related entries. In this paper we consider the problem of inter-linking Knowledge Base entries, in order to get relevant information from other parts of the Knowledge Base.\nTo achieve this, we propose to detect \\textit{actionable phrases} -- text fragments that describe how to perform a certain action -- and link them to other entries. The extraction method that we implement achieves an F-score of 67.35\\%. We also show that using actionable phrases results in better linking quality than using coarser-grained spans of text, as proposed in the literature. Besides the evaluation of both steps, we also include a detailed error analysis and release our annotation to the community.", "references": ["S. Aıt-Mokhtar, J.-P. Chanod, and C. Roux. Robustness beyond shallowness: Incremental deep parsing. Nat. Lang. Eng., 8(3):121--144, June 2002.", "S. Bird, E. Klein, and E. Loper. Natural Language Processing with Python. O'Reilly Media, Inc., 1st edition, 2009.", "C. Brun, V. Nikoulina, and N. Lagos. Linguistically-adapted structural query annotation for digital libraries in the social sciences. In Proceedings of the 6th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, LaTeCH'12, pages 55--64, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890585"}, {"title": "Rationale and Architecture for Incorporating Human Oculomotor Plant Features in User Interest Modeling", "authors": ["Sampath Jayarathna\n,", "Frank Shipman"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWe present a conceptual framework expanding the use of eye movement as a source of implicit relevance feedback. While gaze time has been the primary feature to be incorporated in interest modeling, this work constructs a model of human oculomotor plant features during user's interaction with multiple everyday applications with the goal of better interpreting user gaze data. The following presents the anatomical reasoning behind incorporating additional gaze features, the integration of the additional features into an existing interest modeling architecture, and a plan for assessing the impact of the addition of the features.", "references": ["Borji, A. and Itti, L., \"Defending Yarbus: Eye movements reveal observers' task,\" Journal of vision, vol. 14, p. 29, 2014.", "Borji, A., Lennartz, A., and Pomplun, M., \"What do eyes reveal about the mind?: Algorithmic inference of search targets from fixations,\" Neurocomputing, vol. 149, pp. 788--799, 2015.", "Borji, A., Sihite, D. N., and Itti, L., \"Probabilistic learning of task-specific visual attention,\" in Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, 2012, pp. 470--477."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854992"}, {"title": "A bounded memory allocator for software-defined global address spaces", "authors": ["François Gindraud\n,", "Fabrice Rastello\n,", "Albert Cohen\n,", "François Broquedis"], "publication": "ISMM 2016: Proceedings of the 2016 ACM SIGPLAN International Symposium on Memory Management", "abstract": "ABSTRACT\nThis paper presents a memory allocator targeting manycore architec- tures with distributed memory. Among the family of Multi Processor System on Chip (MPSoC), these devices are composed of multiple nodes linked by an on-chip network; most nodes have multiple processors sharing a small local memory. While MPSoC typically excel on their performance-per-Watt ratio, they remain hard to program due to multilevel parallelism, explicit resource and memory management, and hardware constraints (limited memory, network topology). Typical programming frameworks for MPSoC leave much target-specific work to the programmer: combining threads or node-local OpenMP, software caching, explicit message passing (and sometimes, routing), with non-standard interfaces. More abstract, automatic frameworks exist, but they target large-scale clusters and do not model the hardware constraints of MPSoC. The memory allocator described in this paper is one component of a larger runtime system, called Givy, to support dynamic task graphs with automatic software caching and data-driven execution on MPSoC. To simplify the programmer’s view of memory, both runtime and program data objects live in a Global Address Space (GAS). To avoid address collisions when objects are dynamically allocated, and to manage virtual memory mappings across nodes, a GAS-aware memory allocator is required. This paper proposes such an allocator with the following properties: (1) it is free of inter-node synchronizations; (2) its node-local performance match that of state-of-the-art shared-memory allocators; (3) it provides node-local mechanisms to implement inter-node software caching within a GAS; (4) it is well suited for small memory systems (a few MB per node).", "references": ["Cppmem. http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/.", "Tcmalloc. http://gperftools.googlecode.com/svn/trunk/ doc/tcmalloc.html.", "Tilera. http://www.tilera.com."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926697.2926709"}, {"title": "Extracting Search Query Patterns via the Pairwise Coupled Topic Model", "authors": ["Takuya Konishi\n,", "Takuya Ohwa\n,", "Sumio Fujita\n,", "Kazushi Ikeda\n,", "Kohei Hayashi"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nA fundamental yet new challenge in information retrieval is the identification of patterns behind search queries. For example, the query \"NY restaurant\" and \"boston hotel\" shares the common pattern \"LOCATION SERVICE\". However, because of the diversity of real queries, existing approaches require data preprocessing by humans or specifying the target query domains, which hinders their applicability.\nWe propose a probabilistic topic model that assumes that each term (e.g., \"NY\") has a topic (LOCATION). The key idea is that we consider topic co-occurrence in a query rather than a topic sequence, which significantly reduces computational cost yet enables us to acquire coherent topics without the preprocessing. Using two real query datasets, we demonstrate that the obtained topics are intelligible by humans, and are highly accurate in keyword prediction and query generation tasks.", "references": ["G. Agarwal, G. Kabra, and K. C.-C. Chang. Towards rich query interpretation: Walking back and forth for mining query templates. In WWW, 2010.", "R. Agrawal, A. Gupta, Y. Prabhu, and M. Varma. Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages. In WWW, 2013.", "D. M. Blei and J. D. Lafferty. A correlated topic model of science. The Annals of Applied Statistics, 1(1):17--35, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835794"}, {"title": "Designing a question-answering system for comic contents", "authors": ["Yukihiro Moriyama\n,", "Byeongseon Park\n,", "Shinnosuke Iwaoki\n,", "Mitsunori Matsushita"], "publication": "MANPU '16: Proceedings of the 1st International Workshop on coMics ANalysis, Processing and Understanding", "abstract": "ABSTRACT\nThe objective of our research is to create a question answering system for comics. Because a comic has multimodal contents, we have to answer questions about text as well as illustrations. This is different from the conventional question answering system. To solve this problem, in this study, we organized the information to be obtained from comic illustrations and examined the framework of question answering for this content. Then, we built a prototype system and examined the question answering system for comic contents.", "references": ["S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. IEEE Trans. Pattern Anal. Mach. Intell., 24(4):509--522, 2002.", "S. Cruchet, A. Gaudinat, and C. Boyer. Supervised approach to recognize question type in a QA system for health. eHealth Beyond the Horizon - Get IT There, 136:407--412, 2008.", "V. L. Garcia, E. Motta, and V. Uren. Aqualog: An ontology-driven question answering system to interface the semantic web. In Proc. 2006 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Companion Volume: Demonstrations, pages 269--272, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011549.3011554"}, {"title": "Mass Serialization Method for Document Encryption Policy Enforcement", "authors": ["Margaret Sturgill\n,", "Steven J. Simske"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nAnalytics obtained during the creation of a database of mass serialized codes can also be used to help enforcement of encryption policy on documents. In this paper, we introduce a set of metrics which complement traditional NIST cryptography methods -- 4 mass serialization and one entropy metric -- which in combination can allow a discrimination between encrypted vs. zipped files. We describe the use of these methods to identify a broad range of non-randomness in number sets, and apply them to a more mundane problem-that of automatic assessment of the encryption state of a corpora of documents.", "references": ["Association of Computational Linguistics, ACL Anthology http://aclweb.org/anthology .", "Dieharder tool (http://www.phy.duke.edu/~rgb/General/dieharder.php) based on Diehard Tests (http://en.wikipedia.org/wiki/Diehard_test .", "Dorfinger P., Panholzer G. and John W. 2011. Entropy estimation for real-time encrypted traffic identification. In Proceedings of the Third international conference on Traffic monitoring and analysis (TMA'11), Jordi Domingo-Pascual, Yuval Shavitt, and Steve Uhlig (Eds.). Springer-Verlag, Berlin, Heidelberg, 164--171."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967166"}, {"title": "FdDCA: A Novel Fuzzy Deterministic Dendritic Cell Algorithm", "authors": ["Nura Mukhtar\n,", "George M. Coghill\n,", "Wei Pang"], "publication": "GECCO '16 Companion: Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion", "abstract": "ABSTRACT\nThe Dendritic Cell Algorithm (DCA) and its improved version: Deterministic Dendritic Cell Algorithm (dDCA) are essentially binary classification algorithms based on the behavior of Dendritic Cells (DCs) in the immune system. Both DCA and dDCA collect and process the data in form of signals, and produce output signal. The signals are divided in two types: danger and safe signals, and the output signal is determined by the values of the danger and safe signals. However, both DCA and dDCA suffer from data misclassification due to their sensitivity to data order. In this research we proposed a Fuzzy Deterministic Dendritic Cell Algorithm (FdDCA), which combines dDCA, fuzzy sets, and K-means clustering. The main objective of this research is to smooth the sharp boundaries between signals since we cannot always identify a clear boundary between the values of the signals. Our approach fuzzifies the signal values using linguistic variables, and a rule base is built to support fuzzy inference. The experimental results based on real data sets show that our approach shows a promising results compared to DCA and dDCA", "references": ["J. Kim and P.J. Bentley. Towards an artificial immune system for network intrusion detection: An investigation of dynamic clonal selection. In Proceedings of Congress Evolutionary Computation, pages 1244--1252. IEEE, 2001.", "L.N. de Castro and F.J. Von Zuben. The clonal selection algorithm with engineering applications. In Proceedings of GECCO Workshop on Artificial Immune Systems and Their Applications, pages 36--37, July 2000.", "S. Forrest, A.S. Perelson, L. Allen, and R. Cherukuri. Self-nonselfdiscrimination in a computer. In In Proceedings of IEEE Symposium on Research in Security and Privacy, pages 36--37. IEEE, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908961.2931662"}, {"title": "Scalable Time-Decaying Adaptive Prediction Algorithm", "authors": ["Yinyan Tan\n,", "Zhe Fan\n,", "Guilin Li\n,", "Fangshan Wang\n,", "Zhengbing Li\n,", "Shikai Liu\n,", "Qiuling Pan\n,", "Eric P. Xing\n,", "Qirong Ho"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nOnline learning is used in a wide range of real applications, e.g., predicting ad click-through rates (CTR) and personalized recommendations. Based on the analysis of users' behaviors in Video-On-Demand (VoD) recommender systems,we discover that the most recent users' actions can better reflect users' current intentions and preferences. Under this observation, we thereby propose a novel time-decaying online learning algorithm derived from the state-of-the-art FTRL-proximal algorithm, called Time-Decaying Adaptive Prediction (TDAP) algorithm.\nTo scale Big Data, we further parallelize our algorithm following the data parallel scheme under both BSP and SSP consistency model. We experimentally evaluate our TDAP algorithm on real IPTV VoD datasets using two state-of-the-art distributed computing platforms, TDAP achieves good accuracy: it improves at least 5.6% in terms of prediction accuracy, compared to FTRL-proximal algorithm; and TDAP scales well: it runs 4 times faster when the number of machines increases from 2 to 10.", "references": ["A. Agarwal, O. Chapelle, M. Dudík, and J. Langford. A reliable effective terascale linear learning system. JMLR, 15(1):1111--1133, 2014.", "D. Agarwal, B.-C. Chen, and P. Elango. Fast online learning through offline initialization for time-sensitive recommendation. In SIGKDD, pages 703--712, 2010.", "B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. Models and issues in data stream systems. In PODS, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939714"}, {"title": "POMP: a powerful splice mapper for RNA-seq reads", "authors": ["Subrata Saha\n,", "Sanguthevar Rajasekaran"], "publication": "BCB '16: Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics", "abstract": "ABSTRACT\nRNA Sequencing (RNA-seq) based on next-generation sequencing (NGS) technology enables transcriptome analyses of entire genomes at a very high resolution. Due to limitations of the sequencing technology the reads are very short and erroneous. As a consequence it is a very challenging task to accurately map RNA-seq reads onto the genome and identify the splice junctions. There are two shortcomings in some of the existing best-known algorithms for identifying splice junctions: 1) the junction boundaries are predicted within a large range, 2) they take a long time and 3) the predictions of splice junctions are inaccurate. In this article we propose a novel algorithm POMP to accurately detect the splice junctions considering all the shortcomings of the existing algorithms as stated above. It generates accurate candidate splice junctions utilizing expected properties around the splice junctions. These candidates are used as examples to train a learner. The model learnt by the learner can be used to identify splice junctions. Extensive experiments were done considering whole human genome splicing events. Experimental results show that POMP is indeed a more effective and efficient algorithm compared to the other state-of-the-art algorithms in terms of sensitivity, specificity, and runtime.", "references": ["Trapnell,C., Pachter,L. and Salzberg,S.L. (2009) TopHat: discovering splice junctions with RNA-Seq. Bioinformatics, 25, 1105--1111.", "Langmead,B., Trapnell,C., Pop,M. and Salzberg,S.L. (2009) Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol., 10, R25.", "Au,K.F., Jiang,H., Lin,L., Xing,Y. and Wong,W.H. (2010) Detection of splice junctions from paired-end RNA-seq data by SpliceMap.Nucleic Acids Res., 38, 4570--4578."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975167.2975210"}, {"title": "Explicit In Situ User Feedback for Web Search Results", "authors": ["Jin Young Kim\n,", "Jaime Teevan\n,", "Nick Craswell"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nGathering evidence about whether a search result is relevant is a core concern in the evaluation and improvement of information retrieval systems. Two common sources of evidence for establishing relevance are judgements from trained assessors and logs of online user behavior. However, both are limited; it is hard for a trained assessor to know exactly what users want to find, and user behavior only provides an implicit and ambiguous signal. In this paper, we aim to address these limitations by collecting explicit feedback on web search results from users in situ as they search. When users return to the search result page via the browser back button after having clicked on a result, we ask them to provide a binary thumbs up or thumbs down judgment and text feedback. We collect in situ feedback from a large commercial search engine, and compare this feedback with the judgments provided by trained assessors. We find that in situ feedback differs significantly from traditional relevance judgments, and that it suggests a different interpretation of behavior signals, with the dwell time threshold between negative and positive in situ feedback being 87 seconds, longer than the more common heuristic of 30 seconds. Using text feedback from users, we discuss why user feedback may differ from editorial judgments.", "references": ["Chilton, L. and Teevan, J. (2011). Addressing information needs directly in the search result page. In Proceedings of WWW 2011.", "Claypool, M., Le, P., Wased, M. and Brown, D. (2001). Implicit interest indicators. In Proceedings of IUI 2001.", "Fox, S., K. Karnawat, M. Mydland, S. Dumais, and T. White. Evaluating implicit measures to improve Web search. TOIS, 23(2), 2005, 147--168."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914754"}, {"title": "UpBit: Scalable In-Memory Updatable Bitmap Indexing", "authors": ["Manos Athanassoulis\n,", "Zheng Yan\n,", "Stratos Idreos"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nBitmap indexes are widely used in both scientific and commercial databases. They bring fast read performance for specific types of queries, such as equality and selective range queries. A major drawback of bitmap indexes, however, is that supporting updates is particularly costly. Bitmap indexes are kept compressed to minimize storage footprint; as a result, updating a bitmap index requires the expensive step of decoding and then encoding a bitvector. Today, more and more applications need support for both reads and writes, blurring the boundaries between analytical processing and transaction processing. This requires new system designs and access methods that support general updates and, at the same time, offer competitive read performance. In this paper, we propose scalable in-memory Updatable Bitmap indexing (UpBit), which offers efficient updates, without hurting read performance. UpBit relies on two design points. First, in addition to the main bitvector for each domain value, UpBit maintains an update bitvector, to keep track of updated values. Effectively, every update can now be directed to a highly-compressible, easy-to-update bitvector. While update bitvectors double the amount of uncompressed data, they are sparse, and as a result their compressed size is small. Second, we introduce fence pointers in all update bitvectors which allow for efficient retrieval of a value at an arbitrary position. Using both synthetic and real-life data, we demonstrate that UpBit significantly outperforms state-of-the-art bitmap indexes for workloads that contain both reads and writes. In particular, compared to update-optimized bitmap index designs UpBit is 15-29x faster in terms of update time and 2.7x faster in terms of read performance. In addition, compared to read-optimized bitmap index designs UpBit achieves efficient and scalable updates (51-115x lower update latency), while allowing for comparable read performance, having up to 8% overhead.", "references": ["G. Antoshenkov. Byte-aligned Bitmap Compression. In Proceedings of the Conference on Data Compression (DCC), pages 476--476, 1995.", "M. Athanassoulis, S. Chen, A. Ailamaki, P. B. Gibbons, and R. Stoica. MaSM: Efficient Online Updates in Data Warehouses. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pages 865--876, 2011.", "M. Athanassoulis, S. Chen, A. Ailamaki, P. B. Gibbons, and R. Stoica. Online Updates on Data Warehouses via Judicious Use of Solid-State Storage. ACM Transactions on Database Systems (TODS), 40(1), 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2915964"}, {"title": "Placing Broadcast News Videos in their Social Media Context Using Hashtags", "authors": ["Joseph G. Ellis\n,", "Svebor Karaman\n,", "Hongzhi Li\n,", "Hong Bin Shim\n,", "Shih-Fu Chang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the growth of social media platforms in recent years, social media is now a major source of information and news for many people around the world. In particular the rise of hashtags have helped to build communities of discussion around particular news, topics, opinions, and ideologies. However, television news programs still provide value and are used by a vast majority of the population to obtain their news, but these videos are not easily linked to broader discussion on social media. We have built a novel pipeline that allows television news to be placed in its relevant social media context, by leveraging hashtags. In this paper, we present a method for automatically collecting television news and social media content (Twitter) and discovering the hashtags that are relevant for a TV news video. Our algorithms incorporate both the visual and text information within social media and television content, and we show that by leveraging both modalities we can improve performance over single modality approaches.", "references": ["J. Allan, J. G. Carbonell, G. Doddington, J. Yamron, and Y. Yang. Topic detection and tracking pilot study final report. 1998.", "S. Amer-Yahia, S. Anjum, A. Ghenai, A. Siddique, S. Abbar, S. Madden, A. Marcus, and M. El-Haddad. Maqsa: a system for social analytics on news.", "L. Ballan, M. Bertini, T. Uricchio, and A. Del Bimbo. Data-driven approaches for social image and video tagging. Multimedia Tools and Applications, 74(4):1443--1468, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2970929"}, {"title": "Tweet Properly: Analyzing Deleted Tweets to Understand and Identify Regrettable Ones", "authors": ["Lu Zhou\n,", "Wenbo Wang\n,", "Keke Chen"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nInappropriate tweets can cause severe damages on authors' reputation or privacy. However, many users do not realize the negative consequences until they publish these tweets. Published tweets have lasting effects that may not be eliminated by simple deletion because other users may have read them or third-party tweet analysis platforms have cached them. Regrettable tweets, i.e., tweets with identifiable regrettable contents, cause the most damage on their authors because other users can easily notice them. In this paper, we study how to identify the regrettable tweets published by \\emph{normal individual users} via the contents and users' historical deletion patterns. We identify normal individual users based on their publishing, deleting, followers and friends statistics. We manually examine a set of randomly sampled deleted tweets from these users to identify regrettable tweets and understand the corresponding regrettable reasons. By applying content-based features and personalized history-based features, we develop classifiers that can effectively predict regrettable tweets.", "references": ["H. Almuhimedi, S. Wilson, B. Liu, N. Sadeh, and A. Acquisti. Tweets are forever: a large-scale quantitative analysis of deleted tweets. In Proceedings of CSCW, pages 897--908. ACM, 2013.", "J. Bak, C. Lin, and A. H. Oh. Self-disclosure topic model for classifying and analyzing twitter conversations. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP, pages 1986--1996, 2014.", "L. Bauer, L. F. Cranor, S. Komanduri, M. L. Mazurek, M. K. Reiter, M. Sleeper, and B. Ur. The post anachronism: The temporal dimension of facebook privacy. In Proceedings of the 12th ACM workshop on Workshop on privacy in the electronic society, pages 1--12. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883052"}, {"title": "A language based comparison of different similarity functions and classifiers using web based Bilingual Question Answering System developed using Machine Learning Approach", "authors": ["Krishma Singla\n,", "Mohit Dua\n,", "Garima Nanda"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nContemporary information techniques and services offered by the Internet are going through the dilemma of determining and managing an increasing amount of textual information, to which ingress is often difficult. But recently Machine Learning approaches have shown their outstanding performance and elasticity in many applications such as Artificial Intelligence and Pattern Recognition. Question Answering (QA) System is an Information Retrieval system in which the expected response given is directly the answer as requested by the user instead of list of references which have some probability of being the answer. The main intention of this research is to present the knowledge and fetch the answer for a given query by employing machine learning approach. The query will be matched to the knowledge database by computing their similarity. The stated research portrays the Web Based Bilingual Question Answering system constituting of Hindi and English language employing by machine learning approach.", "references": ["Garima Nanda, Krishma Singla and Mohit Dua \"A Hindi Question Answering System using Machine Learning approach\" (ICCTICT 2016) IEEE, (unpublished).", "Sunil A. Khillare, Bharat A. Shelke, and C. NamrataMahender,\" Comparitive Study on Question Answering Systems and Techniques,\" International Journal of Advanced Research in Computer Science and Software Engineering, pp. 775--778, Vol. 4, Issue 11, November 2014.", "Jovita, Linda, Andrei Hartawan, DerwinSuhartono,\" Using Vector Space Model in Question Answering System,\" International Conference on Computer Science and Computational Intelligence (ICCSCI 2015), ScienceDirect, pp. 305--311."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905336"}, {"title": "Understanding Sparse Topical Structure of Short Text via Stochastic Variational-Gibbs Inference", "authors": ["Tianyi Lin\n,", "Siyuan Zhang\n,", "Hong Cheng"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWith the soaring popularity of online social media like Twitter, analyzing short text has emerged as an increasingly important task which is challenging to classical topic models, as topic sparsity exists in short text. Topic sparsity refers to the observation that individual document usually concentrates on several salient topics, which may be rare in entire corpus. Understanding this sparse topical structure of short text has been recognized as the key ingredient for mining user-generated Web content and social medium, which are featured in the form of extremely short posts and discussions. However, the existing sparsity-enhanced topic models all assume over-complicated generative process, which severely limits their scalability and makes them unable to automatically infer the number of topics from data.\nIn this paper, we propose a probabilistic Bayesian topic model, namely Sparse Dirichlet mixture Topic Model (SparseDTM), based on Indian Buffet Process (IBP) prior, and infer our model on the large text corpora through a novel inference procedure called stochastic variational-Gibbs inference. Unlike prior work, the proposed approach is able to achieve exact sparse topical structure of large short text collections, and automatically identify the number of topics with a good balance between completeness and homogeneity of topic coherence. Experiments on different genres of large text corpora demonstrate that our approach outperforms various existing sparse topic models. The improvement is significant on large-scale collections of short text.", "references": ["C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan. An introduction to mcmc for machine learning. Machine learning, 50(1--2):5--43, 2003.", "C. Archambeau, B. Lakshminarayanan, and G. Bouchard. Latent ibp compound dirichlet allocation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(2):321--333, 2015.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983765"}, {"title": "Measuring the Semantic Uncertainty of News Events for Evolution Potential Estimation", "authors": ["Xiangfeng Luo\n,", "Junyu Xuan\n,", "Jie Lu\n,", "Guangquan Zhang"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nThe evolution potential estimation of news events can support the decision making of both corporations and governments. For example, a corporation could manage its public relations crisis in a timely manner if a negative news event about this corporation is known with large evolution potential in advance. However, existing state-of-the-art methods are mainly based on time series historical data, which are not suitable for the news events with limited historical data and bursty properties. In this article, we propose a purely content-based method to estimate the evolution potential of the news events. The proposed method considers a news event at a given time point as a system composed of different keywords, and the uncertainty of this system is defined and measured as the Semantic Uncertainty of this news event. At the same time, an uncertainty space is constructed with two extreme states: the most uncertain state and the most certain state. We believe that the Semantic Uncertainty has correlation with the content evolution of the news events, so it can be used to estimate the evolution potential of the news events. In order to verify the proposed method, we present detailed experimental setups and results measuring the correlation of the Semantic Uncertainty with the Content Change of news events using collected news events data. The results show that the correlation does exist and is stronger than the correlation of value from the time-series-based method with the Content Change. Therefore, we can use the Semantic Uncertainty to estimate the evolution potential of news events.", "references": ["Lada A. Adamic and Bernardo A. Huberman. 2000. Power-law distribution of the world wide web. Science 287, 5461 (2000), 2115--2115.", "Rakesh Agrawal and Ramakrishnan Srikant. 1994. Fast algorithms for mining association rules in large databases. In Proceedings of the 20th International Conference on Very Large Data Bases (VLDB’94). Morgan Kaufmann Publishers, San Francisco, CA, 487--499.", "James Allan, Jaime G. Carbonell, George Doddington, Jonathan Yamron, and Yiming Yang. 1998. Topic detection and tracking pilot study final report. In Proceedings of DARPA Broadcast News Transcription and Understanding Workshop. 194--218."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2903719"}, {"title": "An Automated Approach for Cross-Browser Inconsistency (XBI) Detection", "authors": ["Chandra Prakash Patidar\n,", "Meena Sharma"], "publication": "COMPUTE '16: Proceedings of the 9th Annual ACM India Conference", "abstract": "ABSTRACT\nDue to the spread of the internet and the ever increasing number of web applications, the issue of compatibility across browsers has become very important. This compatibility issue is also referred as Cross Browser Inconsistency (XBI) wherein same website looks or behaves differently in different web browsers. In this paper our aim is to address this issue of compatibility and propose an automated approach of detecting XBIs. Cross Browser Inconsistencies can either be in the content, structure or behavior of the webpage. In order to get a grasp of the above mentioned types of inconsistencies, we surveyed some random websites and analyzed them in different browsers. We also studied the basic working of browser, in order to establish its connection with the occurrences of XBIs. Each browser has its own rendering mechanisms, which sometimes differs from standards. Hence, the execution of these websites is different in different browsers. Finally we have proposed an automated approach for XBI detection.", "references": ["S. Roy Choudhary, H. Versee, and A. Orso. \"X-PERT: A Web Application Testing Tool for Cross-Browser Inconsistency Detection\", In ACM ISSTA-2014, July 21-25, 2014, San Jose, CA, USA.", "Ali Mesbah, Mukul R. Prasad \"Automated Cross-Browser Compatibility Testing\" In proceeding of the 33rd International Conference on Software Engineering (ICSE). ACM, May 2011, pp. 561--570.", "S. Roy Choudhary, H. Versee, and A. Orso. \"WebDiff: Automated Identification of Cross-browser Issues in Web Applications\" In Proceeding of the 2010 IEEE International Conference on Software Maintenance (ICSM). IEEE, September 2010, pp. 1--10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2998476.2998496"}, {"title": "Search Strategy Formulation: A Framework For Learning", "authors": ["Andrew MacFarlane\n,", "Tony Russell-Rose"], "publication": "CERI '16: Proceedings of the 4th Spanish Conference on Information Retrieval", "abstract": "ABSTRACT\nHealthcare information professionals perform systematic literature reviews to gather the evidence needed to answer specific research questions and formulate policy. However, performing a systematic review is a resource-intensive and time consuming undertaking, often taking years to complete. Moreover, the output relies heavily on the quality of the initial search strategy in ensuring that the scope is sufficiently exhaustive and not biased by easily accessible studies. In this paper we introduce a structured methodology and a framework for learning which together aim to embody best practices from the community and provide support for many of the common issues in search strategy development.", "references": ["Elliott, J. H., Turner, T., Clavisi, O., Thomas, J., Higgins, J. P. T., Mavergames, C., and Gruen, R. L. 2014. Living systematic reviews: an emerging opportunity to narrow the evidence-practice gap. In: Plos medicine, Vol. 11, No. 2.", "Lefebvre, C., Manheimer, E., and Glanville, J. 2011. Searching for Studies. In Higgins, J. P. T., and Green S., Eds. Cochrane Handbook for Systematic Reviews of Interventions Version 5.1.0 {updated March 2011}. The Cochrane Collaboration. Available on: http://handbook.cochrane.org/.", "Hemingway, P. and Brereton, N. 2009. What is a systematic review? 2nd ed. Hayward Medical Communications."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934732.2934752"}, {"title": "Lifelong Machine Learning and Computer Reading the Web", "authors": ["Zhiyuan Chen\n,", "Estevam R. Hruschka\n,", "Bing Liu"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThis tutorial introduces Lifelong Machine Learning (LML) and Machine Reading. The core idea of LML is to learn continuously and accumulate the learned knowledge, and to use the knowledge to help future learning, which is perhaps the hallmark of human learning and human intelligence. By us- ing prior knowledge seamlessly and effortlessly, we humans can learn without a lot of training data, but current machine learning algorithms tend to need a huge amount of training data. LML aims to mimic this human capability. Machine Reading is a research area with the goal of building systems to read natural language text. Among different approaches employed in Machine Reading, this tutorial focuses on projects and approaches that use the idea of LML. Most current machine learning (ML) algorithms learn in isolation. They are designed to address a specific problem using a single dataset. That is, given a dataset, an ML algorithm is executed on the dataset to build a model. Although this type of isolated learning is very useful, it does not have the ability to accumulate past knowledge and to make use of the knowledge for future learning, which we believe are critical for the future of machine learning and data mining. LML aims to design and develop computational systems and algorithms with this capability, i.e., to learn as humans do in a lifelong manner.\nIn this tutorial, we introduce this important problem and the existing LML techniques and discuss opportunities and challenges of big data for lifelong machine learning. We also want to motivate researchers and practitioners to actively explore LML as the big data provides us a golden opportunity to learn a large volume of diverse knowledge, to connect different pieces of it, and to use it to raise data mining and machine learning to a new level.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2945381"}, {"title": "A Survey of Recent Prefetching Techniques for Processor Caches", "authors": ["Sparsh Mittal"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nAs the trends of process scaling make memory systems an even more crucial bottleneck, the importance of latency hiding techniques such as prefetching grows further. However, naively using prefetching can harm performance and energy efficiency and, hence, several factors and parameters need to be taken into account to fully realize its potential. In this article, we survey several recent techniques that aim to improve the implementation and effectiveness of prefetching. We characterize the techniques on several parameters to highlight their similarities and differences. The aim of this survey is to provide insights to researchers into working of prefetching techniques and spark interesting future work for improving the performance advantages of prefetching even further.", "references": ["Tor Aamodt, Pedro Marcuello, Paul Chow, Per Hammarlund, and Hong Wang. 2002. Prescient instruction prefetch. In Workshop on Multithreaded Execution, Architecture and Compilation. 2--10.", "Alaa R. Alameldeen and David A. Wood. 2007. Interactions between compression and prefetching in chip multiprocessors. In HPCA. 228--239.", "Jorge Albericio, Rubén Gran, Pablo Ibánez, Víctor Viñals, and Jose María Llabería. 2012. ABS: A low-cost adaptive controller for prefetching in a banked shared last-level cache. ACM Trans. Arch. Code Opt. 8, 4 (2012), 19."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2907071"}, {"title": "Session details: Main Track - Software Architecture and Web Services in IS (II)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255996"}, {"title": "Open Data for Local Search: Challenges and Perspectives", "authors": ["Eric Charton\n,", "Nizar Ghoula\n,", "Marie-Jean Meurs"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nLocal search engines are specialized information retrieval systems enabling users to discover amenities and services in their neighbourhood. Developing a local search system still raises scientific questions, as well as very specific technical issues. Those issues come for example from the lack of information about local events and actors, or the specific form taken by the indexable data. Available open data can be exploited to dramatically improve the design of local search engines and their content. The purpose of this workshop is to explore new fields of investigation both in terms of algorithmic approaches as well as originality of usable data. The workshop focuses on how open data can be used to enhance the capabilities of local search engines.", "references": ["M. Alobaidi, K. Mahmood, and S. Sabra. Semantic Enrichment for Local Search Engine using Linked Open Data. In OD4LS 2016 Workshop, WWW2016. ACM, 2016.", "C. An and D. Rockmore. Improving Local Search with Open Geographic Data. In OD4LS 2016 Workshop, WWW2016. ACM, 2016.", "C. Bizer, T. Heath, and T. Berners-Lee. Linked Data - The Story so far. Int. jour. on semantic web and information systems, 5(3):1--22, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890487"}, {"title": "User Models Development Based on Cross-Domain for Recommender Systems", "authors": ["Marivaldo Bispo Rodrigues\n,", "Gabriela O. Mota da Silva\n,", "Frederico Araújo Durão"], "publication": "Webmedia '16: Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nRecommender systems are used by many sites and services, and are important tools to help the user to find what is most relevant in the immense amount of information available. One way to build a Recommendation System is content-based filtering, which recommends items to the user based on a profile that contains information about the content, such as genre, keywords, etc. For this to happen effectively, the system must take into account the preferences and needs of users in order to generate useful recommendations. This work proposes the modeling of user profiles with integration of multiple domains and automatically. Then, through a transfer of knowledge of a domain to another, increase the performance of the recomendation. The results of the evaluation showed that information sharing between the domains increased the performance of the recommendation, as in the test with the metric prec@5, where obtained an improvement of more than 90\\%.", "references": ["F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause. Cross-system user modeling and personalization on the social web. User Modeling and User-Adapted Interaction, 23(2):169--209, 2012.", "S. Berkovsky, T. Kuflik, and F. Ricci. Cross-representation mediation of user models. User Modeling and User-Adapted Interaction, 19(1--2):35--63, Feb. 2009.", "Z. Gantner, L. Drumond, C. Freudenthaler, S. Rendle, and L. Schmidt-Thieme. Learning attribute-to-feature mappings for cold-start recommendations. In 2010 IEEE 10th International Conference on Data Mining (ICDM), pages 176--185, dec. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2976796.2988211"}, {"title": "Multiple Queries as Bandit Arms", "authors": ["Cheng Li\n,", "Paul Resnick\n,", "Qiaozhu Mei"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nExisting retrieval systems rely on a single active query to pull documents from the index. Relevance feedback may be used to iteratively refine the query, but only one query is active at a time. If the user's information need has multiple aspects, the query must represent the union of these aspects. We consider a new paradigm of retrieval where multiple queries are kept ``active'' simultaneously. In the presence of rate limits, the active queries take turns accessing the index to retrieve another ``page'' of results. Turns are assigned by a multi-armed bandit based on user feedback. This allows the system to explore which queries return more relevant results and to exploit the best ones. In empirical tests, query pools outperform solo, combined queries. Significant improvement is observed both when the subtopic queries are known in advance and when the queries are generated in a user-interactive process.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proc. of WSDM, 2009.", "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 2002.", "D. Bouneffouf, A. Bouzeghoub, and A. L. Gançarski. Contextual bandits for context-based information retrieval. In Neural Information Processing. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983816"}, {"title": "Analysis of Spatial, Temporal, and Content Characteristics of Videos in the YFCC100M Dataset", "authors": ["Jun-Ho Choi\n,", "Jong-Seok Lee"], "publication": "MMCommons '16: Proceedings of the 2016 ACM Workshop on Multimedia COMMONS", "abstract": "ABSTRACT\nThe Yahoo Flickr Creative Commons 100 Million dataset (YFCC100M) is one of the largest public databases containing images and videos and their annotations for research on multimedia analysis. In this paper, we present our study on analysis of characteristics of the 0.8 million videos in the dataset in spatial, temporal, and content perspectives. For this, all the video frames and metadata of the videos are examined. In addition, user-wise analysis of the characteristics is conducted. We make the obtained results publicly available in the form of a metadata dataset for the research community.", "references": ["J. Bernd, D. Borth, C. Carrano, J. Choi, B. Elizalde, G. Friedland, L. Gottlieb, K. Ni, R. Pearce, D. Poland, et al. Kickstarting the commons: The YFCC100M and the YLI corpora. In Proceedings of the ACM Workshop on Community-Organized Multimodal Mining: Opportunities for Novel Solutions (MMCommons), pages 1--6, 2015.", "J. Bernd, D. Borth, B. Elizalde, G. Friedland, H. Gallagher, L. Gottlieb, A. Janin, S. Karabashlieva, J. Takahashi, and J. Won. The YLI-MED corpus: Characteristics, procedures, and plans. arXiv:1503.04250, 2015.", "M. Cha, H. Kwak, P. Rodriguez, Y.-Y. Ahn, and S. Moon. Analyzing the video popularity characteristics of large-scale user generated content systems. IEEE/ACM Transactions on Networking (TON), 17(5):1357--1370, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983554.2983559"}, {"title": "VizioMetrix: A Platform for Analyzing the Visual Information in Big Scholarly Data", "authors": ["Po-shen Lee\n,", "Jevin D. West\n,", "Bill Howe"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe present VizioMetrix, a platform that extracts visual information from the scientific literature and makes it available for use in new information retrieval applications and for studies that look at patterns of visual information across millions of papers. New ideas are conveyed visually in the scientific literature through figures --- diagrams, photos, visualizations, tables --- but these visual elements remain ensconced in the surrounding paper and difficult to use directly to facilitate information discovery tasks or longitudinal analytics. Very few applications in information retrieval, academic search, or bibliometrics make direct use of the figures, and none attempt to recognize and exploit the type of figure, which can be used to augment interactions with a large corpus of scholarly literature.\nThe VizioMetrix platform processes a corpus of documents, classifies the figures, organizes the results into a cloud-hosted databases, and drives three distinct applications to support bibliometric analysis and information retrieval. The first application supports information retrieval tasks by allowing rapid browsing of classified figures. The second application supports longitudinal analysis of visual patterns in the literature and facilitates data mining of these figures. The third application supports crowdsourced tagging of figures to improve classification, augment search, and facilitate new kinds of analyses. Our initial corpus is the entirety of PubMed Central (PMC), and will be released to the public alongside this paper; we welcome other researchers to make use of these resources.", "references": ["A. Ahmed, E. P. Xing, W. W. Cohen, and R. F. Murphy. Structured correspondence topic models for mining captioned figures in biological literature. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 39--48. ACM, 2009.", "S. Bhatia, P. Mitra, and C. L. Giles. Finding algorithms in scientific articles. In Proceedings of the 19th international conference on World wide web, pages 1061--1062. ACM, 2010.", "Z. Chen, M. Cafarella, and E. Adar. Diagramflyer: A search engine for data-driven diagrams. In Proceedings of the 24th International Conference on World Wide Web Companion, WWW '15 Companion, pages 183--186, Republic and Canton of Geneva, Switzerland, 2015. International World Wide Web Conferences Steering Committee."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890523"}, {"title": "Capturing and Annotating Processes using a Collaborative Platform", "authors": ["Tobias Weller\n,", "Maria Maleshkova"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nExisting standards in capturing processes concentrate on client tools. Furthermore, semantic information are often available that cannot be captured in a structured way with the proposed standard formats. In addition, processes are usually used and maintained by multiple persons. Therefore, a collaborative platform to discuss and share information about processes is valuable.\nIn order to address the challenge of maintaining and sharing knowledge about processes, we provide a tool to capture and annotate processes using Semantic MediaWiki as a collaborative platform. We demonstrate the practical applicability of our tool by presenting a demo available in the World Wide Web.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889303"}, {"title": "Tracking Sentiment by Time Series Analysis", "authors": ["Anastasia Giachanou\n,", "Fabio Crestani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn recent years social media have emerged as popular platforms for people to share their thoughts and opinions on all kind of topics. Tracking opinion over time is a powerful tool that can be used for sentiment prediction or to detect the possible reasons of a sentiment change. Understanding topic and sentiment evolution allows enterprises or government to capture negative sentiment and act promptly. In this study, we explore conventional time series analysis methods and their applicability on topic and sentiment trend analysis. We use data collected from Twitter that span over nine months. Finally, we study the usability of outliers detection and different measures such as sentiment velocity and acceleration on the task of sentiment tracking.", "references": ["X. An, R. A. Ganguly, Y. Fang, B. S. Scyphers, M. A. Hunter, and G. J. Dy. Tracking Climate Change Opinions from Twitter Data. In KDD '14, 2014.", "J. Bollen and A. Pepe. Modeling Public Mood and Emotion: Twitter Sentiment and Socio-Economic Phenomena. In ICWSM '11, pages 450--453, 2011.", "A. Giachanou and F. Crestani. Like it or not: A survey of twitter sentiment analysis methods. ACM Computing Surveys,noop3001in press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914702"}, {"title": "Text Data Understanding", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915035"}, {"title": "DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks", "authors": ["Shuangfei Zhai\n,", "Keng-hao Chang\n,", "Ruofei Zhang\n,", "Zhongfei Mark Zhang"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nIn this paper, we investigate the use of recurrent neural networks (RNNs) in the context of search-based online advertising. We use RNNs to map both queries and ads to real valued vectors, with which the relevance of a given (query, ad) pair can be easily computed. On top of the RNN, we propose a novel attention network, which learns to assign attention scores to different word locations according to their intent importance (hence the name DeepIntent). The vector output of a sequence is thus computed by a weighted sum of the hidden states of the RNN at each word according their attention scores. We perform end-to-end training of both the RNN and attention network under the guidance of user click logs, which are sampled from a commercial search engine. We show that in most cases the attention network improves the quality of learned vector representations, evaluated by AUC on a manually labeled dataset. Moreover, we highlight the effectiveness of the learned attention scores from two aspects: query rewriting and a modified BM25 metric. We show that using the learned attention scores, one is able to produce sub-queries that are of better qualities than those of the state-of-the-art methods. Also, by modifying the term frequency with the attention scores in a standard BM25 formula, one is able to improve its performance evaluated by AUC.", "references": ["D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.", "J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley, and Y. Bengio. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), June 2010.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939759"}, {"title": "Efficient processing of videos in a multi-auditory environment using device lending of GPUs", "authors": ["Konstantin Pogorelov\n,", "Michael Riegler\n,", "Jonas Markussen\n,", "Håkon Kvale Stensland\n,", "Pål Halvorsen\n,", "Carsten Griwodz\n,", "Sigrun Losada Eskeland\n,"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nIn this paper, we present a demo that utilizes Device Lending via PCI Express (PCIe) in the context of a multi-auditory environment. Device Lending is a transparent, low-latency cross-machine PCIe device sharing mechanism without any the need for implementing application-specific distribution mechanisms. As workload, we use a computer-aided diagnosis system that is used to automatically find polyps and mark them for medical doctors during a colonoscopy. We choose this scenario because one of the main requirements is to perform the analysis in real-time. The demonstration consists of a setup of two computers that demonstrates how Device Lending can be used to improve performance, as well as its effect of providing the performance needed for real-time feedback. We also present a performance evaluation that shows its real-time capabilities of it.", "references": ["Dolphin Interconnect Solution PXH810 NTB Adapter, 2015.", "J. Duato, A. Pena, F. Silla, R. Mayo, and E. Quintana-Ortí. rCUDA: Reducing the number of GPU-based accelerators in high performance clusters. In Proc. of HPCS, pages 224--231, 2010.", "L. B. Kristiansen, J. Markussen, H. K. Stensland, M. Riegler, H. Kohmann, F. Seifert, R. Nordstrøm, C. Griwodz, and P. Halvorsen. Device lending in PCI Express Networks. In Proc. of NOSSDAV, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910636"}, {"title": "Measuring Metrics", "authors": ["Pavel Dmitriev\n,", "Xian Wu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nYou get what you measure, and you can't manage what you don't measure. Metrics are a powerful tool used in organizations to set goals, decide which new products and features should be released to customers, which new tests and experiments should be conducted, and how resources should be allocated. To a large extent, metrics drive the direction of an organization, and getting metrics 'right' is one of the most important and difficult problems an organization needs to solve. However, creating good metrics that capture long-term company goals is difficult. They try to capture abstract concepts such as success, delight, loyalty, engagement, life-time value, etc. How can one determine that a metric is a good one? Or, that one metric is better than another? In other words, how do we measure the quality of metrics? Can the evaluation process be automated so that anyone with an idea of a new metric can quickly evaluate it? In this paper we describe the metric evaluation system deployed at Bing, where we have been working on designing and improving metrics for over five years. We believe that by applying a data driven approach to metric evaluation we have been able to substantially improve our metrics and, as a result, ship better features and improve search experience for Bing's users.", "references": ["Angrist, J. D. and Pischke, J-S. Mastering Metrics: The Path from Cause to Effect. 2014.", "Blackburn, C. and Valerdi, R. Navigating the Metrics Landscape: An Introductory Literature Guide to Metric Selection, Implementation, & Decision Making. Conference on Systems Engineering Research, 2009.", "Davis, J. Measuring Marketing: 103 Key Metrics Every Marketer Needs. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983356"}, {"title": "ESPRESSO: Explaining Relationships between Entity Sets", "authors": ["Stephan Seufert\n,", "Klaus Berberich\n,", "Srikanta J. Bedathur\n,", "Sarath Kumar Kondreddi\n,", "Patrick Ernst\n,", "Gerhard Weikum"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAnalyzing and explaining relationships between entities in a knowledge graph is a fundamental problem with many applications. Prior work has been limited to extracting the most informative subgraph connecting two entities of interest. This paper extends and generalizes the state of the art by considering the relationships between two sets of entities given at query time. Our method, coined ESPRESSO, explains the connection between these sets in terms of a small number of relatedness cores: dense sub-graphs that have strong relations with both query sets. The intuition for this model is that the cores correspond to key events in which entities from both sets play a major role. For example, to explain the relationships between US politicians and European politicians, our method identifies events like the PRISM scandal and the Syrian Civil War as relatedness cores. Computing cores of bounded size is NP-hard. This paper presents efficient approximation algorithms. Our experiments with real-life knowledge graphs demonstrate the practical viability of our approach and, through user studies, the superior output quality compared to state-of-the-art baselines.", "references": ["S. Agrawal, S. Chaudhuri, and G. Das. DBXplorer: A System for Keyword-Based Search over Relational Databases. In ICDE'02, pages 5--16, 2002.", "L. Akoglu, D. H. Chau, C. Faloutsos, N. Tatti, H. Tong, and J. Vreeken. Mining Connection Pathways for Marked Nodes in Large Graphs. In SDM'13, pages 37--45. SIAM, 2013.", "R. Andersen and K. Chellapilla. Finding Dense Subgraphs with Size Bounds. In Algorithms and Models for the Web-Graph, volume 5427 of LNCS, pages 25--37. Springer, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983778"}, {"title": "Emotion spotting: discovering regions of evidence in audio-visual emotion expressions", "authors": ["Yelin Kim\n,", "Emily Mower Provost"], "publication": "ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nResearch has demonstrated that humans require different amounts of information, over time, to accurately perceive emotion expressions. This varies as a function of emotion classes. For example, recognition of happiness requires a longer stimulus than recognition of anger. However, previous automatic emotion recognition systems have often overlooked these differences. In this work, we propose a data-driven framework to explore patterns (timings and durations) of emotion evidence, specific to individual emotion classes. Further, we demonstrate that these patterns vary as a function of which modality (lower face, upper face, or speech) is examined, and consistent patterns emerge across different folds of experiments. We also show similar patterns across emotional corpora (IEMOCAP and MSP-IMPROV). In addition, we show that our proposed method, which uses only a portion of the data (59% for the IEMOCAP), achieves comparable accuracy to a system that uses all of the data within each utterance. Our method has a higher accuracy when compared to a baseline method that randomly chooses a portion of the data. We show that the performance gain of the method is mostly from prototypical emotion expressions (defined as expressions with rater consensus). The innovation in this study comes from its understanding of how multimodal cues reveal emotion over time.", "references": ["M. R. Amer, B. Siddiquie, S. Khan, A. Divakaran, and H. Sawhney. Multimodal fusion using dynamic hybrid models. In IEEE Winter Conference on Applications of Computer Vision, pages 556–563. IEEE, 2014.", "P. Boersma and D. Weenink. Praat: doing phonetics by computer (version 6.0.17){computer program}. retrieved 21 april 2016 from http://www.praat.org/.", "C. Busso, M. Bulut, C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. Chang, S. Lee, and S. Narayanan. Iemocap: Interactive emotional dyadic motion capture database. Language Resources and Evaluation, 42(4):335–359, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993148.2993151"}, {"title": "GCaR: Garbage Collection aware Cache Management with Improved Performance for Flash-based SSDs", "authors": ["Suzhen Wu\n,", "Yanping Lin\n,", "Bo Mao\n,", "Hong Jiang"], "publication": "ICS '16: Proceedings of the 2016 International Conference on Supercomputing", "abstract": "ABSTRACT\nGarbage Collection (GC) is an important performance concern for flash-based SSDs, because it tends to disrupt the normal operations of an SSD. This problem continues to plague flash-based storage systems, particularly in the high performance computing and enterprise environment. An important root cause for this problem, as revealed by previous studies, is the serious contention for the flash resources and the severe mutually adversary interference between the user I/O requests and GC-induced I/O requests. The on-board buffer cache within SSDs serves to play an essential role in smoothing the gap between the upper-level applications and the lower-level flash chips and alleviating this problem to some extend. Nevertheless, the existing cache replacement algorithms are well optimized to reduce the miss rate of the buffer cache by reducing the I/O traffic to the flash chips as much as possible, but without considering the GC operations within the flash chips. Consequently, they fail to address the root cause of the problem and thus are far from being sufficient and effective in reducing the expensive I/O traffic to the flash chips that are in the GC state.\nTo address this important performance issue in flash-based storage systems, particularly in the HPC and enterprise environment, we propose a Garbage Collection aware Replacement policy, called GCaR, to improve the performance of flash-based SSDs. The basic idea is to give higher priority to caching the data blocks belonging to the flash chips that are in the GC state. This substantially lessens the contentions between the user I/O operations and the GC-induced I/O operations. To verify the effectiveness of GCaR, we have integrated it into the SSD extended Disksim simulator. The simulation results show that GCaR can significantly improve the storage performance by reducing the average response time by up to 40.7%.", "references": ["N. Agrawal, V. Prabhakaran, T. Wobber, J. Davis, M. Manasse, and R. Panigrahy. Design Tradeoffs for SSD Performance. In Proceedings of the 2008 USENIX Annual Technical Conference (USENIX'08), Boston, MA, Jun. 2008.", "Block I/O Traces in SNIA. http://iotta.snia.org/tracetypes/3.", "J. Bucy, J. S. Schindler, S. W. Schlosser, and G. R. Ganger. The DiskSim Simulation Environment Version 4.0 Reference Manual. May 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2925426.2926263"}, {"title": "Cloud Calipers", "authors": ["George Neville-Neil"], "publication": "Queue", "abstract": "Abstract\nNaming the next generation and remembering that the cloud is just other people's computers", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.2993454"}, {"title": "Identifying the Hub Proteins of Co-Regulation Networks Based on Multi-Agent Based Method", "authors": ["Quan Gu\n,", "Yongsheng Ding\n,", "Tao Han"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThe information of hub proteins can provide very useful insights for selecting or prioritizing targets during drug development. In this paper, we propose a multi-agent system based network hub-protein-simulatorto identifying the transcription factors from co-regulation networks by the multi-agent based method combined with the graphical spectrum analysis and immune-genetic algorithm. Meanwhile, along with the identified hub transcription factors, their biological processes, and pathway analysis were also explored. It is anticipated that the hubproteinsimulator could become a very useful tool for system biology and drug development, particularly in deciphering unknown protein functions, determining protein complexes, and in identifying the key targets from a complicated disease system.", "references": ["Chou, K.-C. and Shen, H.-B. 2010. A new method for predicting the subcellular localization of eukaryotic proteins with both single and multiple sites: Euk-mPLoc 2.0. PloS One. 5, 4 (2010), e9931.", "Gu, Q. et al. 2015. An ensemble classifier based prediction of G-protein-coupled receptor classes in low homology. Neurocomputing. 154, (2015), 110--118.", "Gu, Q. et al. 2011. Genome-wide patterns of promoter sharing and co-expression in bovine skeletal muscle. BMC genomics. 12, 1 (2011), 23."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015197"}, {"title": "Towards Mobile Query Auto-Completion: An Efficient Mobile Application-Aware Approach", "authors": ["Aston Zhang\n,", "Amit Goyal\n,", "Ricardo Baeza-Yates\n,", "Yi Chang\n,", "Jiawei Han\n,", "Carl A. Gunter\n,", "Hongbo Deng"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe study the new mobile query auto-completion (QAC) problem to exploit mobile devices' exclusive signals, such as those related to mobile applications (apps). We propose AppAware, a novel QAC model using installed app and recently opened app signals to suggest queries for matching input prefixes on mobile devices. To overcome the challenge of noisy and voluminous signals, AppAware optimizes composite objectives with a lighter processing cost at a linear rate of convergence. We conduct experiments on a large commercial data set of mobile queries and apps. Installed app and recently opened app signals consistently and significantly boost the accuracy of various baseline QAC models on mobile devices.", "references": ["R. Baeza-Yates, G. Dupret, and J. Velasco. A study of mobile search queries in japan. In Proceedings of the International World Wide Web Conference (WWW), 2007.", "R. Baeza-Yates, D. Jiang, F. Silvestri, and B. Harrison. Predicting the next app that you are going to use. In Proceedings of the ACM International Conference on Web Search and Data Mining (WSDM), 2015.", "Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proceedings of the International Conference on World Wide Web (WWW), 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882977"}, {"title": "Linear Distance Preserving Pseudo-Supervised and Unsupervised Hashing", "authors": ["Min Wang\n,", "Wengang Zhou\n,", "Qi Tian\n,", "Zhengjun Zha\n,", "Houqiang Li"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the advantage in compact representation and efficient comparison, binary hashing has been extensively investigated for approximate nearest neighbor search. In this paper, we propose a novel and general hashing framework, which simultaneously considers a new linear pair-wise distance preserving objective and point-wise constraint. The direct distance preserving objective aims to keep the linear relationships between the Euclidean distance and the Hamming distance of data points. Based on different point-wise constraints, we propose two methods to instantiate this framework. The first one is a pseudo-supervised hashing method, which uses existing unsupervised hashing methods to generate binary codes as pseudo-supervised information. The second one is an unsupervised hashing method, in which quantization loss is considered. We validate our framework on two large-scale datasets. The experiments demonstrate that our pseudo-supervised method achieves consistent improvement for the state-of-the-art unsupervised hashing methods, while our unsupervised method outperforms the state-of-the-art methods.", "references": ["J. L. Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509--517, 1975.", "L. Cao, Z. Li, Y. Mu, and S.-F. Chang. Submodular video hashing: a unified framework towards video pooling and indexing. In ACM Multimedia, pages 299--308, 2012.", "M. A. Carreira-Perpinán and R. Raziperchikolaei. Hashing with binary autoencoders. In CVPR, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964334"}, {"title": "Characterizing smartphone power management in the wild", "authors": ["Mohammad A. Hoque\n,", "Sasu Tarkoma"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nFor better reliability and prolonged battery life, it is important that users and vendors understand the quality of charging and the performance of smartphone batteries. Considering the diverse set of devices and user behavior it is a challenge. In this work, we analyze a large collection of battery analytics dataset collected from 30K devices of 1.5K unique smartphone models. We analyze their battery properties and state of charge while charging, and reveal the characteristics of different components of their power management systems: charging mechanisms, state of charge estimation techniques, and their battery properties. We explore diverse charging behavior of devices and their users.", "references": ["Nilanjan Banerjee, Ahmad Rahmati, Mark D. Corner, Sami Rollins, and Lin Zhong. 2007. Users and Batteries: Interactions and Adaptive Energy Management in Mobile Systems. In Proceedings of the 9th International Conference on Ubiquitous Computing (UbiComp '07). Berlin, Heidelberg, 217--234.", "Soo Seok Choi and Hong S Lim. 2002. Factors that affect cycle-life and possible degradation mechanisms of a Li-ion cell based on LiCoO2. Journal of Power Sources 111, 1 (2002), 130 -- 136.", "Scott Dearborn. 2005. Charging Lithium-Ion batteries for Maximum Run Times. Technical Report. http://powerelectronics.com/site-files/powerelectronics.com/files/archive/powerelectronics.com/mag/504PET23.pdf."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2968295"}, {"title": "An Empirical Study on Recommendation with Multiple Types of Feedback", "authors": ["Liang Tang\n,", "Bo Long\n,", "Bee-Chung Chen\n,", "Deepak Agarwal"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nUser feedback like clicks and ratings on recommended items provides important information for recommender systems to predict users' interests in unseen items. Most systems rely on models trained using a single type of feedback, e.g., ratings for movie recommendation and clicks for online news recommendation. However, in addition to the primary feedback, many systems also allow users to provide other types of feedback, e.g., liking or sharing an article, or hiding all articles from a source. These additional feedback potentially provides extra information for the recommendation models. To optimize user experience and business objectives, it is important for a recommender system to use both the primary feedback and additional feedback. This paper presents an empirical study on various training methods for incorporating multiple user feedback types based on LinkedIn recommendation products. We study three important problems that we face at LinkedIn: (1) Whether to send an email based on clicks and complaints, (2) how to rank updates in LinkedIn feeds based on clicks and hides and (3) how jointly optimize for viral actions and clicks in LinkedIn feeds. Extensive offline experiments on historical data show the effectiveness of these methods in different situations. Online A/B testing results further demonstrate the impact of these methods on LinkedIn production systems.", "references": ["G. Adomavicius and Y. Kwon. New Recommendation Techniques for Multicriteria Rating Systems. IEEE Expert / IEEE Intelligent Systems, 22:48--55, 2007.", "R. Ando and T. Zhang. A high-performance semi-supervised learning method for text chunking. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 1--9. Association for Computational Linguistics Morristown, NJ, USA, 2005.", "A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. In Advances in Neural Information Processing Systems: Proceedings of the 2006 Conference, page 41. MIT Press, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939690"}, {"title": "Didactical Ideas in Computer Science", "authors": ["Beatriz Rabin\n,", "Sylvia da Rosa"], "publication": "ITiCSE '16: Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education", "abstract": "ABSTRACT\nIn this poster, we present new didactical ideas for teaching recursion in introductory programming classes supported by Guy Brousseau's Theory of Situations [1], applying Jean Piaget's epistemological theory[2]. We analyse students' responses in order to generate new teaching guidelines for this subject, not only in teaching this concept but also to enhance future assessments.", "references": ["La teoría de las Situaciones Didácticas: un marco para pensar y actuar la enseñanza de la Matemática. Patricia Sadovsky. https://www.fing.edu.uy/grupos/nifcc/material/2015/teoria_situaciones.pdf", "La Prise de Conscience, Jean Piaget, Presses Universitaires de France."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899415.2925475"}, {"title": "Topic Modeling based on Louvain method in Online Social Networks", "authors": ["Guilherme Sakaji Kido\n,", "Rodrigo Augusto Igawa\n,", "Sylvio Barbon Junior"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nOnline Social Networks (OSNs) are the most used media nowadays, such as Twitter. The OSNs provide valuable information to marketing and competitiveness based on users posts and opinions stored inside huge volume of data from several themes, topics and subjects. In order to mining the topics discussed on an OSN we present a novel application of Louvain method for Topic Modeling based on communities detection in graphs by modularity. The proposed approach succeeded in finding topics in five different datasets composed of textual content from Twitter and Youtube. Another important contribution achieved was about the presence of texts posted by spammers. In this case, a particular behavior observed by graph architecture (density and degree) allows the classification of a topic as natural or artificial, this last created by the spammers on OSNs.", "references": ["A. Akilan. Text mining: Challenges and future directions. In Electronics and Communication Systems (ICECS), 2015 2nd International Conference on, pages 1679-1684. IEEE, 2015.", "V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008+, July 2008.", "Y. Chen, H. Amiri, Z. Li, and T.-S. Chua. Emerging topic detection for organizations from microblogs. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '13, pages 43-52, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022015"}, {"title": "Overview of Text Data Access", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915037"}, {"title": "Evaluating the evaluations of code recommender systems: a reality check", "authors": ["Sebastian Proksch\n,", "Sven Amann\n,", "Sarah Nadi\n,", "Mira Mezini"], "publication": "ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nWhile researchers develop many new exciting code recommender systems, such as method-call completion, code-snippet completion, or code search, an accurate evaluation of such systems is always a challenge. We analyzed the current literature and found that most of the current evaluations rely on artificial queries extracted from released code, which begs the question: Do such evaluations reflect real-life usages? To answer this question, we capture 6,189 fine-grained development histories from real IDE interactions. We use them as a ground truth and extract 7,157 real queries for a specific method-call recommender system. We compare the results of such real queries with different artificial evaluation strategies and check several assumptions that are repeatedly used in research, but never empirically evaluated. We find that an evolving context that is often observed in practice has a major effect on the prediction quality of recommender systems, but is not commonly reflected in artificial evaluations.", "references": ["S. Amann, S. Proksch, and S. Nadi. FeedBaG: An Interaction Tracker for Visual Studio. In Proceedings of the 24th International Conference on Program Comprehension Tool Track, 2016.", "M. Bruch, M. Monperrus, and M. Mezini. Learning from Examples to Improve Code Completion Systems. In Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on the foundations of software engineering, 2009.", "R. DeLine, M. Czerwinski, and G. Robertson. Easing Program Comprehension by Sharing Navigation Data. In 2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC’05), 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970276.2970330"}, {"title": "Factors Involved in Structuring of a Business Process Office in a Public Organization", "authors": ["Joyce A. Oliveira\n,", "Carina F. Alves\n,", "George Valenca"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nBusiness Process Office (BPMO) has been structured in public organizations with the purpose of formalize BPM actions and increase the effectiveness of services delivery to citizens. Peculiarities inherent this context like little flexibility to change and stiffness of the organizational structure difficult the consolidation of BPMO. This article discusses the factors that influence positively and negatively the structuration of this unity. The research was conducted through an action research. The data were treated using techniques of grounded theory. The knowledge of factors and their reported interrelations can help to increase the chances of successful implementation of a Business Process Office", "references": ["Carron, A.; Widmeyer, W. Brawley, L.(1985): The development of instrument to assess cohesion in sport teams: the group environment questionnaire. Journal of sport psychology, v.7, p. 244-267.", "Chen, G; Kanfer, R. (2006): Toward A Systems Theory Of Motivated Behavior In Work Teams. Research in Organizational Behavior: Elsevier. Vol. 27, 223-267.", "Corbin, J. e Strauss, A. (2007): Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory. 3rd ed., Thousand Oaks: Sage."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022056"}, {"title": "SoLSCSum: A Linked Sentence-Comment Dataset for Social Context Summarization", "authors": ["Minh-Tien Nguyen\n,", "Chien-Xuan Tran\n,", "Duc-Vu Tran\n,", "Minh-Le Nguyen"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper presents a dataset named SoLSCSum for social context summarization. The dataset includes 157 open-domain articles along with their comments collected from Yahoo News. The articles and their comments were manually annotated by two annotators to extract standard summaries. The inter-annotator agreement is 74.5% and Cohen's Kappa is 0.5845. To illustrate the potential use of our dataset, a learning to rank model was trained by using a set of local and cross features. Experimental results demonstrate that: (1) our model trained by Ranking SVM obtains significant improvements from 5.5% to 14.8% of ROUGE-1 over state-of-the-art baselines in document summarization and (2) our dataset can be used to train summary methods such as SVM.", "references": ["Z. Cao, C. Chen, W. Li, S. Li, F. Wei, and M. Zhou. Tgsum: Build tweet guided multi-document summarization dataset. In arXiv preprint arXiv:1511.08417, 2015.", "C. Cortes and V. Vapnik. Support-vector networks. Machine Learning 20(3): 273--297, 1995.", "G. Erkan and D. R. Radev. Lexrank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research: 457--479, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983376"}, {"title": "Multi-Dueling Bandits and Their Application to Online Ranker Evaluation", "authors": ["Brian Brost\n,", "Yevgeny Seldin\n,", "Ingemar J. Cox\n,", "Christina Lioma"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nOnline ranker evaluation focuses on the challenge of efficiently determining, from implicit user feedback, which ranker out of a finite set of rankers is the best. It can be modeled by dueling bandits, a mathematical model for online learning under limited feedback from pairwise comparisons. Comparisons of pairs of rankers is performed by interleaving their result sets and examining which documents users click on. The dueling bandits model addresses the key issue of which pair of rankers to compare at each iteration.\nMethods for simultaneously comparing more than two rankers have recently been developed. However, the question of which rankers to compare at each iteration was left open. We address this question by proposing a generalization of the dueling bandits model that uses simultaneous comparisons of an unrestricted number of rankers.\nWe evaluate our algorithm on standard large-scale online ranker evaluation datasets. Our experimentals show that the algorithm yields orders of magnitude gains in performance compared to state-of-the-art dueling bandit algorithms.", "references": ["P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 47(2--3):235--256, 2002.", "B. Brost, I. J. Cox, Y. Seldin, and C. Lioma. An improved multileaving algorithm for online ranker evaluation. SIGIR, 2016.", "B. Brost, Y. Seldin, I. J. Cox, and C. Lioma. Multi-dueling bandits and their application to online ranker evaluation - extended version. arXiv preprint arXiv:1608.06253, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983659"}, {"title": "Fast non-blind image deblurring in frequency domain based on matrix decomposition", "authors": ["Weili Li\n,", "Yu Liu\n,", "Xiaoqing Yin\n,", "Maojun Zhang"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThis study proposes a data separation algorithm with computationally efficient strategies for non-blind deconvolution in the frequency domain. First, the blurred image is separated into a couple of basis and corresponding coefficients. Then the traditional non-blind deconvolution method in the frequency domain is employed in the pre-processing step and the deblurred bases are saved. For the new blurred image with the same blur kernel, the iterative optimization is converted into linear addition and multiplication operations. Results of qualitative and quantitative evaluations demonstrate the efficiency and effectiveness of the proposed approach. This method is meaningful for the design of a real-time image deconvolution method. Thus far, this method is only suitable in the frequency domain.", "references": ["Wiener, N. Extrapolation, Interpolation and Smoothing of Stationary Time Series, with Engineering Applications. Technology Press of the Massachusetts Institute of Technology, pp. 1043--54, 1950.", "Richardson, W. Bayesian-Based Iterative Method of Image Restoratio. Journal of the Optical Society of America, 62(1), pp. 55--59, 1972.", "Lucy, L. B. An Iterative Technique for the Rectification of Observed Distributions. Astronomical Journal, 79(79), pp. 745--754, 1974."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015169"}, {"title": "Modeling Individual Users' Responsiveness to Maximize Recommendation Impact", "authors": ["Masahiro Sato\n,", "Hidetaka Izumo\n,", "Takashi Sonoda"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nRecommender systems provide personalized information based on a user's preferences. Differences in preferences among users are estimated from past records such as click logs or purchase logs. Recommender systems typically assume that users will respond to recommendations, provided that their favorite items are correctly selected. However, the responsiveness to recommendations depends on the type of users; while some users might be easily persuaded to take action, others might be more hesitant. In this paper, we propose a purchase prediction model that incorporates the differences in the responsiveness. We derived the individual users' responsiveness from a combination of purchase logs and recommendation logs. Improvement in the accuracy of purchase prediction was verified using a grocery shopping dataset. Another relatively unexplored yet important objective of recommender algorithms is to maximize recommendation impact, which is defined as the increase in purchase probability through recommendations. The impact of recommendations by our model exceeded that of a conventional model that ignores individual users' responsiveness. These results demonstrate the importance of modeling the responsiveness of individual users. In cases where recommendation logs are insufficient, the responsiveness needs to be estimated from other sources. Consequently, we investigated the correlation of the responsiveness with user attributes and item attributes. The estimates of the responsiveness from the correlated attributes outperformed the mean estimates. Furthermore, the recommendation impact of the model estimated from the correlated attributes was almost comparable to that of the model estimated from recommendation logs. These findings can help overcome the cold-start problem of inadequate recommendation logs. Our study presents a new direction in the field of personalization based on the responsiveness to recommendations.", "references": ["Adomavicius, G. and Tuzhilin, A. 2005. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. IEEE T. Knowl. Data En. 17, 6 (June 2005), 734--749. DOI= http://dx.doi.org/10.1109/TKDE.2005.99.", "Azaria, A., Hassidim, A., Kraus, S., Eshkol, A., Weintraub, O., and Netanely, I. 2013. Movie recommender system for profit maximization. In Proceedings of the 7th ACM conference on Recommender systems (Hong Kong, China, October 12 - 16, 2013). RecSys '13. ACM, New York, NY, USA, 121--128. DOI= http://dx.doi.org/10.1145/2507157.2507162.", "Bodapati, A. V. 2008. Recommendation systems with purchase data. J. Marketing Res. 45(1) (February 2008), 77- 93. DOI= http://dx.doi.org/10.1509/jmkr.45.1.77."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930259"}, {"title": "Colocation as a Hybrid ICT Sourcing Strategy to Improve Operational Agility", "authors": ["Roman Beck\n,", "Immanuel Pahlke\n,", "Jens Vykoukal"], "publication": "ACM SIGMIS Database: the DATABASE for Advances in Information Systems", "abstract": "Abstract\nFast access to communication networks and the availability of high-performance information and com-munication technology (ICT) infrastructures is indis-pensable for accelerating business transactions. Yet with increased environmental volatility, companies need to become more agile in identifying and responding to market- and technology-based challenges. Accordingly, a responsive and high-performance ICT infrastructure remains a top priority for firms. Thus, new ICT sourcing strategies may lead to significant competitive advantages, especially in dynamic business environments. This article analyzes a hybrid ICT sourcing strategy called colocation that allows firms to operate their own ICT resources in facilities of special-ized data center providers. Grounded in the theory of dynamic capabilities, we theorize and empirically ex-amine how colocation and top management support enable firms to improve their operational agility in the presence of environmental turbulence.", "references": ["Adler, P., Goldoftas, S. B., and Levine, D. I. (1999). \"Flexibility versus Ef?ciency? A Case Study of Model Changeovers in the Toyota Production System.\" Organization Science, Vol. 10 No. 1: pp. 43--68.", "Agarwal, R. and Selen, W. (2009). \"Dynamic Capability Building in Service Value Networks for Achieving Service Innovation.\" Decision Sciences, Vol. 40, No. 3: pp. 431--475.", "Allen, B. R. and Boynton, A. C. (1991). \"Information Architecture: In Search of Efficient Flexibility.\" MIS Quarterly, Vol. 15, No. 4: pp. 435--445."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2963175.2963177"}, {"title": "Analyzing Aggregated Semantics-enabled User Modeling on Google+ and Twitter for Personalized Link Recommendations", "authors": ["Guangyuan Piao\n,", "John G. Breslin"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nIn this paper, we study if reusing Google+ profiles can provide reliable recommendations on Twitter to resolve the cold start problem. Next, we investigate the impact of giving different weights for aggregating user profiles from two OSNs and present that giving a higher weight to the targeted OSN profile for aggregation allows the best performance in the context of a personalized link recommender system. Finally, we propose a user modeling strategy which combines entity-and category-based user profiles using with a discounting strategy. Results show that our proposed strategy improves the quality of user modeling significantly compared to the baseline method.", "references": ["F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user modeling on twitter for personalized news recommendations. In User Modeling, Adaption and Personalization, pages 1--12. Springer, 2011.", "F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Semantic enrichment of twitter posts for user profile construction on the social web. In The Semanic Web: Research and Applications, pages 375--389. Springer, 2011.", "F. Abel, C. Hauff, G.-J. Houben, and K. Tao. Leveraging User Modeling on the Social Web with Linked Data. In Web Engineering SE - 31, pages 378--385. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930278"}, {"title": "A Supervised KeyPhrase Extraction System", "authors": ["Adebayo Kolawole John\n,", "Luigi Di Caro\n,", "Guido Boella"], "publication": "SEMANTiCS 2016: Proceedings of the 12th International Conference on Semantic Systems", "abstract": "ABSTRACT\nIn this paper, we present a multi-featured supervised automatic keyword extraction system. We extracted salient semantic features which are descriptive of candidate keyphrases, a Random Forest classifier was used for training. The system achieved an accuracy of 58.3 % precision and has shown to outperform two top performing systems when benchmarked on a crowdsourced dataset. Furthermore, our approach achieved a personal best Precision and F-measure score of 32.7 and 25.5 respectively on the Semeval Keyphrase extraction challenge dataset. The paper describes the approaches used as well as the result obtained.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "G. Boella, L. Di Caro, A. Ruggeri, and L. Robaldo. Learning from syntax generalizations for automatic semantic annotation. Journal of Intelligent Information Systems, 43(2):231--246, 2014.", "L. Breiman. Random forests. Machine learning, 45(1):5--32, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993318.2993323"}, {"title": "Simulation of Interaction: A Tutorial on Modelling and Simulating User Interaction and Search Behaviour", "authors": ["Leif Azzopardi"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch is an inherently interactive, non-deterministic and user-dependent process. This means that there are many different possible sequences of interactions which could be taken (some ending in success and others ending in failure). Simulation provides a low cost, repeatable and reproducible way to explore a large range of different possibilities. This makes simulation very appealing, but it also requires care and consideration in developing, implementing and instantiating models of user behaviour for the purposes of experimentation.\nIn this tutorial, we aim to provide researchers with an overview of simulation, detailing the various types of simulation, models of search behavior used to simulate interaction, along with an overview of the various models of querying, stopping, selecting and marking. Through the course of the tutorial we will describe various studies and how they have used simulation to explore different behaviours and aspects of the search process. The final section of the tutorial will be dedicated to \"best practice\" and how to build, ground and validate simulations. The tutorial will conclude with a demonstration of an open source simulation framework that can be used develop various kinds of simulations.", "references": ["L. Azzopardi. Query side evaluation: An empirical analysis of effectiveness and effort. In Proceedings of the 32\\textsuperscriptnd ACM SIGIR, pages 556--563, 2009.", "L. Azzopardi. Usage based effectiveness measures: Monitoring application performance in information retrieval. In Proceedings of the 18th ACM CIKM Conference, pages 631--640, 2009.", "L. Azzopardi. The economics in interactive information retrieval. In Proc. 34th ACM SIGIR, pages 15--24, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914799"}, {"title": "CourseNavigator: interactive learning path exploration", "authors": ["Zhan Li\n,", "Olga Papaemmanouil\n,", "Georgia Koutrika"], "publication": "ExploreDB '16: Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web", "abstract": "ABSTRACT\nCourse selection decision making is an extremely tedious task that needs to consider course prerequisites, degree requirements, class schedules, as well as the student's preferences and constraints. As a result, students often make short term decisions based on imprecise information without deep understanding of the longer-term impact on their education goal and in most cases without good understanding of the alternative options. In this paper, we introduce CourseNavigator, a new course exploration service that attempts to address the course exploration challenge. Our service identifies all possible course selection options for a given academic period, referred to as learning paths, that can meet the student's customized goals and constraints. CourseNavigator offers a suite of learning path generation algorithms designed to meet a range of course exploration end-goals such as learning paths for a given period and desired degree as well as the highest ranked paths based on user-defined ranking functions. Our techniques rely on a graph-search algorithm for enumerating candidate learning paths and employ a number of strategies (i.e., early detection of dead-end paths, limiting the exploration to strategic course selections) for improving the exploration efficiency.", "references": ["MSU Degree Navigator, https://degnav.msu.edu/.", "Rutgers Degree Navigator, https://nbdn.rutgers.edu/.", "Parameswaran et al. Recommendation systems with complex constraints: A course recommendation perspective. ACM Trans. Inf. Syst., 29(4):20:1--20:33, Dec. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948674.2948676"}, {"title": "Geometric Graph Indexing for Similarity Search in Scientific Databases", "authors": ["Ayser Armiti\n,", "Michael Gertz"], "publication": "SSDBM '16: Proceedings of the 28th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nSearching a database for similar graphs is a critical task in many scientific applications, such as in drug discovery, geoinformatics, or pattern recognition. Typically, graph edit distance is used to estimate the similarity of non-identical graphs, which is a very hard task. Several indexing structures and lower bound distances have been proposed to prune the search space. Most of them utilize the number of edit operations and assume graphs with a discrete label alphabet that has a certain canonical order. Unfortunately, such assumptions cannot be guaranteed for geometric graphs where vertices have coordinates in some two dimensional space.\nIn this paper, we study similarity range queries for geometric graphs with edit distance constraints. First, we propose an efficient index structure to discover similar vertices. For this, we embed the vertices of different graphs in a higher dimensional space, which are then indexed using the well-known R-tree. Second, we propose three lower bound distances to filter non-similar graphs with different pruning power and complexity. Using representative geometric graphs extracted from a variety of application domains, namely chemoinformatics, character recognition, and image analysis, our framework achieved on average a pruning performance of 94% with 77% reduction in the response time.", "references": ["CJK Fonts: Chinese, Japanese, and Korean Fonts. https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/bookr-mod/cjk-fonts-1.zip. Accessed: 01/12/2015.", "AIDS Antiviral Screen. http://dtp.nci.nih.gov/docs/aids/aids\\_data.html, 2004. Accessed: 07/07/2014.", "A. Armiti and M. Gertz. Efficient Geometric Graph Matching Using Vertex Embedding. In Proceedings of the 21st International Conference on Advances in Geographic Information Systems, SIGSPATIAL'13, pages 234--243, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2949689.2949691"}, {"title": "Doc2Sent2Vec: A Novel Two-Phase Approach for Learning Document Representation", "authors": ["Ganesh J\n,", "Manish Gupta\n,", "Vasudeva Varma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDoc2Sent2Vec is an unsupervised approach to learn low-dimensional feature vector (or embedding) for a document. This embedding captures the semantics of the document and can be fed as input to machine learning algorithms to solve a myriad number of applications in the field of data mining and information retrieval. Some of these applications include document classification, retrieval, and ranking.\nThe proposed approach is two-phased. In the first phase, the model learns a vector for each sentence in the document using a standard word-level language model. In the next phase, it learns the document representation from the sentence sequence using a novel sentence-level language model. Intuitively, the first phase captures the word-level coherence to learn sentence embeddings, while the second phase captures the sentence-level coherence to learn document embeddings. Compared to the state-of-the-art models that learn document vectors directly from the word sequences, we hypothesize that the proposed decoupled strategy of learning sentence embeddings followed by document embeddings helps the model learn accurate and rich document representations.\nWe evaluate the learned document embeddings by considering two classification tasks: scientific article classification and Wikipedia page classification. Our model outperforms the current state-of-the-art models in the scientific article classification task by ?12.07% and the Wikipedia page classification task by ?6.93%, both in terms of F1 score. These results highlight the superior quality of document embeddings learned by the Doc2Sent2Vec approach.", "references": ["Harris, Z.: Distributional structure. Word, 10(23). (1954) 146--162", "Blei, D., Ng, A.Y., Jordan, M.I.: Latent Dirichlet Allocation. In: JMLR. (2013)", "Le, Q., Mikolov, T.: Distributed Representations of Sentences and Documents. In: ICML. (2014) 1188--1196"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914717"}, {"title": "A Falling Line", "authors": ["Byungjoo Lee"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nA Falling Line is an interactive installation that creates responsive sound from participant's drawing on a black wall. In the form of white line, the drawing represents the waveform of the created sound. Audiences move a computer mouse to elongate the line but no modification or deletion of the existing line is allowed. To ensure the standard CD-quality sound (44100 kHz, 16 bit), a special electronics were used to extract the raw output from a high performance mouse. In terms of technology, this work demonstrates a novel concept of creating digital sound. In terms of artistic expression, the interaction provides high tension to the audience when trying to create some kind of meaningful sound from the irreversible drawing.", "references": ["Jérémie Garcia, Theophanis Tsandilas, Carlos Agon, and Wendy Mackay. 2011. Inksplorer: Exploring musical ideas on paper and computer. In New Interfaces for Musical Expression (NIME 2011).", "Michael Xuelin Huang, Will Tang, Kenneth WK Lo, Chi Kin Lau, Grace Ngai, and Stephen Chan. 2012. MelodicBrush: a cross-modal link between ancient and digital art forms. In CHI'12 Extended Abstracts on Human Factors in Computing Systems. ACM, 995-998.", "Kazuhiro Jo. 2008. DrawSound: a drawing instrument for sound performance. In Proceedings of the 2nd international conference on Tangible and embedded interaction. ACM, 59-62."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2891096"}, {"title": "Mobile App Retrieval for Social Media Users via Inference of Implicit Intent in Social Media Text", "authors": ["Dae Hoon Park\n,", "Yi Fang\n,", "Mengwen Liu\n,", "ChengXiang Zhai"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPeople often implicitly or explicitly express their needs in social media in the form of \"user status text\". Such text can be very useful for service providers and product manufacturers to proactively provide relevant services or products that satisfy people's immediate needs. In this paper, we study how to infer a user's intent based on the user's \"status text\" and retrieve relevant mobile apps that may satisfy the user's needs. We address this problem by framing it as a new entity retrieval task where the query is a user's status text and the entities to be retrieved are mobile apps. We first propose a novel approach that generates a new representation for each query. Our key idea is to leverage social media to build parallel corpora that contain implicit intention text and the corresponding explicit intention text. Specifically, we model various user intentions in social media text using topic models, and we predict user intention in a query that contains implicit intention. Then, we retrieve relevant mobile apps with the predicted user intention. We evaluate the mobile app retrieval task using a new data set we create. Experiment results indicate that the proposed model is effective and outperforms the state-of-the-art retrieval models.", "references": ["A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and R. Passonneau. Sentiment analysis of twitter data. In Workshop on Languages in Social Media, pages 30--38. Association for Computational Linguistics, 2011.", "E. Agichtein and L. Gravano. Snowball: Extracting relations from large plain-text collections. In ACM conference on Digital libraries, pages 85--94. ACM, 2000.", "A. Ashkan, C. L. Clarke, E. Agichtein, and Q. Guo. Classifying and characterizing query intent. In Advances in Information Retrieval, pages 578--586. Springer, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983843"}, {"title": "The ranking game", "authors": ["Ran Ben Basat\n,", "Elad Kravi"], "publication": "WebDB '16: Proceedings of the 19th International Workshop on Web and Databases", "abstract": "ABSTRACT\nIn the web, page creators often compete for their ranking on relevant search queries, as high ranking attracts users and may lead to increased revenues. The positive effect of this competition is that it encourages page owners to improve their content. However, some techniques used for this improvement, such as keyword stuffing, are considered harmful. Current search engine literature largely ignores the interplay between the retrieval system and the pages' content evolvement. This paper studies the above phenomenon.\nWe model pages as strategic players, competing for a better rank by content manipulations, while the search engine controls the ranking mechanism. We show that such competition may degrade retrieval effectiveness as irrelevant pages tend to outrank better ones. Further, we investigate how the search engine's choice of a ranking scheme may reduce the incentive to manipulate the page content. Finally, we propose a novel ranking solution that empirically minimizes the adverse effect on a real dataset.", "references": ["R. Ben Basat, M. Tennenholtz, and O. Kurland. The probability ranking principle is not optimal in adversarial retrieval settings. In ICTIR, pages 51--60. ACM, 2015.", "A. Białecki, R. Muir, and G. Ingersoll. Apache lucene 4. In SIGIR 2012 workshop on open source information retrieval, page 17, 2012.", "C. Castillo, D. Donato, L. Becchetti, P. Boldi, S. Leonardi, M. Santini, and S. Vigna. A reference collection for web spam. In SIGIR, volume 40, pages 11--24. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2932194.2932201"}, {"title": "A Scriptable Standard-Compliant Reporting and Logging Framework for SystemC", "authors": ["Rolf Meyer\n,", "Jan Wagner\n,", "Bastian Farkas\n,", "Sven Horsinka\n,", "Patrick Siegl\n,", "Rainer Buchty\n,", "Mladen Berekovic"], "publication": "ACM Transactions on Embedded Computing Systems", "abstract": "Abstract\nWith the ever-increasing complexity of digital designs, debugging and evaluation face likewise increasing challenges. While recent advances in hardware/software co-simulation have been made, solutions for corresponding debugging and evaluation did not mature and improve in a similar fashion. In this article, we present a dedicated solution to ease the debugging and evaluation efforts, particularly focusing on full-system simulation. Improving significantly over existing solutions, the presented approach features a standards-compliant powerful and flexible method of deriving, logging, and filtering detailed status information from SystemC-based models. At the core of this approach are flexible scripting capabilities that may change all logging parameters during runtime, thus not requiring re-compiling the to-be-simulated model, as in many competing solutions. The approach is tested and benchmarked with a real-world full-system example, demonstrating the overall benefits. The presented solution is published as open source via github (see text) and, by strictly adhering to existing standards, is generally compatible with existing SystemC simulation environments.", "references": ["0xAX et al. 2015. Linux Inside. GitBook. Retrieved from https://0xax.gitbooks.io/linux-insides/content/.", "Accellera. 2015. Accellera working group for configuration, control and inspection. Retrieved from http://www.accellera.org/activities/committees/systemc-cci/.", "Aeroflex/Gaisler. 2015. Aeroflex/Gaisler IP and manual download. Retrieved from http://www.gaisler.com/index.php/downloads."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983623"}, {"title": "Learning to Rank with Selection Bias in Personal Search", "authors": ["Xuanhui Wang\n,", "Michael Bendersky\n,", "Donald Metzler\n,", "Marc Najork"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nClick-through data has proven to be a critical resource for improving search ranking quality. Though a large amount of click data can be easily collected by search engines, various biases make it difficult to fully leverage this type of data. In the past, many click models have been proposed and successfully used to estimate the relevance for individual query-document pairs in the context of web search. These click models typically require a large quantity of clicks for each individual pair and this makes them difficult to apply in systems where click data is highly sparse due to personalized corpora and information needs, e.g., personal search. In this paper, we study the problem of how to leverage sparse click data in personal search and introduce a novel selection bias problem and address it in the learning-to-rank framework. This paper proposes a few bias estimation methods, including a novel query-dependent one that captures queries with similar results and can successfully deal with sparse data. We empirically demonstrate that learning-to-rank that accounts for query-dependent selection bias yields significant improvements in search effectiveness through online experiments with one of the world's largest personal search engines.", "references": ["J. A. Aslam, E. Kanoulas, V. Pavlu, S. Savev, and E. Yilmaz. Document selection methodologies for efficient and effective learning-to-rank. In 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 468--475, 2009.", "R. Bekkerman. Automatic categorization of email into folders: Benchmark experiments on Enron and SRI corpora. Technical report, University of Massachusetts Amherst, 2004.", "P. F. Brown, V. J. D. Pietra, R. L. Mercer, S. A. D. Pietra, and J. C. Lai. An estimate of an upper bound for the entropy of English. Computational Linguistics, 18(1):31--40, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911537"}, {"title": "Interactive Image Search for Clothing Recommendation", "authors": ["Zhengzhong Zhou\n,", "Yifei Xu\n,", "Jingjin Zhou\n,", "Liqing Zhang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis demo delivers a novel retrieval system which meets users' multi-dimensional requirements in clothing image search. In this system, users are able to use both image and keywords as query inputs. We employ the color, texture, shape and attributes as additional descriptors to further refine the requirements. We propose the Hybrid Topic (HT) model, a probabilistic network integrating the multi-channel descriptors into a unified framework, to learn the intricate semantic representation of the descriptors above. The proposed model provides an effective multi-modal representation of clothes. Our experiments show that the HT method significantly outperforms the CNN-based deep search methods.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. In NIPS, pages 601--608, 2001.", "W. Chong, D. Blei, and F.-F. Li. Simultaneous image classification and annotation. In CVPR, pages 1903--1910, 2009.", "N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, volume 1, pages 886--893, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973834"}, {"title": "Two birds, one stone: a fast, yet lightweight, indexing scheme for modern database systems", "authors": ["Jia Yu\n,", "Mohamed Sarwat"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nClassic database indexes (e.g., B+-Tree), though speed up queries, suffer from two main drawbacks: (1) An index usually yields 5% to 15% additional storage overhead which results in non-ignorable dollar cost in big data scenarios especially when deployed on modern storage devices. (2) Maintaining an index incurs high latency because the DBMS has to locate and update those index pages affected by the underlying table changes. This paper proposes Hippo a fast, yet scalable, database indexing approach. It significantly shrinks the index storage and mitigates maintenance overhead without compromising much on the query execution performance. Hippo stores disk page ranges instead of tuple pointers in the indexed table to reduce the storage space occupied by the index. It maintains simplified histograms that represent the data distribution and adopts a page grouping technique that groups contiguous pages into page ranges based on the similarity of their index key attribute distributions. When a query is issued, Hippo leverages the page ranges and histogram-based page summaries to recognize those pages such that their tuples are guaranteed not to satisfy the query predicates and inspects the remaining pages. Experiments based on real and synthetic datasets show that Hippo occupies up to two orders of magnitude less storage space than that of the B+-Tree while still achieving comparable query execution performance to that of the B+-Tree for 0.1% -- 1% selectivity factors. Also, the experiments show that Hippo outperforms BRIN (Block Range Index) in executing queries with various selectivity factors. Furthermore, Hippo achieves up to three orders of magnitude less maintenance overhead and up to an order of magnitude higher throughput (for hybrid query/update workloads) than its counterparts.", "references": ["New york city taxi and limousine commission. http://www.nyc.gov/html/tlc/html/about/trip\\_record\\_data.html.", "Page view statistics for wikimedia projects. https://dumps.wikimedia.org/other/pagecounts-raw/.", "S. Agarwal, H. Milner, A. Kleiner, A. Talwalkar, M. Jordan, S. Madden, B. Mozafari, and I. Stoica. Knowing when you're wrong: building fast and reliable approximate query processing systems. In Proceedings of the International Conference on Management of Data, SIGMOD, pages 481--492. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3025111.3025120"}, {"title": "Usability Evaluation of Reference Management Systems", "authors": ["Ana C.T. Klock\n,", "Irmgard A.H.C. Nakazoni\n,", "Isabela Gasparini\n,", "Marcelo S. Hounsell"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nDue to the large volume of data available, researchers find it difficult to store and organize the relevant papers to their investigation. Reference management systems optimize this process, assisting in editing of a new paper through standardization and proper formatting of citations and references. The purpose of this paper is to evaluate the usability of EndNote, Mendeley and Zotero systems. Evaluation methods were used with and without user participation. It was observed that EndNote users had the highest completion rate of the requested tasks while Mendeley users achieved the highest satisfaction rate.", "references": ["Duong, K. (2010). Rolling Out Zotero Across Campus as a P rt f S L r r 's Outr Eff rts. Science e Technology Libraries, v. 29, n. 4, p. 315-324.", "Pampel, H. e Dallmeier-Tiessen, S. (2014). Open Research Data: From Vision to Practice. In: Bartling, S.; Friesike, S.{Eds.}. Opening Science: The Evolving Guide on How the Internet is Changing Research, Collaboration and Scholarly Publishing. Cham: Springer International Publishing. p. 213- 224.", "Francese, E. (2011). The Usage of Reference Management Software (RMS) in an Academic Environment: a Survey at Tallinn University. Session on Divergence and Convergence: Information Work in Digital Cultural Memory Institutions,"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022039"}, {"title": "Therenow: what is happening over there, right now?", "authors": ["Xiaoming Leng\n,", "Ying Yan\n,", "Yang Chen\n,", "Börje F. Karlsson\n,", "Thomas Moscibroda"], "publication": "SA '16: SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications", "abstract": "ABSTRACT\nImagine you need to know what is happening at a certain location. How could you achieve that? A search engine might be a choice, but the information may be outdated since the page was crawled. Radio and TV news can broadcast in real-time, but they focus only on hot events. Social networks can also be real-time, but how to request what you want and quickly spread your question?", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2999508.2999509"}, {"title": "Age-related Differences in the Content of Search Queries when Reformulating", "authors": ["Saraschandra Karanam\n,", "Herre van Oostendorp"], "publication": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis study investigated the change in the content of the queries when performing reformulations in relation to age and task difficulty. Results showed that both generalization and specialization strategies were applied significantly more often for difficult tasks compared to simple tasks. Young participants were found to use specialization strategy significantly more often than old participants. Generalization strategy was also used significantly more often by young participants, especially for difficult tasks. Young participants were found to reformulate much longer than old participants. The semantic relevance of queries with the target information was found to be significantly higher for difficult tasks compared to simple tasks. It showed a decreasing trend across reformulations for old participants and remained constant for young participants, indicating that as old participants reformulated, they produced queries that were further away from the target information. Implications of these findings for design of information search systems are discussed.", "references": ["Anne Aula. 2005. User study on older adults use of the Web and search engines. Universal Access in the Information Society 4, 1 (2005), 67-81.", "Pia Borlund and Peter Ingwersen. 1997. The development of a method for the evaluation of interactive information retrieval systems. Journal of documentation 53, 3 (1997), 225-250.", "Aline Chevalier, Aurélie Dommes, and Jean-Claude Marquié. 2011. Information searching on the web: the cognitive difficulties experienced by older users in modifying unsuccessful information searches. In Engineering Psychology and Cognitive Ergonomics. Springer, 225-232."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2858036.2858444"}, {"title": "Explainable Matrix Factorization for Collaborative Filtering", "authors": ["Behnoush Abdollahi\n,", "Olfa Nasraoui"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nExplanations have been shown to increase the user's trust in recommendations in addition to providing other benefits such as scrutability, which is the ability to verify the validity of recommendations. Most explanation methods are designed for classical neighborhood-based Collaborative Filtering (CF) or rule-based methods. For the state of the art Matrix Factorization (MF) recommender systems, recent explanation methods, require an additional data source, such as item content data, in addition to rating data. In this paper, we address the case where no such additional data is available and propose a new Explainable Matrix Factorization (EMF) technique that computes an accurate top-$n$ recommendation list of items that are explainable. We also introduce new explanation quality metrics, that we call Mean Explainability Precision (MEP) and Mean Explainability Recall (MER).", "references": ["J. L. Herlocker, J. A. Konstan, and J. Riedl. Explaining collaborative filtering recommendations. In Proceedings of the 2000 ACM conference on Computer supported cooperative work, pages 241--250. ACM, 2000.", "J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems (TOIS), 22(1):5--53, 2004.", "K. J\\\"arvelin and J. Kek\\\"al\\\"ainen. Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems (TOIS), 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889405"}, {"title": "Robust Decentralized Low-Rank Matrix Decomposition", "authors": ["István Hegedűs\n,", "Árpád Berta\n,", "Levente Kocsis\n,", "András A. Benczúr\n,", "Márk Jelasity"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nLow-rank matrix approximation is an important tool in data mining with a wide range of applications, including recommender systems, clustering, and identifying topics in documents. When the matrix to be approximated originates from a large distributed system, such as a network of mobile phones or smart meters, a challenging problem arises due to the strongly conflicting yet essential requirements of efficiency, robustness, and privacy preservation. We argue that although collecting sensitive data in a centralized fashion may be efficient, it is not an option when considering privacy and efficiency at the same time. Thus, we do not allow any sensitive data to leave the nodes of the network. The local information at each node (personal attributes, documents, media ratings, etc.) defines one row in the matrix. This means that all computations have to be performed at the edge of the network. Known parallel methods that respect the locality constraint, such as synchronized parallel gradient search or distributed iterative methods, require synchronized rounds or have inherent issues with load balancing, and thus they are not robust to failure. Our distributed stochastic gradient descent algorithm overcomes these limitations. During the execution, any sensitive information remains local, whereas the global features (e.g., the factor model of movies) converge to the correct value at all nodes. We present a theoretical derivation and a thorough experimental evaluation of our algorithm. We demonstrate that the convergence speed of our method is competitive while not relying on synchronization and being robust to extreme and realistic failure scenarios. To demonstrate the feasibility of our approach, we present trace-based simulations, real smartphone user behavior analysis, and tests over real movie recommender system data.", "references": ["Dimitris Achlioptas and Frank McSherry. 2005. On spectral learning of mixtures of distributions. In Proceedings of the 18th Annual Conference on Learning Theory (COLT’05). 458--469.", "Waseem Ahmad and Ashfaq Khokhar. 2006. Secure aggregation in large scale overlay networks. In Proceedings of the IEEE Global Telecommunications Conference (GLOBECOM’06). DOI:http://dx.doi.org/10.1109/GLOCOM.2006.315", "Ethem Alpaydin. 2010. Introduction to Machine Learning (2nd ed.). MIT Press, Cambridge, MA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854157"}, {"title": "Information (Re)Use in Context", "authors": ["Mark S. Ackerman"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nOver the last 25-30 years, an enormous amount has been learned about how people seek, use, maintain, and reuse information and expertise in groups and other collectivities. We have also seen major changes in the kinds of information available and in how it is available.\nI believe we're on the cusp of the next generation of computational environments and user experiences. It goes under many names - pervasive environments, Internet of Things, Big Data, ubicomp, and on and on - but what is clear is that things are about to change for information - and for users.\nThis talk considers some of the changes that might occur, grounding them in current work - then and tries to find the new roles and characteristics that search and information seeking will have. (Spoiler Alert: search and seeking will more tightly intertwine.).", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855007"}, {"title": "Audience Prism: Segmentation and Early Classification of Visitors Based on Reading Interests", "authors": ["Lilly Kumari\n,", "Sunny Dhamnani\n,", "Akshat Bhatnagar\n,", "Atanu R. Sinha\n,", "Ritwik Sinha"], "publication": "CODS '16: Proceedings of the 3rd IKDD Conference on Data Science, 2016", "abstract": "ABSTRACT\nThe largest Media and Entertainment (M&E) web portals today cater to more than 100 Million unique visitors every month. In Customer Relationship Management, customer segmentation plays an important role, with the goal of targeting different products for different segments. Marketers segment their customers based on customer attributes. In the non-subscription based media business, the customer is analogous to the visitor, the product to the content, and a purchase to consumption. Knowing which segment an audience member belongs to, enables better engagement. In this work, we address the problems: 1) How can we segment audience members of an M&E web property based on their media consumption interests? 2) When a new visitor arrives, how can we classify them into one of the above defined segments (without having to wait for consumption history)? We apply our proposed solution to a real world data-set and show that we can achieve coherent clusters and can predict cluster membership with a high level of accuracy. We also build a tool that the editors can find valuable towards understanding their audience.", "references": ["M. Charrad, N. Ghazzali, V. Boiteau, and A. Niknafs. Nbclust: an r package for determining the relevant number of clusters in a data set. Journal of Statistical Software, 61(6):1--36, 2014.", "T. Hastie, R. Tibshirani, J. Friedman, and J. Franklin. The elements of statistical learning: data mining, inference and prediction. The Mathematical Intelligencer, 27(2):83--85, 2005.", "K. Hornik, I. Feinerer, M. Kober, and C. Buchta. Spherical k-means clustering. Journal of Statistical Software, 50(10):1--22, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2888451.2888459"}, {"title": "Conversational Recommendation System with Unsupervised Learning", "authors": ["Yueming Sun\n,", "Yi Zhang\n,", "Yunfei Chen\n,", "Roger Jin"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe will demonstrate a conversational products recommendation agent. This system shows how we combine research in personalized recommendation systems with research in dialogue systems to build a virtual sales agent. Based on new deep learning technologies we developed, the virtual agent is capable of learning how to interact with users, how to answer user questions, what is the next question to ask, and what to recommend when chatting with a human user. Normally a descent conversational agent for a particular domain requires tens of thousands of hand labeled conversational data or hand written rules. This is a major barrier when launching a conversation agent for a new domain. We will explore and demonstrate the effectiveness of the learning solution even when there is no hand written rules or hand labeled training data.", "references": ["Jason Williams, Antoine Raux, Deepak Ramachadran, and Alan Black, \"The Dialog State Tracking Challenge\", Proceedings of the SIGDIAL 2013 Conference, Metz, France, August 2013", "LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton, \"Deep learning\", Nature 521, no. 7553 (2015): 436--444."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959114"}, {"title": "Reducing Click and Skip Errors in Search Result Ranking", "authors": ["Jiepu Jiang\n,", "James Allan"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nSearch engines provide result summaries to help users quickly identify whether or not it is worthwhile to click on a result and read in detail. However, users may visit non-relevant results and/or skip relevant ones. These actions are usually harmful to the user experience, but few considered this problem in search result ranking. This paper optimizes relevance of results and user click and skip activities at the same time. Comparing two equally relevant results, our approach learns to rank the one that users are more likely to click on at a higher position. Similarly, it demotes non-relevant web pages with high click probabilities. Experimental results show this approach reduces about 10%-20% of the click and skip errors with a trade off of 2.1% decline in nDCG@10.", "references": ["Overview of the special issue on contextual search and recommendation. ACM Trans. Inf. Syst., 33(1), 2015.", "E. Adar, J. Teevan, and S. T. Dumais. Large scale analysis of web revisitation patterns. In CHI '08, 2008.", "E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR '06, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835838"}, {"title": "Spectral and Cepstral Audio Noise Reduction Techniques in Speech Emotion Recognition", "authors": ["Jouni Pohjalainen\n,", "Fabien Fabien Ringeval\n,", "Zixing Zhang\n,", "Björn Schuller"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nSignal noise reduction can improve the performance of machine learning systems dealing with time signals such as audio. Real-life applicability of these recognition technologies requires the system to uphold its performance level in variable, challenging conditions such as noisy environments. In this contribution, we investigate audio signal denoising methods in cepstral and log-spectral domains and compare them with common implementations of standard techniques. The different approaches are first compared generally using averaged acoustic distance metrics. They are then applied to automatic recognition of spontaneous and natural emotions under simulated smartphone-recorded noisy conditions. Emotion recognition is implemented as support vector regression for continuous-valued prediction of arousal and valence on a realistic multimodal database. In the experiments, the proposed methods are found to generally outperform standard noise reduction algorithms.", "references": ["J. Barker, E. Vincent, N. Ma, C. Christensen, and P. Green. The PASCAL CHiME speech separation and recognition challenge. Computer Speech and Language, 27(3):621--633, Nov. 2013.", "M. Berouti, R. Schwartz, and J. Makhoul. Enhancement of speech corrupted by acoustic noise. In Proc. ICASSP, Washington, D.C., USA, Apr. 1979.", "S. F. Boll. Suppression of acoustic noise in speech using spectral subtraction. IEEE Trans. Acoustics, Speech, and Signal Processing, 27(2):113--120, Apr. 1979."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967306"}, {"title": "Barbara Made the News: Mining the Behavior of Crowds for Time-Aware Learning to Rank", "authors": ["Flávio Martins\n,", "João Magalhães\n,", "Jamie Callan"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nIn Twitter, and other microblogging services, the generation of new content by the crowd is often biased towards immediacy: what is happening now. Prompted by the propagation of commentary and information through multiple mediums, users on the Web interact with and produce new posts about newsworthy topics and give rise to trending topics. This paper proposes to leverage on the behavioral dynamics of users to estimate the most relevant time periods for a topic. Our hypothesis stems from the fact that when a real-world event occurs it usually has peak times on the Web: a higher volume of tweets, new visits and edits to related Wikipedia articles, and news published about the event.\nIn this paper, we propose a novel time-aware ranking model that leverages on multiple sources of crowd signals. Our approach builds on two major novelties. First, a unifying approach that given query q, mines and represents temporal evidence from multiple sources of crowd signals. This allows us to predict the temporal relevance of documents for query q. Second, a principled retrieval model that integrates temporal signals in a learning to rank framework, to rank results according to the predicted temporal relevance. Evaluation on the TREC 2013 and 2014 Microblog track datasets demonstrates that the proposed model achieves a relative improvement of 13.2% over lexical retrieval models and 6.2% over a learning to rank baseline.", "references": ["M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In Proceedings of WSDM '12, 2012, 443--452.", "J. Choi, W. B. Croft, and J. Y. Kim. Quality models for microblog retrieval. In Proceedings of CIKM '12, 2012, 1834--1838.", "Ciglan and K. Nørvåg. WikiPop: Personalized event detection system based on wikipedia page view statistics. In Proceedings of CIKM '10, 2010, 1931--1932."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835825"}, {"title": "Google Analytics: A Tool to make websites more Robust", "authors": ["Loveleen Gaur\n,", "Gurinder Singh\n,", "Jeyta\n,", "Shubhankar Kumar"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nE-Commerce is a reliably creating business segment with a significant measure of potential. The continuing advancement of customers prompts an unyieldingly genuine contention. Various fresh works are arriving in the business sector through included parts, placing weight on assessing. An assessing competition will impact benefit of associations out and out and may pulverize business segment costs over a whole deal. Toward the end, there may be various terminations as a result of this resistance in expense.\nGoogle Analytics is a specific illustrative instrument from Google which serves to trace guests & assemble an extensive variety of profitable data concerning them. This instrument has ended up being extremely standard for site heads and has a tremendous offer of business part. The instrument's straightforwardness of utilization has developed it as an OK distinctive choice for customary web investigative mechanical assemblies. Then again, with regards to conveying unrefined statistics, belongings get troublesome; Google Analytics tries to maintain assembled data developing a fitting ability to passage rough data. It is a venture course founded examination device & gives a straightforward perspective of site movement and promoting viability. It has capable & development includes that provide knowledge into sites & enhance site ROI. This exploration rag comprises of contextual investigation on Google Analytics that exhibits components and creates the report. On the assessment's premise of web utilization, site proprietors can improve the proficiency of showcasing, and web traffic flow. This paper likewise exhibits the Google's restrictions analytics and proposes better way to deal with the concerns.\nThis paper separates & depicts the tactic by these inconveniences remain tended near & perceives whether Google Analytics can be seeing as the best in class distinctive alternative for accumulate numbers aimed at web use mining.", "references": ["Gunther C.W., Verbeek E. XES Standard Definition. Eindhoven University of Technology. 2012.", "Hughes D. Documentation for Lars. Mime Consulting. 2013. Available at: http://lars.readthedocs.org/en/release-0.2/. Accessed December 10, 2013.", "Jamari P. Improving the Performance of Proxy Server by Using Data Mining Technique. World Academy Of Science, Engineering and Technology. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905251"}, {"title": "Examining Additivity and Weak Baselines", "authors": ["Sadegh Kharazmi\n,", "Falk Scholer\n,", "David Vallet\n,", "Mark Sanderson"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nWe present a study of which baseline to use when testing a new retrieval technique. In contrast to past work, we show that measuring a statistically significant improvement over a weak baseline is not a good predictor of whether a similar improvement will be measured on a strong baseline. Sometimes strong baselines are made worse when a new technique is applied. We investigate whether conducting comparisons against a range of weaker baselines can increase confidence that an observed effect will also show improvements on a stronger baseline. Our results indicate that this is not the case -- at best, testing against a range of baselines means that an experimenter can be more confident that the new technique is unlikely to significantly harm a strong baseline. Examining recent past work, we present evidence that the information retrieval (IR) community continues to test against weak baselines. This is unfortunate as, in light of our experiments, we conclude that the only way to be confident that a new technique is a contribution is to compare it against nothing less than the state of the art.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. 2009. Diversifying search results. In Proceedings of WSDM. ACM, 5--14.", "Timothy G. Armstrong, Alistair Moffat, William Webber, and Justin Zobel. 2009. Improvements that don’t add up: Ad-hoc retrieval results since 1998. In Proceedings of CIKM. ACM, 601--610.", "David Bodoff. 2013. Fuhr’s challenge: Conceptual research, or bust. In ACM SIGIR Forum, Vol. 47. ACM, 3--16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882782"}, {"title": "Towards Cohesive Extractive Summarization through Anaphoric Expression Resolution", "authors": ["Jamilson Batista\n,", "Rafael Dueire Lins\n,", "Rinaldo Lima\n,", "Steven J. Simske\n,", "Marcelo Riss"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nThis paper presents a new method for improving the cohesiveness of summaries generated by extractive summarization systems. The solution presented attempts to improve the legibility and cohesion of the generated summaries through coreference resolution. It is based on a post-processing step that binds dangling coreference to the most important entity in a given coreference chain. The proposed solution was evaluated on the CNN corpus of 3,000 news articles, using four state-of-the-art summarization systems and seventeen techniques for sentence scoring proposed in the literature. The experimental results may be considered encouraging, as the final summaries reached better ROUGE scores, besides being more cohesive.", "references": ["J. Batista, R. Ferreira, H. Oliveira, R. Ferreira, R. D. Lins, G. Pereira e Silva, S. J. Simske, and M. Riss. A quantitative and qualitative assessment of automatic text summarization systems. In Proc. of the 2015 ACM, DocEng '15, pages 65--68, New York, NY, USA, 2015.", "J. Christensen, S. Soderl, and O. Etzioni. Towards coherent multi-document summarization. In Proc. of the North American Chapter of the ACL: Human Language Technologies, NAACL, 2013.", "R. L. Donaway, K. W. Drummey, and L. A. Mather. A comparison of rankings produced by summarization evaluation measures. In Proc. of the 2000 NAACL-ANLP - Volume 4, NAACL-ANLP-AutoSum '00, pages 69--78, Stroudsburg, PA, USA, 2000. ALC."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2967159"}, {"title": "Joint Modeling of User Check-in Behaviors for Real-time Point-of-Interest Recommendation", "authors": ["Hongzhi Yin\n,", "Bin Cui\n,", "Xiaofang Zhou\n,", "Weiqing Wang\n,", "Zi Huang\n,", "Shazia Sadiq"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nPoint-of-Interest (POI) recommendation has become an important means to help people discover attractive and interesting places, especially when users travel out of town. However, the extreme sparsity of a user-POI matrix creates a severe challenge. To cope with this challenge, we propose a unified probabilistic generative model, the Topic-Region Model (TRM), to simultaneously discover the semantic, temporal, and spatial patterns of users’ check-in activities, and to model their joint effect on users’ decision making for selection of POIs to visit. To demonstrate the applicability and flexibility of TRM, we investigate how it supports two recommendation scenarios in a unified way, that is, hometown recommendation and out-of-town recommendation. TRM effectively overcomes data sparsity by the complementarity and mutual enhancement of the diverse information associated with users’ check-in activities (e.g., check-in content, time, and location) in the processes of discovering heterogeneous patterns and producing recommendations. To support real-time POI recommendations, we further extend the TRM model to an online learning model, TRM-Online, to track changing user interests and speed up the model training. In addition, based on the learned model, we propose a clustering-based branch and bound algorithm (CBB) to prune the POI search space and facilitate fast retrieval of the top-k recommendations.\nWe conduct extensive experiments to evaluate the performance of our proposals on two real-world datasets, including recommendation effectiveness, overcoming the cold-start problem, recommendation efficiency, and model-training efficiency. The experimental results demonstrate the superiority of our TRM models, especially TRM-Online, compared with state-of-the-art competitive methods, by making more effective and efficient mobile recommendations. In addition, we study the importance of each type of pattern in the two recommendation scenarios, respectively, and find that exploiting temporal patterns is most important for the hometown recommendation scenario, while the semantic patterns play a dominant role in improving the recommendation effectiveness for out-of-town users.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering 17, 6, 734--749.", "Amr Ahmed, Yucheng Low, Mohamed Aly, Vanja Josifovski, and Alexander J. Smola. 2011. Scalable distributed inference of dynamic user interests for behavioral targeting. In KDD. 114--122.", "Loulwah AlSumait, Daniel Barbar, and Carlotta Domeniconi. 2008. On-line LDA: Adaptive topic models for mining text streams with applications to topic detection and tracking. In ICDM. 3--12."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2873055"}, {"title": "Potential and Pitfalls of Domain-Specific Information Extraction at Web Scale", "authors": ["Astrid Rheinländer\n,", "Mario Lehmann\n,", "Anja Kunkel\n,", "Jörg Meier\n,", "Ulf Leser"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nIn many domains, a plethora of textual information is available on the web as news reports, blog posts, community portals, etc. Information extraction (IE) is the default technique to turn unstructured text into structured fact databases, but systematically applying IE techniques to web input requires highly complex systems, starting from focused crawlers over quality assurance methods to cope with the HTML input to long pipelines of natural language processing and IE algorithms. Although a number of tools for each of these steps exists, their seamless, flexible, and scalable combination into a web scale end-to-end text analytics system still is a true challenge. In this paper, we report our experiences from building such a system for comparing the \"web view\" on health related topics with that derived from a controlled scientific corpus, i.e., Medline. The system combines a focused crawler, applying shallow text analysis and classification to maintain focus, with a sophisticated text analytic engine inside the Big Data processing system Stratosphere. We describe a practical approach to seed generation which led us crawl a corpus of ~1 TB web pages highly enriched for the biomedical domain. Pages were run through a complex pipeline of best-of-breed tools for a multitude of necessary tasks, such as HTML repair, boilerplate detection, sentence detection, linguistic annotation, parsing, and eventually named entity recognition for several types of entities. Results are compared with those from running the same pipeline (without the web-related tasks) on a corpus of 24 million scientific abstracts and a third corpus made of ~250K scientific full texts. We evaluate scalability, quality, and robustness of the employed methods and tools. The focus of this paper is to provide a large, real-life use case to inspire future research into robust, easy-to-use, and scalable methods for domain-specific IE at web scale.", "references": ["S. Agarwal and H. Yu. Biomedical negation scope detection with conditional random fields. J. Am. Med. Inform. Assn., 17(6):696--701, 2010.", "A. Alexandrov, R. Bergmann, S. Ewen, J.-C. Freytag, F. Hueske, A. Heise, O. Kao, M. Leich, U. Leser, V. Markl, F. Naumann, M. Peters, A. Rheinlander, M. J. Sax, S. Schelter, M. Höger, K. Tzoumas, and D. Warneke. The stratosphere platform for big data analytics. VLDB J., 23(6):939--964, 2014.", "S. Chakrabarti, M. van den Berg, and B. Dom. Focused crawling: A new approach to topic-specific web resource discovery. Comput. Netw., 31(11--16):1623--1640, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2903736"}, {"title": "Job recommendation with Hawkes process: an effective solution for RecSys Challenge 2016", "authors": ["Wenming Xiao\n,", "Xiao Xu\n,", "Kang Liang\n,", "Junkang Mao\n,", "Jun Wang"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nThe RecSys Challenge 2016 focuses on the prediction of users' interest in clicking a job posting in the career-oriented social networking site Xing. Given users' profile, the content of the job posting, as well as the historical activities of users, we aim in recommending top job postings to users for the coming week. This paper introduces the winning strategy for such a recommendation task. We summarize several key components that result in our leading position in this contest. First, we build a hierarchical pairwise model with ensemble learning as the overall prediction framework. Second, we integrate both content and behavior information in our feature engineering process. In particular, we model the temporal activity pattern using a self-exciting point process, namely Hawkes Process, to generate the most relevant recommendation at the right moment. Finally, we also tackle the challenging cold start issue using a semantic based strategy that is built on the topic modeling with the users profiling information. Our approach achieved the highest leader-board and full scores among all the submissions.", "references": ["O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view. Springer Science & Business Media, 2008.", "F. Abel, A. Benczúr, D. Kohlsdorf, M. Larson, and R. Pálovics. Recsys challenge 2016: Job recommendations. In Proceedings of the 2016 International ACM Recommender Systems, 2016.", "J. Bennett and S. Lanning. The netflix prize. In Proceedings of KDD cup and workshop, volume 2007, page 35, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987543"}, {"title": "ScrumMaster's Attributions and Competences: An Exploratory Study", "authors": ["Joao H.J.A. Bernardo\n,", "Jose J.L. Dias Junior\n,", "Jose A.O.G. Cunha"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe need for faster deliveries with maximum business value to the product has gained prominence in current software development scenario. One of the key roles is the ScrumMaster in the context of agile projects management process based on Scrum. In this way, it is important to understand how this role has been perceived by practitioners in software development in order to identify elements that are beyond the proposed by Scrum. Hence, this paper presents a qualitative research, performed to identify attributions and competences inherent to the role of ScrumMaster under professionals viewpoint that works in the public sector. This work has identified 20 different ScrumMaster attributions in respect of Product Owner, Team and organization, as also 12 competences considered important to this role.", "references": ["L. Bardin. Content analysis. Editions Lisbon, 1977.", "J. M. Bass. Scrum master activities: Process tailoring in large enterprise projects. In Global Software Engineering (ICGSE), 2014 IEEE 9th International Conference on, pages 6-15. IEEE, 2014.", "G. Chin. Agile project management: how to succeed in the face of changing project requirements. AMACOM Div American Mgmt Assn, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022035"}, {"title": "miMic: The Microphone as a Pencil", "authors": ["Davide Rocchesso\n,", "Davide A. Mauro\n,", "Stefano Delle Monache"], "publication": "TEI '16: Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction", "abstract": "ABSTRACT\nmiMic, a sonic analogue of paper and pencil is proposed: An augmented microphone for vocal and gestural sonic sketching. Vocalizations are classified and interpreted as instances of sound models, which the user can play with by vocal and gestural control. The physical device is based on a modified microphone, with embedded inertial sensors and buttons. Sound models can be selected by vocal imitations that are automatically classified, and each model is mapped to vocal and gestural features for real-time control. With miMic, the sound designer can explore a vast sonic space and quickly produce expressive sonic sketches, which may be turned into sound prototypes by further adjustment of model parameters.", "references": ["Sarah Fdili Alaoui, Baptiste Caramiaux, Marcos Serrano, and Frédéric Bevilacqua. 2012. Movement Qualities As Interaction Modality. In Proceedings of the Designing Interactive Systems Conference (DIS '12). ACM, New York, NY, USA, 761--769. DOI: http://dx.doi.org/10.1145/2317956.2318071", "David Sanchez Blancas and Jordi Janer. 2014. Sound retrieval from voice imitation queries in collaborative databases. In Audio Engineering Society Conference: Semantic Audio. Audio Engineering Society.", "Bill Buxton. 2007. Sketching User Experiences: Getting the Design Right and the Right Design. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2839462.2839467"}, {"title": "Measuring and Predicting Search Engine Users’ Satisfaction", "authors": ["Ovidiu Dan\n,", "Brian D. Davison"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nSearch satisfaction is defined as the fulfillment of a user’s information need. Characterizing and predicting the satisfaction of search engine users is vital for improving ranking models, increasing user retention rates, and growing market share. This article provides an overview of the research areas related to user satisfaction. First, we show that whenever users choose to defect from one search engine to another they do so mostly due to dissatisfaction with the search results. We also describe several search engine switching prediction methods, which could help search engines retain more users. Second, we discuss research on the difference between good and bad abandonment, which shows that in approximately 30% of all abandoned searches the users are in fact satisfied with the results. Third, we catalog techniques to determine queries and groups of queries that are underperforming in terms of user satisfaction. This can help improve search engines by developing specialized rankers for these query patterns. Fourth, we detail how task difficulty affects user behavior and how task difficulty can be predicted. Fifth, we characterize satisfaction and we compare major satisfaction prediction algorithms.", "references": ["Mikhail Ageev, Qi Guo, Dmitry Lagun, and Eugene Agichtein. 2011. Find it if you can. In SIGIR’11. ACM Press, New York, NY, 345.", "Azzah Al-Maskari, Mark Sanderson, and Paul Clough. 2007. The relationship between IR effectiveness measures and user satisfaction. In SIGIR’07. ACM Press, New York, NY, 773.", "Rolph E. Anderson and Srini S. Srinivasan. 2003. E-satisfaction and e-loyalty: A contingency framework. Psychol. Market. 20, 2 (Feb. 2003), 123--138."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2893486"}, {"title": "Fast Video Deduplication via Locality Sensitive Hashing with Similarity Ranking", "authors": ["Yeguang Li\n,", "Ke Xia"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThe explosive growth of the massive video data brings great challenges to the fast video deduplication. There is encouraging progress of the deduplication techniques in the past few years, especially with the help of the binary hashing methods. However, till now there is rare work that studies the generic hash based framework and the efficient similarity ranking strategy for video deduplication. This paper proposes a flexible and fast video deduplication framework based on hash codes, which supports the hash table indexing using any existing hashing algorithm, and ranks the candidate videos by exploring the similarities among the key frames over multiple tables. Our experiments on the popular large-scale dataset demonstrate that the proposed framework can achieve satisfying performance in the task of video deduplication.", "references": ["J. L. Bentley. Multidimensional binary search trees used for associative searching. Commun. ACM, 18:509--517, 1975.", "Y. Cai, L. Yang, W. Ping, F. Wang, T. Mei, X.-S. Hua, and S. Li. Million-scale near-duplicate video retrieval system. In ACM MM, 2011.", "M. S. Charikar. Similarity estimation techniques from rounding algorithms. In ACM Symposium on Theory of Computing, pages 380--388, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007725"}, {"title": "Estimating Embedding Vectors for Queries", "authors": ["Hamed Zamani\n,", "W. Bruce Croft"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThe dense vector representation of vocabulary terms, also known as word embeddings, have been shown to be highly effective in many natural language processing tasks. Word embeddings have recently begun to be studied in a number of information retrieval (IR) tasks. One of the main steps in leveraging word embeddings for IR tasks is to estimate the embedding vectors of queries. This is a challenging task, since queries are not always available during the training phase of word embedding vectors. Previous work has considered the average or sum of embedding vectors of all query terms (AWE) to model the query embedding vectors, but no theoretical justification has been presented for such a model. In this paper, we propose a theoretical framework for estimating query embedding vectors based on the individual embedding vectors of vocabulary terms. We then provide a number of different implementations of this framework and show that the AWE method is a special case of the proposed framework. We also introduce pseudo query vectors, the query embedding vectors estimated using pseudo-relevant documents. We further extrinsically evaluate the proposed methods using two well-known IR tasks: query expansion and query classification. The estimated query embedding vectors are evaluated via query expansion experiments over three newswire and web TREC collections as well as query classification experiments over the KDD Cup 2005 test set. The experiments show that the introduced pseudo query vectors significantly outperform the AWE method.", "references": ["J. Bai, J.-Y. Nie, G. Cao, and H. Bouchard. Using Query Contexts in Information Retrieval. In SIGIR '07, pages 15--22, 2007.", "S. M. Beitzel, E. C. Jensen, O. Frieder, D. Grossman, D. D. Lewis, A. Chowdhury, and A. Kolcz. Automatic Web Query Classification Using Labeled and Unlabeled Training Data. In SIGIR '05, pages 581--582, 2005.", "S. M. Beitzel, E. C. Jensen, O. Frieder, D. D. Lewis, A. Chowdhury, and A. Kolcz. Improving Automatic Query Classification via Semi-Supervised Learning. In ICDM '05, pages 42--49, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970403"}, {"title": "Comparative Mining of B2C Web Sites by Discovering Web Database Schemas", "authors": ["C. I. Ezeife\n,", "Bindu Peravali"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nDiscovering potentially useful and previously unknown information or knowledge from heterogeneous web contents such as \"list all laptop prices from Walmart and Staples between 2013 and 2015 including make, type, screen size, CPU power, year of make\", would require the difficult task of finding the schema of web documents from different web pages, performing web content data integration, building their virtual or physical data warehouse integration before web content extraction and mining from the database. Wrappers that extract target information from web pages can be manual, semi-supervised or automatic systems. Automatic systems such as the WebOMiner system, use some data extraction techniques based on parsing the web page html source code into a document object model (DOM) tree, then traverse the DOM for pattern discovery. Some limitations of these existing systems include using complicated matching techniques such as tree matching, Finite state automata, not yielding accurate results for complex queries such as historical and derived.\nThis paper proposes building the WebOMiner S which uses web structure and content mining approaches on the DOM-tree html code to simplify and make more easily extendable, the web data extraction process of theWebOMiner system. TheWebOMiner system is based on non-deterministic finite state automata (NFA) to recognize and extract web different types (e.g., text, image, links, and lists). The proposed WebOMiner S replaces the use of NFA of the WebOMiner with a frequent structure finder algorithm which uses regular expression matching in Java xpath parser and methods (such as compile(),evaluate()) to dynamically discover the most frequent structure (which is the most frequently repeated blocks in the html code represented as tags < divclass = \" \" >) in the Dom tree. This approach eliminates the need for any supervised training or updating the wrapper for each new B2C web page making the approach simpler, more easily extendable and automated.", "references": ["E. Annoni and C. Ezeife. Modeling web documents as objects for automatic web content extraction-object-oriented web data model. In ICEIS (1), pages 91--100, 2009.", "C.-H. Chang and S.-C. Lui. Iepad: information extraction based on pattern discovery. In Proceedings of the 10th international conference on World Wide Web, pages 681--688. ACM, 2001.", "S. Chawathe, H. Garcia-Molina, J. Hammer, K. Ireland, Y. Papakonstantinou, J. Ullman, and J. Widom. The tsimmis project: Integration of heterogenous information sources. In Proceeding of IPSIâĂ &Zacute;94, Japan, March 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938522"}, {"title": "Diversifying Query Auto-Completion", "authors": ["Fei Cai\n,", "Ridho Reinanda\n,", "Maarten De Rijke"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nQuery auto-completion assists web search users in formulating queries with a few keystrokes, helping them to avoid spelling mistakes and to produce clear query expressions, and so on. Previous work on query auto-completion mainly centers around returning a list of completions to users, aiming to push queries that are most likely intended by the user to the top positions but ignoring the redundancy among the query candidates in the list. Thus, semantically related queries matching the input prefix are often returned together. This may push valuable suggestions out of the list, given that only a limited number of candidates can be shown to the user, which may result in a less than optimal search experience.\nIn this article, we consider the task of diversifying query auto-completion, which aims to return the correct query completions early in a ranked list of candidate completions and at the same time reduce the redundancy among query auto-completion candidates. We develop a greedy query selection approach that predicts query completions based on the current search popularity of candidate completions and on the aspects of previous queries in the same search session. The popularity of completion candidates at query time can be directly aggregated from query logs. However, query aspects are implicitly expressed by previous clicked documents in the search context. To determine the query aspect, we categorize clicked documents of a query using a hierarchy based on the open directory project. Bayesian probabilistic matrix factorization is applied to derive the distribution of queries over all aspects. We quantify the improvement of our greedy query selection model against a state-of-the-art baseline using two large-scale, real-world query logs and show that it beats the baseline in terms of well-known metrics used in query auto-completion and diversification. In addition, we conduct a side-by-side experiment to verify the effectiveness of our proposal.", "references": ["Rakesh Agrawal, Sreenivas Gollapudi, Alan Halverson, and Samuel Ieong. 2009. Diversifying search results. In WSDM’09. ACM, New York, NY, 5--14.", "Kevin Bache, David Newman, and Padhraic Smyth. 2013. Text-based measures of document diversity. In KDD’13. ACM, New York, NY, 23--31.", "Ziv Bar-Yossef and Naama Kraus. 2011. Context-sensitive query auto-completion. In WWW’11. ACM, New York, NY, 107--116."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910579"}, {"title": "Load pattern analysis of key accounts based on two-step clustering", "authors": ["Yujiao Li\n,", "Qingping Huang\n,", "Song Liu\n,", "Peng Liu"], "publication": "ICIIP '16: Proceedings of the 2016 International Conference on Intelligent Information Processing", "abstract": "ABSTRACT\nDifferent from traditional power load pattern analysis methods which classify power load according to industrial properties, the two-step clustering method based on data mining algorithms is used for analyzing the power load patterns of key accounts. This paper analyses the electricity load patterns by processing power usage data of key accounts based on two-step clustering and constructs load clustering analysis model. The index of mean index adequacy (MIA) and mean distance between curves (MDC) are used to evaluate clustering results and determine the optimal number of clustering. Based on an annual load data set of 150 key accounts which include 8 kinds of industries, the practical calculation examples are analyzed. Through the calculation examples, the correctness and the effectiveness of the proposed model are verified. The results show that the method provides reference for power supply departments in the load management of key accounts.", "references": ["Meng, A.B., Lu, H. M., and Li, H.L., et al. 2015. Electricity customer classification based on optimized FCM clustering by hybrid CSO. J. Power. Sys. Pro. and Cont. 43, 20 (Oct. 2015), 150--154.", "Wang, Z. Y., Cao, Y. J. 2007. Electric Power System Load Profiles Analysis. J. Proc. of the CSU-EPSA. 19, 3 (Jun. 2007), 62--65.", "Lu, J. C., Fan, W. G. 2014. Application of Data Mining Technology in Electric Power Enterprises in Era of Big Data. J. Elec. Power. 27, 9 (Sep. 2014), 88--93."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3028842.3028897"}, {"title": "Session details: Speech Analysis and Audio Retrieval", "authors": ["Leo Wanner"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3248660"}, {"title": "Towards detecting media bias by utilizing user comments", "authors": ["Sevgi Yigit-Sert\n,", "Ismail Sengor Altingovde\n,", "Özgür Ulusoy"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nAutomatic detection of media bias is an important and challenging problem. We propose to leverage user comments along with the content of the online news articles to automatically identify the latent aspects of a given news topic, as a first step of detecting the news resources that are biased towards a particular subset of such aspects.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003.", "A. Dallmann, F. Lemmerich, D. Zoller, and A. Hotho. Media bias in german online newspapers. In HT '15, pages 133--137, 2015.", "Y.-R. Lin, J. P. Bagrow, and D. Lazer. Quantifying bias in social and mainstream media. SIGWEB Newsl., pages 5:1--5:6, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908186"}, {"title": "SIGIR 2016 Workshop WebQA II: Web Question Answering Beyond Factoids", "authors": ["Alessandro Moschitti\n,", "Lluiís Márquez\n,", "Preslav Nakov\n,", "Eugene Agichtein\n,", "Charles Clarke\n,", "Idan Szpektor"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search engines have made great progress at answering factoid queries. However, they are not well-tailored for managing more complex questions, especially when they require explanation and/or description. The WebQA workshop series aims at exploring diverse approaches to answering questions on the Web. This year, particular emphasis will be given to Community Question Answering (CQA), where comments by the users engaged in the forum communities can be used to answer new questions. Questions posted on the Web can be short and ambiguous (similarly to Web queries to a search engine). These issues make the WebQA task more challenging than traditional QA, and finding the most effective approaches for it remains an open problem.\nUnlike the more formal conference format, the aim of this workshop is to bring together researchers in diverse areas working on this problem, including those from NLP, IR, social media and recommender systems communities. This workshop is specifically designed for the SIGIR audience. However, due to its format, its goal, as compared to the main conference, is to conduct a more focused and open discussion, encouraging the presentation of work in progress and late-breaking initial results in Web Question Answering. Both academic and industrial participation will be solicited, including keynotes and invited speakers.", "references": ["E. Agichtein, D. Carmel, C. L. Clarke, P. Paritosh, D. Pelleg, and I. Szpektor. Web question answering: Beyond factoids: SIGIR 2015 workshop. In SIGIR, 2015.", "E. Agichtein, D. Carmel, D. Harman, D. Pelleg, and Y. Pinter. Overview of the TREC 2015 LiveQA track. In TREC, 2015.", "A. Barrón-Cedeño, S. Filice, G. Da San Martino, S. Joty, L. Màrquez, P. Nakov, and A. Moschitti. Thread-level information for comment classification in community question answering. In ACL, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917767"}, {"title": "Viewing support system for multi-view videos", "authors": ["Xueting Wang"], "publication": "ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nMulti-view videos taken by multiple cameras from different angles are expected to be useful in a wide range of applications, such as web lecture broadcasting, concerts and sports viewing, etc. These videos can enhancing viewing experience of users' personal preference through means of virtual camera switching and controlling viewing interfaces. However, the increasing number of cameras burdens even experts on suitable viewpoint selection. Thus, my doctoral research goal is to construct a system providing convenient and high quality viewing support for personal multi-view video viewing. We intend to include 3 parts: automatic viewpoint sequence recommendation, multimodal user feedback analysis, and on-line recommendation updating. Prior works focused on automatic viewpoint sequence recommending considering contextual information and user preference. We proposed a context-dependent recommending model and improved by considering the spatio-temporal contextual information. Further work will concentrate on analyzing multimodal user feedback while viewing recommendations to detect the unsatisfactory timing and model the user preference of viewpoint switching. The switching records and multimodal feedback can be used for on-line recommendation updating to improve the personal viewing support.", "references": ["I. Ahmad. Multi-view video: get ready for next-generation television. IEEE Distributed Systems Online, 8(3):6–6, 2007.", "C. Chen, O. Wang, S. Heinzle, P. Carr, A. Smolic, and M. Gross. Computational sports broadcasting: Automated director assistance for live sports. In Proceedings of the IEEE International Conference on Multimedia and Expo (ICME), pages 1–6, 2013.", "R. T. Collins, O. Amidi, and T. Kanade. An active camera system for acquiring multi-view video. In Proceedings of the International Conference on Image Processing (ICIP), 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993148.2997613"}, {"title": "Selectively Personalizing Query Auto-Completion", "authors": ["Fei Cai\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuery auto-completion (QAC) is being used by many of today's search engines. It helps searchers formulate queries by providing a list of query completions after entering an initial prefix of a query. To cater for a user's specific information needs, personalized QAC strategies use a searcher's search history and their profile. Is personalization consistently effective in different search contexts?\nWe study the QAC problem by selectively personalizing the query completion list. Based on a lenient personalized QAC strategy that encodes the ranking signal as a trade-off between query popularity and search context, we propose a model for selectively personalizing query auto-completion (SP-QAC) to study this trade-off. We predict effective trade-offs based on a regression model, where the typed query prefix, clicked documents and preceding queries in the same session are used to weigh personalization in QAC. Experiments on the AOL query log show the SP-QAC model can significantly outperform a state-of-the-art personalized QAC approach.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In WWW '11, pages 107--116, 2011.", "F. Cai and M. de Rijke. Query auto completion in information retrieval. Found. Trends in Inform. Retr., 2016. To appear.", "F. Cai, S. Liang, and M. de Rijke. Time-sensitive personalized query auto-completion. In CIKM '14, pages 1599--1608, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914686"}, {"title": "Query Answering Efficiency in Expert Networks Under Decentralized Search", "authors": ["Liang Ma\n,", "Mudhakar Srivatsa\n,", "Derya Cansever\n,", "Xifeng Yan\n,", "Sue Kase\n,", "Michelle Vanni"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nExpert networks are formed by a group of expert-profes\\-sionals with different specialties to collaboratively resolve specific queries. In such networks, when a query reaches an expert who does not have sufficient expertise, this query needs to be routed to other experts for further processing until it is completely solved; therefore, query answering efficiency is sensitive to the underlying query routing mechanism being used. Among all possible query routing mechanisms, decentralized search, operating purely on each expert's local information without any knowledge of network global structure, represents the most basic and scalable routing mechanism. However, there is still a lack of fundamental understanding of the efficiency of decentralized search in expert networks. In this regard, we investigate decentralized search by quantifying its performance under a variety of network settings. Our key findings reveal the existence of network conditions, under which decentralized search can achieve significantly short query routing paths (i.e., between O(log n) and O(log2n) hops, n: total number of experts in the network). Based on such theoretical foundation, we then study how the unique properties of decentralized search in expert networks is related to the anecdotal small-world phenomenon. To the best of our knowledge, this is the first work studying fundamental behaviors of decentralized search in expert networks. The developed performance bounds, confirmed by real datasets, can assist in predicting network performance and designing complex expert networks.", "references": ["K. Balog, L. Azzopardi, and M. De Rijke, \"Formal models for expert finding in enterprise corpora,\" in ACM SIGIR, 2006.", "P. Serdyukov, H. Rode, and D. Hiemstra, \"Modeling multi-step relevance propagation for expert finding,\" in ACM CIKM, 2008.", "Q. Shao, Y. Chen, S. Tao, X. Yan, and N. Anerousis, \"Efficient ticket routing by resolution sequence mining,\" in ACM SIGKDD, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983652"}, {"title": "Picture-based Approach to Group Recommender Systems in the E-Tourism Domain", "authors": ["Amra Delic"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nThis PhD research aims to integrate group decision making into a personality based recommender systems in a domain with complex and emotional products i.e., e-tourism domain. In this domain, decisions, especially in groups, are often non rational. Based on the ongoing research on picture-based recommender systems at the e-commerce group, TU Wien and the software of Pixtri OG, the research will develop new methods to model group recommendations and support emotion-aware group decision processes, based on and evaluated by a world-wide study.", "references": ["D. Forsyth. Group Dynamics. Wadsworth Cengage Learning, 6th edition, 2014.", "H. Gibson and A. Yiannakis. Tourist roles: Needs and the lifecourse. Annals of tourism research, 29(2):358--383, 2002.", "L. Hu, J. Cao, G. Xu, L. Cao, Z. Gu, and W. Cao. Deep modeling of group preferences for group-based recommendation. In AAAI, pages 1861--1867. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930368"}, {"title": "Towards large-scale data discovery: position paper", "authors": ["Raul Castro Fernandez\n,", "Ziawasch Abedjan\n,", "Samuel Madden\n,", "Michael Stonebraker"], "publication": "ExploreDB '16: Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web", "abstract": "ABSTRACT\nWith thousands of data sources spread across multiple databases and data lakes, modern organizations face a data discovery challenge. Analysts spend more time finding relevant data to answer the questions at hand than analyzing it.\nIn this paper we introduce a data discovery system that facilitates locating relevant data among thousands of data sources. We represent data sources succinctly through signatures, and then create search paths that permit quick execution of a set of data discovery primitives used for finding relevant data. We have built a prototype that is being used to solve data discovery challenges of two big organizations.", "references": ["R. Agrawal and R. Srikant. Searching with Numbers. In WWW, 2002.", "M. J. Cafarella, A. Halevy, et al. WebTables: Exploring the Power of Tables on the Web. VLDB, 2008.", "A. Das Sarma, L. Fang, et al. Finding Related Tables. In SIGMOD, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948674.2948675"}, {"title": "DiFacto: Distributed Factorization Machines", "authors": ["Mu Li\n,", "Ziqi Liu\n,", "Alexander J. Smola\n,", "Yu-Xiang Wang"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nFactorization Machines offer good performance and useful embeddings of data. However, they are costly to scale to large amounts of data and large numbers of features. In this paper we describe DiFacto, which uses a refined Factorization Machine model with sparse memory adaptive constraints and frequency adaptive regularization. We show how to distribute DiFacto over multiple machines using the Parameter Server framework by computing distributed subgradients on minibatches asynchronously. We analyze its convergence and demonstrate its efficiency in computational advertising datasets with billions examples and features.", "references": ["A. Ahmed, N. Shervashidze, S. Narayanamurthy, V. Josifovski, and A. J. Smola. Distributed large-scale natural graph factorization. In World Wide Web Conference, Rio de Janeiro, 2013.", "R. M. Bell and Y. Koren. Lessons from the netflix prize challenge. SIGKDD Explorations, 9 (2): 75--79, 2007. URL http://doi.acm.org/10.1145/1345448.1345465.", "J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. Le, M. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Ng. Large scale distributed deep networks. In Neural Information Processing Systems, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835781"}, {"title": "Intent-Aware Diversification Using a Constrained PLSA", "authors": ["Jacek Wasilewski\n,", "Neil Hurley"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe intent-aware diversification framework was introduced initially in information retrieval and adopted to the context of recommender systems in the work of Vargas et al. The framework considers a set of aspects associated with items to be recommended. For instance, aspects may correspond to genres in movie recommendations. The framework depends on input aspect model consisting of item selection or relevance probabilities, given an aspect, and user intents, in the form of probabilities that the user is interested in each aspect. In this paper, we examine a number of input aspect models and evaluate the impact that different models have on the framework. In particular, we propose a constrained PLSA model that allows for interpretable output, in terms of known aspects, while achieving greater performance that the explicit co-occurrence counting method used in previous work. We evaluate the proposed models using a well-known MovieLens dataset for which item genres are available.", "references": ["O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. ACM CIKM '09 Conference Proceedings, pages 621--630, 2009.", "C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Büttcher, and I. MacKinnon. Novelty and Diversity in Information Retrieval Evaluation. ACM SIGIR'08 Conference Proceedings, page 659, 2008.", "C. Desrosiers and G. Karypis. A Comprehensive Survey of Neighborhood-based Recommendation Methods. Recommender Systems Handbook, 54:107--144, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959177"}, {"title": "Scalability of Continuous Active Learning for Reliable High-Recall Text Classification", "authors": ["Gordon V. Cormack\n,", "Maura R. Grossman"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nFor finite document collections, continuous active learning ('CAL') has been observed to achieve high recall with high probability, at a labeling cost asymptotically proportional to the number of relevant documents. As the size of the collection increases, the number of relevant documents typically increases as well, thereby limiting the applicability of CAL to low-prevalence high-stakes classes, such as evidence in legal proceedings, or security threats, where human effort proportional to the number of relevant documents is justified. We present a scalable version of CAL ('S-CAL') that requires O(log N) labeling effort and O(N log N) computational effort---where N is the number of unlabeled training examples---to construct a classifier whose effectiveness for a given labeling cost compares favorably with previously reported methods. At the same time, S-CAL offers calibrated estimates of class prevalence, recall, and precision, facilitating both threshold setting and determination of the adequacy of the classifier.", "references": ["Da Silva Moore v. Publicis Groupe. 287 F.R.D. 182, S.D.N.Y., 2012.", "Case Management Order: Protocol Relating to the Production of Electronically Stored Information (\"ESI\"). In In Re: Actos (Pioglitazone) Products Liability Litigation. MDL No. 6:11-md-2299, W.D. La., July 27, 2012.", "M. Bagdouri, D. D. Lewis, and D. W. Oard. Sequential testing in classifier evaluation yields biased estimates of effectiveness. In SIGIR 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983776"}, {"title": "Luhn Revisited: Significant Words Language Models", "authors": ["Mostafa Dehghani\n,", "Hosein Azarbonyad\n,", "Jaap Kamps\n,", "Djoerd Hiemstra\n,", "Maarten Marx"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUsers tend to articulate their complex information needs in only a few keywords, making underspecified statements of request the main bottleneck for retrieval effectiveness. Taking advantage of feedback information is one of the best ways to enrich the query representation, but can also lead to loss of query focus and harm performance in particular when the initial query retrieves only little relevant information when overfitting to accidental features of the particular observed feedback documents. Inspired by the early work of Luhn [23], we propose significant words language models of feedback documents that capture all, and only, the significant shared terms from feedback documents. We adjust the weights of common terms that are already well explained by the document collection as well as the weight of rare terms that are only explained by specific feedback documents, which eventually results in having only the significant terms left in the feedback model.\nOur main contributions are the following. First, we present significant words language models as the effective models capturing the essential terms and their probabilities. Second, we apply the resulting models to the relevance feedback task, and see a better performance over the state-of-the-art methods. Third, we see that the estimation method is remarkably robust making the models in- sensitive to noisy non-relevant terms in feedback documents. Our general observation is that the significant words language models more accurately capture relevance by excluding general terms and feedback document specific terms.", "references": ["N. Abdul-jaleel, J. Allan, W. B. Croft, O. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. Umass at trec 2004: Novelty and hard. In TREC-13, 2004.", "C. Buckley and S. Robertson. Relevance feedback track overview: Trec 2008. In TREC 2008, 2008.", "C. Buckley, M. Lease, and S. M. D. Overview of the trec 2010 relevance feedback track. In TREC 2010, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983814"}, {"title": "Interleaved Evaluation for Retrospective Summarization and Prospective Notification on Document Streams", "authors": ["Xin Qian\n,", "Jimmy Lin\n,", "Adam Roegiest"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe propose and validate a novel interleaved evaluation methodology for two complementary information seeking tasks on document streams: retrospective summarization and prospective notification. In the first, the user desires relevant and non-redundant documents that capture important aspects of an information need. In the second, the user wishes to receive timely, relevant, and non-redundant update notifications for a standing information need. Despite superficial similarities, interleaved evaluation methods for web ranking cannot be directly applied to these tasks; for example, existing techniques do not account for temporality or redundancy. Our proposed evaluation methodology consists of two components: a temporal interleaving strategy and a heuristic for credit assignment to handle redundancy. By simulating user interactions with interleaved results on submitted runs to the TREC 2014 tweet timeline generation (TTG) task and the TREC 2015 real-time filtering task, we demonstrate that our methodology yields system comparisons that accurately match the result of batch evaluations. Analysis further reveals weaknesses in current batch evaluation methodologies to suggest future directions for research.", "references": ["E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. SIGIR, 2006.", "J. Aslam, M. Ekstrand-Abueg, V. Pavlu, F. Diaz, R. McCreadie, and T. Sakai. TREC 2014 Temporal Summarization Track overview. TREC, 2014.", "O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):Article 6, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911494"}, {"title": "Mining parallel corpora from sina weibo and twitter", "authors": ["Wang Ling\n,", "Luís Marujo\n,", "Chris Dyer\n,", "Alan W. Black\n,", "Isabel Trancoso"], "publication": "Computational Linguistics", "abstract": "Abstract\nMicroblogs such as Twitter, Facebook, and Sina Weibo China's equivalent of Twitter are a remarkable linguistic resource. In contrast to content from edited genres such as newswire, microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles. In this work, we show that some microblog users post \"self-translated\" messages targeting audiences who speak different languages, either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language. We introduce a method for finding and extracting this naturally occurring parallel data. Identifying the parallel content requires solving an alignment problem, and we give an optimally efficient dynamic programming algorithm for this. Using our method, we extract nearly 3M Chinese-English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages. Additionally, from a random sample of Twitter, we obtain substantial amounts of parallel data in multiple language pairs. Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as in terms of utility as training data for a Chinese-English machine translation system. Relative to traditional parallel data resources, the automatically extracted parallel data yield substantial translation quality improvements in translating microblog text and modest improvements in translating edited news content.", "references": ["Ambati, Vamshi and Stephan Vogel. 2010. Can crowds build parallel corpora for machine translation systems? In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk, CSLDAMT '10, pages 62-65, Stroudsburg, PA.", "Ambati, Vamshi, Stephan Vogel, and Jaime Carbonell. 2012. Collaborative workflow for crowdsourcing translation. In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work, CSCW '12, pages 1191-1194, New York, NY.", "Bergsma, Shane, Paul McNamee, Mossaab Bagdouri, Clayton Fink, and Theresa Wilson. 2012. Language identification for creating language-specific Twitter collections. In Proceedings of the Second Workshop on Language in Social Media, LSM '12, pages 65-74, Stroudsburg, PA."], "doi_url": "https://dl.acm.org/doi/abs/10.1162/COLI_a_00249"}, {"title": "Playing Your Cards Right: The Effect of Entity Cards on Search Behaviour and Workload", "authors": ["Horatiu Bota\n,", "Ke Zhou\n,", "Joemon M. Jose"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nIn addition to merging results of different types (e.g.~images, videos, news items) into a ranked list of Web documents, modern search engines have also started displaying entity cards (ECs) on the results page. Entity cards are intended to enhance search experience in several ways: (i) they help searchers navigate diversified results, (ii) provide a summary of relevant content directly on the results page and (iii) support exploratory search by highlighting relevant entities associated with a given user query. We conducted a large-scale crowd-sourced user study, with more than $700$ unique searchers, to investigate the effects of entity cards on search behaviour and perceived workload. We find that the presence of ECs has a strong effect on both the way users interact with search results and their perceived task workload. Furthermore, by manipulating EC properties content, coherence and vertical diversity), we uncover different effects and interactions between card properties on measures of search behaviour and workload. Our study contributes an in-depth analysis of the effects of entity cards on user interaction with modern Web search interfaces.", "references": ["J. Arguello and R. Capra. The effect of aggregated search coherence on search behavior. ACM CIKM '12, pages 1293--1302.", "J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. ACM CIKM '14, pages 539--548, 2014.", "J. Arguello, R. Capra, and W.-C. Wu. Factors affecting aggregated search coherence and search behavior. ACM CIKM '13, pages 1989--1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854967"}, {"title": "Modelling Contextual Information in Session-Aware Recommender Systems with Neural Networks", "authors": ["Bartłomiej Twardowski"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPreparing recommendations for unknown users or such that correctly respond to the short-term needs of a particular user is one of the fundamental problems for e-commerce. Most of the common Recommender Systems assume that user identification must be explicit. In this paper a Session-Aware Recommender System approach is presented where no straightforward user information is required. The recommendation process is based only on user activity within a single session, defined as a sequence of events. This information is incorporated in the recommendation process by explicit context modeling with factorization methods and a novel approach with Recurrent Neural Network (RNN). Compared to the session modeling approach, RNN directly models the dependency of user observed sequential behavior throughout its recurrent structure. The evaluation discusses the results based on sessions from real-life system with ephemeral items (identified only by the set of their attributes) for the task of top-n best recommendations.", "references": ["D. Gayo-Avello. A survey on session detection methods in query logs and a proposal for future evaluation. Information Sciences, 179(12), 2009.", "B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. Session-based Recommendations with Recurrent Neural Networks. International Conference on Learning Representations, 2016.", "B. Hidasi and D. Tikk. General factorization framework for context-aware recommendations. Data Mining and Knowledge Discovery, 30, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959162"}, {"title": "Effective Speaker Retrieval and Recognition through Vector Quantization and Unsupervised Distance Learning", "authors": ["Victor de Abreu Campos\n,", "Daniel Carlos Guimarães Pedronette"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nThe huge amount of multimedia content accumulated daily has demanded the development of effective retrieval approaches. In this context, speaker recognition methods capable of automatically identifying a person through their voice is of great relevance. This paper presents a novel speaker recognition approach modelled in a retrieval scenario and using a recent unsupervised learning method. The proposed approach considers MFCC features and a Vector Quantization model to compute distances among audio objects. Next, a rank-based unsupervised learning method is used for improving the effectiveness of retrieval results. Several experiments were conducted considering three public datasets with different settings, such as background noise from diverse sources. Experimental results demonstrate that the proposed approach can achieve very high effectiveness results. In addition, effectiveness gains up to +27\\% were obtained by the unsupervised learning procedure.", "references": ["FalaBrasil Project. On-line at http://www.laps.ufpa.br/falabrasil. Acessed 04 March 2016.", "Youtube search for Google Tech Talks. On-line at https://www.youtube.com/results?q=GoogleTechTalks. Acessed 04 March 2016.", "M. Anusuya and S. Katti. Front end analysis of speech recognition: a review. International Journal of Speech Technology, 14(2):99--145, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2927006.2927010"}, {"title": "Remote Sensing Noise Reduction Using Minimum Patch Based on OMP", "authors": ["Ramandeep Kaur\n,", "Kamaljit Kaur"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn recent years, the technology of the remote sensing is growing rapidly. Image enhancement is one of most commonly used of image processing operations. Noise reduction plays very important role in digital image processing and various technologies have been locate ahead to reduce the noise of the remote sensing images. The noise reduction using wavelet coefficients based on Orthogonal Matching Pursuit (OMP) has less consequences on the edges than available methods but this is not as establish in edge preservation techniques. So in this paper we provide a new technique minimum patch based noise reduction OMP which reduce the noise from an image and used edge preservation patch which preserve the edges of the image and presents the superior results than existing OMP technique. Experimental results show that the proposed minimum patch approach outperforms over existing techniques.", "references": ["V. Ahirwar, H. Yadav, A. Jain, \"Hybrid model for preserving brightness over the digital image processing,\" in Computer and Communication Technology (ICCCT), 2013 4th International Conference on, vol., no., pp. 48--53, 20-22 Sept. 2013.", "Tian Xiurong, \"The application of adaptive unsharp mask algorithm in medical image enhancement,\" in Cross Strait Quad-Regional Radio Science and Wireless Technology Conference (CSQRWC), 2011, vol.2, no., pp. 1368--1370, 26-30 July 2011.", "Shih-Chia Huang, Chien Hui Yeh., \"Image contrast enhancement for preserving mean brightness without losing image features\", in Engineering Applications of Artificial Intelligence 26 (2013) 1487--1492."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015168"}, {"title": "Hadoop based collaborative recommendation system", "authors": ["Harsh Varudkar"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\n21st century is of information and internet. Internet usage is spread across whole globe. Ecommerce market and social media are generator of rapid growth of information and data. Users' view towards market is changing rapidly. One such situation recommendation systems are great tool for users to find the better product or interest based services without crawling the whole internet. Information filtering system have a subclass called recommender systems. Collaborative recommendation system is a type of recommendation system. Recommendation system are not only useful for end users but as per industry aspect it is a very useful for understanding trends and do some analytics. But the data which has to be analyzed is in very huge amount. Analyzing such amount of data may take time as well as data handling is also difficult in normal systems. Distributed environment like Hadoop will provide good scalability to generate recommendation and handle huge amount of data.", "references": ["Bellogin, A., Castells, P., & Cantador, I. (2014). Neighbor selection and weighting in user-based collaborative filtering: A performance prediction approach. ACM Transactions on the Web (TWEB) Volume 8 Issue 2, March 2014, Article No. 12", "Shi, Y., Larson, M., & Hanjalic, A. (2014). Collaborative filtering beyond the user-item matrix: A survey of the state of the art and future challenges, ACM Comput. Surv.. (CSUR)", "CAI, Y., LEUNG, H. F., LI, Q., MIN, H. Q., HAN, H., TANG, J. and LI, J. Z., 2014. Typicality-based Collaborative Filtering Recommendation. IEEE Trans. Knowl. Data Eng., 26(3). IEEE Computer Society"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905353"}, {"title": "ADS: the adaptive data series index", "authors": ["Kostas Zoumpatianos\n,", "Stratos Idreos\n,", "Themis Palpanas"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nNumerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available. This, however, is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. We present a detailed design and evaluation of our method using approximate and exact query algorithms with both synthetic and real data sets. Adaptive indexing significantly outperforms previous solutions, gracefully handling large data series collections, reducing the data to query delay: By the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), our method has already answered $$3*10^5$$3ź105 queries.", "references": ["Huijse, P., Estévez, P.A., Protopapas, P., Principe, J.C., Zegers, P.: Computational intelligence challenges and applications on large-scale astronomical time series databases. IEEE Comput. Intell. Mag. 9(3), 27---39 (2014)", "Kashino, K., Smith, G., Murase, H.: Time-series active search for quick retrieval of audio and video. In: ICASSP (1999)", "Raza, U., Camerra, A., Murphy, A.L., Palpanas, T., Picco, G.P.: Practical data prediction for real-world wireless sensor networks. IEEE Trans. Knowl. Data Eng. 27(8), 2231---2244 (2015)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0442-5"}, {"title": "Text Summarization", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915048"}, {"title": "Anonymizing Query Logs by Differential Privacy", "authors": ["Sicong Zhang\n,", "Hui Yang\n,", "Lisa Singh"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuery logs are valuable resources for Information Retrieval (IR) research. However, because they are also rich in private and personal information, the huge concern of leaking user privacy prevents query logs from being shared from the search companies to the broad research community. Bothered by the lack of good research data for years, the authors of this paper are motivated to explore ways to generate anonymized query logs that can still be effectively used to support the search task. We introduce a framework to anonymize query logs by differential privacy, the latest development in privacy research. The framework is empirically evaluated against multiple search algorithms on their retrieval utility, measured in standard IR evaluation metrics, using the anonymized logs. The experiments show that our framework is able to achieve a good balance between retrieval utility and privacy.", "references": ["E. Adar. User 4xxxxx9: Anonymizing query logs. In Query Logs Workshop at the WWW'07.", "E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR '06.", "C. Carpineto and G. Romano. Semantic search log k-anonymization with generalized k-cores of query concept graph. In ECIR'13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914732"}, {"title": "Session details: Main Track - Requirements Engineering in IS", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255986"}, {"title": "Risk Assessment of Pregnant Women Access to Basic Healthcare Units", "authors": ["Edmir P.V. Prado\n,", "Eunice Almeida Silva"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nAccessibility is an essential condition for the full exercise of citizenship and a civic right that should not be denied to any citizen. Nevertheless, there are many architectural barriers found in urban areas, such as broken and narrow sidewalks, slippery surfaces, stairs and ramps excessively steep, among others. People with locomotion difficulties, whether permanent or temporary, are the public who suffer most from lack of access to planned areas, especially to public healthcare services, essential to the well-being of the population. In this context, this paper implemented a system to assess the risk of pregnant women to access Basic Health Units (UBS). The system was applied in two basic health units and we found that 35% of pregnant women are exposed to high or medium risk of health complications due to obstacles on the path to healthcare units..", "references": ["Silva, E. A. 2012. Sociologia aplicada a enfermagem. Ed. Manole: Sao Paulo.", "BRASIL, Ministerio da Saude. 2002. Programa Humanizacao do Parto, Humanizacao do Pre-Natal e Nascimento.http://bvsms.saude.gov.br/bvs/publicacoes/parto.pdf. Acesso em 18/04/2015", "Pagliuca, L. M. F., Aragao, A.E. A., Almeida, P. C. 2007. Acessibilidade e deficiencia fisica: identificacao de barreiras arquitetonicas em areas internas de hospitais de Sobral, Ceara. Revista da Escola de Enfermagem da USP, 41, 4, 581-588."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022000"}, {"title": "On the Effects of Spam Filtering and Incremental Learning for Web-Supervised Visual Concept Classification", "authors": ["Matthias Springstein\n,", "Ralph Ewerth"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nDeep neural networks have been successfully applied to the task of visual concept classification. However, they require a large number of training examples for learning. Although pre-trained deep neural networks are available for some domains, they usually have to be fine-tuned for an envisaged target domain. Recently, some approaches have been suggested that are aimed at incrementally (or even endlessly) learning visual concepts based on Web data. Since tags of Web images are often noisy, normally some filtering mechanisms are employed in order to remove ``spam'' images that are not appropriate for training. In this paper, we investigate several aspects of a web-supervised system that has to be adapted to another target domain: 1.) the effect of incremental learning, 2.) the effect of spam filtering, and 3.) the behavior of particular concept classes with respect to 1.) and 2.). The experimental results provide some insights under which conditions incremental learning and spam filtering are useful.", "references": ["K. Chatfield, R. Arandjelović, O. Parkhi, and A. Zisserman. On-the-fly learning for visual search of large-scale image and video datasets. International Journal of Multimedia Information Retrieval, 4(2):75--93, 2015.", "X. Chen and A. Gupta. Webly supervised learning of convolutional networks. arXiv preprint arXiv:1505.01554, 2015.", "X. Chen, A. Shrivastava, and A. Gupta. Neil: Extracting visual knowledge from web data. In IEEE International Conference on Computer Vision (ICCV), pages 1409--1416. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912072"}, {"title": "Selective Exploration of Commercial Documents in Web Search", "authors": ["Alexander Shishkin\n,", "Ekaterina Gladkikh\n,", "Aleksandr Vorobev"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nImplicit user feedback is known to be a strong signal of user preferences in web search. Hence, solving the exploration-exploitation dilemma [5] became an important direction of improvement of ranking algorithms in the last years. In this poster, in the case of commercial queries, we consider a new negative effect of exploration on the user utility -- distracting and confusing users by shifting well-known documents from their common positions -- and propose an approach to take it into account within Multi-Armed Bandit algorithms, usually applied to solve the dilemma.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR'2006, pages 19--26. ACM, 2006.", "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2--3):235--256, 2002.", "H. K. Dai, L. Zhao, Z. Nie, J.-R. Wen, L. Wang, and Y. Li. Detecting online commercial intention (oci). In WWW'2006, pages 829--837. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889376"}, {"title": "Background", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915034"}, {"title": "A Context-aware Time Model for Web Search", "authors": ["Alexey Borisov\n,", "Ilya Markov\n,", "Maarten de Rijke\n,", "Pavel Serdyukov"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn web search, information about times between user actions has been shown to be a good indicator of users' satisfaction with the search results. Existing work uses the mean values of the observed times, or fits probability distributions to the observed times. This implies a context-independence assumption that the time elapsed between a pair of user actions does not depend on the context, in which the first action takes place. We validate this assumption using logs of a commercial web search engine and discover that it does not always hold. For between 37% to 80% of query-result pairs, depending on the number of observations, the distributions of click dwell times have statistically significant differences in query sessions for which a given result (i) is the first item to be clicked and (ii) is not the first. To account for this context bias effect, we propose a context-aware time model (CATM). The CATM allows us (i) to predict times between user actions in contexts, in which these actions were not observed, and (ii) to compute context-independent estimates of the times by predicting them in predefined contexts. Our experimental results show that the CATM provides better means than existing methods to predict and interpret times between user actions.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, pages 19--26. ACM, 2006.", "E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In SIGIR, pages 3--10. ACM, 2006.", "J. Arguello. Predicting search task difficulty. In Advances in Information Retrieval, pages 88--99. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911504"}, {"title": "Automated Identification of Classes Using Natural Language Processing", "authors": ["Daniel Antonio Conte\n,", "Jean C.R. Hauck"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe correct and sufficient documentation of an information system tends to facilitate its maintenance. In this sense, the class diagram is an important UML artifact for the design of an objectoriented information system. The development of this type of diagram, however, is often costly and complex because it involves different roles and a thorough knowledge of the domain area. Some experiences have demonstrated the feasibility of the automated generation of class diagrams, and the analysis based on descriptions is one of the possible techniques. This study aims to apply natural language processing to support the development of the class diagram. For this, an application prototype is modeled and implemented in order to validate the proposal. The initial evaluation of the use of the tool was considered satisfactory.", "references": ["Abbott, R. J. 1983. Program design by informal English descriptions. Communications of the ACM, 26(11), 882-894.", "Bezerra, E. 2006. Principios De Analise E Projeto De Sistemas Com Uml-3a Edicao (Vol. 3). Elsevier Brasil.", "Dias, F., Morgado, G., Oscar, P., da Silveira, D. S., Alencar, A. J., Lima, P., e Schmitz, E. A. 2006. Uma Abordagem para a Transformacao Automatica do Modelo de Negocio em Modelo de Requisitos. In WER (pp. 51-60)"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022006"}, {"title": "Object-aware Deep Network for Commodity Image Retrieval", "authors": ["Zhiwei Fang\n,", "Jing Liu\n,", "Yuhang Wang\n,", "Yong Li\n,", "Song Hang\n,", "Jinhui Tang\n,", "Hanqing Lu"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nRecent years, with the development of e-commerce and population of mobile phones, image-based commodity retrieval has attracted much attention. This paper proposed a deep framework for commodity image retrieval(CMIR) from the view that they are same designed commodities. Our framework can catch as many design details as possible by exploring object detection and ranking sensitive feature learning, while the former is performed based on Faster R-CNN, and the later is learned with a multi-task Siamese Network. Besides, we refine the processing speed of the framework to make it a live system. Our framework is implemented on an android application based on Client/Server structure model whose server response time is about 150 ms per query.", "references": ["K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In British Machine Vision Conference, 2014.", "J. Cheng, C. Leng, J. Wu, H. Cui, H. Lu, et al. Fast and accurate image matching with cascade hashing for 3d reconstruction. CVPR. IEEE, 2014.", "S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 539--546 vol. 1, June 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912027"}, {"title": "Simulating Interactive Information Retrieval: SimIIR: A Framework for the Simulation of Interaction", "authors": ["David Maxwell\n,", "Leif Azzopardi"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSimulation provides a powerful and cost-effective approach to explore and evaluate how interactions between a searcher and system influence search behaviour and performance. With a growing interest in simulation and an increasing number of papers using such an approach, there is a need for a flexible framework for simulation. Thus, we present SimIIR, an open-source toolkit for building and conducting Interactive Information Retrieval (IIR) experiments. The framework consists of a number of high level components, including the simulation, the searcher and the system, all of which must be configured. The SimIIR framework provides a series of interchangeable components. Examples of these components include the querying strategies (how simulated queries are formulated) and stopping strategies (the depth to which a searcher will examine snippets and documents) that a simulated searcher will employ. We have implemented various existing strategies so that they can be used by other researchers to not only replicate and reproduce past experiments, but also create new experiments. This paper describes the SimIIR framework and the different components that can be configured and extended as required.", "references": ["L. Azzopardi. Query side evaluation: An empirical analysis of effectiveness and effort. In Proceedings of the 32nd ACM SIGIR, pages 556--563, 2009.", "L. Azzopardi. The economics in interactive information retrieval. In Proc. 34th ACM SIGIR, pages 15--24, 2011.", "L. Azzopardi, M. de Rijke, and K. Balog. Building simulated queries for known-item topics: An analysis using six european languages. In Proc. 30th ACM SIGIR, pages 455--462, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911469"}, {"title": "Diverse Yet Efficient Retrieval using Locality Sensitive Hashing", "authors": ["Vidyadhar Rao\n,", "Prateek Jain\n,", "C.V. Jawahar"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nTypical retrieval systems have three requirements: a) Accurate retrieval, i.e., the method should have high precision, b) Diverse retrieval, i.e., the obtained set of samples should be diverse, and c) Retrieval time should be small. However, most of the existing methods address only one or two of the above mentioned requirements. In this work, we present a method based on randomized locality sensitive hashing which tries to address all of the above requirements simultaneously. While earlier hashing-based approaches considered approximate retrieval to be acceptable only for the sake of efficiency, we argue that one can further exploit approximate retrieval to provide impressive trade-offs between accuracy and diversity. We also extend our method to the problem of multi-label prediction, where the goal is to output a diverse and accurate set of labels for a given document in real-time. Finally, we present empirical results on image and text retrieval tasks and show that our method retrieves diverse and accurate images/labels while ensuring 100x-speed-up over the existing diverse retrieval approaches.", "references": ["R. Agrawal, A. Gupta, Y. Prabhu, and M. Varma. Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages. In WWW, 2013.", "A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In FOCS, 2006.", "T. Aytekin and M. Ö. Karakaya. Clustering-based diversity improvement in top-n recommendation. IIS, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2911998"}, {"title": "Domain-Aware Grade Prediction and Top-n Course Recommendation", "authors": ["Asmaa Elbadrawy\n,", "George Karypis"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAutomated course recommendation can help deliver personalized and effective college advising and degree planning. Nearest neighbor and matrix factorization based collaborative filtering approaches have been applied to student-course grade data to help students select suitable courses. However, the student-course enrollment patterns exhibit grouping structures that are tied to the student and course academic features, which lead to grade data that are not missing at random (NMAR). Existing approaches for dealing with NMAR data, such as Response-aware and context-aware matrix factorization, do not model NMAR data in terms of the user and item features and are not designed with the characteristics of grade data in mind. In this work we investigate how the student and course academic features influence the enrollment patterns and we use these features to define student and course groups at various levels of granularity. We show how these groups can be used to design grade prediction and top-n course ranking models for neighborhood-based user collaborative filtering, matrix factorization and popularity-based ranking approaches. These methods give lower grade prediction error and more accurate top-n course rankings than the other methods that do not take domain knowledge into account.", "references": ["G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Trans. Inf. Syst., 23(1), 2005.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '09, pages 19--28. ACM, 2009.", "D. Agarwal, B.-C. Chen, and B. Long. Localized factor models for multi-context recommendation. In SIGKDD, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959133"}, {"title": "Applying a tendency to be well retweeted to false information detection", "authors": ["Zen Yoshida\n,", "Masayoshi Aritsugi"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nWhile a lot of useful information can be found in SNS, false information also diffuses through it, thereby confusing many people sometimes. In this paper, we predict a tendency of tweets to be well retweeted and consider applying the tendency to false information detection. The tendency prediction can be implemented with simple features of tweets. We examine the effect of the tendency when it is used in false information detection empirically. Our experimental results indicate that it would be valuable to take the tendency into account for the detection. We also discuss findings when applying them to tweets in Japanese.", "references": ["E. F. Can, H. Oktay, and R. Manmatha. Predicting retweet count using visual cues. In Proceedings of the 22nd ACM International Conference on Information & Knowledge Management, CIKM '13, pages 1481--1484, New York, NY, USA, 2013. ACM.", "C. Castillo, M. Mendoza, and B. Poblete. Information credibility on twitter. In Proceedings of the 20th International Conference on World Wide Web, WWW '11, pages 675--684, New York, NY, USA, 2011. ACM.", "A. Gupta and P. Kumaraguru. Credibility ranking of tweets during high impact events. In Proceedings of the 1st Workshop on Privacy and Security in Online Social Media, PSOSM '12, pages 2:2--2:8, New York, NY, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011199"}, {"title": "Practical Private Range Search Revisited", "authors": ["Ioannis Demertzis\n,", "Stavros Papadopoulos\n,", "Odysseas Papapetrou\n,", "Antonios Deligiannakis\n,", "Minos Garofalakis"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nWe consider a data owner that outsources its dataset to an untrusted server. The owner wishes to enable the server to answer range queries on a single attribute, without compromising the privacy of the data and the queries. There are several schemes on \"practical\" private range search (mainly in Databases venues) that attempt to strike a trade-off between efficiency and security. Nevertheless, these methods either lack provable security guarantees, or permit unacceptable privacy leakages. In this paper, we take an interdisciplinary approach, which combines the rigor of Security formulations and proofs with efficient Data Management techniques. We construct a wide set of novel schemes with realistic security/performance trade-offs, adopting the notion of Searchable Symmetric Encryption (SSE) primarily proposed for keyword search. We reduce range search to multi-keyword search using range covering techniques with tree-like indexes. We demonstrate that, given any secure SSE scheme, the challenge boils down to (i) formulating leakages that arise from the index structure, and (ii) minimizing false positives incurred by some schemes under heavy data skew. We analytically detail the superiority of our proposals over prior work and experimentally confirm their practicality.", "references": ["B. H. Bloom. Space/Time Trade-offs in Hash Coding with Allowable Errors. Commun. of the ACM, 1970.", "A. Boldyreva, N. Chenette, Y. Lee, and A. O Neill. Order-Preserving Symmetric Encryption. In EUROCRYPT, 2009.", "A. Boldyreva, N. Chenette, and A. O'Neill. Order-Preserving Encryption Revisited: Improved Security Analysis and Alternative Solutions. In CRYPTO, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2882911"}, {"title": "Multiple View Interactive Environment to Analyze Software Product Line Tools", "authors": ["Kattiana Constantino\n,", "Eduardo Figueiredo\n,", "Glauco Carneiro\n,", "Raquel Minardi"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nSoftware Product Line (SPL) relies on the development of a collection of information systems from a shared set of software assets. In this context, the adoption of SPL in the industry relies heavily on tool support. This paper presents ViSPLatform, a visualization environment aimed at portraying data related to experiments focusing on SPL tools. We conducted a preliminary evaluation to analyze to which extent the platform is effective to support the understanding of characteristics of the SPL tools. The results of this study show that ViSPLatform can somehow indicate strengths and improvement opportunities in the analyzed SPL tools. For instance, they show that Automatic Analysis is a strength of the SPLOT tool and that Interface is an improvement opportunity", "references": ["D. S. Batory. Feature models, grammars and propositional formulas. In 9th Int. SPLs Conf. (SPLC), 2005.", "M. Bostock, V. Ogievetsky, and J. Heer. D3 data-driven documents. IEEE Transactions on Visualization and Comp. Graphics, 17(12), 2011.", "G. Botterweck, S. Thiel, C. Cawley, D. Nestor, and A. Preussner. Visual configuration in automotive software product lines. In 32nd Annual IEEE Int. Comp. Soft. and Appl. Conf. (COMPSAC), 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021996"}, {"title": "UCFrame: A Use Case Framework for Crowd-Centric Requirement Acquisition", "authors": ["Wei-Chung Hu\n,", "Hewijin Christine Jiau"], "publication": "ACM SIGSOFT Software Engineering Notes", "abstract": "Abstract\nTo build needed mobile applications in specific domains, requirements should be collected and analyzed in holistic approach. However, resource is limited for small vendor groups to perform holistic requirement acquisition and elicitation. The rise of crowdsourcing and crowdfunding gives small vendor groups new opportunities to build needed mobile applications for the crowd. By finding prior stakeholders and gathering requirements effectively from the crowd, mobile application projects can establish sound foundation in early phase of software process. Therefore, integration of crowd-based requirement engineering into software process is important for small vendor groups. Conventional requirement acquisition and elicitation methods are analyst-centric. Very little discussion is in adapting requirement acquisition tools for crowdcentric context. In this study, several tool features of use case documentation are revised in crowd-centric context. These features constitute a use case-based framework, called UCFrame, for crowd-centric requirement acquisition. An instantiation of UCFrame is also presented to demonstrate the effectiveness of UCFrame in collecting crowd requirements for building two mobile applications.", "references": ["P. Abrahamsson, A. Hanhineva, H. Hulkko, T. Ihme, J. Jäälinoja, M. Korkala, J. Koskela, P. Kyllönen, and O. Salo. Mobile-D: An Agile Approach for Mobile Application Development. In Companion Proceedings of the 19th Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications, pages 174--175, 2004.", "T. A. Alspaugh and A. I. Antón. Scenario Support for Effective Requirements. Information and Software Technology, 50(3):198--220, Feb. 2008.", "B. Anda and D. I. K. Sjøberg. Towards an Inspection Technique for Use Case Models. In Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering, pages 127--134, July 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2894784.2894795"}, {"title": "Real-time Filtering on Interest Profiles in Twitter Stream", "authors": ["Yue Fei\n,", "Chao Lv\n,", "Yansong Feng\n,", "Dongyan Zhao"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe advent of Twitter has led to the ubiquitous information overload problem with a dramatic increase in the amount of tweets a user is exposed to. In this paper, we consider real-time tweet filtering with respect to users' interest profiles in public Twitter stream. While traditional filtering methods mainly focus on judging relevance of a document, we aim to retrieve relevant and novel documents to address the high redundancy of tweets. An unsupervised approach is proposed to model relevance between tweets and different profiles adaptively and a neural network language model is employed to learn semantic representation for tweets. Experiments on TREC 2015 dataset demonstrate the effectiveness of the proposed approach.", "references": ["M. Albakour, C. Macdonald, I. Ounis, et al. On sparsity and drift for effective real-time filtering in microblogs. In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management, pages 419--428. ACM, 2013.", "Y. Fei, Y. Hong, and J. Yang. Handling topic drift for topic tracking in microblogs. In Advances in Information Retrieval, pages 477--488. Springer, 2015.", "Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. arXiv preprint arXiv:1405.4053, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925462"}, {"title": "Approximate Asymmetric Search for Binary Embedding Codes", "authors": ["Chih-Yi Chiu\n,", "Yu-Cyuan Liou\n,", "Amorntip Prayoonwong"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nIn this article, we propose a method of approximate asymmetric nearest-neighbor search for binary embedding codes. The asymmetric distance takes advantage of less information loss at the query side. However, calculating asymmetric distances through exhaustive search is prohibitive in a large-scale dataset. We present a novel method, called multi-index voting, that integrates the multi-index hashing technique with a voting mechanism to select appropriate candidates and calculate their asymmetric distances. We show that the candidate selection scheme can be formulated as the tail of the binomial distribution function. In addition, a binary feature selection method based on minimal quantization error is proposed to address the memory insufficiency issue and improve the search accuracy. Substantial experimental evaluations were made to demonstrate that the proposed method can yield an approximate accuracy to the exhaustive search method while significantly accelerating the runtime. For example, one result shows that in a dataset of one billion 256-bit binary codes, examining only 0.5% of the dataset, can reach 95--99% close accuracy to the exhaustive search method and accelerate the search by 73--128 times. It also demonstrates an excellent tradeoff between the search accuracy and time efficiency compared to the state-of-the-art nearest-neighbor search methods. Moreover, the proposed feature selection method shows its effectiveness and improves the accuracy up to 8.35% compared with other feature selection methods.", "references": ["A. Babenko and V. Lempitsky. 2014. Additive quantization for extreme vector compression. In Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition (CVPR’14).", "A. Babenko and V. Lempitsky. 2015. Tree quantization for large-scale similarity search and classification. In Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition (CVPR’15).", "D. Cai, C. Zhang, and X. He. 2010. Unsupervised feature selection for multi-cluster data, In Proceedings of ACM Conference on Knowledge Discovery and Data Mining (KDD’10)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2990504"}, {"title": "Extended Discriminative Spatial Pyramid", "authors": ["Meng Di\n,", "Ye Xu"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn this paper, we introduce a novel model for embedding image spatial information into a feature vector based on an extension of spatial pyramid model (SPM). Our novel model considers the spatial distributions of both visual words and visual word combinations, extending the original SPM with a new explanation. The popular combination \"spatial pyramid + max pooling + linear SVMs\" for image classification and some existing works can be seen as simple implementations of our novel model, and we propose another one for better illustration. Three simple implementations are contrastively analyzedon Caltech 101, 15 Scenes and UIUC-Sports datasets, and our proposed one slightly outperforms the others.", "references": ["Y. Huang, Z. Wu, L. Wang, and T. Tan, \"Feature Coding in Image Classification: A Comprehensive Study,\" IEEE TPAMI, vol. 36, no. 3, pp. 493--506, 2014.", "D. G. Lowe, \"Distinctive image features from scale-invariant keypoints,\" IJCV, vol. 60, pp. 91--110, 2004.", "J. Yang, K. Yu, and T. Huang, \"Supervised Translation-Invariant Sparse Coding,\" in CVPR, 2010, pp. 3517--3524."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015182"}, {"title": "Article De-duplication Using Distributed Representations", "authors": ["Shumpei Okura\n,", "Yukihiro Tagami\n,", "Akira Tajima"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn news recommendation systems, eliminating redundant information is important as well as providing interesting articles for users. We propose a method that quantifies the similarity of articles based on their distributed representation, learned with the category information as weak supervision. This method is useful for evaluation under tight time constraints, since it only requires low-dimensional inner product calculation for estimating similarities. The experimental results from human evaluation and online performance in A/B testing suggest the effectiveness of our proposed method, especially for quantifying middle-level similarities. Currently, this method is used on Yahoo!\\ JAPAN's front page, which has millions of users per day and billions of page views per month.", "references": ["Q. Le and T. Mikolov. Distributed representations of sentences and documents. In ICML, 2014.", "P. Li and C. König. b-bit minwise hashing. In WWW, 2010.", "P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol. Extracting and composing robust features with denoising autoencoders. In ICML, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889355"}, {"title": "Pig target extraction based on adaptive elliptic block and wavelet edge detection", "authors": ["Changhua Ma\n,", "Weixing Zhu\n,", "Hao Li\n,", "Xincheng Li"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn order to obtain the prospect targets from the top view image of pig barns, the target extraction method of pigs based on adaptive elliptical block and wavelet edge detection is proposed in this paper. Firstly, two-dimensional OTSU global threshold segmentation and mathematic morphology processing were used to get the initial segmentation results. And then, adaptive elliptical block were taken around each pig respectively in the original image according to the initial segmentation results. Finally, the wavelet edge detection for secondary accurate extraction was used in each elliptical block and the complete contours of each pig were obtained. This method is suitable for a complex environment of the light changes in pig barns. This work provides a good foundation for the further research of pig's individual identification and behavior analysis. On the other hand, it also explores a new way to extract target contours of other similar images in complex environments and scenes.", "references": ["Chencheng Huang, Li Zeng. Robust image segmentation using local robust statistics and correntropy-based K-means clustering{J}. Optics and Lasers in Engineering 66(2015)187--203.", "Hanping Mao, Bo Hu, Yancheng Zhang, etc. The optimizing of color features and threshold segmentation algorithm in weed identification{J}. Journal of agricultural engineering, 2007, 23(9) 154--158.", "Guoqing Ma, Cai Liu, Danian Huang. The removal of additional edges in the edge detection of potential field data{J}. Journal of Applied Geophysics 114 (2015) 168--173."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015171"}, {"title": "ExpLOD: A Framework for Explaining Recommendations based on the Linked Open Data Cloud", "authors": ["Cataldo Musto\n,", "Fedelucio Narducci\n,", "Pasquale Lops\n,", "Marco De Gemmis\n,", "Giovanni Semeraro"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this paper we present ExpLOD, a framework which exploits the information available in the Linked Open Data (LOD) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. The methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the LOD cloud. Next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. In the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. The preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.", "references": ["M. Bilgic and R. Mooney. Explaining recommendations: Satisfaction vs. promotion. In Beyond Personalization, IUI WS, volume 5, 2005.", "G. Carenini and J. Moore. An empirical study of the influence of user tailoring on evaluative argument effectiveness. In IJCAI 2001, pages 1307--1314, 2001.", "T. H. Haveliwala. Topic-Sensitive PageRank: A Context-Sensitive Ranking Algorithm for Web Search. IEEE Trans. Knowl. Data Eng., 15(4):784--796, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959173"}, {"title": "Learning about Teaching in Low-Resource Indian Contexts", "authors": ["Aditya Vishwanath\n,", "Arkadeep Kumar\n,", "Neha Kumar"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nOnline learning environments are being deployed globally to offer learning opportunities to diverse student communities. We propose the deployment of such an environment in low-resource after-school settings across India. We draw on preliminary research conducted in summer 2015 that leveraged existing ties with an NGO working across 35 after-school classrooms. Our larger goal is to (1) support tutors in curating and distributing learning content to students, (2) engage students in a mobile, networked learning environment where they can share and collaborate, and (3) evaluate the feasibility of online learning environments for low-resource contexts. In this submission, our focus is on the first component.", "references": ["Aditya Vishwanath and Neha Kumar. 2015. Designing for a Rural Online Learning Community. InProceedings of the 2015 Annual Symposium on Computing for Development (DEV '15). ACM, New York, NY, USA, 73--74.", "Toyama, K. - There are no technology shortcuts to good education: 2011. http://edutechdebate.org/ict-in-schools/there-are-no-technology-shortcuts-to-good-education/. Accessed: 2016-01--14.", "Educomp Smart School: 2015. http://educomp.com/content/educomp-smart-school. Accessed: 2016-01--14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893440"}, {"title": "The Healing Power of Poison: Helpful Non-relevant Documents in Feedback", "authors": ["Mostafa Dehghani\n,", "Samira Abnar\n,", "Jaap Kamps"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe use of feedback information is an effective approach to address the vocabulary gap between a user's query and the relevant documents. It has been shown that some relevant documents act like \"poison pills,\" i.e. they hurt the performance of feedback systems despite the fact that they are relevant. In this paper, we study the positive counterpart of this by investigating the helpfulness of nonrelevant documents in feedback. In general, we find that although documents that are explicitly judged as non-relevant are normally assumed to be poisonous for feedback systems, sometimes considering high-scored non-relevant documents as a positive feedback helps to improve the performance of retrieval. In our experimental data, we observe a considerable fraction of non-relevant documents in higher ranked positions of the initial retrieval run, for most of the topics. Hence, by ignoring the potential value of non-relevant documents, we may loose a lot of useful information. We investigate the potential contribution of non-relevant documents using existing state-of-the-art feedback methods. Our main findings are the following. First, we find that some of the nonrelevant documents are exclusively helpful, they improve retrieval on their own, and others are complementary helpful, they lead to further improvement when added to a set of relevant documents. Second, we discover that, on average, exclusively helpful non-relevant documents have a higher contribution to the performance improvement, compared to the complementary ones. Third, we show that non-relevant documents in topics with poor average precision in the initial retrieval are more likely to help in the feedback.", "references": ["N. Abdul-jaleel, J. Allan, W. B. Croft, O. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. Umass at trec 2004: Novelty and hard. In TREC-13, 2004.", "M. Dehghani. Significant words representations of entities. In SIGIR '16, pages 1183--1183, 2016.", "M. Dehghani, H. Azarbonyad, J. Kamps, D. Hiemstra, and M. Marx. Luhn revisited: Significant words language models. In CIKM '16, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983910"}, {"title": "Weakly-Supervised Recognition, Localization, and Explanation of Visual Entities", "authors": ["Pascal Mettes"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nTo learn from visual collections, manual annotations are required. Humans however can no longer keep up with providing strong and time consuming annotations on the ever increasing wealth of visual data. As a result, approaches are required that can learn from fast and weak forms of annotations in visual data. This doctorial symposium summarizes my ongoing PhD dissertation on how to utilize weakly-supervised annotations to recognize, localize, and explain visual entities in images and videos. In this context, visual entities denote objects, scenes, and actions (in images), and actions and events (in videos). The summary is performed through four publications. For each publication, we discuss the current state-of-the-art, as well as our proposed novelties and performed experiments. The end of the summary discusses several possibilities to extend the dissertation.", "references": ["S. Bhattacharya, F. X. Yu, and S.-F. Chang. Minimally needed evidence for complex event recognition in unconstrained videos. In ICMR, 2014.", "L. Bossard, M. Guillaumin, and L. Van Gool. Food-101--mining discriminative components with random forests. In ECCV, 2014.", "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2971479"}, {"title": "A Fast 3D Retrieval Algorithm via Class-Statistic and Pair-Constraint Model", "authors": ["Zan Gao\n,", "Deyu Wang\n,", "Hua Zhang\n,", "Yanbing Xue\n,", "Guangping Xu"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the development of 3D technologies and devices, 3D model retrieval becomes a hot research topic where multi-view matching algorithms have demonstrated satisfying performance. However, exciting works overlook the common factors among objects in a single class, and they are time consuming in retrieval processing. In this paper, a class-statistics and pair-constraint model (CSPC) method is originally proposed for 3D model retrieval, which is composed of supervised class-based statistics model and pair-constraint object retrieval model. In our CSPC model, we firstly convert view-based distance measure into object-based distance measure without falling in performance, which will advance 3D model retrieval speed. Secondly, the generality of the distribution of each feature dimension in each class is computed to judge category information, and then we further adopt this distribution information to build class models. Finally, an object-based pairwise constraint is introduced on the base of the class-statistic measure, which can remove a lot of false alarm samples in retrieval. Experimental results on ETH, NTU-60, MVRED and PSB 3D datasets show that our method is fast, and its performance is also comparable with the-state-of-the-art algorithms.", "references": ["Y. Gao, A. Liu, and W. Nie, 3d object retrieval with multimodal views, in Eurographics Workshop on 3D Object Retrieval, 2015, pp. 129--136.", "K. Lu, N. He, J. Xue, J. Dong, and L. Shao, Learning view-model joint relevance for 3d object retrieval, IEEE Transactions on Image Processing, vol. 24, no. 5, pp. 1449--1459, 2015.", "Y. Gao, Q. Dai, M. Wang, and N. Zhang, \"3d model retrieval using weighted bipartite graph matching,\" Signal Processing: Image Communication, vol. 26, pp. 39--47, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967194"}, {"title": "Top-k Relevant Semantic Place Retrieval on Spatial RDF Data", "authors": ["Jieming Shi\n,", "Dingming Wu\n,", "Nikos Mamoulis"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nRDF data are traditionally accessed using structured query languages, such as SPARQL. However, this requires users to understand the language as well as the RDF schema. Keyword search on RDF data aims at relieving the user from these requirements; the user only inputs a set of keywords and the goal is to find small RDF subgraphs which contain all keywords. At the same time, popular RDF knowledge bases also include spatial semantics, which opens the road to location-based search operations. In this work, we propose and study a novel location-based keyword search query on RDF data. The objective of top-k relevant semantic places (kSP) retrieval is to find RDF subgraphs which contain the query keywords and are rooted at spatial entities close to the query location. The novelty of kSP queries is that they are location-aware and that they do not rely on the use of structured query languages. We design a basic method for the processing of kSP queries. To further accelerate kSP retrieval, two pruning approaches and a data preprocessing technique are proposed. Extensive empirical studies on two real datasets demonstrate the superior and robust performance of our proposals compared to the basic method.", "references": ["Alternative fueling station locator. http://www.afdc.energy.gov/locator/stations/.", "Bbc lab post. http://www.bbc.co.uk/blogs/internet/entries/63841314-c3c6--33d2-a7b8-f58ca040a65b.", "Crime in chicagoland. http://crime.chicagotribune.com/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2882941"}, {"title": "EveTAR: A New Test Collection for Event Detection in Arabic Tweets", "authors": ["Hind Almerekhi\n,", "Maram Hasanain\n,", "Tamer Elsayed"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nResearch on event detection in Twitter is often obstructed by the lack of publicly-available evaluation mechanisms such as test collections; this problem is more severe when considering the scarcity of them in languages other than English. In this paper, we present EveTAR, the first publicly-available test collection for event detection in Arabic tweets. The collection includes a crawl of 590M Arabic tweets posted in a month period and covers 66 significant events (in 8 different categories) for which more than 134k relevance judgments were gathered using crowdsourcing with high average inter-annotator agreement (Kappa value of 0.6). We demonstrate the usability of the collection by evaluating 3 state-of-the-art event detection algorithms. The collection is also designed to support other retrieval tasks, as we show in our experiments with ad-hoc search systems.", "references": ["N. Alsaedi and P. Burnap. Arabic event detection in social media. In Computational Linguistics and Intelligent Text Processing, pages 384--401. 2015.", "H. Becker, M. Naaman, and L. Gravano. Beyond trending topics: Real-world event identification on Twitter. In ICWSM'11, pages 438--441, 2011.", "T. Gottron, O. Radcke, and R. Pickhardt. On the temporal dynamics of influence on the social semantic web. In Semantic Web and Web Science, pages 75--87. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914681"}, {"title": "Towards Efficient Location and Placement of Dynamic Replicas for Geo-Distributed Data Stores", "authors": ["Pierre Matri\n,", "Alexandru Costan\n,", "Gabriel Antoniu\n,", "Jesús Montes\n,", "María S. Pérez"], "publication": "ScienceCloud '16: Proceedings of the ACM 7th Workshop on Scientific Cloud Computing", "abstract": "ABSTRACT\nLarge-scale scientific experiments increasingly rely on geo-distributed clouds to serve relevant data to scientists worldwide with minimal latency. State-of-the-art caching systems often require the client to access the data through a caching proxy, or to contact a metadata server to locate the closest available copy of the desired data. Also, such caching systems are inconsistent with the design of distributed hash-table databases such as Dynamo, which focus on allowing clients to locate data independently. We argue there is a gap between existing state-of-the-art solutions and the needs of geographically distributed applications, which require fast access to popular objects while not degrading access latency for the rest of the data. In this paper, we introduce a probabilistic algorithm allowing the user to locate the closest copy of the data efficiently and independently with minimal overhead, allowing low-latency access to non-cached data. Also, we propose a network-efficient technique to identify the most popular data objects in the cluster and trigger their replication close to the clients. Experiments with a real-world data set show that these principles allow clients to locate the closest available copy of data with small memory footprint and low error-rate, thus improving read-latency for non-cached data and allowing hot data to be read locally.", "references": ["An architectural blueprint for autonomic computing. Technical report, IBM, June 2005.", "Amazon Web Services. https://aws.amazon.com/, 2016. {Online; accessed Feb-1016}.", "Google Cloud. https://cloud.google.com/, 2016. {Online; accessed Feb-1016}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2913712.2913715"}, {"title": "Automatic Music Video Generation Based on Emotion-Oriented Pseudo Song Prediction and Matching", "authors": ["Jen-Chun Lin\n,", "Wen-Li Wei\n,", "Hsin-Min Wang"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe main difficulty in automatic music video (MV) generation lies in how to match two different media (i.e., video and music). This paper proposes a novel content-based MV generation system based on emotion-oriented pseudo song prediction and matching. We use a multi-task deep neural network (MDNN) to jointly learn the relationship among music, video, and emotion from an emotion-annotated MV corpus. Given a queried video, the MDNN is applied to predict the acoustic (music) features from the visual (video) features, i.e., the pseudo song corresponding to the video. Then, the pseudo acoustic (music) features are matched with the acoustic (music) features of each music track in the music collection according to a pseudo-song-based deep similarity matching (PDSM) metric given by another deep neural network (DNN) trained on the acoustic and pseudo acoustic features of the positive (official), less-positive (artificial), and negative (artificial) MV examples. The results of objective and subjective experiments demonstrate that the proposed pseudo-song-based framework performs well and can generate appealing MVs with better viewing and listening experiences.", "references": ["Juslin, P. N. and Västfjäll, D. Emotional responses to music: the need to consider underlying mechanisms. Behavioral and Brain Sciences, 31(5): 559--621, 2008.", "Hua, X.-S., Lu, L., and Zhang, H.-J. Automatic music video generation based on temporal pattern analysis. In ACM MM, 2004.", "Yoon, J.-C., Lee, I.-K., and Byun, S. Automated music video generation using multi-level feature-based segmentation. Multimedia Tools and Application, 41(2): 197--214, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967245"}, {"title": "An IS for Managing Scientific Projects", "authors": ["Leonardo S. Ramos\n,", "Kary A.C.S. Ocana\n,", "Daniel Oliveira"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nManaging scientific projects is a complex task. The project may be associated with several different scientific experiments that in turn require implementations of different computer simulations (scientific workflows). This management becomes even more complex if we consider that the project tasks should be associated with the specification and execution of these simulations (which can take days or weeks to finish) and that the project's team can be geographically dispersed. This paper presents the SciManager information system that aims at helping scientists managing scientific projects. The SciManager is able to manage the project, its associated experiments and workflows in a single tool, making all information related. The SciManager is based on a cloud architecture, which means it is easily available for project members. An experimental evaluation was held out and approximately 88% of users agreed that SciManager is useful and easy to use in scientist's daily duties.", "references": ["E. Deelman, D. Gannon, M. Shields, and I. Taylor, \"Workflows and e-Science: An overview of workflow system features and capabilities,\" Future Generation Computer Systems, vol. 25, no. 5, pp. 528 - 540, 2009", ". V. Jagadish, J. Gehrke, A. Labrinidis, Y. Papakonstantinou, J. M. Patel, R. Ramakrishnan, and C. Shahabi, \"Big data and its technical challenges,\" CACM, vol. 57, no. 7, pp. 86-94, Jul. 2014", "J. Freire, D. Koop, E. Santos, and C. T. Silva, \"Provenance for Computational Tasks: A Survey,\" CSE, vol. 10, no. 3, pp. 11-21, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021992"}, {"title": "A Domain Ontology for Privacy Preservation in Data Published by the Brazilian Government", "authors": ["Maria J. Queiroz\n,", "Natasha C.Q. Lino\n,", "Gustavo H.M.B. Motta"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nWhile considering transparency as a rule and secrecy as an exception, the Access to Information Act (AIA) provides for the protection of citizens' personal data when the publication of data related to the public sector on the Internet (Art. 31). Existing systematic methods for anonymization can be applied to meet this need. Thus, this article aims to develop a domain ontology for privacy preservation area in published data in order to comply with the provisions of AIA and initiatives of the Brazilian government, besides enabling the semantic unification of terms of anonymisation area and interoperability between tools for this purpose.", "references": ["Brasil. Lei no 12.527, de 18 de novembro de 2011. Diario Oficial {da} Republica Federativa do Brasil, Brasilia, DF, 18 nov. 2011. Disponivel em:. Acesso em: 09 out. 2015.", "Open Government Partnership (Brasil). 2o Plano de Acao Brasileiro. Versao traduzida. 2013. Disponivel em:. Acesso em: 07. jun. 2015.", "Controladoria-Geral da Uniao. Guias e orientacoes. Acesso em: 03 jul. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021958"}, {"title": "From Two CSCW Frameworks to User Requirements Definition for a Retail Planning Collaborative Software", "authors": ["Grégory Petit\n,", "Justin Soles"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis case study explains how we used two computer-supported cooperative work (CSCW) frameworks to define collaboration-related user requirements and experience attributes for Retail.Me, a new retail planning solution currently being designed at JDA Software. Our focus is on how this kind of framework can be used in industry and if one particular framework better answered our need to define user requirements and experience attributes for collaborative software. We explain how we configured each of the frameworks, how we reconciled them, and how this helped us reach our goal of defining user requirements and experience attributes for Retail.Me. At the end of this case study, we highlight differences in using the two frameworks, discuss their respective advantages and disadvantages and identify what we could have done to improve our process of defining user requirements and experience attributes.", "references": ["Alan Dix, Janet E. Finlay, Gregory D. Abowd, and Russell Beale. 2003. Human-Computer Interaction (3rd Edition). Prentice-Hall, Inc., Upper Saddle River, NJ, USA.", "Clarence A. Ellis, Simon J. Gibbs, and Gail Rein. 1991. Groupware: some issues and experiences. Commun. ACM 34, 1 (January 1991), 39--58.", "JDA Software. Are you ready for Me? Welcome to the age of Me-Commerce. Retrieved September 4, 2015 from http://www.jda.com/retailme/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2851584"}, {"title": "Scene-driven Retrieval in Edited Videos using Aesthetic and Semantic Deep Features", "authors": ["Lorenzo Baraldi\n,", "Costantino Grana\n,", "Rita Cucchiara"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper presents a novel retrieval pipeline for video collections, which aims to retrieve the most significant parts of an edited video for a given query, and represent them with thumbnails which are at the same time semantically meaningful and aesthetically remarkable. Videos are first segmented into coherent and story-telling scenes, then a retrieval algorithm based on deep learning is proposed to retrieve the most significant scenes for a textual query. A ranking strategy based on deep features is finally used to tackle the problem of visualizing the best thumbnail. Qualitative and quantitative experiments are conducted on a collection of edited videos to demonstrate the effectiveness of our approach.", "references": ["E. Apostolidis and V. Mezaris. Fast Shot Segmentation Combining Global and Local Visual Descriptors. In IEEE International Conference on Acoustics, Speech and Signal Processing, pages 6583--6587, 2014.", "L. Ballan, M. Bertini, G. Serra, and A. Del Bimbo. A data-driven approach for tag refinement and localization in web videos. Computer Vision and Image Understanding, 140:58--67, 2015.", "L. Baraldi, C. Grana, and R. Cucchiara. A deep siamese network for scene detection in broadcast videos. In Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, MM '15, pages 1199--1202, New York, NY, USA, 2015. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912012"}, {"title": "Crowdsensing based Multi-Modal Storytelling of Urban Emergency Events using Social Media", "authors": ["Zheng Xu\n,", "Hui Zhang\n,", "Yunhuai Liu\n,", "Lin Mei"], "publication": "MobiMedia '16: Proceedings of the 9th EAI International Conference on Mobile Multimedia Communications", "abstract": "ABSTRACT\nWith the development of Web 2.0, ubiquitous computing, and corresponding technologies, social media has the ability to provide the concepts of information contribution, diffusion, and exchange. Different from the permitting the general public to issue the user-generated information, social media has enabled them to avoid the need to use centralized, authoritative agencies. One of the important functions of Weibo is to monitor real time urban emergency events, such as fire, explosion, traffic jam, etc. Weibo user can be seen as social sensors and Weibo can be seen as the sensor platform. In this paper, the proposed method focuses on the step for storytelling of urban emergency events: given the Weibo posts related to a detected urban emergency event, the proposed method targets at mining the multi-modal information (e.g., images, videos, and texts), as well as storytelling the event precisely and concisely. To sum up, we propose a novel urban emergency event storytelling method to generate multi-modal summary from Weibo. Specifically, the proposed method consists of three stages: irrelevant Weibo post filtering, mining multimodal information and storytelling generation. We conduct extensive case studies on real-world microblog datasets to demonstrate the superiority of the proposed framework.", "references": ["T.-S. Chua, H. Luan, M. Sun, and S. Yang, \"Next: Nus-Tsinghua center for extreme search of user-generated content,\" IEEE MultiMedia Mag., vol. 19, no. 3, pp. 81--87, Jul.-Sep. 2012.", "H. Ma, \"Internet of Things: Objectives and Scientific Challenges,\" J. Computer Science and Tech., vol. 26, no. 6, 2011, pp. 919--24.", "B. Guo et al., \"Opportunistic IoT: Exploring the Harmonious Interaction between Human and the Internet of Things,\" J. Network and Computer Applications, vol. 36, no. 6, 2013, pp. 1531--39."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021385.3021424"}, {"title": "Text Clustering", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915046"}, {"title": "Balancing Relevance Criteria through Multi-Objective Optimization", "authors": ["Joost van Doorn\n,", "Daan Odijk\n,", "Diederik M. Roijers\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOffline evaluation of information retrieval systems typically focuses on a single effectiveness measure that models the utility for a typical user. Such a measure usually combines a behavior-based rank discount with a notion of document utility that captures the single relevance criterion of topicality. However, for individual users relevance criteria such as credibility, reputability or readability can strongly impact the utility. Also, for different information needs the utility can be a different mixture of these criteria. Because of the focus on single metrics, offline optimization of IR systems does not account for different preferences in balancing relevance criteria.\nWe propose to mitigate this by viewing multiple relevance criteria as objectives and learning a set of rankers that provide different trade-offs w.r.t. these objectives. We model document utility within a gain-based evaluation framework as a weighted combination of relevance criteria. Using the learned set, we are able to make an informed decision based on the values of the rankers and a preference w.r.t. the relevance criteria. On a dataset annotated for readability and a web search dataset annotated for sub-topic relevance we demonstrate how trade-offs between can be made explicit. We show that there are different available trade-offs between relevance criteria.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM'09, pages 5--14. ACM, 2009.", "B. Carterette. System effectiveness, user models, and user utility: a conceptual framework for investigation. In SIGIR'11, pages 903--912. ACM, 2011.", "C. L. Clarke, N. Craswell, I. Soboroff, and A. Ashkan. A comparative analysis of cascade measures for novelty and diversity. In WSDM'11, pages 75--84. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914708"}, {"title": "Question Answering on Linked Data: Challenges and Future Directions", "authors": ["Saeedeh Shekarpour\n,", "Kemele M. Endris\n,", "Ashwini Jaya Kumar\n,", "Denis Lukovnikov\n,", "Kuldeep Singh\n,", "Harsh Thakkar\n,", "Christoph Lange"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nQuestion Answering (QA) systems are becoming the inspiring model for the future of search engines. While, recently, datasets underlying QA systems have been promoted from unstructured datasets to structured datasets with semantically highly enriched metadata, question answering systems are still facing serious challenges and are therefore not meeting users' expectations. This paper provides an exhaustive insight of challenges known so far for building QA systems, with a special focus on employing structured data (i.e. knowledge graphs).It thus helps researchers to easily spot gaps to fill with their future research agendas.", "references": ["A. B. Abacha and P. Zweigenbaum. \"Medical question answering: translating medical questions into sparql queries\". In: ACM International Health Informatics Symposium, IHI '12, Miami, FL, USA, January 28--30, 2012. 2012.", "D. Amodei et al. \"Deep Speech 2: End-to-End Speech Recognition in English and Mandarin\". In: arXiv preprint arXiv:1512.02595 (2015).", "S. Auer et al. \"DBpedia: A Nucleus for a Web of Open Data\". In: The Semantic Web (ISWC+ASWC). 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890571"}, {"title": "Fast and general distributed transactions using RDMA and HTM", "authors": ["Yanzhe Chen\n,", "Xingda Wei\n,", "Jiaxin Shi\n,", "Rong Chen\n,", "Haibo Chen"], "publication": "EuroSys '16: Proceedings of the Eleventh European Conference on Computer Systems", "abstract": "ABSTRACT\nRecent transaction processing systems attempt to leverage advanced hardware features like RDMA and HTM to significantly boost performance, which, however, pose several limitations like requiring priori knowledge of read/write sets of transactions and providing no availability support. In this paper, we present DrTM+R, a fast in-memory transaction processing system that retains the performance benefit from advanced hardware features, while supporting general transactional workloads and high availability through replication. DrTM+R addresses the generality issue by designing a hybrid OCC and locking scheme, which leverages the strong atomicity of HTM and the strong consistency of RDMA to preserve strict serializability with high performance. To resolve the race condition between the immediate visibility of records updated by HTM transactions and the unready replication of such records, DrTM+R leverages an optimistic replication scheme that uses seqlock-like versioning to distinguish the visibility of tuples and the readiness of record replication. Evaluation using typical OLTP workloads like TPC-C and SmallBank shows that DrTM+R scales well on a 6-node cluster and achieves over 5.69 and 94 million transactions per second without replication for TPC-C and SmallBank respectively. Enabling 3-way replication on DrTM+R only incurs at most 41% overhead before reaching network bottleneck, and is still an order-of-magnitude faster than a state-of-the-art distributed transaction system (Calvin).", "references": ["Agrawal, D., Bernstein, A. J., Gupta, P., and Sengupta, S. Distributed optimistic concurrency control with reduced rollback. Distributed Computing 2, 1 (1987), 45--59.", "Agrawal, D., El Abbadi, A., Jeffers, R., and Lin, L. Ordered shared locks for real-time databases. The VLDB Journal 4, 1 (1995), 87--126.", "Aguilera, M. K., Leners, J. B., Kotla, R., and Walfish, M. Yesquel: scalable sql storage for web applications. In SOSP (2015), ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901318.2901349"}, {"title": "Axiomatic Analysis for Improving the Log-Logistic Feedback Model", "authors": ["Ali Montazeralghaem\n,", "Hamed Zamani\n,", "Azadeh Shakery"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPseudo-relevance feedback (PRF) has been proven to be an effective query expansion strategy to improve retrieval performance. Several PRF methods have so far been proposed for many retrieval models. Recent theoretical studies of PRF methods show that most of the PRF methods do not satisfy all necessary constraints. Among all, the log-logistic model has been shown to be an effective method that satisfies most of the PRF constraints. In this paper, we first introduce two new PRF constraints. We further analyze the log-logistic feedback model and show that it does not satisfy these two constraints as well as the previously proposed \"relevance effect\" constraint. We then modify the log-logistic formulation to satisfy all these constraints. Experiments on three TREC newswire and web collections demonstrate that the proposed modification significantly outperforms the original log-logistic model, in all collections.", "references": ["S. Clinchant and E. Gaussier. Information-based Models for Ad Hoc IR. In SIGIR '10, pages 234--241, 2010.", "S. Clinchant and E. Gaussier. A Theoretical Analysis of Pseudo-Relevance Feedback Models. In ICTIR '13, pages 6--13, 2013.", "K. Collins-Thompson. Reducing the Risk of Query Expansion via Robust Constrained Optimization. In CIKM '09, pages 837--846, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914768"}, {"title": "Principles for the Design of Online A/B Metrics", "authors": ["Widad Machmouchi\n,", "Georg Buscher"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we describe principles for designing metrics in the context of A/B experiments. We share some issues that comes up in designing such experiments and provide solutions to avoid such pitfalls.", "references": ["H. Feild et al. 2010. Predicting searcher frustration. In SIGIR'10: 34--41.", "Hassan. 2012. A semi-supervised approach to modeling web search satisfaction. In SIGIR'12: 275--284.", "Ron Kohavi, Alex Deng, Brian Frasca, Roger Longbotham, Toby Walker, and Ya Xu. Trustworthy online controlled experiments: Five puzzling outcomes explained. Proceedings of the 18th Conference on Knowledge Discovery and Data Mining, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926731"}, {"title": "Coordinated and efficient huge page management with ingens", "authors": ["Youngjin Kwon\n,", "Hangchen Yu\n,", "Simon Peter\n,", "Christopher J. Rossbach\n,", "Emmett Witchel"], "publication": "OSDI'16: Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation", "abstract": "ABSTRACT\nModern computing is hungry for RAM, with today's enormous capacities eagerly consumed by diverse workloads. Hardware address translation overheads have grown with memory capacity, motivating hardware manufacturers to provide TLBs with thousands of entries for large page sizes (called huge pages). Operating systems and hypervisors support huge pages with a hodge-podge of best-effort algorithms and spot fixes that made sense for architectures with limited huge page support, but the time has come for a more fundamental redesign.\nIngens is a framework for huge page support that relies on a handful of basic primitives to provide transparent huge page support in a principled, coordinated way. By managing contiguity as a first-class resource and by tracking utilization and access frequency of memory pages, Ingens is able to eliminate a number of fairness and performance pathologies that plague current systems. Experiments with our prototype demonstrate fairness improvements, performance improvements (up to 18%), tail-latency reduction (up to 41%), and reduction of memory bloat from 69% to less than 1% for important applications like Web services (e.g., the Cloudstone benchmark) and the Redis key-value store.", "references": ["http://www.7-cpu.com/cpu/Skylake.html. [Accessed April, 2016].", "http://www.7-cpu.com/cpu/Haswell.html. [Accessed April, 2016].", "Apache Cloudstack. https://en.wikipedia.org/wiki/Apache_CloudStack. [Accessed April, 2016]."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3026877.3026931"}, {"title": "An Approach for Personalized Web Information Retrieval using Modified PageRank Method", "authors": ["Aarti Singh\n,", "Anu Sharma"], "publication": "AICTC '16: Proceedings of the International Conference on Advances in Information Communication Technology & Computing", "abstract": "ABSTRACT\nSearch engines - a tool to retrieve the desired information from web are based on the link structure of the web to arrange the Web Search Results (WSR) for a given query. Study of available literature highlighted that only a few studies consider the user's rating of a web page in ranking WSR. Also, most of the user queries are short and ambiguous and results obtained do not satisfy their information needs. So, it is desirable to personalize the WSR. The present study proposes a novel method for rating web pages by implicit methods and a modification to existing inverted index is presented. A modified PageRank algorithm using proposed Inverted Recommendation Index is also discussed. A novel strategy for personalized re-ranking the search results based on Long Term Interest (LTI) and Short Term Interest (STI) is also presented.", "references": ["Baeza-Yates, R. and Ribeiro-Neto, B. 1999. Modern Information Retrieval, ACM Press.", "Brin S., Page L., Motwani R. and Winograd, T. 1998. The Page Rank Citation Ranking: Bringing order to The Web. Technical Report, Stanford University Available on the Internet at http://dbpubs.stanford.edu:8090/pub/1999-66", "Dou, Z., Song, R., Wen, J. R., and Yuan, X. 2009. Evaluating the effectiveness of personalized Web search. IEEE Trans. Knowl. Data Eng., 21, 1178--1190."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2979779.2979881"}, {"title": "Enhancing Information Retrieval with Adapted Word Embedding", "authors": ["Navid Rekabsaz"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecent developments on word embedding provide a novel source of information for term-to-term similarity. A recurring question now is whether the provided term associations can be properly integrated in the traditional information retrieval models while preserving their robustness and effectiveness. In this paper, we propose addressing the question of combining the term-to-term similarity of word embedding with IR models. The retrieval models in the approach are enhanced by altering the basic components of document retrieval, i.e. term frequency (tf) and document frequency (df). In addition, we target the study of the meaning of the term relatedness of word embedding models and its applicability in IR. This research topic consists of first explore of reliable similarity thresholds of word embedding vectors to indicate ?related terms? and second, identification of the linguistic types of the terms relatedness.", "references": ["J. Karlgren, A. Holst, and M. Sahlgren. Filaments of meaning in word space. In Proc. of ECIR. 2008.", "G. Kruszewski and M. Baroni. So similar and yet incompatible: Toward automated identification of semantically compatible words. In Proc. of NAACL, 2015.", "J. M. Ponte and W. B. Croft. A language modeling approach to information retrieval. In Proc. of SIGIR, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911475"}, {"title": "Introduction to the Special Issue on Recommender System Benchmarking", "authors": ["Paolo Cremonesi\n,", "Alan Said\n,", "Domonkos Tikk\n,", "Michelle X. Zhou"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "", "references": ["Gediminas Adomavicius, Alexander Tuzhilin, Shlomo Berkovsky, Ernesto W. De Luca, and Alan Said. 2010. Context-awareness in recommender systems: Research workshop and movie recommendation challenge. In Proceedings of the 4th ACM Conference on Recommender Systems (RecSys’10). ACM, New York, NY, 385--386. DOI:http://dx.doi.org/10.1145/1864708.1864801", "Xavier Amatriain, Pablo Castells, Arjen de Vries, Christian Posse, and Harald Steck (Eds.). 2012. Proc. of the Workshop on Recommendation Utility Evaluation: Beyond RMSE (RUE’12).", "Alejandro Bellogín, Pablo Castells, Alan Said, and Domonkos Tikk. 2013. Workshop on reproducibility and replication in recommender systems evaluation: RepSys. In Proceedings of the 7th ACM Conference on Recommender Systems (RecSys’13). ACM, New York, NY, 485--486. DOI:http://dx.doi.org/10.1145/2507157.2508006"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2870627"}, {"title": "Context-Based IDE Command Recommender System", "authors": ["Marko Gasparic"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nSoftware developer's working process could benefit from the support of an active help system that is able to recommend applicable and useful integrated development environment (IDE) commands. While previous work focused on prediction methods that can identify what developers will eventually discover autonomously, and without taking into account the characteristics of their working tasks, we want to build a system that recommends only commands that lead to better work performance. Since we cannot expect that developers are willing to invest a significant effort to use our recommender system (RS), we are developing a context-aware multi-criteria RS based on implicit feedback. We already created and evaluated context and user models. We also acquired a data set with more than 100,000 command executions. Currently, we are developing RS algorithm for predicting the scores of performance and effort expectancy and developer's intention to use a specific command. We are also developing a user interface, that has to be persuasive, effective, and efficient. To date, a user interface for IDE command RS has not been developed.", "references": ["G. Adomavicius and Y. Kwon. Multi-criteria recommender systems. In Recommender Systems Handbook, pages 847--880. Springer, 2015.", "G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-aware recommender systems. AI Magazine, pages 67--80, 2011.", "G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender Systems Handbook, pages 191--226. Springer, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959106"}, {"title": "Representing Documents via Latent Keyphrase Inference", "authors": ["Jialu Liu\n,", "Xiang Ren\n,", "Jingbo Shang\n,", "Taylor Cassidy\n,", "Clare R. Voss\n,", "Jiawei Han"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nMany text mining approaches adopt bag-of-words or $n$-grams models to represent documents. Looking beyond just the words, fiie, the explicit surface forms, in a document can improve a computer's understanding of text. Being aware of this, researchers have proposed concept-based models that rely on a human-curated knowledge base to incorporate other related concepts in the document representation. But these methods are not desirable when applied to vertical domains (eg, literature, enterprise, etc) due to low coverage of in-domain concepts in the general knowledge base and interference from out-of-domain concepts. In this paper, we propose a data-driven model named Latent Keyphrase InferenceLAKI) that represents documents with a vector of closely related domain keyphrases instead of single words or existing concepts in the knowledge base. We show that given a corpus of in-domain documents, topical content units can be learned for each domain keyphrase, which enables a computer to do smart inference to discover latent document keyphrases, going beyond just explicit mentions. Compared with the state-of-art document representation approaches, LAKI fills the gap between bag-of-words and concept-based models by using domain keyphrases as the basic representation unit. It removes dependency on a knowledge base while providing, with keyphrases, readily interpretable representations. When evaluated against 8 other methods on two text mining tasks over two corpora, LAKI outperformed all.", "references": ["R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern information retrieval, volume 463. 1999.", "C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. Dbpedia-a crystallization point for the web of data. Web Semantics: science, services and agents on the world Wide Web, 7(3):154--165, 2009.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883088"}, {"title": "Mechanism Design for Personalized Recommender Systems", "authors": ["Qingpeng Cai\n,", "Aris Filos-Ratsikas\n,", "Chang Liu\n,", "Pingzhong Tang"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nStrategic behaviour from sellers on e-commerce websites, such as faking transactions and manipulating the recommendation scores through artificial reviews, have been among the most notorious obstacles that prevent websites from maximizing the efficiency of their recommendations. Previous approaches have focused almost exclusively on machine learning-related techniques to detect and penalize such behaviour. In this paper, we tackle the problem from a different perspective, using the approach of the field of mechanism design. We put forward a game model tailored for the setting at hand and aim to construct truthful mechanisms, i.e. mechanisms that do not provide incentives for dishonest reputation-augmenting actions, that guarantee good recommendations in the worst-case. For the setting with two agents, we propose a truthful mechanism that is optimal in terms of social efficiency. For the general case of m agents, we prove both lower and upper bound results on the effciency of truthful mechanisms and propose truthful mechanisms that yield significantly better results, when compared to an existing mechanism from a leading e-commerce site on real data.", "references": ["E. H. Clarke. Multipart pricing of public goods. Public Choice, 2:19--33, 1971.", "B. Faltings. Using incentives to obtain truthful information. In Agents and Artificial Intelligence, pages 3--10. Springer, 2013.", "T. Groves. Incentives in Teams. Econometrica, 41:617--631, 1973."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959135"}, {"title": "Seeking Serendipity: A Living Lab Approach to Understanding Creative Retrieval in Broadcast Media Production", "authors": ["Sabrina Sauer\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper presents a method to map user needs and integrate serendipitous search behaviors in search algorithm development: the living lab approach. This user-centered design approach involves technology users during technology development to catch unexpected insights and successfully innovate. This paper focuses on the preliminary findings of a living lab case study to answer the question how this methodology reveals fine-grained information about users' serendipitous search behaviors. The case study involves a specific user group, media professionals who work in broadcast television and use audiovisual archives to create audiovisual content, during the development of new search algorithms for a large audiovisual archive. Research insights are based on data gathered during one co-design workshop, and ten in-depth semi-structured interviews with media professionals.\nFindings stipulate that these users balance socio-technical constraints and affordances during creative retrieval to (1) find exactly what is sought; and (2) increase the possibility of serendipitous, unforeseen search results. We conclude that modeling these search processes in terms of improvising with constraints and affordances enables an effective articulation and channeling of user-technology interaction insights into new technology development. The paper suggests next steps in the living lab approach to further understand serendipitous search and creative retrieval processes.", "references": ["M. Anwar, H. Al-Ansari, and A. Abdullah. Information seeking behaviour of Kuwaiti journalists. Libri, 54: 228--236, 2004.", "B. Aryana, T. Clemmensen, and C. Boks. Users' participation in requirements gathering for smart phones applications in emerging markets. Universal Access in the Information Society, 14:265--280, 2015.", "L. Azzopardi and K. Balog. Towards a living lab for information retrieval research and development. A proposal for a living lab for product search tasks. In Multilingual and Multimodal Information Access Evaluation, pages 26--37, Berlin, Heidelberg, 2011. Springer."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914721"}, {"title": "It ROCS!: The RASH Online Conversion Service", "authors": ["Angelo Di Iorio\n,", "Alejandra Gonzalez-Beltran\n,", "Francesco Osborne\n,", "Silvio Peroni\n,", "Francesco Poggi\n,", "Fabio Vitali"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn this poster paper we introduce the RASH Online Conversion Service, i.e., a Web application that allows the conversion of ODT documents into RASH, a HTML-based markup language for writing scholarly articles, and from RASH into LaTeX according to Springer LNCS and ACM ICPS.", "references": ["Capadisli, S., Riedl, R., Auer, S. (2015). Enabling Accessible Knowledge. In Proceedings of CeDEM 2015. http://csarven.ca/enabling-accessible-knowledge", "Conboy, G., Garrish, M., Gylling, M., McCoy, W., Makoto, M., Weck, D. (2014). EPUB 3 Overview. Recommended Speci cation 26 June 2014. http://www.idpf.org/epub/301/spec/epub-overview.html", "Constantin, A., Peroni, S., Pettifer, S., Shotton, D., Vitali, F. (2016). The Document Components Ontology (DoCO). In Semantic Web, 7 (2). http://dx.doi.org/10.3233/SW-150177"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889408"}, {"title": "What is translational literature and how to classify it?: crowd-sourcing as a starting point for corpus building and type distinction in comparative literature", "authors": ["Christine Ivanovic\n,", "Barbara Seidl"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nBy focusing on the construction of a prospective typology of translational literature, we seek to explore how digital media can be applied to data collections in the humanities. In addition we would like to examine as to how this approach might support an evaluation of the categories for text identification and the inclusion in a genre-specific corpus. We will start by outlining the concept of translational literature and then propose a collaborative crowd-sourcing project based on litblogs, designed to inspire both the search for relevant texts as well as determining their categorization.", "references": ["Riesch, H. and Potter, C. 2014. Citizen science as seen by scientists: Methodological, epistemological and ethical dimensions. In: Public Understanding of Science. Vol. 23, No. 1, 2014, 107--120.", "Hassan, W.S. 2006. Agency and Translational Literature: Ahdaf Soueif's \"'The Map of Love\". In: PMLA. Vol 121, No. 3, 2006, 753--768.", "Trumbull, D. J., Bonney, R., Bascom, D. and Cabral, A. 1999: Thinking Scientifically during Participation in a Citizen-Science Project. Science Education 84 Issue 2, 265--275."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012632"}, {"title": "Interactive physically-based sound design of 3D model using material optimization", "authors": ["Kazuhiko Yamamoto\n,", "Takeo Igarashi"], "publication": "SCA '16: Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation", "abstract": "ABSTRACT\nPhysically-based sound rendering enriches 3D animation. However, it is difficult to make an object with a given shape produce a specific sound using physically-based sound rendering because the user would need to define appropriate internal material distribution. To address this, we propose an example-based method to design physically-based sound for a 3D model. Our system optimizes the material distribution inside the 3D model so that physically-based sound rendering produces sounds similar to the target sounds specified by the user. A problem is that modal analysis required for this optimization is prohibitively expensive. In order to run the optimization at an interactive rate, we present fast approximate modal analysis that enables three orders of magnitude acceleration of the eigenproblem computation compared to standard modal analysis for an elastic object. It consists of data-driven online coarsening of the mesh and hierarchical component mode synthesis with efficient error correction. We demonstrate the feasibility of the method with a set of comparisons and examples.", "references": ["{Adr91} Adrien A.-M.: The missing link: Modal synthesis. In Representations of Musical Signals. MIT Press Cambridge, 1991. 1", "{AV07} Arthur D., Vassilvitskii S.: k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, Society for Industrial and Applied Mathematic (2007), 1027--1024. 6", "{Bat13} Bathe K.-J.: The subspace iteration method - revisited. Computers and Structures 126 (2013), 977--983. 3, 6"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2982818.2982849"}, {"title": "Video similarity search by using compact representations", "authors": ["Henrique Batista da Silva\n,", "Raquel Pereira de Almeida\n,", "Gabriel Barbosa da Fonseca\n,", "Carlos Caetano\n,", "Dario Vieira\n,"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe amount of applications using unstructured data, like videos, has been increased, and the researches concerning multimedia retrieval have attracted great attention. The need to efficiently index and retrieve this kind of data is of great concern, due to the fact that common searching approaches based on the use of keywords are not adequate for large video databases. Similarity search is a content based approach and it has been successfully used in retrieval systems. Accordingly, a major challenge is to provide an accurate and compact video representation that can achieve good performance with a fast answer in this type of searching. In this work, we proposed a compact video representation by using Min-Hash and the k-nearest GIST descriptors. Furthermore, we also present the first use of BossaNova Video Descriptor (BNVD) to video similarity search. Both compact video representations have shown more than 88% of mean average precision on similarity video search. The experimental results indicate high efficiency of our proposed representations in video retrieval task.", "references": ["S. Avila, N. Thome, M. Cord, E. Valle, and A. de A. Araújo. Pooling in image representation: the visual codeword point of view. Computer Vision and Image Understanding, 117(5):453--465, 2013.", "H. Bay, T. Tuytelaars, and L. Van Gool. Surf: Speeded up robust features. In A. Leonardis, H. Bischof, and A. Pinz, editors, Computer Vision - ECCV 2006, volume 3951 of Lecture Notes in Computer Science, pages 404--417. Springer Berlin Heidelberg, 2006.", "A. Broder. On the resemblance and containment of documents. In Compression and Complexity of Sequences 1997. Proceedings, pages 21--29, Jun 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851876"}, {"title": "Slob: security learning by ontology browsing: comprehensive cyber security learning resources in a web portal", "authors": ["Soon A. Chun\n,", "James Geller\n,", "Ankur Taunk\n,", "Karthik Sankaran\n,", "Tushar Swaminathan"], "publication": "Journal of Computing Sciences in Colleges", "abstract": "Abstract\nOntologies represent knowledge of a domain that can be used for data annotation, natural language processing, data integration, etc. In this project, an ontology is used to support learning and teaching. We present the SLOB (Security Learning by Ontology Browsing) Web Portal that brings together many learning resources for college-level cyber security classes at one central location. SLOB provides simple access to multi-media data, including videos, PowerPoint presentations, book pages, images and scientific papers in a unified framework. These resources are indexed by a Cyber Security Ontology created in this project, which provides definitions and hierarchical context for domain concepts. In addition, SLOB integrates social media cyber security sources, both targeted towards specific ontology concepts and general purpose cyber security. The methodology and approach are transferable to any knowledge-based teaching domain for which an ontology has been created.", "references": ["Bai, Y., Wang, X., Teaching Offensive Security in a Virtual Environment, Journal of Computing Sciences in Colleges, 31(1), 140--142, 2015.", "Bajec, M., Eder, J., Souag, A., Salinesi, C., Comyn-Wattiau, I., Ontologies for Security Requirements: A Literature Survey and Classification. Proceedings Advanced Information Systems Engineering Workshops, 2012.", "Fenz, S., Ekelhart, A., Formalizing information security knowledge. Proceedings 4th International Symposium on Information, Computer, and Communications Security, Sydney, Australia, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2904298.2904315"}, {"title": "Automatic Identification and Contextual Reformulation of Implicit System-Related Queries", "authors": ["Adam Fourney\n,", "Susan T. Dumais"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search functionality is increasingly integrated into operating systems, software applications, and other interactive environments that extend beyond the traditional web browser. In particular, intelligent virtual assistants (e.g., Microsoft Cortana or Apple Siri) often \"fall-back\" to generic web search in cases where utterances fall outside the set of scenarios known to the agent. In this paper we analyze a 3 month log of web search queries posed via the Cortana virtual assistant. We report that, in this environment, users frequently ask questions that implicitly pertain to the systems or devices from which they are searching (e.g., asking: [how do I take a screenshot]). Unfortunately, accurately answering these implicit system queries poses significant challenges to general web search engines, due in part to the lack of available context. We show that such queries: (1) can be detected with high precision, (2) are common, and (3) can be automatically reformulated to substantially improve retrieval performance in these fall-through scenarios.", "references": ["Apple Corporation. iOS - Siri - Apple. http://www.apple.com/ios/siri/, 2015.", "P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the Impact of Short- and Long-term Behavior on Search Personalization. In Proc. SIGIR '12, pages 185--194, New York, NY, USA, 2012. ACM.", "M. Ekstrand, W. Li, T. Grossman, J. Matejka, and G. Fitzmaurice. Searching for Software Learning Resources Using Application Context. In Proc. UIST '11, pages 195--204, New York, NY, USA, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914701"}, {"title": "On measuring the lattice of commonalities among several linked datasets", "authors": ["Michalis Mountantonakis\n,", "Yannis Tzitzikas"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nA big number of datasets has been published according to the principles of Linked Data and this number keeps increasing. Although the ultimate objective is linking and integration, it is not currently evident how connected the current LOD cloud is. Measurements (and indexes) that involve more than two datasets are not available although they are important: (a) for obtaining complete information about one particular URI (or set of URIs) with provenance (b) for aiding dataset discovery and selection, (c) for assessing the connectivity between any set of datasets for quality checking and for monitoring their evolution over time, (d) for constructing visualizations that provide more informative overviews. Since it would be prohibitively expensive to perform all these measurements in a naïve way, in this paper we introduce indexes (and their construction algorithms) that can speedup such tasks. In brief, we introduce (i) a namespace-based prefix index, (ii) a sameAs catalog for computing the symmetric and transitive closure of the owl:sameAs relationships encountered in the datasets, (iii) a semantics-aware element index (that exploits the aforementioned indexes), and finally (iv) two lattice-based incremental algorithms for speeding up the computation of the intersection of URIs of any set of datasets. We discuss the speedup obtained by the introduced indexes and algorithms through comparative results and finally we report measurements about connectivity of the LOD cloud that have never been carried out so far.", "references": ["C. Aggarwal, Y. Xie, and P. S. Yu. Gconnect: A connectivity index for massive disk-resident graphs. Proceedings of the VLDB Endowment, 2(1):862--873, 2009.", "S. Auer, J. Demter, M. Martin, and J. Lehmann. LODStats - an Extensible Framework for High-Performance Dataset Analytics. In Proceedings of EKAW, volume 7603, pages 353--362. 2012.", "N. Bikakis and T. K. Sellis. Exploration and visualization in the web of big linked data: A survey of the state of the art. In LWDM, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2994509.2994527"}, {"title": "Efficient and Effective Higher Order Proximity Modeling", "authors": ["Xiaolu Lu\n,", "Alistair Moffat\n,", "J. Shane Culpepper"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nBag-of-words retrieval models are widely used, and provide a robust trade-off between efficiency and effectiveness. These models often make simplifying assumptions about relations between query terms, and treat term statistics independently. However, query terms are rarely independent, and previous work has repeatedly shown that term dependencies can be critical to improving the effectiveness of ranked retrieval results. Among all term-dependency models, the Markov Random Field (MRF) [Metzler and Croft, SIGIR, 2005] model has received the most attention in recent years. Despite clear effectiveness improvements, these models are not deployed in performance-critical applications because of the potentially high computational costs. As a result, bigram models are generally considered to be the best compromise between full term dependence, and term-independent models such as BM25. Here we provide further evidence that term-dependency features not captured by bag-of-words models can reliably improve retrieval effectiveness. We also present a new variation on the highly-effective MRF model that relies on a BM25-derived potential. The benefit of this approach is that it is built from feature functions which require no higher-order global statistics. We empirically show that our new model reduces retrieval costs by up to 60%, with no loss in effectiveness compared to previous approaches.", "references": ["G. Amati. Probability models for information retrieval based on divergence from randomness. PhD thesis, University of Glasgow, 2003.", "P. Bailey, A. Moffat, F. Scholer, and P. Thomas. User variability and IR system evaluation. In Proc. SIGIR, pages 625--634, 2015.", "M. Bendersky and W. B. Croft. Modeling higher-order term dependencies in information retrieval using query hypergraphs. In Proc. SIGIR, pages 941--950, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970404"}, {"title": "Snap, Eat, RepEat: A Food Recognition Engine for Dietary Logging", "authors": ["Michele Merler\n,", "Hui Wu\n,", "Rosario Uceda-Sosa\n,", "Quoc-Bao Nguyen\n,", "John R. Smith"], "publication": "MADiMa '16: Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management", "abstract": "ABSTRACT\nWe present a system to assist users in dietary logging habits, which performs food recognition from pictures snapped on their phone in two different scenarios. In the first scenario, called \"Food in context\", we exploit the GPS information of a user to determine which restaurant they are having a meal at, therefore restricting the categories to recognize to the set of items in the menu. Such context allows us to also report precise calories information to the user about their meal, since restaurant chains tend to standardize portions and provide the dietary information of each meal. In the second scenario, called \"Foods in the wild\" we try to recognize a cooked meal from a picture which could be snapped anywhere. We perform extensive experiments on food recognition on both scenarios, demonstrating the feasibility of our approach at scale, on a newly introduced dataset with 105K images for 500 food categories.", "references": ["K. Aizawa, Y. Maruyama, H. Li, and C. Morikawa. Food balance estimation by using personal dietary tendencies in a multimedia food log. IEEE Transactions on Multimedia, 15(8):2176--2185, 2013.", "A. H. Andrew, G. Borriello, and J. Fogarty. Simplifying mobile phone food diaries: Design and evaluation of a food index-based nutrition diary. In Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare, PervasiveHealth '13, pages 260--263, 2013.", "M. Anthimopoulos, J. Dehais, S. Shevchik, B. H. Ransford, D. Duke, P. Diem, and S. Mougiakakou. Computer vision-based carbohydrate estimation for type 1 patients with diabetes using smartphones. J, Diabetes Science and Technology, 9(3):507--515, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986035.2986036"}, {"title": "Collaborative Knowledge Base Embedding for Recommender Systems", "authors": ["Fuzheng Zhang\n,", "Nicholas Jing Yuan\n,", "Defu Lian\n,", "Xing Xie\n,", "Wei-Ying Ma"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nAmong different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.", "references": ["ahmet uyar, f. m. a. Evaluating search features of google knowledge graph and bing satori. Online Information Review (2015).", "Bobadilla, J., Ortega, F., Hernando, A., and Gutiérrez, A. Recommender systems survey. Knowledge-Based Systems 46 (2013), 109--132.", "Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakhnenko, O. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems (2013), 2787--2795."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939673"}, {"title": "LONLIES: Estimating Property Values for Long Tail Entities", "authors": ["Mina Farid\n,", "Ihab F. Ilyas\n,", "Steven Euijong Whang\n,", "Cong Yu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search engines often retrieve answers for queries about popular entities from a growing knowledge base that is populated by a continuous information extraction process. However, less popular entities are not frequently mentioned on the web and are generally interesting to fewer users; these entities reside on the long tail of information. Traditional knowledge base construction techniques that rely on the high frequency of entity mentions to extract accurate facts about these mentions have little success with entities that have low textual support. We present Lonlies, a system for estimating property values of long tail entities by leveraging their relationships to head topics and entities. We demonstrate (1) how Lonlies builds communities of entities that are relevant to a long tail entity utilizing a text corpus and a knowledge base; (2) how Lonlies determines which communities to use in the estimation process; (3) how we aggregate estimates from community entities to produce final estimates, and (4) how users interact with Lonlies to provide feedback to improve the final estimation results.", "references": ["M. S. Bernstein, J. Teevan, S. Dumais, D. Liebling, and E. Horvitz. Direct Answers for Search Queries in the Long Tail. In SIGCHI, 2012.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, 2008.", "J. Callan, M. Hoy, C. Yoo, and L. Zhao. Clueweb09 data set, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911466"}, {"title": "Hybrid Recommendation System using Particle Swarm Optimization and User Access Based Ranking", "authors": ["G. Sumathi\n,", "S. Sendhilkumar\n,", "G. S. Mahalakshmi"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nThis paper introduces a novel architecture for a new user recommendation system which is based on Particle Swarm Optimization (PSO) algorithm and User Access Based Ranking (UABR) approach. The Recommendation System (RS) is an efficient tool for providing the relevant pages to the users. A vital issue for the RS that has enormously captured the attention of researchers is the cold-start problem. This issue is related to recommendations for new users. For new users, the system does not have data about their preferences in order to make recommendations. We proposed a technique with the swarm intelligence approach of Particle Swarm Optimization in combination with User access based ranking algorithm for the new user recommendation. The PSO algorithm is applied to user grouping. Using this approach, users with similar searching travels are gathered into the same cluster. Recommendations for new user are produced through the user access based ranking algorithm. The results of experiments exhibits that the proposed strategy can effectively enhance the quality of recommendation with the better precision, recall and F_Score values.", "references": ["Ahmad, A.M. and Hijazi, M.H. 2004. Web page recommendation model for web personalization. In Knowledge-based intelligent information and engineering systems. 587--593, Springer Berlin Heidelberg.", "Bobadilla, J., Ortega, F., Hernando, A., and Bernal, J. 2012. A collaborative filtering approach to mitigate the new user cold start problem. Knowledge-based systems. 26, 225--238.", "Castellanos, I. and Rojas, Y. 2014. Recommender system using collaborative filtering for the publication system of multimedia content-Video Web 1.0. Intl. Jour. of innovation and applied studies, 6(3), 326--334."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980405"}, {"title": "Engineering Quality and Reliability in Technology-Assisted Review", "authors": ["Gordon V. Cormack\n,", "Maura R. Grossman"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe objective of technology-assisted review (\"TAR\") is to find as much relevant information as possible with reasonable effort. Quality is a measure of the extent to which a TAR method achieves this objective, while reliability is a measure of how consistently it achieves an acceptable result. We are concerned with how to define, measure, and achieve high quality and high reliability in TAR. When quality is defined using the traditional goal-post method of specifying a minimum acceptable recall threshold, the quality and reliability of a TAR method are both, by definition, equal to the probability of achieving the threshold. Assuming this definition of quality and reliability, we show how to augment any TAR method to achieve guaranteed reliability, for a quantifiable level of additional review effort. We demonstrate this result by augmenting the TAR method supplied as the baseline model implementation for the TREC 2015 Total Recall Track, measuring reliability and effort for 555 topics from eight test collections. While our empirical results corroborate our claim of guaranteed reliability, we observe that the augmentation strategy may entail disproportionate effort, especially when the number of relevant documents is low. To address this limitation, we propose stopping criteria for the model implementation that may be applied with no additional review effort, while achieving empirical reliability that compares favorably to the provably reliable method. We further argue that optimizing reliability according to the traditional goal-post method is inconsistent with certain subjective aspects of quality, and that optimizing a Taguchi quality loss function may be more apt.", "references": ["M. Bagdouri, W. Webber, D. D. Lewis, and D. W. Oard. Towards minimizing the annotation cost of certified text classification. In SIGIR 2013.", "D. Blair and M. E. Maron. An evaluation of retrieval effectiveness for a full-text document-retrieval system. Commun. ACM, 28(3):289--299, 1985.", "D. C. Blair. Stairs redux: Thoughts on the stairs evaluation, ten years after. J. Am. Soc. Inf. Sci., 47(1):4--22, Jan. 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911510"}, {"title": "Work in Progress: K-Nearest Neighbors Techniques for ABAC Policies Clustering", "authors": ["Yahya Benkaouz\n,", "Mohammed Erradi\n,", "Bernd Freisleben"], "publication": "ABAC '16: Proceedings of the 2016 ACM International Workshop on Attribute Based Access Control", "abstract": "ABSTRACT\nIn this paper, we present an approach based on the K-Nearest Neighbors algorithms for policies clustering that aims to reduce the ABAC policies dimensionality for high scale systems. Since ABAC considers a very large set of attributes for access decisions, it turns out that using such model for large scale systems might be very complicated. To date, researchers have proposed to use data mining techniques to discover roles for RBAC system construction. In this work in progress, we consider the usage of KNN-based techniques for the classification of ABAC policies based on similarity computations of rules in order to enhance the ABAC flexibility and to reduce the number of policy rules.", "references": ["G. Amato and F. Falchi. knn based image classification relying on local feature similarity. In Proceedings of the Third International Conference on SImilarity Search and APplications, pages 101--108. ACM, 2010.", "X. Bai, R. Guerraoui, A.-M. Kermarrec, and V. Leroy. Collaborative personalized top-k processing. ACM Transactions on Database Systems, 36(4):26, 2011.", "M. Bertier, D. Frey, R. Guerraoui, A.-M. Kermarrec, and V. Leroy. The gossple anonymous social network. In Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware, Middleware '10, pages 191--211, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2875491.2875497"}, {"title": "Moodplay: Interactive Mood-based Music Discovery and Recommendation", "authors": ["Ivana Andjelkovic\n,", "Denis Parra\n,", "John O'Donovan"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nA large body of research in recommender systems focuses on optimizing prediction and ranking. However, recent work has highlighted the importance of other aspects of the recommendations, including transparency, control and user experience in general. Building on these aspects, we introduce MoodPlay, a hybrid recommender system music which integrates content and mood-based filtering in an interactive interface. We show how MoodPlay allows the user to explore a music collection by latent affective dimensions, and we explain how to integrate user input at recommendation time with predictions based on a pre-existing user profile. Results of a user study (N=240) are discussed, with four conditions being evaluated with varying degrees of visualization, interaction and control. Results show that visualization and interaction in a latent space improve acceptance and understanding of both metadata and item recommendations. However, too much of either can result in cognitive overload and a negative impact on user experience.", "references": ["M. J. Albers. Cognitive strain as a factor in effective document design. In Proceedings of the 15th Annual International Conference on Computer Documentation, SIGDOC '97, pages 1--6, New York, NY, USA, 1997. ACM.", "C. Baccigalupo and E. Plaza. Case-based sequential ordering of songs for playlist recommendation. In Advances in Case-Based Reasoning, pages 286--300. Springer, 2006.", "L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In Workshop on context-aware recommender systems (CARS'09), 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930280"}, {"title": "Data Summarization with Social Contexts", "authors": ["Hao Zhuang\n,", "Rameez Rahman\n,", "Xia Hu\n,", "Tian Guo\n,", "Pan Hui\n,", "Karl Aberer"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhile social data is being widely used in various applications such as sentiment analysis and trend prediction, its sheer size also presents great challenges for storing, sharing and processing such data. These challenges can be addressed by data summarization which transforms the original dataset into a smaller, yet still useful, subset. Existing methods find such subsets with objective functions based on data properties such as representativeness or informativeness but do not exploit social contexts, which are distinct characteristics of social data. Further, till date very little work has focused on topic preserving data summarization, despite the abundant work on topic modeling. This is a challenging task for two reasons. First, since topic model is based on latent variables, existing methods are not well-suited to capture latent topics. Second, it is difficult to find such social contexts that provide valuable information for building effective topic-preserving summarization model. To tackle these challenges, in this paper, we focus on exploiting social contexts to summarize social data while preserving topics in the original dataset. We take Twitter data as a case study. Through analyzing Twitter data, we discover two social contexts which are important for topic generation and dissemination, namely (i) CrowdExp topic score that captures the influence of both the crowd and the expert users in Twitter and (ii) Retweet topic score that captures the influence of Twitter users' actions. We conduct extensive experiments on two real-world Twitter datasets using two applications. The experimental results show that, by leveraging social contexts, our proposed solution can enhance topic-preserving data summarization and improve application performance by up to 18%.", "references": ["Machine learning for language toolkit. http://mallet.cs.umass.edu/.", "Twitter public apis. https://dev.twitter.com/overview/documentation.", "Twitter public search apis. https://dev.twitter.com/rest/public/search."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983736"}, {"title": "TopPRF: A Probabilistic Framework for Integrating Topic Space into Pseudo Relevance Feedback", "authors": ["Jun Miao\n,", "Jimmy Xiangji Huang\n,", "Jiashu Zhao"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nTraditional pseudo relevance feedback (PRF) models choose top k feedback documents for query expansion and treat those documents equally. When k is determined, feedback terms are selected without considering the reliability of these documents for relevance. Because the performance of PRF is sensitive to the selection of feedback terms, noisy terms imported from these irrelevant documents or partially relevant documents will harm the final results extensively. Intuitively, terms in these documents should be considered less important for feedback term selection. Nonetheless, how to measure the reliability of feedback documents is a difficult problem.\nRecently, topic modeling has become more and more popular in the information retrieval (IR) area. In order to identify how reliable a feedback document is to be relevant, we attempt to adapt the topical information into PRF. However, topics are hard to be quantified and therefore the identification of topic is usually fuzzy. It is very challenging for integrating the obtained topical information effectively into IR and other text-processing-related areas. Current research work mainly focuses on mining relevant information from particular topics. This is extremely difficult when the boundaries of different topics are hard to define. In this article, we investigate a key factor of this problem, the topic number for topic modeling and how it makes topics “fuzzy.” To effectively and efficiently apply topical information, we propose a new probabilistic framework, “TopPRF,” and three models, TS-COS, TS-EU, and TS-Entropy, via integrating “Topic Space” (TS) information into pseudo relevance feedback. These methods discover how reliable a document is to be relevant through both term and topical information. When selecting feedback terms, candidate terms in more reliable feedback documents should obtain extra weights. Experimental results on various public collections justify that our proposed methods can significantly reduce the influence of “fuzzy topics” and obtain stable, good results over the strong baseline models. Our proposed probabilistic framework, TopPRF, and three topic-space-based models are capable of searching documents beyond traditional term matching only and provide a promising avenue for constructing better topic-space-based IR systems. Moreover, in-depth discussions and conclusions are made to help other researchers apply topical information effectively.", "references": ["J. Allan, M. E. Connell, W. B. Croft, F. Feng, D. Fisher, and X. Li. 2000. INQUERY and TREC-9. In Proceedings of the 9th Text REtrieval Conference, 13.", "D. Andrzejewski and D. Buttler. 2011. Latent topic feedback for information retrieval. In Proceedings of the 17th ACM Conference on Knowledge Discovery and Data Mining, 600--608. ACM, New York, NY.", "M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker, and P. Williams. 1997. Okapi at TREC-5. In Proceedings of the 5th Text REtrieval Conference. NIST Special Publication SP, 143166."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2956234"}, {"title": "Enabling Hybrid PCM Memory System with Inherent Memory Management", "authors": ["Yu-Ming Chang\n,", "Yuan-Hao Chang\n,", "Hsiu-Chang Chen\n,", "Tei-Wei Kuo"], "publication": "RACS '16: Proceedings of the International Conference on Research in Adaptive and Convergent Systems", "abstract": "ABSTRACT\nReplacing the traditional volatile main memory, e.g., DRAM, with a non-volatile phase change memory (PCM) has become a possible solution to reduce the energy consumption of computing systems. To further reduce the bit cost of PCM, the development trend of PCM goes from single-level-cell (SLC) the multi-level-cell (MLC) technology. However, the worse endurance and the intolerable long write latency hinder a MLC PCM from being used as the main memory of computing systems. In this work, we propose a memory management design to facilitate enabling the use of hybrid PCMas main memory to achieve a better trade-off between the cost and the performance of PCM-based computing systems, where the hybrid PCM is composed of SLC PCM and MLC PCM. In particular, the proposed design can be seamlessly integrated into the inherent memory management of modern operation systems without additional hardware components. The evaluation results show that the proposed design over a hybrid PCM can improve the average read/write performance for almost 10 times and extend the lifetime for more than 32 times, compared to systems with pure MLC PCM.", "references": ["D. P. Bovet and M. Cesati. Understanding the Linux Kernel, the 3rd Edition. O'rielly, 2005.", "H.-S. Chang et al. A Light-Weighted Software-Controlled Cache for PCM-based Main Memory Systems. In Proc. of the IEEE/ACM ICCAD, pages 22--29, 2015.", "H.-S. Chang et al. Marching-Based Wear-Leveling for PCM-Based Storage Systems. ACM Trans. Des. Autom. Electron. Syst., 20(2):25:1--25:22, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987386.2987398"}, {"title": "Smart Service Portfolios: Do the Cities Follow Standards?", "authors": ["Leonidas Anthopoulos\n,", "Marijn Janssen\n,", "Vishanth Weerakkody"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nSmart services concern the core element of a smart city, since they support the realization of urban \"intelligence\" in terms of people, economy, governance, environment, mobility and leaving. Smart services aim to enhance quality of life within a city and in this respect to improve \"livability\". The types and purposes of smart services cannot be easily pre-defined, since they are the outcome of innovation, which cannot be pre-defined either, but instead it is the product of citizens' and businesses' creativity. However, standard bodies that work on smart city definition have described smart city portfolios, which are suggested to city policy makers and potential entrepreneurs. The aim of this paper is to validate whether standardized smart service portfolios are being followed by smart cities in practice. In this regard, a set of more than 70 smart cities are examined and their smart services are matched to these portfolios. The outcomes are extremely important and leave space for future research in this regard.", "references": ["Anthopoulos, L. and Reddick, Ch. 2015. Understanding electronic government research and smart city. Information Polity, Special Issue on \"Smartness in Governance, Government, Urban Spaces, and the Internet of Things\", 1, 1--19. DOI: 10.3233/IP-150371", "Rogers, E.M. 1996. Diffusion of Innovations. The Free Press, New York.", "Anthopoulos, L. 2015. Defining Smart City Architecture for Sustainability. In Tampouris, E. et al. (Eds) Proceedings of 14th Electronic Government and 7th Electronic Participation Conference (IFIP2015) (Thessaloniki, Greece, August 30-September 2, 2015), IOS Press, Amsterdam, 140--147. DOI= 10.3233/978--1--61499--570--8--140"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888618"}, {"title": "The Contextual Turn: from Context-Aware to Context-Driven Recommender Systems", "authors": ["Roberto Pagano\n,", "Paolo Cremonesi\n,", "Martha Larson\n,", "Balázs Hidasi\n,", "Domonkos Tikk\n,", "Alexandros Karatzoglou\n,", "Massimo Quadrana"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nA critical change has occurred in the status of context in recommender systems. In the past, context has been considered 'additional evidence'. This past picture is at odds with many present application domains, where user and item information is scarce. Such domains face continuous cold start conditions and must exploit session rather than user information. In this paper, we describe the `Contextual Turn?: the move towards context-driven recommendation algorithms for which context is critical, rather than additional. We cover application domains, algorithms that promise to address the challenges of context-driven recommendation, and the steps that the community has taken to tackle context-driven problems. Our goal is to point out the commonalities of context-driven problems, and urge the community to address the overarching challenges that context-driven recommendation poses.", "references": ["G. Adomavicius and A. Tuzhilin. Context-Aware Recommender Systems, pages 191--226. Springer, 2015.", "L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In CARS Workshop at ACM RecSys 2009.", "P. Borlund. The concept of relevance in IR. JASIST, 54(10):913--925, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959136"}, {"title": "Pienapple search: an integrated search interface to support finding, refinding and sharing", "authors": ["Martynas Buivys\n,", "Leif Azzopardi"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nPienapple is a search interface that aims to combine bookmarking and searching within a blended experience to facilitate improved access, serendipity, and sharing. While personal and social bookmarking platforms already exist, they are often separated from the search system, resulting in an increased effort and complexity because two or more systems need to be used. Instead, Pienapple attempts to lower the overall effort of bookmarking, (re)accessing and sharing by bringing these activities together to provide a more supportive search interface.", "references": ["Aula, A., Jhaveri, N., & Käki, M. (2005). Information search and re-access strategies of experienced web users. In Proc. of the 14th www conference (pp. 583--592).", "Brooke, J. (1996). Sus: A quick and dirty usability scale.", "Jhaveri, N. (2004). Intermediate and post-session web page revisitation techniques and tools (Unpublished master's thesis). Department of Computer Sciences, University of Tampere, Finland."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017569"}, {"title": "Externalization of knowledge through Group Storytelling: a case study in online tutoring", "authors": ["Maria Teresa A.. Gouvea\n,", "Flavia Maria Santoro\n,", "Claudia Cappelli\n,", "Mariano Pimentel"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nOne of the great challenges of knowledge management is the externalization of knowledge (the conversion of tacit in explicit knowledge) effectively. Tacit knowledge is associated with personal experiences and represents the subjective knowledge that is often difficult to be formalized or explained. Group Storytelling is an important approach to tacit knowledge retrieval, which through the collaborative construction of stories it helps in externalization. This paper presents an exploratory case study with tutors of an online course, whose results showed that it is possible to capture the tacit knowledge through this technique with computer system support.", "references": ["Rodrigues, M. V. 2013. Gestao do Conhecimento e Cultura Organizacional. Rio de Janeiro, Grupo IBMEC Educacional.", "Perret, R., Borges, M. R. S. e Santoro, F. M. 2004. Applying Group Storytelling in Knowledge Management. In International Workshop on Groupware (CRIWG), San Carlos, Costa Rica. Groupware: Design, Implementation, and Use - Lecture Notes in Computer Science. Berlin: SpringerVerlag, v. 3198, 34-41.", "Takeuchi, I., Nonaka, I. 2008.Gestao do Conhecimento. Bookman"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021968"}, {"title": "Semi-supervised Identification of Rarely Appearing Persons in Video by Correcting Weak Labels", "authors": ["Eric Müller\n,", "Christian Otto\n,", "Ralph Ewerth"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nSome recent approaches for character identification in movies and TV broadcasts are realized in a semi-supervised manner by assigning transcripts and/or subtitles to the speakers. However, the labels obtained in this way achieve only an accuracy of $80\\% - 90\\%$ and the number of training examples for the different actors is unevenly distributed. In this paper, we propose a novel approach for person identification in video by correcting and extending the training data with reliable predictions to reduce the number of annotation errors. Furthermore, the intra-class diversity of rarely speaking characters is enhanced. To address the imbalance of training data per person, we suggest two complementary prediction scores. These scores are also used to recognize whether or not a face track belongs to a (supporting) character whose identity does not appear in the transcript etc. Experimental results demonstrate the feasibility of the proposed approach, outperforming the current state of the art.", "references": ["M. Bauml, M. Tapaswi, and R. Stiefelhagen. Semi-supervised learning with constraints for person identification in multimedia data. In IEEE Conference on Computer Vision and Pattern Recognition, pages 3602--3609. IEEE, 2013.", "N. Cherniavsky, I. Laptev, J. Sivic, and A. Zisserman. Semi-supervised learning of facial attributes in video. In Trends and Topics in Computer Vision, pages 43--56. Springer, 2012.", "R. G. Cinbis, J. Verbeek, and C. Schmid. Unsupervised metric learning for face identification in tv video. In IEEE International Conference on Computer Vision, pages 1559--1566. IEEE, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912073"}, {"title": "Opinion retrieval in Twitter using stylistic variations", "authors": ["Anastasia Giachanou\n,", "Fabio Crestani"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nMicroblogs have emerged as a popular platform for sharing information and expressing opinion. Twitter opinion retrieval is now recognized as a powerful tool for finding people's attitudes on different topics. However, the short length and the informal language of tweets make Twitter opinion retrieval very challenging. In this paper, we propose a stylistic-based method that leverages simple and specific stylistic variations to retrieve tweets that are relevant and opinionated on a particular topic. Results show that the proper handling of textual meta-communications can significantly improve opinion retrieval performance in Twitter.", "references": ["S. Brody and N. Diakopoulos. Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!: using word lengthening to detect sentiment in microblogs. In EMNLP'11, pages 562--570, 2011.", "D. Davidov, O. Tsur, and A. Rappoport. Enhanced sentiment learning using twitter hashtags and smileys. In Coling'10, pages 241--249. Association for Computational Linguistics, 2010.", "A. Go, R. Bhayani, and L. Huang. Technical report, Standford, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851922"}, {"title": "A semantic-based question answering system for indonesian translation of Quran", "authors": ["Syopiansyah Jaya Putra\n,", "Ria Hari Gusmita\n,", "Khodijah Hulliyah\n,", "Husni Teja Sukmana"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nThis paper presents a work in developing a semantic-based question answering system (QAS) for Indonesian Translation of Quran (ITQ). This research is motivated by the lacks of previous built QAS that caused by a keyword-based retrieval. Instead of keeping the retrieval method, we shifted to a semantic approach where the retrieval process is done by using a semantic similarity measurement. In doing so, we built an ontology of ITQ to get the concepts as well as verses where they appear in. We applied three factoid question types on the QAS that including Who, Where, and When. Furthermore, a weighted vector for each concept that belongs to respective expected answering type (also called as named entity group) i.e. Person, Location, and Time is generated in order to feed semantic interpreter on user question. From 222 concepts defined from the ontology, we clustered them into 77, 24, and 6 concepts for Person, Location, and Time respectively. Since we found there are some characteristics of texts in ITQ, we developed our own modules to deal with including generate the inverted index and named entity recognition. Answer extraction is conducted by applying some features extraction in order to score the answer candidates. Evaluation of the system is designed by providing two data set of question and answer where the first one is purposed to measure the effectiveness of semantic approach comparing with keyword-based retrieval and the last one aims to know system performance in regard the appearance of concepts in ITQ.", "references": ["Gusmita, Ria Hari, et al. \"A rule-based question answering system on relevant documents of Indonesian Quran Translation.\" Cyber and IT Service Management (CITSM), 2014 International Conference on. IEEE, 2014", "Zidny, Nafán, and Gusmita, Ria Hari, \"Developing an Indonesian Question Answering System about Khulafaur Rasyidin History\", in Proceedings of The 1st International Conference on Cyber & IT Service Management in Conjunction with the ITIL v.3 Workshop, Training and Certification, Bandung, Indonesia, 2012.", "Anggraeny, Meynar Dwi. \"Implementasi Question Answering System Dengan Metode Rule-Based Pada Terjemahan Al Qur'an Surat Al Baqarah.\" (2007)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011219"}, {"title": "LSH ensemble: internet-scale domain search", "authors": ["Erkang Zhu\n,", "Fatemeh Nargesian\n,", "Ken Q. Pu\n,", "Renée J. Miller"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe study the problem of domain search where a domain is a set of distinct values from an unspecified universe. We use Jaccard set containment score, defined as |Q ∩ X|/|Q|, as the measure of relevance of a domain X to a query domain Q. Our choice of Jaccard set containment over Jaccard similarity as a measure of relevance makes our work particularly suitable for searching Open Data and data on the web, as Jaccard similarity is known to have poor performance over sets with large differences in their domain sizes. We demonstrate that the domains found in several real-life Open Data and web data repositories show a power-law distribution over their domain sizes.\nWe present a new index structure, Locality Sensitive Hashing (LSH) Ensemble, that solves the domain search problem using set containment at Internet scale. Our index structure and search algorithm cope with the data volume and skew by means of data sketches using Minwise Hashing and domain partitioning. Our index structure does not assume a prescribed set of data values. We construct a cost model that describes the accuracy of LSH Ensemble with any given partitioning. This allows us to formulate the data partitioning for LSH Ensemble as an optimization problem. We prove that there exists an optimal partitioning for any data distribution. Furthermore, for datasets following a power-law distribution, as observed in Open Data and Web data corpora, we show that the optimal partitioning can be approximated using equi-depth, making it particularly efficient to use in practice.\nWe evaluate our algorithm using real data (Canadian Open Data and WDC Web Tables) containing up over 262 million domains. The experiments demonstrate that our index consistently outperforms other leading alternatives in accuracy and performance. The improvements are most dramatic for data with large skew in the domain sizes. Even at 262 million domains, our index sustains query performance with under 3 seconds response time.", "references": ["P. Agrawal, A. Arasu, and R. Kaushik. On indexing error-tolerant set containment. In SIGMOD, pages 927--938, 2010.", "A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In Communications of the ACM, pages 117--122, 2008.", "D. Aumueller, H. H. Do, S. Massmann, and E. Rahm. Schema and ontology matching with COMA++. In SIGMOD, pages 906--908, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2994509.2994534"}, {"title": "Unconscious Biometrics for Continuous User Verification", "authors": ["Isao Nakanishi"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn user management system, continuous or successive (on-demand) authentication is required to prevent identity theft. In particular, biometrics of which data are unconsciously presented to authentication systems is necessary. In this paper, brain waves and intra-palm propagation signals are introducedas biometrics and their verification performancesusing actually measured data are presented.", "references": ["Altinok A. and Turk M. 2003. Temporal Integration for Continuous Multimodal Biometrics. In Proceedings of Workshop on Multimodal User Authentication (2003), 207--214.", "Nakanishi I. and Miyamoto C. 2010. On-Demand Biometric Authentication of Computer Users Using Brain Waves. In Networked Digital Technologies. F. Zavoral et al. Eds. Communications in Computer and Information Science (CCIS) series of Springer LNCS, 87 (Jul. 2010), 504--514.", "Poulos M., Rangoussi M., Chrissikopoulos V., and Evangelou A. 1999. Person Identification Based on Parametric Processing of the EEG. In Proceedings. of the 9th IEEE International Conference on Electronics, Circuits and Systems, 1(1999), 283--286."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015180"}, {"title": "Vietnamese plagiarism detection method", "authors": ["Le Thanh Nguyen\n,", "Nguyen Xuan Toan\n,", "Dinh Dien"], "publication": "SoICT '16: Proceedings of the Seventh Symposium on Information and Communication Technology", "abstract": "ABSTRACT\nNowadays, with the era of information technology development, not only in Vietnam but also all over the world, plagiarism problem is becoming very popular in many areas of life. Besides, the application of natural language processing in detecting plagiarism has been studied and made the significant progress in recent years. However, the Vietnamese plagiarism detection method just starts at a basic level for exact copy and near copy cases, even the foreign plagiarism detection software cannot detect Vietnamese plagiarism cases effectively, especially paraphrasing cases. In fact, the violators can create plagiarism cases very easily by rewriting the sentences by using the synonyms, near-meaning words.... In this paper, we propose the Vietnamese plagiarism detection method combining four methods: substrings n-gram, LCS, CS and Fuzzy-based. Our model not only achieves good results in simple cases like exact copy and near copy but also detects paraphrasing cases effectively. The experimental results show that our model has 90% precision, 88.3% recall and 89.1% F-measure.", "references": ["Alzahrani S M, Salim N, Abraham A. 2012. Understanding plagiarism linguistic patterns, textual features, and detection methods. IEEE Transactions on Systems, Man, and Cybernetics- Part C: Applications and Reviews. Vol. 42, No. 2 (March 2012), 133--149.", "C. Grozea, C. Gehl, and M. Popescu 2012. ENCOPLOT: Pairwise sequence matching in linear time applied to plagiarism detection. Proc. SEPLN (Donostia, Spain, 2012), 10--18.", "C. Basile, D. Benedetto, E. Caglioti, G. Cristadoro, and M. D. Esposti 2009. A plagiarism detection procedure in three steps: Selection, matches and \"squares\". Proc. SEPLN (Donostia, Spain, 2009), 19--23."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011077.3011109"}, {"title": "On a Topic Model for Sentences", "authors": ["Georgios Balikas\n,", "Massih-Reza Amini\n,", "Marianne Clausel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nProbabilistic topic models are generative models that describe the content of documents by discovering the latent topics underlying them. However, the structure of the textual input, and for instance the grouping of words in coherent text spans such as sentences, contains much information which is generally lost with these models. In this paper, we propose sentenceLDA, an extension of LDA whose goal is to overcome this limitation by incorporating the structure of the text in the generative and inference processes. We illustrate the advantages of sentenceLDA by comparing it with LDA using both intrinsic (perplexity) and extrinsic (text classification) evaluation tasks on different text collections.", "references": ["L. Azzopardi, M. Girolami, and K. van Risjbergen. Investigating the relationship between language model perplexity and IR precision-recall measures. In SIGIR, pages 369--370, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "J. L. Boyd-Graber and D. M. Blei. Syntactic topic models. In Advances in neural information processing systems, pages 185--192, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914714"}, {"title": "Session details: Session 2A: Memory Management", "authors": ["Ricardo Bianchini"], "publication": "ACM SIGPLAN Notices", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3262085"}, {"title": "Using the SPENCE Model of Online/Offline Community to Analyse Sociality of Social Machines", "authors": ["Caroline A. Halcrow\n,", "Leslie Carr\n,", "Susan Halford"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nOnline/offline community (O/OC), the integrated performance of community in a blend of online/offline activities is increasingly prevalent as online systems organise, mediate and broadcast forms of communal engagement. O/OCs are social machines where the focus is on the social achievement, rather than the computational outcomes, of the combined human-technical infrastructure. An O/OC model SPENCE is proposed as an analytical tool for describing social machines from the perspective of sociality. Twitter is a technical infrastructure and social network of shared online/offline community phenomena that is also a social machine combining social participation with conventional forms of machine-based computation. Drawing from the extensive Twitter research literature, a sample of papers are analysed against SPENCE, demonstrating the clarity of the organisation of inter-relating themes of a range of perspectives in current Twitter research. It is concluded that SPENCE provides a lens of synthesis for the sociality dimension of a social machine and can be used in taxonomic activities (such as the social machines observatory) to differentiate social machines.", "references": ["Giddens, A. and Sutton, P. 2013. Sociology, 7th ed. Polity, Cambridge.", "Moscovici, S. 1981. On Social representations. Social Cognition: Perspectives on Everyday Understanding, 181--209.", "Preece, J. and Maloney-Krichmar, D. 2005. Online Communities: Design, Theory, and Practice. Journal of Computer-Mediated Communication 10, 4."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890596"}, {"title": "Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification", "authors": ["Xiaodong Yang\n,", "Pavlo Molchanov\n,", "Jan Kautz"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper presents a novel framework to combine multiple layers and modalities of deep neural networks for video classification. We first propose a multilayer strategy to simultaneously capture a variety of levels of abstraction and invariance in a network, where the convolutional and fully connected layers are effectively represented by our proposed feature aggregation methods. We further introduce a multimodal scheme that includes four highly complementary modalities to extract diverse static and dynamic cues at multiple temporal scales. In particular, for modeling the long-term temporal information, we propose a new structure, FC-RNN, to effectively transform pre-trained fully connected layers into recurrent layers. A robust boosting model is then introduced to optimize the fusion of multiple layers and modalities in a unified way. In the extensive experiments, we achieve state-of-the-art results on two public benchmark datasets: UCF101 and HMDB51.", "references": ["D. Borth, T. Chen, R. Ji, and S. Chang. Sentibank: large-scale ontology and classi ers for detecting sentiment and emotions in visual content. In ACM Multimedia, 2013.", "T. Brox, A. Bruhn, N. Papenberg, and J. Weickert. High accuracy optical ow estimation based on a theory for warping. In ECCV, 2004.", "Z. Cai, L. Wang, X. Peng, and Y. Qiao. Motionlets: mid-level 3D parts for human motion recognition. In CVPR, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964297"}, {"title": "Past, Present, and Future of Recommender Systems: An Industry Perspective", "authors": ["Xavier Amatriain"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nIn 2006, Netflix announced a $1M prize competition to advance recommendation algorithms. The recommendation problem was simplified as the accuracy in predicting a user rating measured by the Root Mean Squared Error. While that formulation helped get the attention of the research community, it put the focus on the wrong approach and metric while leaving many important factors out, in particular the UI. In this talk I will talk of the Netflix Prize as the past of recommendations. I will then describe the present from an industry perspective based on my personal experience at Netflix first and Quora now . I will describe the different components of modern recommender systems such as: personalized ranking, similarity, explanations, context-awareness, or search as recommendation. I will also review the usage of novel algorithmic approaches such as Factorization Machines, Restricted Boltzmann Machines, SimRank, Deep Neural Networks, or Listwise Learning-to-rank. We will see how those components and algorithmic approaches can be used to recommend not only movies, but also questions, answers, topics, or users.\nBut, most importantly, I will give many examples of prototypical industrial-scale recommender systems with special focus on the user interface and its interaction with the algorithms. It is clearly in the interface of the UI and the novel algorithms where the future of recommender systems lays.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856798"}, {"title": "Quality Assessment of Wikipedia Articles without Feature Engineering", "authors": ["Quang Vinh Dang\n,", "Claudia-Lavinia Ignat"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nAs Wikipedia became the largest human knowledge repository, quality measurement of its articles received a lot of attention during the last decade. Most research efforts focused on classification of Wikipedia articles quality by using a different feature set. However, so far, no ``golden feature set\" was proposed. In this paper, we present a novel approach for classifying Wikipedia articles by analysing their content rather than by considering a feature set. Our approach uses recent techniques in natural language processing and deep learning, and achieved a comparable result with the state-of-the-art.", "references": ["N. S. Altman. An introduction to kernel and nearest-neighbor nonparametric regression. The American Statistician, 46(3):175--185, 1992.", "Y. Bengio. Learning deep architectures for AI. Found. Trends Mach. Learn., 2(1):1--127, Jan. 2009.", "J. E. Blumenstock. Size matters: word count as a measure of quality on Wikipedia. In Proc. of WWW, pages 1095--1096, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910917"}, {"title": "TPC: Target-Driven Parallelism Combining Prediction and Correction to Reduce Tail Latency in Interactive Services", "authors": ["Myeongjae Jeon\n,", "Yuxiong He\n,", "Hwanju Kim\n,", "Sameh Elnikety\n,", "Scott Rixner\n,", "Alan L. Cox"], "publication": "ASPLOS '16: Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems", "abstract": "ABSTRACT\nIn interactive services such as web search, recommendations, games and finance, reducing the tail latency is crucial to provide fast response to every user. Using web search as a driving example, we systematically characterize interactive workload to identify the opportunities and challenges for reducing tail latency. We find that the workload consists of mainly short requests that do not benefit from parallelism, and a few long requests which significantly impact the tail but exhibit high parallelism speedup. This motivates estimating request execution time, using a predictor, to identify long requests and to parallelize them. Prediction, however, is not perfect; a long request mispredicted as short is likely to contribute to the server tail latency, setting a ceiling on the achievable tail latency. We propose TPC, an approach that combines prediction information judiciously with dynamic correction for inaccurate prediction. Dynamic correction increases parallelism to accelerate a long request that is mispredicted as short. TPC carefully selects the appropriate target latencies based on system load and parallelism efficiency to reduce tail latency.\nWe implement TPC and several prior approaches to compare them experimentally on a single search server and on a cluster of 40 search servers. The experimental results show that TPC reduces the 99th- and 99.9th-percentile latency by up to 40% compared with the best prior work. Moreover, we evaluate TPC on a finance server, demonstrating its effectiveness on reducing tail latency of interactive services beyond web search.", "references": ["M.-C. Albutiu, A. Kemper, and T. Neumann. Massively parallel sort-merge joins in main memory multi-core database systems. VLDB, 5 (10): 1064--1075, June 2012.", "R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. The impact of caching on search engines. In SIGIR, 2007.", "L. A. Barroso, J. Dean, and U. Hölzle. Web search for a planet: The google cluster architecture. IEEE Micro, 23 (2): 22--28, Mar. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872362.2872370"}, {"title": "Multi-Scale Triplet CNN for Person Re-Identification", "authors": ["Jiawei Liu\n,", "Zheng-Jun Zha\n,", "QI Tian\n,", "Dong Liu\n,", "Ting Yao\n,", "Qiang Ling\n,", "Tao Mei"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nPerson re-identification aims at identifying a certain person across non-overlapping multi-camera networks. It is a fundamental and challenging task in automated video surveillance. Most existing researches mainly rely on hand-crafted features, resulting in unsatisfactory performance. In this paper, we propose a multi-scale triplet convolutional neural network which captures visual appearance of a person at various scales. We propose to optimize the network parameters by a comparative similarity loss on massive sample triplets, addressing the problem of small training set in person re-identification. In particular, we design a unified multi-scale network architecture consisting of both deep and shallow neural networks, towards learning robust and effective features for person re-identification under complex conditions. Extensive evaluation on the real-world Market-1501 dataset have demonstrated the effectiveness of the proposed approach.", "references": ["Roberto Vezzani, Davide Baltieri, and Rita Cucchiara. People reidentification in surveillance and forensics: A survey. ACM Computing Surveys (CSUR), 46(2):29, 2013.", "Shaogang Gong, Marco Cristani, Shuicheng Yan, and Chen Change Loy. Person re-identification, volume 1. Springer, 2014.", "Sakrapee Paisitkriangkrai, Chunhua Shen, and Anton van den Hengel. Learning to rank in person re-identification with metric ensembles. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1846--1855, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967209"}, {"title": "Development of e-Guide App for the Holy Week", "authors": ["Luiz F. Carvalho\n,", "Eduardo Abreu Carazza\n,", "Darlinton B.F. Carvalho\n,", "Fabio Correa\n,", "Alessandra F. Brasileiro"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis article presents the principles considered in the development of an electronic guide that aims to contribute to the dissemination and participation in the celebration of Holy Week in the city of Sao Joao del-Rei, MG. It is a scientific-technological study, which draws on exploratory research on the topic, analysis and application of taxonomy techniques for organizing information, which culminated in the development of an application for smartphones in order to provide access to information available on the Internet (web). The presented results are a reference model for the development of e-guide applications that allow access considering three ways organization (chronological, thematic and spatial), content with multimedia format and interactivity among its users promoted through other popular service social media (mashup). Despite the scientific findings, we believe that the application tends to promote regional tourism, improving the experience of user participation in the celebration of Holy Week, besides serving as a reference for developing similar initiatives involving the development of e-guide apps that rely on the use of multimedia information and services available online.", "references": ["ANATEL - Agencia Nacional de Telecomunicacoes. 2015. Relatorios Consolidados - Indicadores de 2012 a 2014.", "CAMPOS, Adalgisa Arantes. Aspectos da Semana Santa atraves do estudo das Irmandades do Santissimo Sacramento: cultura artistica e solenidades (Minas Gerais seculos XVIII ao XX). Revista Barroco, 2005, p. 71-88.", "CAMPOS, Maria Luiza de Almeida; GOMES, Hagar Espanha. Taxonomia e classificacao: a categorizacao como principio. VIII ENANCIB - Encontro Nacional de Pesquisa em Ciencia da Informacao, 2007"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022017"}, {"title": "Mental Visual Indexing: Towards Fast Video Browsing", "authors": ["Richang Hong\n,", "Jun He\n,", "Hanwang Zhang\n,", "Tat-Seng Chua"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nVideo browsing describes an interactive process where users want to find a target shot in a long video. Therefore, it is crucial for a video browsing system to be fast and accurate with minimum user effort. In sharp contrast to traditional Relevance Feedback (RF), we propose a novel paradigm for fast video browsing dubbed Mental Visual Indexing (MVI). At each interactive round, the user only needs to select one of the displayed shots that is most visually similar to her mental target and then the user's choice will further tailor the search to the target. The search model update given a user feedback only requires vector inner products, which makes MVI highly responsive. MVI is underpinned by a sequence model in terms of Recurrent Neural Network (RNN), which is trained by automatically generated shot sequences from a rigorous Bayesian framework, which simulates user feedback process. Experimental results on three 3-hour movies conducted by real users demonstrate the effectiveness of the proposed approach.", "references": ["M. Ferecatu and D. Geman. A statistical framework for image category search from a mental picture. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31(6):1087--1101, 2009.", "J. He, X. Shang, H. Zhang, and T.-S. Chua. Mental visual browsing. In MultiMedia Modeling, pages 424--428. Springer, 2016.", "H. Jégou and O. Chum. Negative evidences and co-occurences in image retrieval: The benefit of pca and whitening. In Computer Vision--ECCV 2012, pages 774--787. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967296"}, {"title": "Knowledgebase Harvesting for User-Adaptive Systems Through Focused Crawling and Semantic Web", "authors": ["Bujar Raufi\n,", "Florije Ismaili\n,", "Jaumin Ajdari\n,", "Xhemal Zenuni"], "publication": "CompSysTech '16: Proceedings of the 17th International Conference on Computer Systems and Technologies 2016", "abstract": "ABSTRACT\nThe expansion and ever evolving web makes it difficult to find relevant information that best fits user's intentions. This paper introduces development of hybrid approach that addresses the issue of collecting large knowledgebase by fusing the thematic or focused crawling methodologies, with adaptive and semantic web concepts. Focused crawling ensures the goal directed search of data on the web, adaptive web environments establish proper content and link adaptation whilst semantic web inserts meaning to web documents from the sense of content and metadata. The thematic crawling process retrieved approximately 11,429 documents from 11,286 visited locations resulting in 9,807 database entries out of which 81 entries are classified as top ranked distributed in seven categories. On the next phase, a reasoning process was performed against the semantic ontology which comprised the top ranked documents as class individuals. Results indicated that retrieved relevant documents, together with assertions against class individuals from the ontology highly reflect the user browsing activities and intentions.", "references": ["Barbosa, L., J. Freire. An Adaptive Crawler for Locating Hidden-Web Entry Points. In Proceedings of the 16th international conference on World Wide Web. 2007, pp. 441--450. ACM.", "Bergmark, D., C. Lagoze, A. Sbityakov. Focused crawls, tunneling, and digital libraries. In: ECDL '02: Proceedings of the 6th European Conference on Research and Advanced Technology for Digital Libraries, London, UK, Springer-Verlag pp. 91--106, 2002.", "Berners-Lee, T., J. Hendler. Publishing on the semantic web. 2001. Nature 410, no. 6832. pp. 1023--1024."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983468.2983510"}, {"title": "Efficient discovery of longest-lasting correlation in sequence databases", "authors": ["Yuhong Li\n,", "Leong Hou U\n,", "Man Lung Yiu\n,", "Zhiguo Gong"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe search for similar subsequences is a core module for various analytical tasks in sequence databases. Typically, the similarity computations require users to set a length. However, there is no robust means by which to define the proper length for different application needs. In this study, we examine a new query that is capable of returning the longest-lasting highly correlated subsequences in a sequence database, which is particularly helpful to analyses without prior knowledge regarding the query length. A baseline, yet expensive, solution is to calculate the correlations for every possible subsequence length. To boost performance, we study a space-constrained index that provides a tight correlation bound for subsequences of similar lengths and offset by intraobject and interobject grouping techniques. To the best of our knowledge, this is the first index to support a normalized distance metric of arbitrary length subsequences. In addition, we study the use of a smart cache for disk-resident data (e.g., millions of sequence objects) and a graph processing unit-based parallel processing technique for frequently updated data (e.g., nonindexable streaming sequences) to compute the longest-lasting highly correlated subsequences. Extensive experimental evaluation on both real and synthetic sequence datasets verifies the efficiency and effectiveness of our proposed methods.", "references": ["Agrawal, R., Faloutsos, C., Swami, A.N.: Efficient similarity search in sequence databases. In: FODO, pp. 69---84 (1993)", "Assent, I., Krieger, R., Afschari, F., Seidl, T.: The TS-tree: efficient time series search and retrieval. In: EDBT, pp. 252---263 (2008)", "Athitsos, V., Papapetrou, P., Potamias, M., Kollios, G., Gunopulos, D.: Approximate embedding-based subsequence matching of time series. In: SIGMOD, pp. 365---378 (2008)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0432-7"}, {"title": "AutoLabel: labeling places from pictures and websites", "authors": ["Rufeng Meng\n,", "Sheng Shen\n,", "Romit Roy Choudhury\n,", "Srihari Nelakuditi"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nMost location based services require semantic place names such as Staples, rather than physical coordinates. Past work has mostly focussed on achieving localization accuracy, while assuming that the translation of physical coordinates to semantic names will be done manually. This paper makes an effort to automate this step, by leveraging the presence of a website corresponding to each store and the availability of a repository of WiFi-tagged pictures from different stores. By correlating the text inside the pictures, against the text extracted from store websites, our proposed system, called AutoLabel, can automatically label clusters of pictures, and the corresponding WiFi APs, with store names. Later, when a user enters a store, her mobile device scans the WiFi APs and consults a lookup table to recognize the store she is in. Experiment results from 40 different stores show recognition accuracy upwards of 87%, even with as few as 10 pictures from a store, offering hope that automatic large-scale semantic labeling may indeed be possible from pictures and websites of stores.", "references": ["Amazon firefly. https://developer.amazon.com/public/solutions/devices/fire-phone/docs/understanding-firefly.", "Apple icloud photo library. http://www.apple.com/icloud/photos/.", "Eye-fi adds geotagging via wi-fi. http://goo.gl/q8pzQs."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971759"}, {"title": "Matrix and Tensor Decomposition in Recommender Systems", "authors": ["Panagiotis Symeonidis"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis turorial offers a rich blend of theory and practice regarding dimensionality reduction methods, to address the information overload problem in recommender systems. This problem affects our everyday experience while searching for knowledge on a topic. Naive Collaborative Filtering cannot deal with challenging issues such as scalability, noise, and sparsity. We can deal with all the aforementioned challenges by applying matrix and tensor decomposition methods. These methods have been proven to be the most accurate (i.e., Netflix prize) and efficient for handling big data. For each method (SVD, SVD++, timeSVD++, HOSVD, CUR, etc.) we will provide a detailed theoretical mathematical background and a step-by-step analysis, by using an integrated toy example, which runs throughout all parts of the tutorial, helping the audience to understand clearly the differences among factorisation methods.", "references": ["Yehuda Koren. Factorization meets the neighborhood: A multifaceted collaborative filtering model. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '08, pages 426--434, New York, NY, USA, 2008. ACM.", "Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30--37, August 2009.", "Panagiotis Symeonidis, Alexandros Nanopoulos, and Yannis Manolopoulos. Tag recommendations based on tensor dimensionality reduction. In RecSys '08: Proceedings of the 2008 ACM conference on Recommender systems, pages 43--50. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959195"}, {"title": "A Framework for Optimum Selection of Online Social Network Management Systems", "authors": ["Mohammed Al-Hougbany\n,", "Muhammad Al-Qurishi\n,", "Mabrook Al-Rakhami\n,", "Majed AlRubaian\n,", "Atif Alamri"], "publication": "ICC '16: Proceedings of the International Conference on Internet of things and Cloud Computing", "abstract": "ABSTRACT\nMany Social Media Management Systems (SMMS) have been developed to utilize multiple accounts over different online social networks. Each system has advantages and disadvantages and can be more or less useful depending on its features and cost. However, the divers and lack of consensus in SMMS functionalities, lead to a problem for the decision makers to determine what platforms and tools they should be using. In this paper, we propose a new framework to select the most appropriate platform to manage multiple social network accounts. The proposed framework has two phases, namely, evaluation and ranking. The current practice of evaluation process involves expert users opinions on the systems to rate its importance based on the users' preferences which is measured on the efficiency of the tool for finding required results. The evaluation phase of the proposed technique combines the current practice with the weight of importance, where the later one has been calculated by applying statistical methods. The ranking phase has designed based on the well-known Analytic Hierarchy Process AHP algorithm. The results have been showed as a ranking list of the candidate SMMS.", "references": ["B. Batrinca and P. Treleaven, \"Social media analytics: a survey of techniques, tools and platforms,\" AI & SOCIETY, vol. 30, pp. 89--116, 2015/02/01 2015.", "M. Al-Qurishi, M. Al-Rakhami, M. Alrubaian, A. Alarifi, S. M. M. Rahman, and A. Alamri, \"Selecting the best open source tools for collecting and visualzing social media content,\" in Web Applications and Networking (WSWAN), 2015 2nd World Symposium on, 2015, pp. 1--6.", "M. Al-Qurishi, R. Aldrees, M. AlRubaian, M. Al-Rakhami, S. M. M. Rahman, and A. Alamri, \"A new model for classifying social media users according to their behaviors,\" in Web Applications and Networking (WSWAN), 2015 2nd World Symposium on, 2015, pp. 1--5."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896387.2896409"}, {"title": "MusiSkate: enhancing the skateboarding experience through musical feedback", "authors": ["Sarthak Ghosh\n,", "Pratik Shah\n,", "Lorina Navarro\n,", "Xiaowei Chen"], "publication": "MobileHCI '16: Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct", "abstract": "ABSTRACT\nIn this paper, we investigate the potential of using musical feedback to enhance the skateboarding experience and to encourage skaters to gain more skills. We adhere to the UCD (User-Centered Design) process to discover opportunities for technological contributions in skating, followed by proposing MusiSkate as a solution based on user needs and contexts. Our findings suggest that MusiSkate has the potential to enhance the satisfaction of skating. Furthermore, it conforms to the guidelines for designing skateboarding applications as set forth by existing literature. Finally, we suggest future explorations for using audio feedback with skateboarding based on the results of our pilot study.", "references": ["Sebastiaan Pijnappel and Florian Mueller. 2013. Copy paste skate. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA '13). ACM, New York, NY, USA, 2863--2864.", "Sebastiaan Pijnappel and Florian Mueller. 2013. 4 design themes for skateboarding. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 1271--1274.", "Seifert, T., and C. Hedderson. \"Intrinsic motivation and flow in skateboarding: An ethnographic study.\" Journal of Happiness Studies 11.3 (2010): 277--292."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957265.2961854"}, {"title": "A Recommender System to tackle Enterprise Collaboration", "authors": ["Gabriel de Souza P. Moreira\n,", "Gilmar Souza"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn order to survive, companies depend on their capacity to generate and manage knowledge while promoting alignment among its employees. To tackle this problem, it was developed an enterprise collaboration platform named Smart Canvas, a service whose goal is to leverage companies' knowledge and tear down silos by connecting people, teams, and content. These connections are suggested by a Recommender System, using techniques like Topic Modeling, Content-Based Filtering and Graph traversing. Smart Canvas is a multi-tenant Software as a Service, featuring a scalable cloud-based Recommender System architecture, including tools like Spark and Titan Graph Database, deployed on Google Cloud Platform.", "references": ["Nigel Fenwick, 2015. Resolving The Collaboration Paradox. Forrester Reports (Jun. 2015). Available in https://www.forrester.com/report/Resolving+The+Collaboration+Paradox/-/E-RES119837", "Singhal, A., Buckley, C., & Mitra, M. 1996. Pivoted document length normalization. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval (pp. 21--29). ACM"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959115"}, {"title": "Probing for requirements knowledge to stimulate architectural thinking", "authors": ["Preethu Rose Anish\n,", "Balaji Balasubramaniam\n,", "Abhishek Sainani\n,", "Jane Cleland-Huang\n,", "Maya Daneva\n,", "Roel J. Wieringa\n,", "Smita Ghaisas"], "publication": "ICSE '16: Proceedings of the 38th International Conference on Software Engineering", "abstract": "ABSTRACT\nSoftware requirements specifications (SRSs) often lack the detail needed to make informed architectural decisions. Architects therefore either make assumptions, which can lead to incorrect decisions, or conduct additional stakeholder interviews, resulting in potential project delays. We previously observed that software architects ask Probing Questions (PQs) to gather information crucial to architectural decision-making. Our goal is to equip Business Analysts with appropriate PQs so that they can ask these questions themselves. We report a new study with over 40 experienced architects to identify reusable PQs for five areas of functionality and organize them into structured flows. These PQ-flows can be used by Business Analysts to elicit and specify architecturally relevant information. Additionally, we leverage machine learning techniques to determine when a PQ-flow is appropriate for use in a project, and to annotate individual PQs with relevant information extracted from the existing SRS. We trained and evaluated our approach on over 8,000 individual requirements from 114 requirements specifications and also conducted a pilot study to validate its usefulness.", "references": ["T. Tuunanen and M. Rossi, \"Engineering a Method for Wide Audience Requirements Elicitation and Integrating It to Software Development,\" in Proceedings of 37th Hawaii Int. Conference on System Sciences, Big Island, Hawaii, USA, 2004, IEEE, 10", "P. R. Anish, B. Balasubramaniam, J. Cleland-Huang, R. Wieringa, M. Daneva, S. Ghaisas. Identifying Architecturally Significant Functional Requirements, TwinPeaks 2015). IEEE Press, 3--8.", "P. R. Anish, M. Daneva, J. Cleland-Huang, R. Wieringa, S. Ghaisas. What You Ask Is What You Get: Understanding Architecturally Significant Functional Requirements, RE 2015, IEEE Press, 86--95."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2884781.2884801"}, {"title": "An Exploration of Evaluation Metrics for Mobile Push Notifications", "authors": ["Luchen Tan\n,", "Adam Roegiest\n,", "Jimmy Lin\n,", "Charles L.A. Clarke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nHow do we evaluate systems that filter social media streams and send users updates via push notifications on their mobile phones? Such notifications must be relevant, timely, and novel. In this paper, we explore various evaluation metrics for this task, focusing specifically on measuring relevance. We begin with an analysis of metrics deployed at the TREC 2015 Microblog evaluations. A simple change to the metrics, reflecting a different assumption, dramatically alters system rankings. Applying another metric, previously used in the TREC Microblog evaluations, again yields different system rankings. We find little correlation between a number of \"reasonable\" evaluation metrics, which suggests that system effectiveness depends on how you measure it---an undesirable state in IR evaluation. However, we argue that existing evaluation metrics can be generalized into a framework that uses the same underlying contingency table, but places different weights and penalties. Although we stop short of proposing the \"one true metric\", this framework can guide the future development of a family of metrics that more accurately models user needs.", "references": ["J. Allan. Topic Detection and Tracking:\\ Event-Based Information Organization. Kluwer, 2002.", "J. Aslam, M. Ekstrand-Abueg, V. Pavlu, F. Diaz, R. McCreadie, and T. Sakai. TREC 2014 Temporal Summarization Track overview. TREC, 2014.", "J. Lin, M. Efron, Y. Wang, G. Sherman, and E. Voorhees. Overview of the TREC-2015 Microblog Track. TREC, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914694"}, {"title": "An Approach to Requirements Engineering Applied to Information Systems", "authors": ["Adailton Ferreira Araujo\n,", "Juliano Lopes Oliveira\n,", "Almir Firmino Silva\n,", "Bruno Nunes Machado\n,", "Jailton Alkimin Louzada\n,", "Paulo Marcos Soares"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nInformation systems (IS) rely on software to model, simulate and execute business processes. The complexity, size and diversity of these processes is a challenge for Requirements Engineering (RE). This paper presents an approach to deal with this challenge. In this approach the concept of Business Process is the basis for all RE activities and products. A proof of concept of the feasibility of this approach has been taken with its use in the specification of software that supports the RE process itself. The comparison of this software with others that represent the state of the art on RE tools shows that few tools meet the requirements related to the RE support for IS, especially in supporting the concepts of business processes.", "references": ["Caliber rm. www.borland.com/en-GB/Products/ Requirements-Management/Caliber.", "Cameo requirements+ (plugin). www.magicdraw.com/cameoreq", "Case spec. www.analysttool.com"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021987"}, {"title": "SocialStories: Segmenting Stories within Trending Twitter Topics", "authors": ["Kokil Jaidka\n,", "Kaushik Ramachandran\n,", "Prakhar Gupta\n,", "Sajal Rustagi"], "publication": "CODS '16: Proceedings of the 3rd IKDD Conference on Data Science, 2016", "abstract": "ABSTRACT\nThis study present SocialStories - a system based on incremental clustering for streaming tweets, for identifying fine-grained stories within a broader trending topic on Twitter. The contributions include a novel tf-metric, called the inverse cluster frequency, and a decay weighting for entities. We present our experiments on 0.19 million tweets posted in June 2014, revolving around the mentions of a software brand before, during and after a marketing conference and a software release. The novelty of our work is the text-based similarity calculation metrics, including a new similarity metric, called the inverse cluster frequency, and time-specific metrics that allow for the decay of old entities with the passage of time and preserve the homogeneity and the freshness of stories. We report improved performance and higher recall of 80%, against the gold standard (posthoc journalistic reports), as compared to LDA-, and Wavelet-based systems. Our algorithm is able to cluster 80% of all tweets into story-based clusters, which are 86% pure. It also enables earlier detection of trending stories than manual reports, and is far more accurate in identifying fine-grained stories within sub-topics as compared to baseline systems.", "references": ["S. Ahmed and M. M. Skoric. My name is khan: The use of twitter in the campaign for 2013 pakistan general election. In System Sciences (HICSS), 2014 47th Hawaii International Conference on, pages 2242--2251. IEEE, 2014.", "J. Allan. Topic detection and tracking: event-based information organization, volume 12. Springer Science & Business Media, 2002.", "F. Alvanaki, S. Michel, K. Ramamritham, and G. Weikum. See what's enblogue: real-time emergent topic identification in social media. In Proceedings of the 15th International Conference on Extending Database Technology, pages 336--347. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2888451.2888453"}, {"title": "Recommender Systems with Personality", "authors": ["Amos Azaria\n,", "Jason Hong"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe believe that in the future, the most common form of recommender systems will be present in a personal assistant. We claim that such an intelligent agent must be personal, i.e., know its user's preferences and recommend relevant content, a dynamic learner, instructable, supportive and affable. We describe the current state of the art and the challenges which should be addressed in each of these agent properties and provide examples of how we expect future personal agents to convey these properties.", "references": ["Amos Azaria, Jayant Krishnamurthy, and Tom M Mitchell. Instructable intelligent personal agent. In AAAI, volume 4, 2016.", "John S Breese, David Heckerman, and Carl Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Uncertainty in artificial intelligence, pages 43--52. Morgan Kaufmann Publishers Inc., 1998.", "David L Chen and Raymond J Mooney. Learning to interpret natural language navigation instructions from observations. San Francisco, CA, pages 859--865, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959138"}, {"title": "Using Semantics to Search Answers for Unanswered Questions in Q&A Forums", "authors": ["Priyanka Singh\n,", "Elena Simperl"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe expert based question and answering forums are crowdsourced and rely on people to provide answers for questions. This paper focuses on technology based Q&A systems like StackOverflow and Reddit. These websites are popular and yet many questions remain unanswered. The Suman system uses semantic keyword search in combination with traditional text search techniques to find similar questions with answers for unanswered questions. Furthermore, the Suman system also recommends experts who can answer those questions. This helps to narrow down the long tail of unanswered questions. The Suman system utilises Semantic Web and Linked Data technologies to integrate the datasets from two websites, structure them and link them to Linked Data Cloud. It uses available tools to solve name entity disambiguation problem and expands the query term with added semantics. The Suman system was evaluated and results were analysed to show its viability.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "T. Berners-Lee, J. Hendler, and O. Lassila. The semantic web: Scientific american. Scientific American, 284(5):34--43, 2001.", "J. Bhogal, A. Macfarlane, and P. Smith. A review of ontology based query expansion. Information processing & management, 43(4):866--886, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890569"}, {"title": "SPrank: Semantic Path-Based Ranking for Top-N Recommendations Using Linked Open Data", "authors": ["Tommaso Di Noia\n,", "Vito Claudio Ostuni\n,", "Paolo Tomeo\n,", "Eugenio Di Sciascio"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nIn most real-world scenarios, the ultimate goal of recommender system applications is to suggest a short ranked list of items, namely top-N recommendations, that will appeal to the end user. Often, the problem of computing top-N recommendations is mainly tackled with a two-step approach. The system focuses first on predicting the unknown ratings, which are eventually used to generate a ranked recommendation list. Actually, the top-N recommendation task can be directly seen as a ranking problem where the main goal is not to accurately predict ratings but to directly find the best-ranked list of items to recommend. In this article we present SPrank, a novel hybrid recommendation algorithm able to compute top-N recommendations exploiting freely available knowledge in the Web of Data. In particular, we employ DBpedia, a well-known encyclopedic knowledge base in the Linked Open Data cloud, to extract semantic path-based features and to eventually compute top-N recommendations in a learning-to-rank fashion. Experiments with three datasets related to different domains (books, music, and movies) prove the effectiveness of our approach compared to state-of-the-art recommendation algorithms.", "references": ["Sarabjot Singh Anand, Patricia Kearney, and Mary Shapcott. 2007. Generating semantically enriched user profiles for Web personalization. ACM Transactions on Internet Technology 7, 4, Article No. 22.", "Suhrid Balakrishnan and Sumit Chopra. 2012. Collaborative ranking. In Proceedings of the 5th ACM International Conference on Web Search and Data Mining (WSDM’12). ACM, New York, NY, 143--152.", "Alejandro Bellogin, Pablo Castells, and Ivan Cantador. 2011. Precision-oriented evaluation of recommender systems: An algorithmic comparison. In Proceedings of the 5th ACM Conference on Recommender Systems (RecSys’11). ACM, New York, NY, 333--336."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899005"}, {"title": "Diversified top-k clique search", "authors": ["Long Yuan\n,", "Lu Qin\n,", "Xuemin Lin\n,", "Lijun Chang\n,", "Wenjie Zhang"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nMaximal clique enumeration is a fundamental problem in graph theory and has been extensively studied. However, maximal clique enumeration is time-consuming in large graphs and always returns enormous cliques with large overlaps. Motivated by this, in this paper, we study the diversified top-k clique search problem which is to find top-k cliques that can cover most number of nodes in the graph. Diversified top-k clique search can be widely used in a lot of applications including community search, motif discovery, and anomaly detection in large graphs. A naive solution for diversified top-k clique search is to keep all maximal cliques in memory and then find k of them that cover most nodes in the graph by using the approximate greedy max k-cover algorithm. However, such a solution is impractical when the graph is large. In this paper, instead of keeping all maximal cliques in memory, we devise an algorithm to maintain k candidates in the process of maximal clique enumeration. Our algorithm has limited memory footprint and can achieve a guaranteed approximation ratio. We also introduce a novel light-weight $$\\mathsf {PNP}$$PNP-$$\\mathsf {Index}$$Index, based on which we design an optimal maximal clique maintenance algorithm. We further explore three optimization strategies to avoid enumerating all maximal cliques and thus largely reduce the computational cost. Besides, for the massive input graph, we develop an I/O efficient algorithm to tackle the problem when the input graph cannot fit in main memory. We conduct extensive performance studies on real graphs and synthetic graphs. One of the real graphs contains 1.02 billion edges. The results demonstrate the high efficiency and effectiveness of our approach.", "references": ["Aggarwal, A., Vitter, J., et al.: The input/output complexity of sorting and related problems. Commun. ACM 31(9), 1116---1127 (1988)", "Agrawal, R., Gollapudi, S., Halverson, A., Ieong, S.: Diversifying search results. In: Proceedings of WSDM'09, pp. 5---14 (2009)", "Akkoyunlu, E.A.: The enumeration of maximal cliques of large graphs. SIAM J. Comput. 2(1), 1---6 (1973)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0408-z"}, {"title": "The Impact of Fixed-Cost Pooling Strategies on Test Collection Bias", "authors": ["Aldo Lipani\n,", "Guido Zuccon\n,", "Mihai Lupu\n,", "Bevan Koopman\n,", "Allan Hanbury"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nIn Information Retrieval, test collections are usually built using the pooling method. Many pooling strategies have been developed for the pooling method. Herein, we address the question of identifying the best pooling strategy when evaluating systems using precision-oriented measures in presence of budget constraints on the number of documents to be evaluated. As a quality measurement we use the bias introduced by the pooling strategy, measured both in terms of Mean Absolute Error of the scores and in terms of ranking errors. Based on experiments on 15 test collections, we conclude that, for precision-oriented measures, the best strategies are based on Rank-Biased Precision (RBP). These results can inform collection builders because they suggest that, under fixed assessment budget constraints, RBP-based sampling produces less biased pools than other alternatives.", "references": ["B. Carterette, J. Allan, and R. Sitaraman. Minimal test collections for retrieval evaluation. In Proc. of SIGIR, 2006.", "G. V. Cormack, C. R. Palmer, and C. L. Clarke. Efficient construction of large test collections. In Proc. of SIGIR, 1998.", "A. Lipani, M. Lupu, and A. Hanbury. Splitting water: Precision and anti-precision to reduce pool bias. In Proc. of SIGIR, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970429"}, {"title": "Simple Dynamic Emission Strategies for Microblog Filtering", "authors": ["Luchen Tan\n,", "Adam Roegiest\n,", "Charles L.A. Clarke\n,", "Jimmy Lin"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPush notifications from social media provide a method to keep up-to-date on topics of personal interest. To be effective, notifications must achieve a balance between pushing too much and pushing too little. Push too little and the user misses important updates; push too much and the user is overwhelmed by unwanted information. Using data from the TREC 2015 Microblog track, we explore simple dynamic emission strategies for microblog push notifications. The key to effective notifications lies in establishing and maintaining appropriate thresholds for pushing updates. We explore and evaluate multiple threshold setting strategies, including purely static thresholds, dynamic thresholds without user feedback, and dynamic thresholds with daily feedback. Our best technique takes advantage of daily feedback in a simple yet effective manner, achieving the best known result reported in the literature to date.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. SIGIR, 1998.", "J. G. Fiscus and G. R. Doddington. Topic detection and tracking evaluation overview. Topic Detection and Tracking. Kluwer, Norwell, MA, 2002.", "L. S. Larkey, F. Feng, M. Connell, and V. Lavrenko. Language-specific models in multilingual topic tracking. SIGIR, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914704"}, {"title": "Predicting User Satisfaction with Intelligent Assistants", "authors": ["Julia Kiseleva\n,", "Kyle Williams\n,", "Ahmed Hassan Awadallah\n,", "Aidan C. Crook\n,", "Imed Zitouni\n,", "Tasos Anastasakos"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThere is a rapid growth in the use of voice-controlled intelligent personal assistants on mobile devices, such as Microsoft's Cortana, Google Now, and Apple's Siri. They significantly change the way users interact with search systems, not only because of the voice control use and touch gestures, but also due to the dialogue-style nature of the interactions and their ability to preserve context across different queries. Predicting success and failure of such search dialogues is a new problem, and an important one for evaluating and further improving intelligent assistants. While clicks in web search have been extensively used to infer user satisfaction, their significance in search dialogues is lower due to the partial replacement of clicks with voice control, direct and voice answers, and touch gestures.\nIn this paper, we propose an automatic method to predict user satisfaction with intelligent assistants that exploits all the interaction signals, including voice commands and physical touch gestures on the device. First, we conduct an extensive user study to measure user satisfaction with intelligent assistants, and simultaneously record all user interactions. Second, we show that the dialogue style of interaction makes it necessary to evaluate the user experience at the overall task level as opposed to the query level. Third, we train a model to predict user satisfaction, and find that interaction signals that capture the user reading patterns have a high impact: when including all available interaction signals, we are able to improve the prediction accuracy of user satisfaction from 71% to 81% over a baseline that utilizes only click and query features.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: a game for modeling different types of web search success using interaction data. In SIGIR, pp. 345--354, 2011.", "E. Agichtein, E. Brill, and S. T. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, pp. 19--26, 2006.", "A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between ir effectiveness measures and user satisfaction. In SIGIR, pp. 773--774, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911521"}, {"title": "Utilizing Focused Relevance Feedback", "authors": ["Elinor Brondwine\n,", "Anna Shtok\n,", "Oren Kurland"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present a novel study of ad hoc retrieval methods utilizing document-level relevance feedback and/or focused relevance feedback; namely, passages marked as (non-)relevant. The first method uses a novel mixture model that integrates relevant and non-relevant information at the language model level. The second method fuses retrieval scores produced by using relevant and non-relevant information separately. Empirical exploration attests to the merits of our methods, and sheds light on the effectiveness of using and integrating relevance feedback for textual units of varying granularities.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. UMASS at TREC 2004 -- novelty and hard. In Proc. of TREC-13, 2004.", "P. Arvola, S. Geva, J. Kamps, R. Schenkel, A. Trotman, and J. Vainio. Overview of the inex 2010 ad hoc track. In Comparative Evaluation of Focused Retrieval - INEX, pages 1--32. 2010.", "C. Buckley and S. Robertson. Relevance feedback track overview: TREC 2008. In Proc. of TREC-17, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914695"}, {"title": "A Framework for Task-specific Short Document Expansion", "authors": ["Ramakrishna B. Bairi\n,", "Raghavendra Udupa\n,", "Ganesh Ramakrishnan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nCollections that contain a large number of short texts are becoming increasingly common (eg., tweets, reviews, etc). Analytical tasks (such as classification, clustering, etc.) involving short texts could be challenging due to the lack of context and owing to their sparseness. An often encountered problem is low accuracy on the task. A standard technique used in the handling of short texts is expanding them before subjecting them to the task. However, existing works on short text expansion suffer from certain limitations: (i) they depend on domain knowledge to expand the text; (ii) they employ task-specific heuristics; and (iii) the expansion procedure is tightly coupled to the task. This makes it hard to adapt a procedure, designed for one task, into another. We present an expansion technique -- TIDE (Task-specIfic short Document Expansion) -- that can be applied on several Machine Learning, NLP and Information Retrieval tasks on short texts (such as short text classification, clustering, entity disambiguation, and the like) without using task specific heuristics and domain-specific knowledge for expansion. At the same time, our technique is capable of learning to expand short texts in a task-specific way. That is, the same technique that is applied to expand a short text in two different tasks is able to learn to produce different expansions depending upon what expansion benefits the task's performance. To speed up the learning process, we also introduce a technique called block learning. Our experiments with classification and clustering tasks show that our framework improves upon several baselines according to the standard evaluation metrics which includes the accuracy and normalized mutual information (NMI).", "references": ["Measuring semantic similarity between words using web search engines. WWW, 2007.", "S. Banerjee, K. Ramanathan, and A. Gupta. Clustering short texts using wikipedia. SIGIR, 2007.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983811"}, {"title": "Analysis of Methods and Tools for Relevant Words Recognition in Microblogs", "authors": ["Danielly Sorato\n,", "Fabio B. Goularte\n,", "Silvia M. Nassar\n,", "Renato Fileto"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nExtracting accurate information from the huge volumes of data, much of them unstructured, generated in social media is currently a big challenge. However, it has several relevant applications, some of them latent yet. One of the first and most decisive steps in this information extraction process is the recognition of relevant words in texts. This article presents a comparative study of methods and tools for recognizing relevant words on microblog posts. Among several analyzed tools, five have been selected for experments with 100,000 tweets. These experiments showed high variability of the results generated by different tools, suggesting a need for improvements", "references": ["Habib, M. B., and Keulen, V. M. (2014). Information extraction for social media. ACL.", "Jurafsky, D. and Martin, J. H. (2008). Speech and Language processing: An introduction to natural language processing. 2nd Ed., Pearson Prentice Hall.", "Tjong Kim Sang, E. F., and De Meulder, F. (2003). Introduction to the CoNLL-2003 shared task: Languageindependent named entity recognition. In Proc. CNLL at HLT-NAACL (vol. 4, pp. 142-147). ACL"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022014"}, {"title": "Inventor Name Disambiguation for a Patent Database Using a Random Forest and DBSCAN", "authors": ["Kunho Kim\n,", "Madian Khabsa\n,", "C. Lee Giles"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nInventor name disambiguation is the task that distinguishes each unique inventor from all other inventor records in a patent database. This task is essential for processing person name queries in order to get information related to a specific inventor, e.g. a list of all that inventor's patents. Using earlier work on author name disambiguation, we apply it to inventor name disambiguation. A random forest classifier is trained to classify whether each pair of inventor records is the same person. The DBSCAN algorithm is use for inventor record clustering, and its distance function is derived using the random forest classifier. For scalability, blocking functions are used to reduce the complexity of record matching and enable parallelization since each block can be run simultaneously. Tested on the USPTO patent database, 12 million inventor records were disambiguated in 6.5 hours. Evaluation on the labeled datasets from USPTO PatentsView competition shows our algorithm outperforms all algorithms submitted to the competition.", "references": ["L. Breiman. Random forests. Machine learning, 45(1):5--32, 2001.", "M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining(KDD'96), volume 96, pages 226--231, 1996.", "J. Huang, S. Ertekin, and C. L. Giles. Efficient name disambiguation for large-scale databases. In Proceedings of the 10th European Conference on Principle and Practice of Knowledge Discovery in Databases(PKDD'06), pages 536--544, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925465"}, {"title": "Features for Discriminating Helicobacter Pylori Infection from Gastric X-ray Images", "authors": ["Koji Abe\n,", "Daiki Miura\n,", "Masahide Minami"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThis paper presents a method for extracting effective image features from double contrast X-ray images of stomach to discriminate Helicobacter pylori infection with the images. In the proposed method, after the area for diagnosis is determined, the proposed features are extracted from the area based on characteristics of the images with the infection. In the images, a pattern of folds is shown in the area and diagnosticians diagnose the infection or a normal case reading the pattern. The features are designed according to the standard for reading the fold patterns of the infection. In addition to quantitative evaluation for the infection, the proposed method discriminates the images into normal and infection cases using a learning machine regarding the proposed features as variables. Experimental results obtained by applying the proposed method to the X-ray images have shown effectiveness of the proposed features.", "references": ["S. Nakajima and T. Ito. Atlas of diagnosis for h. pylori infection by X-ray fluoroscopy. Association of Gastrointestinal Contrast Imaging in Kansai (Japanese Edition), Kobe, Hyogo, 2013.", "H. Watabe, T. Mitsushima, Y. Yamaji, M. Okamoto, R. Wada, T. Kokubo, H. Doi, H. Yoshida, T. Kawabe, and M. Omata. Predicting the development of gastric cancer from combining helicobacter pylori antibodies and serum pepsinogen status: a prospective endoscopic cohort study. Gut, 54(6):764--768, June 2005.", "T. Kudo, S. Kakizaki, N. Sohara, Y. Onozato, S. Okamura, Y. Inui, and M. Mori. Analysis of abc(d) stratification for screening patients with gastric cancer. World Journal of Gastroenterology, 17(43):4793--4798, November 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015190"}, {"title": "Towards an Ontology-Driven Adaptive Dialogue Framework", "authors": ["Georgios Meditskos\n,", "Stamatia Dasiopoulou\n,", "Louisa Pragst\n,", "Stefan Ultes\n,", "Stefanos Vrochidis\n,", "Ioannis Kompatsiaris\n,", "Leo Wanner"], "publication": "MARMI '16: Proceedings of the 1st International Workshop on Multimedia Analysis and Retrieval for Multimodal Interaction", "abstract": "ABSTRACT\nIn this paper, we describe the principles and technologies that underpin the development of an adaptive dialogue manager framework, tailored to carrying out human-agent conversations in a natural, robust and flexible manner. Our research focus is twofold. First, the investigation of dialogue strategies that can handle dynamically created user and system actions, while still enabling the agent to adapt its actions to various and possibly changing contexts. Second, the utilisation of rich semantic annotations for capturing background knowledge, as well as conversation topics and semantics of user utterances extracted through language analysis. The resulting annotations comprise the situational descriptions upon which reasoning takes place to recognise the conversation context and compile appropriate responses.", "references": ["N. Aggarwal and P. Buitelaar. A system description of natural language query over dbpedia. Proc. of Interacting with Linked Data, pages 96--99, 2012.", "I. Augenstein, S. Padó, and S. Rudolph. Lodifier: Generating linked data from unstructured text. In The Semantic Web: Research and Applications - Extended Semantic Web Conference, pages 210--224, 2012.", "M. Ballesteros, B. Bohnet, S. Mille, and L. Wanner. Data-driven deep-syntactic dependency parsing. Natural Language Engineering, pages 1--36, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2927006.2927009"}, {"title": "Cued Retrieval of Personal Memories of Social Interactions", "authors": ["Seyed Ali Bahrainian\n,", "Fabio Crestani"], "publication": "LTA '16: Proceedings of the first Workshop on Lifelogging Tools and Applications", "abstract": "ABSTRACT\nThis paper aims at developing a social interactions summarizer system that firstly summarizes a person's daily social interactions, with the purpose of enhancing his episodic memory and secondly provides various methods for searching in the collected data. The first goal originates from studies that have shown that replaying video or audio recordings of an experience have proved effective in enhancing people's episodic memory. The second goal is based on the fact that with the emergence of wearable devices for lifelogging, every day huge archives of data consisting of images, audio, etc could be generated from a person's life. Over time the growth rate of such archives is so substantially high that manually searching them, even after a few months of data collection, would be cumbersome and virtually impossible. In this study, we present a method for effectively summarizing one's social interactions for enhancing her episodic memory. Our results, reporting work in progress, illustrate that our method is highly effective in augmenting one's episodic memory.", "references": ["R. Atkinson. Hilgard's Introduction to Psychology. Harcourt College Publishers, 2000.", "E. Berry, A. Hampshire, J. Rowe, S. Hodges, N. Kapur, P. Watson, G. Browne, G. Smyth, K. Wood, and A. Owen. The neural basis of effective memory therapy in a patient with limbic encephalitis. J Neurol Neurosurg Psychiatry, 80:1202--1205, 2009.", "D. M. Blei and J. D. Lafferty. Dynamic topic models. In Proceedings of the 23rd International Conference on Machine Learning, ICML '06, pages 113--120, New York, NY, USA, 2006. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983576.2983577"}, {"title": "Concept Evolution Modeling Using Semantic Vectors", "authors": ["Tin Kam Ho\n,", "Luis A. Lastras\n,", "Oded Shmueli"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe propose a method for a concept-centric semantic analysis of an evolving corpus, highlighting the persistent concepts, emergence of new concepts, and the changes in the semantic associations between concepts. We report our findings on a corpus of computer science literature that spans six decades, revealing interesting patterns about the progress of the discipline.", "references": ["Bengio, Y., Ducharme, R., Vincent, P., and Janvin, C. 2003. A neural probabilistic language model. J. Machine Learning Research. 3, 1137--1155.", "Cheng, X. and Roth, D. 2013. Relational inference for Wikification. Proc. of the Conf. on Empirical Methods in Natural Language Processing (Seattle, Washington, USA, October 18-21, 2013), 1787--1796.", "Jatowt, A. and Duh, K. 2014. A framework for analyzing semantic change of words across time. Proc. of the ACM/IEEE-CS Joint Conf. on Digital Libraries (London, UK, September 8--12, 2014), 229--238."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889392"}, {"title": "How Writers Search: Analyzing the Search and Writing Logs of Non-fictional Essays", "authors": ["Matthias Hagen\n,", "Martin Potthast\n,", "Michael Völske\n,", "Jakob Gomoll\n,", "Benno Stein"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nMany writers of non-fictional texts engage intensively in exploratory web search scenarios during their background research on the essay topic. Though understanding such search behavior is necessary for the development of search engines that specifically support writing tasks, it has neither been systematically recorded nor analyzed. This paper contributes part of the missing research: We report on the outcomes of a large-scale corpus construction initiative to acquire detailed interaction logs of writers who were given a writing task on 150 pre-defined TREC topics. The corpus is freely available to foster research on exploratory search. Each essay is at least 5000 words long and comes with a chronological log of search queries, result clicks, web browsing trails, and fine-grained writing revisions that reflect the task completion status. To ensure reproducibility, a fully-fledged, static web search environment has been created on top of the ClueWeb09 corpus as part of our initiative.\nIn this paper, we present initial analyses of the recorded search interaction logs and overview insights gained from them: (1) essay writing behavior corresponds to search patterns that are rather stable for the same writer, (2) fact-checking queries often conclude a writing task, (3) recurring anchor queries are often submitted to not lose the main themes or to explore new directions, (4) query terms can be learned while searching and reading, (5) the number of submitted queries is not a good indicator for task completion.", "references": ["E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In SIGIR 2006, pp. 3--10.", "E. Agichtein, R. White, S. Dumais, and P. Bennet. Search, interrupted: Understanding and predicting search task continuation. In SIGIR 2012, pp. 315--324.", "J. Arguello. Predicting search task difficulty. In ECIR 2014, pp. 88--99."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854969"}, {"title": "Space-Efficient Index Scheme for PCM-Based Multiversion Databases in Cyber-Physical Systems", "authors": ["Yuan-Hung Kuan\n,", "Yuan-Hao Chang\n,", "Tseng-Yi Chen\n,", "Po-Chun Huang\n,", "Kam-Yiu Lam"], "publication": "ACM Transactions on Embedded Computing Systems", "abstract": "Abstract\nIn this article, we study the indexing problem of using PCM as the storage medium for embedded multiversion databases in cyber-physical systems (CPSs). Although the multiversion B+-tree (MVBT) index has been shown to be efficient in managing multiple versions of data items in a database, MVBT is designed for databases residing in traditional block-oriented storage devices. It can have serious performance problems when the databases are on phase-change memory (PCM). Since the embedded multiversion database in CPSs may have limited storage space and are update intensive, to resolve the problems of MVBT of lack of space efficiency and heavy update cost, we propose a new index scheme, called space-efficient multiversion index (SEMI), to enhance the space utilization and access performance in serving various types of queries. In SEMI, since the number of keys in the database may be small, instead of using a B-tree index, we propose to use a binary-search tree to organize the index keys. Furthermore, multiple versions of the same data item may be stored consecutively and indexed by a single entry to maximize the space utilization and at the same time to enhance the performance in serving version-range queries. Analytical studies have been conducted on SEMI, and a series of experiments have been performed to evaluate its performance as compared with MVBT under different workloads. The experimental results have demonstrated that SEMI can achieve very high space utilization and has better performance in serving update transactions and range queries as compared with MVBT.", "references": ["S. Barker, A. Mishra, D. Irwin, E. Cecchet, P. Shenoy, and J. Albrecht. 2012. Smart*: An open data set and tools for enabling research in sustainable homes. In The 2012 Workshop on Data Mining Applications in Sustainability.", "B. Becker, S. Gschwind, T. Ohler, B. Seeger, and P. Widmayer. 1996. An asymptotically optimal multiversion B-tree. VLDB Journal 5, 4 (Dec. 1996), 264--275. DOI:http://dx.doi.org/10.1007/s007780050028", "J. Chen, G. Xing, X. Wang, and X. Fu. 2011c. Fidelity-aware utilization control for cyber-physical surveillance systems. In Proceedings of the IEEE Real-Time Systems Symposium. 117--126."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2950060"}, {"title": "FITDATA: A system for monitoring physical activity based on mobile devices", "authors": ["Eduardo W. Ritter\n,", "Sandro J. Rigo"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe increased use of physical activity monitoring devices has created possibilities and opportunities to help in health care, as well as encourage the practice of physical activity and help to promote a healthier lifestyle, has also facilitated the sharing of information between professionals and patients. Because of the increased demand for these devices, several models have recently been developed and released by different manufacturers. In this context, this paper proposes the development of a physical activity monitoring system prototype aimed at health professionals, called FitData. In order to monitor the patient, the system uses commercially available wearables and mobile devices, connected to a physical activity tracking platform. The purpose of the system is to assist health professionals in the conduct of treatment, through the monitoring and evaluation of the patient. In order to evaluate the prototype was performed a questionnaire and applied to experts. The results were considered promising and allowed to observe the interest of users in the system.", "references": ["World Health Organization. 2009. Global health risks: mortality and burden of disease attributable to selected major risks. Retrieved from http://www.who.int/healthinfo/global_burden_disease/Global HealthRisks_report_full.pdf", "World Health Organization. 2014. Physical activity. Factsheet N degree 385. Retrieved from http://www.who.int/mediacentre/factsheets/fs385/en/", "Guillen, S. et al. 2009. New technologies for promoting a healthy diet and active living. Nutrition reviews. 67, 1 (May 2009), 107-110."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022047"}, {"title": "Taifūrin: Wind-Chime Installation As A Novel Typhoon Early Warning System", "authors": ["Paul Haimes\n,", "Tetsuaki Baba\n,", "Kumiko Kushiyama"], "publication": "ACE '16: Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nTaifūrin is a novel typhoon early warning system that informs people when a typhoon is approaching. We combined a traditional Japanese wind-chime (known as fūrin) with near real-time remotely-sensed typhoon data and electronic components connected to a single-circuit board computer to create a unique IoT (Internet of Things) device in the form of a simple art installation. In doing so, we aimed to combine modern interactivity with a traditional sense of Japanese aesthetics, known as wabi-sabi.", "references": ["Statistics Bureau of the Ministry of Internal Affairs and Communications. 2016. Japan Statistical Yearbook. (2016). http://www.stat.go.jp/english/data/nenkan/1431-02.htm.", "Japan Meteorological Agency. 2016. Tropical Cyclone Information. (2016). http://www.jma.go.jp/en/typh/.", "Dana Buntrock. 2010. Materials and Meaning in Contemporary Japanese Architecture: Tradition and Today. Routledge, Oxon, UK."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001773.3001830"}, {"title": "Instant Search: A Hands-on Tutorial", "authors": ["Ganesh Venkataraman\n,", "Abhimanyu Lad\n,", "Viet Ha-Thuc\n,", "Dhruv Arya"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInstant search has become a common part of the search experience in most popular search engines and social networking websites. The goal is to provide instant feedback to the user in terms of query completions (\"instant suggestions\") or directly provide search results (\"instant results\") as the user is typing their query. The need for instant search has been further amplified by the proliferation of mobile devices and services like Siri and Google Now that aim to address the user's information need as quickly as possible. Examples of instant results include web queries like \"weather san jose\" (which directly provides the current temperature), social network queries like searching for someone's name on Facebook or LinkedIn (which directly provide the people matching the query). In each of these cases, instant search constitutes a superior user experience, as opposed to making the user complete their query before the system returns a list of results on the traditional search engine results page (SERP).\nWe consider instant search experience to be a combination of instant results and instant suggestions, with the goal of satisfying the user's information need as quickly as possible with minimal effort on the part of the user. We first present the challenges involved in putting together an instant search solution at scale, followed by a survey of IR and NLP techniques that can be used to address them. We will also conduct a hands-on session aimed at putting together an end-to-end instant search system using open source tools and publicly available data sets. These tools include typeahead.js from Twitter for the frontend and Lucene/elasticsearch for the backend. We present techniques for prefix-based retrieval as well as injecting custom ranking functions into elasticsearch. For the search index, we will use the dataset made available by Stackoverflow.\nThis tutorial is aimed at both researchers interested in knowing about retrieval techniques used for instant search as well as practitioners interested in deploying an instant search system at scale. The authors have worked extensively on building and scaling LinkedIn's instant search experience. To the best of our knowledge, this is the first tutorial that covers both theoretical and practical aspects of instant search.", "references": ["Elasticsearch documentation, https://www.elastic.co/guide/index.html.", "Stackoverflow creative commons data dump, http://blog.stackoverflow.com/2009/06/stack-overflow-creative-commons-data-dump/.", "Twitter bootstrap library. http://getbootstrap.com."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914806"}, {"title": "The Semantic Web and the Semantics of the Web: Where Does Meaning Come From?", "authors": ["Peter Norvig"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe would like to understand the meaning of content on the web. Bit where should that meaning come from? From markup language annotations created by the authors of the content? Crowdsourced from readers of the content? Automatically extracted by machine learning algorithms? This talk investigates the possibilities.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2874818"}, {"title": "Query to Knowledge: Unsupervised Entity Extraction from Shopping Queries using Adaptor Grammars", "authors": ["Ke Zhai\n,", "Zornitsa Kozareva\n,", "Yuening Hu\n,", "Qi Li\n,", "Weiwei Guo"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search queries provide a surprisingly large amount of information, which can be potentially organized and converted into a knowledgebase. In this paper, we focus on the problem of automatically identifying brand and product entities from a large collection of web queries in online shopping domain. We propose an unsupervised approach based on adaptor grammars that does not require any human annotation efforts nor rely on any external resources. To reduce the noise and normalize the query patterns, we introduce a query standardization step, which groups multiple search patterns and word orderings together into their most frequent ones. We present three different sets of grammar rules used to infer query structures and extract brand and product entities. To give an objective assessment of the performance of our approach, we conduct experiments on a large collection of online shopping queries and intrinsically evaluate the knowledgebase generated by our method qualitatively and quantitatively. In addition, we also evaluate our framework on extrinsic tasks on query tagging and chunking. Our empirical studies show that the knowledgebase discovered by our approach is highly accurate, has good coverage and significantly improves the performance on the external tasks.", "references": ["S. P. Abney. Parsing by chunks. Springer, 1992.", "A. Alasiry, M. Levene, and A. Poulovassilis. Detecting candidate named entities in search queries. In SIGIR, 2012.", "C. Barr, R. Jones, and M. Regelson. The linguistic structure of english web-search queries. In EMNLP, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911495"}, {"title": "Geoparsing and Geosemantics for Social Media: Spatiotemporal Grounding of Content Propagating Rumors to Support Trust and Veracity Analysis during Breaking News", "authors": ["Stuart E. Middleton\n,", "Vadims Krivcovs"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nIn recent years, there has been a growing trend to use publicly available social media sources within the field of journalism. Breaking news has tight reporting deadlines, measured in minutes not days, but content must still be checked and rumors verified. As such, journalists are looking at automated content analysis to prefilter large volumes of social media content prior to manual verification. This article describes a real-time social media analytics framework for journalists. We extend our previously published geoparsing approach to improve its scalability and efficiency. We develop and evaluate a novel approach to geosemantic feature extraction, classifying evidence in terms of situatedness, timeliness, confirmation, and validity. Our approach works for new unseen news topics. We report results from four experiments using five Twitter datasets crawled during different English-language news events. One of our datasets is the standard TREC 2012 microblog corpus. Our classification results are promising, with F1 scores varying by class from 0.64 to 0.92 for unseen event types. We lastly report results from two case studies during real-world news stories, showcasing different ways our system can assist journalists filter and cross-check content as they examine the trust and veracity of content and sources.", "references": ["Emanuele Bastianelli, Danilo Croce, Roberto Basili, and Daniele Nardi. 2013. UNITOR-HMM-TK: Structured kernel-based learning for spatial role labeling. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval’13). ACL 2013, 573--579.", "Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing with python—Analyzing text with the natural language toolkit, O’Reilly Media.", "Christina Boididou, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia Boato, and Yiannis Kompatsiaris. 2015. The CERTH-UNITN Participation @ verifying multimedia use 2015. In MediaEval Benchmarking Initiative for Multimedia Evaluation (MediaEval’15)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2842604"}, {"title": "Appendixes", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915053"}, {"title": "A Method Based on Naming Similarity to Identify Reuse Opportunities", "authors": ["Johnatan Oliveira\n,", "Eduardo Fernandes\n,", "Mauricio Souza\n,", "Eduardo Figueiredo"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nSoftware reuse is a development strategy in which existing software components, called reusable assets, are used in the development of new software systems. There are many advantages of reuse in software development, such as minimization of development efforts and improvement of software quality. New methods for reusable asset extraction are essential to achieve these advantages. Extraction methods may be used in different contexts including software product lines derivation. However, few methods have been proposed in literature for reusable asset extraction and recommendation of these reuse opportunities. In this paper, we propose a method for extraction of reuse opportunities based on naming similarity of two types of object-oriented entities: classes and methods. Our method, called JReuse, computes a similarity function to identify similarly named classes and methods from a set of software systems from a domain. These classes and methods compose a repository with reuse opportunities. We also present a prototype tool to support the extraction by applying our method. We evaluate the method with 38 e-commerce information systems mined from GitHub. As a result, we observe that our method is able to identify classes and methods that are relevant in the e-commerce domain.", "references": ["G. Caldiera and V. Basili. Identifying and qualifying reusable software components. Computer, 24(2):61-70, 1991", "J. Cybulski and K. Reed. Requirements classification and reuse: Crossing domain boundaries. In Proceedings of the 6th International Conference on Software Reuse (ICSR), pages 190-210, 2000.", "W. Frakes and C. Terry. Software reuse: metrics and models. Computing Surveys (CSUR), 28(2):415-435, 1996"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022007"}, {"title": "Ontological Networks: Mapping Ontological Knowledge Bases into Graphs", "authors": ["Lucas Fonseca Navarro\n,", "Estevam Rafael Hruschka\n,", "Ana Paula Appel"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWith the exponentially growing amount of available data on the Web over the last years, several projects have been created to automatically extract knowledge from this information set. As the data domains on the Web are too wide, most of these projects store the acquired knowledge in ontological knowledge bases (OKBs). Mapping it into graph-based representation makes possible to apply graph-mining techniques to extract implicit information. However most of these projects treat the mapping process using different adjustments in several ways, thus, there is not a standard mapping process or a formal way defifined to do this task. In this paper we formally describe a graph structure called Ontological Network and how it can be used to map an Ontological Knowledge Base. We also show some graph-mining based algorithms to add new facts and to extend the ontology of an OKB while mapped into an Ontological Network as example.", "references": ["A. P. Appel and E. R. Hruschka Junior. Prophet -- a link-predictor to learn new rules on nell. In Proceedings of the 2011 IEEE 11th International Conference on Data Mining Workshops, ICDMW'11, pages 917--924, Washington, DC, USA, 2011. IEEE Computer Society.", "F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi, and P. F. Pate-Schneider. The description logic handbook: Theory, implementation, and applications. Cambridge University Press, 2 edition edition, 2010.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In In Proceedings of SIGMOD, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890587"}, {"title": "Online Learning to Rank for Information Retrieval: SIGIR 2016 Tutorial", "authors": ["Artem Grotov\n,", "Maarten de Rijke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDuring the past 10--15 years offline learning to rank has had a tremendous influence on information retrieval, both scientifically and in practice. Recently, as the limitations of offline learning to rank for information retrieval have become apparent, there is increased attention for online learning to rank methods for information retrieval in the community. Such methods learn from user interactions rather than from a set of labeled data that is fully available for training up front.\nBelow we describe why we believe that the time is right for an intermediate-level tutorial on online learning to rank, the objectives of the proposed tutorial, its relevance, as well as more practical details, such as format, schedule and support materials.", "references": ["Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learnng Research, 3: 397--422, 2003.", "Alexey Borisov, Pavel Serdyukov, and Maarten de Rijke. Using metafeatures to increase the effectiveness of latent semantic models in web search. In WWW 2016: 25th International World Wide Web Conference. ACM, April 2016.", "Christopher J.C. Burges. From ranknet to lambdarank to lambdamart: An overview. Technical Report MSR-TR-2010-82, June 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914798"}, {"title": "Automatical Storyline Generation with Help from Twitter", "authors": ["Ting Hua\n,", "Xuchao Zhang\n,", "Wei Wang\n,", "Chang-Tien Lu\n,", "Naren Ramakrishnan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nStoryline detection aims to connect seemly irrelevant single documents into meaningful chains, which provides opportunities for understanding how events evolve over time and what triggers such evolutions. Most previous work generated the storylines through unsupervised methods that can hardly reveal underlying factors driving the evolution process. This paper introduces a Bayesian model to generate storylines from massive documents and infer the corresponding hidden relations and topics. In addition, our model is the first attempt that utilizes Twitter data as human input to ``supervise'' the generation of storylines. Through extensive experiments, we demonstrate our proposed model can achieve significant improvement over baseline methods and can be used to discover interesting patterns for real world cases.", "references": ["David M Blei and John D Lafferty. Dynamic topic models. In Proceedings of the 23rd international conference on Machine learning, pages 113--120. ACM, 2006.", "David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. In The Journal of Machine Learning Research, volume 3, pages 993--1022. MIT Press, 2003.", "Ting Hua, Ning Yue, Feng Chen, Chang-Tien Lu, and Naren Ramakrishnan. Topical analysis of interactions between news and social media. In Proceedings of the 30th AAAI Conference on Artificial Intelligence, pages 2964--2971, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983698"}, {"title": "An Experiment in an Industrial Business Intelligence environment to improve data loads maintenance", "authors": ["Juli K.G. Costa\n,", "Igor P.O. Santos\n,", "Methanias C. junior\n,", "Andre V.R.P. Nascimento"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nBusiness Intelligence (BI) and Data Analytics applications depend on an effective ETL (Extract, Transform and Load) process . This paper presents an approach and a Rapid Application Development (RAD) tool to increase efficiency and effectiveness of ETL programs development and maintenance. Furthermore, it is also described a controlled experiment conducted in industry to carefully evaluated the efficiency and effectiveness of the tool. The results indicate that our approach can indeed be used as method aimed at improving and speed up ETL process maintenance.", "references": ["Singh, R. and Singh, K. A Descriptive Classification of Causes of Data Quality Problems in Data Warehouse. In: IJCSI INTERNATIONAL JOURNAL OF COMPUTER SCIENCE ISSUES. Vol. 7, Issue 3, No 2, 2010.", "Kimball, R., Ross, M. and Thomthwaite, W. The data warehouse lifecycle toolkit. 2. ed. Indianapolis, Indiana: Wiley Publishing Inc., 2008.", "Santos, V. and Belo, O. Slowly Changing Dimensions Specification a Relational Algebra Approach. In: PROC. Of Int. Conf. on Advances in Communication and Information Technology, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022045"}, {"title": "DopeLearning: A Computational Approach to Rap Lyrics Generation", "authors": ["Eric Malmi\n,", "Pyry Takala\n,", "Hannu Toivonen\n,", "Tapani Raiko\n,", "Aristides Gionis"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWriting rap lyrics requires both creativity to construct a meaningful, interesting story and lyrical skills to produce complex rhyme patterns, which form the cornerstone of good flow. We present a rap lyrics generation method that captures both of these aspects. First, we develop a prediction model to identify the next line of existing lyrics from a set of candidate next lines. This model is based on two machine-learning techniques: the RankSVM algorithm and a deep neural network model with a novel structure. Results show that the prediction model can identify the true next line among 299 randomly selected lines with an accuracy of 17%, i.e., over 50 times more likely than by random. Second, we employ the prediction model to combine lines from existing songs, producing lyrics with rhyme and a meaning. An evaluation of the produced lyrics shows that in terms of quantitative rhyme density, the method outperforms the best human rappers by 21%. The rap lyrics generator has been deployed as an online tool called DeepBeat, and the performance of the tool has been assessed by analyzing its usage logs. This analysis shows that machine-learned rankings correlate with user preferences.", "references": ["Y. Bengio, I. J. Goodfellow, and A. Courville. Deep learning. Book in preparation for MIT Press, 2015.", "D. Berger. Rap genius university: Rhyme types. http://genius.com/posts/24-Rap-genius-university-rhyme-types. Accessed: 2015-05-07.", "J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley, and Y. Bengio. Theano: a CPU and GPU math expression compiler. Proceedings of the Python for Scientific Computing Conference (SciPy), 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939679"}, {"title": "ADORES: a diversity-oriented online recommender system", "authors": ["Max Chevalier\n,", "Damien Dudognon\n,", "Josiane Mothe"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nBrowsing a content platform usually does not require a user identification. In this context, personalized approaches can not be used since no information related to the user is available. In that case, it is important to consider the variety of potential interests of users when providing recommendations. In this paper, we propose a scalable recommendation diversity-oriented model which considers solely the current visited document, the available collection and the past clickthrough documents to produce a list of diversified recommendations. A learning phase is integrated to improve recommendation relevance along time. Our proposals are validated through several experiments.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE TKDE, 17(6):734--749, 2005.", "L. Candillier, M. Chevalier, D. Dudognon, and J. Mothe. Multiple similarities for diversity in recommender systems. International Journal On Advances in Intelligent Systems, 5(3 and 4):234--246, 2012.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In WWW '09, pages 1--10, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851921"}, {"title": "Geodata supported classification of patent applications", "authors": ["Jan Stutzki\n,", "Matthias Schubert"], "publication": "GeoRich '16: Proceedings of the Third International ACM SIGMOD Workshop on Managing and Mining Enriched Geo-Spatial Data", "abstract": "ABSTRACT\nThe automatic classification of patent applications into a particular patent classification system remains a challenge with many practical applications. From a computer science point of view, the task is a multi-label hierarchical classification problem, i.e. each patent application might belong to multiple classes within the class hierarchy. The problem is still especially difficult for purely text-based classifiers because patents and patent applications are often formulated in a rather generic way. Thus, additional sources of information should be used to improve class prediction. In our approach, we propose the use of location information contained in the meta data of a patent application in combination with text-based patent classification. We argue that certain technological areas often cluster in geographic regions. For example, space travel technology is often collocated at Houston, Texas due to the NASA facilities in this area. In many cases, the addresses of the inventors are correlated to the technological area of a given patent. Thus, the addresses can be exploited to provide additional information about the technological area. We present a geo-enriched classifier joining established methods for text-based classification with location-based topic prediction. Since the location-based prediction is not applicable to all cases, we provide a method to regulate the impact of the spatial predictor for these cases. Our experiments indicate that spatial prediction is applicable to a considerable amount of patent applications and that the combination of spatial prediction and text-based classification significantly improves the prediction accuracy.", "references": ["Y. Bengio. Practical recommendations for gradient-based training of deep architectures. In Neural Networks: Tricks of the Trade, pages 437--478. Springer, 2012.", "J. Bentley. amultidimensional binary search trees used for associative searching, °comm, 1975.", "K. Beuls, B. Pflugfelder, and A. Hanbury. Comparative analysis of balanced winnow and svm in large scale patent categorization. In Proceedings of Dutch-Belgian Information Retrieval Workshop (DIR), pages 8--15, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948649.2948653"}, {"title": "Relationship-aware code search for JavaScript frameworks", "authors": ["Xuan Li\n,", "Zerui Wang\n,", "Qianxiang Wang\n,", "Shoumeng Yan\n,", "Tao Xie\n,", "Hong Mei"], "publication": "FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "abstract": "ABSTRACT\nJavaScript frameworks, such as jQuery, are widely used for developing web applications. To facilitate using these JavaScript frameworks to implement a feature (e.g., functionality), a large number of programmers often search for code snippets that implement the same or similar feature. However, existing code search approaches tend to be ineffective, without taking into account the fact that JavaScript code snippets often implement a feature based on various relationships (e.g., sequencing, condition, and callback relationships) among the invoked framework API methods. To address this issue, we present a novel Relationship-Aware Code Search (RACS) approach for finding code snippets that use JavaScript frameworks to implement a specific feature. In advance, RACS collects a large number of code snippets that use some JavaScript frameworks, mines API usage patterns from the collected code snippets, and represents the mined patterns with method call relationship (MCR) graphs, which capture framework API methods’ signatures and their relationships. Given a natural language (NL) search query issued by a programmer, RACS conducts NL processing to automatically extract an action relationship (AR) graph, which consists of actions and their relationships inferred from the query. In this way, RACS reduces code search to the problem of graph search: finding similar MCR graphs for a given AR graph. We conduct evaluations against representative real-world jQuery questions posted on Stack Overflow, based on 308,294 code snippets collected from over 81,540 files on the Internet. The evaluation results show the effectiveness of RACS: the top 1 snippet produced by RACS matches the target code snippet for 46% questions, compared to only 4% achieved by a relationship-oblivious approach.", "references": ["Annie T. T. Ying and Martin P. Robillard. Selection and presentation practices for code example summarization. In Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE '14), pp. 460-471, 2014.", "Siddharth Subramanian and Reid Holmes. Making sense of online code snippets. In Proceedings of the 10th Working Conference on Mining Software Repositories (MSR '13), pp. 85-88, 2013.", "David Mandelin, Lin Xu, Rastislav Bodik, and Doug Kimelman. Jungloid mining: helping to navigate the API jungle. In Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI '05), pp. 48-61, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2950290.2950341"}, {"title": "A Visual Representation for Indoor Emergency Management", "authors": ["Flavio Nunes\n,", "Fernando Teles\n,", "Renato Novais\n,", "Sandro Andrade\n,", "Manoel Neto"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nHuman beings spend much time indoors, such as schools, factories and businesses. The emergency management in such environments is useful and challenging. The location and visualization technologies in these environments are not as advanced as existing for open environments (e.g., location via GPS, visualization in maps). Currently, much effort is devoted to identify people in indoor environments. Despite the relevance of this activity, few studies investigate aspects related to the visualization of this information. This paper presents a new visualization for indoor environments aimed at supporting the emergency. The proposed visualization was based on the opinion of emergency professionals, developed as a prototype and validated with end users. The results show that the developed visualization is effective in transmitting information regarding a possible indoors-emergency scenario and can thus support the professionals in their rescue activities.", "references": ["About. http://paperjs.org/about/. Acessado em 29 de agosto de 2015.", "Jquery. http://jquery.com. Acessado em 29 de agosto de 2015.", "Visem wiki page. https://rescue.ifba.edu.br/visem/index.html. Accessed: 2016-04-04."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022042"}, {"title": "Prioritized garbage collection: explicit GC support for software caches", "authors": ["Diogenes Nunez\n,", "Samuel Z. Guyer\n,", "Emery D. Berger"], "publication": "OOPSLA 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nProgrammers routinely trade space for time to increase performance, often in the form of caching or memoization. In managed languages like Java or JavaScript, however, this space-time tradeoff is complex. Using more space translates into higher garbage collection costs, especially at the limit of available memory. Existing runtime systems provide limited support for space-sensitive algorithms, forcing programmers into difficult and often brittle choices about provisioning.\nThis paper presents prioritized garbage collection, a cooperative programming language and runtime solution to this problem. Prioritized GC provides an interface similar to soft references, called priority references, which identify objects that the collector can reclaim eagerly if necessary. The key difference is an API for defining the policy that governs when priority references are cleared and in what order. Application code specifies a priority value for each reference and a target memory bound. The collector reclaims references, lowest priority first, until the total memory footprint of the cache fits within the bound. We use this API to implement a space-aware least-recently-used (LRU) cache, called a Sache, that is a drop-in replacement for existing caches, such as Google's Guava library. The garbage collector automatically grows and shrinks the Sache in response to available memory and workload with minimal provisioning information from the programmer. Using a Sache, it is almost impossible for an application to experience a memory leak, memory pressure, or an out-of-memory crash caused by software caching.", "references": ["Edward E. Aftandilian and Samuel Z. Guyer. GC assertions: Using the garbage collector to check heap properties. In Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 235–244. ACM, 2009.", "Berk Atikoglu, Yuehai Xu, Eitan Frachtenberg, Song Jiang, and Mike Paleczny. Workload analysis of a large-scale keyvalue store. In Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems, SIGMETRICS ’12, pages 53–64, 2012.", "Jonathan Bellis. Jamm. https://github.com/jbellis/jamm."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983990.2984028"}, {"title": "Deep Learning at Scale and at Ease", "authors": ["Wei Wang\n,", "Gang Chen\n,", "Haibo Chen\n,", "Tien Tuan Anh Dinh\n,", "Jinyang Gao\n,", "Beng Chin Ooi\n,", "Kian-Lee Tan\n,", "Sheng Wang\n,", "Meihui Zhang"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nRecently, deep learning techniques have enjoyed success in various multimedia applications, such as image classification and multimodal data analysis. Large deep learning models are developed for learning rich representations of complex data. There are two challenges to overcome before deep learning can be widely adopted in multimedia and other applications. One is usability, namely the implementation of different models and training algorithms must be done by nonexperts without much effort, especially when the model is large and complex. The other is scalability, namely the deep learning system must be able to provision for a huge demand of computing resources for training large models with massive datasets. To address these two challenges, in this article we design a distributed deep learning platform called SINGA, which has an intuitive programming model based on the common layer abstraction of deep learning models. Good scalability is achieved through flexible distributed training architecture and specific optimization techniques. SINGA runs on both GPUs and CPUs, and we show that it outperforms many other state-of-the-art deep learning systems. Our experience with developing and training deep learning models for real-life multimedia applications in SINGA shows that the platform is both usable and scalable.", "references": ["Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado et al. 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. arXiv:1603.04467. http://tensorflow.org/.", "Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, James Bergstra, Ian J. Goodfellow, Arnaud Bergeron, Nicolas Bouchard, and Yoshua Bengio. 2012. Theano: New features and speed improvements. In Proceedings of the Deep Learning Workshop (NIPS’12).", "Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016b. Training deep nets with sublinear memory cost. arXiv:1604.06174. http://arxiv.org/abs/1604.06174"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996464"}, {"title": "LIRE: open source visual information retrieval", "authors": ["Mathias Lux\n,", "Michael Riegler\n,", "Pål Halvorsen\n,", "Konstantin Pogorelov\n,", "Nektarios Anagnostopoulos"], "publication": "MMSys '16: Proceedings of the 7th International Conference on Multimedia Systems", "abstract": "ABSTRACT\nWith an annual growth rate of 16.2% of taken photos a year, researchers predict an almost unbelievable number of 4.9 trillion stored images in 2017. Nearly 80% of these photos in 2017 will be taken with mobile phones. To be able to cope with this immense amount of visual data in a fast and accurate way, a visual information retrieval systems are needed for various domains and applications. LIRE, short for Lucene Image Retrieval, is a light weight and easy to use Java library for visual information retrieval. It allows developers and researchers to integrate common content based image retrieval approaches in their applications and research projects. LIRE supports global and local image features and can cope with millions of images using approximate search and distributing indexes on the cloud. In this demo we present a novel tool called F-search that emphasize the core strengths of LIRE: lightness, speed and accuracy.", "references": ["G. Amato and P. Savino. Approximate similarity search in metric spaces using inverted files. In Proc. of InfoScale, 2008.", "H. Bay, T. Tuytelaars, and L. Van Gool. Surf: Speeded up robust features. In Computer vision--ECCV 2006, pages 404--417. Springer, 2006.", "A. Bosch, A. Zisserman, and X. Munoz. Representing shape with a spatial pyramid kernel. In Proceedings of the 6th ACM international conference on Image and video retrieval, CIVR '07, pages 401--408, New York, NY, USA, 2007. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910017.2910630"}, {"title": "Developing a Measure of Search Expertise", "authors": ["Earl Bailey\n,", "Diane Kelly"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWhile search expertise has long been considered an important variable in the study of online information search, the creation of a robust measure to characterize it has eluded researchers. Instead, those wishing to measure search expertise often include a single item that asks people to indicate how often they search or for how long they have been searching. In this paper, we report initial results of a four-phase study aimed at developing a measure of search expertise. Interviews and focus groups were conducted with nine professional searchers and an inventory of items related to online search expertise was created. While participants identified a number of usual items for determining search expertise, such as prior search experience, domain knowledge and resource knowledge, they also identified a large number of items related to personality characteristics such as persistence, flexibility, curiosity, adaptability and humility. These results suggest that measuring personality characteristics in addition to experience and knowledge might help determine who will be a more successful searcher. In today's search environments, where many people describe themselves as experts, representing these types of characteristics in a measure of search expertise might allow researchers and practitioners to observe more variation in populations of interest, design more effective instruction and make better predictions about search outcomes.", "references": ["Aula, A. & Nordhausen, K. (2006). Modeling successful performance in Web searching. JASIST, 57, 1678--1693.", "Bellardo, T. (1985). An investigation of online searcher traits and their relationship to search outcome. JASIS, 36, 241--250.", "Borgman, C.L. (1989). All users of information systems are not created equal: An exploration into individual differences. IP&M, 25(3), 237--252."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854983"}, {"title": "Linked Open Data Search Engine", "authors": ["Hiteshwar Kumar Azad\n,", "Akshay Deepak\n,", "Kumar Abhishek"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nLinked data indicate a manner of publishing and interlinking structured data on the web. The basic hypothesis behind the concept of linked data is that the value and importance of data increases more when it is interlinked with different data sources. This interlinked web of data is termed as the Linked data. Searching data and providing the most relevant information in linked data is a big challenge. A search engine's utility depends upon the relevance of the search results it returns. Traditional search engines are made to search data on the World Wide Web, where the data are not interlinked. On the other hand, Linked Data based search engine will have to operate over an interlinked web of data. Yet another challenge is to rank the search results. The searched term or phrase can be present in numerous web pages. The usefulness of information present in some pages may be greater than others. So in order to provide the most relevant data, Search engines need to apply various ranking methods on their search results. However the methodology used for ranking data cannot be used in the same manner as it is used in traditional search engines, because the probability of a random user to visit a particular link is not equally likely. In this manuscript a methodology for ranking linked data has been proposed. Also, we have categorized the search into two basic types as Forward search and Backward search. The aim of this bifurcation is to minimize search delays and to provide the end user the data that he or she is most probably looking for.", "references": ["Hiteshwar Kumar Azad and Kumar Abhishek. Entropy measurement and algorithm for semantic-synaptic web mining. In Data Mining and Intelligent Computing (ICDMIC), 2014 International Conference on, pages 1--5. IEEE, 2014.", "Hiteshwar Kumar Azad and Kumar Abhishek. Semantic-synaptic web mining: A novel model for improving the web mining. In Communication Systems and Network Technologies (CSNT), 2014 Fourth International Conference on, pages 454--457. IEEE, 2014.", "Ricardo Baeza-Yates and Emilio Davis. Web page ranking using link attributes. In Proceedings of the 13th international World Wide Web conference on Alternate track papers & posters, pages 328--329. ACM, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905075"}, {"title": "Additive Smoothing for Relevance-Based Language Modelling of Recommender Systems", "authors": ["Daniel Valcarce\n,", "Javier Parapar\n,", "Álvaro Barreiro"], "publication": "CERI '16: Proceedings of the 4th Spanish Conference on Information Retrieval", "abstract": "ABSTRACT\nThe use of Relevance-Based Language Models for top-N recommendation has become a promising line of research. Previous works have used collection-based smoothing methods for this task. However, a recent analysis on RM1 (an estimation of Relevance-Based Language Models) in document retrieval showed that this type of smoothing methods demote the IDF effect in pseudo-relevance feedback. In this paper, we claim that the IDF effect from retrieval is closely related to the concept of novelty in recommendation. We perform an axiomatic analysis of the IDF effect on RM2 concluding that this kind of smoothing methods also demotes the IDF effect in recommendation. By axiomatic analysis, we find that a collection-agnostic method, Additive smoothing, does not demote this property. Our experiments confirm that this alternative improves the accuracy, novelty and diversity figures of the recommendations.", "references": ["R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology Behind Search. Addison Wesley, 2011.", "N. J. Belkin and W. B. Croft. Information Filtering and Information Retrieval: Two Sides of the Same Coin? Commun. ACM, 35(12):29--38, 1992.", "A. Bellogín, P. Castells, and I. Cantador. Precision-Oriented Evaluation of Recommender Systems. In RecSys '11, pages 333--336, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934732.2934737"}, {"title": "Image Emotion Computing", "authors": ["Sicheng Zhao"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nImages can convey rich semantics and induce strong emotions in viewers. My research aims to predict image emotions from different aspects with respect to two main challenges: affective gap and subjective evaluation. To bridge the affective gap, we extract emotion features based on principles-of-art to recognize image-centric dominant emotions. As the emotions that are induced in viewers by an image are highly subjective and different, we propose to predict user-centric personalized emotion perceptions for each viewer and image-centric emotion probability distribution for each image. To tackle the subjective evaluation issue, we set up a large scale image emotion dataset from Flickr, named Image-Emotion-Social-Net, on both dimensional and categorical emotion representations with over 1 million images and about 8,000 users. Different types of factors may influence personalized image emotion perceptions, including visual content, social context, temporal evolution and location influence. We make an initial attempt to jointly combine them by the proposed rolling multi-task hypergraph learning. Both discrete and continuous emotion distributions are modelled via shared sparse learning. Further, several potential applications based on image emotions are designed and implemented.", "references": ["D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In ACM International Conference on Multimedia, pages 223--232, 2013.", "T. Chen, F. X. Yu, J. Chen, Y. Cui, Y.-Y. Chen, and S.-F. Chang. Object-based visual sentiment concept analysis and application. In ACM International Conference on Multimedia, pages 367--376, 2014.", "R. G. Collingwood. The principles of art, volume 62. Oxford University Press, USA, 1958."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2971473"}, {"title": "Unifying data exploration and curation", "authors": ["Shan Shan Huang"], "publication": "ExploreDB '16: Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web", "abstract": "ABSTRACT\nRecent years have seen a surge in \"self-service\" business intelligence tools. These tools primarily focus on supporting decision-making by non-technical \"end users\", through data exploration -- the querying of data and inspection of results.\nExploration, however, is only part of the story. Curation is its complement. Curation is the ability to organize data into structures that are meaningful for a particular problem domain and convenient for building further explorations upon. Curation is also the ability to modify data, as well as creating new data through rules and constraints, in order to support what-if's, forecasting, and planning for the future. Exploration and curation often need to interleave in the decision-making process of an end-user.\nIn this talk, we discuss the LogicBlox Modeler, a unifying environment that provides support for both exploration and curation. We motivate the need for a unifying environment through applications in government, major financial institutions, and large global retailers. We discuss our language -- in its visual and textual representations -- that supports not only querying, but also the creation and modification of schema and data. We discuss the challenges imposed on the database runtime by the use cases of exploration and curation at scale and aspects of the LogicBlox database designed to meet these challenges.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948674.2948680"}, {"title": "Towards Modelling Language Innovation Acceptance in Online Social Networks", "authors": ["Daniel Kershaw\n,", "Matthew Rowe\n,", "Patrick Stacey"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nLanguage change and innovation is constant in online and offline communication, and has led to new words entering people's lexicon and even entering modern day dictionaries, with recent additions of 'e-cig' and 'vape'. However the manual work required to identify these 'innovations' is both time consuming and subjective. In this work we demonstrate how such innovations in language can be identified across two different OSN's (Online Social Networks) through the operationalisation of known language acceptance models that incorporate relatively simple statistical tests. From grounding our work in language theory, we identified three statistical tests that can be applied - variation in; frequency, form and meaning. Each show different success rates across the two networks (Geo-bound Twitter sample and a sample of Reddit). These tests were also applied to different community levels within the two networks allowing for different innovations to be identified across different community structures over the two networks, for instance: identifying regional variation across Twitter, and variation across groupings of Subreddits, where identified example innovations included 'casualidad' and 'cym'.", "references": ["Distributional Semantics Resources for Biomedical Text Processing. pages 1--5, Nov. 2013.", "G. Aston and L. Burnard. The BNC handbook: exploring the British National Corpus with SARA. Capstone, 1998.", "D. K. Barnhart. A Calculus for New Words. 28(1):132--138, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835784"}, {"title": "Discovering the skyline of web databases", "authors": ["Abolfazl Asudeh\n,", "Saravanan Thirumuruganathan\n,", "Nan Zhang\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMany web databases are \"hidden\" behind proprietary search interfaces that enforce the top-k output constraint, i.e., each query returns at most k of all matching tuples, preferentially selected and returned according to a proprietary ranking function. In this paper, we initiate research into the novel problem of skyline discovery over top-k hidden web databases. Since skyline tuples provide critical insights into the database and include the top-ranked tuple for every possible ranking function following the monotonic order of attribute values, skyline discovery from a hidden web database can enable a wide variety of innovative third-party applications over one or multiple web databases. Our research in the paper shows that the critical factor affecting the cost of skyline discovery is the type of search interface controls provided by the website. As such, we develop efficient algorithms for three most popular types, i.e., one-ended range, free range and point predicates, and then combine them to support web databases that feature a mixture of these types. Rigorous theoretical analysis and extensive real-world online and offline experiments demonstrate the effectiveness of our proposed techniques and their superiority over baseline solutions.", "references": ["B. Arai, G. Das, D. Gunopulos, and N. Koudas. Anytime measures for top-k algorithms. In VLDB, 2007.", "A. Asudeh, S. Thirumuruganathan, N. Zhang, and G. Das. Discovering the skyline of web databases. CoRR, abs/1512.02138, 2015.", "A. Asudeh, G. Zhang, N. Hassan, C. Li, and G. Zaruba. Crowdsourcing pareto-optimal object finding by pairwise comparisons. CIKM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2904483.2904491"}, {"title": "Query Rewriting for Archived Information Retrieval", "authors": ["Nana Zhu\n,", "Xueting Li\n,", "Lei Xiong\n,", "Han Xue"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nWord mismatch is a fundamental issue in the field of information retrieval. To address this problem, one of the major approaches is query formulation. Previous work mainly focused on the study of synonym based term replacement and the query paraphrasing. However, the word level replacement overlooked the context of terms and the query level paraphrasing yielded on the low performance. In this paper, we proposed a phrase-rewriting scheme for query formulation in Web search by exploiting multiple online search engines. Through the use of phrases, we actually explore the term context in the query. Meanwhile, phrase rewriting was employed to explore the semantic similarity of phrases. Experimental results showed that the proposed approach outperformed the baselines significantly.", "references": ["Xu J, Croft W B. Query expansion using local and global document analysis {C}//Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1996: 4--11.", "Hovy E H, Hermjakob U, Lin C Y. The Use of External Knowledge of Factoid QA {C}//TREC. 2001, 2001: 644--52.", "Buscaldi D, Rosso P, Arnal E S. A wordnet-based query expansion method for geographical information retrieval {C}//Working notes for the CLEF workshop. 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007733"}, {"title": "DCCSR: Document Clustering by Conceptual and Semantic Relevance as Factors of Unsupervised Learning", "authors": ["Annaluri Sreenivasa Rao\n,", "S. Ramakrishna"], "publication": "AICTC '16: Proceedings of the International Conference on Advances in Information Communication Technology & Computing", "abstract": "ABSTRACT\nUnsupervised learning of text documents is an essential and significant process of knowledge discovery and data mining. The concept, context and semantic relevancy are the important and exclusive factors in text mining, where as in the case of unsupervised learning of record structured data, these factors are not in scope. The current majority of benchmarking document clustering models is keen and relies on term frequency, and all these models are not considering the concept, context and semantic relations during document clustering. In regard to this, our earlier work introduced a novel document clustering approach that named as Document Clustering by Conceptual Relevance (DCCR), which is aimed at concept relevancy. With the lessons learned from the empirical study of the DCCR, here we presented a novel document clustering approach, which is based on concept and semantic relevancy of the documents. The significant contribution of this proposal is feature formation by concept and semantic relevance. An unsupervised learning approach that estimates similarity between any two documents by concept and semantic relevance score is proposed. This novel method represents the concept as correlation between arguments and activities in given documents, and the semantic relevance is assessed by estimating the similarity between documents through the hyponyms of the arguments. The experiments was conducted to assess the significance of the proposed model and in regard to this, the benchmark datasets were used.", "references": ["P. Berkhin. 2004. Survey of clustering data mining techniques{Online}.Available:http://www.accrue.com/products/rp_cluster_review.pdf.", "Xu Rui. 2005. Survey of Clustering Algorithms. IEEE Transactions on Neural Networks,16(3): pp. 634--678.", "MillerG.1995.Wordnet:Alexicaldatabasefor English. CACM, 38(11), pp. 39--41."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2979779.2979822"}, {"title": "Web Content Extraction: a MetaAnalysis of its Past and Thoughts on its Future", "authors": ["Tim Weninger\n,", "Rodrigo Palacios\n,", "Valter Crescenzi\n,", "Thomas Gottron\n,", "Paolo Merialdo"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nIn this paper, we present a meta-analysis of several Web content extraction algorithms, and make recommendations for the future of content extraction on the Web. First, we find that nearly all Web content extractors do not consider a very large, and growing, portion of modernWeb pages. Second, it is well understood that wrapper induction extractors tend to break as theWeb changes; ; heuristic/ feature engineering extractors were thought to be immune to a Web site's evolution, but we find that this is not the case: heuristic content extractor performance also tends to degrade over time due to the evolution of Web site forms and practices. We conclude with recommendations for future work that address these and other findings.", "references": ["Z. Bar-Yossef and S. Rajagopalan. Template detection via data mining and its applications. In WWW, page 580, New York, New York, USA, May 2002. ACM Press.", "M. J. Cafarella, A. Halevy, and J. Madhavan. Structured data on the web. Communications of the ACM, 54(2):72--79, 2011.", "M. J. Cafarella, A. Halevy, D. Z.Wang, E.Wu, and Y. Zhang. Webtables: Exploring the power of tables on the web. Proc. VLDB Endow., 1(1):538--549, Aug. 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897350.2897353"}, {"title": "Ziggy: characterizing query results for data explorers", "authors": ["Thibault Sellam\n,", "Martin Kersten"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nData exploration has received much attention during the last few years. The aim is to learn interesting new facts from a possibly unfamiliar data set. Typically, explorers operate by trial and error: they write a query, inspect the results and refine their specifications accordingly. In this demo proposal, we present Ziggy, a system to help them understand their query results. Ziggy's aim is to complement an existing exploration system. It assumes that users already have a query in mind, but they do not know what is interesting about it. To assist them, it detects characteristic views, that is, small sets of columns on which the tuples in the results are different from those in the rest of the database. Thanks to these views, our explorers can understand why their selection is unique and make more informed exploration decisions.", "references": ["S. Agarwal, A. P. Iyer, A. Panda, S. Madden, B. Mozafari, and I. Stoica. Blink and it's done: interactive queries on very large data. PVLDB, 5(12):1902--1905, 2012.", "L. V. Hedges and I. Olkin. Statistical method for meta-analysis. Academic press, 1985.", "T. Sellam and M. Kersten. Cluster-driven navigation of the query space. IEEE TKDE, 28(5):1118 -- 1131, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007287"}, {"title": "Privacy-Preserving IR 2016: Differential Privacy, Search, and Social Media", "authors": ["Hui Yang\n,", "Ian Soboroff\n,", "Li Xiong\n,", "Charles L.A. Clarke\n,", "Simson L. Garfinkel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDue to lack of mature techniques in privacy-preserving information retrieval (IR), concerns about information privacy and security have become serious obstacles that prevent valuable user data to be used in IR research such as studies on query logs, social media, and medical record retrieval. In SIGIR 2014 and SIGIR 2015, we have run the privacy-preserving IR workshops exploring and understanding the privacy and security risks in information retrieval. This year, we continue the efforts of connecting the two disciplines of IR and privacy/security by organizing this workshop. We target on three themes, differential privacy and IR dataset release, privacy in search and browsing, and privacy in social media. The workshop includes panels with researchers from both fields on these three themes, as well as invite industry speakers for real-world challenges. The goals of this workshop include (1) bringing together the two research fields, and (2) yielding fruitful collaborations.", "references": ["L. Fan, L. Bonomi, L. Xiong, and V. Sunderam. Monitoring web browsing behavior with differential privacy. In Proceedings of the 23rd International Conference on World Wide Web, WWW '14, 2014.", "M. Gaboardi, E. J. G. Arias, J. Hsu, A. Roth, and Z. S. Wu. Dual query: Practical private query release for high dimensional data. In ICML 2014, Beijing, China, 21--26 June 2014.", "W. Jiang, L. Si, and J. Li. Protecting source privacy in federated search. In W. Kraaij, A. P. de Vries, C. L. A. Clarke, N. Fuhr, and N. Kando, editors, SIGIR, pages 761--762. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2917763"}, {"title": "CCCF: Improving Collaborative Filtering via Scalable User-Item Co-Clustering", "authors": ["Yao Wu\n,", "Xudong Liu\n,", "Min Xie\n,", "Martin Ester\n,", "Qing Yang"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nCollaborative Filtering (CF) is the most popular method for recommender systems. The principal idea of CF is that users might be interested in items that are favorited by similar users, and most of the existing CF methods measure users' preferences by their behaviours over all the items. However, users might have different interests over different topics, thus might share similar preferences with different groups of users over different sets of items. In this paper, we propose a novel and scalable method CCCF which improves the performance of CF methods via user-item co-clustering. CCCF first clusters users and items into several subgroups, where each subgroup includes a set of like-minded users and a set of items in which these users share their interests. Then, traditional CF methods can be easily applied to each subgroup, and the recommendation results from all the subgroups can be easily aggregated. Compared with previous works, CCCF has several advantages including scalability, flexibility, interpretability and extensibility. Experimental results on four real world data sets demonstrate that the proposed method significantly improves the performance of several state-of-the-art recommendation algorithms.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 19--28. ACM, 2009.", "E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels. In Advances in Neural Information Processing Systems, pages 33--40, 2009.", "A. Beutel, A. Ahmed, and A. J. Smola. Accams: Additive co-clustering to approximate matrices succinctly. In Proceedings of the 24th International Conference on World Wide Web, pages 119--129, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835836"}, {"title": "Session details: Main Track - Data and Metadata Management", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255987"}, {"title": "Semantic Enrichment for Local Search Engine using Linked Open Data", "authors": ["Mazen AlObaidi\n,", "Khalid Mahmood\n,", "Susan Sabra"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nLocal search engines are a vital part of presence of local businesses on the Internet. Local search engines improvement is an important element to ensure that local businesses can be found by millions of people whom are using web to find services. However, web presence can be disguised or not properly documented. Our approach will improve the effectiveness of local search, and increase the ranking of local businesses. We introduce an approach for enhancing local search engines efficiency in returning more accurate results. Our approach consists of semantically enriching the results of a query using Linked Open Data (LOD) web content. Our preliminary evaluation demonstrated evidence that our approach has a better search with more accurate results.", "references": ["Alistair M., Matthews, B., Wilson, M., and Brickley, D. (2005) \"SKOS core: simple knowledge organisation for the web.\" In International Conference on Dublin Core and Metadata Applications, pp. pp-3.", "Bertin, M., & Atanassova, I. (2012). Semantic Enrichment of Scientific Publications and Metadata: Citation Analysis Through Contextual and Cognitive Analysis. D-Lib Magazine, 18(7/8). http://doi.org/10.1045/july2012-bertin.", "Bontcheva, K., Aswani, N., Kieniewicz, J., Andrews, S., & Wallis, M. (2015). EnviLOD WP5: Quantitative Evaluation of LOD-based Semantic Enrichment on Environmental Science Literature. Retrieved from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.385.31&rep=rep1&type=pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890481"}, {"title": "Improving IP Geolocation using Query Logs", "authors": ["Ovidiu Dan\n,", "Vaibhav Parikh\n,", "Brian D. Davison"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nIP geolocation databases map IP addresses to their geographical locations. These databases are important for several applications such as local search engine relevance, credit card fraud protection, geotargetted advertising, and online content delivery. While they are the most popular method of geolocation, they can have low accuracy at the city level. In this paper we evaluate and improve IP geolocation databases using data collected from search engine logs. We generate a large ground-truth dataset using real time global positioning data extracted from search engine logs. We show that incorrect geolocation information can have a negative impact on implicit user metrics. Using the dataset we measure the accuracy of three state-of-the-art commercial IP geolocation databases. We then introduce a technique to improve existing geolocation databases by mining explicit locations from query logs. We show significant accuracy gains in 44 to 49 out of the top 50 countries, depending on the IP geolocation database. Finally, we validate the approach with a large scale A/B experiment that shows improvements in several user metrics.", "references": ["Bing Geocoding API. http://msdn.microsoft.com/en-us/library/ff701711.aspx, (accessed July 17, 2015).", "Bing Reverse Geocoding API. http://msdn.microsoft.com/en-us/library/ff701710.aspx, (accessed July 17, 2015).", "Google Geocoding API. https://developers.google.com/maps/documentation/geocoding/, (accessed July 17, 2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835820"}, {"title": "Effective Trend Detection within a Dynamic Search Context", "authors": ["Anat Hashavit\n,", "Roy Levin\n,", "Ido Guy\n,", "Gilad Kutiel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn recent years, studies about trend detection in online social media streams have begun to emerge. Since not all users are likely to always be interested in the same set of trends, some of the research also focused on personalizing the trends by using some predefined personalized context.\nIn this paper, we take this problem further to a setting in which the user's context is not predefined, but rather determined as the user issues a query. This presents a new challenge since trends cannot be computed ahead of time using high latency algorithms. We present RT-Trend, an online trend detection algorithm that promptly finds relevant in-context trends as users issue search queries over a dataset of documents.\nWe evaluate our approach using real data from an online social network by assessing its ability to predict actual activity increase of social network entities in the context of a search result. Since we implemented this feature into an existing tool with an active pool of users, we also report click data, which suggests positive feedback.", "references": ["IBM-Connections. www-03.ibm.com/software/products/en/conn, 2007.", "Z. Al Bawab, G. H. Mills, and J.-F. Crespo. Finding trending local topics in search queries for personalization of a recommendation system. In SIGKDD 2012.", "N. G. Golbandi, L. K. Katzir, Y. K. Koren, and R. L. Lempel. Expediting search trend detection via prediction of query counts. In WSDM 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914705"}, {"title": "DI-DAP: An Efficient Disaster Information Delivery and Analysis Platform in Disaster Management", "authors": ["Tao Li\n,", "Wubai Zhou\n,", "Chunqiu Zeng\n,", "Qing Wang\n,", "Qifeng Zhou\n,", "Dingding Wang\n,", "Jia Xu\n,", "Yue Huang\n,", "Wentao Wang\n,"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn disaster management, people are interested in the development and the evolution of the disasters. If they intend to track the information of the disaster, they will be overwhelmed by the large number of disaster-related documents, microblogs, and news, etc. To support disaster management and minimize the loss during the disaster, it is necessary to efficiently and effectively collect, deliver, summarize, and analyze the disaster information, letting people in affected area quickly gain an overview of the disaster situation and improve their situational awareness.\nTo present an integrated solution to address the information explosion problem during the disaster period, we designed and implemented DI-DAP, an efficient and effective disaster information delivery and analysis platform. DI-DAP is an information centric information platform aiming to provide convenient, interactive, and timely disaster information to the users in need. It is composed of three separated but complementary services: Disaster Vertical Search Engine, Disaster Storyline Generation, and Geo-Spatial Data Analysis Portal. These services provide a specific set of functionalities to enable users to consume highly summarized information and allow them to conduct ad-hoc geospatial information retrieval tasks. To support these services, DI-DAP adopts FIU-Miner, a fast, integrated, and user-friendly data analysis platform, which encapsulated all the computation and analysis workflow as well-defined tasks. Moreover, to enable ad-hoc geospatial information retrieval, an advanced query language MapQL is used and the query template engine is integrated.\nDI-DAP is designed and implemented as a disaster management tool and is currently been exercised as the disaster information platform by more than 100 companies and institutions in South Florida area.", "references": ["F. E. M. Agency. https://www.fema.gov/public-private-partnership-models. 2002.", "D. Ahlers and S. Boll. Adaptive geospatially focused crawling. In Proceedings of the 18th ACM conference on Information and knowledge management, pages 445--454. ACM, 2009.", "M. Avvenuti, S. Cresci, A. Marchetti, C. Meletti, and M. Tesconi. Ears (earthquake alert and report system): a real time decision support system for earthquake crisis management. In Proceedings of the 20th ACM SIGKDD, pages 1749--1758. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983355"}, {"title": "Exploiting Network Analysis to Investigate Topic Dynamics in the Digital Library Evaluation Domain", "authors": ["Leonidas Papachristopoulos\n,", "Michalis Sfakakis\n,", "Nikos Kleidis\n,", "Giannis Tsakonas\n,", "Christos Papatheodorou"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe multidimensional nature of digital libraries evaluation domain and the amount of scientific production published on the field hinders and disorientates the interested researchers who contemplate to focus on the specific domain. These communities need guidance in order to exploit the considerable amount of data and the diversity of methods effectively as well as to identify new research goals and develop their plans for future works. This poster investigates the core topics of the digital library evaluation field and their impact by applying topic modeling and network analysis on a corpus of the JCDL, ECDL/TDPL and ICADL conferences proceedings in the period 2001-2013.", "references": ["Blei, D.M., Y Ng, A., and Jordan, M.I. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research 3, 993--1022.", "Papachristopoulos, L., Kleidis, N., Sfakakis, M., Tsakonas, G., and Papatheodorou, C. 2015. Discovering the topical evolution of the digital library evaluation community. In Proceedings of the 9th International Conference on Metadata and Semantic Research. CCIS No. 544, Springer, Berlin, 101--112.", "Afiontzi, E., Kazadeis, G., Papachristopoulos, L., Sfakakis, M., Tsakonas, G., and Papatheodorou, C. 2013. Charting the digital library evaluation domain with a semantically enhanced mining methodology. In Proceedings of the 13th ACM/IEEE-CS Joint Conference on Digital Libraries. ACM, New York, 125--134."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925464"}, {"title": "Effective Construction of Relative Lempel-Ziv Dictionaries", "authors": ["Kewen Liao\n,", "Matthias Petri\n,", "Alistair Moffat\n,", "Anthony Wirth"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWeb crawls generate vast quantities of text, retained and archived by the search services that initiate them. To store such data and to allow storage costs to be minimized, while still providing some level of random access to the compressed data, efficient and effective compression techniques are critical. The Relative Lempel Ziv (RLZ) scheme provides fast decompression and retrieval of documents from within large compressed collections, and even with a relatively small RAM-resident dictionary, is competitive relative to adaptive compression schemes. To date, the dictionaries required by RLZ compression have been formed from concatenations of substrings regularly sampled from the underlying document collection, then pruned in a manner that seeks to retain only the high-use sections. In this work, we develop new dictionary design heuristics, based on effective construction, rather than on pruning; we identify dictionary construction as a (string) covering problem. To avoid the complications of string covering algorithms on large collections, we focus on k-mers and their frequencies. First, with a reservoir sampler, we efficiently identify the most common k-mers. Then, since a collection typically comprises regions of local similarity, we select in each \"epoch\" a segment whose k-mers together achieve, locally, the highest coverage score. The dictionary is formed from the concatenation of these epoch-derived segments. Our selection process is inspired by the greedy approach to the Set Cover problem.\nCompared with the best existing pruning method, CARE, our scheme has a similar construction time, but achieves better compression effectiveness. Over several multi-gigabyte document collections, there are relative gains of up to 27%.", "references": ["G. Cormode and S. Muthukrishnan. An improved data stream summary: the count-min sketch and its applications. J. Alg., 55 (1): 58--75, 2005.", "G. Cormode, H. J. Karloff, and A. Wirth. Set cover algorithms for very large datasets. In Proc. CIKM, pages 479--488, 2010.", "S. Gog, T. Beller, A. Moffat, and M. Petri. From theory to practice: Plug and play with succinct data structures. In Proc. SEA, pages 326--337, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883042"}, {"title": "A Probabilistic Fusion Framework", "authors": ["Yael Anava\n,", "Anna Shtok\n,", "Oren Kurland\n,", "Ella Rabinovich"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThere are numerous methods for fusing document lists retrieved from the same corpus in response to a query. Many of these methods are based on seemingly unrelated techniques and heuristics. Herein we present a probabilistic framework for the fusion task. The framework provides a formal basis for deriving and explaining many fusion approaches and the connections between them. Instantiating the framework using various estimates yields novel fusion methods, some of which significantly outperform state-of-the-art approaches.", "references": ["A. Arampatzis and J. Kamps. A signal-to-noise approach to score normalization. In Proc. of CIKM, pages 797--806, 2009.", "A. Arampatzis and S. Robertson. Modeling score distributions in information retrieval. Information Retrieval, 14(1):26--46, 2011.", "J. A. Aslam and M. Montague. Models for metasearch. In Proc. of SIGIR, pages 276--284, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983739"}, {"title": "Mobile App Tagging", "authors": ["Ning Chen\n,", "Steven C.H. Hoi\n,", "Shaohua Li\n,", "Xiaokui Xiao"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nMobile app tagging aims to assign a list of keywords indicating core functionalities, main contents, key features or concepts of a mobile app. Mobile app tags can be potentially useful for app ecosystem stakeholders or other parties to improve app search, browsing, categorization, and advertising, etc. However, most mainstream app markets, e.g., Google Play, Apple App Store, etc., currently do not explicitly support such tags for apps. To address this problem, we propose a novel auto mobile app tagging framework for annotating a given mobile app automatically, which is based on a search-based annotation paradigm powered by machine learning techniques. Specifically, given a novel query app without tags, our proposed framework (i) first explores online kernel learning techniques to retrieve a set of top-N similar apps that are semantically most similar to the query app from a large app repository; and (ii) then mines the text data of both the query app and the top-N similar apps to discover the most relevant tags for annotating the query app. To evaluate the efficacy of our proposed framework, we conduct an extensive set of experiments on a large real-world dataset crawled from Google Play. The encouraging results demonstrate that our technique is effective and promising.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "L. Bottou. Stochastic gradient descent tricks. In Neural Networks: Tricks of the Trade, pages 421--436. 2012.", "N. Chen, S. C. Hoi, S. Li, and X. Xiao. Simapp: A framework for detecting similar mobile applications by online kernel learning. In WSDM, pages 305--314, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835812"}, {"title": "Memory-based Recommendations of Entities for Web Search Users", "authors": ["Ignacio Fernández-Tobías\n,", "Roi Blanco"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nModern search engines have evolved from mere document retrieval systems to platforms that assist the users in discovering new information. In this context, entity recommendation systems exploit query log data to proactively provide the users with suggestions of entities (people, movies, places, etc.) from knowledge bases that are relevant for their current information need. Previous works consider the problem of ranking facts and entities related to the user's current query, or focus on specific recommendation domains requiring supervised selection and extraction of features from knowledge bases. In this paper we propose a set of domain-agnostic methods based on nearest neighbors collaborative filtering that exploit query log data to generate entity suggestions, taking into account the user's full search session. Our experimental results on a large dataset from a commercial search engine show that the proposed methods are able to compute relevant entity recommendations outperforming a number of baselines. Finally, we perform an analysis on a cross-domain scenario using different entity types, and conclude that even if knowing the right target domain is important for providing effective recommendations, some inter-domain user interactions are helpful for the task at hand.", "references": ["E. Amitay, D. Carmel, N. Har'El, S. Ofek-Koifman, A. Soffer, S. Yogev, and N. Golbandi. Social search and discovery using a unified approach. In Proc. of Hypertext 2009, pages 199--208.", "A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, 2008.", "A. L. Berger and J. D. Lafferty. Information retrieval as statistical translation. In Proc. of SIGIR 1999, pages 222--229."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983823"}, {"title": "A Dynamic Community-Based Personalization for e-Government Services", "authors": ["Sabrine Ben Abdrabbah\n,", "Raouia Ayachi\n,", "Nahla Ben Amor"], "publication": "ICEGOV '15-16: Proceedings of the 9th International Conference on Theory and Practice of Electronic Governance", "abstract": "ABSTRACT\nThe government portals and websites contain a wide range of information and services to help citizens and businesses comply in ease with the government requirements. One of the most important challenges for e-Government services is matching particular needs and interests of citizens and businesses to achieve efficient e-Government services quality. Recommender systems have been proposed to deliver users with the most interesting information service thereby addressing the information overload problem. In this paper, we focus on the implementation of a recommender system in an e-Government context to provide personalized G2C e-services. The proposed approach combines the expert pre-defined categorization of the e-government services and the citizens rating history to identify the relevant services for the active citizen. The efficiency of the proposed e-Government services personalization method is studied via a comparative study with the benchmark item-based and a state-of-the-art recommender system for Government-to-Business e-services. Experimental results show a considerable improvement for the proposed recommendation approach in term of performance and accuracy.", "references": ["Aston, N., Hertzler, J. and Hu, W. 2014. Overlapping Community Detection in Dynamic Networks. Journal of Software Engineering and Applications. 7, 872--882. doi: 10.4236/jsea.2014.710078.", "Blondel, V.D., Guillaume, J., Lambiotte, R. and Lefebvre, E. 2008. Fast Unfolding of Communities in Large Networks-Louvain Method, In: Journal of Statical Mechanics: Theory and Experiment.", "Cazabet, R. and Amblard, F. 2011. Simulate to detect: a multi-agent system for community detection. In: The 2011 ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), 2(August 2011), 402--408."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910019.2910050"}, {"title": "Audience Expansion for Online Social Network Advertising", "authors": ["Haishan Liu\n,", "David Pardoe\n,", "Kun Liu\n,", "Manoj Thakur\n,", "Frank Cao\n,", "Chongzhe Li"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nOnline social network advertising platforms, such as that provided by LinkedIn, generally allow marketers to specify targeting options so that their ads appear to a desired demographic. Audience Expansion is a technique developed at LinkedIn to simplify targeting and identify new audiences with similar attributes to the original target audience. We developed two methods to achieve Audience Expansion: campaign-agnostic expansion and campaign-aware expansion. In this paper, we describe the details of these methods, present in-depth analysis of their trade-offs, and demonstrate a hybrid strategy that possesses the combined strength of both methods. Through large scale online experiments, we show the effectiveness of the proposed approach, and as a result, the benefits it brings to the whole marketplace including both LinkedIn and advertisers. The achieved benefits can be characterized as: 1) simplified targeting process and increased reach for advertisers, and 2) better utilization of LinkedIn's ads inventory and higher and more efficient market participation.", "references": ["W. Amaldoss, K. Jerath, and A. Sayedi. Keyword management costs and \"broad match\" in sponsored search advertising. Marketing Science, 2015.", "A. Bagherjeiran, A. Hatch, A. Ratnaparkhi, and R. Parekh. Large-scale customized models for advertisers. In Proceedings of the 2010 IEEE International Conference on Data Mining Workshops, ICDMW '10, pages 1029--1036. IEEE, 2010.", "A. Bindra, S. Pokuri, K. Uppala, and A. Teredesai. Distributed big advertiser data mining. In Proceedings of the 2012 IEEE International Conference on Data Mining Workshops, pages 914--914, Dec 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939680"}, {"title": "CUTiS: optimized online ClUstering of Trajectory data Stream", "authors": ["Ticiana L. Coelho da Silva\n,", "Karine Zeitouni\n,", "José A. F. de Macêdo\n,", "Marco A. Casanova"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nRecent approaches for online clustering of moving objects location are restricted to instantaneous positions. Subse-quently, they fail to capture the behavior of moving objects over time. By continuously tracking sub-trajectories of moving object at each time window, it becomes possible to gain insight on the current behavior and potentially detect mobility patterns in real time. In our previous work [1], we proposed CUTiS, an incremental algorithm for discovering and maintaining the density-based clusters in trajectory data streams, while tracking the evolution of the clusters. This paper extends [1] to CUTiS* by proposing an indexing structure for sub-trajectory data based on a space-filling curve. The proposed index improves the performance of our approach without losing quality in the clusters results as we show in our experiments conducted on a real dataset.", "references": ["T. Coelho da Silva, K. Zeitouni, and J. de Macêdo. Online clustering of trajectory data streams. In MDM, 2016.", "T. Coelho da Silva, K. Zeitouni, J. de Macêdo, and M. A. Casanova. On-line mobility pattern discovering using trajectory data. In EDBT, pages 682--683, 2016.", "T. Coelho da Silva, K. Zeitouni, J. de Macêdo, and M. A. Casanova. A framework for online mobility pattern discovery from trajectory data stream. In MDM, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938516"}, {"title": "Multistatic radars locating a human being behind corners based on the method of mirror localization", "authors": ["Kewei Wu\n,", "Chongyi Fan\n,", "Xiaotao Huang\n,", "Xiangyang Li"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nNon-line of sight (NLOS) is a problem that influences the accuracy of target location. However, the NLOS signals can be utilized to locate the target hidden behind corners, meanwhile, transmitter is not easy to find by anti-radiation missiles for it is hidden behinda corner. In this paper, the information of NLOS range is utilized to locate human being hidden behind the corners by our multistatic radar system based on method of mirror localization (MOML). The method of mirror localization derives from the principle mirror imaging. The echoes obtained by receiver radars have the strongest signals which do not spread through the human being marking time before restrain static clutters. We can locate the virtual image of the real transmitted antenna by taking advantage of time delay of the strongest signals based on time of arrival (TOA) before suppressing clutters. The virtual radar of the real transmitted antenna is called virtual transmitted antenna. We replace the real transmitted antenna by virtual transmitted antenna. Thus the NLOS problems are turned into the line of sight (LOS) problems. Then we can locate the human being by TOA method after restraining clutter. In the case of complex propagation models, the time delay of propagation is not necessary to be hnown in the method of mirror localization.", "references": ["G. R. Curry, Radar System Performance Modeling, Artech House, 2005.", "M. N. Petsios, E. G. Alivizatos and N. K. Uzunoglu, \"Solving the association problem for a multistatic range-only radar target tracker,\" Signal Processing, Vol. 88, No. 9, pp. 2254--2277, 2008.", "S. Kingsley and S. Quegan, Understanding Radar Systems, Sci Tech Publishing, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015174"}, {"title": "Transfer Learning for Cross-Lingual Sentiment Classification with Weakly Shared Deep Neural Networks", "authors": ["Guangyou Zhou\n,", "Zhao Zeng\n,", "Jimmy Xiangji Huang\n,", "Tingting He"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNOTE FROM ACM: It has been determined that this article plagiarized the contents of a previously published paper. Therefore ACM has shut off access to this paper.\nThis article has been removed from the ACM Digital Library because it was found to plagiarize an earlier work written by Xiangbo Shu, Guo-Jin Qi, Jinhui Tang, and Jingdong Wang published by ACM and entitled DOI:http://doi.acm.org/10.1145/2733373.2806216 Weakly-Shared Deep Transder Networks for Heterogeneous-Domain Knowledge Propagation. In Proceedings of the 23rd ACM International Conference on Multimedia (MM '15). ACM, New York, NY, USA, 35-44.\nFor further information, contact the ACM Director of Publications.", "references": ["B. A., A. Joshi, and P. Bhattacharyya. Cross-lingual sentiment analysis for Indian languages using linked wordnets. In COLING, pages 73--82, 2012.", "S. Artem, J. Laura, H. Felix, and R. Stefan. Boosting cross-language retrieval by learning bilingual phrase associations from relevance rankings. In EMNLP, pages 1688--1699, 2013.", "C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. Multilingual subjectivity analysis using machine translation. In EMNLP, pages 127--135, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911490"}, {"title": "Prediction and Predictability for Search Query Acceleration", "authors": ["Seung-Won Hwang\n,", "Saehoon Kim\n,", "Yuxiong He\n,", "Sameh Elnikety\n,", "Seungjin Choi"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nA commercial web search engine shards its index among many servers, and therefore the response time of a search query is dominated by the slowest server that processes the query. Prior approaches target improving responsiveness by reducing the tail latency, or high-percentile response time, of an individual search server. They predict query execution time, and if a query is predicted to be long-running, it runs in parallel; otherwise, it runs sequentially. These approaches are, however, not accurate enough for reducing a high tail latency when responses are aggregated from many servers because this requires each server to reduce a substantially higher tail latency (e.g., the 99.99th percentile), which we call extreme tail latency.\nTo address tighter requirements of extreme tail latency, we propose a new design space for the problem, subsuming existing work and also proposing a new solution space. Existing work makes a prediction using features available at indexing time and focuses on optimizing prediction features for accelerating tail queries. In contrast, we identify “when to predict?” as another key optimization question. This opens up a new solution of delaying a prediction by a short duration to allow many short-running queries to complete without parallelization and, at the same time, to allow the predictor to collect a set of dynamic features using runtime information. This new question expands a solution space in two meaningful ways. First, we see a significant reduction of tail latency by leveraging “dynamic” features collected at runtime that estimate query execution time with higher accuracy. Second, we can ask whether to override prediction when the “predictability” is low. We show that considering predictability accelerates the query by achieving a higher recall.\nWith this prediction, we propose to accelerate the queries that are predicted to be long-running. In our preliminary work, we focused on parallelization as an acceleration scenario. We extend to consider heterogeneous multicore hardware for acceleration. This hardware combines processor cores with different microarchitectures such as energy-efficient little cores and high-performance big cores, and accelerating web search using this hardware has remained an open problem.\nWe evaluate the proposed prediction framework in two scenarios: (1) query parallelization on a multicore processor and (2) query scheduling on a heterogeneous processor. Our extensive evaluation results show that, for both scenarios of query acceleration using parallelization and heterogeneous cores, the proposed framework is effective in reducing the extreme tail latency compared to a start-of-the-art predictor because of its higher recall, and it improves server throughput by more than 70% because of its improved precision.", "references": ["R. Baeza-Yates, A. Gionis, F. P. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. 2008. Design trade-offs for search engine caching. ACM Transactions on Web 2, 4 (Oct. 2008), 1--28.", "R. Baeza-Yates, V. Murdock, and C. Hauff. 2009. Efficiency trade-offs in two-tier web search systems. In SIGIR.", "M. Becchi and P. Crowley. 2006. Dynamic thread assignment on heterogeneous multiprocessor architectures. ACM Computing Frontiers (2006)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2943784"}, {"title": "Audiovisual Tool for Solfège Assessment", "authors": ["Rodrigo Schramm\n,", "Helena De Souza Nunes\n,", "Cláudio Rosito Jung"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nSolfège is a general technique used in the music learning process that involves the vocal performance of melodies, regarding the time and duration of musical sounds as specified in the music score, properly associated with the meter-mimicking performed by hand movement. This article presents an audiovisual approach for automatic assessment of this relevant musical study practice. The proposed system combines the gesture of meter-mimicking (video information) with the melodic transcription (audio information), where hand movement works as a metronome, controlling the time flow (tempo) of the musical piece. Thus, meter-mimicking is used to align the music score (ground truth) with the sung melody, allowing assessment even in time-dynamic scenarios. Audio analysis is applied to achieve the melodic transcription of the sung notes and the solfège performances are evaluated by a set of Bayesian classifiers that were generated from real evaluations done by experts listeners.", "references": ["Frédéric Bevilacqua, Bruno Zamborlin, Anthony Sypniewski, Norbert Schnell, Fabrice Guédy, and Nicolas Rasamimanana. 2010. Continuous realtime gesture following and recognition. In Proceedings of the 8th International Conference on Gesture in Embodied Communication and Human-Computer Interaction (GW’09). Springer-Verlag, Berlin, 73--84.", "Alain de Cheveigné and Hideki Kawahara. 2002. YIN, a fundamental frequency estimator for speech and music. J. Acoust. Soc. Am. 111, 4 (Apr. 2002), 1917--1930.", "Richard O. Duda, Peter E. Hart, and David G. Stork. 2001. Pattern Classification (2nd ed.). Wiley-Interscience."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007194"}, {"title": "A Real-Time Audit Mechanism Based on the Compression Technique", "authors": ["Shing-Han Li\n,", "David C. Yen\n,", "Ying-Ping Chuang"], "publication": "ACM Transactions on Management Information Systems", "abstract": "Abstract\nLog management and log auditing have become increasingly crucial for enterprises in this era of information and technology explosion. The log analysis technique is useful for discovering possible problems in business processes and preventing illegal-intrusion attempts and data-tampering attacks. Because of the complexity of the dynamically changing environment, auditing a tremendous number of data is a challenging issue. We provide a real-time audit mechanism to improve the aforementioned problems in log auditing. This mechanism was developed based on the Lempel-Ziv-Welch (LZW) compression technique to facilitate effective compression and provide reliable auditing log entries. The mechanism can be used to predict unusual activities when compressing the log data according to pre-defined auditing rules. Auditors using real-time and continuous monitoring can perceive instantly the most likely anomalies or exceptions that could cause problems. We also designed a user interface that allows auditors to define the various compression and audit parameters, using real log cases in the experiment to verify the feasibility and effectiveness of this proposed audit mechanism. In summary, this mechanism changes the log access method and improves the efficiency of log analysis. This mechanism greatly simplifies auditing so that auditors must only trace the sources and causes of the problems related to the detected anomalies. This greatly reduces the processing time of analytical audit procedures and the manual checking time, and improves the log audit efficiency.", "references": ["S. A. Abu Taleb, H. M. J. Musafa, A. M. Khtoom, and K. Gharaybih. 2010. Improving LZW image compression. European Journal of Scientific Research 44, 3, 502--509.", "M. K. Ahmed, M. Hussain, and A. Raza. 2009. An automated user transparent approach to log Web URLs for forensic analysis. In Proceedings of the 5th International Conference on IT Security Incident Management and IT Forensics. 120--127.", "S. Al-Fedaghi and B. Mattar. 2010. On security log management systems. Global Journal of Computer Science and Technology 10, 6, 73--82."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2629569"}, {"title": "A Supervised Learning Algorithm for Binary Domain Classification of Web Queries using SERPs", "authors": ["Alexander C. Nwala\n,", "Michael L. Nelson"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nGeneral purpose Search Engines (SEs) crawl all domains (e.g., Sports, News, Entertainment) of the Web, but sometimes the informational need of a query is restricted to a particular domain (e.g., Medical). We leverage the work of SEs as part of our effort to route domain specific queries to local Digital Libraries (DLs). SEs are often used even if they are not the \"best\" source for certain types of queries. Rather than tell users to \"use this DL for this kind of query\", we intend to automatically detect when a query could be better served by a local DL (such as a private, access-controlled DL that is not crawlable via SEs). This is not an easy task because Web queries are short, ambiguous, and there is lack of quality labeled training data (or it is expensive to create). To detect queries that should be routed to local, specialized DLs, we first send the queries to Google and then examine the features in the resulting Search Engine Result Pages. Using 400,000 AOL queries for the \"non-scholar\" domain and 400,000 queries from the NASA Technical Report Server for the \"scholar\" domain, our classifier achieved a precision of 0.809 and F-measure of 0.805.", "references": ["L. Gravano, V. Hatzivassiloglou, and R. Lichtenstein. Categorizing web queries according to geographical locality. In Proceedings of the Twelfth International Conference on Information and Knowledge Management, pages 325--333, 2003.", "G. Pass, A. Chowdhury, and C. Torgeson. A picture of search. In Proceedings of the 1st International Conference on Scalable Information Systems, 2006.", "D. Shen, R. Pan, J.-T. Sun, J. J. Pan, K. Wu, J. Yin, and Q. Yang. Q2C@UST: our winning solution to query classification in KDDCUP 2005. ACM SIGKDD Explorations Newsletter, 7(2):100--110, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925449"}, {"title": "A Big Data Approach For Querying Data in EHR Systems", "authors": ["Nunziato Cassavia\n,", "Mario Ciampi\n,", "Giuseppe De Pietro\n,", "Elio Masciari"], "publication": "IDEAS '16: Proceedings of the 20th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nInformation management in healthcare is nowadays experiencing a great revolution. After the impressive progress in digitizing medical data by private organizations, also the federal government and other public stakeholders have also started to make use of healthcare data for data analysis purposes in order to extract actionable knowledge. In this paper, we propose an architecture for supporting interoperability in healthcare systems by exploiting Big Data techniques. In particular, we describe a proposal based on big data techniques to implement a nationwide system able to improve EHR data access efficiency and reduce costs.", "references": ["Synapses/SynEx goes XML. Studies in Health Technology and Informatics, IOS press (1999)", "(2001), http://healthcare.omg.org/Roadmap/corbamed_roadmap.htm", "Big data. Nature (Sep 2008)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938503.2938539"}, {"title": "Sentiment Domain Adaptation with Multi-Level Contextual Sentiment Knowledge", "authors": ["Fangzhao Wu\n,", "Sixing Wu\n,", "Yongfeng Huang\n,", "Songfang Huang\n,", "Yong Qin"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSentiment domain adaptation is widely studied to tackle the domain-dependence problem in sentiment analysis field. Existing domain adaptation methods usually train a sentiment classifier in a source domain and adapt it to the target domain using transfer learning techniques. However, when the sentiment feature distributions of the source and target domains are significantly different, the adaptation performance will heavily decline. In this paper, we propose a new sentiment domain adaptation approach by adapting the sentiment knowledge in general-purpose sentiment lexicons to a specific domain. Since the general sentiment words of general-purpose sentiment lexicons usually convey consistent sentiments in different domains, they have better generalization performance than the sentiment classifier trained in a source domain. In addition, we propose to extract various kinds of contextual sentiment knowledge from massive unlabeled samples in target domain and formulate them as sentiment relations among sentiment expressions. It can propagate the sentiment information in general sentiment words to massive domain-specific sentiment expressions. Besides, we propose a unified framework to incorporate these different kinds of sentiment knowledge and learn an accurate domain-specific sentiment classifier for target domain. Moreover, we propose an efficient optimization algorithm to solve the model of our approach. Extensive experiments on benchmark datasets validate the effectiveness and efficiency of our approach.", "references": ["R. P. Abelson. Whatever became of consistency theory? Personality and Social Psychology Bulletin, 9(1):37--54, 1983.", "A. Beck and M. Teboulle. A fast iterative shrinkage thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183--202, 2009.", "J. Blitzer, M. Dredze, F. Pereira, et al. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL, volume 7, pages 440--447, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983851"}, {"title": "Exploiting Diverse Distance Metrics for Surrogate-Based Optimisation of Ordering Problems: A Case Study", "authors": ["Jim Smith\n,", "Christopher Stone\n,", "Martin Serpell"], "publication": "GECCO '16: Proceedings of the Genetic and Evolutionary Computation Conference 2016", "abstract": "ABSTRACT\nSurrogate-assisted Optimisation has proven success in the continuous domain, but only recently begun to be explored for other representations, in particular permutations. The use of Gaussian kernel-based models has been proposed, but only tested on small problems. This case study considers much larger instances, in the experimental setting of a real-world ordering problem. We also investigate whether creating models using different distance metrics generates a diverse ensemble. Results demonstrate the following effects of use to other researchers: (i) Numerical instability in matrix inversion is a factor across all metrics, regardless of algorithm used. The likelihoood increases significantly once the models are parameterised using evolved solutions as well as the initial random population; (ii) This phase transition is also observed in different indicators of model quality. For example, predictive accuracy typically decreases once models start to include data from evolved samples. We explain this transition in terms of the distribution of samples and Gaussian kernel basis of the models; (iii) Measures of how well models predict rank-orderings are less affected; (iv) Benchmark comparisons show that using surrogate models decreases the number of evaluations required to find good solutions, without affecting quality.", "references": ["Y. Jin. A comprehensive survey of fitness approximation in evolutionary computation. Soft Computing,9(1): 3--12, 2005", "D. R. Jones, M. Schonlau, and W. J. Welch. Efficient global optimization of expensive black-box functions. Journal of Global Optimization, 13(4):455--492, 1998.", "Y. Jin. Surrogate-assisted evolutionary computation: Recent advances and future challenges. Swarm and Evolutionary Computation, 1(2):61--70, June 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908812.2908854"}, {"title": "SLAM Algorithm Based on Cross-Correlation Scan Matching", "authors": ["Jaromir Konecny\n,", "Michal Prauzek\n,", "Jakub Hlavica"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nMobile robotics, and particularly robot localization, has undergone tremendous development over the years. Conventional approaches typically employ a large set of sensors to determine robot's position.\nThis contribution focuses on Simultaneous localization and mapping (SLAM) based on cross-correlation scan matching with input data being acquired through one laser sensor. The method does not involve additional sensors, such as odometers, thought it maintains to provide satisfactory and robust convergence towards an accurate robot position determination. The method is implemented and tested in a real indoor environment and, as experimental results show, is capable of operation in real time.", "references": ["Nieto, J., Bailey, T., and Nebot, E. 2007. Recursive scan-matching slam. Robotics and Autonomous Systems, 55(1), pages 39--49.", "Armesto, L. and Tornero, J. 2004. Slam based on kalman filter for multi-rate fusion of laser and encoder measurements. In Proceedings of the International Conference on Intelligent Robots and Systems(IROS 2004). 2004 IEEE/RSJ, vol. 2, pages 1860--1865.", "Diosi, A. and Kleeman, L. 2005. Laser scan matching in polar coordinates with application to slam. In International Conference on Intelligent Robots and Systems (IROS 2005). 2005 IEEE/RSJ, pages 3317--3322."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015184"}, {"title": "A Multithreaded Algorithm for Mining Maximal Cohesive Dense Modules from Interaction Networks with Gene Profiles", "authors": ["Aditya Goparaju\n,", "Saeed Salem"], "publication": "BCB '16: Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics", "abstract": "ABSTRACT\nSeveral graph datasets exist which have additional attributes, representing properties of either nodes or edges in the graph. Recent research has focused on finding integrated or cohesive clusters where the clusters are not only densely connected but also have similarities in a subspace of their attributes. Cohesive clusters are more robust and accurately represent the cluster structure as they exhibit similarity in two domains (network structure and attributes).\nIn this paper, we propose a multithreaded enumeration technique, for mining maximal cohesive and dense clusters from node-attributed graphs. For relaxed constraints the number of result clusters on a large graph can be very high and we need a way to find a representative set of clusters which can be most similar to all remaining clusters. We propose a novel technique to find representative clusters from the output space. Experiments on two real interaction networks show the effectiveness of the proposed algorithm.", "references": ["D. Avis and K. Fukuda. Reverse search for enumeration. Discrete Applied Mathematics, 65(1):21--46, 1996.", "S. Bandyopadhyay, R. Sharan, and T. Ideker. Systematic identification of functional orthologs based on protein network comparison. Genome research, 16(3):428--435, 2006.", "N. N. Batada, T. Reguly, A. Breitkreutz, L. Boucher, B.-J. Breitkreutz, L. D. Hurst, and M. Tyers. Still stratus not altocumulus: further evidence against the date/party hub distinction. PLoS biology, 5(6):e154, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975167.2985693"}, {"title": "Personal Multi-view Viewpoint Recommendation based on Trajectory Distribution of the Viewing Target", "authors": ["Xueting Wang\n,", "Kensho Hara\n,", "Yu Enokibori\n,", "Takatsugu Hirayama\n,", "Kenji Mase"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nMulti-camera videos with abundant information and high flexibility are expected to be useful in a wide range of applications, such as surveillance systems, web lecture broadcasting, concerts and sports viewing, etc. Viewers can enjoy a high-presence viewing experience of their own choosing by means of virtual camera switching and controlling viewing interfaces. However, some viewers may feel annoyed by continual manual viewpoint selection, especially when the number of selectable viewpoints is relatively large. In order to solve this issue, we propose an automatic viewpoint-recommending method designed especially for soccer games. This method focuses on a viewer's personal preference for viewpoint-selection, instead of common and professional editing rules. We assume that the different trajectory distributions cause a difference in the viewpoint selection according to personal preference. We therefore analyze the relationship between the viewer's personal viewpoint selecting tendency and the spatio-temporal game context. We compare methods based on a Gaussian mixture model, a general histogram+SVM and bag-of-words+SVM to seek the best representation for this relationship. The performance of the proposed methods are verified by assessing the degree of similarity between the recommended viewpoints and the viewers' edited records.", "references": ["I. Ahmad. Multi-view video: get ready for next-generation television. IEEE Distributed Systems Online, 8(3):6--6, 2007.", "R. T. Collins, O. Amidi, and T. Kanade. An active camera system for acquiring multi-view video. In in Proc. International Conference on Image Processing, 2002.", "G. Csurka, C. Dance, L. Fan, J. Willamowski, and C. Bray. Visual categorization with bags of keypoints. In Workshop on statistical learning in computer vision, ECCV, volume 1, pages 1--2. Prague, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967265"}, {"title": "Arrp: a functional language with multi-dimensional signals and recurrence equations", "authors": ["Jakob Leben"], "publication": "FARM 2016: Proceedings of the 4th International Workshop on Functional Art, Music, Modelling, and Design", "abstract": "ABSTRACT\nWe present a new functional programming language for digital signal processing (DSP) named Arrp, in which signals are regarded as multi-dimensional arrays with an infinite dimension representing time, and defined using quasi-affine recurrence equations. An immediate benefit is an intuitive syntax that is very close to common mathematical notation used in DSP. Code reuse, especially in multi-dimensional and multi-rate signal processing, is supported through polymorphic and higher-order functions. We describe the differences between our approach and other paradigms in the domain, demonstrate the benefits of the language, and outline a method for compilation of the language into efficient C++ code using the polyhedral model. Preliminary experimental evaluation of our compiler shows that Arrp executes as fast or faster than hand-written C++ code, without explicit parallelization.", "references": ["X. Amatriain, P. Arumi, and D. Garcia. CLAM: A framework for efficient and rapid development of cross-platform audio applications. In Proceedings of the 14th ACM International Conference on Multimedia, pages 951–954, New York, NY, USA, 2006. ACM. doi: 10.1145/ 1180639.1180847.", "M. Aronsson, E. Axelsson, and M. Sheeran. Stream processing for embedded domain specific languages. In Proceedings of the 26nd 2014 International Symposium on Implementation and Application of Functional Languages, pages 8:1–8:12, New York, NY, USA, 2014.", "ACM. doi: 10.1145/2746325.2746334."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975980.2975983"}, {"title": "How Many Workers to Ask?: Adaptive Exploration for Collecting High Quality Labels", "authors": ["Ittai Abraham\n,", "Omar Alonso\n,", "Vasilis Kandylas\n,", "Rajesh Patel\n,", "Steven Shelford\n,", "Aleksandrs Slivkins"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCrowdsourcing has been part of the IR toolbox as a cheap and fast mechanism to obtain labels for system development and evaluation. Successful deployment of crowdsourcing at scale involves adjusting many variables, a very important one being the number of workers needed per human intelligence task (HIT). We consider the crowdsourcing task of learning the answer to simple multiple-choice HITs, which are representative of many relevance experiments. In order to provide statistically significant results, one often needs to ask multiple workers to answer the same HIT. A stopping rule is an algorithm that, given a HIT, decides for any given set of worker answers to stop and output an answer or iterate and ask one more worker. In contrast to other solutions that try to estimate worker performance and answer at the same time, our approach assumes the historical performance of a worker is known and tries to estimate the HIT difficulty and answer at the same time. The difficulty of the HIT decides how much weight to give to each worker's answer. In this paper we investigate how to devise better stopping rules given workers' performance quality scores. We suggest adaptive exploration as a promising approach for scalable and automatic creation of ground truth. We conduct a data analysis on an industrial crowdsourcing platform, and use the observations from this analysis to design new stopping rules that use the workers' quality scores in a non-trivial manner. We then perform a number of experiments using real-world datasets and simulated data, showing that our algorithm performs better than other approaches.", "references": ["Ittai Abraham, Omar Alonso, Vasilis Kandylas, and Aleksandrs Slivkins. Adaptive crowdsourcing algorithms for the bandit survey problem. In 26th COLT, 2013.", "Omar Alonso and Stefano Mizzaro. Using crowdsourcing for TREC relevance assessment. Inf. Process. Manage., 48(6):1053--1066, 2012.", "Peter Auer, Nicolò Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2--3):235--256, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911514"}, {"title": "On the Value of Reminders within E-Commerce Recommendations", "authors": ["Lukas Lerche\n,", "Dietmar Jannach\n,", "Malte Ludewig"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nMost research in recommender systems is focused on the problem of identifying and ranking items that are relevant for the individual users but unknown to them. The potential value of such systems is to help users discover new items, e.g., in e-commerce settings. Many real-world systems however also utilize recommendation lists for a different goal, namely to remind users of items that they have viewed or consumed in the past. In this work, we aim to quantify the value of such reminders in recommendation lists (\"recominders\"), which has to our knowledge not been done in the past. We first report the results of a live experiment in which we applied a naive reminding strategy on an online platform and compare them with results obtained through different offline analyses. We then propose more elaborate reminding techniques, which aim to avoid reminders of too obvious or of already outdated items. Overall, our results show that although reminders do not lead to new item discoveries, they can be valuable both for users and service providers.", "references": ["http://sifter.org/simon/journal/20061211.html (last accessed: 02/2016), 2006.", "Gediminas Adomavicius and Alexander Tuzhilin. Context-aware recommender systems. In Recommender Systems Handbook, pages 217--253. Springer, 2011.", "Ashton Anderson, Ravi Kumar, Andrew Tomkins, and Sergei Vassilvitskii. The dynamics of repeat consumption. In Prof. WWW '14, pages 419--430, 2014.", "David Ben-Shimon, Alexander Tsikinovsky, Michael Friedmann, Bracha Shapira, Lior Rokach, and Johannes Hoerle. RecSys challenge 2015 and the YOOCHOOSE dataset. In Proc. RecSys '15, pages 357--358, 2015.", "Pedro G. Campos, Fernando Dıez, and Iván Cantador. Time-aware recommender systems: A comprehensive survey and analysis of existing evaluation protocols. UMUAI, 24(1--2):67--119, 2014.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930244"}, {"title": "Demo: Real-Time C2C Matching Based on Social Media Messages", "authors": ["M.R. Mohamed Rilfi\n,", "H.M.N. Dilum Bandara"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nSocial media has a huge potential in the domain of Consumer-to-Consumer (C2C) e-commerce. We plan to exploit this opportunity through matching social media messages from users who are interested in selling and buying items. Such C2C matching in real time is none-trivial due to the complexities of interpreting social media messages, diversity of products/services, sheer number of messages, and computational requirements. Alternatively, if such matching can be done in (near) real-time, it provides a greater potential both to the buyers and sellers. We outline a solution to address this big data problem using information extraction, real-time stream, complex event, and NoSQL dynamic query processing.", "references": ["Anderson, N. and Hong, J. 2014. Evaluation of information extraction techniques to label extracted data from e-commerce web pages. In Proc. companion publication of 23rd Intl. Conf. on World wide web companion (Apr. 2014), 1275--1278.", "Liu, G. et al. 2015. Real-time Complex Event Processing and Analytics for Smart Grid. In Procedia Computer Science. 61, (Nov. 2015), 113--119."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2948868"}, {"title": "Controversy Detection in Wikipedia Using Collective Classification", "authors": ["Shiri Dori-Hacohen\n,", "David Jensen\n,", "James Allan"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nConcerns over personalization in IR have sparked an interest in detection and analysis of controversial topics. Accurate detection would enable many beneficial applications, such as alerting search users to controversy. Wikipedia's broad coverage and rich metadata offer a valuable resource for this problem. We hypothesize that intensities of controversy among related pages are not independent; thus, we propose a stacked model which exploits the dependencies among related pages. Our approach improves classification of controversial web pages when compared to a model that examines each page in isolation, demonstrating that controversial topics exhibit homophily. Using notions of similarity to construct a subnetwork for collective classification, rather than using the default network present in the relational data, leads to improved classification with wider applications for semi-structured datasets, with the effects most pronounced when a small set of neighbors is used.", "references": ["U. Brandes, P. Kenis, J. Lerner, and D. van Raaij. Network analysis of collaboration structure in Wikipedia. WWW, 2009.", "M. Bröcheler, L. Mihalkova, and L. Getoor. Probabilistic Similarity Logic. CoRR, 2012.", "S. Chakrabarti, B. Dom, and P. Indyk. Enhanced hypertext categorization using hyperlinks. 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914745"}, {"title": "Ranking Financial Tweets", "authors": ["Diego Ceccarelli\n,", "Francesco Nidito\n,", "Miles Osborne"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecently Twitter has complemented traditional newswire as a source of valuable Financial information. Although there is a rich body of published research dealing with the task of ranking tweets, there has been little published research dealing with ranking tweets within a Financial context. Here we consider whether popularity factors within Twitter can be used as a signal for popularity within the domain of financial experts. Our results suggest that what interests Finance is not the same as what interests the users of Twitter.", "references": ["Y. Duan, L. Jiang, T. Qin, M. Zhou, and H.-Y. Shum. An empirical study on learning to rank of tweets. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 295--303. Association for Computational Linguistics, 2010.", "R. Nagmoti, A. Teredesai, and M. De Cock. Ranking approaches for microblog search. In Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on, volume 1, pages 153--157. IEEE, 2010.", "I. Ounis, C. Macdonald, J. Lin, and I. Soboroff. Overview of the trec-2011 microblog track. In Proceeddings of the 20th Text REtrieval Conference (TREC 2011), volume 32, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926727"}, {"title": "Unsupervised, Efficient and Semantic Expertise Retrieval", "authors": ["Christophe Van Gysel\n,", "Maarten de Rijke\n,", "Marcel Worring"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe introduce an unsupervised discriminative model for the task of retrieving experts in online document collections. We exclusively employ textual evidence and avoid explicit feature engineering by learning distributed word representations in an unsupervised way. We compare our model to state-of-the-art unsupervised statistical vector space and probabilistic generative approaches. Our proposed log-linear model achieves the retrieval performance levels of state-of-the-art document-centric methods with the low inference cost of so-called profile-centric approaches. It yields a statistically significant improved ranking over vector space and generative models in most cases, matching the performance of supervised methods on various benchmarks. That is, by using solely text we can do as well as methods that work with external evidence and/or relevance feedback. A contrastive analysis of rankings produced by discriminative and generative approaches shows that they have complementary strengths due to the ability of the unsupervised discriminative model to perform semantic matching.", "references": ["The knowledge-based economy. Techn. report, Organisation for Economic Co-operation and Development, 1996.", "P. Bailey, A. P. De Vries, N. Craswell, and I. Soboroff. Overview of the TREC 2007 enterprise track. In TREC, 2007.", "K. Balog. People Search in the Enterprise. PhD thesis, University of Amsterdam, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882974"}, {"title": "Session details: Main Track - Methodologies and Approaches for IS (I)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255988"}, {"title": "Fresh Starts", "authors": ["Kate Matsudaira"], "publication": "Queue", "abstract": "Abstract\nJust because you have been doing it the same way doesn't mean you are doing it the right way.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.2996549"}, {"title": "Like It or Not: A Survey of Twitter Sentiment Analysis Methods", "authors": ["Anastasia Giachanou\n,", "Fabio Crestani"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nSentiment analysis in Twitter is a field that has recently attracted research interest. Twitter is one of the most popular microblog platforms on which users can publish their thoughts and opinions. Sentiment analysis in Twitter tackles the problem of analyzing the tweets in terms of the opinion they express. This survey provides an overview of the topic by investigating and briefly describing the algorithms that have been proposed for sentiment analysis in Twitter. The presented studies are categorized according to the approach they follow. In addition, we discuss fields related to sentiment analysis in Twitter including Twitter opinion retrieval, tracking sentiments over time, irony detection, emotion detection, and tweet sentiment quantification, tasks that have recently attracted increasing attention. Resources that have been used in the Twitter sentiment analysis literature are also briefly presented. The main contributions of this survey include the presentation of the proposed approaches for sentiment analysis in Twitter, their categorization according to the technique they use, and the discussion of recent research trends of the topic and its related fields.", "references": ["Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media (LSM’11). Association for Computational Linguistics, Stroudsburg, PA, USA, 30--38.", "Fotis Aisopos, George Papadakis, and Theodora Varvarigou. 2011. Sentiment analysis of social media content using n-gram graphs. In Proceedings of the 3rd ACM SIGMM International Workshop on Social Media (WSM’11). ACM, New York, NY, 9--14. DOI:http://dx.doi.org/10.1145/2072609.2072614", "Giambattista Amati, Marco Bianchi, and Giuseppe Marcone. 2014. Sentiment estimation on twitter. In Proceedings of the 5th Italian Information Retrieval Workshop (IIR’14), Vol. 1127. CEUR Workshop Proceedings, 39--50."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938640"}, {"title": "Downside management in recommender systems", "authors": ["Huan Gui\n,", "Haishan Liu\n,", "Xiangrui Meng\n,", "Anmol Bhasin\n,", "Jiawei Han"], "publication": "ASONAM '16: Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "abstract": "ABSTRACT\nIn recommender systems, bad recommendations can lead to a net utility loss for both users and content providers. The downside (individual loss) management is a crucial and important problem, but has long been ignored. We propose a method to identify bad recommendations by modeling the users' latent preferences that are yet to be captured using a residual model, which can be applied independently on top of existing recommendation algorithms. We include two components in the residual utility: benefit and cost, which can be learned simultaneously from users' observed interactions with the recommender system. We further classify user behavior into fine-grained categories, based on which an efficient optimization algorithm to estimate the benefit and cost using Bayesian partial order is proposed. By accurately calculating the utility users obtained from recommendations based on the benefit-cost analysis, we can infer the optimal threshold to determine the downside portion of the recommender system. We validate the proposed method by experimenting with real-world datasets and demonstrate that it can help to prevent bad recommendations from showing.", "references": ["N. Balasubramanian, G. Kumaran, and V. R. Carvalho. Predicting query performance on the web. In Proceedings of the 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 785--786. ACM, 2010.", "J. Bennett and S. Lanning. The netflix prize. In Proceedings of KDD cup and workshop, volume 2007, page 35, 2007.", "J. Bobadilla, F. Ortega, A. Hernando, and A. Gutiérrez. Recommender systems survey. Knowledge-Based Systems, 46:109--132, July 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3192424.3192497"}, {"title": "Rank Diffusion for Context-Based Image Retrieval", "authors": ["Daniel Carlos Guimarães Pedronette\n,", "Ricardo da S. Torres"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper presents an efficient diffusion-based re-ranking approach. The proposed method propagates contextual information defined in terms of top-ranked objects of ranked lists in a diffusion process. That makes the method suitable for large scale real-world collections. Experiments were conducted considering public image collections, several descriptors, and comparisons with state-of-the-art methods. Experimental results demonstrate that the proposed method provides high effectiveness gains with low computational costs.", "references": ["N. Arica and F. T. Y. Vural. BAS: a perceptual shape descriptor based on the beam angle statistics. Pattern Recognition Letters, 24(9--10):1627--1639, 2003.", "X. Bai, S. Bai, and X. Wang. Beyond diffusion process: Neighbor set similarity for fast re-ranking. Information Sciences, 325:342 -- 354, 2015.", "P. Brodatz. Textures: A Photographic Album for Artists and Designers. Dover, 1966."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912060"}, {"title": "Recommendations with Optimal Combination of Feature-Based and Item-Based Preferences", "authors": ["Mona Nasery\n,", "Matthias Braunhofer\n,", "Francesco Ricci"], "publication": "UMAP '16: Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization", "abstract": "ABSTRACT\nMany recommender systems rely on item ratings to predict users' preferences and generate recommendations. However, users often express preferences by referring to features of the items, e.g., \"I like Tarantino's movies\". But, it has been shown that user models based on feature preferences may lead to wrong recommendations. In this paper we cope with this issue and we introduce a novel prediction model that generate better item recommendations, especially in cold-start situations, by exploiting both item-based and feature-based preferences. We also show that it is possible to optimize the combination of the two types of preferences when actively requesting them to users.", "references": ["M. Braunhofer and F. Ricci. Contextual information elicitation in travel recommender systems. In Information and Communication Technologies in Tourism 2016, pages 579--592. Springer, 2016.", "M. Elahi, M. Braunhofer, F. Ricci, and M. Tkalcic. Personality-based active learning for collaborative filtering recommender systems. In AI* IA 2013: Advances in Artificial Intelligence, pages 360--371. Springer, 2013.", "M. Enrich, M. Braunhofer, and F. Ricci. Cold-start management with cross-domain collaborative filtering and tags. In E-Commerce and Web Technologies, pages 101--112. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2930238.2930282"}, {"title": "A Sequential Decision Formulation of the Interface Card Model for Interactive IR", "authors": ["Yinan Zhang\n,", "Chengxiang Zhai"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe Interface Card model is a promising new theoretical framework for modeling and optimizing interactive retrieval interfaces, but how to systematically instantiate it to solve concrete interface optimization problems remains an open challenge. We propose a novel formulation of the Interface Card model based on sequential decision theory, leading to a general framework for formal modeling of user states and stopping actions. The proposed framework naturally connects optimization of interactive retrieval with Markov Decision Processes and Partially Observable Markov Decision Processes, and enables the use of reinforcement learning algorithms for optimizing interactive retrieval interfaces. Simulation and user study experiments demonstrate the effectiveness of the proposed model in automatically adjusting the interface layout in adaptation to inferred user stopping tendencies in addition to user interaction and screen size.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20(4):357--389, Oct. 2002.", "L. Azzopardi. Modelling interaction with economic models of search. In SIGIR '14, pages 3--12, 2014.", "L. Azzopardi and G. Zuccon. An analysis of theories of search and search behavior. In ICTIR '15, pages 81--90, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911543"}, {"title": "New Variable Step-size of l1-LMS Algorithm", "authors": ["Sihai Guan\n,", "Zhi LI\n,", "Hairu Zhang"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn order to quickenthe convergence rateand enhanceperformanceforanti-noise when identify the unknown coefficients of a sparse system. A variable step-size l1-LMS algorithm is proposed. In this paper, using current error and correlation value of errorto adjust step-size and zero-attracting part. Moreover, when the current error satisfies different conditions, the two step-size formulas will switch dynamically. Some l1-LMS algorithms availableadapted fixed step-size. However, fixed step-size cannot balance the contradictions convergence rate and the steady-state mean square error (MSE), efficiently. In addition, how to improve performance for noise resistance may be still a problem even with correlated inputs. All are the problem needs to be studied urgently. In order to solve theabovedifficulties, an improvedvariable step-size l1-LMS algorithm is proposed. Performances of the proposed l1-LMS algorithm are analyzed. After theoretical analysis, the algorithm, experiments with different signal-to-noiseratio (SNR) are given to show the efficiency of the proposed l1-LMS algorithm. The variable step-size l1-LMS algorithm can achieve faster convergence rate, and implacable anti-noise, and identify the unknown coefficients efficiently.", "references": ["Sayed AH. Indefinite Least-Squares {M}. John Wiley & Sons, Inc., 2008.", "Zhen Zhu, Xiang Gao, Leilei Cao, et al. Analysis on the adaptive filter based on LMS algorithm{J}. Optik, 2016, 127(11):4698--4704.", "Liu Y, Tang W. Enhanced incremental LMS with norm constraints for distributed in-network estimation {J}. Signal Processing, 2014, 94(1):373--385."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015198"}, {"title": "Information literacy: bridging the gap between theory and practice", "authors": ["Jamshid Beheshti\n,", "Joan C. Bartlett\n,", "Dania Bilal\n,", "Jacek Gwizdka\n,", "Thomas P. Mackey\n,", "Trudi Jacobson\n,", "Louise Limberg\n,"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nThe objective of this panel is to discuss a multi-faceted conceptual framework to link information literacy theory and practice. The panelists will present findings of their research into adult and young users' knowledge of and competencies in information literacy in varied information environments. The ultimate goal of the panel is to build consensus on a future research agenda that could lead to bridging the gap between information literacy theory and practice.", "references": ["ACRL. (2015). Framework for Information Literacy for Higher Education. Chicago: Association of College and Research Libraries. Available at: http://www.ala.org/acrl/sites/ala.org.acrl/files/content/issues/infolit/Framework_ILHE.pdf", "Bawden, D. (2014). Being fluent and keeping looking. In Kurbanoglu, S. et al. (Eds), Information Literacy: Lifelong Learning and Digital Citizenship in the 21st Century, CCIS, No. 492. Heidelberg, Springer-Verlag, 13--18.", "Chen, X., Sin, S. C. J., Theng, Y. L., & Lee, C. S. (2015). Why Students Share Misinformation on Social Media: Motivation, Gender, and Study-level Differences. The Journal of Academic Librarianship, 41(5), 583--592."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017466"}, {"title": "A Topical Approach to Retrievability Bias Estimation", "authors": ["Colin Wilkie\n,", "Leif Azzopardi"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nRetrievability is an independent evaluation measure that offers insights to an aspect of retrieval systems that performance and efficiency measures do not. Retrievability is often used to calculate the retrievability bias, an indication of how accessible a system makes all the documents in a collection. Generally, computing the retrievability bias of a system requires a colossal number of queries to be issued for the system to gain an accurate estimate of the bias. However, it is often the case that the accuracy of the estimate is not of importance, but the relationship between the estimate of bias and performance when tuning a systems parameters. As such, reaching a stable estimation of bias for the system is more important than getting very accurate retrievability scores for individual documents. This work explores the idea of using topical subsets of the collection for query generation and bias estimation to form a local estimate of bias which correlates with the global estimate of retrievability bias. By using topical subsets, it would be possible to reduce the volume of queries required to reach an accurate estimate of retrievability bias, reducing the time and resources required to perform a retrievability analysis. Findings suggest that this is a viable approach to estimating retrievability bias and that the number of queries required can be reduced to less than a quarter of what was previously thought necessary.", "references": ["Azzopardi, L., Bache, R.: On the relationship between effectiveness and accessibility. In: Proc. of the 33rd ACM SIGIR. pp. 889--890 (2010)", "Azzopardi, L., Vinay, V.: Retrievability: An evaluation measure for higher order information access tasks. In: Proc. of the 17th ACM CIKM. pp. 561--570 (2008)", "Bache, R.: Measuring and improving access to the corpus. In: Current Challenges in Patent Information Retrieval, The Information Retrieval Series, vol. 29, pp. 147--165 (2011)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970437"}, {"title": "XKnowSearch!: Exploiting Knowledge Bases for Entity-based Cross-lingual Information Retrieval", "authors": ["Lei Zhang\n,", "Michael Färber\n,", "Achim Rettinger"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn recent years, the amount of entities in large knowledge bases available on the Web has been increasing rapidly, making it possible to propose new ways of intelligent information access. Within the context of globalization, there is a clear need for techniques and systems that can enable multilingual and cross-lingual information access. In this paper, we present XKnowSearch!, a novel entity-based system for multilingual and cross-lingual information retrieval, which supports keyword search and also allows users to influence the search process according to their search intents. By leveraging the multilingual knowledge base on the Web, keyword queries and documents can be represented in their semantic forms, which can facilitate query disambiguation and expansion, and can also overcome the language barrier between queries and documents in different languages.", "references": ["C. Bizer, T. Heath, and T. Berners-Lee. Linked Data - The Story So Far. Int. J. Semantic Web Inf. Syst., 5(3):1--22, 2009.", "M. F\\\"arber, L. Zhang, and A. Rettinger. Kuphi - an investigation tool for searching for and via semantic relations. In ESWC, pages 349--354, 2014.", "J. Hoffart, D. Milchevski, and G. Weikum. STICS: searching with strings, things, and cats. In SIGIR, pages 1247--1248, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983324"}, {"title": "Digital democracy: an analysis of resources and acceptance", "authors": ["Barbara P. Caetano\n,", "Guilherme W. Oliveira\n,", "Melise M.V. Paula\n,", "Jano M. Souza"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nTechnological advances have influenced the relationship between government and citizen. In this scenario, the Digital Democracy theme that encourages the state to adopt strategies that enable the performance of the citizen not as a client of the information provided, but as a catalyst for democracy, arises. Parallel to this, changes can be observed with regard to the understanding of citizenship. However, digital democracy is a phenomenon that requires clarification both in relation to the various resources available as in the acceptance of these new possibilities for social participation. In this article, an exploratory study that sought to understand this phenomenon will be described. The study was conducted from three lines of action: literature review, analysis of resources available and survey research. In the survey, 220 people were interviewed via an online questionnaire. Research shows that there are different initiatives converge to similar degrees of digital democracy. Moreover, the survey showed a consistent level of acceptance of the use of technology in this context.", "references": ["Allan, R. 2009. New technologies, same old politics. Nature. 458, 7237 (2009), 409-410.", "Araujo, R. de P.A. et al. 2015. Democracia digital e experiencias de e-participacao: webativismo e politicas publicas. Hist. cienc. saude-Manguinhos. 22, supl (2015), 1597-1619.", "Bernardes, M.B. et al. 2015. Ranking das prefeituras da regiao Sul do Brasil: uma avaliacao a partir de criterios estabelecidos na Lei de Acesso a Informacao. Revista de Administracao Publica. 49, 3 (2015), 761-792"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021978"}, {"title": "Overview of the Special Issue on Trust and Veracity of Information in Social Media", "authors": ["Symeon Papadopoulos\n,", "Kalina Bontcheva\n,", "Eva Jaho\n,", "Mihai Lupu\n,", "Carlos Castillo"], "publication": "ACM Transactions on Information Systems", "abstract": "", "references": ["Janna Anderson and Lee Rainie. 2012. The future of big data. Retrieved December 17, 2015 from http://www.pewinternet.org/2012/07/20/the-future-of-big-data/.", "Alessandro Bessi, Mauro Coletto, George A. Davidescu, Antonio Scala, Guido Caldarelli, and Walter Quattrociocchi. 2015. Science vs conspiracy: Collective narratives in the age of misinformation. PLOS ONE 10, 2 (23 Feb. 2015), e0118093+. DOI:http://dx.doi.org/10.1371/journal.pone.0118093", "Christina Boididou, Katerina Andreadou, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia Boato, Michael Riegler, and Yiannis Kompatsiaris. 2015. Verifying multimedia use at MediaEval 2015. In Working Notes Proceedings of the MediaEval 2015 Workshop."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2870630"}, {"title": "Beyond Relevance: Adapting Exploration/Exploitation in Information Retrieval", "authors": ["Kumaripaba Athukorala\n,", "Alan Medlar\n,", "Antti Oulasvirta\n,", "Giulio Jacucci\n,", "Dorota Glowacka"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nWe present a novel adaptation technique for search engines to better support information-seeking activities that include both lookup and exploratory tasks. Building on previous findings, we describe (1) a classifier that recognizes task type (lookup vs. exploratory) as a user is searching and (2) a reinforcement learning based search engine that adapts accordingly the balance of exploration/exploitation in ranking the documents. This allows supporting both task types surreptitiously without changing the familiar list-based interface. Search results include more diverse results when users are exploring and more precise results for lookup tasks. Users found more useful results in exploratory tasks when compared to a base-line system, which is specifically tuned for lookup tasks.", "references": ["Adä, I., and Berthold, M. R. Eve: a framework for event detection. Evolving systems 4, 1 (2013), 61--70.", "Athukorala, K., Glowacka, D., Oulasvirta, A., Vreeken, J., and Jacucci, G. Is exploratory search different? a comparison of information search behavior for exploratory and lookup tasks. JASIST (2015).", "Athukorala, K., Hoggan, E., Lehtiö, A., Ruotsalo, T., and Jacucci, G. Information-seeking behaviors of computer scientists: Challenges for electronic literature search tools. In ASIST (2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856786"}, {"title": "Wavelet-Based Multi-Exposure Image Fusion", "authors": ["Wenlong Zhang\n,", "Xiaolin Liu\n,", "Wuchao Wang"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThis paper proposes a novel wavelet-based algorithm for the fusion of multi-exposed images. The luminance inversion is suppressed by introducing the brightness of input images into the well-exposedness weight. The weight is used to fuse the approximate sub-bands of the input images in the wavelet domain. At the same time, the detail sub-bands of the input images are fused by the adjusted contrast weight to avoid losing details around the strong edges. Besides, a novel enhancement function was proposed to enhance the contrast of the fused image. The experiments illustrate that the proposed method is able to effectively preserve details, enhance contrast, and maintain consistency with the luminance distribution of the input images.", "references": ["A. A. Goshtasby, \"Fusion of multi-exposure images,\" Image & Vision Computing, 23(6), 611--618 (2005).", "S. Li and X. Kang, \"Fast multi-exposure image fusion with median filter and recursive filter,\" IEEE Trans. Consumer Electron, 58(2), 626--632 (2012).", "S. Raman and S. Chaudhuri, \"Bilateral filter based compositing for variable exposure photography,\" in Proc. Eurographics, pp. 1--4 (2009)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015199"}, {"title": "Embedding-based Query Language Models", "authors": ["Hamed Zamani\n,", "W. Bruce Croft"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nWord embeddings, which are low-dimensional vector representations of vocabulary terms that capture the semantic similarity between them, have recently been shown to achieve impressive performance in many natural language processing tasks. The use of word embeddings in information retrieval, however, has only begun to be studied. In this paper, we explore the use of word embeddings to enhance the accuracy of query language models in the ad-hoc retrieval task. To this end, we propose to use word embeddings to incorporate and weight terms that do not occur in the query, but are semantically related to the query terms. We describe two embedding-based query expansion models with different assumptions. Since pseudo-relevance feedback methods that use the top retrieved documents to update the original query model are well-known to be effective, we also develop an embedding-based relevance model, an extension of the effective and robust relevance model approach. In these models, we transform the similarity values obtained by the widely-used cosine similarity with a sigmoid function to have more discriminative semantic similarity values. We evaluate our proposed methods using three TREC newswire and web collections. The experimental results demonstrate that the embedding-based methods significantly outperform competitive baselines in most cases. The embedding-based methods are also shown to be more robust than the baselines.", "references": ["N. Abdul-jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, D. Metzler, M. D. Smucker, T. Strohman, H. Turtle, and C. Wade. UMass at TREC 2004: Novelty and HARD. In TREC '04, 2004.", "M. ALMasri, C. Berrut, and J.-P. Chevallet. A Comparison of Deep Learning Based Query Expansion with Pseudo-Relevance Feedback and Mutual Information. In ECIR '16, pages 709--715, 2016.", "J. Bai, J.-Y. Nie, G. Cao, and H. Bouchard. Using Query Contexts in Information Retrieval. In SIGIR '07, pages 15--22, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970405"}, {"title": "Load-Balancing in Distributed Selective Search", "authors": ["Yubin Kim\n,", "Jamie Callan\n,", "J. Shane Culpepper\n,", "Alistair Moffat"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSimulation and analysis have shown that selective search can reduce the cost of large-scale distributed information retrieval. By partitioning the collection into small topical shards, and then using a resource ranking algorithm to choose a subset of shards to search for each query, fewer postings are evaluated. Here we extend the study of selective search using a fine-grained simulation investigating: selective search efficiency in a parallel query processing environment; the difference in efficiency when term-based and sample-based resource selection algorithms are used; and the effect of two policies for assigning index shards to machines. Results obtained for two large datasets and four large query logs confirm that selective search is significantly more efficient than conventional distributed search. In particular, we show that selective search is capable of both higher throughput and lower latency in a parallel environment than is exhaustive search.", "references": ["R. Aly, D. Hiemstra, and T. Demeester. Taily: Shard Selection Using the Tail of Score Distributions. In Proc. SIGIR, pages 673--682, 2013.", "F. Cacheda, V. Carneiro, V. Plachouras, and I. Ounis. Performance analysis of distributed information retrieval architectures using an improved network simulation model. Inf. Proc. Man., 43: 204--224, 2007.", "Y. Kim, J. Callan, J. S. Culpepper, and A. Moffat. Does selective search benefit from WAND optimization? In Proc. ECIR, 2016. To appear."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914689"}, {"title": "Robust and Collective Entity Disambiguation through Semantic Embeddings", "authors": ["Stefan Zwicklbauer\n,", "Christin Seifert\n,", "Michael Granitzer"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nEntity disambiguation is the task of mapping ambiguous terms in natural-language text to its entities in a knowledge base. It finds its application in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question & Answering. We propose a new collective, graph-based disambiguation algorithm utilizing semantic entity and document embeddings for robust entity disambiguation. Robust thereby refers to the property of achieving better than state-of-the-art results over a wide range of very different data sets. Our approach is also able to abstain if no appropriate entity can be found for a specific surface form. Our evaluation shows, that our approach achieves significantly (>5%) better results than all other publicly available disambiguation algorithms on 7 of 9 datasets without data set specific tuning. Moreover, we discuss the influence of the quality of the knowledge base on the disambiguation accuracy and indicate that our algorithm achieves better results than non-publicly available state-of-the-art algorithms.", "references": ["A. Alhelbawy and R. J. Gaizauskas. Collective named entity disambiguation using graph ranking and clique partitioning approaches. In Proc. of the 25th Int. Conf. on Computational Linguistics, Technical Papers, pages 1544--1555, 2014.", "A. E. C. Basave, G. Rizzo, A. Varga, M. Rowe, M. Stankovic, and A.-S. Dadzie. Making sense of microposts named entity linking challenge. volume 1141 of CEUR, pages 54--60, 2014.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In 7th WWW, pages 107--117, Amsterdam, The Netherlands, 1998. Elsevier Science Publishers B. V."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911535"}, {"title": "Efficient Memory Traces with Full Pointer Information", "authors": ["Philipp Lengauer\n,", "Verena Bitto\n,", "Stefan Fitzek\n,", "Markus Weninger\n,", "Hanspeter Mössenböck"], "publication": "PPPJ '16: Proceedings of the 13th International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools", "abstract": "ABSTRACT\nTracing objects and their references is paramount for tracking down memory-related performance problems. In this paper, we present a novel approach for recording references between objects at minimal run-time overhead. Extending our memory monitoring tool AntTracks with pointer information allows for a complete reconstruction of the heap before and after garbage collections as well as for an offline analysis of all garbage collection decisions made. Additionally, we describe several trace optimization techniques, such as exploiting VM-internal information, to reduce the tracing overhead even further. We evaluate our approach by means of the DaCapo benchmark suite and a selection of memory-intensive benchmarks from the DaCapoScala benchmark suite and the SPECjvm benchmark suite.", "references": ["E. Aftandilian and S. Z. Guyer. Gc assertions: Using the garbage collector to check heap properties. In Proceedings of the 2008 ACM SIGPLAN Workshop on Memory Systems Performance and Correctness: Held in Conjunction with the Thirteenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS '08), MSPC '08, pages 36--40, New York, NY, USA, 2008.", "M. Arnold, M. Vechev, and E. Yahav. Qvm: An efficient runtime for detecting defects in deployed systems. In Proceedings of the 23rd ACM SIGPLAN Conference on Object-oriented Programming Systems Languages and Applications, OOPSLA '08, pages 143--162, New York, NY, USA, 2008.", "V. Bitto, P. Lengauer, and H. Mössenböck. Efficient rebuilding of large java heaps from event traces. In Proceedings of the Principles and Practices of Programming on The Java Platform, PPPJ 2015, Melbourne, FL, USA, September 8-11, 2015, pages 76--89, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2972206.2972220"}, {"title": "Embedded Textual Content for Document Image Classification with Convolutional Neural Networks", "authors": ["Lucia Noce\n,", "Ignazio Gallo\n,", "Alessandro Zamberletti\n,", "Alessandro Calefati"], "publication": "DocEng '16: Proceedings of the 2016 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nIn this paper we introduce a novel document image classification method based on combined visual and textual information. The proposed algorithm's pipeline is inspired to the ones of other recent state-of-the-art methods which perform document image classification using Convolutional Neural Networks. The main addition of our work is the introduction of a preprocessing step embedding additional textual information into the processed document images. To do so we combine Optical Character Recognition and Natural Language Processing algorithms to extract and manipulate relevant text concepts from document images. Such textual information is then visually embedded within each document image to improve the classification results of a Convolutional Neural Network. Our experiments prove that the overall document classification accuracy of a Convolutional Neural Network trained using these text-augmented document images is considerably higher than the one achieved by a similar model trained solely on classic document images, especially when different classes of documents share similar visual characteristics.", "references": ["E. Appiani, F. Cesarini, A. M. Colla, M. Diligenti, M. Gori, S. Marinai, and G. Soda. Automatic document classification and indexing in high-volume applications. International Journal on Document Analysis and Recognition (IJDAR), 2001.", "S. Argamon, O. Frieder, D. A. Grossman, and D. D. Lewis. Content-based document image retrieval in complex document collections. In Document Recognition and Retrieval (DRR), 2007.", "S. Baldi, S. Marinai, and G. Soda. Using tree-grammars for training set expansion in page classification. In International Conference on Document Analysis and Recognition (ICDAR), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960811.2960814"}, {"title": "Report on the 3rd International Workshop on Bibliometric-enhanced Information Retrieval (BIR 2016)", "authors": ["Philipp Mayr\n,", "Ingo Frommholz\n,", "Guillaume Cabanac"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nTo foster collaboration and knowledge transfer between the fields of bibliometrics / scientometrics / informetrics on the one hand and information retrieval on the other hand, we successfully ran a workshop series on bibliometric-enhanced information retrieval (BIR). This workshop report presents the BIR 2016 workshop, which has been co-located with ECIR for the third time this year. We motivate our workshop and outline the papers (one keynote and seven regular papers) presented at ECIR 2016 in Padua, Italy. Finally we reflect on past BIR workshops and conclude with an outlook of future direction.", "references": ["M. K. Abbasi and I. Frommholz. Exploiting Information Needs and Bibliographics for Polyrepresentative Document Clustering. In Proc. of the First Workshop on Bibliometric-enhanced Information Retrieval (BIR 2014), pages 21--28, 2014.", "M. K. Abbasi and I. Frommholz. Polyrepresentative Clustering: A Study of Simulated User Strategies and Representations. In Proc. of the 2nd Workshop on Bibliometricenhanced Information Retrieval (BIR 2015), pages 47--54, 2015.", "M. Bertin and I. Atanassova. A Study of Lexical Distribution in Citation Contexts through the IMRaD Standard. In Proc. of the First Workshop on Bibliometric-enhanced Information Retrieval (BIR 2014), pages 5--12, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964803"}, {"title": "The LExR Collection for Expertise Retrieval in Academia", "authors": ["Vitor Mangaravite\n,", "Rodrygo L.T. Santos\n,", "Isac S. Ribeiro\n,", "Marcos André Gonçalves\n,", "Alberto H.F. Laender"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nExpertise retrieval has been the subject of intense research over the past decade, particularly with the public availability of benchmark test collections for expertise retrieval in enterprises. Another domain which has seen comparatively less research on expertise retrieval is academic search. In this paper, we describe the Lattes Expertise Retrieval (LExR) test collection for research on academic expertise retrieval. LExR has been designed to provide a large-scale benchmark for two complementary expertise retrieval tasks, namely, expert profiling and expert finding. Unlike currently available test collections, which fully support only one of these tasks, LExR provides graded relevance judgments performed by expert judges separately for each task. In addition, LExR is both cross-organization and cross-area, encompassing candidate experts from all areas of knowledge working in research institutions all over Brazil. As a result, it constitutes a valuable resource for fostering new research directions on expertise retrieval in an academic setting.", "references": ["P. Bailey, N. Craswell, I. Soboroff, and A. P. de Vries. The CSIRO enterprise search test collection. SIGIR Forum, 41(2):42--45, 2007.", "K. Balog, T. Bogers, L. Azzopardi, M. de Rijke, and A. van den Bosch. Broad expertise retrieval in sparse data environments. In Proc. of SIGIR, pages 551--558, 2007.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Found. Trends Inf. Retr., 6(2-3):127--256, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914678"}, {"title": "Collaborative Denoising Auto-Encoders for Top-N Recommender Systems", "authors": ["Yao Wu\n,", "Christopher DuBois\n,", "Alice X. Zheng\n,", "Martin Ester"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nMost real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics.", "references": ["D. Agarwal and B. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 19--28, 2009.", "Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In Advances in Neural Information Processing Systems, pages 153--160, 2006.", "M. Chen, K. Q. Weinberger, F. Sha, and Y. Bengio. Marginalized denoising auto-encoders for nonlinear representations. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 1476--1484, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835837"}, {"title": "A Comprehensive Survey and Classification of Approaches for Community Question Answering", "authors": ["Ivan Srba\n,", "Maria Bielikova"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nCommunity question-answering (CQA) systems, such as Yahoo! Answers or Stack Overflow, belong to a prominent group of successful and popular Web 2.0 applications, which are used every day by millions of users to find an answer on complex, subjective, or context-dependent questions. In order to obtain answers effectively, CQA systems should optimally harness collective intelligence of the whole online community, which will be impossible without appropriate collaboration support provided by information technologies. Therefore, CQA became an interesting and promising subject of research in computer science and now we can gather the results of 10 years of research. Nevertheless, in spite of the increasing number of publications emerging each year, so far the research on CQA systems has missed a comprehensive state-of-the-art survey. We attempt to fill this gap by a review of 265 articles published between 2005 and 2014, which were selected from major conferences and journals. According to this evaluation, at first we propose a framework that defines descriptive attributes of CQA approaches. Second, we introduce a classification of all approaches with respect to problems they are aimed to solve. The classification is consequently employed in a review of a significant number of representative approaches, which are described by means of attributes from the descriptive framework. As a part of the survey, we also depict the current trends as well as highlight the areas that require further attention from the research community.", "references": ["Mark S. Ackerman and David W. McDonald. 1996. Answer Garden 2: Merging Organizational Memory with Collaborative Help. In Proc. of the 1996 ACM conference on Computer Supported Cooperative Work-CSCW’96. ACM Press, New York, NY, 97--105. DOI:http://dx.doi.org/10.1145/240080.240203", "Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S. Ackerman. 2008. Knowledge Sharing and Yahoo Answers: Everyone Knows Something. In Proceeding of the 17th International Conference on World Wide Web-WWW’08. ACM Press, New York, NY, 665--674. DOI:http://dx.doi.org/10.1145/1367497.1367587", "Eugene Agichtein, Carlos Castillo, Debora Donato, Aristides Gionis, and Gilad Mishne. 2008. Finding High-Quality Content in Social Media. In Proc. of the International Conference on Web Search and Web Data Mining-WSDM’08. ACM Press, New York, NY, 183--194. DOI:http://dx.doi.org/ 10.1145/1341531.1341557"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2934687"}, {"title": "PerSentiment: A Personalized Sentiment Classification System for Microblog Users", "authors": ["Kaisong Song\n,", "Ling Chen\n,", "Wei Gao\n,", "Shi Feng\n,", "Daling Wang\n,", "Chengqi Zhang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nMicroblogging services are playing increasingly important roles in our daily life today. It is useful for microblog users to instantly understand the sentiment of a large number of microblogs posted by their friends and make appropriate response. Despite considerable progress on microblog sentiment classification, most of the existing works ignore the influence of personal distinctions of different microblog users on the sentiments they convey, and none of them has provided real-world personalized sentiment classification systems. Considering personal distinctions in sentiment analysis is natural and necessary as different people have different language habits, personal characters, opinion bias and so on. In this demonstration, we present a live system based on Twitter called PerSentiment, an individuality-dependent sentiment classification system which makes the first attempt to analyze the personalized sentiment of recent tweets and retweets posted by the authenticated user and the users he/she follows. Our system consists of four steps, i.e., requesting tweets via Twitter API, preprocessing collected tweets for extracting features, building personalized sentiment classifier based on a novel and extensible Latent Factor Model (LFM) trained on emoticon-tagged tweets, and finally visualizing the sentiment of friends' tweets to provide a guide for better sentiment understanding.", "references": ["D. Agarwal, B.-C. Chen, and B. Pang. Personalized recommendation of user comments via factor models. In EMNLP, pages 571--582, 2011.", "K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. Collaborative personalized tweet recommendation. In SIGIR, pages 661--670, 2012.", "A. Go, R. Bhayani, and L. Huang. Twitter sentiment classification using distant supervision. In Technical Report, Stanford University, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890540"}, {"title": "Time to ship: Some Examples from the Real-World", "authors": ["Omar Alonso"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThere is new and exciting research work in analyzing and exploiting information from corpora with temporal information such as news, email, or social media. We review some of the current activities around extracting temporal information from social media and present a number of examples from real-world systems. We also outline a number of open problems and potential new research areas.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889296"}, {"title": "Towards screen readers with concurrent speech: where to go next?", "authors": ["João Guerreiro"], "publication": "ACM SIGACCESS Accessibility and Computing", "abstract": "Abstract\nBlind people rely mostly on the auditory feedback of screen readers to consume digital information. Despite the browsing strategies employed by blind users [3], how fast can information be processed remains a major problem. Sighted people use scanning as a strategy to achieve this goal, by glancing at all content expecting to identify information of interest to be subsequently analyzed with further care. In contrast, screen readers rely on a sequential auditory channel that is impairing a quicker overview of the content, when compared to the visual presentation on screen.", "references": ["Ahmed, F., Borodin, Y., Puzis, Y., & Ramakrishnan, I. V. (2012, April). Why read if you can skim: towards enabling faster screen reading. In Proceedings of the International Cross-Disciplinary Conference on Web Accessibility (p. 39). ACM.", "Alain, C., Snyder, J. S., He, Y., & Reinke, K. S. (2007). Changes in auditory cortex parallel rapid perceptual learning. Cerebral Cortex, 17(5), 1074--1084.", "Borodin, Y., Bigham, J. P., Dausch, G., & Ramakrishnan, I. V. (2010, April). More than meets the eye: a survey of screen-reader browsing strategies. In Proceedings of the 2010 International Cross Disciplinary Conference on Web Accessibility (W4A) (p. 13). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2961108.2961110"}, {"title": "Automated Verification of Phenotypes using PubMed", "authors": ["Ryan Bridges\n,", "Jette Henderson\n,", "Joyce C. Ho\n,", "Byron C. Wallace\n,", "Joydeep Ghosh"], "publication": "BCB '16: Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics", "abstract": "ABSTRACT\nIn the realm of data driven clinical research, medical concepts, or phenotypes, are used to serve as indicators for patient clusters of interest. Often, studies will use groups of algorithmically generated phenotypes (feature groups) to predict the occurrence of heart disease, diabetes, and other conditions. When these groups are algorithmically generated, the most common method of verification is manual human annotation, which can be time consuming and sometimes inconsistent. In this paper, we propose a supervision-free method of verification that uses co-occurrence in PubMed articles to determine clinical significance. We demonstrate the efficacy of the method by 1) applying it to phenotypes generated through automatic machine learning methods and 2) showing it separates randomly generated groups of phenotypes from curated groups of known, clinical phenotypes.", "references": ["M. R. Boland, Z. Shahn, D. Madigan, G. Hripcsak, and N. P. Tatonetti. Birth month affects lifetime disease risk: a phenome-wide method. Journal of the American Medical Informatics Association, page ocv046, 2015.", "R. J. Carroll, A. E. Eyler, and J. C. Denny. Naive electronic health record phenotype identification for rheumatoid arthritis. In AMIA Annu Symp Proc, volume 2011, pages 189--96, 2011.", "Y. Chen, R. J. Carroll, E. R. M. Hinz, A. Shah, A. E. Eyler, J. C. Denny, and H. Xu. Applying active learning to high-throughput phenotyping algorithms for electronic health records data. Journal of the American Medical Informatics Association, 20(e2):e253--e259, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975167.2985844"}, {"title": "Metadata Extraction from Open edX Online Courses Using Dynamic Mapping of NoSQL Queries", "authors": ["Dmitry Mouromtsev\n,", "Aleksei Romanov\n,", "Dmitry Volchek\n,", "Fedor Kozlov"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe paper describes use cases and architecture of the course extraction plugin for the Open edX platform build upon Linked Open Data. The issue of frequent repetitions of educational materials within the MOOC and relativity of recommendation tools for course developers is considered. Comprehensive review of the designed ontology and mapping, as well as evaluation using test courses are given. The last part of the paper discusses new possibilities and opportunities for the future work.", "references": ["M. d'Aquin, \"Linked data for open and distance learning,\" 2012.", "C. Bizer, T. Heath, and T. Berners-Lee, \"Linked data-the story so far,\" Semantic Services, Interoperability and Web Applications: Emerging Concepts, pp. 205--227, 2009.", "S. Dietze, H. Q. Yu, D. Giordano, E. Kaldoudi, N. Dovrolis, and D. Taibi, \"Linked education: interlinking educational resources and the web of data,\" in Proceedings of the 27th annual ACM symposium on applied computing, pp. 366--371, ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890462"}, {"title": "The Dial: Exploring Computational Strangeness", "authors": ["Kristina Andersen\n,", "Peter Knees"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThis paper describes the process of a computational idea emerging from a process of user engagement: algorithmic recommendations as artistic obstructions in creative work. Through a collaboration between HCI and Music Information Retrieval, we conducted open-ended interviews with professional makers of Electronic Dance Music. We describe how the idea emerged from this process, and consider how algorithmic recommendation systems could be re-considered as tools for artistic inspiration. We propose the concept of a \"Strangeness Dial,\" which allows the gradual adjustment of the degree of desired otherness, which is tested through the use of a non-functional prop and a series of interviews.", "references": ["Panagiotis Adamopoulos and Alexander Tuzhilin. 2014. On Unexpectedness in Recommender Systems: Or How to Better Expect the Unexpected. ACM Transactions on Intelligent Systems and Technology 5, 4, Article 54 (Dec. 2014), 32 pages. DOI: http://dx.doi.org/10.1145/2559952", "Xavier Amatriain, Pablo Castells, Arjen de Vries, Christian Posse, and Harald Steck (Eds.). 2012. Proceedings of the Workshop on Recommendation Utility Evaluation: Beyond RMSE (RUE 2012). CEUR-WS, Dublin, Ireland.", "Kristina Andersen. 2013. Making Magic Machines. In 10th European Academy of Design Conference - Crafting the Future."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892439"}, {"title": "Dynamic Heuristics: Greedy Search: A Mobile Information Retrieval Algorithm for Ambient Learning Systems", "authors": ["Simon Nyaga Mwendia\n,", "Peter Waiganjo\n,", "Robert Oboko"], "publication": "AfriCHI'16: Proceedings of the First African Conference on Human Computer Interaction", "abstract": "ABSTRACT\nResearch supervision services like providing study materials can be enhanced through mobile information retrieval algorithms. An example is semantic searching algorithms, which require the user to input one or two real world concepts. Systems that implement mobile learning approaches like ambient learning can use semantic searching algorithms to support research supervision services through mobile phones. However, there is low adoption of such approaches in some of the African universities. This has been attributed to limited technical limitations of mobile devices that include mobile phones. For instance, complex interfaces, restricted input and small screens on mobile phones make it difficult to enter search keywords when the user is in a hurry. As an attempt to address these limitations, this paper describes dynamic heuristics - greedy search algorithm that automatically generate search keywords. The algorithm can be used to allow flexible mobile information retrieval on a typical ambient learning system.", "references": ["Elif Aktolga. 2014. Integrating Non-topical Aspects into Information Retriaval.", "Nana Yaw Asabere. Benefits and Challenges of Mobile Learning Implementation: Story of Developing Nations. International Journal of Computer Applications 73, 1: 23--27.", "BCcampus and COL. 2008. Education for a Digital World, Advice, Guidelines, and Effective Practice From Around The Globe. Commonwealth of Learning, Vancouver, British Columbia Canada."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2998581.2998586"}, {"title": "Beyond Topical Relevance: Studying Understandability and Reliability in Consumer Health Search", "authors": ["Joao Palotti"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNowadays people rely on search engines to explore, understand and manage their health. A recent study from Pew Internet states that one in each three adult American Internet users have used the Internet as a diagnosis tool. Retrieving incorrect or unclear health information poses high risks as people may dismiss serious symptoms, use inappropriate treatments or escalate their health concerns about common symptomatology. A number of studies have shown that the average user experiences difficulty in understanding the content of a large portion of the results retrieved by current search engine technology. Other studies have examined how poor the quality of health information on the web can be. In the context of consumer (non-experts) health search, search engines should not only retrieve relevant information, but also promote information that is understandable by the user and that is reliable/trustable and verified. The focus of my Ph.D. is to go beyond topical relevance and study understandability and reliability as two important facets of relevance that must be incorporated into search systems to increase user satisfaction, especially in the context of consumer health search.", "references": ["M. Benigeri and P. Pluye. Shortcomings of health information on the internet. Health Prom. Inter., 2003.", "S. Fox and M. Duggan. Health online. Technical report, The Pew Internet & American Life Project, 2013.", "D. Friedman, L. Hoffman-Goetz, and J. Arocha. Readability of cancer information on the internet. J Cancer Educ, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911480"}, {"title": "Where the Event Lies: Predicting Event Occurrence in Textual Documents", "authors": ["Andrea Ceroni\n,", "Ujwal Gadiraju\n,", "Jan Matschke\n,", "Simon Wingert\n,", "Marco Fisichella"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nManually inspecting text in a document collection to assess whether an event occurs in it is a cumbersome task. Although a manual inspection can allow one to identify and discard false events, it becomes infeasible with increasing numbers of automatically detected events. In this paper, we present a system to automatize event validation, defined as the task of determining whether a given event occurs in a given document or corpus. In addition to supporting users seeking for information that corroborates a given event, event validation can also boost the precision of automatically detected event sets by discarding false events and preserving the true ones. The system allows to specify events, retrieves candidate web documents, and assesses whether events occur in them. The validation results are shown to the user, who can revise the decision of the system. The validation method relies on a supervised model to predict the occurrence of events in a non-annotated corpus. This system can also be used to build ground-truths for event corpora.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. In SIGIR, 1998.", "J. Araki and J. Callan. An annotation similarity model in passage ranking for historical fact validation. In SIGIR, 2014.", "A. Ceroni and M. Fisichella. Towards an entity-based automatic event validation. In ECIR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911452"}, {"title": "Ranking-Oriented Collaborative Filtering: A Listwise Approach", "authors": ["Shuaiqiang Wang\n,", "Shanshan Huang\n,", "Tie-Yan Liu\n,", "Jun Ma\n,", "Zhumin Chen\n,", "Jari Veijalainen"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nCollaborative filtering (CF) is one of the most effective techniques in recommender systems, which can be either rating oriented or ranking oriented. Ranking-oriented CF algorithms demonstrated significant performance gains in terms of ranking accuracy, being able to estimate a precise preference ranking of items for each user rather than the absolute ratings (as rating-oriented CF algorithms do). Conventional memory-based ranking-oriented CF can be referred to as pairwise algorithms. They represent each user as a set of preferences on each pair of items for similarity calculations and predictions. In this study, we propose ListCF, a novel listwise CF paradigm that seeks improvement in both accuracy and efficiency in comparison with pairwise CF. In ListCF, each user is represented as a probability distribution of the permutations over rated items based on the Plackett-Luce model, and the similarity between users is measured based on the Kullback--Leibler divergence between their probability distributions over the set of commonly rated items. Given a target user and the most similar users, ListCF directly predicts a total order of items for each user based on similar users’ probability distributions over permutations of the items. Besides, we also reveal insightful connections among pointwise, pairwise, and listwise CF algorithms from the perspective of the matrix representations. In addition, to make our algorithm more scalable and adaptive, we present an incremental algorithm for ListCF, which allows incrementally updating the similarities between users when certain user submits a new rating or updates an existing rating. Extensive experiments on benchmark datasets in comparison with the state-of-the-art approaches demonstrate the promise of our approach.", "references": ["John S. Breese, David Heckerman, and Carl Kadie. 1998. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence (UAI). 43--52.", "Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: From pairwise approach to listwise approach. In Proceedings of the 24th International Conference on Machine Learning (ICML). 129--136.", "Edward Challis and David Barber. 2013. Gaussian Kullback-Leibler approximate inference. J. Mach. Learn. Res. 14, 1 (2013), 2239--2286."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2960408"}, {"title": "Detection Techniques of Dead Code: Systematic Literature Review", "authors": ["Camila Bastos\n,", "Paulo Afonso Junior\n,", "Heitor Costa"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe evolution is necessary for information systems do not become inadequate. However, this evolution has been identified as critical aspect in ensuring maintainability, because of the increased amount of dead code in these systems. The identification and elimination of dead code decreases the code size and the complexity, facilitating the understanding. Techniques have been proposed in the literature for automating the detection of dead code. Thus, Systematic Literature Review was performed to find existing dead code detection techniques. As result, two main techniques were found: Accessibility Analysis and Data Flow Analysis. In addition, quantitative and qualitative analysis were performed and they are presented to help researchers on which technique to use.", "references": ["Beyer, D.; Chlipala, A. J.; Henzinger, T. A.; Jhala, R.; Majumdar, R. Generating Tests from Counterexamples. In: International Conference on Software Engineering. pp. 326- 335. 2004.", "Biolchini, J. C. A.; Mian, P. G.; Natali, A. C.; Conte, T. U.; Travassos, G. H. Scientific Research Ontology to Support Systematic Review in Software Engineering. In: Advanced Engineering Informatics. pp. 133-151. 2007.", "Boomsma, H.; Gross, H.G. Dead Code Elimination for Web Systems Written in PHP: Lessons Learned from an Industry Case. In: International Conference of Software Maintenance. pp. 511-515. 2012"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021998"}, {"title": "Examining the Coherence of the Top Ranked Tweet Topics", "authors": ["Anjie Fang\n,", "Craig Macdonald\n,", "Iadh Ounis\n,", "Philip Habel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTopic modelling approaches help scholars to examine the topics discussed in a corpus. Due to the popularity of Twitter, two distinct methods have been proposed to accommodate the brevity of tweets: the tweet pooling method and Twitter LDA. Both of these methods demonstrate a higher performance in producing more interpretable topics than the standard Latent Dirichlet Allocation (LDA) when applied on tweets. However, while various metrics have been proposed to estimate the coherence of the generated topics from tweets, the coherence of the top ranked topics, those that are most likely to be examined by users, has not been investigated. In addition, the effect of the number of generated topics K on the topic coherence scores has not been studied. In this paper, we conduct large-scale experiments using three topic modelling approaches over two Twitter datasets, and apply a state-of-the-art coherence metric to study the coherence of the top ranked topics and how K affects such coherence. Inspired by ranking metrics such as precision at n, we use coherence at n to assess the coherence of a topic model. To verify our results, we conduct a pairwise user study to obtain human preferences over topics. Our findings are threefold: we find evidence that Twitter LDA outperforms both LDA and the tweet pooling method because the top ranked topics it generates have more coherence; we demonstrate that a larger number of topics (K) helps to generate topics with more coherence; and finally, we show that coherence at n is more effective when evaluating the coherence of a topic model than the average coherence score.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "A. Fang, C. Macdonald, I. Ounis, and P. Habel. Topics in tweets: A user study of topic coherence metrics for Twitter data. In Proc. of ECIR, 2016.", "A. Fang, C. Macdonald, I. Ounis, and P. Habel. Using word embedding to evaluate the coherence of topics from Twitter data. In Proc. of SIGIR, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914731"}, {"title": "Sequential Query Expansion using Concept Graph", "authors": ["Saeid Balaneshin-kordan\n,", "Alexander Kotov"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nManually and automatically constructed concept graphs (or semantic networks), in which the nodes correspond to words or phrases and the typed edges designate semantic relationships between words and phrases, have been previously shown to be rich sources of effective latent concepts for query expansion. However, finding good expansion concepts for a given query in large and dense concept graphs is a challenging problem, since the number of candidate concepts that are related to query terms and phrases and need to be examined increases exponentially with the distance from the original query concepts. In this paper, we propose a two-stage feature-based method for sequential selection of the most effective concepts for query expansion from a concept graph. In the first stage, the proposed method weighs the concepts according to different types of computationally inexpensive features, including collection and concept graph statistics. In the second stage, a sequential concept selection algorithm utilizing more expensive features is applied to find the most effective expansion concepts at different distances from the original query concepts. Experiments on TREC datasets of different type indicate that the proposed method achieves significant improvement in retrieval accuracy over state-of-the-art methods for query expansion using concept graphs.", "references": ["R. Anand and A. Kotov. Improving difficult queries by leveraging clusters in term graph. In Proceedings of the 11th AIRS, pages 426--432, 2015.", "S. Balaneshin-kordan and A. Kotov. An empirical comparison of term association and knowledge graphs for query expansion. In Proceedings of the 38th ECIR, pages 761--767, 2016.", "S. Balaneshin-kordan and A. Kotov. Optimization method for weighting explicit and latent concepts in clinical decision support queries. In Proceedings of the 2nd ACM ICTIR, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983857"}, {"title": "Generative Feature Language Models for Mining Implicit Features from Customer Reviews", "authors": ["Shubhra Kanti Karmaker Santu\n,", "Parikshit Sondhi\n,", "ChengXiang Zhai"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nOnline customer reviews are very useful for both helping consumers make buying decisions on products or services and providing business intelligence. However, it is a challenge for people to manually digest all the opinions buried in large amounts of review data, raising the need for automatic opinion summarization and analysis. One fundamental challenge in automatic opinion summarization and analysis is to mine implicit features, i.e., recognizing the features implicitly mentioned (referred to) in a review sentence. Existing approaches require many ad hoc manual parameter tuning, and are thus hard to optimize or generalize; their evaluation has only been done with Chinese review data. In this paper, we propose a new approach based on generative feature language models that can mine the implicit features more effectively through unsupervised statistical learning. The parameters are optimized automatically using an Expectation-Maximization algorithm. We also created eight new data sets to facilitate evaluation of this task in English. Experimental results show that our proposed approach is very effective for assigning features to sentences that do not explicitly mention the features, and outperforms the existing algorithms by a large margin.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society. Series B (methodological), pages 1--38, 1977.", "A. Esuli and F. Sebastiani. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6, pages 417--422, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983729"}, {"title": "Cost-Effective Online Trending Topic Detection and Popularity Prediction in Microblogging", "authors": ["Zhongchen Miao\n,", "Kai Chen\n,", "Yi Fang\n,", "Jianhua He\n,", "Yi Zhou\n,", "Wenjun Zhang\n,", "Hongyuan Zha"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nIdentifying topic trends on microblogging services such as Twitter and estimating those topics’ future popularity have great academic and business value, especially when the operations can be done in real time. For any third party, however, capturing and processing such huge volumes of real-time data in microblogs are almost infeasible tasks, as there always exist API (Application Program Interface) request limits, monitoring and computing budgets, as well as timeliness requirements. To deal with these challenges, we propose a cost-effective system framework with algorithms that can automatically select a subset of representative users in microblogging networks in offline, under given cost constraints. Then the proposed system can online monitor and utilize only these selected users’ real-time microposts to detect the overall trending topics and predict their future popularity among the whole microblogging network. Therefore, our proposed system framework is practical for real-time usage as it avoids the high cost in capturing and processing full real-time data, while not compromising detection and prediction performance under given cost constraints. Experiments with real microblogs dataset show that by tracking only 500 users out of 0.6 million users and processing no more than 30,000 microposts daily, about 92% trending topics could be detected and predicted by the proposed system and, on average, more than 10 hours earlier than they appear in official trends lists.", "references": ["Mohamed Ahmed, Stella Spagna, Felipe Huici, and Saverio Niccolini. 2013. A peek into the future: Predicting the evolution of popularity in user generated content. In Proceedings of the 6th ACM International Conference on Web Search and Data Mining (WSDM’13). ACM, New York, NY, 607--616.", "James Allan (Ed.). 2002. Topic Detection and Tracking: Event-based Information Organization. Kluwer Academic Publishers, Norwell, MA.", "Foteini Alvanaki, Sebastian Michel, Krithi Ramamritham, and Gerhard Weikum. 2012. See what’s enBlogue: Real-time emergent topic identification in social media. In Proceedings of the 15th International Conference on Extending Database Technology (EDBT’12). ACM, New York, NY, 336--347."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001833"}, {"title": "Real-time Video Recommendation Exploration", "authors": ["Yanxiang Huang\n,", "Bin Cui\n,", "Jie Jiang\n,", "Kunqian Hong\n,", "Wenyu Zhang\n,", "Yiran Xie"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nVideo recommendation has attracted growing attention in recent years. However, conventional techniques have limitations in real-time processing, accuracy or scalability for the large-scale video data. To address the deficiencies of current recommendation systems, we introduce some new techniques to provide real-time and accurate recommendations to users in the video recommendation system of Tencent Inc.. We develop a scalable online collaborative filtering algorithm based upon matrix factorization, with an adjustable updating strategy considering implicit feedback solution of different user actions. To select high-quality candidate videos for real-time top-N recommendation generation, we utilize additional factors like video type and time factor to compute similar videos. In addition, we propose the scalable implementation of our algorithm together with some optimizations to make the recommendations more efficient and accurate, including the demographic filtering and demographic training. To demonstrate the effectiveness and efficiency of our model, we conduct comprehensive experiments by collecting real data from Tencent Video. Furthermore, our video recommendation system is in production to provide recommendation services in Tencent Video, one of the largest video sites in China, and verifies its superiority in performance.", "references": ["J. Abernethy, K. Canini, J. Langford, and A. Simma. Online collaborative filtering. University of California at Berkeley, Tech. Rep, 2007.", "R. M. Bell and Y. Koren. Scalable collaborative filtering with jointly derived neighborhood interpolation weights. In Proc of the 2007 7th IEEE ICDM Conference, pages 43--52. IEEE, 2007.", "B. Chandramouli, J. J. Levandoski, A. Eldawy, and M. F. Mokbel. Streamrec: A real-time recommender system. In Proc of the 2011 ACM SIGMOD Conference, pages 1243--1246, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2903743"}, {"title": "HEVC-compliant Tile-based Streaming of Panoramic Video for Virtual Reality Applications", "authors": ["Alireza Zare\n,", "Alireza Aminlou\n,", "Miska M. Hannuksela\n,", "Moncef Gabbouj"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nDelivering wide-angle and high-resolution spherical panoramic video content entails a high streaming bitrate. This imposes challenges when panorama clips are consumed in virtual reality (VR) head-mounted displays (HMD). The reason is that the HMDs typically require high spatial and temporal fidelity contents and strict low-latency in order to guarantee the user's sense of presence while using them. In order to alleviate the problem, we propose to store two versions of the same video content at different resolutions, each divided into multiple tiles using the High Efficiency Video Coding (HEVC) standard. According to the user's present viewport, a set of tiles is transmitted in the highest captured resolution, while the remaining parts are transmitted from the low-resolution version of the same content. In order to enable randomly choosing different combinations, the tile sets are encoded to be independently decodable. We further study the trade-off in the choice of tiling scheme and its impact on compression and streaming bitrate performances. The results indicate streaming bitrate saving from 30% to 40%, depending on the selected tiling scheme, when compared to streaming the entire video content.", "references": ["Bjøntegard, G. 2001. Calculation of average psnr differences between rd-curves, document VCEG-M33. Austin.", "Feldmann, C., Bulla, C., and Cellarius, B. 2013. Efficient stream-reassembling for video conferencing applications using tiles in HEVC. In MMEDIA 2013, The Fifth International Conferences on Advances in Multimedia, Venice, Italy.", "Hannuksela, M. M., Wang, Y.-K., and Gabbouj, M. 2004. Isolated regions in video coding. IEEE Trans. on Multimedia, vol. 6, p. 259--267."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967292"}, {"title": "ASNets: A Benchmark Dataset of Aligned Social Networks for Cross-Platform User Modeling", "authors": ["Xuezhi Cao\n,", "Yong Yu"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAligning heterogeneous online social networks is a highly beneficial task proposed in recent years. It targets at automatically aligning accounts from multiple networks by whether they are held by the same natural person. Aligning the networks can improve personalized services by cross-platform user modeling, and is the prerequisite for cross-network analysis. However, there is currently no public benchmark dataset available due to its recency. As performances of this task depend highly on the dataset, experiments using different private datasets are not directly comparable. Therefore, in this paper we propose ASNets, a benchmark dataset with two sets of aligned social networks. With this dataset, we can now properly evaluate different approaches and compare them fairly. The two sets of aligned networks have 328,224 and 141,614 aligned users respectively, covering multilingual usage (Chinese and English) and various types of social networks including general purposed networks, review sites and microblogging sites. We describe the collecting methodology and statistics in details, and evaluate several state-of-the-art network aligning approaches. Beside introducing the dataset, we further propose several potential research directions that benefit from ASNets.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "F. Carmagnola and F. Cena. User identification for cross-system personalisation. Information Sciences, 179(1):16--32, 2009.", "X. Kong, J. Zhang, and P. S. Yu. Inferring anchor links across multiple heterogeneous social networks. In CIKM, pages 179--188. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983864"}, {"title": "Backward Chaining Ontology Reasoning Systems with Custom Rules", "authors": ["Hui Shi\n,", "Kurt Maly\n,", "Dazhi Chong\n,", "Gongjun Yan\n,", "Wu He"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn the semantic web, content is tagged with \"meaning\" or \"semantics\" to facilitate machine processing and web searching. In general, question answering systems that are built on top of reasoning and inference face a number of difficult issues. In this paper, we analyze scalability issues faced by a question answering system used by a knowledge base with science information that has been harvested from the web. Using this system, we will be able to answer questions that contain qualitative descriptors such as \"groundbreaking\", \"top researcher\", and \"tenurable at university x\". This question answering system has been built using ontologies, reasoning systems and custom based rules for the reasoning system. Furthermore, we evaluated the performance of our optimized backward chaining engine on supporting custom rules and designed the experimental environment including scalable datasets, rule sets, query sets and metrics and compared the experimental results with other in-memory ontology reasoning systems. The results show that our developed backward chaining ontology reasoning system has better scalability than in-memory reasoning systems.", "references": ["Breslin, J.G., Harth, A., Bojars, U. and Decker, S. (2005). Towards semantically-interlinked online communities. The Semantic Web: Research and Applications. Springer. pp. 500--514.", "Schaffert, S. (2006). IkeWiki: A semantic wiki for collaborative knowledge management. Enabling Technologies: Infrastructure for Collaborative Enterprises, (2006). WETICE'06. 15th IEEE International Workshops on, IEEE.", "Sure, Y. et al. (2002). OntoEdit: Collaborative ontology development for the semantic web: Springer."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890521"}, {"title": "PeARS: a Peer-to-peer Agent for Reciprocated Search", "authors": ["Aurelie Herbelot"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThis paper presents PeARS (Peer-to-peer Agent for Reciprocated Search), an algorithm for distributed Web search that emulates the offline behaviour of a human with an information need. Specifically, the algorithm models the process of 'calling a friend', i.e. directing one's query to the knowledge holder most likely to answer it. The system allows network users to index and share part of their browsing history in a way that makes them 'experts' on some topics. A layer of distributional semantics agents then performs targeted information retrieval in response to user queries, in a fully automated fashion.", "references": ["Marco Baroni, Georgiana Dinu, and Germán Kruszewski. Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of ACL, pages 238--247, 2014.", "Katrin Erk. Vector space models of word meaning and phrase meaning: A survey. Language and Linguistics Compass, 6(10):635--653, 2012.", "Yi Yang, Wen-tau Yih, and Christopher Meek. WIKIQA: A Challenge Dataset for Open-Domain Question Answering. In Proceedings of EMNLP, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889369"}, {"title": "Appearance-Based Retrieval of Mathematical Notation in Documents and Lecture Videos", "authors": ["Kenny Davila"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLarge data collections containing millions of math formulae in different formats are available on-line. Retrieving math expressions from these collections is challenging. Based on the notion that visually similar formulas are related, we propose a framework for appearance-based formula retrieval in two different modalities: symbolic for text documents and image-Based for videos.\nWe believe that we can achieve high quality formula retrieval results using the visual appearance of math notation without complex formula semantic analysis.\nWe represent mathematical notation using different graph types to take advantage of the information available on each domain. For symbolic formula retrieval, math expressions in text formats like LaTeX are parsed to generate Symbol Layout Trees. For image-based formula retrieval, image processing techniques are used to create a graph-based image content representation.\nWe store these graphs using an inverted index of pairs of primitives defined by the triplet (p, q, r), where p and q are the labels of two primitives connected in the graph by the path r.\nRetrieval is a two-stage process: candidate selection and reranking. The first stage uses pairs of primitives from the query graph to find matches in the inverted index. Each match is given an initial score using the Dice coefficient of matched pairs of primitives.\nThe best top-K candidates from the first stage are selected for re-ranking using a detailed similarity metric. Two steps are performed for each candidate: matching and scoring. The matching step is done by searching for the largest common substructure between query and candidate graphs. Matching is related to the problem of finding the maximum common subgraph isomorphism (MCS) between two graphs. In addition, we consider label unification for symbolic formula retrieval, and our wildcard query nodes can match entire subgraphs. In the scoring step, multiple similarity criteria define a score vector used to sort candidates, either by lexicographic order or by a function of these scores.\nDifferent datasets and benchmarks will be required to evaluate each modality. For symbolic formula retrieval, we will use the most recent versions of the NTCIR MathIR Tasks benchmarks. To the best of our knowledge, there are no benchmarks for large scale image-based formula retrieval. However, the same collections used for symbolic formula retrieval could be adapted by rendering math expressions to images. In addition, we will use datasets of math lecture videos for image-based formula retrieval.\nTraditional graded-scales of relevance used for evaluation of retrieval systems have been shown to have inconsistency issues. We plan to use pairwise candidate comparisons during our evaluation phase. Some aggregation methods exist that generate relevance scores and ideal rankings using these pairwise candidate comparisons.\nThe proposed framework can be adapted to work for other domains like chemistry or technical diagrams where visually similar elements are usually related.", "references": ["A. Aizawa, M. Kohlhase, I. Ounis, and M. Schubotz. NTCIR-11 Math-2 task overview. In Proceedings of NTCIR-11 Math-2 task Workshop Meeting {1}, 2014.", "K. Radinsky and N. Ailon. Ranking from pairs and triplets: Information quality, evaluation methods and query complexity. In WSDM, pages 105--114, New York, NY, USA, 2011. ACM.", "M. N. Volkovs and R. S. Zemel. New learning methods for supervised and unsupervised preference aggregation. JMLR, 15(1):1135--1176, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911477"}, {"title": "Exploring databases via reverse engineering ranking queries with PALEO", "authors": ["Kiril Panev\n,", "Sebastian Michel\n,", "Evica Milchevski\n,", "Koninika Pal"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nA novel approach to explore databases using ranked lists is demonstrated. Working with ranked lists, capturing the relative performance of entities, is a very intuitive and widely applicable concept. Users can post lists of entities for which explanatory SQL queries and full result lists are returned. By refining the input, the results, or the queries, user can interactively explore the database content. The demonstrated system is centered around our PALEO framework for reverse engineering OLAP-style database queries and novel work on mining interesting categorical attributes.", "references": ["Database Basketball portal. http://www.databasebasketball.com/", "DBLP computer science bibliography. http://dblp.uni-trier.de/", "R. Fagin, R. Kumar, and D. Sivakumar. Comparing top k lists. SIAM J. Discrete Math., 17(1), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007300"}, {"title": "Fast Ranking with Additive Ensembles of Oblivious and Non-Oblivious Regression Trees", "authors": ["Domenico Dato\n,", "Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Raffaele Perego\n,", "Nicola Tonellotto\n,", "Rossano Venturini"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nLearning-to-Rank models based on additive ensembles of regression trees have been proven to be very effective for scoring query results returned by large-scale Web search engines. Unfortunately, the computational cost of scoring thousands of candidate documents by traversing large ensembles of trees is high. Thus, several works have investigated solutions aimed at improving the efficiency of document scoring by exploiting advanced features of modern CPUs and memory hierarchies. In this article, we present QuickScorer, a new algorithm that adopts a novel cache-efficient representation of a given tree ensemble, performs an interleaved traversal by means of fast bitwise operations, and supports ensembles of oblivious trees. An extensive and detailed test assessment is conducted on two standard Learning-to-Rank datasets and on a novel very large dataset we made publicly available for conducting significant efficiency tests. The experiments show unprecedented speedups over the best state-of-the-art baselines ranging from 1.9 × to 6.6 × . The analysis of low-level profiling traces shows that QuickScorer efficiency is due to its cache-aware approach in terms of both data layout and access patterns and to a control flow that entails very low branch mis-prediction rates.", "references": ["Nima Asadi, Jimmy Lin, and Arjen P. de Vries. 2014. Runtime optimizations for tree-based machine learning models. IEEE Trans. Knowl. Data Eng. 26, 9 (2014), 2281--2292.", "Nima Asadi and Jimmy J. Lin. 2013. Training efficient tree-based models for document ranking. In Proceedings of the 35th European Conference on Information Retrieval (ECIR). Springer, 146--157.", "Christopher J. C. Burges. 2010. From RankNet to LambdaRank to LambdaMART: An Overview. Technical Report MSR-TR-2010-82."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987380"}, {"title": "The Effects of Aggregated Search Coherence on Search Behavior", "authors": ["Jaime Arguello\n,", "Rob Capra"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nAggregated search is the task of combining results from multiple independent search systems in a single Search Engine Results Page (SERP). Aggregated search coherence refers to the extent to which different sources on the SERP focus on similar senses of an ambiguous or underspecified query. In previous studies, we found that the query senses in a set of vertical results can influence user engagement with the web results (the so-called “spillover” effect). In this work, we investigate five research questions (RQ1--RQ5) that extend our prior work. First, we investigate the extent to which results from different sources focus on different senses of an ambiguous query (RQ1). Second, we investigate how the vertical-to-web spillover effect varies across different verticals (RQ2). Then, we examine whether the level of spillover depends on the vertical position (RQ3) and on whether the vertical results are displayed with a border and different-colored background to distinguish them from the web results (RQ4). Finally, we propose a new method for displaying results from a particular vertical that are more consistent with the query senses in the web results (RQ5). We evaluate this new method based on how it influences users to make more correct decisions with respect to the web results—to engage with the web results when at least one of them is relevant and to avoid engaging with the web results otherwise. Our results show the following trends. In terms of RQ1, our analysis suggests that the top results from the web search engine are more diversified than the top results from our four different verticals considered (images, news, shopping, and video). In terms of RQ2, we found a stronger spillover effect for the images vertical than the news, shopping, and video verticals. In terms of RQ3, we found a stronger level of spillover when the vertical was positioned at the top of the SERP versus to the right side of the web results. In terms of RQ4, we found an interesting additive effect between the vertical’s position and displaying the vertical results enclosed in a border and with a different-colored background—the image vertical had no spillover when presented to the right side of the web results and with a border and background. Finally, in terms of RQ5, we found that our proposed vertical results selection approach can influence users to make more correct predictions about their level of engagement with the web results.", "references": ["Rakesh Agrawal, Sreenivas Gollapudi, Alan Halverson, and Samuel Ieong. 2009. Diversifying search results. In WSDM. ACM, 5--14.", "Jaime Arguello. 2015. Improving aggregated search coherence. In Advances in Information Retrieval, Allan Hanbury, Gabriella Kazai, Andreas Rauber, and Norbert Fuhr (Eds.). Lecture Notes in Computer Science, Vol. 9022. Springer International Publishing, 25--36.", "Jaime Arguello and Robert Capra. 2012. The effect of aggregated search coherence on search behavior. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM’12). ACM, New York, NY, 1293--1302."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2935747"}, {"title": "Pairwise Preferences Based Matrix Factorization and Nearest Neighbor Recommendation Techniques", "authors": ["Saikishore Kalloori\n,", "Francesco Ricci\n,", "Marko Tkalcic"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMany recommendation techniques rely on the knowledge of preferences data in the form of ratings for items. In this paper, we focus on pairwise preferences as an alternative way for acquiring user preferences and building recommendations. In our scenario, users provide pairwise preference scores for a set of item pairs, indicating how much one item in each pair is preferred to the other. We propose a matrix factorization (MF) and a nearest neighbor (NN) prediction techniques for pairwise preference scores. Our MF solution maps users and items pairs to a joint latent features vector space, while the proposed NN algorithm leverages specific user-to-user similarity functions well suited for comparing users preferences of that type. We compare our approaches to state of the art solutions and show that our solutions produce more accurate pairwise preferences and ranking predictions.", "references": ["B. Ackerman and Y. Chen. Evaluating rank accuracy based on incomplete pairwise preferences. In Proc. Workshop on UCERSTI Recsys '11, 2011.", "L. Blédaité and F. Ricci. Pairwise preferences elicitation and exploitation for conversational collaborative filtering. In Proc. Hypertext & Social Media '15, pages 231--236, 2015.", "A. Brun, A. Hamad, O. Buffet, and A. Boyer. Towards preference relations in recommender systems. In Preference Learning Workshop (ECML-PKDD '10), 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959142"}, {"title": "Performance Analysis and Optimization of Full Garbage Collection in Memory-hungry Environments", "authors": ["Yang Yu\n,", "Tianyang Lei\n,", "Weihua Zhang\n,", "Haibo Chen\n,", "Binyu Zang"], "publication": "VEE '16: Proceedings of the12th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments", "abstract": "ABSTRACT\nGarbage collection (GC), especially full GC, would non- trivially impact overall application performance, especially for those memory-hungry ones handling large data sets. This paper presents an in-depth performance analysis on the full GC performance of Parallel Scavenge (PS), a state-of-the-art and the default garbage collector in the HotSpot JVM, using traditional and big-data applications running atop JVM on CPU (e.g., Intel Xeon) and many-integrated cores (e.g., Intel Xeon i). The analysis uncovers that unnecessary memory accesses and calculations during reference updating in the compaction ase are the main causes of lengthy full GC. To this end, this paper describes an incremental query model for reference calculation, which is further embodied with three schemes (namely optimistic, sort-based and region-based) for different query patterns. Performance evaluation shows that the incremental query model leads to averagely 1.9X (up to 2.9X) in full GC and 19.3% (up to 57.2%) improvement in application throughput, as well as 31.2% reduction in pause time over the vanilla PS collector on CPU, and the numbers are 2.1X (up to 3.4X), 11.1% (up to 41.2%) and 34.9% for Xeon i accordingly.", "references": ["SPECjvm2008. https://www.spec.org/jvm2008/, 2015.", "D. Abuaiadh, Y. Ossia, E. Petrank, and U. Silbershtein. An efficient parallel heap compaction algorithm. In Proceedings of the 19th Annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, OOPSLA '04, pages 224--236, New York, NY, USA, 2004. ACM. ISBN 1--58113--831--8. 10.1145/1028976.1028995. URL http://doi.acm.org/10.1145/1028976.1028995.", "Apache. Apache gira: an iterative gra processing system built for high scalability. http://gira.apache.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2892242.2892251"}, {"title": "Manipulating Time Perception of Web Search Users", "authors": ["Cheng Luo\n,", "Fan Zhang\n,", "Xue Li\n,", "Yiqun Liu\n,", "Min Zhang\n,", "Shaoping Ma\n,", "Delin Yang"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nTime is an important factor in information retrieval studies including search evaluation, user behavior analysis and query understanding. In most of the previous works, time is usually an objective factor measured by timing devices. However, the time perceived by user seems more intuitive to describe the impact of time because search user's opinion is considered subjective. Psychological researches have reported that time perception can be affected by many physical and psychological factors. In this work, a laboratory study with 50 participants was adopted to investigate the impact of Temporal Relevance, e.g., the awareness of elapsed time, on time perception of Web search users. Experimental results show that participants in high temporal relevance environments tend to perceive significantly longer task durations than the actual ones. It shows that the perception of time can be manipulated in Web search scenario and reveals the necessity to take the factor of user perception into consideration in time-related Web search researches such as effort-based evaluation.", "references": ["I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval, pages 103--112. ACM, 2014.", "P. Bailey, A. Moffat, F. Scholer, and P. Thomas. User variability and ir system evaluation. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15, pages 625--634, New York, NY, USA, 2015. ACM.", "R. A. Block and D. Zakay. Prospective and retrospective duration judgments: A meta-analytic review. Psychonomic bulletin & review, 4(2):184--197, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854994"}, {"title": "Tutorial: Lessons Learned from Building Real-life Recommender Systems", "authors": ["Xavier Amatriain\n,", "Deepak Agarwal"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn 2006, Netflix announced a \\$1M prize competition to advance recommendation algorithms. The recommendation problem was simplified as the accuracy in predicting a user rating measured by the Root Mean Squared Error. While that formulation helped get the attention of the research community, it put the focus on the wrong approach and metric while leaving many important factors out. In this tutorial we will describe the advances in Recommender Systems in the last 10 years from an industry perspective based on the instructors' personal experience at companies like Quora, LinkedIn, Netflix, or Yahoo! We will do so in the form of different lessons learned through the years.\nSome of those lessons will describe the different components of modern recommender systems such as: personalized ranking, similarity, explanations, context-awareness, or multi-armed bandits. Others will also review the usage of novel algorithmic approaches such as Factorization Machines, Restricted Boltzmann Machines, SimRank, Deep Neural Networks, or Listwise Learning-to-rank. Others will dive into details of the importance of gathering the right data or using the correct optimization metric.\nBut, most importantly, we will give many examples of prototypical industrial-scale recommender systems with special focus on those unsolved challenges that should define the future of the recommender systems area.", "references": ["Recommender Systems in Industry: A Netflix Case Study. X Amatriain, J Basilico, Recommender Systems Handbook, 385--419", "Personalizing LinkedIn Feed. Deepak Agarwal et al.. KDD 2015", "Data Mining Methods for Recommender Systems. X Amatriain, JM Pujol, Recommender Systems Handbook, 227--262"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959194"}, {"title": "Expedition: A Time-Aware Exploratory Search System Designed for Scholars", "authors": ["Jaspreet Singh\n,", "Wolfgang Nejdl\n,", "Avishek Anand"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nArchives are an important source of study for various scholars. Digitization and the web have made archives more accessible and led to the development of several time-aware exploratory search systems. However these systems have been designed for more general users rather than scholars. Scholars have more complex information needs in comparison to general users. They also require support for corpus creation during their exploration process. In this paper we present Expedition - a time-aware exploratory search system that addresses the requirements and information needs of scholars. Expedition possesses a suite of ad-hoc and diversity based retrieval models to address complex information needs; a newspaper-style user interface to allow for larger textual previews and comparisons; entity filters to more naturally refine a result list and an interactive annotated timeline which can be used to better identify periods of importance.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of WSDM. ACM, 2009.", "O. Alonso, K. Berberich, S. Bedathur, and G. Weikum. Neat: News exploration along time. Proc. of ECIR'2010.", "O. Alonso, M. Gertz, and R. Baeza-Yates. Clustering and Exploring Search Results Using Timeline Constructions. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM '09, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911465"}, {"title": "Semantic Image Profiling for Historic Events: Linking Images to Phrases", "authors": ["Jia Chen\n,", "Qin Jin\n,", "Yifan Xiong"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nAutomatically generating image profiles for historic events is desired for history knowledge preservation and curation. However, a simple profile with groups of related images lacks explicit semantic information, such as which images correspond to which aspects of the event. In this paper, we propose to add explicit semantic information to image profiling by linking images in the profile with related phrases in the event description. We measure the relevance of an image-phrase pair via a real-valued matching score. We exploit instance-wise ranking loss function to learn the matching score and we deal with two challenges: 1) how to automatically generate labeled positive data: we leverage out-of-domain labeled datasets to generate pseudo positive in-domain labels and propose a new algorithm (WIL4PPL) to robustly learn the model from the noisy pseudo positive labels; 2) how to automatically generate negative data: we propose a negative set generation algorithm to guide the model in learning which phrases and images to distinguish. We compare our model to three baselines and conduct detailed analysis and case studies to verify the quality of learnt semantic information. The extensive experiment results show the effectiveness of our proposed algorithms which significantly outperform the baselines.", "references": ["K. Barnard, P. Duygulu, D. A. Forsyth, N. de Freitas, D. M. Blei, and M. I. Jordan. Matching words and pictures. Journal of Machine Learning Research, 3:1107--1135, 2003.", "J. Chen, Q. Jin, Y. Yu, and A. G. Hauptmann. Image profiling for history events on the fly. In Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, MM '15, Brisbane, Australia, October 26 - 30, 2015, pages 291--300, 2015.", "J. Chen, Q. Jin, W. Zhang, S. Bao, Z. Su, and Y. Yu. Tell me what happened here in history. In ACM Multimedia Conference, MM '13, Barcelona, Spain, October 21--25, 2013, pages 467--468, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964306"}, {"title": "Label Noise Reduction in Entity Typing by Heterogeneous Partial-Label Embedding", "authors": ["Xiang Ren\n,", "Wenqi He\n,", "Meng Qu\n,", "Clare R. Voss\n,", "Heng Ji\n,", "Jiawei Han"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nCurrent systems of fine-grained entity typing use distant supervision in conjunction with existing knowledge bases to assign categories (type labels) to entity mentions. However, the type labels so obtained from knowledge bases are often noisy (i.e., incorrect for the entity mention's local context). We define a new task, Label Noise Reduction in Entity Typing (LNR), to be the automatic identification of correct type labels (type-paths) for training examples, given the set of candidate type labels obtained by distant supervision with a given type hierarchy. The unknown type labels for individual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task. We propose a general framework, called PLE, to jointly embed entity mentions, text features and entity types into the same low-dimensional space where, in that space, objects whose types are semantically close have similar representations. Then we estimate the type-path for each training example in a top-down manner using the learned embeddings. We formulate a global objective for learning the embeddings from text corpora and knowledge bases, which adopts a novel margin-based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases. Our experiments on three public typing datasets demonstrate the effectiveness and robustness of PLE, with an average of 25% improvement in accuracy compared to next best method.", "references": ["A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, 2013.", "T. Cour, B. Sapp, and B. Taskar. Learning from partial labels. JMLR, 12:1501--1536, 2011.", "L. Dong, F. Wei, H. Sun, M. Zhou, and K. Xu. A hybrid neural model for type classification of entity mentions. In IJCAI, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939822"}, {"title": "PlaylistPlayer: An Interface Using Multiple Criteria to Change the Playback Order of a Music Playlist", "authors": ["Tomoyasu Nakano\n,", "Jun Kato\n,", "Masahiro Hamasaki\n,", "Masataka Goto"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nWe propose a novel interface that allows the user to interactively change the playback order of multiple songs by choosing one or more criteria. The criteria include not only the song's title and artist name but also its content automatically estimated by music/singing signal processing and artist-level social analysis. The artist-level social information is discovered from Wikipedia and DBpedia. With regard to manipulating playback order, existing interfaces typically allow the user to change it manually or automatically by choosing one of a few types of criteria. The proposed interface, on the other hand, deals with nine properties and multiple integrations of them (e.g., vocal gender and beats per minute). To realize the ordering by multiple criteria, a distance matrix is computed from the criteria vectors and is then used to estimate paths for ascending, descending, and random orders by applying principle component analysis or to estimate a path for a smooth order by solving the travelling salesman problem.", "references": ["Bishop, C. M. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.", "Bonnin, G., and Jannach, D. Automated generation of music playlists: Survey and experiments. Journal of ACM Computing Surveys (CSUR) 47, 2 (2015), 1--35.", "Chang, C.-C., and Lin, C.-J. Libsvm: A library for support vector machines. ACM TIST 2 (2011), 1--39."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856809"}, {"title": "Deep Web Query Interface Integration Based on Incremental Schema Matching and Merging", "authors": ["Chichang Jou"], "publication": "MISNC, SI, DS 2016: Proceedings of the The 3rd Multidisciplinary International Social Networks Conference on SocialInformatics 2016, Data Science 2016", "abstract": "ABSTRACT\nData hidden inside the deep web are of much higher quality than those in the surface web. Internet users need to fill in query conditions in the HTML query interface and click the submit button to obtain deep web data. Unfortunately, deep web data from one site normally is insufficient for users. Users usually need to integrate information from several deep web sites. It is time-consuming to manually perform form filling for many web sites and to collect their query results. An integrated deep web query interface could help alleviate the above web users' burdens. One of the key technologies in building such integrated query interface is schema matching and merging. Previous solutions usually perform schema matching and merging separately in a holistic approach by utilizing the statistical information of attributes of the involved schemas. That approach does not take user preference of the web sites into account. We propose new deep web query interface integration (DWQII) methodology based on incremental schema matching and merging. Our matching method is based on string similarity and synonyms of labels. Besides schema matching and merging, our system also automatically transforms query conditions from the integrated query interface into those suitable for individual web sites. Our methodology has the benefit of being able to easily supplement new deep web query interfaces into previously established integrated query interfaces. We design and implement DWQII using object oriented approach. To test DWQII, we integrate nine search interfaces in the books domain. These web sites are collected from the open directory dmoz.org, including Amazon, eBay, and other popular sites. We also conduct query experiments using our integrated query interface to verify feasibility and measure performance of the methodology.", "references": ["Bergman, M. (2001). White paper: the deep web: surfacing hidden value. Journal of Electronic Publishing, 7(1).", "Bernstein, P. A. and Melnik, S. (2006). Incremental schema matching. In Proceedings of the 32nd international conference on VLDB, pp. 1167--1170.", "Doan, A., Domingos, P., and Halevy, A. Y. (2001). Reconciling schemas of disparate data sources: A machine-learning approach. In Proceedings of the ACM SIGMOD, 30(2), pp. 509--520."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2955129.2955170"}, {"title": "VERA: A Platform for Veracity Estimation over Web Data", "authors": ["Mouhamadou Lamine Ba\n,", "Laure Berti-Equille\n,", "Kushal Shah\n,", "Hossam M. Hammady"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nSocial networks and the Web in general are characterized by multiple information sources often claiming conflicting data values. Data veracity is hard to estimate, especially when there is no prior knowledge about the sources or the claims and in time-dependent scenarios where initially very few observers can report first information. Despite the wide set of recently proposed truth discovery approaches, \"no-one-fits-all\" solution emerges for estimating the veracity of on-line information in open contexts. However, analyzing the space of conflicting information and disagreeing sources might be relevant, as well as ensembling multiple truth discovery methods. This demonstration presents VERA, a Web-based platform that supports information extraction from Web textual data and micro-texts from Twitter and estimates data veracity. Given a user query, VERA systematically extracts entities and relations from Web content, structures them as claims relevant to the query and gathers more conflicting/corroborating information. VERA combines multiple truth discovery algorithms through ensembling returns the veracity label and score of each data value and the trustworthiness scores of the sources. VERA will be demonstrated through several real-world scenarios to show its potential value for fact-checking from Web data.", "references": ["L. Berti-Equille. Data Veracity Estimation with Ensembling Truth Discovery Methods. In IEEE Big Data Workshop on Data Quality Issues in Big Data, 2015.", "L. Berti-Equille and J. Borge-Holthoefer. Veracity of Big Data: From Truth Discovery Computation Algorithms to Models of Misinformation Dynamics. Morgan & Claypool, 2015.", "S. Cohen, J. T. Hamilton, and F. Turner. Computational Journalism. CACM, 54(10):66--71, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890536"}, {"title": "Going Beyond Relevance: Incorporating Effort in Information Retrieval", "authors": ["Manisha Verma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPrimary focus of Information retrieval (IR) systems has been to optimizefor Relevance. Existing approaches used to rank documents or evaluate IR systems do not account for \"user effort\". At present, relevance captures topical overlap between document and user query. This mechanism does not take into consideration either time or effort of end user to satisfy information need. While a judge may spend time assessing a document, an end user may not thoroughly examine a document. We identified factors that are associated with effort for a single document and gathered judgments for same. We also investigated the role of several features in predicting effort on webpage. In future, we shall investigate role of effort on mobile and investigate effort based evaluation methodology that also takes into account user's search task.", "references": ["M. Sanderson, M. L. Paramita, P. Clough, and E. Kanoulas. Do user preferences and evaluation measures line up? SIGIR '10. ACM.", "M. Verma and E. Yilmaz. Characterizing relevance on mobile and desktop. ECIR '16. Springer.", "M. Verma, E. Yilmaz, and N. Craswell. On obtaining effort based judgements for information retrieval. WSDM '16. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911487"}, {"title": "Future Digital Libraries: Research and Responsibilities", "authors": ["Maria Zemankova"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIn October 1991 the National Science Foundation (NSF) sponsored a workshop to examine the role of the Information Retrieval research community in the emerging environment of Internet, high performance text processing capabilities and ever-increasing volumes of digitized documents. Ed Fox, Michael Lesk and Michael McGill drafted a White Paper, calling for a National Electronic Science, Engineering, and Technology Library. The term \"Digital Library\" was adopted and for follow-up workshops with the goal to identify research directions, leading to National Science Foundation (NSF)/Defense Advanced Research Projects Agency (DARPA)/National Aeronautics and Space Administration (NASA) Research in Digital Libraries Initiative announced in late 1993. Now, in 2016, 25 years after the first workshop, 15 years after the Joint Conference on Digital Libraries has been established, and many initiatives and developments around the world, what is the state of Digital Libraries? What items should be in digital libraries, who should their custodians, how can the items be organized to support knowledge discovery, how can the contents be safeguarded and preserved? Ebla, Syria (2500 B.C. - 2250 B.C.) constitutes the oldest organized library of tables yet discovered. What will the archaeologists discover in year 4400 about the world, politics, economies, technologies, science, climate, species, health, food, culture, art, entertainment and everyday life through the ages? The talk will examine what we can do to support innovative research and design and implementation of lasting, informative Digital Libraries that will promote global goals of knowledge discovery and international understanding and personal needs to organize and selectively share important facts, creations, and memories.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2926740"}, {"title": "Convex Optimization for 3D Parallel MRI Reconstruction", "authors": ["Kai Zhu\n,", "Cishen Zhang\n,", "Jingxin Zhang\n,", "Ifat-Al Baqee\n,", "Sulaiman A. Al Hasani"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThe 3dimensional (3D) volume imaging in magnetic resonanceimaging (MRI) enables encoding in frequency, phaseand partition directions in k-space. To increase scan speed, subsampling of multiple-coil k-space data is applied. The imagereconstruction problem from subsampled 3D k-space datais non-convex due to the coupling between image and sensitivityprofile of coils. In this paper, it is shown that the magnitudeof 3D image is constrained in a convex hull and thus canbe solved by a two-step convex optimization procedure. Comparedwith other methods, this method directly processes 3Dk-space data without using sensitivity profile of coils. Phantomand in vivo data are used to test the proposed method, resulting in improved reconstructed image with lower meansquared error.", "references": ["Wright, G. A. 1997. Magnetic resonance imaging. IEEE Signal Proc. Mag. 14(Jan. 1997), 56--66.", "Zaitsev, A M., Maclaren, J., and Herbst, M. 2015. Motion artifacts in MRI: A complex problem with many partial solutions. J. Magn. Reson. Imaging. 42 (Oct. 2015), 887--901.", "Ying, L., and Liang, Z. P. 2010. Parallel MRI using phased array coils. IEEE Signal Proc. Mag. 27 (July2010),90--98."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015181"}, {"title": "Enriching Topic Modelling with Users' Histories for Improving Tag Prediction in Q&A Systems", "authors": ["Glenn Boudaer\n,", "Johan Loeckx"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe automatic attribution of tags in Question & Answering (Q&A) systems like Stack Exchange can significantly reduce the human effort in tagging as well as improve the consistency among users. Existing approaches typically either rely on Natural Language Processing solely or employ collaborative filtering techniques. In this paper, we attempt to combine the best of both worlds by investigating whether incorporating a personal profile, consisting of a user's history or its social network can significantly improve the predictions of state-of-the-art text-based methods. Our research has found that enriching content-based text features with this personal profile allows to trade-off the precision of predictions for recall and as such improve the \"exact match\" (predicting the number of tags and the tags themselves correctly) in a multi-label setting from a baseline of 18.2% text-only to 54.3%.", "references": ["\"Ask Different\" StackExchange Forum. http://apple.stackexchange.com/, 2015.", "J. Allan, J. Carbonell, G. Doddington, J. Yamron, Y. Yang, J. A. Umass, B. A. Cmu, D. B. Cmu, A. B. Cmu, R. B. Cmu, et al. Topic detection and tracking pilot study final report. In In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, 1998.", "N. Bessis and F. Xhafa. Next Generation Data Technologies for Collective Computational Intelligence, volume 352. Springer Science & Business Media, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890566"}, {"title": "React: Facebook's Functional Turn on Writing JavaScript", "authors": ["Pete Hunt\n,", "Paul O'Shannessy\n,", "Dave Smith\n,", "Terry Coatta"], "publication": "Queue", "abstract": "Abstract\nA discussion with Pete Hunt, Paul O'Shannessy, Dave Smith and Terry Coatta", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.2994373"}, {"title": "Exploring the Use of Query Auto Completion: Search Behavior and Query Entry Profiles", "authors": ["Catherine L. Smith\n,", "Jacek Gwizdka\n,", "Henry Feild"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nQuery auto completion (QAC) is nearly ubiquitous in modern search systems, however, there are few published studies on how searchers use QAC query suggestions. This study describes the use of QAC by 29 searchers working on eight assigned search topics in a lab setting. We found that our subjects had differing propensities to use QAC, with some searchers rarely using it, while others used QACs for about half their queries. This study extends prior work by examining the use of QAC in the context of whole search sessions across multiple topics, and by comparing search behavior and visual attention for queries that used QAC and those that did not. The study concludes with an exploration of differences in QAC usage and query behavior among searchers, which reveals six possible query entry profiles.", "references": ["P. Anick and R. G. Kantamneni. A Longitudinal Study of Real-time Search Assistance Adoption. In Proc. of SIGIR'08, pages 701--702, New York, NY, 2008. ACM.", "H. A. Feild and J. Allan. Using CrowdLogger for in Situ Information Retrieval System Evaluation. In Proc. of the 2013 Workshop on Living Labs for Information Retrieval Evaluation, LivingLab '13, pages 15--18, New York, NY, 2013. ACM.", "H. A. Feild, J. Allan, and J. Glatt. CrowdLogging: Distributed, Private, and Anonymous Search Logging. In Proc. of SIGIR'11, pages 375--384, New York, NY, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854975"}, {"title": "Opinion Mining and Sentiment Analysis", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915050"}, {"title": "Technical Perspective: Taming the name game", "authors": ["David Forsyth"], "publication": "Communications of the ACM", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2885250"}, {"title": "Rethinking the Cost of Information Search Behavior", "authors": ["Yinglong Zhang\n,", "Jacek Gwizdka"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we present a cognitive-economic approach to examining the cost in information search. Unlike previous studies on economic models, we calculated the cost in information search based on participants' eye-tracking data as well as their behavioral data, such as query formulation, search task duration, SERP and web page visits. Using Principal Component Analysis (PCA), we explored a possible latent factor structure of variables representing the cost in information search. Our results indicated that the cost of information seeking could be associated with two distinct aspects of search, exploratory and validation processes.", "references": ["Smucker, M. D. and Clarke, C. L. A. 2011. Time-based calibration of effectiveness measures. In Proceedings of SIGIR'2011. ACM, New York, NY. 95--104.", "Hemmer, E. 2013. Information Seeking Stopping Behavior in Online Scenarios. Peter Lang Pub Inc.", "Speier, C. and Morris, M. G. 2003. The influence of query interface design on decision-making performance. Mis Quart, 27, 3, 397--423."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914742"}, {"title": "NTCIR Lifelog: The First Test Collection for Lifelog Research", "authors": ["Cathal Gurrin\n,", "Hideo Joho\n,", "Frank Hopfgartner\n,", "Liting Zhou\n,", "Rami Albatal"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTest collections have a long history of supporting repeatable and comparable evaluation in Information Retrieval (IR). However, thus far, no shared test collection exists for IR systems that are designed to index and retrieve multimodal lifelog data. In this paper we introduce the first test collection for personal lifelog data, which has been employed for the NTCIR12-Lifelog task. In this paper, the requirements for the test collection are motivated, the process of creating the test collection is described, along with an overview of the test collection. Finally suggestions are given for possible applications of the test collection.", "references": ["S. Chowdhury, P. J. McParlane, M. S. Ferdous, and J. Jose. \"my day in review\": Visually summarising noisy lifelog data. In ICMR'15, pages 607--610. ACM, 2015.", "A. Dean-Hall, C. L. A. Clarke, J. Kamps, P. Thomas, and E. M. Voorhees. Overview of the TREC 2014 contextual suggestion track. In TREC'14, 2014.", "M. Dodge and R. Kitchin. \"Outlines of a world coming into existence\": Pervasive computing and the ethics of forgetting. Environment and Planning B, 34(3):431--445, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914680"}, {"title": "Torii: Attribute-based Polarity Analysis with Big Datasets", "authors": ["Fernando O. Gallego"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPolarity analysis has become a key aspect of market analysis. The number of companies that are interested in the general opinion of the crowd regarding the items that they sell is increasing everyday. Attribute-based polarity analysis is a fine-grained approach that computes if the opinion about an attribute of (a component of) an item is positive, negative, or neutral. The existing techniques have a number of problems, namely: they do not take into account the conditions expressed in the opinions (e.g., when they hold and when they do not), they do not generally use any contextual information (e.g., past user opinions on the same attribute), and they are not validated on big datasets (e.g., billions of messages). In this paper, we present Torii, which is an attribute-based polarity analysis technique that takes both conditions and contextual information into account; we also present our approach to validate it on big datasets.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911479"}, {"title": "Preliminary investigation on user interaction with IBM watson analytics", "authors": ["Parisa Lak\n,", "Mefta Sadat\n,", "Carl Julien Barrelet\n,", "Martin Petitclerc\n,", "Andriy Miranskyy\n,", "Craig Statchuk\n,", "Ayse Basar Bener"], "publication": "CASCON '16: Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nIBM Watson Analytics (WA) helps a broad spectrum of users to discover patterns in their data. It is a natural language processing platform to transform data into meaningful insight. The current WA recommendation algorithms consider both the attributes of target dataset as well as the attributes of the user questions to come up with the prediction outcome. Our research is focused on exploring how users interact with the system. First, we investigated how the users make decisions in selecting recommendations. Second, we looked into the kind of questions that users ask. Our analysis shows two prominent kind of questions: (1) questions starting with interrogative words, such as \"What\" or \"How\" (2) questions entered in the form of keywords. Third, we evaluated whether the user behavior in entering questions is related to their decision in selecting recommendations. Our analysis shows the kind of questions the users asks influences the selected visualisation type, the selected relevancy type and selected position ranking. The p-value for all selection characteristics is p < 2.2e--6. This result supports the thesis that the user behavior defined by the kind of questions asked (question type feature) can be used as a user identifier of decision in selecting recommendations.", "references": ["G. Adomavicius and A. Tuzhilin. Extending recommender systems: A multidimensional approach. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-01), Workshop on Intelligent Techniques for Web Personalization (ITWP2001), Seattle, Washington, August, pages 4--6. Citeseer, 2001.", "G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender systems handbook, pages 217--253. Springer, 2011.", "R. Atterer, M. Wnuk, and A. Schmidt. Knowing the user's every move: user activity tracking for website usability evaluation and implicit interaction. In Proceedings of the 15th international conference on World Wide Web, pages 203--212. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3049877.3049900"}, {"title": "Social Question Answering: Textual, User, and Network Features for Best Answer Prediction", "authors": ["Piero Molino\n,", "Luca Maria Aiello\n,", "Pasquale Lops"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nCommunity question answering (CQA) sites use a collaborative paradigm to satisfy complex information needs. Although the task of matching questions to their best answers has been tackled for more than a decade, the social question-answering practice is a complex process. The factors influencing the accuracy of question-answer matching are many and hard to disentangle. We approach the task from an application-oriented perspective, probing the space of several dimensions relevant to this problem: features, algorithms, and topics. We gather under a learning to rank framework the most extensive feature set used in literature to date, including 225 features from five different families. We test the power of such features in predicting the best answer to a question on the largest dataset from Yahoo Answers used for this task so far (40M answers) and provide a faceted analysis of the results along different topical areas and question types. We propose a novel family of distributional semantics measures that most of the time can seamlessly replace widely used linguistic similarity features, being more than one order of magnitude faster to compute and providing greater predictive power. The best feature set reaches an improvement between 11% and 26% in P@1 compared to recent well-established state-of-the-art methods.", "references": ["Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S. Ackerman. 2008. Knowledge sharing and Yahoo Answers: Everyone knows something. In Proceedings of the 17th International Conference on World Wide Web (WWW’08). 665--674.", "Eugene Agichtein, Carlos Castillo, Debora Donato, Aristides Gionis, and Gilad Mishne. 2008. Finding high-quality content in social media. In Proceedings of the International Conference on Web Search and Data Mining (WSDM’08). ACM, New York, NY, 183--194.", "Ashton Anderson, Daniel Huttenlocher, Jon Kleinberg, and Jure Leskovec. 2012. Discovering value from community activity on focused question answering sites: A case study of stack overflow. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’12). ACM, New York, NY, 850--858. DOI:http://dx.doi.org/10.1145/2339530.2339665"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948063"}, {"title": "EARec: leveraging expertise and authority for pull-request reviewer recommendation in GitHub", "authors": ["Haochao Ying\n,", "Liang Chen\n,", "Tingting Liang\n,", "Jian Wu"], "publication": "CSI-SE '16: Proceedings of the 3rd International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nPull-Request (PR) is a primary way of code contribution from developers to improve quality of software projects in GitHub. For a popular GitHub project, tens of PR are submitted daily, while only a small number of developers, i.e core developers, have the grant to judge whether to merge these changes into the main branches or not. Due to the time-consumption of PR review and the diversity of PR aspects, it is becoming a big challenge for core developers to quickly discover the useful PR. Currently, recommending appropriate reviewers (developers) for incoming PR to quickly collect meaningful comments, is treated as an effective and crowdsourced way to help core developers to make decisions and thus accelerate project development. In this paper, we propose a reviewer recommendation approach (EARec) which simultaneously considers developer expertise and authority. Specifically, we first construct a graph of incoming PR and possible reviewers, and then take advantage of text similarity of PR and social relations of reviewers to find the appropriate reviewers. The experimental analysis on MSR Mining Challenge Dataset provides good evaluation for our approach in terms of precision and recall.", "references": ["S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. Indexing by latent semantic analysis. JAsIs, 41(6):391--407, 1990.", "G. Gousios. The ghtorrent dataset and tool suite. In Proceedings of the 10th Working Conference on Mining Software Repositories, pages 233--236, 2013.", "G. Gousios, M. Pinzger, and A. v. Deursen. An exploratory study of the pull-based software development model. In Proceedings of the 36th ACM Conference on Software Engineering, pages 345--355, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897659.2897660"}, {"title": "PISA: An Index for Aggregating Big Time Series Data", "authors": ["Xiangdong Huang\n,", "Jianmin Wang\n,", "Raymond Wong\n,", "Jinrui Zhang\n,", "Chen Wang"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAggregation operation plays an important role in time series database management. As the amount of data increases, current solutions such as summary table and MapReduce-based methods struggle to respond to such queries with low latency. Other approaches such as segment tree based methods have a poor insertion performance when the data size exceeds the available memory. This paper proposes a new segment tree based index called PISA, which has fast insertion performance and low latency for aggregation queries. PISA uses a forest to overcome the performance disadvantages of insertions in traditional segment trees. By defining two kinds of tags, namely code number and serial number, we propose an algorithm to accelerate queries by avoiding reading unnecessary data on disk. The index is stored on disk and only takes a few hundred bytes of memory for billions of data points. PISA can be easily implemented on both traditional databases and NoSQL systems, examples including MySQL and Cassandra. It handles aggregation queries within milliseconds on a commodity server for a time range that may contain tens of billions of data points.", "references": ["V. Abramova and J. Bernardino. NoSQL databases: MongoDB vs Cassandra. In C3S2E, pages 14--22. ACM, 2013.", "P. Bhatotia, M. Dischinger, R. Rodrigues, and U. A. Acar. Slider: Incremental sliding-window computations for large-scale data analysis. CITI, Universidade Nova de Lisboa, Lisbon, 2012.", "M. de Berg, O. Cheong, M. van Kreveld, and M. Overmars. More geometric data structures. Computational Geometry: Algorithms and Applications, pages 219--241, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983775"}, {"title": "Expressive Query Construction through Direct Manipulation of Nested Relational Results", "authors": ["Eirik Bakke\n,", "David R. Karger"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nDespite extensive research on visual query systems, the standard way to interact with relational databases remains to be through SQL queries and tailored form interfaces. We consider three requirements to be essential to a successful alternative: (1) query specification through direct manipulation of results, (2) the ability to view and modify any part of the current query without departing from the direct manipulation interface, and (3) SQL-like expressiveness. This paper presents the first visual query system to meet all three requirements in a single design. By directly manipulating nested relational results, and using spreadsheet idioms such as formulas and filters, the user can express a relationally complete set of query operators plus calculation, aggregation, outer joins, sorting, and nesting, while always remaining able to track and modify the state of the complete query. Our prototype gives the user an experience of responsive, incremental query building while pushing all actual query processing to the database layer. We evaluate our system with formative and controlled user studies on 28 spreadsheet users; the controlled study shows our system significantly outperforming Microsoft Access on the System Usability Scale.", "references": ["A. Abouzied, J. Hellerstein, and A. Silberschatz. DataPlay: Interactive tweaking and example-driven correction of graphical database queries. In Proceedings of the 25th annual ACM symposium on User interface software and technology (UIST '12), pages 207--218, New York, NY, USA, 2012. ACM.", "S. Achler. GBXT: A gesture-based data exploration tool for your favorite database system. In Model and Data Engineering, pages 224--237. Springer International Publishing, Cham, Switzerland, 2014.", "M. Angelaccio, T. Catarci, and G. Santucci. Query by Diagram: A fully visual query system. Journal of Visual Languages & Computing, 1(3):255--273, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2915210"}, {"title": "Time-aware Multi-Viewpoint Summarization of Multilingual Social Text Streams", "authors": ["Zhaochun Ren\n,", "Oana Inel\n,", "Lora Aroyo\n,", "Maarten de Rijke"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA viewpoint is a triple consisting of an entity, a topic related to this entity and sentiment towards this topic. In time-aware multi-viewpoint summarization one monitors viewpoints for a running topic and selects a small set of informative documents. In this paper, we focus on time-aware multi-viewpoint summarization of multilingual social text streams. Viewpoint drift, ambiguous entities and multilingual text make this a challenging task. Our approach includes three core ingredients: dynamic viewpoint modeling, cross-language viewpoint alignment, and, finally, multi-viewpoint summarization. Specifically, we propose a dynamic latent factor model to explicitly characterize a set of viewpoints through which entities, topics and sentiment labels during a time interval are derived jointly; we connect viewpoints in different languages by using an entity-based semantic similarity measure; and we employ an update viewpoint summarization strategy to generate a time-aware summary to reflect viewpoints. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed method for time-aware multi-viewpoint summarization of multilingual social text streams.", "references": ["A. Ahmed and E. P. Xing. Timeline: A dynamic hierarchical dirichlet process model for recovering birth/death and evolution of topics in text stream. In UAI, 2012.", "M. Albakour, C. Macdonald, I. Ounis, et al. On sparsity and drift for effective real-time filtering in microblogs. In CIKM. ACM, 2013.", "J. Allan. Introduction to topic detection and tracking. In Topic detection and tracking, pages 1--16. Springer, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983710"}, {"title": "Session details: Main Track - Information Systems", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255993"}, {"title": "PDF: A Probabilistic Data Fusion Framework for Retrieval and Ranking", "authors": ["Ashraf Bah Rabiou\n,", "Ben Carterette"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nData fusion has been shown to be a simple and effective way to improve retrieval results. Most existing data fusion methods combine ranked lists from different retrieval functions for a single given query. But in many real search settings, the diversity of retrieval functions required to achieve good fusion performance is not available. Researchers are typically limited to a few variants on a scoring function used by the engine of their choice, with these variants often producing similar results due to being based on the same underlying term statistics.\nThis paper presents a framework for data fusion based on combining ranked lists from different queries that users could have entered for their information need. If we can identify a set of \"possible queries\" for an information need, and estimate probability distributions concerning the probability of generating those queries, the probability of retrieving certain documents for those queries, and the probability of documents being relevant to that information need, we have the potential to dramatically improve results over a baseline system given a single user query. Our framework is based on several component models that can be mixed and matched. We present several simple estimation methods for components. In order to demonstrate effectiveness, we present experimental results on 5 different datasets covering tasks such as ad-hoc search, novelty and diversity search, and search in the presence of implicit user feedback. Our results show strong performances for our method; it is competitive with state-of-the-art methods on the same datasets, and in some cases outperforms them.", "references": ["J. Aslam and M. Montague. Models for metasearch. In Proc. SIGIR, 2001.", "A. Bah and B. Carterette. Aggregating results from multiple related queries to improve web search over sessions. In Proc. AIRS, 2014.", "B. Bartell, G. Cottrell, and R. Belew. Automatic combination of multiple ranked retrieval systems. In Proc. SIGIR, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970419"}, {"title": "Infusing Collaborative Recommenders with Distributed Representations", "authors": ["Greg Zanotti\n,", "Miller Horvath\n,", "Lucas Nunes Barbosa\n,", "Venkata Trinadh Kumar Gupta Immedisetty\n,", "Jonathan Gemmell"], "publication": "DLRS 2016: Proceedings of the 1st Workshop on Deep Learning for Recommender Systems", "abstract": "ABSTRACT\nRecommender systems assist users in navigating complex information spaces and focus their attention on the content most relevant to their needs. Often these systems rely on user activity or descriptions of the content. Social annotation systems, in which users collaboratively assign tags to items, provide another means to capture information about users and items. Each of these data sources provides unique benefits, capturing different relationships.\nIn this paper, we propose leveraging multiple sources of data: ratings data as users report their affinity toward an item, tagging data as users assign annotations to items, and item data collected from an online database. Taken together, these datasets provide the opportunity to learn rich distributed representations by exploiting recent advances in neural network architectures. We first produce representations that subjectively capture interesting relationships among the data. We then empirically evaluate the utility of the representations to predict a user's rating on an item and show that it outperforms more traditional representations. Finally, we demonstrate that traditional representations can be combined with representations trained through a neural network to achieve even better results.", "references": ["M. Balabanović and Y. Shoham. Fab: content-based, collaborative recommendation. Communications of the ACM, 40(3):66--72, 1997.", "A. B. Barragans-Martinez, E. Costa-Montenegro, J. C. Burguillo, M. Rey-Lopez, F. A. Mikic-Fonte, and A. Peleteiro. A hybrid content-based and item-based collaborative filtering approach to recommend {TV} programs enhanced with singular value decomposition. Information Sciences, 180(22):4290--4311, 2010.", "R. Burke. Hybrid recommender systems: Survey and experiments. User modeling and user-adapted interaction, 12(4):331--370, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988450.2988455"}, {"title": "Power Analysis for Interleaving Experiments by Means of Offline Evaluation", "authors": ["Hosein Azarbonyad\n,", "Evangelos Kanoulas"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nEvaluation in information retrieval takes one of two forms: collection-based offline evaluation, and in-situ online evaluation. Collections constructed by the former methodology are reusable, and hence able to test the effectiveness of any experimental algorithm, while the latter requires a different experiment for every new algorithm. Due to this a funnel approach is often being used, with experimental algorithms being compared to the baseline in an online experiment only if they outperform the baseline in an offline experiment. One of the key questions in the design of online and offline experiments concerns the number of measurements required to detect a statistically significant difference between two algorithms. Power analysis can provide an answer to this question, however, it requires an a-priori knowledge of the difference in effectiveness to be detected, and the variance in the measurements. The variance is typically estimated using historical data, but setting a detectable difference prior to the experiment can lead to suboptimal, upper-bound results. In this work we make use of the funnel approach in evaluation and test whether the difference in the effectiveness of two algorithms measured by the offline experiment can inform the required number of impression of an online interleaving experiment. Our analysis on simulated data shows that the number of impressions required are correlated with the difference in the offline experiment, but at the same time widely vary for any given difference.", "references": ["O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th International Conference on World Wide Web, WWW'09, 2009.", "O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM Trans. Inf. Syst., 30(1), 2012.", "A. Chuklin, I. Markov, and M. d. Rijke. Click models for web search. Synthesis Lectures on Information Concepts, Retrieval, and Services, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970432"}, {"title": "PULP: A System for Exploratory Search of Scientific Literature", "authors": ["Alan Medlar\n,", "Kalle Ilves\n,", "Ping Wang\n,", "Wray Buntine\n,", "Dorota Glowacka"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDespite the growing importance of exploratory search, information retrieval (IR) systems tend to focus on lookup search. Lookup searches are well served by optimising the precision and recall of search results, however, for exploratory search this may be counterproductive if users are unable to formulate an appropriate search query. We present a system called PULP that supports exploratory search for scientific literature, though the system can be easily adapted to other types of literature. PULP uses reinforcement learning (RL) to avert the user from context traps resulting from poorly chosen search queries, trading off between exploration (presenting the user with diverse topics) and exploitation (moving towards more specific topics). Where other RL-based systems suffer from the \"cold start\" problem, requiring sufficient time to adjust to a user's information needs, PULP initially presents the user with an overview of the dataset using temporal topic models. Topic models are displayed in an interactive alluvial diagram, where topics are shown as ribbons that change thickness with a given topics relative prevalence over time. Interactive, exploratory search sessions can be initiated by selecting topics as a starting point.", "references": ["K. Athukorala, D. Glowacka, A. Oulasvirta, J. Vreeken, and G. Jacucci. Is exploratory search different? a comparison of information search behavior for exploratory and lookup tasks. JASIST, 2015.", "K. Athukorala, A. Medlar, K. Ilves, and D. Glowacka. Balancing exploration and exploitation: Empirical parameterization of exploratory search systems. In CIKM, 2015.", "K. Athukorala, A. Medlar, A. Oulasvirta, G. Jacucci, and D. Glowacka. Beyond relevance: Adapting exploration/exploitation in information retrieval. In IUI. ACM, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911455"}, {"title": "Which team benefits from collaboration?: investigating collaborative information seeking using personal and social contextual signals", "authors": ["Dongho Choi\n,", "Chirag Shah\n,", "Vivek Singh"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nCollaboration often involves looking for information together to achieve a common goal, such as a collaborative search task. A general expectation in collaboration is that through working together, participants obtain better outcomes than those achieved by individual efforts. However, this is not always true and certain collaborative teams benefit more from collaboration than others. This study aims to identify the settings in which teams perform the best in exploratory search tasks. Specifically, this study considers a variety of social signals to characterize individuals (e.g. number of phone calls, number of sms messages) and identify the pairs of individuals who are likely to perform best in collaborative information seeking tasks. Based on an exploratory multi-method study (N=35) involving \"in-the-wild\" phone data collection for two weeks and one in-lab search session, we report that: (1) the difference in social activities between the collaborators' daily lives was found to be associated with collaborative information seeking performance and (2) one member of a team - one who has lower social interaction - might significantly influence the outcomes for the team. The results pave way for future study design and analysis in the area of sensor-enhanced collaborative information seeking.", "references": ["Biemer, P. P., Groves, R. M., Lyberg, L. E., Mathiowetz, N. A., and Sudman, S. (2011). Measurement errors in surveys, volume 173. John Wiley & Sons.", "Burdick, T. A. (1996). Success and Diversity in Information Seeking: Gender and the Information Search Styles Model. School Library Media Quarterly, 25(1):19--26.", "Burns, M. N., Begale, M., Duffecy, J., Gergle, D., Karr, C. J., Giangrande, E., and Mohr, D. C. (2011). Harnessing context sensing to develop a mobile intervention for depression. Journal of medical Internet research, 13(3):e55."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017599"}, {"title": "Retrieving Non-Redundant Questions to Summarize a Product Review", "authors": ["Mengwen Liu\n,", "Yi Fang\n,", "Dae Hoon Park\n,", "Xiaohua Hu\n,", "Zhengtao Yu"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nProduct reviews have become an important resource for customers before they make purchase decisions. However, the abundance of reviews makes it difficult for customers to digest them and make informed choices. In our study, we aim to help customers who want to quickly capture the main idea of a lengthy product review before they read the details. In contrast with existing work on review analysis and document summarization, we aim to retrieve a set of real-world user questions to summarize a review. In this way, users would know what questions a given review can address and they may further read the review only if they have similar questions about the product. Specifically, we design a two-stage approach which consists of question retrieval and question diversification. We first propose probabilistic retrieval models to locate candidate questions that are relevant to a review. We then design a set function to re-rank the questions with the goal of rewarding diversity in the final question set. The set function satisfies submodularity and monotonicity, which results in an efficient greedy algorithm of submodular optimization. Evaluation on product reviews from two categories shows that the proposed approach is effective for discovering meaningful questions that are representative for individual reviews.", "references": ["M. Bendersky, W. B. Croft, and D. A. Smith. Joint annotation of search queries. In ACL, pages 102--111, 2011.", "A. Berger and J. Lafferty. Information retrieval as statistical translation. In SIGIR, pages 222--229, 1999.", "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In SIGIR, pages 335--336, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911544"}, {"title": "Searching Web Data using MinHash LSH", "authors": ["BiChen Rao\n,", "Erkang Zhu"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nIn this extended abstract, we explore the use of MinHash Locality Sensitive Hashing (MinHash LSH) to address the problem of indexing and searching Web data. We discuss a statistical tuning strategy of MinHash LSH, and experimentally evaluate the accuracy and performance, compared with inverted index. In addition, we describe an on-line demo for the index with real Web data.", "references": ["Mayank Bawa, Tyson Condie, and Prasanna Ganesan. LSH Forest: Self-tuning Indexes for Similarity Search. In WWW, pages 651--660. ACM, 2005.", "A. Broder. On the Resemblance and Containment of Documents. In SEQUENCES, pages 21--. IEEE Computer Society, 1997.", "Moses Charikar. Similarity Estimation Techniques from Rounding Algorithms. In STOC, pages 380--388. ACM, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2914838"}, {"title": "Life-long learning on the inclusive web", "authors": ["Jutta Treviranus"], "publication": "W4A '16: Proceedings of the 13th Web for All Conference", "abstract": "ABSTRACT\nIf our formal education systems were to be graded on achieving the following assignment: \"to enable all students to reach their diverse, full potential, so that they can be prosperous, self-guided contributors to our global community,\" our systems of education would be flunking. The impact of this failure will exponentially worsen over time, given socio-technical trends. To achieve this crucial learning goal we need more than incremental improvement. We need disruptive innovation. Can the Web be the disruptive impetus and generative scaffolding for an education system that can achieve this goal? How can we both reform and leverage Web accessibility approaches to support this mission? These are the questions explored in this article. Complex adaptive systems, emerging decentralized systems of trust, \"small\" and \"thick\" data analytics, Internet of things sensing, open platforms, but most importantly -- connected communities, are all recruited in the thought experiment to craft a candidate response.", "references": ["Hanushek, Eric (2013). Endangering Prosperity: A Global View of the American School. Brookings Institution.", "Anya Kamenetz (September 2009). \"How Web-Savvy Edupunks Are Transforming American Higher Education\". Fast Company (139).", "Pijl, S.J., Meijer, C. J. W., & Hegarty, S. (Eds.) (1997) Inclusive Education: A Global Agenda (London: Routledge)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2899475.2899476"}, {"title": "LDM: Log Disk Mirroring with Improved Performance and Reliability for SSD-Based Disk Arrays", "authors": ["Suzhen Wu\n,", "Bo Mao\n,", "Xiaolan Chen\n,", "Hong Jiang"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nWith the explosive growth in data volume, the I/O bottleneck has become an increasingly daunting challenge for big data analytics. Economic forces, driven by the desire to introduce flash-based Solid-State Drives (SSDs) into the high-end storage market, have resulted in hybrid storage systems in the cloud. However, a single flash-based SSD cannot satisfy the performance, reliability, and capacity requirements of enterprise or HPC storage systems in the cloud. While an array of SSDs organized in a RAID structure, such as RAID5, provides the potential for high storage capacity and bandwidth, reliability and performance problems will likely result from the parity update operations. In this article, we propose a Log Disk Mirroring scheme (LDM) to improve the performance and reliability of SSD-based disk arrays. LDM is a hybrid disk array architecture that consists of several SSDs and two hard disk drives (HDDs). In an LDM array, the two HDDs are mirrored as a write buffer that temporally absorbs the small write requests. The small and random write data are written on the mirroring buffer by using the logging technique that sequentially appends new data. The small write data are merged and destaged to the SSD-based disk array during the system idle periods. Our prototype implementation of the LDM array and the performance evaluations show that the LDM array significantly outperforms the pure SSD-based disk arrays by a factor of 20.4 on average, and outperforms HPDA by a factor of 5.0 on average. The reliability analysis shows that the MTTDL of the LDM array is 2.7 times and 1.7 times better than that of pure SSD-based disk arrays and HPDA disk arrays.", "references": ["N. Agrawal, V. Prabhakaran, T. Wobber, J. Davis, M. Manasse, and R. Panigrahy. 2008. Design tradeoffs for SSD performance. In Proceedings of the 2008 USENIX Annual Technical Conference (USENIX’08). 57--70.", "M. Balakrishnan, A. Kadav, V. Prabhakaran, and D. Malkhi. 2010a. Differential RAID: Rethinking RAID for SSD reliability. In Proceedings of the 5th European Conference on Computer systems (EuroSys’10). 15--26.", "M. Balakrishnan, A. Kadav, V. Prabhakaran, and D. Malkhi. 2010b. Differential RAID: Rethinking RAID for SSD reliability. ACM Transactions on Storage 6, 2 (2010), 1--22."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2892639"}, {"title": "Evaluating Search Result Diversity using Intent Hierarchies", "authors": ["Xiaojie Wang\n,", "Zhicheng Dou\n,", "Tetsuya Sakai\n,", "Ji-Rong Wen"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch result diversification aims at returning diversified document lists to cover different user intents for ambiguous or broad queries. Existing diversity measures assume that user intents are independent or exclusive, and do not consider the relationships among the intents. In this paper, we introduce intent hierarchies to model the relationships among intents. Based on intent hierarchies, we propose several hierarchical measures that can consider the relationships among intents. We demonstrate the feasibility of hierarchical measures by using a new test collection based on TREC Web Track 2009-2013 diversity test collections. Our main experimental findings are: (1) Hierarchical measures are generally more discriminative and intuitive than existing measures using flat lists of intents; (2) When the queries have multilayer intent hierarchies, hierarchical measures are less correlated to existing measures, but can get more improvement in discriminative power; (3) Hierarchical measures are more intuitive in terms of diversity or relevance. The hierarchical measures using the whole intent hierarchies are more intuitive than only using the leaf nodes in terms of diversity and relevance.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, 2009.", "J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR, 1998.", "B. A. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. TOIS, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911497"}, {"title": "Deep Match between Geology Reports and Well Logs Using Spatial Information", "authors": ["Bin Tong\n,", "Martin Klinkigt\n,", "Makoto Iwayama\n,", "Yoshiyuki Kobayashi\n,", "Anshuman Sahu\n,", "Ravigopal Vennelakanti"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn the shale oil & gas industry, operators are looking toward big data and new analytics tools and techniques to optimize operations and reduce cost. Formation evaluation is one of the most crucial steps before the fracturing operation. To assist engineers in understanding the subsurface and in turn make optimal operations, we focus on learning semantic relations between geology reports and well logs, which are collected during down-hole drilling. The challenges are how to represent the features of the geology reports and the well logs collected at measured depths and how to effectively embed them into a common feature space. We propose both linear and nonlinear (artificial neural network) models to achieve such an embedding. Extensive validations are conducted on public well data of North Dakota in the United States. We empirically discover that both geology reports and well logs follow a neighborhood property measured by geological distance. We show that this spatial information is highly effective in both the linear and nonlinear models and our nonlinear model with the spatial information performs the best among the state-of-the-art methods.", "references": ["F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. J. Goodfellow, A. Bergeron, N. Bouchard, and Y. Bengio. Theano: New Features and Speed Improvements. In NIPS, 2012.", "E. Denton, J. Weston, M. Paluri, L. Bourdev, and R. Fergus. User Conditional Hashtag Prediction for Images. In KDD, pages 1731--1740, 2015.", "A. Gress and I. Davidson. A Flexible Framework for Projecting Heterogeneous Data. In CIKM, pages 1169--1178, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983352"}, {"title": "Content Selection and Curation for Web Archiving: The Gatekeepers vs. the Masses", "authors": ["Ian Milligan\n,", "Nick Ruest\n,", "Jimmy Lin"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nAny preservation effort must begin with an assessment of what content to preserve, and web archiving is no different. There have historically been two answers to the question \"what should we archive?\" The Internet Archive's broad entire-web crawls have been supplemented by narrower domain- or topic-specific collections gathered by numerous libraries. We can characterize this as content selection and curation by \"gatekeepers\". In contrast, we have witnessed the emergence of another approach driven by \"the masses\"---we can archive pages that are contained in social media streams such as Twitter. The interesting question, of course, is how these approaches differ. We provide an answer to this question in the context of a case study about the 2015 Canadian federal elections. Based on our analysis, we recommend a hybrid approach that combines an effort driven by social media and more traditional curatorial methods.", "references": ["S. G. Ainsworth, A. AlSum, H. SalahEldeen, M. C. Weigle, and M. L. Nelson. How much of the web is archived? arXiv:1212.6177, Dec. 2012.", "M. Duggan. The demographics of social media users, Aug. 2015.", "M. M. Farag and E. A. Fox. Building and archiving event web collections: A focused crawler approach. Bulletin of IEEE Technical Committee on Digital Libraries, 11(2), 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910913"}, {"title": "A Comparative Study On Features for Similar Image Search", "authors": ["Haihui Liu\n,", "Wan-Lei Zhao\n,", "Hanzi Wang\n,", "Kyungmo Koo\n,", "Sangwhan Moon"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nFeature representation plays a key role to the success of an image retrieval system. In this paper, a comparative study over the effectiveness of several features for content-based image search is presented. This study covers across several conventional features as well as convolutional neural networks (CNN) features, which are introduced recently into retrieval tasks. In particular, the evaluation is conducted when features are under the same encoding scheme. In addition, a hybrid feature representation that combines keypoint detector and CNN descriptor is proposed, in which the geometric invariances of keypoint feature and the distinctiveness of CNN feature are integrated. Experiments on popular evaluation benchmarks show that this hybrid feature achieves superior performance.", "references": ["A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. In ECCV, pages 584--599, Sep. 2014.", "H. Bay, T. Tuytelaars, and L. V. Gool. SURF: Speeded up robust features. Computer Vision and Image Understanding, 110(3):346--359, 2008.", "D. M. Chen, G. Baatz, and K. Koser. City-scale landmark identification on mobile devices. In CVPR, pages 737--744, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3008269"}, {"title": "Automatic Driver Monitoring Using Electrical Impedance Measurement on Steering Wheel", "authors": ["Marketa Venclikova\n,", "Radek Hrabuska\n,", "Michal Prauzek\n,", "Jiri Koziorek"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThis article deals with the analysis of dependence among the driver's bioelectrical impedance status and surrounding effects, which can negatively influence the driver's attention and thus lead to decrease the driver's safety while driving. Bioelectrical impedance was measured using AD5933 circuit and two conductive silicon electrodes placed on the steering wheel. The measurement was performed on several drivers of various age at a different daytime and in a different grade of traffic. Hereafter acquired data were statistically analyzed and significant values, which affect the measured driver's impedance with given probability were identified. Based on results of the analysis, we proposed an algorithm of software for detection the events that could possibly decrease the driver's safety. The driver's impedance data acquired from the steering wheel is used as a control variable for the detection algorithm.", "references": ["Stankus, M., Prauzek, M. Video processing design for wireless ADAS applications (2014) Canadian Conference on Electrical and Computer Engineering, art. no. 6900987,", "Zaldivar, J., Calafate, C., Cano, J., and Manzoni, P. (2011). Providing accident detection in vehicular networks through obd-ii devices and android-based smartphones. 813--819.", "Aliane, N., Fernandez, J., Bemposta, S., Mata, M., and Diez, R. (2012). Sacat: An instrumented vehicle for driver assistance and safety. 363--368."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015185"}, {"title": "Impact of Review-Set Selection on Human Assessment for Text Classification", "authors": ["Adam Roegiest\n,", "Gordon V. Cormack"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn a laboratory study, human assessors were significantly more likely to judge the same documents as relevant when they were presented for assessment within the context of documents selected using random or uncertainty sampling, as compared to relevance sampling. The effect is substantial and significant [0.54 vs. 0.42, p<0.0002] across a population of documents including both relevant and non-relevant documents, for several definitions of ground truth. This result is in accord with Smucker and Jethani's SIGIR 2010 finding that documents were more likely to be judged relevant when assessed within low-precision versus high-precision ranked lists. Our study supports the notion that relevance is malleable, and that one should take care in assuming any labeling to be ground truth, whether for training, tuning, or evaluating text classifiers.", "references": ["G. V. Cormack, C. L. A. Clarke, C. R. Palmer, and S. S. L. To. Passage-Based Refinement (MultiText Experiments for TREC-6). In Proc. TREC-6, 1997.", "G. V. Cormack and M. R. Grossman. Evaluation of Machine-learning Protocols for Technology-assisted Review in Electronic Discovery. In Proc. SIGIR 2014, 2014.", "G. V. Cormack and M. R. Grossman. Autonomy and reliability of continuous active learning for technology-assisted review. arXiv Preprint, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914709"}, {"title": "Piglet: Interactive and Platform Transparent Analytics for RDF & Dynamic Data", "authors": ["Stefan Hagedorn\n,", "Kai-Uwe Sattler"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nData analytics has gained more and more focus during recent years and many data processing platforms have been developed. They all provide a powerful but often complex API that users have to learn. Furthermore, results can only be stored or printed, without any possibility for visualization.\nIn this paper we present Piglet, a compiler for the high-level Pig Latin script language that generates code for various platforms like Spark, Flink, Storm, and PipeFabric. Piglet lets users write elegant code with extensions for SPARQL and RDF, as well as support for streaming data. An integration into the notebook-based frontend Zeppelin provides a homogeneous and interactive user interface for exploring, analyzing, and visualizing data from different sources and lets users share their scripts and results.", "references": ["A. Arasu, M. Cherniack, E. Galvez, D. Maier, A. S. Maskey, E. Ryvkina,M. Stonebraker, and R. Tibbetts. Linear road: a stream data management benchmark. In PVLDB, pages 480--491, 200", "S. Hagedorn, K. Hose, and K.-U. Sattler. SPARQling Pig - Processing Linked Data with Pig Latin. In BTW, March 2015.", "C. Olston, B. Reed, U. Srivastava, R. Kumar, and A. Tomkins. Pig latin: a not-so-foreign language for data processing. In SIGMOD, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890530"}, {"title": "A Risk Calculus Extension to the XACML Language", "authors": ["Jhonatan Alves\n,", "Carla Merkle Westphall\n,", "Gustavo Roecker Schmitt"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe increase of dynamic cloud computing environments introduces the need for new ways of access control in applications. One access control model which adapts flexibly to such systems on the Internet is the RAdAC (Risk-Adaptive Access Control). This model is based on the user confidence degree and the risk of releasing access to some information taking into account the context in which a request is performed. However, in practice, to use such model it is necessary to implement a technological support as, for example, extending the access control architecture present in the XACML (eXtensible Access Control Markup Language). This paper extends the XACML access control architecture to support the RAdAC model providing a quantitative, concrete and dynamic risk calculus in order to improve the access control in cloud environments. A prototype was developed in Amazon EC2 cloud environment to perform dynamic access control policies using the proposed XACML extension. Some risk calculus tests are described in the paper to exemplify the RAdAC decisions.", "references": ["Security for cloud computing: 10 steps to ensure success. Technical report, 2012.", "Chen Chen, Weili Han, and Jianming Yong. Specify and enforce the policies of quantified risk adaptive access control. In Weiming Shen, Ning Gu, Tun Lu, Jean-Paul A. Barthes, and Junzhou Luo, editors, CSCWD, pages 110-115. IEEE, 2010.", "Liang Chen, Luca Gasparini, and Timothy J Norman. Xacml and risk-aware access control. 2013"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022010"}, {"title": "A Supervised Learning Model for High-Dimensional and Large-Scale Data", "authors": ["Chong Peng\n,", "Jie Cheng\n,", "Qiang Cheng"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nWe introduce a new supervised learning model using a discriminative regression approach. This new model estimates a regression vector to represent the similarity between a test example and training examples while seamlessly integrating the class information in the similarity estimation. This distinguishes our model from usual regression models and locally linear embedding approaches, rendering our method suitable for supervised learning problems in high-dimensional settings. Our model is easily extensible to account for nonlinear relationship and applicable to general data, including both high- and low-dimensional data. The objective function of the model is convex, for which two optimization algorithms are provided. These two optimization approaches induce two scalable solvers that are of mathematically provable, linear time complexity. Experimental results verify the effectiveness of the proposed method on various kinds of data. For example, our method shows comparable performance on low-dimensional data and superior performance on high-dimensional data to several widely used classifiers; also, the linear solvers obtain promising performance on large-scale classification.", "references": ["Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and Cordelia Schmid. 2014. Good practice in large-scale learning for image classification. IEEE Trans. Pattern Anal. Mach. Intell. 36, 3 (2014), 507--520.", "Peter Andras. 2014. Function approximation using combined unsupervised and supervised learning. IEEE Trans. Neur. Netw. Learn. Syst. 25, 3 (2014), 495--505.", "K. Bache and M. Lichman. 2013. UCI Machine Learning Repository. (2013). Retrieved from http://archive.ics.uci.edu/ml."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2972957"}, {"title": "Investigating Multi-Thread Utilization as a Software Defence Mechanism Against Side Channel Attacks", "authors": ["Ibraheem Frieslaar\n,", "Barry Irwin"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nA state-of-the-art software countermeasure to defend against side channel attacks is investigated in this work. The implementation of this novel approach consists of using multi-threads and a task scheduler on a microcontroller to purposefully leak out information at critical points in the cryptographic algorithm and confuse the attacker. This research demonstrates it is capable of outperforming the known countermeasure of hiding and shuffling in terms of preventing the secret information from being leaked out. Furthermore, the proposed countermeasure mitigates the side channel attacks, such as correlation power analysis and template attacks.", "references": ["P. Kocher, J. Ja e, and B. Jun, differential power analysis,\" in Advances in Cryptology UCRYPTOS 99, pp. 388--397, Springer, 1999.", "P. Pessl and S. Mangard, \\Enhancing side-channel analysis of binary- eld multiplication with bit reliability,\" in Topics in Cryptology-CT-RSA 2016, pp. 255--270, Springer, 2016.", "H. Seuschek, J. Heyszl, and F. De Santis, \\A cautionary note: Side-channel leakage implications of deterministic signature schemes,\" in Proceedings of the Third Workshop on Cryptography and Security in Computing Systems, pp. 7--12, ACM, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015176"}, {"title": "SEADE Workshop Proposal - The Serendipity Factor: Evaluating the Affordances of Digital Environments", "authors": ["Lori McCay-Peet\n,", "Elaine G. Toms\n,", "Anabel Quan-Haase"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nFor two decades, research has sought to understand serendipity and how it may be facilitated in digital environments such as information visualizations systems, search systems, and social media. The motivation to support serendipity comes from its association with positive outcomes that range from personal benefits to global rewards. To date, research has made significant headway in defining and mapping the process of serendipity and new tools are emerging to support it. Creative and robust heuristics and methods of evaluation, however, are required to help move the research forward, to ensure that new or enhanced features, functions, or tools are providing affordances as intended. Without sound approaches, we are blind as to what facilitates serendipity and proposed heuristics to aid practitioners are speculative. SEADE (pronounced 'seed') is a one-day workshop that will examine how we balance the tension between diversity and novelty in designing digital environments and subsequently how we evaluate the 'serendipitousness' of those environments. Since 2006, in its earlier iterations as IIiX and HCIR, CHIIR has served as a venue for the discussion of user-centred information interaction in context. CHIIR provides an ideal venue for bringing together researchers from diverse information and computer science communities and beyond working on the problem of providing support for serendipity in digital environments.", "references": ["Tufekci, Z. 2015, May 1 Facebook said its algorithms do help form echo chambers. And the tech press missed it. The World Post. Retrieved from http://www.huffingtonpost.com/zeynep-tufekci/facebook-algorithm-echo-chambers_b_7259916.html", "Bakshy, E., Messing, S. and Adamic, L.A. 2015. Exposure to ideologically diverse news and opinion on Facebook. Science, 348(6239), 1130--1132.", "Pariser, E. 2011. The filter bubble: What the internet is hiding from you. London: Viking."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2878739"}, {"title": "Parallel Document Inversion using GPU", "authors": ["Sungbo Jung\n,", "Dar-Jen Chang\n,", "Juw Won Park"], "publication": "RACS '16: Proceedings of the International Conference on Research in Adaptive and Convergent Systems", "abstract": "ABSTRACT\nRecent advances in the technology of the Graphics Processing Unit (GPU) has led to a surge of interest in using the GPU for general purpose applications. We can utilize the GPU in computation as a massive parallel co-processor because the GPU consists of multiple cores. The GPU is also an affordable, attractive, and user-programmable commodity. Although the inverted index is a useful data structure that can be used for full text search or document retrieval, the large number of documents will require tremendous time to create the index. The performance of document inversion can be improved by multicore GPU. Our approach is to implement a linear-time, hash-based, single program multiple data (SPMD), document inversion algorithm on the NVIDIA GPU/CUDA programming platform utilizing the huge computational power of the GPU, to develop high performance solutions for document indexing.", "references": ["Ankur Narang, V.A., Monu Kedia, Vijay K. Garg, 2009. Highly scalable algorithm for distributed real-time text indexing. In High Performance Computing (HiPC) IEEE, Kochi, 332--341.", "Atallah, M.J. and Fox, S., 1998. Algorithms and Theory of Computation Handbook. CRC Press, Inc., Boca Raton, FL, USA.", "Baeza-Yates, R. and Ribeiro-Neto, B., 1999. Modern Information Retrieval. Addison Wesley."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987386.2987438"}, {"title": "Web-scale Multimedia Search for Internet Video Content", "authors": ["Lu Jiang"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe World Wide Web has been witnessing an explosion of video content. Video data are becoming one of the most valuable sources to assess insights and information. However, existing video search methods are still based on text matching (text-to-text search), and could fail for the huge volumes of videos that have little relevant metadata or no metadata at all. In this paper, we propose an accurate, efficient and scalable semantic search method for Internet videos that allows for intelligent and flexible search schemes over the video content (text-to-video search and text&video-to-video search). To achieve this ambitious goal, we propose several novel methods to improve accuracy and efficiency. The extensive experiments demonstrate that the proposed methods are able to surpass state-of-the-art accuracy and efficiency on multiple datasets. Based on the proposed methods, we implement E-Lamp Lite, the first of its kind large-scale semantic search engine for Internet videos. According to National Institute of Standards and Technology (NIST), it achieved the best accuracy in the TRECVID Multimedia Event Detection (MED) 2013, 2014 and 2015, one of the most representative task for content-based video search. To the best of our knowledge, E-Lamp Lite is the first content-based semantic search system that is capable of indexing and searching a collection of 100 million videos.", "references": ["E. Apostolidis, V. Mezaris, M. Sahuguet, B. Huet, B.vCervenková, D. Stein, S. Eickeler, J. L. Redondo Garcia, R. Troncy, and L. Pikora. Automatic fine-grained hyperlinking of videos within a closed collection using scene segmentation. In MM, 2014.", "Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, 2009.", "A. Brodersen, S. Scellato, and M. Wattenhofer. Youtube around the world: geographic popularity of videos. In WWW, 2012.", "P. Das, R. K. Srihari, and J. J. Corso. Translating related words to videos and back through latent topics. In WSDM, 2013.", "J. Davidson, B. Liebald, J. Liu, et al. The youtube video recommendation system. In RecSys, 2010.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2888599"}, {"title": "Understanding the Message of Images with Knowledge Base Traversals", "authors": ["Lydia Weiland\n,", "Ioana Hulpus\n,", "Simone Paolo Ponzetto\n,", "Laura Dietz"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThe message of news articles is often supported by the pointed use of iconic images. These images together with their captions encourage emotional involvement of the reader. Current algorithms for understanding the semantics of news articles focus on its text, often ignoring the image. On the other side, works that target the semantics of images, mostly focus on recognizing and enumerating the objects that appear in the image. In this work, we explore the problem from another perspective: Can we devise algorithms to understand the message encoded by images and their captions? To answer this question, we study how well algorithms can describe an image-caption pair in terms of Wikipedia entities, thereby casting the problem as an entity-ranking task with an image-caption pair as query. Our proposed algorithm brings together aspects of entity linking, subgraph selection, entity clustering, relatedness measures, and learning-to-rank. In our experiments, we focus on media-iconic image-caption pairs which often reflect complex subjects such as sustainable energy and endangered species. Our test collection includes a gold standard of over 300 image-caption pairs about topics at different levels of abstraction. We show that with a MAP of 0.69, the best results are obtained when aggregating content-based and graph-based features in a Wikipedia-derived knowledge base.", "references": ["K. Balog, P. Serdyukov, and A. P. d. Vries. Overview of the TREC 2010 entity track. Technical report, DTIC Document, 2010.", "V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, P10008:1--12, Oct. 2008.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In WWW, pages 107--117, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970414"}, {"title": "\"Is Sven Seven?\": A Search Intent Module for Children", "authors": ["Nevena Dragovic\n,", "Ion Madrazo Azpiazu\n,", "Maria Soledad Pera"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe Internet is the biggest data-sharing platform, comprised of an immeasurable quantity of resources covering diverse topics appealing to users of all ages. Children shape tomorrow's society, so it is essential that this audience becomes agile with searching information. Although young users prefer well-known search engines, their lack of skill in formulating adequate queries and the fact that search tools were not designed explicitly with children in mind, can result in poor outcomes. The reasons for this include children's limited vocabulary, which makes it challenging to articulate information needs using short queries, or their tendency to create queries that are too long, which translates to few or irrelevant retrieved results. To enhance web search environments in response to children's behaviors and expectations, in this paper we discuss an initial effort to verify well-known issues, and identify yet to be explored ones, that affect children in formulating (natural language or keyword) queries. We also present a novel search intent module developed in response to these issues, which can seamlessly be integrated with existing search engines favored by children. The proposed module interprets a child's query and creates a shorter and more concise query to submit to a search engine, which can lead to a more successful search session. Initial experiments conducted using a sample of children queries validate the correctness of the proposed search intent module.", "references": ["D. Bilal. Ranking, relevance judgment, and precision of information retrieval on children's queries: Evaluation of google, yahoo!, bing, yahoo! kids, and ask kids. JASIST, 63(9):1879--1896, 2012.", "D. Bilal and R. Ellis. Evaluating leading web search engines on children's queries. In Human-Computer Interaction. Users and Applications, pages 549--558. Springer, 2011.", "I. Dabasinškienž. Intimacy, familiarity and formality: Diminutives in modern lithuanian.Lituanus, 55(1), 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914738"}, {"title": "Automatic Discovery of Attribute Synonyms Using Query Logs and Table Corpora", "authors": ["Yeye He\n,", "Kaushik Chakrabarti\n,", "Tao Cheng\n,", "Tomasz Tylenda"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nAttribute synonyms are important ingredients for keyword-based search systems. For instance, web search engines recognize queries that seek the value of an entity on a specific attribute (referred to as e+a queries) and provide direct answers for them using a combination of knowledge bases, web tables and documents. However, users often refer to an attribute in their e+a query differently from how it is referred in the web table or text passage. In such cases, search engines may fail to return relevant answers. To address that problem, we propose to automatically discover all the alternate ways of referring to the attributes of a given class of entities (referred to as attribute synonyms) in order to improve search quality. The state-of-the-art approach that relies on attribute name co-occurrence in web tables suffers from low precision. Our main insight is to combine positive evidence of attribute synonymity from query click logs, with negative evidence from web table attribute name co-occurrences. We formalize the problem as an optimization problem on a graph, with the attribute names being the vertices and the positive and negative evidences from query logs and web table schemas as weighted edges. We develop a linear programming based algorithm to solve the problem that has bi-criteria approximation guarantees. Our experiments on real-life datasets show that our approach has significantly higher precision and recall compared with the state-of-the-art.", "references": ["Bing Synonyms API. https://datamarket.azure.com/dataset/bing/synonyms.", "Dictionary and Thesaurus - Merriam-Webster Online. http://www.merriam-webster.com/.", "Microsoft solver foundation. http://msdn.microsoft.com/en-us/library/ff524509.aspx."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2874816"}, {"title": "REACT: Context-Sensitive Recommendations for Data Analysis", "authors": ["Tova Milo\n,", "Amit Somech"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nData analysis may be a difficult task, especially for non-expert users, as it requires deep understanding of the investigated domain and the particular context. In this demo we present REACT, a system that hooks to the analysis UI and provides the users with personalized recommendations of analysis actions. By matching the current user session to previous sessions of analysts working with the same or other data sets, REACT is able to identify the potentially best next analysis actions in the given user context. Unlike previous work that mainly focused on individual components of the analysis work, REACT provides a holistic approach that captures a wider range of analysis action types by utilizing novel notions of similarity in terms of the individual actions, the analyzed data and the entire analysis workflow.\nWe demonstrate the functionality of REACT, as well as its effectiveness through a digital forensics scenario where users are challenged to detect cyber attacks in real life data achieved from honeypot servers.", "references": ["R. Amar, J. Eagan, and J. Stasko. Low-level components of analytic activity in information visualization. In INFOVIS. IEEE, 2005.", "N. Augsten, D. Barbosa, M. Böhlen, and T. Palpanas. Tasm: Top-k approximate subtree matching. In ICDE, 2010.", "G. Chatzopoulou, M. Eirinaki, and N. Polyzotis. Query recommendations for interactive database exploration. In SSDBM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2899392"}, {"title": "Modality-Dependent Cross-Media Retrieval", "authors": ["Yunchao Wei\n,", "Yao Zhao\n,", "Zhenfeng Zhu\n,", "Shikui Wei\n,", "Yanhui Xiao\n,", "Jiashi Feng\n,", "Shuicheng Yan"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nIn this article, we investigate the cross-media retrieval between images and text, that is, using image to search text (I2T) and using text to search images (T2I). Existing cross-media retrieval methods usually learn one couple of projections, by which the original features of images and text can be projected into a common latent space to measure the content similarity. However, using the same projections for the two different retrieval tasks (I2T and T2I) may lead to a tradeoff between their respective performances, rather than their best performances. Different from previous works, we propose a modality-dependent cross-media retrieval (MDCR) model, where two couples of projections are learned for different cross-media retrieval tasks instead of one couple of projections. Specifically, by jointly optimizing the correlation between images and text and the linear regression from one modal space (image or text) to the semantic space, two couples of mappings are learned to project images and text from their original feature spaces into two common latent subspaces (one for I2T and the other for T2I). Extensive experiments show the superiority of the proposed MDCR compared with other methods. In particular, based on the 4,096-dimensional convolutional neural network (CNN) visual feature and 100-dimensional Latent Dirichlet Allocation (LDA) textual feature, the mAP of the proposed method achieves the mAP score of 41.5%, which is a new state-of-the-art performance on the Wikipedia dataset.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research 3 (2003), 993--1022.", "A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, and T. Mikolov. 2013. Devise: A deep visual-semantic embedding model. In Advances in Neural Information Processing Systems. 2121--2129.", "Y. Gong, Q. Ke, M. Isard, and S. Lazebnik. 2013. A multi-view embedding space for modeling internet images, tags, and their semantics. International Journal of Computer Vision 106 (2013), 1--24."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775109"}, {"title": "Contextual Bandits in a Collaborative Environment", "authors": ["Qingyun Wu\n,", "Huazheng Wang\n,", "Quanquan Gu\n,", "Hongning Wang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nContextual bandit algorithms provide principled online learning solutions to find optimal trade-offs between exploration and exploitation with companion side-information. They have been extensively used in many important practical scenarios, such as display advertising and content recommendation. A common practice estimates the unknown bandit parameters pertaining to each user independently. This unfortunately ignores dependency among users and thus leads to suboptimal solutions, especially for the applications that have strong social components.\nIn this paper, we develop a collaborative contextual bandit algorithm, in which the adjacency graph among users is leveraged to share context and payoffs among neighboring users while online updating. We rigorously prove an improved upper regret bound of the proposed collaborative bandit algorithm comparing to conventional independent bandit algorithms. Extensive experiments on both synthetic and three large-scale real-world datasets verified the improvement of our proposed algorithm against several state-of-the-art contextual bandit algorithms.", "references": ["Y. Abbasi-yadkori, D. Pál, and C. Szepesvári. Improved algorithms for linear stochastic bandits. In NIPS, pages 2312--2320. 2011.", "K. Amin, M. Kearns, and U. Syed. Graphical models for bandit problems. Proceedings of UAI 2011, 2011.", "P. Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3:397--422, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911528"}, {"title": "Practical guidelines for change recommendation using association rule mining", "authors": ["Leon Moonen\n,", "Stefano Di Alesio\n,", "David Binkley\n,", "Thomas Rolfsnes"], "publication": "ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nAssociation rule mining is an unsupervised learning technique that infers relationships among items in a data set. This technique has been successfully used to analyze a system's change history and uncover evolutionary coupling between system artifacts. Evolutionary coupling can, in turn, be used to recommend artifacts that are potentially affected by a given set of changes to the system. In general, the quality of such recommendations is affected by (1) the values selected for various parameters of the mining algorithm, (2) characteristics of the set of changes used to derive a recommendation, and (3) characteristics of the system's change history for which recommendations are generated.\nIn this paper, we empirically investigate the extent to which certain choices for these factors affect change recommendation. Specifically, we conduct a series of systematic experiments on the change histories of two large industrial systems and eight large open source systems, in which we control the size of the change set for which to derive a recommendation, the measure used to assess the strength of the evolutionary coupling, and the maximum size of historical changes taken into account when inferring these couplings. We use the results from our study to derive a number of practical guidelines for applying association rule mining for change recommendation.", "references": ["G. Canfora and L. Cerulo. “Impact Analysis by Mining Software and Change Request Repositories”. In: International Software Metrics Symposium (METRICS). IEEE, 2005, pp. 29–37.", "M.-A. Jashki, R. Zafarani, and E. Bagheri. “Towards a more efficient static software change impact analysis method”. In: ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering (PASTE). ACM, 2008, pp. 84–90.", "X. Ren et al. “Chianti: a tool for change impact analysis of java programs”. In: ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications (OOPSLA). 2004, pp. 432–448."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970276.2970327"}, {"title": "SGT Framework: Social, Geographical and Temporal Relevance for Recreational Queries in Web Search", "authors": ["Stewart Whiting\n,", "Omar Alonso"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhile location-based social networks (LBSNs) have become widely used for sharing and consuming location information, a large number of users turn to general web search engines for recreational activity ideas. In these cases, users typically express a query combining desired activity type, constraints and suitability, around an explicit location and time -- for example, \"parks for kids in NYC in winter\", or \"cheap bars for bachelor party in san francisco\". In this work we characterize such queries as recreational queries, and propose a relevance framework for ranking points of interest (POIs) to present in the web search recreational vertical using signals from query logs and LBSNs. The first part of this framework is a taxonomy of recreational intents, which we derive from those previously seen in query logs and other behavioral data. Based on the most popular recreational intents, we proceed to outline a new relevance model combining social, geographical and temporal information. We implement a prototype and conduct a preliminary user-study evaluation. Results show the proposed relevance model and bundles greatly improve user satisfaction for recreational queries.", "references": ["S. Bannur and O. Alonso. Analyzing temporal characteristics of check-in data. In WWW '14, pages 827--832.", "H. Bota, K. Zhou, J. M. Jose, and M. Lalmas. Composite retrieval of heterogeneous web search. In WWW '14, pages 119--130.", "E. Cho, S. A. Myers, and J. Leskovec. Friendship and mobility: user movement in location-based social networks. In SIGKDD '11, pages 1082--1090. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914743"}, {"title": "Mobile access to cultural heritage: mobile-CH 2016", "authors": ["Liliana Ardissono\n,", "Cristina Gena\n,", "Tsvi Kuflik"], "publication": "MobileHCI '16: Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct", "abstract": "ABSTRACT\nThe Mobile-CH workshop, held in conjunction with the MOBILE HCI Conference, will be the meeting point between cultural heritage research and personalization -- using any kind of technology, especially mobile and ubiquitous ones, to enhance the personal experience in cultural heritage sites. The workshop is aimed at bringing together researchers and practitioners who are working on various aspects of CH and are interested in exploring the potential of state of the art technology to enhance the CH visit experience. The result of the workshop is a multidisciplinary research agenda that will inform future research directions and hopefully, forge some research collaborations.", "references": ["Giorgos Anagnostakis, Michalis Antoniou, Elena Kardamitsi, Thodoris Sachinidis, Panayiotis Koutsabasis, Modestos Stavrakis, Spyros Vosinakis and Dimitrios Zissis, Accessible Museum Collections for the Visually Impaired: Combining Tactile Exploration, Audio Descriptions and Mobile Gestures, this issue.", "Liliana Ardissono, Maurizio Lucenteforte, Noemi Mauro, Adriano Savoca, Angioletta Voghera and Luigi La Riccia, Exploration of Cultural Heritage Information via Textual Search Queries, this issue.", "Carmelo Ardito, Maria Francesca Costabile, Giuseppe Desolda and Maristella Matera, Supporting professional guides to create personalized visit experiences, this issue."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2957265.2965001"}, {"title": "Evaluating Link-based Recommendations for Wikipedia", "authors": ["Malte Schwarzer\n,", "Moritz Schubotz\n,", "Norman Meuschke\n,", "Corinna Breitinger\n,", "Volker Markl\n,", "Bela Gipp"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nLiterature recommender systems support users in filtering the vast and increasing number of documents in digital libraries and on the Web. For academic literature, research has proven the ability of citation-based document similarity measures, such as Co-Citation (CoCit), or Co-Citation Proximity Analysis (CPA) to improve recommendation quality. In this paper, we report on the first large-scale investigation of the performance of the CPA approach in generating literature recommendations for Wikipedia, which is fundamentally different from the academic literature domain. We analyze links instead of citations to generate article recommendations. We evaluate CPA, CoCit, and the Apache Lucene MoreLikeThis (MLT) function, which represents a traditional text-based similarity measure. We use two datasets of 779,716 and 2.57 million Wikipedia articles, the Big Data processing framework Apache Flink, and a ten-node computing cluster. To enable our large-scale evaluation, we derive two quasi-gold standards from the links in Wikipedia's \"See also\" sections and a comprehensive Wikipedia clickstream dataset.\nOur results show that the citation-based measures CPA and CoCit have complementary strengths compared to the text-based MLT measure. While MLT performs well in identifying narrowly similar articles that share similar words and structure, the citation- based measures are better able to identify topically related information, such as information on the city of a certain university or other technical universities in the region. The CPA approach, which consistently outperformed CoCit, is better suited for identifying a broader spectrum of related articles, as well as popular articles that typically exhibit a higher quality. Additional benefits of the CPA approach are its lower runtime requirements and its language-independence that allows for a cross-language retrieval of articles. We present a manual analysis of exemplary articles to demonstrate and discuss our findings. The raw data and source code of our study, together with a manual on how to use them, are openly available at: https://github.com/wikimedia/citolytics", "references": ["Beel, J. et al. 2015. Research-paper recommender systems: a literature survey. Int. Journal on Digital Libraries. (2015).", "Beel, J. et al. 2016. Towards reproducibility in recommender-systems research. User Modeling and User-Adapted Interaction (UMAI). 26, (2016).", "Bellomi, F. and Bonato, R. 2005. Network Analysis for Wikipedia. Proc. of Wikimania. (2005)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910908"}, {"title": "Trust-aware Peer Assessment using Multi-armed Bandit Algorithms", "authors": ["Hou Pong Chan\n,", "Tong Zhao\n,", "Irwin King"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nMassive Open Online Coursers (MOOCs) offer a convenient way for people to access quality courses via the internet. However, the problem of grading open-ended assignments at such a large scale still remains challenging. Although peer assessment have been proposed to handle the large-scale grading problem in MOOCs, existing methods still suffer several limitations: (1) most current peer assessment research ignore the importance of how to allocate the assessment tasks among peers, (2) existing approaches for peer grading learn the complete ranking in an offline manner, (3) theoretical analysis for trust-aware peer grading is missing. In this work, we consider the case that we have prior knowledge about all students' reliability. We formulate the problem of peer assessment as a sequential noisy ranking aggregation problem. We derive a trust-aware allocation scheme for peer assessment to maximize the probability of constructing a correct ranking of assignments with a budget constraint.Moreover, we also derive an upper bound for the probability of prediction error on the inferred ranking of assignments. Furthermore, we propose the Trust-aware Ranking-based Multi-armed Bandit Algorithms to sequentially allocate the assessment tasks to the students based on the derived allocation scheme and learn an accurate peer grading result by taking students' reliability into consideration.", "references": ["P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. In Machine Learning, 2002.", "R. A. Bradley and M. E. Terry. Rank analysis of incomplete block designs the method of paired comparisons. Biometrika, 39(3--4):324--345, 1952.", "R. Busa-Fekete, E. Hüllermeier, and B. Szörényi. Preference-based rank elicitation using statistical models: The case of mallows. In ICML, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891080"}, {"title": "Recurrent Marked Temporal Point Processes: Embedding Event History to Vector", "authors": ["Nan Du\n,", "Hanjun Dai\n,", "Rakshit Trivedi\n,", "Utkarsh Upadhyay\n,", "Manuel Gomez-Rodriguez\n,", "Le Song"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nLarge volumes of event data are becoming increasingly available in a wide variety of applications, such as healthcare analytics, smart cities and social network analysis. The precise time interval or the exact distance between two events carries a great deal of information about the dynamics of the underlying systems. These characteristics make such data fundamentally different from independently and identically distributed data and time-series data where time and space are treated as indexes rather than random variables. Marked temporal point processes are the mathematical framework for modeling event data with covariates. However, typical point process models often make strong assumptions about the generative processes of the event data, which may or may not reflect the reality, and the specifically fixed parametric assumptions also have restricted the expressive power of the respective processes. Can we obtain a more expressive model of marked temporal point processes? How can we learn such a model from massive data?\nIn this paper, we propose the Recurrent Marked Temporal Point Process (RMTPP) to simultaneously model the event timings and the markers. The key idea of our approach is to view the intensity function of a temporal point process as a nonlinear function of the history, and use a recurrent neural network to automatically learn a representation of influences from the event history. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Using both synthetic and real world datasets, we show that, in the case where the true models have parametric specifications, RMTPP can learn the dynamics of such models without the need to know the actual parametric forms; and in the case where the true models are unknown, RMTPP can also learn the dynamics and achieve better predictive performance than other parametric alternatives based on particular prior assumptions.", "references": ["O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view. Springer, 2008.", "E. Bacry, A. Iuga, M. Lasnier, and C.-A. Lehalle. Market impacts and the life cycle of investors orders. 2014.", "E. Bacry, T. Jaisson, and J.-F. Muzy. Estimation of slowly decreasing hawkes kernels: Application to high frequency order book modelling. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939875"}, {"title": "Interactive Topic Modeling for aiding Qualitative Content Analysis", "authors": ["Aneesha Bakharia\n,", "Peter Bruza\n,", "Jim Watters\n,", "Bhuva Narayan\n,", "Laurianne Sitbon"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nTopic Modeling algorithms are rarely used to support the qualitative content analysis process. The main contributing factors for the lack of mainstream adoption can be attributed to the perception that Topic Modeling produces topics of poor quality and that content analysts do not trust the derived topics because they are unable to supply domain knowledge and interact with the algorithm. In this paper, interactive Topic Modeling algorithms namely Dirichlet-Forrest Latent Dirichlet Allocation and Penalised Non-negative Matrix Factorisation, are evaluated with respect to their ability to aid qualitative content analysis. More specifically, the relationship between interactivity, interpretation, topic coherence and trust in interactive content analysis is examined. The findings indicate that providing content analysts with the ability to interact with Topic Modeling algorithms produces topics that are directly related to their research questions. However, a number of improvements to these algorithms were also identified which have the potential to influence future algorithm development to better meet the requirements of qualitative content analysts.", "references": ["D. Andrzejewski, X. Zhu, and M. Craven. Incorporating domain knowledge into topic modeling via dirichlet forest priors. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 25--32. ACM, 2009.", "D. Andrzejewski, X. Zhu, M. Craven, and B. Recht. A framework for incorporating general domain knowledge into latent dirichlet allocation using first-order logic. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Two, pages 1171--1177. AAAI Press, 2011.", "A. Bakharia. Interactive content analysis: evaluating interactive variants of non-negative Matrix Factorisation and Latent Dirichlet Allocation as qualitative content analysis aids. PhD thesis, Queensland University of Technology, Brisbane, Australia, 8 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854960"}, {"title": "Network-Aware Recommendations of Novel Tweets", "authors": ["Noor Aldeen Alawad\n,", "Aris Anagnostopoulos\n,", "Stefano Leonardi\n,", "Ida Mele\n,", "Fabrizio Silvestri"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWith the rapid proliferation of microblogging services such as Twitter, a large number of tweets is published everyday often making users feel overwhelmed with information. Helping these users to discover potentially interesting tweets is an important task for such services. In this paper, we present a novel tweet-recommendation approach, which exploits network, content, and retweet analyses for making recommendations of tweets. The idea is to recommend tweets that are not visible to the user (i.e., they do not appear in the user timeline) because nobody in her social circles published or retweeted them. To do that, we create the user's ego-network up to depth two and apply the transitivity property of the friends-of-friends relationship to determine interesting recommendations, which are then ranked to best match the user's interests. Experimental results demonstrate that our approach improves the state-of-the-art technique.", "references": ["M. G. Armentano, D. L. Godoy, and A. A. Amandi. A topology-based approach for followees recommendation in Twitter. In ITWP'11.", "S. Benzarti and R. Faiz. EgoTR: Personalized tweets recommendation approach. In CSOC'15.", "H. Chen, X. Cui, and H. Jin. Top-k followee recommendation over microblogging systems by exploiting diverse information sources. Future Generation Computer Systems, 55, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914760"}, {"title": "MuSeeCol: A See-through Multi-touch Surface for Face-to-face Musical Collaboration", "authors": ["Wooi Boon Goh\n,", "Lijia Yang\n,", "Kian Leong Ong"], "publication": "ACE '16: Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nMuSeeCol is a collaborative music creation system that allows two users to jointly and playfully compose melodic or percussive music. Collaborative music is rendered when two face-to-face users interact with their respective side of a see-through multi-touch sensitive acrylic panel. We present user study findings from nine pairs of individuals who have used the MuSeeCol system collaboratively and summarize some general observations of what types of interaction designs make for effective face-to-face collaboration.", "references": ["Battocchi, A., Pianesi, F., Tomasini, D., Zancanaro, M., Esposito, G., Venuti, P., Ben Sasson, A. Gal, E. and Weiss, P.L. Collaborative Puzzle Game: a Tabletop Interactive Game for Fostering Collaboration in Children with Autism Spectrum Disorders. in Proc. ITS 2009, 197--204.", "Benford, S., Bederson, B.B., Akesson, K.P., Bayon, V., Druin, A., Hansoon, P., Hourcase, J.P., Ingram, R., Neale, H., O'Malley, C., Simsarian, K.T., Staton, D., Sundblad, Y., Taxen, G. Designing Storytelling Technologies to Encourage Collaboration Between Young Children. in Proc. CHI 2000, 1--6.", "Blaine, T., Perkis, T. The Jam-O-Drum Interactive Music System: A Study in Interaction Design. in Proc. of DIS 2000, 165--173."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3001773.3001788"}, {"title": "Trip Recommendation Meets Real-World Constraints: POI Availability, Diversity, and Traveling Time Uncertainty", "authors": ["Chenyi Zhang\n,", "Hongwei Liang\n,", "Ke Wang"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nAs location-based social network (LBSN) services become increasingly popular, trip recommendation that recommends a sequence of points of interest (POIs) to visit for a user emerges as one of many important applications of LBSNs. Personalized trip recommendation tailors to users’ specific tastes by learning from past check-in behaviors of users and their peers. Finding the optimal trip that maximizes user’s experiences for a given time budget constraint is an NP-hard problem and previous solutions do not consider three practical and important constraints. One constraint is POI availability, where a POI may be only available during a certain time window. Another constraint is uncertain traveling time, where the traveling time between two POIs is uncertain. In addition, the diversity of the POIs included in the trip plays an important role in user’s final adoptions. This work presents efficient solutions to personalized trip recommendation by incorporating these constraints and leveraging them to prune the search space. We evaluated the efficiency and effectiveness of our solutions on real-life LBSN datasets.", "references": ["David L. Applegate, Robert E. Bixby, Vasek Chvatal, and William J. Cook. 2007. The Traveling Salesman Problem: A Computational Study (Princeton Series in Applied Mathematics). Princeton University Press.", "Liliana Ardissono, Anna Goy, Giovanna Petrone, Marino Segnan, and Pietro Torasso. 2003. Intrigue: Personalized recommendation of tourist attractions for desktop and hand held devices. Applied Artificial Intelligence 17, 8--9 (2003), 687--714.", "Senjuti Basu Roy, Gautam Das, Sihem Amer-Yahia, and Cong Yu. 2011. Interactive itinerary planning. In ICDE. 15--26."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948065"}, {"title": "Exploratory querying of extended knowledge graphs", "authors": ["Mohamed Yahya\n,", "Klaus Berberich\n,", "Maya Ramanath\n,", "Gerhard Weikum"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nKnowledge graphs (KGs) are important assets for search, analytics, and recommendations. However, querying a KG to explore entities and discover facts is difficult and tedious, even for users with skills in SPARQL. First, users are not familiar with the structure and labels of entities, classes and relations. Second, KGs are bound to be incomplete, as they capture only major facts about entities and their relationships and miss out on many of the more subtle aspects.\nWe demonstrate TriniT, a system that facilitates exploratory querying of large KGs, by addressing these issues of \"vocabulary\" mismatch and KG incompleteness. TriniT supports query relaxation rules that are invoked to allow for relevant answers which are not found otherwise. The incompleteness issue is addressed by extending a KG with additional text-style token triples obtained by running Open IE on Web and text sources. The query language, relaxation methods, and answer ranking are extended appropriately. The demo shows automatic query relaxation and has support for interactively adding user-customized relaxations. In both situations, the demo provides answer explanations and offers additional query suggestions.", "references": ["K. Balog, M. Bron, M. de Rijke: Query Modeling for Entity Search Based on Terms, Categories, and Examples. ACM TOIS 29(4):22, 2011", "A. Fader, S. Soderland, O. Etzioni: Identifying Relations for Open Information Extraction. EMNLP 2011: 1535--1545", "G. Fokou, S. Jean, A. Hadjali, M. Baron: QaRS: A User-Friendly Graphical Tool for Semantic Query Design and Relaxation. EDBT 2015: 237--252"], "doi_url": "https://dl.acm.org/doi/abs/10.14778/3007263.3007299"}, {"title": "IT Governance in Healthcare Industry Organizations: A Case Study of COBIT Implementation", "authors": ["Edemir P.V. Prado\n,", "Andre Montoia Barata\n,", "Monica Mancini\n,", "Violeta Sun"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThis study describes the implementation of the COBIT framework in a private organization from the healthcare industry and analyse the level of maturity of IT Governance before and after its implementation. This is an exploratory and qualitative study. It was used a single case study strategy in order to describe the implementation of the COBIT framework. Data were collected through interviews in the second half of 2015. The main contribution of the research was the identification that GTI frameworks are becoming increasingly complex and difficult to implement. Organizations can achieve great results focusing on critical processes, instead of implementing all the procedures provided by the framework. This opens an opportunity to review the implementation process of this framework, suiting them to specific needs of each organization.", "references": ["Riekstin, A. C. 2012. Modelo de Governanca de Tecnologia da Informacao de Escritorio ao chao de fabrica. Dissertacao de Mestrado em Engenharia, Universidade de Sao Paulo, Sao Paulo.", "Rossoni, L., and Silva, C. L. M. 2013. Legitimidade, Governanca Corporativa e Desempenho: Analise das Empresas da BM e F Bovespa. Revista de Administracao de Empresas, 53, 3, 272-289.", "Cristofoli, F., Prado, E. P. V., and Takaoka, H. (2012). Gestao da terceirizacao da tecnologia da informacao baseada nas praticas de governanca. In Proceedings of the CONTECSI International Conference on Information Systems and Technology Management (Sao Paulo, Brasil, 30 Maio - 1 de Junho, 2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021957"}, {"title": "Novel Word Embedding and Translation-based Language Modeling for Extractive Speech Summarization", "authors": ["Kuan-Yu Chen\n,", "Shih-Hung Liu\n,", "Berlin Chen\n,", "Hsin-Min Wang\n,", "Hsin-Hsi Chen"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWord embedding methods revolve around learning continuous distributed vector representations of words with neural networks, which can capture semantic and/or syntactic cues, and in turn be used to induce similarity measures among words, sentences and documents in context. Celebrated methods can be categorized as prediction-based and count-based methods according to the training objectives and model architectures. Their pros and cons have been extensively analyzed and evaluated in recent studies, but there is relatively less work continuing the line of research to develop an enhanced learning method that brings together the advantages of the two model families. In addition, the interpretation of the learned word representations still remains somewhat opaque. Motivated by the observations and considering the pressing need, this paper presents a novel method for learning the word representations, which not only inherits the advantages of classic word embedding methods but also offers a clearer and more rigorous interpretation of the learned word representations. Built upon the proposed word embedding method, we further formulate a translation-based language modeling framework for the extractive speech summarization task. A series of empirical evaluations demonstrate the effectiveness of the proposed word representation learning and language modeling techniques in extractive speech summarization.", "references": ["Mari Ostendorf. 2008. Speech technology and information access. IEEE Signal Processing Magazine, 25(3): 150--152.", "Sadaoki Furui, Li Deng, Mark Gales, Hermann Ney, and Keiichi Tokuda. 2012. Fundamental technologies in modern speech recognition. IEEE Signal Processing Magazine, 29(6): 16--17.", "Inderjeet Mani and Mark T. Maybury (Eds.). 1999. Advances in automatic text summarization. Cambridge, MA: MIT Press.", "P. B. Baxendale. 1958. Machine-made index for technical literature-an experiment. IBM Journal, 2(4): 354--361.", "Yang Liu and Dilek Hakkani-Tur. 2011. Speech summarization. Chapter 13 in Spoken Language Understanding: Systems for Extracting Semantic Information from Speech, G. Tur and R. D. Mori (Eds), New York: Wiley.", "Ziqiang Cao, Furu Wei, Sujian Li, Wenjie Li, Ming Zhou, and Houfeng Wang. 2015. Learning Summary Prior Representation for Extractive Summarization. In Proc. ACL, pages 829--833.", "Ani Nenkova and Kathleen McKeown. 2011. Automatic summarization. Foundations and Trends in Information Retrieval, 5(2--3): 103--233.", "Gerald Penn and Xiaodan Zhu. 2008. A? critical reassessment of evaluation baselines for speech summarization. In Proc. ACL, pages 470--478.", "Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. Journal of Machine Learning Research, 3: 1137--1155.", "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In Proc. ICLR, pages 1--12.", "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global vector for word representation. In Proc. EMNLP, pages 1532--1543.", "Will Y. Zou, Richard Socher, Daniel Cer, Christopher D. Manning. 2013. Bilingual word embeddings for phrase-based machine translation. In Proc. ACL, pages 1393--1398.", "Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014. Learning sentiment-specific word embedding for twitter sentiment classification. In Proc. ACL, pages 1555--1565.", "Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proc. ICLR, pages 160--167.", "Marco Baroni, Georgiana Dinu, and German Kruszewski. 2014. Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. In Proc. ACL, pages 238--247.", "Omer Levy, Yoav Goldberg, and Ido Dagan. 2015. Improving distributional similarity with lessons learned from word embeddings. Transactions of the Association for Computational Linguistics, 3: 211--225.", "Han-Shen Huang, Bou-Ho Yang and Chun-Nan Hsu. 2005. Triple jump acceleration for the EM algorithm. In Proc. ICDM, pages 1--4.", "Shih-Hung Liu, Kuan-Yu Chen, Berlin Chen, Hsin-Min Wang, Hsu-Chun Yen, and Wen-Lian Hsu. 2015. Combining relevance language modeling and clarity measure for extractive speech summarization. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23(6): 957--969.", "Hsin-Min Wang, Berlin Chen, Jen-Wei Kuo, and Shih-Sian Cheng. 2005. MATBN: A Mandarin Chinese broadcast news corpus. International Journal of Computational Linguistics and Chinese Language Processing, 10(2): 219--236.", "Jen-Tzung Chien. 2015. Hierarchical Pitman-Yor-Dirichlet language model. IEEE/ACM Transactions on Audio, Speech and Language Processing, 23(8): 1259--1272.", "Chien-Lin Huang and Chung-Hsien Wu. 2007. Spoken Document Retrieval Using Multi-Level Knowledge and Semantic Verification. IEEE Transactions on Audio, Speech, and Language Processing, 15(8): 2551--2560.", "Chin-Yew Lin. 2003. ROUGE: Recall-oriented understudy for gisting evaluation. http://haydn.isi.edu/ROUGE/.", "Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proc. SIGIR, pages 19--25.", "Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proc. SIGIR, pages 335--336.", "Xiaojun Wan and Jianwu Yang. 2008. Multi-document summarization using cluster-based link analysis. In Proc. SIGIR, pages 299--306.", "Gunes Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligent Research, 22(1): 457--479.", "Hui Lin and Jeff Bilmes. 2010. Multi-document summarization via budgeted maximization of submodular functions. In Proc. NAACL HLT, pages 912--920.", "Korbinian Riedhammer, Benoit Favre, and Dilek Hakkani-Tur. 2010. Long story short - Global unsupervised models for keyphrase based meeting summarization. Speech Communication, 52(10): 801--815.", "Mikael Kageback, Olof Mogren, Nina Tahmasebi, and Devdatt Dubhashi. 2014. Extractive summarization using continuous vector space models. In Proc. CVSC, pages 31--39.", "Kuan-Yu Chen, Shih-Hung Liu, Hsin-Min Wang, Berlin Chen, and Hsin-Hsi Chen. 2015. Leveraging word embeddings for spoken document summarization. In Proc. INTERSPEECH, pages 1383--1387.", "Kuan-Yu Chen, Shih-Hung Liu, Berlin Chen, Hsin-Min Wang, Ea-Ee Jan, Wen-Lian Hsu, and Hsin-Hsi Chen. 2015. Extractive broadcast news summarization leveraging recurrent neural network language modeling techniques. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23(8):1322--1334.", "Kuan-Yu Chen, Hsin-Min Wang, Berlin Chen, and Hsin-Hsi Chen. 2013. Weighted matrix factorization for spoken document retrieval. In Proc. ICASSP, pages 8530--8534.", "Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In Proc. NIPS, pages 1--9."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967246"}, {"title": "Efficient Mobile Implementation of A CNN-based Object Recognition System", "authors": ["Keiji Yanai\n,", "Ryosuke Tanno\n,", "Koichi Okamoto"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nBecause of the recent progress on deep learning studies, Convolutional Neural Network (CNN) based method have outperformed conventional object recognition methods with a large margin. However, it requires much more memory and computational costs compared to the conventional methods. Therefore, it is not easy to implement a CNN-based object recognition system on a mobile device where memory and computational power are limited. In this paper, we examine CNN architectures which are suitable for mobile implementation, and propose multi-scale network-in-networks (NIN) in which users can adjust the trade-off between recognition time and accuracy. We implemented multi-threaded mobile applications on both iOS and Android employing either NEON SIMD instructions or the BLAS library for fast computation of convolutional layers, and compared them in terms of recognition time on mobile devices. As results, it has been revealed that BLAS is better for iOS, while NEON is better for Android, and that reducing the size of an input image by resizing is very effective for speedup of CNN-based recognition.", "references": ["M. Lin, Q. Chen, and S. Yan, \"Network in network,\" in Proc. of International Conference on Learning Represenation Conference Track, 2014.", "H. Jegou, M. Douze, and C. Schmid, \"Product quantization for nearest neighbor search,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 1, pp. 117--128, 2011.", "S. Ioffe and C. Szegedy, \"Batch normalization: Accelerating deep network training by reducing internal covariate shift,\" in Proc. of International Conference on Machine Learning, pp. 448--456, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967243"}, {"title": "A Critical Analysis of the Cyber Contract Using Electronic Mail", "authors": ["Biswajit Tripathy"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nElectronic commerce(e-commerce) facilitates the data exchange in connection to the financial and payments aspects of business in day to day life. In order to have transparent and robust business processes, the electronic contract (e-contract) between the buyer and seller should be executed. Electronic mail (email) can also be part of the electronic commerce processes. In electronic business, parties can interact within themselves through emails and with the help of electronics payment system they can purchase goods or services through secure transaction protocols. However, the email should adhere to both the security and legal frameworks of e-contracts. This paper makes a critical analysis of the challenges of using email as a tool for e-commerce and testifies its usage in context of both the security and legal frameworks of e-contracts.", "references": ["D. M. Nyamaka (2011). Electronic Contracts in Tanzania: An Appraisal of the Legal Framework, Accessed from www.http://works.bepress.com/cgi/viewcontent.cgi?article=1001&context=dmnyamaka.", "UNCTAD Report(2000), Building Confidence: Ecommerce and Development. Accessed from www.http://unctad.org/en/Publications.Library.", "D. J. Brinson et al., (2001) Analysing Ecommerce & Internet Law, Prentice Hall PRT, Upper Saddle River, NJ."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905240"}, {"title": "Time-Aware Click Model", "authors": ["Yiqun Liu\n,", "Xiaohui Xie\n,", "Chao Wang\n,", "Jian-Yun Nie\n,", "Min Zhang\n,", "Shaoping Ma"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nClick-through information is considered as a valuable source of users’ implicit relevance feedback for commercial search engines. As existing studies have shown that the search result position in a search engine result page (SERP) has a very strong influence on users’ examination behavior, most existing click models are position based, assuming that users examine results from top to bottom in a linear fashion. Although these click models have been successful, most do not take temporal information into account. As many existing studies have shown, click dwell time and click sequence information are strongly correlated with users’ perceived relevance and search satisfaction. Incorporating temporal information may be important to improve performance of user click models for Web searches. In this article, we investigate the problem of properly incorporating temporal information into click models. We first carry out a laboratory eye-tracking study to analyze users’ examination behavior in different click sequences and find that the user common examination path among adjacent clicks is linear. Next, we analyze the user dwell time distribution in different search logs and find that we cannot simply use a click dwell time threshold (e.g., 30 seconds) to distinguish relevant/irrelevant results. Finally, we propose a novel time-aware click model (TACM), which captures the temporal information of user behavior. We compare the TACM to several existing click models using two real-world search engine logs. Experimental results show that the TACM outperforms other click models in terms of both predicting click behavior (perplexity) and estimating result relevance (NDCG).", "references": ["Eugene Agichtein, Eric Brill, and Susan Dumais. 2006a. Improving Web search ranking by incorporating user behavior information. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’06). ACM, New York, NY, 19--26.", "Eugene Agichtein, Eric Brill, Susan T. Dumais, and Robert Ragno. 2006b. Learning user interaction models for predicting Web search result preferences. In Proceedings of the 29th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’06). ACM, New York, NY, 3--10.", "Alexey Borisov, Ilya Markov, Maarten de Rijke, and Pavel Serdyukov. 2016a. A context-aware time model for Web search. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’16). ACM, New York, NY, 1--10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2988230"}, {"title": "Fully automated multi-label image annotation by convolutional neural network and adaptive thresholding", "authors": ["Hoa M. Le\n,", "Thi-Oanh Nguyen\n,", "Dung Ngo-Tien"], "publication": "SoICT '16: Proceedings of the Seventh Symposium on Information and Communication Technology", "abstract": "ABSTRACT\nThis paper presents a fully automated and flexible ConvNet-based classifier for multi-label image annotation. The classifier alleviates hierarchical representation of image from a convolutional neural network, and adaptive thresholding technique on the ranked list of label scores. The method can annotate images with arbitrary number of labels that the classifier finds fit, as opposed to common methods which only assign a fixed number of those. Experiments show state-of-the-art on classification accuracy and competitive annotation performance across 2 intrinsically different data-sets, Corel5K and MSRCv2. Although the proposed method shows some limitation in learning label semantics, empirical study indicates that it was due to the established drawback of univariate loss function, which the classifier optimised, in multi-label classification. It, therefore, opens for number of directions to improve the performance, while still retains the merits of the proposed method.", "references": ["Y. Bengio, N. Boulanger-Lewandowski, and R. Pascanu. Advances in optimizing recurrent networks. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pages 8624--8628. IEEE, 2013.", "G. Carneiro, A. B. Chan, P. J. Moreno, and N. Vasconcelos. Supervised learning of semantic classes for image annotation and retrieval. IEEE transactions on pattern analysis and machine intelligence, 29(3):394--410, 2007.", "K. Dembczynski, W. Kotlowski, and E. Hüllermeier. Consistent multilabel ranking through univariate losses. arXiv preprint arXiv:1206.6401, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011077.3011118"}, {"title": "A Framework for Topic Generation and Labeling from MOOC Discussions", "authors": ["Thushari Atapattu\n,", "Katrina Falkner"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nThis study proposes a standardised open framework to automatically generate and label discussion topics from Massive Open Online Courses (MOOCs). The proposed framework expects to overcome the issues experienced by MOOC participants and teaching staff in locating and navigating their information needs effectively. We analysed two MOOCs -- Machine Learning and Statistics: Making Sense of Data offered during 2013 and obtained statistically significant results for automated topic labeling. However, more experiments with additional MOOCs from different MOOC platforms are necessary to generalise our findings.", "references": ["Seimens, G. MOOCs are really a platform. EleanSpace, (2002).", "Ezan-Can, A., et al. Unsupervised modeling for understanding MOOC discussion forums: a learning analytics approach. In Proc. LAK 2015.", "Reich, J., et al. Computer Assisted Reading and Discovery for Student Generated Text in Massive Open Online Courses. Learning Analytics, (2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893414"}, {"title": "Keyphrase-Based Hierarchical Clustering for Arabic Documents", "authors": ["Moufeda Hussein\n,", "Abdelwahab Alsammak\n,", "Tarek Elshishtawy"], "publication": "INFOS '16: Proceedings of the 10th International Conference on Informatics and Systems", "abstract": "ABSTRACT\nThe vast amount of available Arabic web pages and text files on the internet makes it necessary to organize data in an easy way for user browsing. Document clustering is a good solution for this problem, which groups similar data into clusters with meaningful labels. In this paper, we propose a domain independent approach, which builds a hierarchical meaningful clustering tree. The proposed approach overcomes the problem of high dimensionality of feature vector by representing each document with its keyphrases. In addition, we introduced a new similarity measure by taking the common lemma form keyphrases among feature vectors of documents. This improves the accuracy of the clustering process with reduced complexity. Many experiments are carried out to evaluate the accuracy of clustering using String-based, Corpus-based, and Knowledge-based similarity measures. A dataset consists of 345 Arabic documents and covering 12 domains is used in these experiments. The results show that applying lexical similarity using keyphrase based gives more accurate clusters labels than using semantic similarity. The best purity result achieved is 0.955, which is obtained using the common lemma form keyphrases similarity method.", "references": ["Black, W., Elkateb, S., Rodriguez, H., Alkhalifa, M., Vossen, P., Pease, A., and Fellbaum, C., 2006. Introducing the Arabic wordnet project. In Proceedings of the Third International WordNet Conference, 295--300.", "El-Shishtawy, T. and Al-Sammak, A., 2012. Arabic keyphrase extraction using linguistic knowledge and machine learning techniques. arXiv preprint arXiv:1203.4605.", "Francetic, M., Nagode, M., and Nastav, B., 2005. Hierarchical clustering with concave data sets. Metodoloski Zvezki 2, 2, 173."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908446.2908494"}, {"title": "Supporting Comment Moderators in Identifying High Quality Online News Comments", "authors": ["Deokgun Park\n,", "Simranjit Sachar\n,", "Nicholas Diakopoulos\n,", "Niklas Elmqvist"], "publication": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "abstract": "ABSTRACT\nOnline comments submitted by readers of news articles can provide valuable feedback and critique, personal views and perspectives, and opportunities for discussion. The varying quality of these comments necessitates that publishers remove the low quality ones, but there is also a growing awareness that by identifying and highlighting high quality contributions this can promote the general quality of the community. In this paper we take a user-centered design approach towards developing a system, CommentIQ, which supports comment moderators in interactively identifying high quality comments using a combination of comment analytic scores as well as visualizations and flexible UI components. We evaluated this system with professional comment moderators working at local and national news outlets and provide insights into the utility and appropriateness of features for journalistic tasks, as well as how the system may enable or transform journalistic practices around online comments.", "references": ["Ashley A. Anderson, Dominique Brossard, Dietram A. Scheufele, Michael A. Xenos, and Peter Ladwig. 2014. The \"Nasty Effect:\" Online Incivility and Risk Perceptions of Emerging Technologies. Journal of Computer-Mediated Communication 19, 3, 373--387. http://doi.org/10.1111/jcc4.12009", "Saeideh Bakhshi, Partha Kanuparthy, and David A. Shamma. 2015. Understanding Online Reviews: Funny, Cool or Useful? Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, ACM, 1270--1276. http://doi.org/10.1145/2675133.2675275", "Dirk Brand and Brink Van Der Merwe. 2014. Comment classification for an online news domain. Retrieved January 18, 2015 from https://scholar.sun.ac.za/handle/10019.1/96148"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2858036.2858389"}, {"title": "Users' preferences for answer forms to reference questions in libraries", "authors": ["Tomohiro Furusawa\n,", "Mamiko Matsubayashi\n,", "Tetsuji Satoh"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nReference service is one of the significant user support services in libraries, and in the service, the librarian provides appropriate information to a user's needs. Studies of a social question and answer (Q&A) site revealed preferences held by users for an answer in terms of subject relevance or prediction. In order to provide a higher quality service, we investigated users' preferences for answers given in libraries. To understand what users prefer for answers, we defined four \"answer forms\" from the perspectives of the \"amount of information\" and \"whether it includes any explanations of information resources or not.\" Respondents ranked four answers, which were developed from the answer forms in response to reference questions. The purpose was to discover their preferred way to be answered in the reference service. Results indicated that people prefer an answer, which provides multiple information resources and attached explanations of the resources, rather than an answer that only gives information resources without offering explanations. In addition, we found relationships between answer preferences and user attributes, such as age and frequency of library use.", "references": ["Chu, F. 1996. Framing reference encounters, RQ, 36(1), 93--101.", "American Library Association. 2008. \"Definitions of Reference\". January 14, 2008. http://www.ala.org/rusa/resources/guidelines/definitionsreference. (accessed 2016-07-19)", "Katz, W. 2002. Reference services and reference processes (8th ed.) McGraw-Hill. (125--127)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011168"}, {"title": "Framing Mobile Information Needs: An Investigation of Hierarchical Query Sequence Structure", "authors": ["Shuguang Han\n,", "Xing Yi\n,", "Zhen Yue\n,", "Zhigeng Geng\n,", "Alyssa Glass"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhen using search engines, people often issue multiple related queries to accomplish a complex search task. A simple query-task structure may not fully capture the complexity of query relations since people may divide a task into multiple subtasks. As a result, this paper applies a three-level hierarchical structure with query, goal and mission - a mission includes several goals, and a goal consists of multiple queries. Particularly, we focus on analyzing query-goal-mission structure for mobile web search because of its increasing popularity and lack of investigation in the literature. This study has three main contributions: (1) we study the query-goal-mission structure for mobile web search, which was not studied before. (2) We identify several differences between mobile and desktop search patterns in terms of goal/mission length, duration and interleaving. (3) We demonstrate that the query-goal-mission structure can be applied to design better user satisfaction metrics. Specifically, goal-based search success rate and mission-based abandonment rate are better aligned with users' long-term engagement than query and session based metrics.", "references": ["A. Drutsa, G. Gusev, and P. Serdyukov. Future user engagement prediction and its application to improve the sensitivity of online experiments. In WWW, pages 256--266, 2015.", "H. Feild and J. Allan. Task-aware query recommendation. In SIGIR, pages 83--92, 2013.", "D. Guan, S. Zhang, and H. Yang. Utilizing query change for session search. In SIGIR, pages 453--462, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983654"}, {"title": "Exploiting Semantic Coherence Features for Information Retrieval", "authors": ["Xinhui Tu\n,", "Jimmy Xiangji Huang\n,", "Jing Luo\n,", "Tingting He"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMost of the existing information retrieval models assume that the terms of a text document are independent of each other. These retrieval models integrate three major variables to determine the degree of importance of a term for a document: within document term frequency, document length and the specificity of the term in the collection. Intuitively, the importance of a term for a document is not only dependent on the three aspects mentioned above, but also dependent on the degree of semantic coherence between the term and the document. In this paper, we propose a heuristic approach, in which the degree of semantic coherence of the query terms with a document is adopted to improve the information retrieval performance. Experimental results on standard TREC collections show the proposed models consistently outperform the state-of-the-art models.", "references": ["Blanco R. and Lioma C. Graph-based term weighting for information retrieval. Information Retrieval, 15(1), 54--92, 2012.", "Craswell N., Robertson S. and Zaragoza H. Relevance weighting for query independent evidence. ACM SIGIR, 416--423, 2005.", "Diaz, F. and Metzler, D. Improving the estimation of relevance models using large external corpora. ACM SIGIR, 154--161, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914691"}, {"title": "Development and Enhancement of a Stemmer for the Greek Language", "authors": ["Georgios Ntais\n,", "Spyridon Saroukos\n,", "Eleni Berki\n,", "Hercules Dalianis"], "publication": "PCI '16: Proceedings of the 20th Pan-Hellenic Conference on Informatics", "abstract": "ABSTRACT\nAlthough there are three stemmers published for the Greek language, only the one presented in this paper and called Ntais' stemmer is freely open and available, together with its enhancements and extensions according to Saroukos' algorithm. The primary algorithm (Ntais' algorithm) uses only capital letters and works with better performance than other past stemming algorithms for the Greek language, giving 92.1 percent correct results. Further extensions of the proposed stemming system (e.g. from capital to small letters) and more evaluation methods are presented according to a new and improved algorithm, Saroukos' algorithm. Stemmer performance metrics are further used for evaluating the existing stemming system and algorithm and show how its accuracy and completeness are enhanced. The improvements were possible by providing an alternative implementation in the programming language PHP, which offers more syntactical rules and exceptions. The two versions of the stemming algorithm are tested and compared.", "references": ["Baeza-Yates, R. and Ribeiro-Neto, B. 1999. Modern Information Retrieval. Addison Wesley, New York.", "van Rijsbergen, C.J. 1979. Information Retrieval Butterworths, London.", "Risvik, K. M, Mikolajewski T. and Boros P. Q. 2003 Segmentation for Web Search. In Proceedings of the 12th International World Wide Web Conference, 52."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3003733.3003775"}, {"title": "Evaluating Retrieval over Sessions: The TREC Session Track 2011-2014", "authors": ["Ben Carterette\n,", "Paul Clough\n,", "Mark Hall\n,", "Evangelos Kanoulas\n,", "Mark Sanderson"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation Retrieval (IR) research has traditionally focused on serving the best results for a single query - so-called ad hoc retrieval. However, users typically search iteratively, refining and reformulating their queries during a session. A key challenge in the study of this interaction is the creation of suitable evaluation resources to assess the effectiveness of IR systems over sessions. This paper describes the TREC Session Track, which ran from 2010 through to 2014, which focussed on forming test collections that included various forms of implicit feedback. We describe the test collections; a brief analysis of the differences between datasets over the years; and the evaluation results that demonstrate that the use of user session data significantly improved effectiveness.", "references": ["B. Carterette, E. Kanoulas, A. Bah, M. Hall, and P. D. Clough. Overview of the TREC 2013 Session track. In Proceedings of TREC, 2013.", "B. Carterette, E. Kanoulas, A. Bah, M. Hall, and P. D. Clough. Overview of the TREC 2014 Session track (notebook version). In Proceedings of TREC, 2014.", "B. Carterette, E. Kanoulas, P. D. Clough, and M. Sanderson, editors. Proceedings of the ECIR 2011 Workshop on Information Retrieval Over Query Sessions, Available at http://ir.cis.udel.edu/ECIR11Sessions."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914675"}, {"title": "Ontology-based model of law retrieval system for R&D projects", "authors": ["Wooju Kim\n,", "Youna Lee\n,", "Donghe Kim\n,", "Minjae Won\n,", "HaeMin Jung"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nResearch and development projects have close relationship with laws. In some cases, new technologies resulted from R&D projects can't be used because some statutes restrict them. The reason of this problem is that researchers don't know exactly which laws can affect their R&D projects. To solve the issue, we suggest a model for law retrieval system that can be used by researchers of R&D projects to find related statutes. Input of this model is a query document that describes the main contents of a project. By using ontology, legal terms are extracted from the document and statutes defining them are retrieved as a set of related laws. After this searching process, statutes are provided to researchers with their ranks, which are assigned using relevance scores we developed. By using this model, we can make a system for researchers to search a list of statutes that may affect R&D projects, and finally, they can adjust their project's direction by checking the list, preventing their works from being useless.", "references": ["Brin, S. and Page, L., \"The anatomy of a large-scale hypertextual Web search engine,\" Computer Networks and ISDN Systems, Vol. 30, pp. 107--117, 1998.", "Church, K. W. and Hanks, P., \"Word association norms, mutual information, and lexicography,\" Comput. Linguist, Vol. 16, No. 1, pp. 22--29, 1990.", "Jo, D. W., Seo, M. J., and Kim, M. Ho., \"A Study on Legal Information Retrieval Engine based on Ontology,\" Korea Information Science Society, pp. 1568--1570, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971629"}, {"title": "Interoperability in the Heterogeneous Cloud Environment: A Survey of Recent User-centric Approaches", "authors": ["Ibrahim Mansour\n,", "Reza Sahandi\n,", "Kendra Cooper\n,", "Adrian Warman"], "publication": "ICC '16: Proceedings of the International Conference on Internet of things and Cloud Computing", "abstract": "ABSTRACT\nCloud computing provides users the ability to access shared, online computing resources. However, providers often offer their own proprietary applications, interfaces, APIs and infrastructures, resulting in a heterogeneous cloud environment. This heterogeneous environment makes it difficult for users to change cloud service providers; exploring capabilities to support the automated migration from one provider to another is an active, open research area. Many standards bodies (IEEE, NIST, DMTF and SNIA), industry (middleware) and academia have been pursuing approaches to reduce the impact of vendor lock-in by investigating the cloud migration problem at the level of the VM. However, the migration downtime, decoupling VM from underlying systems and security of live channels remain open issues. This paper focuses on analysing recently proposed live, cloud migration approaches for VMs at the infrastructure level in the cloud architecture. The analysis reveals issues with flexibility, performance, and security of the approaches, including additional loads to the CPU and disk I/O drivers of the physical machine where the VM initially resides. The next steps of this research are to develop and evaluate a new approach LibZam (Libya Zamzem) that will work towards addressing the identified limitations.", "references": ["Gartner. 2013. Gartner Says Nearly Half of Large Enterprises Will Have Hybrid Cloud Deployments by the End of 2017, Available at: http://www.gartner.com/newsroom/id/2599315 (Accessed: 22-10-2015).", "Steve Woodward, Dave Casper, Alex McDonald, Winston Bumpus, Claude Baudoin. 2014. The State of Cloud Standards in 2014: Interoperability, Portability and Security, Available at: https://www.brighttalk.com/ (Accessed: 22-10-2015).", "Zhizhong Zhang, Chuan Wu, and David W.L. Cheung. 2013. A survey on cloud interoperability: taxonomies, standards, and practice. SIGMETRICS Perform. Eval. Rev. 40, 4 (April 2013), 13--22. DOI=10.1145/2479942.2479945"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2896387.2896447"}, {"title": "An Analysis of the Cost and Benefit of Search Interactions", "authors": ["Leif Azzopardi\n,", "Guido Zuccon"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nInteractive Information Retrieval (IR) systems often provide various features and functions, such as query suggestions and relevance feedback, that a user may or may not decide to use. The decision to take such an option has associated costs and may lead to some benefit. Thus, a savvy user would take decisions that maximises their net benefit. In this paper, we formally model the costs and benefits of various decisions that users, implicitly or explicitly, make when searching. We consider and analyse the following scenarios: (i) how long a user's query should be? (ii) should the user pose a specific or vague query? (iii) should the user take a suggestion or re-formulate? (iv) when should a user employ relevance feedback? and (v) when would the \"find similar\" functionality be worthwhile to the user? To this end, we build a series of cost-benefit models exploring a variety of parameters that affect the decisions at play. Through the analyses, we are able to draw a number of insights into different decisions, provide explanations for observed behaviours and generate numerous testable hypotheses. This work not only serves as a basis for future empirical work, but also as a template for developing other cost-benefit models involving human-computer interaction.", "references": ["E. Agapie, G. Golovchinsky, and P. Qvarfordt. Leading people to longer queries. In Proc. of the SIGCHI, pages 3019--3022, 2013.", "P. Arvola, J. Kekäläinen, and M. Junkkari. Expected reading effort in focused retrieval evaluation. Inf. Retr., 13(5):460--484, 2010.", "L. Azzopardi. Query side evaluation: an empirical analysis of effectiveness and effort. In Proc. of SIGIR, pages 556--563, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970412"}, {"title": "TEAMOPT: Interactive Team Optimization in Big Networks", "authors": ["Liangyue Li\n,", "Hanghang Tong\n,", "Nan Cao\n,", "Kate Ehrlich\n,", "Yu-Ru Lin\n,", "Norbou Buchler"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe science of team science is a rapidly emerging research field that studies strategies to understand and enhance the process and outcomes of collaborative, team-based research. An interesting research question we address in this work is how to maintain and optimize the team performance should certain changes happen to the team. In particular, we take the network approach to understanding the teams and consider optimizing the teams with several operations (e.g., replacement, expansion, shrinkage). We develop TEAMOPT, a system to assist users in optimizing the team performance interactively to support the changes to a team. TEAMOPT takes as input a large network of individuals (e.g., co-author network of researchers) and is able to assist users in assembling a team with specific requirements and optimizing the team in response to the changes made to the team. It is effective in finding the best candidates, and interactive with users' feedback in the loop. The system is developed using HTML5, JavaScript, D3.js (front-end) and Python CGI (back-end). A prototype system is already deployed. We will invite the audience to experiment with our TEAMOPT in terms of its effectiveness, efficiency and applicability to various scenarios.", "references": ["N. Cao, Y. Lin, L. Li, and H. Tong. g-miner: Interactive visual group mining on multivariate graphs. In CHI, pages 279--288, 2015.", "J. B. Kruskal and J. M. Landwehr. Icicle plots: Better displays for hierarchical clustering. The American Statistician, 37(2):162--168, 1983.", "T. Lappas, K. Liu, and E. Terzi. Finding a team of experts in social networks. In KDD, pages 467--476. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983340"}, {"title": "Zero-Example Multimedia Event Detection and Recounting with Unsupervised Evidence Localization", "authors": ["Yi-Jie Lu"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nRetrieval of a complex multimedia event has long been regarded as a challenging task. Multimedia event recounting, other than event detection, focuses on providing comprehensible evidence which justifies a detection result. Recounting enables \"video skimming\", which not only enhances video exploration, but also makes human-in-the-loop possible for improving the detection result. Most existing systems treat event recounting as a disjoint post-processing step over the result of event detection. Unlike these systems, this doctoral research aims to provide an in-depth understanding of how recounting, i.e., evidence localization, helps in event detection in the first place. It can potentially benefit the overall design of an efficient event detection system with or without human-in-the-loop. More importantly, we propose a framework for detecting and recounting everyday events without any needs of training examples. The system only takes a text description of an event as input, then performs evidence localization, event detection and recounting in a large, unlabelled video corpus. The goal of the system is to take advantage of event recounting which eventually improves zero-example event detection. We present preliminary results and work in progress.", "references": ["S. Bhattacharya, F. X. Yu, and S.-F. Chang. Minimally needed evidence for complex event recognition in unconstrained videos. In ACM ICMR, pages 105--112, 2014.", "X. Chang, Y. Yang, A. G. Hauptmann, E. P. Xing, and Y.-L. Yu. Semantic concept discovery for large-scale zero-shot event detection. In IJCAI, 2015.", "X. Chang, Y.-L. Yu, Y. Yang, and A. G. Hauptmann. Searching persuasively: Joint event detection and evidence recounting with limited supervision. In ACM MM, pages 581--590. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2971480"}, {"title": "MedGEC'16 Chairs' Welcome", "authors": ["Stephen L. Smith\n,", "Stefano Cagnoni\n,", "Robert Patton"], "publication": "GECCO '16 Companion: Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908961.2931730"}, {"title": "A Game-Theory Approach for Effective Crowdsource-Based Relevance Assessment", "authors": ["Yashar Moshfeghi\n,", "Alvaro Francisco Huertas Rosero\n,", "Joemon M. Jose"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nDespite the ever-increasing popularity of crowdsourcing (CS) in both industry and academia, procedures that ensure quality in its results are still elusive. We hypothesise that a CS design based on game theory can persuade workers to perform their tasks as quickly as possible with the highest quality. In order to do so, in this article we propose a CS framework inspired by the n-person Chicken game. Our aim is to address the problem of CS quality without compromising on CS benefits such as low monetary cost and high task completion speed. With that goal in mind, we study the effects of knowledge updates as well as incentives for good workers to continue playing. We define a general task with the characteristics of relevance assessment as a case study, because it has been widely explored in the past with CS due to its potential cost and complexity. In order to investigate our hypotheses, we conduct a simulation where we study the effect of the proposed framework on data accuracy, task completion time, and total monetary rewards. Based on a game-theoretical analysis, we study how different types of individuals would behave under a particular game scenario. In particular, we simulate a population comprised of different types of workers with varying ability to formulate optimal strategies and learn from their experiences. A simulation of the proposed framework produced results that support our hypothesis.", "references": ["Omar Alonso. 2013. Implementing crowdsourcing-based relevance experimentation: An industrial perspective. Inform. Retriev. 16, 2 (April 2013), 101--120. DOI:http://dx.doi.org/10.1007/s10791-012-9204-1.", "Omar Alonso and Ricardo Baeza-Yates. 2011. Design and implementation of relevance assessments using crowdsourcing. In Advances in Information Retrieval. Springer, Berlin, 153--164.", "Omar Alonso and Stefano Mizzaro. 2009. Can we get rid of TREC assessors? Using mechanical turk for relevance assessment. In Proceedings of the SIGIR 2009 Workshop on the Future of IR Evaluation. 557--566."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2873063"}, {"title": "A Neural Network Approach to Quote Recommendation in Writings", "authors": ["Jiwei Tan\n,", "Xiaojun Wan\n,", "Jianguo Xiao"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuote is a language phenomenon of transcribing the saying of someone else. Proper usage of quote can usually make the statement more elegant and convincing. However, the ability of quote usage is usually limited by the amount of quotes one remembers or knows. Quote recommendation is a task of exploiting abundant quote repositories to help people make better use of quotes while writing. The task is different from conventional recommendation tasks due to the characteristic of quote. A pilot study has explored this task by using a learning to rank framework and manually designed features. However, it is still hard to model the meaning of a quote, which is an interesting and challenging problem. In this paper, we propose a neural network approach based on LSTMs to the quote recommendation task. We directly learn the distributed meaning representations for the contexts and the quotes, and then measure the relevance based on the meaning representations. In particular, we try to represent the words in quotes with specific embeddings, according to the contexts, topics and even author preferences of the quotes. Experimental results on a large dataset show that our proposed approach achieves the state-of-the-art performance and it outperforms several strong baselines.", "references": ["James Bergstra, Olivier Breuleux, Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference, volume 4, page 3, June 2010. Oral Presentation.", "Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1724--1734, 2014.", "John C. Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121--2159, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983788"}, {"title": "Human-Robots Implicit Communication based on Dialogue between Robots using Automatic Generation of Funny Scenarios from Web", "authors": ["Ryo Mashimo\n,", "Tomohiro Umetani\n,", "Tatsuya Kitamura\n,", "Akiyo Nadamoto"], "publication": "HRI '16: The Eleventh ACM/IEEE International Conference on Human Robot Interaction", "abstract": "ABSTRACT\nNumerous studies have examined communication robots that communicate with people, but it is difficult for robots to communicate with people smoothly. We call the communication style based on dialogue between robots as \"human-robot implicit communication\". As described herein, we propose a Manzai-robots for which the interaction style is human-robot implicit communication based on an automatically generated scenario from web news. Our generated Manzai scenario consists of snappy patter and a misunderstanding of dialogue based on the four kinds of gap of structure of funny points. Our purpose is that people feel familiarity from smoothly human-robot communication using dialogue between robots based on a Manzai scenario. We conducted experiment of three kinds to assess (1) the effectiveness of automatic creation of Manzai scenario for the robots, (2) the effectiveness of the Manzai-robots as a media, and (3) the effectiveness of types of familiarity for Manzai-robots. Based on their results, we measured the familiarity and smooth communication of our Manzai-robots.", "references": ["Y. Chen, S. Y. M. Lee, and C.-R. Huang. Are emotions enumerable or decomposable? and its implications for emotion processing. In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, pages 92--100. Association for computation Linguistics, 2009.", "M. R. Fraune, S. Sherrin, S. Sabanović, and E. R. Smith. Rabble of robots effects: Number and type of robots modulates attitudes, emotions, and stereotypes. In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI '15, pages 109--116. ACM, 2015.", "GansoBakushoOu. Introduction of Manzai. Rittor Music, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2906831.2906888"}, {"title": "On the \"Face of Things\"", "authors": ["Ranran Feng\n,", "Balakrishnan Prabhakaran"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nFace is crucial for human identity, while face identification has become crucial to information security. It is important to understand and work with the problems and challenges for all different aspects of facial feature extraction and face identification. In this tutorial, we identify and discuss four research challenges in current Face Detection/Recognition research and related research areas: (1) Unavoidable Facial Feature Alterations, (2) Voluntary Facial Feature Alterations, (3) Uncontrolled Environments, and (4) Accuracy Control on Large-scale Dataset. We also direct several different applications (spin-offs) of facial feature studies in the tutorial.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2930062"}, {"title": "Quality Management in Crowdsourcing using Gold Judges Behavior", "authors": ["Gabriella Kazai\n,", "Imed Zitouni"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nCrowdsourcing relevance labels has become an accepted practice for the evaluation of IR systems, where the task of constructing a test collection is distributed over large populations of unknown users with widely varied skills and motivations. Typical methods to check and ensure the quality of the crowd's output is to inject work tasks with known answers (gold tasks) on which workers' performance can be measured. However, gold tasks are expensive to create and have limited application. A more recent trend is to monitor the workers' interactions during a task and estimate their work quality based on their behavior. In this paper, we show that without gold behavior signals that reflect trusted interaction patterns, classifiers can perform poorly, especially for complex tasks, which can lead to high quality crowd workers getting blocked while poorly performing workers remain undetected. Through a series of crowdsourcing experiments, we compare the behaviors of trained professional judges and crowd workers and then use the trained judges' behavior signals as gold behavior to train a classifier to detect poorly performing crowd workers. Our experiments show that classification accuracy almost doubles in some tasks with the use of gold behavior data.", "references": ["O. Alonso. Implementing crowdsourcing-based relevance experimentation: an industrial perspective. Information Retrieval}, 16(2):101--120, Apr. 2013.", "Y. Bachrach, T. Graepel, T. Minka, and J. Guiver. How to grade a test without knowing the answers--a bayesian graphical model for adaptive crowdsourcing and aptitude testing. In Proc. of the 29th International Conference on Machine Learning (ICML-12), pages 1183--1190, 2012.", "P. Bailey, N. Craswell, I. Soboroff, P. Thomas, A. P. de Vries, and E. Yilmaz. Relevance assessment: are judges exchangeable and does it matter. In Proc. of the 31st ACM SIGIR conf. on Research and development in IR}, SIGIR '08, pages 667--674, New York, NY, USA, 2008. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835835"}, {"title": "Personalized Group Recommender Systems for Location- and Event-Based Social Networks", "authors": ["Sanjay Purushotham\n,", "C.-C. Jay Kuo"], "publication": "ACM Transactions on Spatial Algorithms and Systems", "abstract": "Abstract\nLocation-Based Social Networks (LBSNs) such as Foursquare, Google+ Local, and so on, and Event-Based Social Networks (EBSNs) such as Meetup, Plancast, and so on, have become popular platforms for users to plan, organize, and attend social events with friends and acquaintances. These LBSNs and EBSNs provide rich content such as online and offline user interactions, location/event descriptions that can be leveraged for personalized group recommendations. In this article, we propose novel Collaborative Filtering-based Bayesian models to capture the location or event semantics and group dynamics such as user interactions, user group membership, user influence, and the like for personalized group recommendations. Empirical experiments on two large real-world datasets (Gowalla LBSN dataset and Meetup EBSN dataset) show that our models outperform the state-of-the-art group recommender systems. We discuss the group characteristics of our datasets and show that modeling of group dynamics learns better group preferences than aggregating individual user preferences. Moreover, our model provides human interpretable results that can be used to understand group participation behavior and location/event popularity.", "references": ["Sihem Amer-Yahia, Senjuti Basu Roy, Ashish Chawlat, Gautam Das, and Cong Yu. 2009. Group recommendation: Semantics and efficiency. Proceedings of the VLDB Endowment 2, 1 (2009), 754--765.", "Linas Baltrunas, Tadas Makcinskas, and Francesco Ricci. 2010. Group recommendations with rank aggregation and collaborative filtering. In ACM RecSys.", "Jie Bao, Yu Zheng, and Mohamed F. Mokbel. 2012. Location-based and preference-aware recommendation using sparse geo-social networking data. In ACM GIS."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987381"}, {"title": "Extracting Information Seeking Intentions for Web Search Sessions", "authors": ["Matthew Mitsui\n,", "Chirag Shah\n,", "Nicholas J. Belkin"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present a method for extracting the self-reported intentions of users engaged in an information seeking episode. We recruited participants to conduct search sessions and subsequently asked them to self-report their intentions. A total of 27 users participated in a lab study, during which they worked on two search tasks. After each search session, participants indicated their intentions during that session while viewing a video replay. Results indicate that the set of search intentions provided to participants was sufficient to account for intentions in four journalism-related information seeking tasks: a copy editing task, interview preparation task, relationships task, and story pitch task. The results also suggest regular patterns in intentions that can be exploited for identification of task type as well as potential applications to personalization and recommendation during a search episode.", "references": ["N. J. Belkin. Anomalous states of knowledge as a basis for information-retrieval. Canadian Journal of Information Science-Revue Canadienne Des Sciences De L Information, 5:133--143, 1980.", "K. Byström and K. Järvelin. Task complexity affects information seeking and use. Inf. Process. Manage., 31(2):191--213, Mar. 1995.", "M. J. Cole, J. Gwizdka, C. Liu, R. Bierig, N. J. Belkin, and X. Zhang. Task and user effects on reading patterns in information search. Interacting with Computers, 23(4):346 -- 362, 2011. Cognitive Ergonomics for Situated Human-Automation Collaboration."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914746"}, {"title": "A Study on the Relationship Between Process and Motivation in Software Development Teams", "authors": ["Daniel Xavier\n,", "Davi Viana\n,", "Bruno Gadelha"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe software development process usually changes between the various organizations, while some have formal and institutionalized processes, others do not have standards in development process, do not specifying in formal documents and tend to change very often. Thus, is believed that there any direct relationship between the how to work of software development teams and the motivation of their members. This study aims to analyze the influence of the software development process in the motivation of development teams. For this, interviews with software developers from different organizations using different software development processes were compared. With this, was possible to verify the influence of software process in motivation the members of the organizations and which characteristics of these processes influence in motivation of these members.", "references": ["Ackerman, A. F., Buchwald, L. S., e Lewski, F. H. (1989). Software inspections: an effective verification process. IEEE software, 6(3), 31.", "Baddoo, N., Hall, T., e Jagielska, D. (2006). Software developer motivation in a high maturity company: a case study. Software process: improvement and practice, 11(3), 219-228.", "Balancho, M. J. S., e Coelho, F. M. (1994). Motivar os alunos: criatividade na relacao pedagogica: conceitos e praticas. Editora Porto, Portugal."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021969"}, {"title": "A Novel Perspective of Image Search for Tracking and Actions", "authors": ["Efstratios Gavves"], "publication": "MADiMa '16: Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management", "abstract": "ABSTRACT\nIn this talk I will focus on how image retrieval and visual search can be re-purposed for tasks that traditionally are considered to be very different. More specifically, I will first discuss a new, retrieval-inspired tracker, which is radically different from state-of-the-art trackers: it requires no model updating, no occlusion detection, no combination of trackers, no geometric matching, and still deliver state-of-the-art tracking performance on state-of-the-art online tracking benchmarks (OTB) and other very challenging YouTube videos. Departing from tracking, I will next focus on the relation between image search and other types of modalities that are not strictly speaking images, such as motion. More specifically, I will discuss a novel method for converting motion, or other types of sequential, dynamical inputs into just standalone, single images, so called \"dynamic images\". By encoding all the relevant dynamic, information into simple single images, dynamic images allow for the use of existing, off-the-shelf image convolutional neural networks or handcrafted machine learning algorithms. The works presented in the talk have been published in the latest CVPR 2016 conference.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986035.2991078"}, {"title": "Multiple Model Guided Image Filter for Image Denoising", "authors": ["Sun Young Kim\n,", "Jun Hoo Cho\n,", "Chang Ho Kang\n,", "Chan Gook Park"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nIn this paper, a multiple model guided image filter (MMGIF) is proposed to eliminate the various additive noises in the measured image and maintain the tracking performance of the automatic target recognition (ATR). One of the guided image filter (GIF) model is a standard GIF (SGIF) for removing the white Gaussian noise, and the other model is a Laplacian GIF (LGIF) for impulse noise called salt-and-pepper noise which generally occurs in CCD camera images. Furthermore, in order to select the proper model of guided filter, the image noise identification method is also proposed in this paper. The proposed algorithm estimates image noise types using kurtosis, skewness, and normality of the noise distribution. The performance of the proposed algorithm is evaluated by several simulations in terms of peak signal to noise ratio (PSNR) and image enhancement factor (IEF).", "references": ["Motwani, M. C., Gadiya, M. C., Motwani, R. C., and Harris, F. C. 2004. Survey of image denoising techniques. In proceedings of GSPx 2004(Santa Clara, CA, September 27-30, 2004).", "Beaurepaire, L., Chehdi, K., and Vozel, B. 1997. Identification of the nature of noise and estimation of its statistical parameters by analysis of local histograms. In Proceedings 1997 IEEE International Conference on Acoustics, Speech and Signal Processing. 4, 2805--2808.", "Vozel, B., Chehdi, K., Klaine, L., Lukin, V. V., and Abramov, S. K. 2006. Noise Identification and Estimation of its Statistical Parameters by Using Unsupervised Variational Classification. In Proceedings 2006 IEEE International Conference on Acoustics, Speech and Signal Processing. 2, 841--844."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015209"}, {"title": "Probing the interconnections between geo-exploration and information exploration behavior", "authors": ["Dongho Choi\n,", "Chirag Shah\n,", "Vivek Singh"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nAs increasingly diverse facets of human life - including socializing, exercising, and information-seeking - are mediated by ubiquitous technology, they open the doors for the study of the hitherto under-explored interconnections between them. This work motivates and grounds the use of geo-exploration data to predict the information exploration behavior of users and to support their search. Based on a two-week field study involving 35 participants, we have identified multiple geo-exploration features that have significant associations with a user's information exploration behavior. We also found that the same geo-exploration features could be combined to build predictive models for various facets of an individual's information exploration behavior, and these models performed significantly better than comparable personality-based models.", "references": ["Christopher Ahlberg, Christopher Williamson, and Ben Shneiderman. 1992. Dynamic queries for information exploration: An implementation and evaluation. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 619--626.", "Hugo S Barbosa, Fernando B de Lima Neto, Alexandre Evsukoff, and Ronaldo Menezes. 2016. Returners and Explorers Dichotomy in Web Browsing Behavior - A Human Mobility Approach. In Complex Networks VII. Springer, 173--184.", "Yael Benn, Ofer Bergman, Liv Glazer, Paris Arent, Iain D Wilkinson, Rosemary Varley, and Steve Whittaker. 2015. Navigating through digital folders uses the same brain structures as real world navigation. Scientific reports 5 (2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971648.2971694"}, {"title": "Personalized Privacy-aware Image Classification", "authors": ["Eleftherios Spyromitros-Xioufis\n,", "Symeon Papadopoulos\n,", "Adrian Popescu\n,", "Yiannis Kompatsiaris"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nInformation sharing in online social networks is a daily practice for billions of users. The sharing process facilitates the maintenance of users' social ties but also entails privacy disclosure in relation to other users and third parties. Depending on the intentions of the latter, this disclosure can become a risk. It is thus important to propose tools that empower the users in their relations to social networks and third parties connected to them. As part of USEMP, a coordinated research effort aimed at user empowerment, we introduce a system that performs privacy-aware classification of images. We show that generic privacy models perform badly with real-life datasets in which images are contributed by individuals because they ignore the subjective nature of privacy. Motivated by this, we develop personalized privacy classification models that, utilizing small amounts of user feedback, provide significantly better performance than generic models. The proposed semi-personalized models lead to performance improvements for the best generic model ranging from 4%, when 5 user-specific examples are provided, to 18% with 35 examples. Furthermore, by using a semantic representation space for these models we manage to provide intuitive explanations of their decisions and to gain novel insights with respect to individuals' privacy concerns stemming from image sharing. We hope that the results reported here will motivate other researchers and practitioners to propose new methods of exploiting user feedback and of explaining privacy classifications to users.", "references": ["M. A. Álvarez, L. Rosasco, and N. D. Lawrence. Kernels for vector-valued functions: A review. Foundations and Trends in Machine Learning, 4(3):195--266, 2012.", "A. Bergamo and L. Torresani. Meta-class features for large-scale object categorization on a budget. In CVPR, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912018"}, {"title": "Rethinking Computer Architectures and Software Systems for Phase-Change Memory", "authors": ["Chengwen Wu\n,", "Guangyan Zhang\n,", "Keqin Li"], "publication": "ACM Journal on Emerging Technologies in Computing Systems", "abstract": "Abstract\nWith dramatic growth of data and rapid enhancement of computing powers, data accesses become the bottleneck restricting overall performance of a computer system. Emerging phase-change memory (PCM) is byte-addressable like DRAM, persistent like hard disks and Flash SSD, and about four orders of magnitude faster than hard disks or Flash SSDs for typical file system I/Os. The maturity of PCM from research to production provides a new opportunity for improving the I/O performance of a system. However, PCM also has some weaknesses, for example, long write latency, limited write endurance, and high active energy. Existing processor cache systems, main memory systems, and online storage systems are unable to leverage the advantages of PCM, and/or to mitigate PCM’s drawbacks. The reason behind this incompetence is that they are designed and optimized for SRAM, DRAM memory, and hard drives, respectively, instead of PCM memory. There have been some efforts concentrating on rethinking computer architectures and software systems for PCM. This article presents a detailed survey and review of the areas of computer architecture and software systems that are oriented to PCM devices. First, we identify key technical challenges that need to be addressed before this memory technology can be leveraged, in the form of processor cache, main memory, and online storage, to build high-performance computer systems. Second, we examine various designs of computer architectures and software systems that are PCM aware. Finally, we obtain several helpful observations and propose a few suggestions on how to leverage PCM to optimize the performance of a computer system.", "references": ["W. Arden. 2009. Semiconductor Industries Association - International Technology Roadmap for Semiconductors. http://www.itrs2.net/itrs-reports.html.", "R. Azevedoy, J. D. Davisz, and K. Straussz. 2013. Zombie memory: Extending memory lifetime by reviving dead blocks. In The 40th Annual International Symposium on Computer Architecture.", "S. Baek, J. Choi, D. Lee, and S. H. Noh. 2013. Energy-efficient and high-performance software architecture for storage class memory. ACM Transactions on Embedding Computing Systems 12, 3, Article 81, 22 pages. DOI:http://dx.doi.org/10.1145/2442116.2442131"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2893186"}, {"title": "k-Multi-preference query over road networks", "authors": ["Peiguang Lin\n,", "Yilong Yin\n,", "Peiyao Nie"], "publication": "Personal and Ubiquitous Computing", "abstract": "Abstract\nNowadays, the road network has gained more and more attention in the research area of databases. Existing works mainly focus on standalone queries, such as k-nearest neighbor queries over a single type of objects (e.g., facility like restaurant or hotel). In this paper, we propose a k-multi-preference (kMP) query over road networks, involving complex query predicates and multiple facilities. In particular, given a query graph, a kMP query retrieves of the top-k groups of vertices (of k facility types) satisfying the label constraints and their aggregate distances are the smallest. A naïve solution to this problem is to enumerate all combinations of vertices with k possible facility types and then select the one with the minimum sum distance. This method, however, incurs rather high computation cost due to exponential possible combinations. In addition, the existing solutions to other standalone queries are for a single type of facilities and cannot be directly used to answer kMP queries. Therefore, in this paper, we propose an efficient approach to process a kMP query, which utilizes an index with bounded space and reduces the computation cost of the shortest path queries. We also design effective pruning techniques to filter out false alarms. Through our extensive experiments, we demonstrate the efficiency and effectiveness of our proposed solutions.", "references": ["Mouratidis K, Yiu ML, Papadias D, Mamoulis N (2006) Continuous nearest neighbor monitoring in road networks. In: Proceedings of the 32nd international conference on very large data bases, pp 43---54", "Yiu ML, Mamoulis N, Papadias D (2005) Aggregate nearest neighbor queries in road networks. IEEE Trans Knowl Data Eng 17(6):820---833", "Mouratidis K, Bakiras S, Papadias D (2006) Continuous monitoring of top-k queries over sliding windows. In: Proceedings of the 2006 ACM SIGMOD international conference on management of data, pp 635---646"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00779-016-0913-0"}, {"title": "Search result diversification using data envelopment analysis", "authors": ["Justin JongSu Song\n,", "Jiyoung Lim\n,", "Wookey Lee\n,", "Jafar Afshar"], "publication": "EDB '16: Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory", "abstract": "ABSTRACT\nHow to resolve query ambiguity and how to avoid redundancies in a search result? The redundancy in returned results(e.g., near duplicates) has a negative effect on retrieval effectiveness(i.e., user satisfaction) and there is less benefit in representing relevant yet redundant results to the user repeatedly. So the ambiguity of query needs to be reflected in the returned results to account for the uncertainty on the user's information need. In a diversity context, the user is usually interested in retrieving various types of relevant documents (the number of information needs) more than the ones which are at the top of the result list. In this paper, we present a new document re-ranking method for information retrieval using Data Envelopment Analysis (DEA) and Diversity Retrieval Measure (DRM). The goal of the proposed re-ranking system is to diversify the documents results from the original ranking list. The experimentation is performed on hundreds of random Decision Making Units (DMUs) and the consequence achieved is compared with the existing system. The result demonstrates that the new method satisfies the unspecified individuals when the query is ambiguous. It also shows that the diversifying method is effective to satisfy the user who wants to get many types of information.", "references": ["F. Anjos and C. Fracassi. Shopping for information? diversification and the network of industries. Manage. Sci., 61(1):161--183, Jan. 2015.", "R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology behind Search (2nd Edition) (ACM Press Books). Addison-Wesley Professional, 2 edition, Feb. 2011.", "A. Charnes, W. Cooper, and E. Rhodes. Measuring the efficiency of decision making units. European Journal of Operational Research, 2(6):429 -- 444, 1978."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007818.3007847"}, {"title": "Minimising the Rank Aggregation Error: (Extended Abstract)", "authors": ["Mathijs M. de Weerdt\n,", "Enrico H. Gerding\n,", "Sebastian Stein"], "publication": "AAMAS '16: Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems", "abstract": "ABSTRACT\nRank aggregation is the problem of generating an overall ranking from a set of individual votes which is as close as possible to the (unknown) correct ranking. The challenge is that votes are often both noisy and incomplete. Existing work focuses on the most likely ranking for a particular noise model. Instead, we focus on minimising the error, i.e., the expected distance between the aggregated ranking and the correct one. We show that this results in different rankings, and we show how to compute local improvements of rankings to reduce the error. Extensive experiments on both synthetic data based on Mallows' model and real data show that Copeland has a smaller error than the Kemeny rule, while the latter is the maximum likelihood estimator.", "references": ["G. Brightwell and P. Winkler. Counting linear extensions is#P-complete. In 23rd ACM Symposium on Theory of Computation, pages 175--181, 1991.", "C. Dwork, R. Kumar, M. Naor, and D. Sivakumar. Rank aggregation methods for the web. In 10th Int. Conf. on World Wide Web, pages 613--622. ACM, 2001.", "E. Hemaspaandra, H. Spakowski, and J. Vogel. The complexity of Kemeny elections. Theoretical Computer Science, 349(3):382--391, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2936924.2937167"}, {"title": "How to Identify Specialized Research Communities Related to a Researcher's Changing Interests", "authors": ["Hamed Alhoori"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nScholarly events and venues are increasing rapidly in number. This poses a challenge for researchers who seek to identify events and venues related to their work in order to draw more efficiently and comprehensively from published research and to share their own findings more effectively. Such efforts are hampered also by the fact that no rating system yet exists to assist researchers in culling the venues most relevant to their current readings and interests. This study describes a methodology we developed in response to this need, one that recommends scholarly venues related to researchers' specific interests according to personalized social web indicators. Our experiments applying our proposed rating and recommendation method show that it outperforms the baseline venue recommendations in terms of accuracy and ranking quality.", "references": ["H. Alhoori, R. Furuta, M. Tabet, M. Samaka, and E. A. Fox, \"Altmetrics for country-level research assessment,\" in Proceedings of the 16th International Conference on Asia-Pacific Digital Libraries, 2014, vol. 8839, pp. 59--64.", "R. Klamma, P. M. Cuong, and Y. Cao, \"You never walk alone\": Recommending academic events based on social network analysis, in Proceedings of the First International Conference on Complex Science, 2009, vol. 4, no. 1, pp. 657--670.", "I. Boukhris and R. Ayachi, \"A novel personalized academic venue hybrid recommender,\" in IEEE 15th International Symposium on Computational Intelligence and Informatics, 2014, pp. 465--470."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925450"}, {"title": "Group Recommender Systems", "authors": ["Ludovico Boratto"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nGroup recommender systems provide suggestions in contexts in which people operate in groups. The goal of this tutorial is to provide the RecSys audience with an overview on group recommendation. We will first formally introduce the problem of producing recommendations to groups, then present a survey based on the tasks performed by these systems. We will also analyze challenging topics like their evaluation, and present emerging aspects and techniques in this area. The tutorial will end with a summary that highlights open issues and research challenges.", "references": ["S. Amer-Yahia, B. Omidvar-Tehrani, S. Basu Roy, and N. Shabib. Group recommendation with temporal affinities. In Proc. 18th International Conference on Extending Database Technology (EDBT), pages 421--432. OpenProceedings.org, 2015.", "L. Boratto and S. Carta. State-of-the-art in group recommendation and new approaches for automatic identification of groups. In Information Retrieval and Mining in Distributed Environments, volume 324 of Studies in Computational Intelligence, pages 1--20. Springer Berlin Heidelberg, 2011.", "L. Boratto and S. Carta. Using collaborative filtering to overcome the curse of dimensionality when clustering users in a group recommender system. In ICEIS 2014 - Proceedings of the 16th International Conference on Enterprise Information Systems, Volume 2, pages 564--572. SciTePress, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959197"}, {"title": "An unsupervised classification process for large datasets using web reasoning", "authors": ["Rafael Peixoto\n,", "Thomas Hassan\n,", "Christophe Cruz\n,", "Aurélie Bertaux\n,", "Nuno Silva"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nDetermining valuable data among large volumes of data is one of the main challenges in Big Data. We aim to extract knowledge from these sources using a Hierarchical Multi-Label Classification process called Semantic HMC. This process automatically learns a label hierarchy and classifies items from very large data sources. Five steps compose the Semantic HMC process: Indexation, Vectorization, Hierarchization, Resolution and Realization. The first three steps construct automatically the label hierarchy from data sources. The last two steps classify new items according to the label hierarchy. This paper focuses in the last two steps and presents a new highly scalable process to classify items from huge sets of unstructured text by using ontologies and rule-based reasoning. The process is implemented in a scalable and distributed platform to process Big Data and some results are discussed.", "references": ["Ben-David, D. et al. 2010. Enterprise Data Classification Using Semantic Web Technologies. 9th International Semantic Web Conference - Volume Part II (2010), 66--81.", "Bi, W. and Kwok, J. 2011. Multi-label classification on tree- and DAG-structured hierarchies. Yeast. (2011), 1--8.", "Chen, M. et al. 2014. Big Data: A Survey. Mobile Networks and Applications. 19, 2 (Jan. 2014), 171--209."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928301"}, {"title": "Separating-Plane Factorization Models: Scalable Recommendation from One-Class Implicit Feedback", "authors": ["Haolan Chen\n,", "Di Niu\n,", "Kunfeng Lai\n,", "Yu Xu\n,", "Masoud Ardakani"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study the video recommendation problem based on a large amount of user viewing logs instead of explicit ratings. As viewing records are implicitly suggest user preferences, existing matrix factorization methods fail to generate discriminative recommendations based on such one-class positive samples. We propose a scalable approach called separating-plane matrix factorization (SPMF) to make effective recommendations based on positive implicit feedback, with a learning complexity that is comparable to traditional matrix factorization. With extensive offline evaluation in Tencent Data Warehouse (TDW) based on a large amount of data, we show that our approach outperforms a wide range of state-of-the-art methods. We also deployed our system in the QQ Browser App of Tencent and performed online A/B testing with real users. Results suggest that our approach increased the video click through rate by $23% over implicit-feedback collaborative filtering (IFCF), a scheme available in Apache Spark's MLlib.", "references": ["Collaborative filtering - spark.mllib. http://spark.apache.org/docs/latest/mllib-collaborative-filtering.htm, 2014.", "Tdw: Tencent open source distributed data warehouse. http://prog3.com/article/1970-01-01/2819892, 2014.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983348"}, {"title": "Socializing the Semantic Gap: A Comparative Survey on Image Tag Assignment, Refinement, and Retrieval", "authors": ["Xirong Li\n,", "Tiberio Uricchio\n,", "Lamberto Ballan\n,", "Marco Bertini\n,", "Cees G. M. Snoek\n,", "Alberto Del Bimbo"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nWhere previous reviews on content-based image retrieval emphasize what can be seen in an image to bridge the semantic gap, this survey considers what people tag about an image. A comprehensive treatise of three closely linked problems (i.e., image tag assignment, refinement, and tag-based image retrieval) is presented. While existing works vary in terms of their targeted tasks and methodology, they rely on the key functionality of tag relevance, that is, estimating the relevance of a specific tag with respect to the visual content of a given image and its social context. By analyzing what information a specific method exploits to construct its tag relevance function and how such information is exploited, this article introduces a two-dimensional taxonomy to structure the growing literature, understand the ingredients of the main works, clarify their connections and difference, and recognize their merits and limitations. For a head-to-head comparison with the state of the art, a new experimental protocol is presented, with training sets containing 10,000, 100,000, and 1 million images, and an evaluation on three test sets, contributed by various research groups. Eleven representative works are implemented and evaluated. Putting all this together, the survey aims to provide an overview of the past and foster progress for the near future.", "references": ["Morgan Ames and Mor Naaman. 2007. Why we tag: Motivations for annotation in mobile and online media. In Proc. of ACM CHI. 971--980.", "Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Support vector machines for multiple-instance learning. In Proc. of NIPS. 561--568.", "Pradeep K. Atrey, M. Anwar Hossain, Abdulmotaleb El Saddik, and Mohan S. Kankanhalli. 2010. Multimodal fusion for multimedia analysis: A survey. Multimedia Systems 16, 6 (2010), 345--379."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2906152"}, {"title": "The unreasonable effectiveness of traditional information retrieval in crash report deduplication", "authors": ["Joshua Charles Campbell\n,", "Eddie Antonio Santos\n,", "Abram Hindle"], "publication": "MSR '16: Proceedings of the 13th International Conference on Mining Software Repositories", "abstract": "ABSTRACT\nOrganizations like Mozilla, Microsoft, and Apple are flooded with thousands of automated crash reports per day. Although crash reports contain valuable information for debugging, there are often too many for developers to examine individually. Therefore, in industry, crash reports are often automatically grouped together in buckets. Ubuntu's repository contains crashes from hundreds of software systems available with Ubuntu. A variety of crash report bucketing methods are evaluated using data collected by Ubuntu's Apport automated crash reporting system. The trade-off between precision and recall of numerous scalable crash deduplication techniques is explored. A set of criteria that a crash deduplication method must meet is presented and several methods that meet these criteria are evaluated on a new dataset. The evaluations presented in this paper show that using off-the-shelf information retrieval techniques, that were not designed to be used with crash reports, outperform other techniques which are specifically designed for the task of crash bucketing at realistic industrial scales. This research indicates that automated crash bucketing still has a lot of room for improvement, especially in terms of identifier tokenization.", "references": ["H. Seo and S. Kim, \"Predicting Recurring Crash Stacks,\" in Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering, ser. ASE 2012. ACM, pp. 180--189. Online}. Available: http://doi.acm.org/10.1145/2351676.2351702", "A. Schröter, N. Bettenburg, and R. Premraj, \"Do stack traces help developers fix bugs?\" in 2010 7th IEEE Working Conference on Mining Software Repositories (MSR), pp. 118--121.", "Mozilla Corporation. Mozilla Crash Reports. {Online}, Available: http://crash-stats.mozilla.com"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2901739.2901766"}, {"title": "A smart-device news recommendation technology based on the user click behavior", "authors": ["Yeong Hyeon Gu\n,", "Seong Joon Yoo\n,", "Zhegao Piao\n,", "Jaechun No\n,", "Zhiyan Jiang\n,", "Helin Yin"], "publication": "EDB '16: Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory", "abstract": "ABSTRACT\nStudies have been conducted in regard to personalized news recommendation using collaborative filtering mechanisms based on users' click behaviors. However, few existing studies have focused on news recommendations depending on the rates of news-category interests. In this paper, we present a personalized news-recommendation system that builds profiles of users' news-category interests, determines the number of news articles to be recommended for each news category in proportion to news-category interests and ranks news articles according to the user's news interests. In order to find the news categories that are interesting to read, the smart device collects the web pages viewed by the user and classifies the contents. We use machine learning techniques in order to classify web pages into different categories, and the results of our experimentation show that Naive Bayes achieved the highest F-measure. The news preference is automatically calculated by the news reading time and the length of the news text. News articles with high preference generated by the collaborative filtering technique are recommended based on the rate of each category. The recommendation system we have implemented is based on collaborative filtering using Mahout Recommender API on Hadoop. Through user testing, we also assess whether the proposed system is useful.", "references": ["Dong, H., Zhu, J., Tang, Y., Xu, C., Ding, R., and Chen, L. 2015. UBS: A Novel News Recommendation System Based on User Behavior Sequence. In International Conference on Knowledge Science, Engineering and Management. Springer International Publishing, 738--750.", "Kim, S. D. and Park, M. G. 2009. An Adaptation System based on Personalized Web Content Items for Mobile Devices. KSII Transactions on Internet & Information Systems.", "Liu, J., Dolan, P., and Pedersen, E. R. 2010. Personalized news recommendation based on click behavior. In Proceedings of the 15th international conference on Intelligent user interfaces. ACM. 31--40."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007818.3007821"}, {"title": "Distributional Random Oversampling for Imbalanced Text Classification", "authors": ["Alejandro Moreo\n,", "Andrea Esuli\n,", "Fabrizio Sebastiani"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe accuracy of many classification algorithms is known to suffer when the data are imbalanced (i.e., when the distribution of the examples across the classes is severely skewed). Many applications of binary text classification are of this type, with the positive examples of the class of interest far outnumbered by the negative examples. Oversampling (i.e., generating synthetic training examples of the minority class) is an often used strategy to counter this problem. We present a new oversampling method specifically designed for classifying data (such as text) for which the distributional hypothesis holds, according to which the meaning of a feature is somehow determined by its distribution in large corpora of data. Our Distributional Random Oversampling method generates new random minority-class synthetic documents by exploiting the distributional properties of the terms in the collection. We discuss results we have obtained on the Reuters-21578, OHSUMED-S, and RCV1-v2 datasets.", "references": ["Gustavo E. Batista, Ronaldo C. Prati, and Maria C. Monard. A study of the behavior of several methods for balancing machine learning training data. SIGKDD Explorations, 6(1):20--29, 2004.", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. SMOTE: Synthetic minority over-sampling technique. Journal of Artificial Intelligence Research, 16(1):321--357, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914722"}, {"title": "The Knowledge Awakens: Keeping Knowledge Bases Fresh with Emerging Entities", "authors": ["Johannes Hoffart\n,", "Dragan Milchevski\n,", "Gerhard Weikum\n,", "Avishek Anand\n,", "Jaspreet Singh"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nEntity search over news, social media and the Web allows users to precisely retrieve concise information about specific people, organizations, movies and their characters, and other kinds of entities. This expressive search mode builds on two major assets: 1) a knowledge base (KB) that contains the entities of interest and 2) entity markup in the documents of interest derived by automatic disambiguation of entity names (NED) and linking names to the KB. These prerequisites are not easily available, though, in the important case when a user is interested in a newly emerging entity (EE) such as new movies, new songs, etc. Automatic methods for detecting and canonicalizing EEs are not nearly at the same level as the NED methods for prominent entities that have rich descriptions in the KB.\nTo overcome this major limitation, we have developed an approach and prototype system that allows searching for EEs in a user-friendly manner. The approach leverages the human in the loop by prompting for user feedback on candidate entities and on characteristic keyphrases for EEs. For convenience and low burden on users, this process is supported by the automatic harvesting oftentative keyphrases. Our demo system shows this interactive process and its high usability.", "references": ["H. Bast, F. Baurle, B. Buchhold, and E. Haußmann. Semantic Full-Text Search with Broccoli. In SIGIR 2014, 2014.", "J. Dalton, L. Dietz, and J. Allan. Entity query feature expansion using knowledge base links. In SIGIR 2014, 2014.", "J. Hoffart, Y. Altun, and G. Weikum. Discovering Emerging Entities with Ambiguous Names. In WWW 2014, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890537"}, {"title": "Scalable algorithms for scholarly figure mining and semantics", "authors": ["Sagnik Ray Choudhury\n,", "Shuting Wang\n,", "C. Lee. Giles"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nMost scholarly papers contain one or multiple figures. Often these figures show experimental results, e.g, line graphs are used to compare various methods. Compared to the text of the paper, figures and their semantics have received relatively less attention. This has significantly limited semantic search capabilities in scholarly search engines. Here, we report scalable algorithms for generating semantic metadata for figures. Our system has four sequential modules: 1. Extraction of figure, caption and mention; 2. Binary classification of figures as compound (contains sub-figures) or not; 3. Three class classification of non compound figures as line graph, bar graph or others; and 4. Automatic processing of line graphs to generate a textual summary. In each step a metadata file is generated, each having richer information than the previous one. The algorithms are scalable yet each individual step has an accuracy greater than 80%.", "references": ["S. Z. Chen, M. J. Cafarella, and E. Adar. Searching for statistical diagrams. Frontiers of Engineering, National Academy of Engineering, pages 69--78, 2011.", "Z. Chen, M. Cafarella, and E. Adar. Diagramflyer: A search engine for data-driven diagrams. In Proceedings of the 24th International Conference on World Wide Web Companion, pages 183--186. International World Wide Web Conferences Steering Committee, 2015.", "S. R. Choudhury and C. L. Giles. An architecture for information extraction from figures in digital libraries. In Proceedings of the 24th International Conference on World Wide Web Companion, WWW 2015- Companion Volume, pages 667--672, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928305"}, {"title": "Exploring the Value of Personality in Predicting Rating Behaviors: A Study of Category Preferences on MovieLens", "authors": ["Raghav Pavan Karumur\n,", "Tien T. Nguyen\n,", "Joseph A. Konstan"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPrior work relevant to incorporating personality into recommender systems falls into two categories: social science studies and algorithmic ones. Social science studies of preference have found only small relationships between personality and category preferences, whereas, algorithmic approaches found a little improvement when incorporating personality into recommendations. As a result, despite good reasons to believe personality assessments should be useful in recommenders, we are left with no substantial demonstrated impact. In this work, we start with user data from a live recommender system, but study category-by-category variations in preference (both rating levels and distribution) across different personality types. By doing this, we hope to isolate specific areas where personality is most likely to provide value in recommender systems, while also modeling an analytic process that can be used in other domains. After controlling for the family-wise error rate, we find that High Agreeableness users rate at least 0.5 stars higher on a 5-star scale compared to low Agreeableness users. We also find differences in consumption in four different personality types between people who manifested high and low levels of that personality.", "references": ["Cantador, I., Fernández-Tobías, I., & Bellogín, A. 2013. Relating personality types with user preferences in multiple entertainment domains. In CEUR Workshop Proceedings, Shlomo Berkovsky.", "Chamorro-Premuzic, T., Kallias, A., & Hsu, A. 2013. Understanding individual differences in film preferences and uses: a psychographic approach. The Social Science of Cinema, 87.", "Chausson, O. 2010 Who watches what?: assessing the impact of gender and personality on film preferences. Paper published online on the MyPersonality project website http://mypersonality.org/wiki/doku.php"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959140"}, {"title": "Linking Organizational Social Network Profiles", "authors": ["Jerome Cheng\n,", "Kazunari Sugiyama\n,", "Min-Yen Kan"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany organizations possess social media accounts on different social networks, but these profiles are not always linked. End applications, users, as well as the organization themselves, can benefit when the profiles are appropriately identified and linked. Most existing works on social network entity linking focus on linking individuals, and do not model features specific for organizational linking. We address this gap not only to link official social media accounts but also to discover and solve the identification and linking of associated affiliate accounts -- such as geographical divisions and brands -- which are important to distinguish.\nWe instantiate our method for classifying profiles on social network services for Twitter and Facebook, which major organizations use. We classify profiles as to whether they belong to an organization or its affiliates. Our best classifier achieves an accuracy of 0.976 on average in both datasets, significantly improving baselines that exploit the features used in state-of-the-art comparable user linkage strategies.", "references": ["T. Iofciu, P. Fankhauser, F. Abel, and K. Bischoff. Identifying Users Across Social Tagging Systems. In Proc. of the 5th International AAAI Conference on Weblogs and Social Media (ICWSM-11), pages 522--525, 2011.", "X. Kong, J. Zhang, and P. S. Yu. Inferring Anchor Links across Multiple Heterogeneous Social Networks. In Proc. of the 22nd ACM International Conference on Information and Knowledge Management (CIKM'13), pages 179--188, 2013.", "A. Malhotra, L. C. Totti, W. Meira Jr, P. Kumaraguru, and V. Almeida. Studying User Footprints in Different Online Social Networks. In Proc. of the 2012 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2012), pages 1065--1070, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914698"}, {"title": "Quote Recommendation in Dialogue using Deep Neural Network", "authors": ["Hanbit Lee\n,", "Yeonchan Ahn\n,", "Haejun Lee\n,", "Seungdo Ha\n,", "Sang-goo Lee"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuotes, or quotations, are well known phrases or sentences that we use for various purposes such as emphasis, elaboration, and humor. In this paper, we introduce a task of recommending quotes which are suitable for given dialogue context and we present a deep learning recommender system which combines recurrent neural network and convolutional neural network in order to learn semantic representation of each utterance and construct a sequence model for the dialog thread. We collected a large set of twitter dialogues with quote occurrences in order to evaluate proposed recommender system. Experimental results show that our approach outperforms not only the other state-of-the-art algorithms in quote recommendation task, but also other neural network based methods built for similar tasks.", "references": ["M. Gasic, C. Breslin, M. Henderson, D. Kim, M. Szummer, B. Thomson, P. Tsiakoulis, and S. Young. On-line policy optimisation of bayesian spoken dialogue systems via human interaction. In ICASSP, 2013.", "Q. He, J. Pei, D. Kifer, P. Mitra, and C. L. Giles. Context-aware citation recommendation. In WWW, 2010.", "S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735--1780, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914734"}, {"title": "SORTIA 2.0: A sorting game for data structure teaching", "authors": ["Paulo E. Battistella\n,", "Giani Petri\n,", "Christiane G.V. Wangenheim\n,", "Aldo V. Wangenheim\n,", "Jean E. Martina"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe teach of sorting algorithms in data structure discipline of Computer courses, typically is accomplished through lectures and implementation of algorithms by students. With the aim of support the teaching algorithms, this paper presents the SORTIA 2.0 game, which aims to teach the Heapsort sorting algorithm through simulation of its execution. It is an online game, single player and free. To evaluate the game we used the model for assessment educational game MEEGA. The evaluation involved 25 students of the discipline of data structure of Computer Science course, of the Federal University of Santa Catarina (UFSC).The results of this first evaluation show that students felt satisfied, confident, immersed and have fun with the game, but principally consider that it really contributes to learning the discipline and also professionally.", "references": ["ACM/IEEE-CS. 2013. Computer Science Curricula 2013.Estados Unidos da America: ACM e IEEE Computer Society, p.514.", "Ministerio da Educacao. 2012. Diretrizes Curriculares Nacionais para Cursos de Graduacao em Computacao. Parecer CNE/CNS 136/2012.", "Choi, J. e Hannafin, M. 1995. Situated Cognition and Learning Environments: Roles, Structures and Implications for Design. Educational Technology Research and Development, 43(2), p. 53-69."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022049"}, {"title": "Music Playlist Recommendation Using Acoustic-Feature Transitions", "authors": ["Shobu Ikeda\n,", "Kenta Oku\n,", "Kyoji Kawagoe"], "publication": "C3S2E '16: Proceedings of the Ninth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nMusic is important in our daily life not only for entertainment but also for mental health. When listening to music, playlists are used to eliminate the need for individual selection. The creation of playlist is difficult and tedious for users and has been the topic of research in many studies. However, many proposed playlist generation methods are based on either similar acoustic features or meta-data similarities. In this study, we propose a new method for music playlist recommendation using acoustic feature transitions where the next song will be selected such that it naturally transitions from the current song. Our preliminary evaluations show that the proposed method is more effective compared with other methods such as random selection and nearest neighbor methods", "references": ["P. Cano, M. Koppenberger, N. Wack, An Industrial strength content-based music recommendation system, In Proceedings of ACM SIGIR Conference '05, pages 673--673, 2005.", "J-W. Ahn, X. Amatriain, Towards fully distributed and privacy-preserving recommendation via expert collaborative filtering and restful liked data, In Proceedings of IEEE/WIC/ACM International Conference on Web Intelligence - Intelligent Agent Technology Conference (WI-IAT'10), pages 66--73, 2010.", "K. Tada, R. Yamanishi, S. Kato, Interactive Music Recommendation System for Adapting Personal Affection, In Proceedings of International Conference on Entertainment Computing, Lecture Notes in Computer Science (LNCS), Vol. 7522, pages 417--510, Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2948992.2949005"}, {"title": "ThingSeek: A Crawler and Search Engine for the Internet of Things", "authors": ["Ali Shemshadi\n,", "Quan Z. Sheng\n,", "Yongrui Qin"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe rapidly growing paradigm of the Internet of Things (IoT) requires new search engines, which can crawl heterogeneous data sources and search in highly dynamic contexts. Existing search engines cannot meet these requirements as they are designed for traditional Web and human users only. This is contrary to the fact that things are emerging as major producers and consumers of information. Currently, there is very little work on searching IoT and a number of works claim the unavailability of public IoT data. However, it is dismissed that a majority of real-time web-based maps are sharing data that is generated by things, directly. To shed light on this line of research, in this paper, we firstly create a set of tools to capture IoT data from a set of given data sources. We then create two types of interfaces to provide real-time searching services on dynamic IoT data for both human and machine users.", "references": ["Christophe, B., Verdot, V., Toubiana, V.: Searching the web of things. In: Proceedings of the 5th IEEE International Conference on Semantic Computing (ICSC). pp. 308--315. IEEE (September 2011)", "Horowitz, D., Kamvar, S.: The anatomy of a large-scale social search engine. In: Proceedings of the 19th International World Wide Web Conference (WWW 2010). pp. 431--440. ACM (April 2010)", "Miorandi, D., Sicari, S., De Pellegrini, F., Chlamtac, I.: Internet of things: Vision, applications and research challenges. Ad Hoc Networks 10(7), 1497--1516 (2012)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911471"}, {"title": "Upcoming SIGWEB supported conferences", "authors": ["Hamman Samuel"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nThe Special Interest Group on Hypertext and the Web, SIGWEB was created in 1989 to support the community participating in the annual ACM Hypertext Conference. Now in its third decade, SIGWEB has grown considerably and now sponsors seven annual conferences of different sizes and covering a wide range of topics. SIGWEB supports several specialized conferences, short courses, and workshops, as well as the Annual Hypertext Conference. SIGWEB sponsored conferences focus on timely topics in applied and computational hypertext and Web disciplines and provide a place for members and the entire applied Hypermedia and Web community to exchange ideas and to meet with and expand their network of colleagues. In this article, we provide a brief overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SIGWEB.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2956573.2957816"}, {"title": "Assessing Review Recommendation Techniques under a Ranking Perspective", "authors": ["Luciana B. Maroun\n,", "Mirella M. Moro\n,", "Jussara M. Almeida\n,", "Ana Paula C. Silva"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nReading online reviews before a purchase is a customary action nowadays. Nevertheless, the increasing volume of reviews works as a barrier to their effectiveness so that many approaches try to predict reviews' quality, which is not standardized to all users due to different backgrounds and preferences. Thus, recommending reviews in a personalized fashion is probably more accurate. Here, we analyze methods for recommending reviews that have not been compared against each other yet. Our experiments consider parameter tuning and comparison through statistical tests. Such study allows to understand the state-of-the-art and to evidence potential improvement directions. Our results show that assessing under a ranking perspective, model simplicity and observed features are important traits for this problem, being Support Vector Regression the best solution.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. on Knowl. and Data Eng., 17(6):734--749, 2005.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Procs. of KDD, Paris, France, 2009.", "M. Anderson. Local consumer review survey 2014, 2014. https://www.brightlocal.com/2014/07/01/local-consumer-review-survey-2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914598"}, {"title": "A learning analytics tool with hybrid graphical and textual interpretation generation", "authors": ["Daniel Amo Filvà\n,", "Marc Alier\n,", "María José Casany\n,", "Enric Mayol"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nThe introduction and use of on-line learning resources has improved students learning process in several aspects. But at the same time, it also introduced more complexity and made more difficult to teachers how to analyze learning evolution and improvement of students. In this paper, we propose a first approach how to visualize and analyze student interaction with on-line learning systems and Virtual Learning Environments (VLE).\nWe present a piece of software that collects information on the interaction of the students with the Moodle VLE and that it displays to teachers in a more analytical way. The interaction data is displayed to support teacher interpretation from a learning point of view, with the inclusion of automatically generated textual explanations about the analysis of such data.", "references": ["Conde, M.A. Hernández-García, A.. A promised land for educational decision-making?: present and future of learning analytics. Proceeding TEEM '13 Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality Pages 239--243.", "Amo, D. (2013). MOOCs: experimental approaches for quality in pedagogical and design fundamentals. In Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality (pp. 219--223). ACM.", "Dierenfeld, H. & Merceron, A. (2012), Learning Analytics with Excel Pivot Tables. In Proceedings of the 1st Moodle Research Conference (MRC2012), Retalis, S. & Dougiamas, M. (Eds), 115--121."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012536"}, {"title": "Going back in Time: An Investigation of Social Media Re-finding", "authors": ["Florian Meier\n,", "David Elsweiler"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSocial Media (SM) has become a valuable information source to many in diverse situations. In IR, research has focused on real-time aspects and as such little is known about how long SM content is of value to users, if and how often it is re-accessed, the strategies people employ to re-access and if difficulties are experienced while doing so. We present results from a 5 month-long naturalistic, log-based study of user interaction with Twitter, which suggest re-finding to be a regular activity and that Tweets can offer utility for longer than one might think. We shed light on re-finding strategies revealing that remembered people are used as a stepping stone to Tweets rather than searching for content directly. Bookmarking strategies reported in the literature are used infrequently as a means to re-access. Finally, we show that by using statistical modelling it is possible to predict if a Tweet has future utility and is likely to be re-found. Our findings have implications for the design of social media search systems and interfaces, in particular for Twitter, to better support users re-find previously seen content.", "references": ["D. Barreau and B. A. Nardi, Finding and reminding: File organization from the desktop, SIGCHI Bull. 27 (1995), no. 3, 39--43.", "F. Benevenuto, T. Rodrigues, M. Cha, and V. Almeida, Characterizing user behavior in online social networks, Proc. IMC, ACM, 2009, pp. 49--62.", "d. boyd, S. Golder, and G. Lotan, Tweet, tweet, retweet: Conversational aspects of retweeting on twitter, Proc. HICSS, IEEE, 2010, pp. 1--10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911524"}, {"title": "Temporally enhanced network-constrained (TENC) R-tree", "authors": ["Mohammadhani Fouladgar\n,", "Ramez Elmasri"], "publication": "MobiGIS '16: Proceedings of the 5th ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems", "abstract": "ABSTRACT\nThis paper describes a new Network-constrained Moving objects indexing structure, which extends the state-of-the-art for this kind of data. The indexing structure we propose is called Temporally Enhanced Network-Constrained R-tree (TENC R-tree), which solves the shortcomings in other Network-Constrained access methods like the FNR-tree [7], MON-tree [1] and UTR-tree. These existing indexing methods are designed to store and retrieve the moving objects based on spatial features, followed by their temporal ones. They are generally not efficient when a query has only temporal constraints, or when a specific moving object id is also part of the query conditions. In such cases, existing methods have to scan the entire database to retrieve the result. Furthermore, the aforementioned methods are not efficient in processing Strict-path query, which is a query type that retrieves trajectories that follow all the edges in the queried path [10].\nOur proposed TENC R-tree index allows good performance for almost all types of queries on moving objects in a constrained network, whether the constraints are spatial, temporal, or based on object id. Also, the TENC R-tree out-performs other access methods on the case of Path queries. Our experiments show the performance has been improved by 10 to 100 times for such queries.", "references": ["V. T. De Almeida and R. H. Güting. Indexing the trajectories of moving objects in networks. GeoInformatica, 9(1):33--60, 2005.", "Z. Ding. Utr-tree: An index structure for the full uncertain trajectories of network-constrained moving objects. In The Ninth International Conference on Mobile Data Management (mdm 2008), pages 33--40. IEEE, 2008.", "Z. Ding and R. H. Guting. Managing moving objects on dynamic transportation networks. In Scientific and Statistical Database Management, 2004. Proceedings. 16th International Conference on, pages 287--296. IEEE, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3004725.3004736"}, {"title": "Editorial: Special Issue on Web Data Quality", "authors": ["Christian Bizer\n,", "Luna Dong\n,", "Ihab Ilyas\n,", "Maria-Esther Vidal"], "publication": "Journal of Data and Information Quality", "abstract": "", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3005395"}, {"title": "Structural Clustering of Machine-Generated Mail", "authors": ["Noa Avigdor-Elgrabli\n,", "Mark Cwalinski\n,", "Dotan Di Castro\n,", "Iftah Gamzu\n,", "Irena Grabovitch-Zuyev\n,", "Liane Lewin-Eytan\n,", "Yoelle Maarek"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSeveral recent studies have presented different approaches for clustering and classifying machine-generated mail based on email headers. We propose to expand these approaches by considering email message bodies. We argue that our approach can help increase coverage and precision in several tasks, and is especially critical for mail extraction. We remind that mail extraction supports a variety of mail mining applications such as ad re-targeting, mail search, and mail summarization. We introduce new structural clustering methods that leverage the HTML structure that is common to messages generated by a same mass-sender script. We discuss how such structural clustering can be conducted at different levels of granularity, using either strict or flexible matching constraints, depending on the use cases.\nWe present large scale experiments carried over real Yahoo mail traffic. For our first use case of automatic mail extraction, we describe novel flexible-matching clustering methods that meet the key requirements of high intra-cluster similarity, adequate clusters size, and relatively small overall number of clusters. We identify the precise level of flexibility that is needed in order to achieve extremely high extraction precision (close to 100%), while producing relatively small number of clusters. For our second use case, namely, mail classification, we show that strict structural matching is more adequate, achieving precision and recall rates between 85%-90%, while converging to a stable classification after a short learning cycle. This represents an increase of 10%-20% compared to the sender-based method described in previous work, when run over the same period length. Our work has been deployed in production in Yahoo mail backend.", "references": ["N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: Ranking and clustering. J. ACM, 55(5), 2008.", "N. Ailon, Z. S. Karnin, E. Liberty, and Y. Maarek. Threading machine generated email. In WSDM, pages 405--414, 2013.", "I. Alberts and D. Forest. Email pragmatics and automatic classification: A study in the organizational context. JASIST, 63(5):904--922, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983350"}, {"title": "Information Seeking and Evaluation of Online Sexual Health Resources among Late Adolescents", "authors": ["Summer Starling\n,", "Coye Cheshire"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nAdolescents increasingly rely on the Internet as a private resource for sexual health information. Despite growing interest in adults' use of online health resources in HCI, we lack a deeper understanding of adolescents' information-seeking processes and assessments of trustworthy online health information. We conducted a qualitative, observational study of late adolescents as they searched for sexual health and sexuality information and a \"think aloud\" protocol to concurrently capture user thoughts and perceptions of online content in situ. Our results reveal a four-phased process that late adolescent users employ for searching and evaluating sexual health information on the web, as well as several emergent themes regarding credible and trustworthy information.", "references": ["Kylene Guse, Deb Levine, Summer Martins, Andrea Lira, Jenna Gaarde, Whitney Westmorland, and Melissa Gilliam. 2012. Interventions using new digital media to improve adolescent sexual health: a systematic review. Journal of Adolescent Health 51, 6: 535--543.", "Michele Ybarra and Michael Suman. 2008. Reasons, assessments and actions taken: sex and age differences in uses of Internet health information. Health Education Research 23, 3: 512-521.", "Patrick Cheong-Iao Pang, Karin Verspoor, Jon Pearce, and Shanton Chang. 2015. Better Health Explorer: Designing for Health Information Seekers. In Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction (OzCHI '15), Bernd Ploderer, Marcus Carter, Martin Gibbs, Wally Smith, and Frank Vetere (Eds.). ACM, New York, NY, USA, 588--597. http://dx.doi.org/10.1145/2838739.2838772"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892528"}, {"title": "A Simple and Effective Approach to Score Standardisation", "authors": ["Tetsuya Sakai"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nWebber, Moffat and Zobel proposed score standardization for information retrieval evaluation with multiple test collections. Given a topic-by-run raw score matrix in terms of some evaluation measure, each score can be standardised using the topic's sample mean and sample standard deviation across a set of past runs so as to quantify how different a system is from the \"average\" system in standard deviation units. Using standardised scores, researchers can compare systems across different test collections without worrying about topic hardness or normalisation. WhileWebber et al. mapped the standardised scores to the [0, 1] range using a standard normal cumulative density function, the present study demonstrates that linear transformation of the standardised scores, a method widely used in educational research, can be a simple and effective alternative. We use three TREC robust track data sets with graded relevance assessments and official runs to compare these methods by means of leave-one-out tests, discriminative power, swap rate tests, and topic set size design. In particular, we demonstrate that our method is superior to the method of Webber et al. in terms of swap rates and topic set size design: put simply, our method ensures pairwise system comparisons that are more consistent across different data sets, and is arguably more convenient for designing a new test collection from a statistical viewpoint.", "references": ["B. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. ACM TOIS, 30(1), 2012.", "G. Cormack and T. Lynam. TREC 2005 spam track overview. In Proceedings of TREC 2005, 2006.", "P. D. Ellis. The Essential Guide to Effect Sizes. Cambridge University Press, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970399"}, {"title": "Phone call log as a context source to modeling individual user behavior", "authors": ["Iqbal H. Sarker\n,", "Alan Colman\n,", "Muhammad Ashad Kabir\n,", "Jun Han"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nMobile phone can record various types of context data related to a user's phone call activities in its call log. Call log provides temporal context to modeling individual user's phone call response behavior, i.e., when a user accepts, rejects or misses an incoming call. In this paper, we explore the potentiality of phone call log as a context source to modeling call response behavior of individual mobile users. Towards this, we present our initial work to generating temporal rules that capture the user's dominant call response behavior at various times of the day and days of the week, utilizing phone call log. Our preliminary experimental results on real datasets show that context information in call log can be used to model individual's phone call response behavior with high accuracy.", "references": ["A Khalil, K Connelly. 2005. Improving Cell Phone Awareness by Using Calendar Information. In Human-Computer Interaction-INTERACT, Springer, 588--600.", "Sin-seok Seo, Arum Kwon, Joon-Myung Kang, John Strassner, and James Won-Ki Hong, 2011. PYP Design and Implementation of a Context-Aware Configuration Manager for Smartphones, Proceedings of the 1st International Workshop on Smart Mobile Applications (SmartApps' 11).", "Muhammad Ashad Kabir, Jun Han, Jian Yu, and Alan Colman. 2014. User-centric social context information management: an ontology-based approach and platform. Personal Ubiquitous Computing. 18, 5 (June 2014), 1061--1083.", "Sina Zulkernain, Praveen Madiraju, Sheikh Iqbal Ahamed and Karl Stamm. 2010. A Mobile Intelligent Interruption Management System. Journal of Universal Computer Science (JUCS), 16, 15: 2060---2080.", "Vijay Srinivasan, Saeed Moghaddam, Abhishek Mukherji, Kiran K Rachuri, Chenren Xu and Emmanuel Munguia Tapia. 2014. MobileMiner: Mining Your Frequent Patterns on Your Phone, Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing, 389--400.", "Rakesh Agrawal and Ramakrishnan Srikant, 1994. Fast Algorithms for Mining Association Rules, Proceedings of the 20th International Conference on Very Large Databases (VLDB), 487--499."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2971592"}, {"title": "SoundGuides: Adapting Continuous Auditory Feedback to Users", "authors": ["Jules Françoise\n,", "Olivier Chapuis\n,", "Sylvain Hanneton\n,", "Frédéric Bevilacqua"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nWe introduce SoundGuides, a user adaptable tool for auditory feedback on movement. The system is based on a interactive machine learning approach, where both gestures and sounds are first conjointly designed and conjointly learned by the system. The system can then automatically adapt the auditory feedback to any new user, taking into account the particular way each user performs a given gesture. SoundGuides is suitable for the design of continuous auditory feedback aimed at guiding users' movements and helping them to perform a specific movement consistently over time. Applications span from movement-based interaction techniques to auditory-guided rehabilitation. We first describe our system and report a study that demonstrates a 'stabilizing effect' of our adaptive auditory feedback method.", "references": ["Fraser Anderson and Walter F Bischof. 2013. Learning and performance with gesture guides. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, Paris, France, 1109- 1118. DOI: http://dx.doi.org/10.1145/2470654.2466143", "Caroline Appert and Shumin Zhai. 2009. Using Strokes As Command Shortcuts: Cognitive Benefits and Toolkit Support. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09). ACM, Boston, USA, 2289-2298. DOI: http://dx.doi.org/10.1145/1518701.1519052", "Yoram Baram and Ariel Miller. 2007. Auditory feedback control for improvement of gait in patients with Multiple Sclerosis. Journal of the Neurological Sciences 254 (2007), 90-94. DOI: http://dx.doi.org/10.1016/j.jns.2007.01.003"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892420"}, {"title": "Towards Cross-domain MOOC Forum Post Classification", "authors": ["Aneesha Bakharia"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nPreliminary research is presented on the generalisability of confusion, urgency and sentiment classifiers for MOOC forum posts. The Stanford MOOCPosts data set is used to train classifiers with forum posts from individual courses and validate these classifiers on MOOC forum posts from other domain areas. While low cross-domain classification accuracy is achieved, the experiment highlights the need for transfer learning and domain adaptation algorithms; and provides insight into the types of algorithms required within an educational context.", "references": ["John Blitzer, Mark Dredze, Fernando Pereira, et al. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL, volume 7, pages 440--447, 2007.", "John Blitzer, Ryan McDonald and Fernando Pereira. Domain adaptation with structural correspondence learning. In the Proceedings of the Proceedings of the 2006 conference on empirical methods in natural language processing, pages 120--128. ACL, 2006.", "Vitomir Kovanovic, Dragan Gasevic, and Marek Hatala. Learning analytics for communities of inquiry. Journal of Learning Analytics, 1(3):195--198, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2893427"}, {"title": "User Experience Dimensions: A Systematic Approach to Experiential Qualities for Evaluating Information Interaction in Museums", "authors": ["Marianne Lykke\n,", "Christian Jantzen"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThe present study develops a set of 10 dimensions based on a systematic understanding of the concept of experience as a holistic psychological. Seven of these are derived from a psychological conception of what experiencing and experiences are. Three supplementary dimensions spring from the observation that experiences apparently have become especially valuable phenomena in Western societies. The 10 dimensions are tried out in a field study at the Center for Art and Media (ZKM) in Germany with the purpose to study their applicability in the evaluation of interactive sound archives. 29 walk-alongs were carried out with 58 museums visitors. Our analysis showed that it was possible to identify the 10 experience dimensions in the study material. Some dimensions were expressed more frequently than others. The distribution of expressed dimensions and the content of the user comments provided a clear picture of how the two sound archives differed in respect to the experiential qualities.", "references": ["Apter, M. J. 1989. Reversal theory: Motivation, emotion and personality. Taylor and Frances/Routledge, London.", "Bargas-Avila, J.A. and Hornbæk, K. 2011. Old Wine in New Bottles or Novel Challenges? A Critical Analysis of Empirical Studies of User Experience. In Proceedings of the CHI 2011 (Vancouver, Canada, May 07-12, 2011). ACM, New York, NY, 2689--2698. DOI=10.1145/1978942.1979336.", "Berntsen, D. and Rubin, D. C. 2012. Understanding autobiographical memory: Theories and approaches. Cambridge University Press, Cambridge."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854965"}, {"title": "Peer Grading in a Course on Algorithms and Data Structures: Machine Learning Algorithms do not Improve over Simple Baselines", "authors": ["Mehdi S.M. Sajjadi\n,", "Morteza Alamgir\n,", "Ulrike von Luxburg"], "publication": "L@S '16: Proceedings of the Third (2016) ACM Conference on Learning @ Scale", "abstract": "ABSTRACT\nPeer grading is the process of students reviewing each others' work, such as homework submissions, and has lately become a popular mechanism used in massive open online courses (MOOCs). Intrigued by this idea, we used it in a course on algorithms and data structures at the University of Hamburg. Throughout the whole semester, students repeatedly handed in submissions to exercises, which were then evaluated both by teaching assistants and by a peer grading mechanism, yielding a large dataset of teacher and peer grades. We applied different statistical and machine learning methods to aggregate the peer grades in order to come up with accurate final grades for the submissions (supervised and unsupervised, methods based on numeric scores and ordinal rankings). Surprisingly, none of them improves over the baseline of using the mean peer grade as the final grade. We discuss a number of possible explanations for these results and present a thorough analysis of the generated dataset.", "references": ["J. Dıez, O. Luaces, A. Alonso-Betanzos, A. Troncoso, and A. Bahamonde. 2013.Peer assessment in MOOCs using preference learning via matrix factorization. In NIPS Workshop on Data Driven Education.", "C. Kulkarni, K. P. Wei, H. Le, D. Chia, K. Papadopoulos, J. Cheng, D. Koller, and S. R. Klemmer. 2015.Peer and self assessment in massive online classes. In Design Thinking Research. 131--168.", "F. Mi and D.-Y. Yeung. 2015.Probabilistic graphical models for boosting cardinal and ordinal peer grading in MOOCs. In 29th AAAI Conference on Artificial Intelligence."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2876034.2876036"}, {"title": "For Your Eyes Only: Consuming vs. Sharing Content", "authors": ["Ram Meshulam\n,", "Roy Sasson"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThis paper analyzes two types of user interactions with online content: (1) private engagement with content, measured by page-views and click-through rate; and (2) social engagement, measured by the number of shares on Facebook as well as share-rate. Based on more than a billion data points across hundreds of publishers worldwide and two time periods, it is shown that the correlation between these signals is generally low. Potential reasons for the low correlation are discussed, and the notion of private-social dissonance is defined. A more in-depth analysis shows that the dissonance between private engagement and social engagement consistently depends on content category. Categories such as Sex, Crime and Celebrities have higher private engagement than social engagement. On the other hand, categories such as Books, Careers and Music have higher social engagement than private engagement. In addition to the offline analysis, a model which utilizes the different signals was trained and deployed on a live recommendation system. The resulting weights ranked the social signal lower than click-through rate. The results are relevant for publishers, content marketers, architects of recommendation systems and researchers who wish to use social signals in order to measure and predict user engagement.", "references": ["J. Berger and K. L. Milkman. What makes online content viral? Journal of Marketing Research, 49(2):192--205, 2012.", "C. Castillo, M. El-Haddad, J. Pfeffer, and M. Stempeck. Characterizing the life cycle of online news stories using social media reactions. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing (CSCW '14), pages 211--223, New York, New York, USA, 2014. ACM Press.", "A. Das Sarma, S. Si, E. F. Churchill, and N. Sundaresan. The \"expression gap\": Do you like what you share? In Proceedings of the 23rd International Conference on World Wide Web, WWW '14 Companion, pages 247--248, Republic and Canton of Geneva, Switzerland, 2014. International World Wide Web Conferences Steering Committee."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890094"}, {"title": "Utilizing semantic big data for realizing a national-scale infrastructure vulnerability analysis system", "authors": ["Sangkeun Lee\n,", "Supriya Chinthavali\n,", "Sisi Duan\n,", "Mallikarjun Shankar"], "publication": "SBD '16: Proceedings of the International Workshop on Semantic Big Data", "abstract": "ABSTRACT\nCritical Infrastructure systems (CIs) such as energy, water, transportation, and communication are highly interconnected and mutually dependent in complex ways. Robust modeling of CIs' interconnections is crucial to identify vulnerabilities in the CIs. We present a vision of national-scale Infrastructure Vulnerability Analysis System (IVAS) leveraging Semantic Big Data (SBD) tools, Big Data, and Geographical Information Systems (GIS) tools. We first survey existing approaches on vulnerability analysis of critical infrastructures and discuss relevant systems and tools aligned with our vision. Next, we present a generic system architecture and discuss challenges including: (1) Constructing and managing a CI network-of-networks graph, (2) Performing analytic operations at scale, and (3) Interactive visualization of analytic output to generate meaningful insights. We argue that this architecture acts as a baseline to realize a national-scale network based vulnerability analysis system.", "references": ["Homeland security infrastructure program (HSIP). https://gii.dhs.gov/HIFLD/hsip-guest.", "Linked Open Data statistics. http://stats.lod2.eu/.", "Maptitude: Geographic Information System. http://www.caliper.com/maptovu.htm."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2928294.2928295"}, {"title": "Automatic Entity Recognition and Typing in Massive Text Data", "authors": ["Xiang Ren\n,", "Ahmed El-Kishky\n,", "Heng Ji\n,", "Jiawei Han"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nIn today's computerized and information-based society, individuals are constantly presented with vast amounts of text data, ranging from news articles, scientific publications, product reviews, to a wide range of textual information from social media. To extract value from these large, multi-domain pools of text, it is of great importance to gain an understanding of entities and their relationships. In this tutorial, we introduce data-driven methods to recognize typed entities of interest in massive, domain-specific text corpora. These methods can automatically identify token spans as entity mentions in documents and label their fine-grained types (e.g., people, product and food) in a scalable way. Since these methods do not rely on annotated data, predefined typing schema or hand-crafted features, they can be quickly adapted to a new domain, genre and language. We demonstrate on real datasets including various genres (e.g., news articles, discussion forum posts, and tweets), domains (general vs. bio-medical domains) and languages (e.g., English, Chinese, Arabic, and even low-resource languages like Hausa and Yoruba) how these typed entities aid in knowledge discovery and management.", "references": ["R. K. Ando and T. Zhang. A high-performance semi-supervised learning method for text chunking. In ACL, 2005.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, 2008.", "A. Carlson, J. Betteridge, R. C. Wang, E. R. Hruschka Jr, and T. M. Mitchell. Coupled semi-supervised learning for information extraction. In WSDM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2912567"}, {"title": "Thinking Inside the Box: Compartmentalized Garbage Collection", "authors": ["Gregor Wagner\n,", "Per Larsen\n,", "Stefan Brunthaler\n,", "Michael Franz"], "publication": "ACM Transactions on Programming Languages and Systems", "abstract": "Abstract\nThe web browser is the “new desktop.” Not only do many users spend most of their time using the browser, the browser has also become host to rich and dynamic applications that were previously tailored to each individual operating system. The lingua franca of web scripting, JavaScript, was pivotal in this development.\nImagine that all desktop applications allocated memory from a single heap managed by the operating system. To reclaim memory upon application shutdown, all processes would then be garbage collected—not just the one being quit. While operating systems improved upon this approach long ago, this was how browsers managed memory until recently.\nThis article explores compartmentalized memory management, an approach tailored specifically to web browsers. The idea is to partition the JavaScript heap into compartments and allocate objects to compartments based on their origin. All objects in the same compartment reference each other direct, whereas cross-origin references go through wrapper objects.\nWe carefully evaluate our techniques using Mozilla’s Firefox browser—which now ships with our enhancements—and demonstrate the benefits of collecting each compartment independently. This simultaneously improves runtime performance (up to 36%) and reduces garbage collection pause times (up to 75%) as well as the memory footprint of the browser. In addition, enforcing the same-origin security policy becomes simple and efficient with compartments.", "references": ["Saleh E. Abdullahi and Graem A. Ringwood. 1998. Garbage collecting the Internet: A survey of distributed garbage collection. Computing Surveys 30, 330--373. http://doi.acm.org/10.1145/292469.292471.", "Alexander Aiken, Manuel Fähndrich, and Raph Levien. 1995. Better static memory management: Improving region-based analysis of higher-order languages. In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI’95). ACM Press, New York, NY, 174--185. DOI:http://dx.doi.org/10.1145/207110.207137", "A. W. Appel. 1989. Simple generational garbage collection and fast allocation. Software—Practice and Experience 19, 2, 171--183. DOI:http://dx.doi.org/10.1002/spe.4380190206"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2866576"}, {"title": "Construction of discriminant model of web documents suitability as search results", "authors": ["Hikari Suganuma\n,", "Takamitsu Shioi\n,", "Kenji Hatano"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nIn the research field of Web search engine development, the most important challenge is to extract more information from queries issued to Web search engines. However, the number of words in these queries tends to be small, so that it is difficult to extract information from them. Therefore, some researchers have focused on developing techniques, such as Web spam detection methods, that discriminate Web documents that do not constitute satisfactory search results.\nIn this paper, we propose a method for constructing a discriminant model for determining whether Web documents constitute suitable or unsuitable search results of Web search engines. In contrast to current Web spam detection techniques, our method analyzes the characteristics of the Web documents quantitatively and eliminates the documents that are estimated to be unsuitable search results. Our experimental results show that our discriminant model can help to improve the effectiveness of Web search engines and the efficiency of Web document discriminators as compared to current Web spam detection techniques.", "references": ["C. J. C. Burges. A Tutorial on Support Vector Machines for Pattern Recognition. Data Mining and Knowledge Discovery, 2(2):121--167, 1998.", "J. Cohen. Statistical Power Analysis for the Behavioral Sciences. Routledge Academic, 2nd edition, 1988.", "K. Eguchi, K. Oyama, A. Aizawa, and H. Ishikawa. Overview of WEB Task at the Fourth NTCIR Workshop. In Proceedings of the Fourth NTCIR Workshop, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011204"}, {"title": "System And User Centered Evaluation Approaches in Interactive Information Retrieval (SAUCE 2016)", "authors": ["Heather L. O'Brien\n,", "Nicola Ferro\n,", "Hideo Joho\n,", "Dirk Lewandowski\n,", "Paul Thomas\n,", "Keith van Rijsbergen"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nThe purpose of this half-day workshop is to bring together academic and industry interactive information retrieval (IIR) researchers with an interest in evaluation methodologies. The workshop articulates contemporary challenges in the investigation of IIR and invites user- and system-oriented researchers to work collaboratively to address these challenges by combining user- and system-centered methodologies in meaningful ways. We anticipate that this workshop will initiate productive knowledge exchange and partnerships that can respond to the increasing user, task, system, and contextual complexity of the IIR field.", "references": ["Agosti, M., Fuhr, N., Toms, E.G. and Vakkari, P. 2013. Evaluation Methodologies in Information Retrieval (Dagstuhl Seminar 13441). Dagstuhl Report. 3, 10 (2013), 92--126. Available, http://drops.dagstuhl.de/opus/volltexte/2014/4433/.", "Arapakis, I. Lalmas, M., Cambazoglu, B. B., Marcos, M.-C. and Jose, J.M. 2014. User engagement in online news: Under the scope of sentiment, interest, affect, and gaze. J. Assoc. Inform. Sci. Tech. 65, 10 (March. 2014), 1988--2005. DOI: 10.1002/asi.23096.", "Chuklin, A., Markov, I. and de Rijke, M. 2015. Click Models for Web Search. Morgan & Claypool Publishers, USA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2886106"}, {"title": "A Practical and Sustainable Model for Learning and Teaching Data Science", "authors": ["Bina Ramamurthy"], "publication": "SIGCSE '16: Proceedings of the 47th ACM Technical Symposium on Computing Science Education", "abstract": "ABSTRACT\nThis paper details our experiences with design and implementation of data science curriculum at University at Buffalo (UB). We discuss (i) briefly the history of project, (ii) a certificate program that we created, (iii) a data-intensive computing course that forms the core of the curriculum and (iv) some of the challenges we faced and how we addressed them. Major goal of the project was to improve the preparedness of our workforce for the emerging data-intensive computing area. We measured this through assessment of student learning on various concepts and topics related to data-intensive computing. We also discuss the best practices in building a data science program. We highlight the importance of external funding support and multi-disciplinary collaborations in the success of the project. The pedagogical resources created for the project are freely available to help educators and other learners navigate the path to learning data science. We expect this paper about our experience will provide a road map for educators who desire to introduce data science in their curriculum.", "references": ["ACM Student Research Competition 2015, http://src.acm.org/, Last viewed Aug. 2015.", "Amazon Web Services: Cloud Computing Services, aws.amazon.com, last viewed August 2015.", "Apache Hadoop. https://hadoop.apache.org/, August 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2839509.2844603"}, {"title": "A Systematic Literature Review on Communication in the Context of Project Management of Information Systems", "authors": ["Vinicius Maretti\n,", "Paulo Afonso Junior\n,", "Heitor Costa"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nCommunication is a critical factor that directly influences on the project's success, no matter its type or the industry type it is within. However, many IT professionals end up ignoring its importance and focusing on technical skills. Taking in consideration the lack of material and its dissemination amongst the various other scientific works, the main goal was, through a systematic literature review, to compile the many sources regarding the Communication Practices in Software Project Management. As result, main techniques, tools and challenges were discussed, quantitatively and qualitatively, in a way that project management professionals will be able either to use this work as a guide to future researches or to help on decision-making in subjects concerning the communication on software projects.", "references": ["Atallah, N. A.; Castro, A. A. Revisoes Sistematicas da Literatura e Metanalise: A Melhor Forma de Evidencia para Tomada de Decisao em Saude e a Maneira mais Rapida de Atualizacao Terapeutica. In: Diagnostico e Tratamento. v.2, n.2. pp.12-15. 1997.", "Bailey, J.; Zhang, C.; Budgen, D.; Charters, S.; Turner, M. Search Engine Overlaps: Do They Agree or Disagree? In: Second International Workshop on Realising EvidenceBased Software Engineering. pp. 2-2. 2007.", "Fan, D. Analysis of Critical Success Factors in IT Project Management. In: International Conference on Industrial and Information Systems. pp. 487-490. IEEE. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021970"}, {"title": "Ontology-Based Search of Genomic Metadata", "authors": ["Javier D. Fernandez\n,", "Maurizio Lenzerini\n,", "Marco Masseroli\n,", "Francesco Venco\n,", "Stefano Ceri"], "publication": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "abstract": "Abstract\nThe Encyclopedia of DNA Elements (ENCODE) is a huge and still expanding public repository of more than 4,000 experiments and 25,000 data files, assembled by a large international consortium since 2007; unknown biological knowledge can be extracted from these huge and largely unexplored data, leading to data-driven genomic, transcriptomic, and epigenomic discoveries. Yet, search of relevant datasets for knowledge discovery is limitedly supported: metadata describing ENCODE datasets are quite simple and incomplete, and not described by a coherent underlying ontology. Here, we show how to overcome this limitation, by adopting an ENCODE metadata searching approach which uses high-quality ontological knowledge and state-of-the-art indexing technologies. Specifically, we developed S.O.S. GeM (http://www.bioinformatics.deib.polimi.it/SOSGeM/), a system supporting effective semantic search and retrieval of ENCODE datasets. First, we constructed a Semantic Knowledge Base by starting with concepts extracted from ENCODE metadata, matched to and expanded on biomedical ontologies integrated in the well-established Unified Medical Language System. We prove that this inference method is sound and complete. Then, we leveraged the Semantic Knowledge Base to semantically search ENCODE data from arbitrary biologists’ queries. This allows correctly finding more datasets than those extracted by a purely syntactic search, as supported by the other available systems. We empirically show the relevance of found datasets to the biologists’ queries.", "references": ["E. C. Hayden, \"Technology: The $1,000 genome,\" Nature, vol. 507, no. 7492, pp. 294-295, 2014.", "C. Sheridan, \"Illumina claims $1,000 genome win,\" Nat. Biotechnol., vol. 32, no. 2, p. 115, 2014.", "1000 Genomes Project Consortium et al., \"A map of human genome variation from population-scale sequencing,\" Nature, vol. 467, no. 7319, pp. 1061-1073, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TCBB.2015.2495179"}, {"title": "Web Service Selection using Semantic Matching", "authors": ["Lalit Purohit\n,", "Sandeep Kumar"], "publication": "AICTC '16: Proceedings of the International Conference on Advances in Information Communication Technology & Computing", "abstract": "ABSTRACT\nWeb services are becoming a common and convenient means of doing business over the Internet. More-and-more web services are kept on arriving over the Internet, offering the same set of services to the end users. The availability of similar web services increases the complexity of discovery as well as the selection process of web services. The traditional way of discovery of web service involves keyword based searching followed by manual selection. The keyword based search is not efficient. In this paper, we have used an improved mechanism for web service selection based on Input as well as Output(IO) information of web services. The IO information of web services is obtained from OWL-S ontology. The results obtained by conducting experiments, indicate that there is a notable improvement in the search of the desired Web Service, using IO based matchmaking over keyword based search. This subsequently leads to better end user satisfaction and automation of web service selection task.", "references": ["Apache. Jena: Java framework for building semantic web applications, http://jena.sourceforge.net/.", "M. Ariba, International Business Machines Corporation. Web services description language (wsdl), http://www.w3.org/tr/wsdl.", "S. Divya, S. K. Dixit, and S. Kumar. A system for web service selection based on qos. In proceedings of International Conference on Information Systems and Computer Networks(ISCON), pages 139--144. IEEE, March 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2979779.2979795"}, {"title": "Incorporating Risk-Sensitiveness into Feature Selection for Learning to Rank", "authors": ["Daniel Xavier De Sousa\n,", "Sérgio Daniel Canuto\n,", "Thierson Couto Rosa\n,", "Wellington Santos Martins\n,", "Marcos André Gonçalves"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLearning to Rank (L2R) is currently an essential task in basically all types of information systems given the huge and ever increasing amount of data made available. While many solutions have been proposed to improve L2R functions, relatively little attention has been paid to the task of improving the quality of the feature space. L2R strategies usually rely on dense feature representations, which contain noisy or redundant features, increasing the cost of the learning process, without any benefits. Although feature selection (FS) strategies can be applied to reduce dimensionality and noise, side effects of such procedures have been neglected, such as the risk of getting very poor predictions in a few (but important) queries. In this paper we propose multi-objective FS strategies that optimize both aspects at the same time: ranking performance and risk-sensitive evaluation. For this, we approximate the Pareto-optimal set for multi-objective optimization in a new and original application to L2R. Our contributions include novel FS methods for L2R which optimize multiple, potentially conflicting, criteria. In particular, one of the objectives (risk-sensitive evaluation) has never been optimized in the context of FS for L2R before. Our experimental evaluation shows that our proposed methods select features that are more effective (ranking performance) and low-risk than those selected by other state-of-the-art FS methods.", "references": ["L. Breiman. Random Forests. Machine Learning, 2001.", "J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. SIGIR, 1998.", "A. M. et al. Web-search ranking with initialized gradient boosted regression trees. JMLR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983792"}, {"title": "Recommending for the World", "authors": ["Justin Basilico\n,", "Yves Raimond"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe Netflix experience is driven by a number of recommendation algorithms: personalized ranking, page generation, similarity, ratings, search, etc. On the January 6th, 2016 we simultaneously launched Netflix in 130 new countries around the world, which brought the total to over 190 countries. Preparing for such a rapid expansion while ensuring each algorithm was ready to work seamlessly created new challenges for our recommendation and search teams. In this talk, we will highlight the four most interesting challenges we encountered in making our algorithms operate globally and how this improved our ability to connect members worldwide with stories they'll love. In particular, we will dive into the problems of uneven availability across catalogs, balancing personal and cultural tastes, handling language, and tracking quality of recommendations. Uneven catalog availability is a challenge because many recommendation algorithms assume that people could interact with any item and then use the absence of interaction implicitly or explicitly as negative information in the model. However, this assumption does not hold globally and across time where item availability differs. Running algorithms globally means needing a notion of location so that we can handle local variations in taste while also providing a good basis for personalization. Language is another challenge in recommending video content because people can typically only enjoy content that has assets (audio, subtitles) in languages they understand. The preferences for how people enjoy such content also vary between people and depend on their familiarity with a language. Also, while would like our recommendations to work well for every one of our members, tracking quality becomes difficult because with so many members in so many countries speaking so many languages, it can be hard to determine when an algorithm or system is performing sub-optimally for some subset of them. Thus, to support this global launch, we examined each and every algorithm that is part of our service and began to address these challenges.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959121"}, {"title": "MASPHID: A Model to Assist Screen Reader Users for Detecting Phishing Sites Using Aural and Visual Similarity Measures", "authors": ["Gunikhan Sonowal\n,", "K. S. Kuppusamy"], "publication": "ICIA-16: Proceedings of the International Conference on Informatics and Analytics", "abstract": "ABSTRACT\nPhishing is one of the major issues in cyber security. In phishing, attackers steal sensitive information from users by impersonation of legitimate websites. This information captured by phisher is used for variety of scenarios such as buying goods using online transaction illegally or sometime may sell the collected user data to illegal sources. Till date, various detection techniques are proposed by different researchers but still phishing detection remains a challenging problem. While phishing remains to be a threat for all users, persons with visual impairments fall under the soft target category, as they primarily depend on the non-visual web access mode. The persons with visual impairments solely depends on the audio generated by the screen readers to identify and comprehend a web page. This weak-link shall be harnessed by attackers in creating impersonate sites that produces same audio output but are visually different. This paper proposes a model titled \"MASPHID\" (Model for Assisting Screenreader users to Phishing Detection) to assist persons with visual impairments in detecting phishing sites which are aurally similar but visually dissimilar. The proposed technique is designed in such a manner that phishing detection shall be carried out without burdening the users with technical details. This model works against zeroday phishing attack and evaluate high accuracy.", "references": ["S. Afroz and R. Greenstadt. Phishzoo: Detecting phishing websites by looking at them. In Semantic Computing (ICSC), 2011 Fifth IEEE International Conference on, pages 368--375, 2011.", "APWG. Anti-phishing work group. http://www.antiphishing.org/, Access on 1 June 2016.", "Y. Cao, W. Han, and Y. Le. Anti-phishing based on automated individual white-list. In Proceedings of the 4th ACM Workshop on Digital Identity Management, DIM '08, pages 51--60. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2980258.2980443"}, {"title": "A Platform for Streaming Push Notifications to Mobile Assessors", "authors": ["Adam Roegiest\n,", "Luchen Tan\n,", "Jimmy Lin\n,", "Charles L.A. Clarke"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present an assessment platform for gathering online relevance judgments for mobile push notifications that will be deployed in the newly-created TREC 2016 Real-Time Summarization (RTS) track. There is emerging interest in building systems that filter social media streams such as tweets to identify interesting and novel content in real time, putatively for delivery to users' mobile phones. In our evaluation design, all participants subscribe to the Twitter streaming API to identify relevant tweets with respect to a set of interest profiles. As the systems generate results, they are pushed in real time to our evaluation broker via a REST API. The broker then \"routes\" the tweets to assessors who have installed a custom app on their mobile phones. We detail the design of this platform and discuss a number of challenges that need to be tackled in this type of \"Living Labs\" setup. It is our goal that such an evaluation design will mitigate any issues that have arisen in traditional batch-style evaluations of this type of task.", "references": ["J. Aslam, M. Ekstrand-Abueg, V. Pavlu, F. Diaz, R. McCreadie, and T. Sakai. TREC 2014 Temporal Summarization Track overview. TREC, 2014.", "A. Hanbury, H. Müller, K. Balog, T. Brodt, G. V. Cormack, I. Eggel, T. Gollub, F. Hopfgartner, J. Kalpathy-Cramer, N. Kando, A. Krithara, J. Lin, S. Mercer, and M. Potthast. Evaluation-as-a-Service: Overview and outlook. arXiv:1512.07454, 2015.", "J. Lin, M. Efron, Y. Wang, G. Sherman, and E. Voorhees. Overview of the TREC-2015 Microblog Track. TREC, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911463"}, {"title": "Spatially Localized Visual Dictionary Learning", "authors": ["Valentin Leveau\n,", "Alexis Joly\n,", "Olivier Buisson\n,", "Patrick Valduriez"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper addresses the challenge of devising new representation learning algorithms that overcome the lack of interpretability of classical visual models. Therefore, it introduces a new recursive visual patch selection technique built on top of a Shared Nearest Neighbors embedding method. The main contribution of the paper is to drastically reduce the high-dimensionality of such over-complete representation thanks to a recursive feature elimination method. We show that the number of spatial atoms of the representation can be reduced by up to two orders of magnitude without much degrading the encoded information. The resulting representations are shown to provide competitive image classification performance with the state-of-the-art while enabling to learn highly interpretable visual models.", "references": ["A. Krizhevsky, et al. Imagenet classification with deep convolutional neural networks. In NIPS'12.", "J. Philbin et al. Lost in quantization: Improving particular object retrieval in large scale image databases. In CVPR'08.", "S. Romberg et al. Scalable logo recognition in real-world images. In ICMR'11."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912070"}, {"title": "LambdaFM: Learning Optimal Ranking with Factorization Machines Using Lambda Surrogates", "authors": ["Fajie Yuan\n,", "Guibing Guo\n,", "Joemon M. Jose\n,", "Long Chen\n,", "Haitao Yu\n,", "Weinan Zhang"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nState-of-the-art item recommendation algorithms, which apply Factorization Machines (FM) as a scoring function and pairwise ranking loss as a trainer (PRFM for short), have been recently investigated for the implicit feedback based context-aware recommendation problem (IFCAR). However, good recommenders particularly emphasize on the accuracy near the top of the ranked list, and typical pairwise loss functions might not match well with such a requirement. In this paper, we demonstrate, both theoretically and empirically, PRFM models usually lead to non-optimal item recommendation results due to such a mismatch. Inspired by the success of LambdaRank, we introduce Lambda Factorization Machines (LambdaFM), which is particularly intended for optimizing ranking performance for IFCAR. We also point out that the original lambda function suffers from the issue of expensive computational complexity in such settings due to a large amount of unobserved feedback. Hence, instead of directly adopting the original lambda strategy, we create three effective lambda surrogates by conducting a theoretical analysis for lambda from the top-N optimization perspective. Further, we prove that the proposed lambda surrogates are generic and applicable to a large set of pairwise ranking loss functions. Experimental results demonstrate LambdaFM significantly outperforms state-of-the-art algorithms on three real-world datasets in terms of four standard ranking measures.", "references": ["Baltrunas. Incarmusic: Context-aware music recommendations in a car. In EC-Web, pages 89--100, 2011.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML, pages 89--96, 2005.", "Z. Cao, T. Qin, T. Liu, M. Tsai, and H. Li. Learning to rank: from pairwise approach to listwise approach. In ICML, pages 129--136, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983758"}, {"title": "Quit While Ahead: Evaluating Truncated Rankings", "authors": ["Fei Liu\n,", "Alistair Moffat\n,", "Timothy Baldwin\n,", "Xiuzhen Zhang"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany types of search tasks are answered through the computation of a ranked list of suggested answers. We re-examine the usual assumption that answer lists should be as long as possible, and suggest that when the number of matching items is potentially small -- perhaps even zero -- it may be more helpful to \"quit while ahead\", that is, to truncate the answer ranking earlier rather than later. To capture this effect, metrics are required which are attuned to the length of the ranking, and can handle cases in which there are no relevant documents. In this work we explore a generalized approach for representing truncated result sets, and propose modifications to a number of popular evaluation metrics.", "references": ["C. Buckley and E. M. Voorhees. Retrieval system evaluation. In E. M. Voorhees and D. K. Harman, editors, TREC: Experiment and Evaluation in Information Retrieval, chapter 3, pages 53--75. MIT Press, 2005.", "Järvelin and J. Kekäläinen. Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Sys., 20 (4): 422--446, 2002.", "A. Moffat and J. Zobel. Rank-biased precision for measurement of retrieval effectiveness. ACM Trans. Inf. Sys., 27 (1): 2:1--2:27, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914737"}, {"title": "What Belongs Together Comes Together: Activity-centric Document Clustering for Information Work", "authors": ["Alexander Seeliger\n,", "Benedikt Schmidt\n,", "Immanuel Schweizer\n,", "Max Mühlhäuser"], "publication": "IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces", "abstract": "ABSTRACT\nMultitasking and interruptions in information work make frequent activity switches necessary. Individuals need to recall and restore earlier states of work which generally involves retrieval of information objects. To avoid resulting tooling time an activity-centric organization of information objects has been proposed. For each activity a collection with related information objects (like documents, websites etc.) is created to improve information access and serve as a memory aid. While the manual maintenance of such information collections is a tedious task and becomes an interruption on its own, the automatic maintenance of such collections using activity mining is promising. Activity mining utilizes interaction histories to extract unique activities based on the stream of interaction with information objects. For activity mining, existing work shows varying success in limited study setups. In this paper, we present a method for activity mining to generate activity-centric information object collections automatically from interaction histories. The technique is a hybrid approach considering all information types used in previous work -- activity stream and accessed content related information. Method performance is evaluated based on interaction histories collected during real work data from eight information workers collected over several weeks. For the dataset our hybrid approach shows on average a performance of 0.53 ARI up to 0.77 ARI, outperforming single metric-based approaches.", "references": ["Bailey, B. P., and Konstan, J. A. On the need for attention-aware systems: Measuring effects of interruption on task performance, error rate, and affective state. Computers in Human Behavior 22 (2006), 685--708.", "Bellotti, V. Managing Activities with TV-ACTA : TaskVista and ActivityCentered Task Assistant. In Personal Information Management Workshop, ACM Press (2006), 8--11.", "Berry, M., Dumais, S., and O'Brien, G. Using linear algebra for intelligent information retrieval. SIAM review, December (1995).", "Blei, D., Ng, A., and Jordan, M. Latent dirichlet allocation. the Journal of machine Learning research 3 (2003), 993--1022.", "Brdiczka, O., Su, N., and Begole, J. Temporal task footprinting: identifying routine tasks by their temporal patterns. In Proceedings of the 15th international conference on Intelligent user interfaces, ACM Press (2010).", "Fowlkes, E. B., and Mallows, C. L. A Method for Comparing Two Hierarchical Clusterings. Journal of the American Statistical Association 78 (1983), 553--569.", "González, V., and Mark, G. Constant, constant, multi-tasking craziness: managing multiple working spheres. In Proceedings of the SIGCHI conference on Human factors in computing systems, vol. 6, ACM Press (2004), 113--120.", "Hastie, T., Tibshirani, R., and Friedman, J. The elements of statistical learning. 2009.", "Hubert, L., and Arabie, P. Comparing partitions. Journal of Classification 2, 1 (1985), 193--218.", "Iqbal, S. T., and Horvitz, E. Disruption and recovery of computing tasks: Field study, analysis, and directions. In Proc. CHI 2007, ACM (2007), 677--686.", "Jeuris, S., Houben, S., and Bardram, J. Laevo: A temporal desktop interface for integrated knowledge work. In Proc. UIST 2014, ACM (2014), 679--688.", "Kaptelinin, V. UMEA: translating interaction histories into project contexts. In Proceedings of the SIGCHI conference on Human factors in computing systems, no. 5, ACM Press (2003), 353--360.", "Kennedy, J. Particle swarm optimization. Encyclopedia of Machine Learning 4 (2010), 1942--1948.", "Landauer, T. K., Foltz, P. W., and Laham, D. An introduction to latent semantic analysis. Discourse Processes 25, 2-3 (Jan. 1998), 259--284.", "Manning, C. D., Raghavan, P., and Schütze, H. Introduction to Information Retrieval, vol. 1. 2008.", "Oliver, N., Smith, G., Thakkar, C., and Surendran, A. C. Swish: Semantic analysis of window titles and switching history. In Proc. IUI 2006, ACM (2006), 194--201.", "Rajaraman, A., and Ullman, J. D. Data mining. In Mining of Massive Datasets. Cambridge University Press, 2011, 1--17. Cambridge Books Online.", "Rand, W. M. Objective Criteria for the Evaluation of Clustering Methods. Journal of the American Statistical Association 66 (1971), 846--850.", "Rattenbury, T. An activity based approach to context-aware computing. PhD thesis, 2008.", "Reinhardt, W., Schmidt, B., Sloep, P., and Drachsler, H. Knowledge Worker Roles and Actions - Results of Two Empirical Studies. Knowledge and Process Management 18, 3 (2011), 150--174.", "Schmidt, B. Information Work Support Based on Activity Data. PhD thesis, TU Darmstadt, Mai 2013.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856767.2856777"}, {"title": "The effectiveness of user-centric social interfaces on evaluating mobile recommendations", "authors": ["Jaewon Choi\n,", "Hong Joo Lee"], "publication": "ICEC '16: Proceedings of the 18th Annual International Conference on Electronic Commerce: e-Commerce in Smart connected World", "abstract": "ABSTRACT\nMany studies on recommender systems have focused on increasing their accuracy by enhancing the algorithms employed. Social perceptions, however, influence both satisfaction and perceived accuracy of mobile recommender systems. Thus, the aim of this study was to investigate the importance of including reasons for particular recommendations by examining the role of social presence and self-reference and their effects on user evaluations of mobile recommender systems. We performed a 2 x 2 experimental setting (Four experimental web pages with user-to-user and item-to-item collaborative filtering) which was used to manipulate customer perception of accuracy through social presence and self-reference. Social presence and self-reference were shown to be antecedents of perceived accuracy of mobile recommender systems. Additionally, perceived accuracy appeared to be a partial mediator of the relationship between social presence and satisfaction, whereas perceived accuracy appeared to be a full mediator of the relationship between self-reference and satisfaction.", "references": ["Aboud, F. E., Mendelson, M. J. (1996). Determinants of Friendship Selection and Quality: Developmental Perspectives (In W. M. Bukowski, A. F. Newcomb, and W. W. Hartup (Eds.) ed.): Cambridge: Cambridge University Press.", "Adomavicius, G., Tuzhilin, A. (2005). Personalization Technologies: A Process-oriented Perspective. Communications of the ACM, 48 (10), 83--90.", "Al-Natour, S., Benbasat, I., Cenfetelli, R. T. (2008). The Effects of Process and Outcome Similarity on Users' Evaluations of Decision Aids. Decision Sciences, 39 (2), 175--211."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2971603.2971622"}, {"title": "Improving Entity Ranking for Keyword Queries", "authors": ["John Foley\n,", "Brendan O'Connor\n,", "James Allan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nKnowledge bases about entities are an important part of modern information retrieval systems. A strong ranking of entities can be used to enhance query understanding and document retrieval or can be presented as another vertical to the user. Given a keyword query, our task is to provide a ranking of the entities present in the collection of interest. We are particularly interested in approaches to this problem that generalize to different knowledge bases and different collections. In the past, this kind of problem has been explored in the enterprise domain through Expert Search. Recently, a dataset was introduced for entity ranking from news and web queries from more general TREC collections.\nApproaches from prior work leverage a wide variety of lexical resources: e.g., natural language processing and relations in the knowledge base. We address the question of whether we can achieve competitive performance with minimal linguistic resources.\nWe propose a set of features that do not require index-time entity linking, and demonstrate competitive performance on the new dataset. As this paper is the first non-introductory work to leverage this new dataset, we also find and correct certain aspects of the benchmark. To support a fair evaluation, we collect 38% more judgments and contribute annotator agreement information.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "K. Balog, L. Azzopardi, and M. De Rijke. Formal models for expert finding in enterprise corpora. In SIGIR'06, pages 43--50.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Foundations and Trends in Information Retrieval, 6(2--3):127--256, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983909"}, {"title": "Pattern-based Unsupervised Induction Of Yorùbá Morphology", "authors": ["Tunde Adegbola"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nThe Unsupervised induction of morphological rules from a simple list of words in a language of interest is a productive approach to Computational Morphology. The most popular algorithms used for this purpose in the literature are based on the assumption that the relatively high occurrence frequencies of certain word segments described as recurrent partials in a lexicon suggests the existence of morpheme boundaries around such high frequency word segments. Even though this word-segment-frequency approach works well for concatenative morphology, it does not cater for some of the most productive morphological processes in Yorùbá and some other African languages. In this paper, unsupervised induction of the morphological rules of Yorùbá was achieved based on a word-pattern-frequency rather than a word-segment-frequency approach. Words in a Yorùbá lexicon were clustered according to the morphological processes on which their formation are based, producing results that hitherto were achievable only by painstaking rule-based manual classification.", "references": ["K. Koskienniemi, \"Two Level Morphology: A General Computational Model-Form Recognition and Production,\" University of Helsinki, 1983.", "K. R. Beesley and L. Kartunen, Finite State Morphology, California: CSLI Publications, 2003.", "Z. Haris, \"From Phoneme to Morpheme,\" Language, pp. 192--222, 1955."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890563"}, {"title": "Session details: Technical Session: Memory Management", "authors": ["John Criswell"], "publication": "VEE '16: Proceedings of the12th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3247415"}, {"title": "Learning Web Queries for Retrieval of Relevant Information about an Entity in a Wikipedia Category", "authors": ["Vikrant Yadav\n,", "Sandeep Kumar"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIn this paper, we present a novel method to obtain a set of most appropriate queries for retrieval of relevant information about an entity from the Web. Using the body text of existing articles in a Wikipedia category, we generate a set of queries capable of fetching the most relevant content for any entity belonging to that category. We find the common topics discussed in the articles of a category using Latent Semantic Analysis (LSA) and use them to formulate the queries. Using Long Short-Term Memory (LSTM) neural network, we reduce the number of queries by removing the less sensible ones and then select the best ones out of them. The experimental results show that the proposed method outperforms the baselines. Existing approaches are performing better in generation of the relevant section title queries by extraction from the headings of the Wikipedia articles as compared to the generation of queries by extraction from the body text of the articles. Whereas, the experimental results show that the proposed approach can perform equally well and even better in extraction of the relevant queries from the body text of the Wikipedia articles.", "references": ["Sauper, C., and Barzilay, R. 2009. Automatically Generating Wikipedia Articles: A Structure-aware Approach. In Proc. of the Joint Conf. of the 47th Annual Meeting of the ACL and the 4th Intl Joint Conf. on NLP of the AFNLP: Volume 1 - Volume 1, pages 208--216", "Tanaka, S., Okazaki, N., and Ishizuka, M. 2010. Learning Web Query Patterns for Imitating Wikipedia Articles. In Proc. of 23rd Intl Conf. On Computational Linguistics (COLING 2010) -- Poster Volume, pp. 1229--1237.", "Sutskever, I., Martens, J., and Hinton, G. Generating Text with Recurrent Neural Networks. ICML 2011"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891114"}, {"title": "SimCC-AT: A Method to Compute Similarity of Scientific Papers with Automatic Parameter Tuning", "authors": ["Masoud Reyhani Hamedani\n,", "Sang-Wook Kim"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we propose SimCC-AT (similarity based on content and citations with automatic parameter tuning) to compute the similarity of scientific papers. As in SimCC, the state-of-the-art method, we exploit a notion of a contribution score in similarity computation. SimCC-AT utilizes an automatic weighting scheme based on SVMrank and thus requires only a smaller number of experiments for parameter tuning than SimCC. Furthermore, our experimental results with a real-world dataset show that the accuracy of SimCC-AT is dramatically higher than that of other existing methods and is comparable to that of SimCC.", "references": ["N. Chiki, B. Rothenburger, and N. Gilles. Combining Link and Content Information for Scientific Topics Discovery. In ICTAI, pages 211--214. 2008.", "J. Han, M. Kamber, and J. Pei. Data Mining: Concepts and Techniques, Second Edition. Morgan Kaufmann, San Francisco, 2006.", "J. Jeh and J. Widom. SimRank: A Measure of Structural-Context Similarity. In SIGKDD, pages 538--543. 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914715"}, {"title": "Watching What and How Politicians Discuss Various Topics: A Large-Scale Video Analytics UI", "authors": ["Emily Song\n,", "Joseph G. Ellis\n,", "Hongzhi Li\n,", "Shih-Fu Chang"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAccurately gauging the political atmosphere is especially difficult in this day and age, as individuals have access to a constantly growing collection of written and audiovisual news sources. This is especially true with regards to the U.S. presidential election, as there are numerous candidates, countless stories, and opinion articles discussing the merits of each particular candidate. It is therefore challenging for people to make an accurate assessment of what each candidate represents and how they would act if they were elected into office. To address this problem, we present a large-scale dataset comprised of videos of politicians speaking organized by the topics they are speaking about, and a user interface for exploring this interesting dataset. Our interface links people and events to relevant pieces of audiovisual media, and presents the desired information in a meaningful and intuitive manner. Our approach is unique by direct linking to actual speaking by politicians about specific topics, rather than links to textual quotes only. We describe the larger underlying infrastructure, a novel automated system that crawls thousands of internet news sources and 100 television news channels daily, and automatically discovers entities and indexes the content into events and topics. We examine how our user interface provides helpful and unique insights to its users, and give an example of the type of large scale trend analysis that can be performed with our system. Our online demo can be accessed at: http://www.ee.columbia.edu/dvmm/PoliticialSpeakerDemo", "references": ["K. Arceneaux, M. Johnson, R. Lindstadt, and R. J. Wielen. The influence of news media on political elites: Investigating strategic responsiveness in congress. American Journal of Political Science, 2016.", "D. D'Alessio and M. Allen. Media bias in presidential elections: a meta-analysis. Journ. of Comm., 2000.", "J. G. Ellis, B. Jou, and S.-F. Chang. Why we watch the news: A dataset for exploring sentiment in broadcast video news. In ICMI, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912025"}, {"title": "A review on Deep Learning approaches in Speaker Identification", "authors": ["Sreenivas Sremath Tirumala\n,", "Seyed Reza Shahamiri"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nDeep learning (DL) is becoming an increasingly interesting and powerful machine learning method with successful applications in many domains, such as natural language processing, image recognition, hand-written character recognition, and computer vision. Despite of its eminent success, limitations of traditional learning approach may still prevent deep learning from achieving a wide range of realistic learning tasks. DL approaches has shown success in speech recognition and speaker identification over traditional approaches such as those that use Mel Frequency Cepstrum Coefficients for feature extraction with Gaussian Mixture Models. However, speaker identification research community are not fully aware of the DL process and its application with respect to speaker identification. This paper is motivated to reduce this knowledge gap and to promote the research of implementing deep learning techniques for speaker identification. In this paper, we present a review of the DL methodologies used for speaker identification and surveys important DL algorithms that can potentially be explored for future works. We categorised the applications of DL for speaker identification according to the process of speaker identification and presented a review of these implementations.", "references": ["Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. In Proceedings of the IEEE, pages 2278--2324, 1998.", "S. S. Tiruala. Deep learning: Fundamentals, methods and applications. In J. Porter, editor, DEEPLEARNING USING UNCONVENTIONALPARADIGMS, chapter 1, pages 11--. NOVA publishes, New York, 2014.", "R. Rajesh, K. Ganesh, S. C. L. Koh, N. Singh, R. Khan, and R. Shree. International conference on modelling optimization and computing applications of speaker recognition. Procedia Engineering, 38:3122--3126, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015210"}, {"title": "Image2Text: A Multimodal Image Captioner", "authors": ["Chang Liu\n,", "Changhu Wang\n,", "Fuchun Sun\n,", "Yong Rui"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this work, we showcase the Image2Text system, which is a real-time captioning system that can generate human-level natural language description for any input image. We formulate the problem of image captioning as a multimodal translation task. Analogous to machine translation, we present a sequence-to-sequence recurrent neural networks (RNN) model for image caption generation. Different from most existing work where the whole image is represented by a convolutional neural networks (CNN) feature, we propose to represent the input image as a sequence of detected objects to serve as the source sequence of the RNN model. Based on the captioning framework, we develop a user-friendly system to automatically generated human-level captions for users. The system also enables users to detect salient objects in an image, and retrieve similar images and corresponding descriptions from a database.", "references": ["J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.", "S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735--1780, 1997.", "X. Jia, E. Gavves, B. Fernando, and T. Tuytelaars. Guiding long-short term memory for image caption generation. arXiv preprint arXiv:1509.04942, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973831"}, {"title": "C3-index: revisiting author's performance measure", "authors": ["Dinesh Pradhan\n,", "Partha Sarathi Paul\n,", "Umesh Maheswari\n,", "Subrata Nandi\n,", "Tanmoy Chakraborty"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nAuthor ranking indices, like h-index and its variants, fail to resolve ties while ranking authors with low index values (major volume including the young ones). In this work we leverage the citations as well as collaboration profile of an author in a novel way using a weighted multi-layered network and propose a page-rank variant to obtain a new author performance measure, C3-index. Experiments on a massive publication dataset reveal several interesting characteristics of our metric: (i) we observe that C3-index is consistent over time, (ii) C3-index has high potential to break ties among low rank authors, (iii) C3-index can be used to predict future achievers at the early stage of their career.", "references": ["S. Alonso et al. h-index: A review focused in its variants, computation and standardization for different scientific fields. JOI, 3(4):273--289, 2009.", "T. Chakraborty et al. On the categorization of scientific citation profiles in computer science. Comm. ACM, 58(9):82--90, Aug. 2015.", "M. Nykl et al. Pagerank variants in the evaluation of citation networks. JOI, 8(3):683--692, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908185"}, {"title": "Error Link Detection and Correction in Wikipedia", "authors": ["Chengyu Wang\n,", "Rong Zhang\n,", "Xiaofeng He\n,", "Aoying Zhou"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe hyperlink structure of Wikipedia forms a rich semantic network connecting entities and concepts, enabling it as a valuable source for knowledge harvesting. Wikipedia, as crowd-sourced data, faces various data quality issues which significantly impacts knowledge systems depending on it as the information source. One such issue occurs when an anchor text in a Wikipage links to a wrong Wikipage, causing the error link problem. While much of previous work has focused on leveraging Wikipedia for entity linking, little has been done to detect error links.\nIn this paper, we address the error link problem, and propose algorithms to detect and correct error links. We introduce an efficient method to generate candidate error links based on iterative ranking in an Anchor Text Semantic Network. This greatly reduces the problem space. A more accurate pairwise learning model was used to detect error links from the reduced candidate error link set, while suggesting correct links in the same time. This approach is effective when data sparsity is a challenging issue. The experiments on both English and Chinese Wikipedia illustrate the effectiveness of our approach. We also provide a preliminary analysis on possible causes of error links in English and Chinese Wikipedia.", "references": ["E. Aktolga, M. Cartright, and J. Allan. Cross-document cross-lingual coreference retrieval. In CIKM, pages 1359--1360, 2008.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Computer Networks, 30(1--7):107--117, 1998.", "S. Bykau, F. Korn, D. Srivastava, and Y. Velegrakis. Fine-grained controversy detection in wikipedia. In ICDE, pages 1573--1584, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983705"}, {"title": "Maximal frequent sequence mining for finding software clones", "authors": ["Yoshihisa Udagawa"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nSoftware clones are introduced to source code by copying and slightly modifying code fragments for reuse. Thus, the problem of finding software clones is essentially the detection of strings that partially match. This paper describes a software clone detection technique using a sequential pattern-mining algorithm. After outlining a code normalization technique that extracts code-matching statements of interest from a specific programming language, viz., Java, we discuss how to extract a set of frequent sequences with gaps from a set of sequences that correspond to methods. The proposed algorithm also deals with maximal frequent sequences to find the most compact representation of sequential patterns. We define the maximal frequent sequence in the context of a partial match of sequences or gapped sequences. The novelty of our approach includes modified longest-common-subsequence (LCS) and backtrace algorithms for handling partial matches of sequences systematically. The paper also reports on the results of a case study using Apache Struts 2.5.2 Core. The results demonstrate the ability of the proposed algorithm to find clones of Types 1, 2, and 3.", "references": ["Roy, C. K. and Cordy, J. R. 2007. A survey on software clone detection research. Queen's Technical Report:541. Queen's Uni-versity at Kingston, Ontario, Canada (Sep. 2007), 1--115.", "2016. Sequence alignment. https://en.wikipedia.org/wiki/Sequence_alignment, (October 2016).", "Roy, C. K. and Cordy, J. R. 2008. NICAD: Accurate detection of near-miss intentional clons using flexible pretty-printing and code normalization. Proceedings of the 16th IEEE International Conference on Program Comprehension (June 2008), 172--181."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011160"}, {"title": "Vapor Engine: Demonstrating an Early Prototype of a Language-Independent Search Engine for Speech", "authors": ["Douglas W. Oard\n,", "Rashmi Sankepally\n,", "Jerome White\n,", "Craig Harman"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nTypical search engines for spoken content begin with some form of language-specific audio processing such as phonetic word recognition. Many languages, however, lack the language tuned preprocessing tools that are needed to create indexing terms for speech. One approach in such cases is to rely on repetition, detected using acoustic features, to find terms that might be worth indexing. Experiments have shown that this approach yields term sets that might be sufficient for some applications in both spoken term detection and ranked retrieval experiments. Such approaches currently work only with spoken queries, however, and only when the searcher is able to speak in a manner similar to that of the speakers in the collection. This demonstration paper proposes Vapor Engine, a new tool for selectively transcribing repeated terms that can be automatically detected from spoken content in any language. These transcribed terms could then be matched to queries formulated using written terms. Vapor Engine is early in development: it currently supports only single-term queries and has not yet having been formally evaluated. This paper introduces the interface and summarizes the challenges it seeks to address.", "references": ["F. Abdulhamid and S. Marshall. Treemaps to visualise and navigate speech audio. In OZCHI, 2013.", "L. Begeja et al. A system for searching and browsing spoken communications. In NAACL-HLT, 2004.", "J. Cui et al. Easyalbum: an interactive photo annotation system based on face clustering and re-ranking. In CHI, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854987"}, {"title": "Hashtag Recommendation Based on Topic Enhanced Embedding, Tweet Entity Data and Learning to Rank", "authors": ["Quanzhi Li\n,", "Sameena Shah\n,", "Armineh Nourbakhsh\n,", "Xiaomo Liu\n,", "Rui Fang"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we present a new approach of recommending hashtags for tweets. It uses Learning to Rank algorithm to incorporate features built from topic enhanced word embeddings, tweet entity data, hashtag frequency, hashtag temporal data and tweet URL domain information. The experiments using millions of tweets and hashtags show that the proposed approach outperforms the three baseline methods -- the LDA topic, the tf.idf based and the general word embedding approaches.", "references": ["Collobert, Ronan, Jason Weston, Leon Bottou, et al., Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493--2537, 2011.", "Fan, R.-E., K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A Library for Large Linear Classification, Journal of Machine Learning Research 9 (2008), 1871--1874", "F. Godin, V. Slavkovikj, W. De Neve, B. Schrauwen, and R. Van de Walle. Using topic models for twitter hashtag recommendation. In WWW'13"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983915"}, {"title": "A Cross-Industry Machine Learning Framework with Explicit Representations", "authors": ["Denise Ichinco\n,", "Sahil Zubair\n,", "Jana Eggers\n,", "Nathan Wilson"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAt Nara Logics, we provide recommendations for ecommerce, supply chain, financial services, travel & hospitality, operations and more for the Global 200. We've learned that for machine intelligence to be accepted, it must interact seamlessly with humans, expose its reasoning to humans, and even incorporate human feedback in real time into its decision making. Just as you take your friends' recommendations more seriously when you can probe their mental model of your likes and dislikes, machine recommendations are more appealing when users understand how they were generated and can provide feedback to those recommendations. These aspects are necessary as commercial interfaces increasingly leverage recommendations alongside statistical analysis.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959125"}, {"title": "Detection of Acoustic Events by using MFCC and Spectro-Temporal Gabor Filterbank Features", "authors": ["Umair Zafar Khan\n,", "Muhammad Usman Akram\n,", "Ali Hassan\n,", "Arslan Shaukat\n,", "Muhammad Kashan Basit\n,", "Abdul Wahid"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nAcoustic event Detection (AED) is concerned with recognition of sound which is produced by the human and the object that is handled by human or by nature. The Detection of acoustic events is an important task for our intelligent system which is supposed to recognize not only speech but also sounds of our indoor and outdoor environments that includes information retrieval, audio-based surveillance and monitoring systems. Currently, System for detection and classification of events from our daily monophonic sound is mature enough to extract features and detect isolated events nearly accurate but accuracy is very low for large dataset and for noisy and overlapped audio events. Mostly the real life sounds are polyphonic and events have some part of overlap which is harder to detect. In our work we will discuss the previous issues for detection and feature extraction of acoustic events. We use the DCASE dataset, published in an international IEEE AASP challenge for Acoustic Event Detection which includes the \"office live\" recordings which were prepared in an office environment. MFCC is a technique commonly used for features extraction of speech and Acoustic event. We propose to use the Gabor filterbank in addition to MFCCs coefficients to analyze the feature. For Classification we use the Decision tree algorithm that gives better classification and detection result.. Finally, we compare our proposed system with each system that was used for DCASE dataset and concluded that our technique gives best F-Score value in detection of events as compare to others.", "references": ["M. Cobos, J. J. Perez-Solano, S. Felici - Castell, J. Segura, and J.M. Navarro. 2014. Cumulative sum - Based localization of sound events in low-cost wireless acoustic sensor networks. IEEEACM Transaction on Speech and Language Processing.", "T. Sandhan, S. Sonowal, and J. Y. Choi. 2014. Audio bank: a highlevel acoustic signal representation for audio event recognition. In Proceeding of 14th International Conference on Control Automation and Systems (ICCAS'14), pp. 82--87, (October 2014) IEEE, Seoul, Republic of Korea.", "S. E. Kucukbay and M. Sert. 2015. Audio-based event detection in office Live environments using optimized MFCC SVM approach. In Proceeding of the IEEE International Conference on Semantic Computing (ICSC '15), (February 2015) pp. 475 480, Calif USA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015186"}, {"title": "Web System for Management and Tracking of the Use of Medication in Ambient Assisted Living", "authors": ["Milene Santos Teixeira\n,", "Leandro Oliveira Freitas\n,", "Jucara Salete Gubiani\n,", "Un Hee Schiefelbein"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe percentage of elderly population in society has grown on a large scale in the last years, and it is estimated that this grown will continue to occur. In face of this, rises up the demand for new products and services that come up with solutions for the necessities of this age group. In order to supply this demand, comes up Ambient Assisted Living, a field of Ambient Intelligence that uses ubiquitous or pervasive computing and aims to provide a safer and more comfortable home life to elderly or to people that need some assistance in daily activities. The goal of this study is to provide a web system for managing and accurate monitoring of the medication use for patients in Ambient Assisted Living environments. The system purpose is to alert the patient to use their medication at the right time preventing them from using the wrong medication, and, also, notify a responsible in case of errors and keep track of the treatment. Validation is done through a simulation with fictitious data performed on a simulator. The intention of this work is to provide this service to real users in order to assist them in their medical treatment.", "references": ["Aarts, E. e Wichert, R.. 2009. Ambient intelligence (pp. 244- 249). Springer Berlin Heidelberg.", "ERCIM NEWS. 2011. Special theme: Ambient Assisted Living. Ed. 87. Disponivel em: http://ercimnews.ercim.eu/images/stories/EN87/EN87-web.pdf", "Garcia, N.M. e Rodrigues, J.J.P. eds., 2015. Ambient Assisted Living. CRC Press."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022002"}, {"title": "Dynamic Collective Entity Representations for Entity Ranking", "authors": ["David Graus\n,", "Manos Tsagkias\n,", "Wouter Weerkamp\n,", "Edgar Meij\n,", "Maarten de Rijke"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nEntity ranking, i.e., successfully positioning a relevant entity at the top of the ranking for a given query, is inherently difficult due to the potential mismatch between the entity's description in a knowledge base, and the way people refer to the entity when searching for it. To counter this issue we propose a method for constructing dynamic collective entity representations. We collect entity descriptions from a variety of sources and combine them into a single entity representation by learning to weight the content from different sources that are associated with an entity for optimal retrieval effectiveness. Our method is able to add new descriptions in real time and learn the best representation as time evolves so as to capture the dynamics of how people search entities. Incorporating dynamic description sources into dynamic collective entity representations improves retrieval effectiveness by 7% over a state-of-the-art learning to rank baseline. Periodic retraining of the ranker enables higher ranking effectiveness for dynamic collective entity representations.", "references": ["E. Amitay, A. Darlow, D. Konopnicki, and U. Weiss. Queries as anchors: selection by association. In HYPERTEXT '05, pages 193--201, 2005.", "K. Balog and K. Nørvåg. On the use of semantic knowledge bases for temporally-aware entity retrieval. In Proceedings of ESAIR '12, pages 1--2, 2012.", "K. Balog, M. Bron, and M. de Rijke. Category-based query modeling for entity search. In ECIR '10, pages 319--331, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835819"}, {"title": "Project Success Prediction in Crowdfunding Environments", "authors": ["Yan Li\n,", "Vineeth Rakesh\n,", "Chandan K. Reddy"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nCrowdfunding has gained widespread attention in recent years. Despite the huge success of crowdfunding platforms, the percentage of projects that succeed in achieving their desired goal amount is only around 40%. Moreover, many of these crowdfunding platforms follow \"all-or-nothing\" policy which means the pledged amount is collected only if the goal is reached within a certain predefined time duration. Hence, estimating the probability of success for a project is one of the most important research challenges in the crowdfunding domain. To predict the project success, there is a need for new prediction models that can potentially combine the power of both classification (which incorporate both successful and failed projects) and regression (for estimating the time for success). In this paper, we formulate the project success prediction as a survival analysis problem and apply the censored regression approach where one can perform regression in the presence of partial information. We rigorously study the project success time distribution of crowdfunding data and show that the logistic and log-logistic distributions are a natural choice for learning from such data. We investigate various censored regression models using comprehensive data of 18K Kickstarter (a popular crowdfunding platform) projects and 116K corresponding tweets collected from Twitter. We show that the models that take complete advantage of both the successful and failed projects during the training phase will perform significantly better at predicting the success of future projects compared to the ones that only use the successful projects. We provide a rigorous evaluation on many sets of relevant features and show that adding few temporal features that are obtained at the project's early stages can dramatically improve the performance.", "references": ["J. Andreoni. Impure altruism and donations to public goods: a theory of warm-glow giving. The economic journal, pages 464--477, 1990.", "A. Ashta and D. Assadi. Do social cause and social technology meet? impact of web 2.0 technologies on peer-to-peer lending transactions. Cahiers du CEREN, 29:177--192, 2009.", "S. Bennett. Log-logistic regression models for survival data. Applied Statistics, pages 165--171, 1983."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2835791"}, {"title": "Spreading word: author frequency of app user reviews", "authors": ["Leonard Hoon\n,", "Milica Stojmenović\n,", "Raj Vasa\n,", "Graham Farrell"], "publication": "OzCHI '16: Proceedings of the 28th Australian Conference on Computer-Human Interaction", "abstract": "ABSTRACT\nApp stores allow developers to publish new updates directly to users. Users evaluate and leave public reviews of their opinions and experiences for others to see. App ratings and reviews are a purchase determinant for users, and are free user-based usability tests. Existing literature offers approaches to extract information from or to summarise app reviews, but what can we say about the authors themselves? We analysed about 8.7 million iOS app reviews written by over 5.5 million unique authors. We found that 71.5% of authors only wrote one review. Only 13,224 instances of authors re-reviewing were observed, by 12,667 authors for 3,345 apps.", "references": ["Apple Inc. App Store Tops 40 Billion Downloads with Almost Half in 2012. https://www.apple.com/pr/library/2013/01/07App-Store-Tops-40-Billion-Downloads-with-Almost-Half-in-2012.html, (2013), Last accessed 11th Apr 2016.", "Chevalier J. A. and Mayzlin D. The effect of word of mouth on sales: Online book reviews. Journal of Marketing Research 43, 3 (2006), 345--354.", "Davis, F. D. Perceived usefulness, perceived ease of use, and user acceptance of information technology. MIS Quarterly 13, 3 (1989), 319--340."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010915.3011850"}, {"title": "Most Popular Theories in Information Systems Research", "authors": ["Patricio R. Correa"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe objective of this work is to identify the theories most widely applied in information systems research. In order to achieve this purpose, an exploration of literature 2015 is realized, based on cocitation analysis. Results indicate that Dynamic Capabilities Theory appears as main in the discussion of information systems research.", "references": ["B. Mohanty, \"Management Information Systems Quarterly (MISQ): A Bibliometric Study,\" Library Philosophy and Practice, no. 1, 2014.", "Y. K. Dwivedi, M. R. Wade, and S. L. Schneberger, Information Systems Theory: Explaining and Predicting Our Digital Society: Springer Science e Business Media, 2011.", "K. A. Walstrom, and L. N. Leonard, \"Citation classics from the information systems literature,\" Information e Management, vol. 38, no. 2, pp. 59-72, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022052"}, {"title": "History by Diversity: Helping Historians search News Archives", "authors": ["Jaspreet Singh\n,", "Wolfgang Nejdl\n,", "Avishek Anand"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nLongitudinal corpora like newspaper archives are of immense value to historical research, and time as an important factor for historians strongly influences their search behaviour in these archives. While searching for articles published over time, a key preference is to retrieve documents which cover the important aspects from important points in time which is different from standard search behavior. To support this search strategy, we introduce the notion of a Historical Query Intent to explicitly model a historian's search task and define an aspect-time diversification problem over news archives.\nWe present a novel algorithm, HistDiv, that explicitly models the aspects and important time windows based on a historian's information seeking behavior. By incorporating temporal priors based on publication times and temporal expressions, we diversify both on the aspect and temporal dimensions. We test our methods by constructing a test collection based on The New York Times Collection with a workload of 30 queries of historical intent assessed manually. We find that HistDiv outperforms all competitors in subtopic recall with a slight loss in precision. We also present results of a qualitative user study to determine wether this drop in precision is detrimental to user experience. Our results show that users still preferred HistDiv's ranking.", "references": ["British newspaper archive http://www.britishnewspaperarchive.co.uk/.", "California digital newspaper collection, http://cdnc.ucr.edu/cgi-bin/cdnc.", "New york times archives, http://timesmachine.nytimes.com/browser."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854959"}, {"title": "Assessing Learning Outcomes in Web Search: A Comparison of Tasks and Query Strategies", "authors": ["Kevyn Collins-Thompson\n,", "Soo Young Rieh\n,", "Carl C. Haynes\n,", "Rohail Syed"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nUsers make frequent use of Web search for learning-related tasks, but little is known about how different Web search interaction strategies affect outcomes for learning-oriented tasks, or what implicit or explicit indicators could reliably be used to assess search-related learning on the Web. We describe a lab-based user study in which we investigated potential indicators of learning in web searching, effective query strategies for learning, and the relationship between search behavior and learning outcomes. Using questionnaires, analysis of written responses to knowledge prompts, and search log data, we found that searchers' perceived learning outcomes closely matched their actual learning outcomes; that the amount searchers wrote in post-search questionnaire responses was highly correlated with their cognitive learning scores; and that the time searchers spent per document while searching was also highly and consistently correlated with higher-level cognitive learning scores. We also found that of the three query interaction conditions we applied, an intrinsically diverse presentation of results was associated with the highest percentage of users achieving combined factual and conceptual knowledge gains. Our study provides deeper insight into which aspects of search interaction are most effective for supporting superior learning outcomes, and the difficult problem of how learning may be assessed effectively during Web search.", "references": ["Ageev, M., Guo, Q., Lagun, D., and Agichtein, E. 2011. Find it if you can: a game for modeling different types of web search success using interaction data. In Proc. of SIGIR '11. ACM, 345--354.", "Agosti, M., Fuhr, N., Toms, E., and Vakkari, P. 2014. Evaluation methodologies in Information Retrieval Dagstuhl seminar 13441. ACM SIGIR Forum. 48, 1 (June 2014), 36--41.", "Allan, J., Croft, B., Moffat, A., & Sanderson, M. 2012. Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012: the second strategic workshop on information retrieval in Lorne. ACM SIGIR Forum. 46, 1 (May 2012), 2--32."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854972"}, {"title": "Semantometrics: Towards Fulltext-based Research Evaluation", "authors": ["Drahomira Herrmannova\n,", "Petr Knoth"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nOver the recent years, there has been a growing interest in developing new research evaluation methods that could go beyond the traditional citation-based metrics. This interest is motivated on one side by the wider availability or even emergence of new information evidencing research performance, such as article downloads, views and Twitter mentions, and on the other side by the continued frustrations and problems surrounding the application of purely citation-based metrics to evaluate research performance in practice.\nSemantometrics are a new class of research evaluation metrics which build on the premise that full-text is needed to assess the value of a publication. This paper reports on the analysis carried out with the aim to investigate the properties of the semantometric contribution measure [Knoth, 2014], which uses semantic similarity of publications to estimate research contribution, and provides a comparative study of the contribution measure with traditional bibliometric measures based on citation counting.", "references": ["P. Knoth and D. Herrmannova. Towards Semantometrics: A New Semantic Similarity Based Measure for Assessing a Research Publication's Contribution. D-Lib Magazine, 20(11/12), 2014.", "C. Schlögl, J. Gorraiz, C. Gumpenberger, K. Jack, and P. Kraker. Are downloads and readership data a substitute for citations' the case of a scholarly journal. LIDA Proceedings, 13, 2014.", "P. O. Seglen. The Skewness of Science. JASIS, 43(9):628--638, oct 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2925448"}, {"title": "The Role of Cores in Recommender Benchmarking for Social Bookmarking Systems", "authors": ["Stephan Doerfel\n,", "Robert Jäschke\n,", "Gerd Stumme"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nSocial bookmarking systems have established themselves as an important part in today’s Web. In such systems, tag recommender systems support users during the posting of a resource by suggesting suitable tags. Tag recommender algorithms have often been evaluated in offline benchmarking experiments. Yet, the particular setup of such experiments has rarely been analyzed. In particular, since the recommendation quality usually suffers from difficulties such as the sparsity of the data or the cold-start problem for new resources or users, datasets have often been pruned to so-called cores (specific subsets of the original datasets), without much consideration of the implications on the benchmarking results.\nIn this article, we generalize the notion of a core by introducing the new notion of a set-core, which is independent of any graph structure, to overcome a structural drawback in the previous constructions of cores on tagging data. We show that problems caused by some types of cores can be eliminated using set-cores. Further, we present a thorough analysis of tag recommender benchmarking setups using cores. To that end, we conduct a large-scale experiment on four real-world datasets, in which we analyze the influence of different cores on the evaluation of recommendation algorithms. We can show that the results of the comparison of different recommendation approaches depends on the selection of core type and level. For the benchmarking of tag recommender algorithms, our results suggest that the evaluation must be set up more carefully and should not be based on one arbitrarily chosen core type and level.", "references": ["Gediminas Adomavicius and Jingjing Zhang. 2012. Impact of data characteristics on recommender systems performance. ACM Transactions on Management Information Systems 3, 1, Article 3, 17 pages. DOI:http://dx.doi.org/10.1145/2151163.2151166", "Adel Ahmed, Vladimir Batagelj, Xiaoyan Fu, Seok-Hee Hong, Damian Merrick, and Andrej Mrvar. 2007. Visualisation and analysis of the Internet Movie Database. In 6th International Asia-Pacific Symposium on Visualization. 17--24. DOI:http://dx.doi.org/10.1109/APVIS.2007.329304", "José Ignacio Alvarez-Hamelin, Luca Dall’Asta, Alain Barrat, and Alessandro Vespignani. 2005. K-core decomposition of Internet graphs: Hierarchies, self-similarity and measurement biases. CoRR cs/0511007 (2005). http://arxiv.org/abs/cs/0511007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700485"}, {"title": "Session details: Main Track - Agile Methods in IS", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255997"}, {"title": "Cobwebs from the Past and Present: Extracting Large Social Networks using Internet Archive Data", "authors": ["Miroslav Shaltev\n,", "Jan-Hendrik Zab\n,", "Philipp Kemkes\n,", "Stefan Siersdorfer\n,", "Sergej Zerr"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSocial graph construction from various sources has been of interest to researchers due to its application potential and the broad range of technical challenges involved. The World Wide Web provides a huge amount of continuously updated data and information on a wide range of topics created by a variety of content providers, and makes the study of extracted people networks and their temporal evolution valuable for social as well as computer scientists. In this paper we present SocGraph - an extraction and exploration system for social relations from the content of around 2 billion web pages collected by the Internet Archive over the 17 years time period between 1996 and 2013. We describe methods for constructing large social graphs from extracted relations and introduce an interface to study their temporal evolution.", "references": ["C. Bird, A. Gourley, P. Devanbu, M. Gertz, and A. Swaminathan. Mining email social networks. In MSR Workshop 2006.", "X. Canaleta, P. Ros, A. Vallejo, D. Vernet, and A. Zaballos. A system to extract social networks based on the processing of information obtained from internet. In ICC Association for Artificial Intelligence 2008.", "D. K. Elson, N. Dames, and K. R. McKeown. Extracting social networks from literary fiction. In Association for Computational Linguistics (ACL) System Demonstrations, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911467"}, {"title": "Frame- and Segment-Level Features and Candidate Pool Evaluation for Video Caption Generation", "authors": ["Rakshith Shetty\n,", "Jorma Laaksonen"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present our submission to the Microsoft Video to Language Challenge of generating short captions describing videos in the challenge dataset. Our model is based on the encoder--decoder pipeline, popular in image and video captioning systems. We propose to utilize two different kinds of video features, one to capture the video content in terms of objects and attributes, and the other to capture the motion and action information. Using these diverse features we train models specializing in two separate input sub-domains. We then train an evaluator model which is used to pick the best caption from the pool of candidates generated by these domain expert models. We argue that this approach is better suited for the current video captioning task, compared to using a single model, due to the diversity in the dataset.\nEfficacy of our method is proven by the fact that it was rated best in MSR Video to Language Challenge, as per human evaluation. Additionally, we were ranked second in the automatic evaluation metrics based table.", "references": ["J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR, 2009.", "Y. Gong, L. Wang, R. Guo, and S. Lazebnik. Multi-scale orderless pooling of deep convolutional activation features. arXiv.org:1403.1840, 2014.", "K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. arXiv, abs/1512.03385, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2984062"}, {"title": "A Study of Realtime Summarization Metrics", "authors": ["Matthew Ekstrand-Abueg\n,", "Richard McCreadie\n,", "Virgil Pavlu\n,", "Fernando Diaz"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUnexpected news events, such as natural disasters or other human tragedies, create a large volume of dynamic text data from official news media as well as less formal social media. Automatic real-time text summarization has become an important tool for quickly transforming this overabundance of text into clear, useful information for end-users including affected individuals, crisis responders, and interested third parties. Despite the importance of real-time summarization systems, their evaluation is not well understood as classic methods for text summarization are inappropriate for real-time and streaming conditions.\nThe TREC 2013-2015 Temporal Summarization (TREC-TS) track was one of the first evaluation campaigns to tackle the challenges of real-time summarization evaluation, introducing new metrics, ground-truth generation methodology and dataset. In this paper, we present a study of TREC-TS track evaluation methodology, with the aim of documenting its design, analyzing its effectiveness, as well as identifying improvements and best practices for the evaluation of temporal summarization systems.", "references": ["J. Allan, editor. Topic Detection and Tracking: Event-based Information Organization. Inf. Retrieval. 2002.", "J. Allan, R. Gupta, and V. Khandelwal. Temporal summaries of new topics. In Proc of SIGIR, 2001.", "O. Alonso and R. Baeza-Yates. Design and implementation of relevance assessments using crowdsourcing. In Proc. of ECIR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983653"}, {"title": "Fifty Shades of Ratings: How to Benefit from a Negative Feedback in Top-N Recommendations Tasks", "authors": ["Evgeny Frolov\n,", "Ivan Oseledets"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nConventional collaborative filtering techniques treat a top-n recommendations problem as a task of generating a list of the most relevant items. This formulation, however, disregards an opposite -- avoiding recommendations with completely irrelevant items. Due to that bias, standard algorithms, as well as commonly used evaluation metrics, become insensitive to negative feedback. In order to resolve this problem we propose to treat user feedback as a categorical variable and model it with users and items in a ternary way. We employ a third-order tensor factorization technique and implement a higher order folding-in method to support online recommendations. The method is equally sensitive to entire spectrum of user ratings and is able to accurately predict relevant items even from a negative only feedback. Our method may partially eliminate the need for complicated rating elicitation process as it provides means for personalized recommendations from the very beginning of an interaction with a recommender system. We also propose a modification of standard metrics which helps to reveal unwanted biases and account for sensitivity to a negative feedback. Our model achieves state-of-the-art quality in standard recommendation tasks while significantly outperforming other methods in the cold-start \"no-positive-feedback\" scenarios.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-Aware Recommender Systems. AI Mag., 32(3):67--80, 2011.", "G. Adomavicius and A. Tuzhilin. Toward the Next Generation of Recommender Systems: a Survey of the State of the Art and Possible Extensions. IEEE Trans. Knowl. Data Eng., 17(6):734--749, 2005.", "X. Amatriain, J. M. Pujol, and N. Oliver. I Like It... I Like It Not: Evaluating User Ratings Noise in Recommender Systems. In Proc. 17th Int. Conf. User Model. Adapt. Pers. Former. UM AH, UMAP '09, pages 247--258, Berlin, Heidelberg, 2009. Springer-Verlag."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959170"}, {"title": "iGlasses: A Novel Recommendation System for Best-fit Glasses", "authors": ["Xiaoling Gu\n,", "Lidan Shou\n,", "Pai Peng\n,", "Ke Chen\n,", "Sai Wu\n,", "Gang Chen"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe demonstrate iGlasses, a novel recommendation system that accepts a frontal face photo as the input and returns the best-fit eyeglasses as the output. As conventional recommendation techniques such as collaborative filtering become inapplicable in the problem, we propose a new recommendation method which exploits the implicit matching rules between human faces and eyeglasses. We first define fine-grained attributes for human faces and frames of glasses respectively. Then, we develop a recommendation framework based on a probabilistic graphical model, which effectively captures the correlation among these fine-grained attributes. Ranking of the frames (glasses) is done by their similarity to the query facial attributes. Finally, we produce a synthesized image for the input face to demonstrate the visual effect when wearing the recommended glasses.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734--749, 2005.", "T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham. Active shape models|their training and application. Comput. Vis. Image Underst., 61(1):38--59, 1995.", "N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Describable visual attributes for face verification and image search. IEEE Trans. Pattern Anal. Mach. Intell., 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911453"}, {"title": "Poster: Context-driven Mood Mining", "authors": ["Rajib Rana"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nNo abstract available.", "references": ["R. LiKamWa, Y. Liu, N. D. Lane, and L. Zhong. Moodscope: building a mood sensor from smartphone usage patterns. In Proceeding of the 11th annual international conference on Mobile systems, applications, and services, pages 389--402. ACM, 2013.", "L. I. Reed, M. A. Sayette, and J. F. Cohn. Impact of depression on response to comedy: a dynamic facial coding analysis. Journal of abnormal psychology, 116(4):804, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2938601"}, {"title": "VisLoiter: a system to visualize loiterers discovered from surveillance videos", "authors": ["Jianquan Liu\n,", "Shoji Nishimura\n,", "Takuya Araki"], "publication": "SIGGRAPH '16: ACM SIGGRAPH 2016 Posters", "abstract": "ABSTRACT\nThis paper presents a system for visualizing the results of loitering discovery in surveillance videos. Since loitering is a suspicious behaviour that often leads to abnormal situations, such as pickpocketing, its analysis attracts attention from researchers [Bird et al. 2005; Ke et al. 2013; A. et al. 2015]. Most of them mainly focus on how to detect or identify loitering individuals by human tracking techniques. A robust approach in [Nam 2015] is one of the state-of-theart methods for detecting loitering persons in crowded scenes using pedestrian tracking based on spatio-temporal changes. However, such tracking-based methods are quite time-consuming. Therefore, it is hard to apply loitering detection across multiple cameras for a long time, or take into account the visualization of loiterers at a glance. To solve this problem, we propose a system, named VisLoiter (Figure 1), which enables efficient loitering discovery based on face features extracted from longtime videos across multiple cameras, instead of the tracking-based manner. By taking the advantage of efficiency, the VisLoiter realizes the visualization of loiterers at a glance. The visualization consists of three display components for (1) the appearance patterns of loitering individuals, (2) the frequency ranking of faces of loiterers, and (3) the lightweight playback of video clips where the discovered loiterer frequently appeared (see Figure 1 (b) and (c)).", "references": ["A., H. F. G., Martínez-Tomás, R., Tapia, S. A., Fernández-Caballero, A., Ratté, S., Eras, A. G., and González, P. L. 2015. Identification of loitering human behaviour in video surveillance environments. In Int'l Work-conference on the Interplay between Natural and Artificial Computation (IWINAC), 516--525.", "Bird, N. D., Masoud, O., Papanikolopoulos, P., and Isaacs, A. 2005. Detection of loitering individuals in public transportation areas. IEEE Tran. on Intelligent Transportation Systems 6(2), 167--177.", "Ke, S., Hoang, L. U. T., Lee, Y., Hwang, J., Yoo, J., and Choi, K. 2013. A review on video-based human activity recognition. Computers 2, 2, 88--131."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2945078.2945125"}, {"title": "E-commerce Product Recommendation by Personalized Promotion and Total Surplus Maximization", "authors": ["Qi Zhao"], "publication": "WSDM '16: Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "abstract": "ABSTRACT\nExisting recommendation algorithms treat recommendation problem as rating prediction and the recommendation quality is measured by RMSE or other similar metrics. However, we argued that when it comes to E-commerce product recommendation, recommendation is more than rating prediction by realizing the fact price plays a critical role in recommendation result. In this work, we propose to build E-commerce product recommender systems based on fundamental economic notions. We first proposed an incentive compatible method that can effectively elicit consumer's willingness-to-pay in a typical E-commerce setting and in a further step, we formalize the recommendation problem as maximizing total surplus. We validated the proposed WTP elicitation algorithm through crowd sourcing and the results demonstrated that the proposed approach can achieve higher seller profit by personalizing promotion. We also proposed a total surplus maximization (TSM) based recommendation framework. We specified TSM by three of the most representative settings - e-commerce where the product quantity can be viewed as infinity, P2P lending where the resource is bounded and freelancer marketing where the resource (job) can be assigned to one freelancer. The experimental results of the corresponding datasets shows that TSM exceeds existing approach in terms of total surplus.", "references": ["Q. Zhao, Y. Zhang, D. Friedman, and F. Tan. E-commerce recommendation with personalized promotion. In Proceedings of the 9th ACM Conference on Recommender Systems, pages 219--226. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835776.2855085"}, {"title": "SecSIFT: Secure Image SIFT Feature Extraction in Cloud Computing", "authors": ["Zhan Qin\n,", "Jingbo Yan\n,", "Kui Ren\n,", "Chang Wen Chen\n,", "Cong Wang"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nThe image and multimedia data produced by individuals and enterprises is increasing every day. Motivated by the advances in cloud computing, there is a growing need to outsource such computational intensive image feature detection tasks to cloud for its economic computing resources and on-demand ubiquitous access. However, the concerns over the effective protection of private image and multimedia data when outsourcing it to cloud platform become the major barrier that impedes the further implementation of cloud computing techniques over massive amount of image and multimedia data. To address this fundamental challenge, we study the state-of-the-art image feature detection algorithms and focus on Scalar Invariant Feature Transform (SIFT), which is one of the most important local feature detection algorithms and has been broadly employed in different areas, including object recognition, image matching, robotic mapping, and so on. We analyze and model the privacy requirements in outsourcing SIFT computation and propose Secure Scalar Invariant Feature Transform (SecSIFT), a high-performance privacy-preserving SIFT feature detection system. In contrast to previous works, the proposed design is not restricted by the efficiency limitations of current homomorphic encryption scheme. In our design, we decompose and distribute the computation procedures of the original SIFT algorithm to a set of independent, co-operative cloud servers and keep the outsourced computation procedures as simple as possible to avoid utilizing a computationally expensive homomorphic encryption scheme. The proposed SecSIFT enables implementation with practical computation and communication complexity. Extensive experimental results demonstrate that SecSIFT performs comparably to original SIFT on image benchmarks while capable of preserving the privacy in an efficient way.", "references": ["Rakesh Agrawal, Jerry Kiernan, Ramakrishnan Srikant, and Yirong Xu. 2004. Order preserving encryption for numeric data. In Proceedings of SIGMOD’04. ACM, 563--574.", "Mikhail J. Atallah and Jiangtao Li. 2005. Secure outsourcing of sequence comparisons. International Journal of Information Security 4.4 (2005), 277--287.", "M. J. Atallah, K. N. Pantazopoulos, J. R. Rice, and E. E. Spafford. 2002. Secure outsourcing of scientific computations. Adv. Comput. 54 (2002), 215--272."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2978574"}, {"title": "Efficient Bayesian Methods for Graph-based Recommendation", "authors": ["Ramon Lopes\n,", "Renato Assunção\n,", "Rodrygo L.T. Santos"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nShort-length random walks on the bipartite user-item graph have recently been shown to provide accurate and diverse recommendations. Nonetheless, these approaches suffer from severe time and space requirements, which can be alleviated via random walk sampling, at the cost of reduced recommendation quality. In addition, these approaches ignore users' ratings, which further limits their expressiveness. In this paper, we introduce a computationally efficient graph-based approach for collaborative filtering based on short-path enumeration. Moreover, we propose three scoring functions based on the Bayesian paradigm that effectively exploit distributional aspects of the users' ratings. We experiment with seven publicly available datasets against state-of-the-art graph-based and matrix factorization approaches. Our empirical results demonstrate the effectiveness of the proposed approach, with significant improvements in most settings. Furthermore, analytical results demonstrate its efficiency compared to other graph-based approaches.", "references": ["F. Christoffel, B. Paudel, C. Newell, and A. Bernstein. Blockbusters and wallflowers: Accurate, diverse, and scalable recommendations with random walks. In Proceedings of the 9th ACM Conference on Recommender Systems, pages 163--170, New York, NY, USA, 2015. ACM.", "J. Cook. Exact calculation of beta inequalities. Technical report, Department of Biostatistics, November 2005.", "C. Cooper, S. H. Lee, T. Radzik, and Y. Siantos. Random walks in recommender systems: Exact computation and simulations. In Proceedings of the 23rd International Conference on World Wide Web, pages 811--816, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959132"}, {"title": "Summarizing Situational Tweets in Crisis Scenario", "authors": ["Koustav Rudra\n,", "Siddhartha Banerjee\n,", "Niloy Ganguly\n,", "Pawan Goyal\n,", "Muhammad Imran\n,", "Prasenjit Mitra"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nDuring mass convergence events such as natural disasters, microblogging platforms like Twitter are widely used by affected people to post situational awareness messages. These crisis-related messages disperse among multiple categories like infrastructure damage, information about missing, injured, and dead people etc. The challenge here is to extract important situational updates from these messages, assign them appropriate informational categories, and finally summarize big trove of information in each category. In this paper, we propose a novel framework which first assigns tweets into different situational classes and then summarize those tweets. In the summarization phase, we propose a two stage summarization framework which first extracts a set of important tweets from the whole set of information through an Integer-linear programming (ILP) based optimization technique and then follows a word graph and content word based abstractive summarization technique to produce the final summary. Our method is time and memory efficient and outperforms the baseline in terms of quality, coverage of events, locations et al., effectiveness, and utility in disaster scenarios.", "references": ["S. Banerjee, P. Mitra, and K. Sugiyama. Multi-document abstractive summarization using ilp based multi-sentence compression. In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI), 2015.", "G. Erkan and D. R. Radev. LexRank:Graph-based lexical centrality as salience in text summarization. Artificial Intelligence Research, 22:457--479, 2004.", "K. Filippova. Multi-sentence compression: finding shortest paths in word graphs. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 322--330. Association for Computational Linguistics, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914600"}, {"title": "On Local Expert Discovery via Geo-Located Crowds, Queries, and Candidates", "authors": ["Wei Niu\n,", "Zhijiao Liu\n,", "James Caverlee"], "publication": "ACM Transactions on Spatial Algorithms and Systems", "abstract": "Abstract\nLocal experts are critical for many location-sensitive information needs, and yet there is a research gap in our understanding of the factors impacting who is recognized as a local expert and in methods for discovering local experts. Hence, in this article, we explore a geo-spatial learning-to-rank framework for identifying local experts. Three of the key features of the proposed approach are: (i) a learning-based framework for integrating multiple user-based, content-based, list-based, and crowd-based factors impacting local expertise that leverages the fine-grained GPS coordinates of millions of social media users; (ii) a location-sensitive random walk that propagates crowd knowledge of a candidate’s expertise; and (iii) a comprehensive controlled study over AMT-labeled local experts on eight topics and in four cities. We find significant improvements of local expert finding versus two state-of-the-art alternatives, as well as evidence for the generalizability of local expert ranking models to new topics and new locations.", "references": ["Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S. Ackerman. 2008. Knowledge sharing and yahoo answers: Everyone knows something. In Proceedings of the 17th International Conference on World Wide Web. DOI:http://dx.doi.org/10.1145/1367497.1367587", "Akram Alkouz, Ernesto William De Luca, and Sahin Albayrak. 2011. Latent semantic social graph model for expert discovery in facebook. In 11th International Conference on Innovative Internet Community Services (I2CS 2011). GI Edition, 128--138.", "Krisztian Balog, Leif Azzopardi, and Maarten De Rijke. 2006. Formal models for expert finding in enterprise corpora. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. DOI:http://dx.doi.org/10.1145/1148170.1148181"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2994599"}, {"title": "Contextual Intent Tracking for Personal Assistants", "authors": ["Yu Sun\n,", "Nicholas Jing Yuan\n,", "Yingzi Wang\n,", "Xing Xie\n,", "Kieran McDonald\n,", "Rui Zhang"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nA new paradigm of recommendation is emerging in intelligent personal assistants such as Apple's Siri, Google Now, and Microsoft Cortana, which recommends \"the right information at the right time\" and proactively helps you \"get things done\". This type of recommendation requires precisely tracking users' contemporaneous intent, i.e., what type of information (e.g., weather, stock prices) users currently intend to know, and what tasks (e.g., playing music, getting taxis) they intend to do. Users' intent is closely related to context, which includes both external environments such as time and location, and users' internal activities that can be sensed by personal assistants. The relationship between context and intent exhibits complicated co-occurring and sequential correlation, and contextual signals are also heterogeneous and sparse, which makes modeling the context intent relationship a challenging task. To solve the intent tracking problem, we propose the Kalman filter regularized PARAFAC2 (KP2) nowcasting model, which compactly represents the structure and co-movement of context and intent. The KP2 model utilizes collaborative capabilities among users, and learns for each user a personalized dynamic system that enables efficient nowcasting of users' intent. Extensive experiments using real-world data sets from a commercial personal assistant show that the KP2 model significantly outperforms various methods, and provides inspiring implications for deploying large-scale proactive recommendation systems in personal assistants.", "references": ["http://www.google.com/landing/now/.", "http://dev.windows.com/en-us/cortana.", "http://www.apple.com/ios/whats-new/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939676"}, {"title": "Session details: Session 2A: Memory Management", "authors": ["Ricardo Bianchini"], "publication": "ASPLOS '16: Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252393"}, {"title": "Audiovisual Summarization of Lectures and Meetings Using a Segment Similarity Graph", "authors": ["Chidansh Bhatt\n,", "Andrei Popescu-Belis\n,", "Matthew Cooper"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWe propose a method for extractive summarization of audiovisual recordings focusing on topic-level segments. We first build a content similarity graph between all segments across the collection, using word vectors from the transcripts, and then select the most central segments for the summaries. We evaluate the method quantitatively on the AMI Meeting Corpus using gold standard reference summaries and the Rouge metric, and qualitatively on lecture recordings using a novel two-tiered approach with human judges. The results show that our method compares favorably with others in terms of Rouge, and outperforms the baselines for human scores, thus also validating our evaluation protocol.", "references": ["C. Bhatt, N. Pappas, M. Habibi, and A. Popescu-Belis. Multimodal reranking of content-based recommendations for hyperlinking video snippets. In Proc. of Int. Conf. on Multimedia Retrieval (ICMR), pages 225--232, 2014.", "S. Bird. NLTK: the Natural Language Toolkit. In Proc. of the COLING/ACL Interactive Presentation Sessions, 2006.", "J. Carletta. Unleashing the killer corpus: experiences in creating the multi-everything AMI Meeting Corpus. Lang. Resources & Evaluation, 41(2):181--190, 2007.", "M. Cooper and J. Foote. Discriminative techniques for keyframe selection. In IEEE International Conference on Multimedia and Expo (ICME), 2005.", "G. Erkan and D. R. Radev. LexRank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research, 2004.", "N. Garg, B. Favre, et al. ClusterRank: a graph based method for meeting summarization. In Proc. INTERSPEECH, 2009.", "T. Hain et al. Transcribing meetings with the AMIDA systems. IEEE Trans. on Audio, Speech, and Language Processing, 20(2):486--498, 2012.", "M. A. Hearst. TextTiling: Segmenting text into multi-paragraph subtopic passages. Computational Linguistics, 23(1):33--64, 1997.", "C. Lai and S. Renals. Incorporating lexical and prosodic information at different levels for meeting summarization. In Proc. of Interspeech, 2014.", "C.-Y. Lin and E. Hovy. Automatic evaluation of summaries using n-gram co-occurrence statistics. In Proc. of NAACL-HLT, 2003.", "I. Mani, G. Klein, D. House, L. Hirschman, T. Firmin, and B. Sundheim. SUMMAC: A text summarization evaluation. Natural Lang. Eng., 8(1):43--68, 2002.", "R. Mihalcea and P. Tarau. TextRank: bringing order into texts. In Empirical Methods in Natural Language Processing (EMNLP), 2004.", "A. G. Money and H. Agius. Video summarisation: A conceptual framework and survey of the state of the art. Journal of Visual Communication and Image Representation, 19(2):121--143, 2008.", "A. Nenkova and K. McKeown. A survey of text summarization techniques. In Mining Text Data. 2012.", "R. Ribeiro and D. M. de Matos. Revisiting centrality-as-relevance: Support sets and similarity as geometric proximity. Journal of Artificial Intelligence Research, 42:275--308, 2011.", "K. Riedhammer, B. Favre, et al. Long story short--global unsupervised models for keyphrase based meeting summarization. Speech Communication, 2010.", "D. Wang, S. Zhu, T. Li, and Y. Gong. Comparative document summarization via discriminative sentence selection. ACM Transactions on Knowledge Discovery from Data (TKDD), 7(1):2, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912047"}, {"title": "Citation Distance: Measuring Changes in Scientific Search Strategies", "authors": ["Ryan Whalen\n,", "Yun Huang\n,", "Craig Tanis\n,", "Anup Sawant\n,", "Brian Uzzi\n,", "Noshir Contractor"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nUsing latent semantic analysis on the full text of scientific articles, we measure the distance between 36 million citing/cited article pairs and chart changes in citation proximity over time. The analysis shows that the mean distance between citing and cited articles has steadily increased since 1990. This demonstrates that current scholars are more likely to cite distantly related research than their peers of 20 years ago who tended to cite more proximate work. These changes coincide with the introduction of new information technologies like the Internet, and the increasing popularity of interdisciplinary and multidisciplinary research. The \"citation distance\" measure shows promise in improving our understanding of the evolution of knowledge. It also offers a method to add nuance to scholarly impact measures by assessing the extent to which an article influences proximate or distant future work.", "references": ["Shiji Chen, Clément Arsenault, and Vincent Larivière. 2015. Are top-cited papers more interdisciplinary? Journal of Informetrics 9, 4: 1034--1046. http://doi.org/10.1016/j.joi.2015.09.003", "Scott C. Deerwester, Susan T Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. JAsIs 41, 6: 391--407.", "James A. Evans and Jacob G. Foster. 2011. Metaknowledge. Science 331, 6018: 721--725. http://doi.org/10.1126/science.1201765"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890515"}, {"title": "Query reformulation by leveraging crowd wisdom for scenario-based software search", "authors": ["Zhixing Li\n,", "Tao Wang\n,", "Yang Zhang\n,", "Yun Zhan\n,", "Gang Yin"], "publication": "Internetware '16: Proceedings of the 8th Asia-Pacific Symposium on Internetware", "abstract": "ABSTRACT\nThe Internet-scale open source software (OSS) production in various communities are generating abundant reusable resources for software developers. However, how to retrieve and reuse the desired and mature software from huge amounts of candidates is a great challenge: there are usually big gaps between the user application contexts (that often used as queries) and the OSS key words (that often used to match the queries). In this paper, we define the scenario-based query problem for OSS retrieval, and then we propose a novel approach to reformulate the raw query by leveraging the crowd wisdom from millions of developers to improve the retrieval results. We build a software-specific domain lexical database based on the knowledge in open source communities, by which we can expand and optimize the input queries. The experiment results show that, our approach can reformulate the initial query effectively and outperforms other existing search engines significantly at finding mature software.", "references": ["A. Aula, and P. Majaranta. Eye-tracking reveals the personal styles for search result evaluation. In In Proceedings of INTERACT' 05, pages 1058--1061, 2005.", "V. Bhat, A. Gokhale, R. Jadhav, J. Pudipeddi, and L. Akoglu. Min(e)d your tags: Analysis of question response time in stackoverflow. In Ieee/acm International Conference on Advances in Social Networks Analysis and Mining, pages 328--335, 2014.", "T. F. Bissyande, F. Thung, D. Lo, L. Jiang, and L. Reveillere. Orion: A software project search engine with integrated diverse software artifacts. In International Conference on Engineering of Complex Computer Systems, pages 242--245, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993717.2993723"}, {"title": "That's Not My Question: Learning to Weight Unmatched Terms in CQA Vertical Search", "authors": ["Boaz Petersil\n,", "Avihai Mejer\n,", "Idan Szpektor\n,", "Koby Crammer"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nA fundamental task in Information Retrieval (IR) is term weighting. Early IR theory considered both the presence or absence of all terms in the lexicon for ranking and needed to weight them all. Yet, as the size of lexicons grew and models became too complex, common weighting models preferred to aggregate only the weights of the query terms that are matched in candidate documents. Thus, unmatched term contribution in these models is only considered indirectly, such as in probability smoothing with corpus distribution, or in weight normalization by document length. In this work we propose a novel term weighting model that directly assesses the weights of unmatched terms, and show its benefits. Specifically, we propose a Learning To Rank framework, in which features corresponding to matched terms are also \"mirrored\" in similar features that account only for unmatched terms. The relative importance of each feature is learned via a click-through query log. As a test case, we consider vertical search in Community-based Question Answering(CQA) sites from Web queries. Queries that result in viewing CQA content often contain fine grained information needs and benefit more from unmatched term weighting. We assess our model both via manual evaluation and via automatic evaluation over a clickthrough log. Our results show consistent improvement in retrieval when unmatched information is taken into account. This holds both when only identical terms are considered matched, and when related terms are matched via distributional similarity.", "references": ["G. Amati, V. Rijsbergen, and C. Joost. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20(4), Oct. 2002.", "J. Arguello, F. Diaz, J. Callan, and J.-F. Crespo. Sources of evidence for vertical selection. In SIGIR, 2009.", "M. Bendersky, D. Metzler, and W. B. Croft. Learning concept importance using a weighted dependence model. In WSDM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911496"}, {"title": "Virtual reality musical instruments: Guidelines for multisensory interaction design", "authors": ["Stefania Serafin\n,", "Cumhur Erkut\n,", "Juraj Kojs\n,", "Rolf Nordahl\n,", "Niels C. Nilsson"], "publication": "AM '16: Proceedings of the Audio Mostly 2016", "abstract": "ABSTRACT\nThe rapid development and availability of low cost technologies has created a wide interest in virtual reality (VR), but how to design and evaluate multisensory interactions in VR remains as a challenge. In this paper, we focus on virtual reality musical instruments, present an overview of our design and evaluation guidelines, and examine historical case studies. Our main contribution is to inform the design and evaluation of the future VRMIs and consider the challenges.", "references": ["Durand Begault. 1994. 3-D sound for virtual reality and multimedia. AP Professional, New York, NY, USA.", "Chuck Blanchard, Scott Burgess, Young Harvill, Jaron Lanier, Ann Lasko, Mark Oberman, Mike Teitel, Chuck Blanchard, Scott Burgess, Young Harvill, Ann Lasko, Mark Oberman, and Mike Teitel. 1990. Reality built for two: a virtual reality tool. SIGGRAPH Comput. Graph. 24, 2 (Feb. 1990), 35--36. DOI: http://dx.doi.org/10.1145/91385.91409", "Cumhur Erkut, Antti Jylhä, and Reha Discioglu. 2011. A Structured Design and Evaluation Model with Application to Rhythmic Interaction Displays. In Proceedings of the 2011 conference on New interfaces for musical expression. Oslo, Norway, 477--480."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986416.2986431"}, {"title": "Understanding User Satisfaction with Intelligent Assistants", "authors": ["Julia Kiseleva\n,", "Kyle Williams\n,", "Jiepu Jiang\n,", "Ahmed Hassan Awadallah\n,", "Aidan C. Crook\n,", "Imed Zitouni\n,", "Tasos Anastasakos"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nVoice-controlled intelligent personal assistants, such as Cortana, Google Now, Siri and Alexa, are increasingly becoming a part of users' daily lives, especially on mobile devices. They introduce a significant change in information access, not only by introducing voice control and touch gestures but also by enabling dialogues where the context is preserved. This raises the need for evaluation of their effectiveness in assisting users with their tasks. However, in order to understand which type of user interactions reflect different degrees of user satisfaction we need explicit judgements. In this paper, we describe a user study that was designed to measure user satisfaction over a range of typical scenarios of use: controlling a device, web search, and structured search dialogue. Using this data, we study how user satisfaction varied with different usage scenarios and what signals can be used for modeling satisfaction in the different scenarios. We find that the notion of satisfaction varies across different scenarios, and show that, in some scenarios (e.g. making a phone call), task completion is very important while for others (e.g. planning a night out), the amount of effort spent is key. We also study how the nature and complexity of the task at hand affects user satisfaction, and find that preserving the conversation context is essential and that overall task-level satisfaction cannot be reduced to query-level satisfaction alone. Finally, we shed light on the relative effectiveness and usefulness of voice-controlled intelligent agents, explaining their increasing popularity and uptake relative to the traditional query-response interaction.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: a game for modeling different types of web search success using interaction data. In SIGIR, 2011.", "M. Ageev, D. Lagun, and E. Agichtein. Improving search result summaries by using searcher behavior data. In SIGIR, pages 13--22, 2013.", "E. Agichtein, E. Brill, and S. T. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, pages 19--26, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854961"}, {"title": "An effective joint model for chinese word segmentation and POS tagging", "authors": ["Heng-Jun Wang\n,", "Nian-Wen Si\n,", "Cheng Chen"], "publication": "ICIIP '16: Proceedings of the 2016 International Conference on Intelligent Information Processing", "abstract": "ABSTRACT\nChinese word segmentation and Part-of-speech (POS) tagging have been studied for decades. However, most of the previous works mainly focus on pipeline method which will lead to error propagation. In order to make word segmentation and POS tagging jointly in one model, in this paper, we propose an effective neural network model to improve the accuracy of the segmentation and tagging. Our model works based on the hierarchical Long Short-Term Memory (LSTM) and trained jointly in one objective function. What's more, to better utilizing the transition features between tags, we further introduce the transition matrix which can help to search the best tagging sequence. Experiment on Chinese Treebank shows that our model achieves competitive accuracy on word segmentation and POS tagging.", "references": ["Zheng, X., Chen, H., & Xu, T. 2013. Deep learning for Chinese word segmentation and POS tagging. Conference on Empirical Methods in Natural Language Processing.", "Zhou, Q., Wen, L., Wang, X., Ma, L., & Wang, Y. 2016. A hierarchical lstm model for joint tasks. The 15th China National Conference on Computational Linguistics & The 4th International Symposium on Natural Laguage Processing based on Naturally Annotated Big Data.", "Martí, Nez, C., & Prodinger, H. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. Acl-02 Conference on Empirical Methods in Natural Language Processing (Vol.410, pp.1--8). Association for Computational Linguistics."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3028842.3028877"}, {"title": "Duplicate detection in web shops using LSH to reduce the number of computations", "authors": ["Iris van Dam\n,", "Gerhard van Ginkel\n,", "Wim Kuipers\n,", "Nikki Nijenhuis\n,", "Damir Vandic\n,", "Flavius Frasincar"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe amount of online shops is growing daily and many Web shops focus on the same product types, like consumer electronics. Since Web shops use different product representations, it is hard to compare products among different Web shops. Duplicate detection methods aim to solve this problem by identifying the same products in differentWeb shops. In this paper, we focus on reducing the computation time of a state-of-the-art duplicate detection algorithm. First, we construct uniform vector representations for the products. We use these vectors as input for a Locality Sensitive Hashing (LSH) algorithm, which pre-selects potential duplicates. Finally, duplicate products are found by applying the Multi-component Similarity Method (MSM). Compared to original MSM, the number of needed computations can be reduced by 95% with only a minor decrease by 9% in the F1-measure.", "references": ["P. Christen. A survey of indexing techniques for scalable record linkage and deduplication. IEEE Transactions on Knowledge and Data Engineering, 24(9):1537--1555, 2012.", "O. Chum, J. Philbin, and A. Zisserman. Near duplicate image detection: Min-Hash and TF-IDF weighting. In 19th British Machine Vision Conference. British Machine Vision Association, 2008. http://www.bmva.org/bmvc/2008/papers/119.pdf.", "K. L. Clarkson. An algorithm for approximate closest-point queries. In Proceedings of the Tenth Annual Symposium on Computational Geometry, pages 160--164. ACM, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851861"}, {"title": "Compression-Based Selective Sampling for Learning to Rank", "authors": ["Rodrigo M. Silva\n,", "Guilherme C.M. Gomes\n,", "Mário S. Alvim\n,", "Marcos A. Gonçalves"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLearning to rank (L2R) algorithms use a labeled training set to generate a ranking model that can be later used to rank new query results. These training sets are very costly and laborious to produce, requiring human annotators to assess the relevance or order of the documents in relation to a query. Active learning (AL) algorithms are able to reduce the labeling effort by actively sampling an unlabeled set and choosing data instances that maximize the effectiveness of a learning function. But AL methods require constant supervision, as documents have to be labeled at each round of the process. In this paper, we propose that certain characteristics of unlabeled L2R datasets allow for an unsupervised, compression-based selection process to be used to create small and yet highly informative and effective initial sets that can later be labeled and used to bootstrap a L2R system. We implement our ideas through a novel unsupervised selective sampling method, which we call Cover, that has several advantages over AL methods tailored to L2R. First, it does not need an initial labeled seed set and can select documents from scratch. Second, selected documents do not need to be labeled as the iterations of the method progress since it is unsupervised (i.e., no learning model needs to be updated). Thus, an arbitrarily sized training set can be selected without human intervention depending on the available budget. Third, the method is efficient and can be run on unlabeled collections containing millions of query-document instances. We run various experiments with two important L2R benchmarking collections to show that the proposed method allows for the creation of small, yet very effective training sets. It achieves full training-like performance with less than 10% of the original sets selected, outperforming the baselines in both effectiveness and scalability.", "references": ["G. Babu and E. Feigelson. Astrostatistics. Chapman & Hall/CRC Interdisciplinary Statistics. Taylor & Francis, 1996.", "K. Brinker. Incorporating diversity in active learning with support vector machines. ICML '03, pages 59--66, 2003.", "P. Cai, W. Gao, A. Zhou, and K. Wong. Relevant knowledge helps in choosing right teacher. SIGIR '11, pages 115--124, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983813"}, {"title": "Analysing Temporal Evolution of Interlingual Wikipedia Article Pairs", "authors": ["Simon Gottschalk\n,", "Elena Demidova"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWikipedia articles representing an entity or a topic in different language editions evolve independently within the scope of the language-specific user communities. This can lead to different points of views reflected in the articles, as well as complementary and inconsistent information. An analysis of how the information is propagated across the Wikipedia language editions can provide important insights in the article evolution along the temporal and cultural dimensions and support quality control. To facilitate such analysis, we present MultiWiki -- a novel web-based user interface that provides an overview of the similarities and differences across the article pairs originating from different language editions on a timeline. MultiWiki enables users to observe the changes in the interlingual article similarity over time and to perform a detailed visual comparison of the article snapshots at a particular time point.", "references": ["P. Bao, B. Hecht, S. Carton, et al. Omnipedia: Bridging the Wikipedia Language Gap. In Proceedings of CHI '12.", "E. Borra, D. Laniado, E. Weltevrede, et al. A Platform for Visually Exploring the Development of Wikipedia Articles. Proc. ICWSM, 2015.", "P. Massa and F. Scrinzi. Manypedia: Comparing Language Points of View of Wikipedia Communities. In Proceedings of the WikiSym '12."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911472"}, {"title": "Search Engines that Learn from Their Users", "authors": ["Anne Schuth"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nMore than half the world's population uses web search engines, resulting in over half a billion queries every single day. For many people, web search engines such as Baidu, Bing, Google, and Yandex are among the first resources they go to when a question arises. Moreover, for many search engines have become the most trusted route to information, more so even than traditional media such as newspapers, news websites or news channels on television. What web search engines present people with greatly influences what they believe to be true and consequently it influences their thoughts, opinions, decisions, and the actions they take. With this in mind two things are important, from an information retrieval research perspective. First, it is important to understand how well search engines (rankers) perform and secondly this knowledge should be used to improve them. This thesis is about these two topics: evaluation of search engines and learning search engines.\nIn the first part of this thesis we investigate how user interactions with search engines can be used to evaluate search engines. In particular, we introduce a new online evaluation paradigm called multileaving that extends upon interleaving. With multileaving, many rankers can be compared at once by combining document lists from these rankers into a single result list and attributing user interactions with this list to the rankers. Then we investigate the relation between A/B testing and interleaved comparison methods. Both studies lead to much higher sensitivity of the evaluation methods, meaning that fewer user interactions are required to arrive at reliable conclusions. This has the important implication that fewer users need to be exposed to the results from possibly inferior search engines.\nIn the second part of this thesis we turn to online learning to rank. We learn from the evaluation methods introduced and extended upon in the first part. We learn the parameters of base rankers based on user interactions. Then we use the multileaving methods as feedback in our learning method, leading to much faster convergence than existing methods. Again, the important implication is that fewer users need to be exposed to possibly inferior search engines as they adapt more quickly to changes in user preferences. The last part of this thesis is of a different nature than the earlier two parts. As opposed to the earlier chapters, we no longer study algorithms. Progress in information retrieval research has always been driven by a combination of algorithms, shared resources, and evaluation.\nIn the last part we focus on the latter two. We introduce a new shared resource and a new evaluation paradigm. Firstly, we propose Lerot. Lerot is an online evaluation framework that allows us to simulate users interacting with a search engine. Our implementation has been released as open source software and is currently being used by researchers around the world. Secondly we introduce OpenSearch, a new evaluation paradigm involving real users of real search engines. We describe an implementation of this paradigm that has already been widely adopted by the research community through challenges at CLEF and TREC.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964817"}, {"title": "Session details: Demonstrations", "authors": ["Alfredo Cuzzocrea\n,", "Abdulmotaleb El Saddik"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIt is our great pleasure to welcome you to the Demo Track of WWW 2016, The 25th International World Wide Web Conference, held in Montreal, Canada, during April 11-15, 2016.\nThe WWW 2016 Demo Track, like in the tradition of WWW Demo conference series, allows researchers and practitioners to demonstrate new systems in a dedicated session. Demo contributions are based on an implemented and tested system that pursues one or more innovative ideas in the interest areas of Web data and information management, Web search, Web intelligence tools, Web mining, social network applications and so forth. Topics of interest for the 2016 edition's conference include (but are not limited to) the following ones:\nBehavioral Analysis and Personalization\nBig Data on the Web\nCrowdsourcing Systems and Social Media\nContent Analysis\nGraph Data Management and Mining\nHigh-Performance Infrastructures for Data- Intensive Web Tasks\nInternet Economics and Monetization\nPervasive Web and Mobility\nSecurity and Privacy\nSemantic Web\nSocial Networks and Graph Analysis\nWeb Information Retrieval\nWeb Infrastructure: Datacenters, Content Delivery Networks, and Cloud Computing\nWeb Mining\nWeb Science\nWeb Search Systems and Applications\nDemo contributions come from academic researchers, industrial practitioners with prototypes or inproduction deployments, as well as from any W3C-related activities. All have in common to show innovative use of Web-based techniques.\nThe WWW 2016 Demo Track call for papers attracted 65 submissions from all over the world (USA, North America, South America, Europe, Australia, Asia, Africa). The program committee reviewed and accepted a very selected collection of 29 papers, and the final statistics is the following: WWW 2016 Demo Track Statistics Number of Submitted Papers 65 Number of Accepted Papers 29.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2872518.3251208"}, {"title": "A Comparative Study of Query-biased and Non-redundant Snippets for Structured Search on Mobile Devices", "authors": ["Nikita V. Spirin\n,", "Alexander S. Kotov\n,", "Karrie G. Karahalios\n,", "Vassil Mladenov\n,", "Pavel A. Izhutov"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTo investigate what kind of snippets are better suited for structured search on mobile devices, we built an experimental mobile search application and conducted a task-oriented interactive user study with 36 participants. Four different versions of a search engine result page (SERP) were compared by varying the snippet type (query-biased vs. non-redundant) and the snippet length (two vs. four lines per result). We adopted a within-subjects experiment design and made each participant do four realistic search tasks using different versions of the application. During the study sessions, we collected search logs, \"think-aloud\" comments, and post-task surveys. Each session was finalized with an interview. We found that with non-redundant snippets the participants were able to complete the tasks faster and find more relevant results. Most participants preferred non-redundant snippets and wanted to see more information about each result on the SERP for any snippet type. Yet, the participants felt that the version with query-biased snippets was easier to use. We conclude with a set of practical design recommendations.", "references": ["N. J. Belkin, D. Kelly, G. Kim, J.-Y. Kim, H.-J. Lee, G. Muresan, M.-C. Tang, X.-J. Yuan, and C. Cool. Query length in interactive information retrieval. SIGIR '03, 2003.", "P. Borlund. Experimental components for the evaluation of interactive information retrieval systems. Journal of documentation, 56(1):71--90, 2000.", "G. Das, V. Hristidis, N. Kapoor, and S. Sudarshan. Ordering the attributes of query results. SIGMOD '06."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983699"}, {"title": "An Optimization Framework for Remapping and Reweighting Noisy Relevance Labels", "authors": ["Yury Ustinovskiy\n,", "Valentina Fedorova\n,", "Gleb Gusev\n,", "Pavel Serdyukov"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRelevance labels is the essential part of any learning to rank framework. The rapid development of crowdsourcing platforms led to a significant reduction of the cost of manual labeling. This makes it possible to collect very large sets of labeled documents to train a ranking algorithm. However, relevance labels acquired via crowdsourcing are typically coarse and noisy, so certain consensus models are used to measure the quality of labels and to reduce the noise. This noise is likely to affect a ranker trained on such labels, and, since none of the existing consensus models directly optimizes ranking quality, one has to apply some heuristics to utilize the output of a consensus model in a ranking algorithm, e.g., to use majority voting among workers to get consensus labels. The major goal of this paper is to unify existing approaches to consensus modeling and noise reduction within a learning to rank framework. Namely, we present a machine learning algorithm aimed at improving the performance of a ranker trained on a crowdsourced dataset by proper remapping of labels and reweighting of samples. In the experimental part, we use several characteristics of workers/labels extracted via various consensus models in order to learn the remapping and reweighting functions. Our experiments on a large-scale dataset demonstrate that we can significantly improve state-of-the-art machine-learning algorithms by incorporating our framework.", "references": ["C. Burges, R. Rango, and Q. Viet Le. Learning to rank with nonsmooth cost functions. Proceedings of the Advances in Neural Information Processing Systems, 19:193--200, 2007.", "C. Burges, K. Svore, P. Bennett, A. Pastusiak, Q. Wu, O. Chapelle, Y. Chang, and T. yan Liu. Learning to rank using an ensemble of lambda-gradient models. JMLR, pages 25--35, 2011.", "O. Chapelle and Y. Chang. Yahoo! learning to rank challenge overview. In Yahoo! Learning to Rank Challenge, pages 1--24, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911501"}, {"title": "Detecting Devastating Diseases in Search Logs", "authors": ["John Paparrizos\n,", "Ryen W. White\n,", "Eric Horvitz"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWeb search queries can offer a unique population-scale window onto streams of evidence that are useful for detecting the emergence of health conditions. We explore the promise of harnessing behavioral signals in search logs to provide advance warning about the presence of devastating diseases such as pancreatic cancer. Pancreatic cancer is often diagnosed too late to be treated effectively as the cancer has usually metastasized by the time of diagnosis. Symptoms of the early stages of the illness are often subtle and nonspecific. We identify searchers who issue credible, first-person diagnostic queries for pancreatic cancer and we learn models from prior search histories that predict which searchers will later input such queries. We show that we can infer the likelihood of seeing the rise of diagnostic queries months before they appear and characterize the tradeoff between predictivity and false positive rate. The findings highlight the potential of harnessing search logs for the early detection of pancreatic cancer and more generally for harnessing search systems to reduce health risks for individuals.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. SIGIR, 19--26, 2006.", "S. L. Ayers and J. J. Kronenfeld. Chronic illness and health-seeking information on the internet. Health, 11(3): 327--347, 2007.", "J. L. Bader and M. F. Theofanos. Searching for cancer information on the internet: Analyzing natural language search queries. JMIR, 5(4), 2003.", "P. Bennett, K. Svore, and S. Dumais. Classification -enhanced ranking. WWW, 111--120, 2010.", "E. V. Bernstam, J. R. Herskovic, and W. R. Hersh. Query log analysis in biomedicine. Handbook of Research on Web Log Analysis, 359--377, 2009.", "K. Castleton et al. A survey of internet utilization among patients with cancer. Supportive Care in Cancer, 19(8): 1183--1190, 2011.", "S. T. Chari et al. Early detection of sporadic pancreatic cancer: Summative review. Pancreas, 44(5): 693, 2015.", "R. J. Cline and K. M. Haynes. Consumer health information seeking on the internet: The state ofthe art. Health Education Research, 16(6): 671--692, 2001.", "S. S. Coughlin et al. Predictors of pancreatic cancer mortality among a large cohort of united states adults. Cancer Causes & Control, 11(10): 915--923, 2000.", "M. De Choudhury, S. Counts, and E. Horvitz. Predicting postpartum changes in emotion and behavior via social media. SIGCHI, 3267--3276, 2013.", "M. De Choudhury, M. R. Morris, and R. W. White. Seeking and sharing health information online: Comparing search engines and social media. SIGCHI, 1365--1376, 2014.", "E. R. DeLong, D. M. DeLong, and D. L. Clarke-Pearson. Comparing the areas under two or more correlated receiver operating characteristic curves: A nonparametric approach. Biometrics, 837--845, 1988.", "D. Downey, S. T. Dumais, and E. Horvitz. Models of searching and browsing: Languages, studies, and application. IJCAI, 2740--2747, 2007.", "J. Everhart and D. Wright. Diabetes mellitus as a risk factor for pancreatic cancer: A meta-analysis. JAMA, 273(20): 1605--1609, 1995.", "A. Fourney, R. W. White, and E. Horvitz. Exploring time-dependent concerns about pregnancy and childbirth from search logs. SIGCHI, 737--746, 2015.", "S. Fox and M. Duggan. Health online 2013, 2013.", "J. H. Friedman. Greedy function approximation: A gradient boosting machine. Annals of Statistics, 1189--1232, 2001.", "C. S. Fuchs et al. A prospective study of cigarette smoking and the risk of pancreatic cancer. Archives of Int. Med., 156(19): 2255--2260, 1996.", "J. Ginsberg et al. Detecting influenza epidemics using search engine query data. Nature, 457(7232): 1012--1014, 2009.", "A. M. Goldstein et al. Increased risk of pancreatic cancer in melanoma-prone kindreds with p16 ink4 mutations. NEJM, 333(15): 970--975, 1995.", "P. R. Helft. Patients with cancer, internet information, and the clinical encounter: a taxonomy of patient users. American Society of Clinical Oncology Educational Book, pages e89--92, 2011.", "R. H. Hruban et al. Progression model for pancreatic cancer. Clin. Cancer Res., 6(8): 2969--2972, 2000.", "R. Huxley et al. Type-II diabetes and pancreatic cancer: a meta-analysis of 36 studies. British J. of Cancer, 92(11): 2076--2083, 2005.", "T. Joachims. Optimizing search engines using clickthrough data. SIGKDD, 133--142, 2002.", "R. Jones et al. Generating query substitutions. WWW, 387--396, 2006.", "J. Klapman and M. P. Malafa. Early detection of pancreatic cancer: Why, who, and how to screen. Cancer Control, 15(4): 280--287, 2008.", "T. Lau and E. Horvitz. Patterns of search: Analyzing and modeling web query refinement. UMAP, 1999.", "C. Lauckner and G. Hsieh. The presentation of health-related search results and its impact on negative emotional outcomes. SIGCHI, 333--342, 2013.", "P. Legmann et al. Pancreatic tumors: comparison of dual-phase helical CT and endoscopic sonography. American J. Roentgenology, 170(5): 1315--1322, 1998.", "D. Li et al. Pancreatic cancer. The Lancet, 363(9414): 1049--1057, 2004.", "A. B. Lowenfels and P. Maisonneuve. Epidemiology and risk factors for pancreatic cancer. Best Practice & Research Clinical Gastro., 20(2):197--209, 2006.", "A. B. Lowenfels et al. Pancreatitis and the risk of pancreatic cancer. NEJM, 328(20): 1433--1437, 1993.", "H. T. Lynch et al. Familial pancreatic cancer: A review. Seminars in Oncology, 23: 251--275, 1996.", "K. McKeown et al. Predicting the impact of scientific concepts using full-text features. JASIST, 2016.", "H. R. Mertz et al. EUS, PET, and CT scanning for evaluation of pancreatic adenocarcinoma. Gastrointestinal Endoscopy, 52(3): 367--371, 2000.", "D. Michaud. Epidemiology of pancreatic cancer. Minerva Chirurgica, 59(2): 99--111, 2004.", "M. Müller et al. Pancreatic tumors: Evaluation with endoscopic US, CT, and MRimaging. Radiology, 190(3):745--751, 1994.", "Y. Ofran et al. Patterns of information-seeking for cancer on the internet: An analysis of real world data. PLoS One, 2012.", "J. Paparrizos, R. W. White, and E. Horvitz. Screening for pancreatic adenocarcinoma using signals from web searchlogs: Feasibility study and results. JOP, 2016.", "M. J. Paul, R. W. White, and E. Horvitz. Search and breast cancer: On disruptive shifts of attention overlife histories of an illness. TWEB, 10(2): 13, 2016.", "M. S. Pepe et al. Phases of biomarker development for early detection of cancer. J. Nat. Cancer Inst., 93(14): 1054--1061, 2001.", "G. Peterson, P. Aslani, and K. A. Williams. How do consumers search for and appraise information on medicines on the internet? A qualitative study using focus groups. JMIR, 5(4), 2003.", "A. G. Renehan et al. Body-mass index and incidence of cancer: A systematic review and meta-analysis of prospective observational studies. The Lancet, 371(9612): 569--578, 2008.", "M. Richardson. Learning about the world from long-term query logs. TWEB, 2(4): 21, 2009.", "S. J. Rulyak et al. Cost-effectiveness of pancreatic cancer screening in familial pancreatic cancer kindreds. Gastrointestinal Endoscopy, 57(1): 23--29, 2003.", "A. Sadilek, H. Kautz, and V. Silenzio. Modeling spread of disease from social interactions. ICWSM, 2012.", "\\relax American Cancer Society. Staging pancreatic cancer. http://www.cancer.org/cancer/pancreaticcancer/detailedguide/pancreatic-cancer-pdf, 2014.", "G. Talamin et al. Alcohol and smoking as risk factors in chronic pancreatitis and pancreatic cancer. Digestive Diseases and Sci., 44(7): 1303--1311, 1999.", "M. I. Trotter and D. W. Morgan. Patients' use of the internet for health related matters: A study of internet usage in 2000 & 2006. Health Inf., 14(3):175--181, 2008.", "R. West, R. W. White, and E. Horvitz. From cookies to cooks: Insights on dietary patterns via analysis of web usage logs. WWW, 1399--1410, 2013.", "R. White and S. Drucker. Investigating behavioral variability in web search. WWW, 21--30, 2007.", "R. W. White et al. Toward enhanced pharmacovigilance using patient-generated data on the internet. Nature CPT, 96(2): 239--246, 2014.", "R. W. White and E. Horvitz. Cyberchondria: Studies of the escalation of medical concerns in web search. TOIS, 27(4): 23, 2009.", "R. W. White and E. Horvitz. Studies of the onset and persistence of medical concerns in search logs. SIGIR, 265--274, 2012.", "R. W. White and E. Horvitz. From health search to healthcare: Explorations of intention and utilization via query logs and user surveys. JAMIA, 21(1): 49--55, 2014.", "R. W. White et al. Web-scale pharmacovigilance: Listening to signals from the crowd. JAMIA, 20(3): 404--408, 2013.", "R. W. White et al. Early identification of adverse drug reactions from search log data. JBI, 59: 42--48, 2016.", "C. J. Yeo et al. Pancreaticoduodenectomy for pancreatic adenocarcinoma: Post operative adjuvant chemoradiation improves survival. Annals of Surgery, 225(5): 621, 1997.", "J. Yu et al. Time to progression of pancreatic ductal adenocarcinoma from low-to-high tumour stages. Gut, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939722"}, {"title": "A Crowd-Powered System for Fashion Similarity Search", "authors": ["Theodoros Semertzidis\n,", "Jasminko Novak\n,", "Michalis Lazaridis\n,", "Mark Melenhorst\n,", "Isabel Micheel\n,", "Dimitrios Michalopoulos\n,", "Martin Böckle\n,"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nDriven by the needs of customers and industry, online fashion search and analytics are recently gaining much attention. As fashion is mostly expressed by visual content, the analysis of fashion images in online social networks is a rich source of possible insights on evolving trends and customer preferences. Although a plethora of visual content is available, the modeling of clothes’ physics and movement, the implicit semantics in fashion designs, and the subjectivity of their interpretation pose difficulties to fully automated solutions for fashion search and analysis. In this article, we present the design and evaluation of a crowd-powered system for fashion similarity search from Twitter, supporting trend analysis for fashion professionals. The system enables fashion similarity search based on specific human-based similarity criteria. This is achieved by implementing a novel machine--crowd workflow that supports complex tasks requiring highly subjective judgments where multiple true solutions may coexist. We discuss how this leads to a novel class of crowd-powered systems for which the output of the crowd is not used to verify the automatic analysis but is the desired outcome. Finally, we show how this kind of crowd involvement enables a novel kind of similarity search and represents a crucial factor for the acceptance of system results by the end user.", "references": ["L. M. Aiello, G. Petkos, C. Martin, D. Corney, S. Papadopoulos, R. Skraba, A. Goker, I. Kompatsiaris, and A. Jaimes. 2013. Sensing trending topics in Twitter. IEEE Transactions on Multimedia, 15, 6, 1268--1282.", "Lora Aroyo and Chris Welty. 2013. Crowd truth: Harnessing disagreement in crowdsourcing a relation extraction gold standard. WebSci2013. ACM.", "Anurag Bhardwaj, Atish Das Sarma, Wei Di, Raffay Hamid, Robinson Piramuthu, and Neel Sundaresan. 2013. Palette power: Enabling visual search through colors. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’13). ACM, New York, NY, 1321--1329."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897365"}, {"title": "An Analysis of Age, Technology Usage, and Cognitive Characteristics Within Information Retrieval Tasks", "authors": ["Michael Crabb\n,", "Vicki L. Hanson"], "publication": "ACM Transactions on Accessible Computing", "abstract": "Abstract\nThis work presents two studies that aim to discover whether age can be used as a suitable metric for distinguishing performance between individuals or if other factors can provide greater insight. Information retrieval tasks are used to test the performance of these factors. First, a study is introduced that examines the effect that fluid intelligence and Internet usage has on individuals. Second, a larger study is reported on that examines a collection of Internet and cognitive factors in order to determine to what extent each of these metrics can account for disorientation in users.\nThis work adds to growing evidence showing that age is not a suitable metric to distinguish between individuals within the field of human-computer interaction. It shows that factors such as previous Internet experience and fluid-based cognitive abilities can be used to gain better insight into users’ reported browsing experience during information retrieval tasks.", "references": ["J. S. Ahuja and J. Webster. 2001. Perceived disorientation: An examination of a new measure to assess web design effectiveness. Interacting with Computers 14, 1, 15--29.", "B. Allen. 1992. Cognitive differences in end user searching of a CD-ROM index. In Proceedings of the 15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM. 298--309.", "B. Allen. 1994. Perceptual speed, learning and information retrieval performance. In Proceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval. Springer, London. 71--80."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2856046"}, {"title": "Using Photos as Micro-Reports of Events", "authors": ["Siripen Pongpaichet\n,", "Mengfan Tang\n,", "Laleh Jalali\n,", "Ramesh Jain"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nPhotos serve dual role. Photos are important for capturing, saving, sharing, and reminiscing memories of events and people. Modern photos, however, are becoming more spontaneous, objective, compelling, and universal reports of a moment in an event also. In this paper our focus is on millions of photos being captured as informative reports and using them for emerging applications including situation recognition, trend analysis, and cultural dynamics. EventShop is an open source platform for situation recognition. Utilizing this platform and using a stream of photo reports from various sources as one of the data streams in this platform, we build a visual analytics system to understand the information that could be gleaned from such photo report streams. Our early experiments are based on the Yahoo Flickr Creative Commons 100 Million photos set released recently. We are also using other sources to import and understand the efficacy of these reports for various important applications.", "references": ["S. Alsubaiee, Y. Altowim, H. Altwaijry, A. Behm, V. Borkar, Y. Bu, M. Carey, I. Cetindil, M. Cheelangi, K. Faraaz, et al. Asterixdb: A scalable, open source bdms. Proceedings of the VLDB Endowment, 7(14):1905--1916, 2014.", "L. Barbosa and J. Feng. Robust sentiment detection on twitter from biased and noisy data. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 36--44. Association for Computational Linguistics, 2010.", "S.-F. Chang, D. Ellis, W. Jiang, K. Lee, A. Yanagawa, A. C. Loui, and J. Luo. Large-scale multimodal semantic concept detection for consumer video. In Proceedings of the international workshop on Workshop on multimedia information retrieval, pages 255--264. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912020"}, {"title": "Diversified Top-k Subgraph Querying in a Large Graph", "authors": ["Zhengwei Yang\n,", "Ada Wai-Chee Fu\n,", "Ruifeng Liu"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nSubgraph querying in a large data graph is interesting for different applications. A recent study shows that top-k diversified results are useful since the number of matching subgraphs can be very large. In this work, we study the problem of top-k diversified subgraph querying that asks for a set of up to k subgraphs isomorphic to a given query graph, and that covers the largest number of vertices. We propose a novel level-based algorithm for this problem which supports early termination and has a theoretical approximation guarantee. From experiments, most of our results on real datasets used in previous works are near optimal with a query time within 10ms on a commodity machine.", "references": ["N. Alon. On the number of subgraphs of presribed type of graphs with a given number of edges. Israel Journal of Mathematics, 38(1--1):116--130, 1981.", "A. Angel and N. Koudas. Efficient diversity-aware search. In SIGMOD, 2011.", "G. Ausiello, N. Boria, A. Giannakos, G. Lucarelli, and V. T. Paschos. Online maximum k-coverage. Discrete Applied Mathematics, 160(13--14):1901--1913, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2915216"}, {"title": "Session details: Big Data Analytics for Health", "authors": ["Alain April"], "publication": "DH '16: Proceedings of the 6th International Conference on Digital Health Conference", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3257759"}, {"title": "Flexible entity search on surfaces", "authors": ["Tuukka Ruotsalo\n,", "Khalil Klouche\n,", "Diogo Cabral\n,", "Salvatore Andolina\n,", "Giulio Jacucci"], "publication": "MUM '16: Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia", "abstract": "ABSTRACT\nSurface computing allows flexible search interaction where users can manipulate the representation of entities recommended for them to create new queries or augment existing queries by taking advantage of increased screen estate and almost physical tactile interaction. We demonstrate a search system based on 1) Direct Manipulation of Entity Representation on Surfaces and 2) Entity Recommendation and Document Retrieval. Entities are modeled as a knowledge-graph and the relevances of entities are computed using the graph structure. Users can manipulate the representation of entities via spatial grouping and assigning preferences on entities. Our contribution can help to design effective information exploration systems that take advantage of large surfaces.", "references": ["Ahn, J.-W., and Brusilovsky, P. Adaptive visualization for exploratory information retrieval. Inf. Proc. Man. 49, 5 (Sept. 2013), 1139--1164.", "Balog, K., Bron, M., and De Rijke, M. Query modeling for entity search based on terms, categories, and examples. ACM Trans. Inf. Syst. 29, 4 (Dec. 2011), 22:1--22:31.", "Chau, D. H., Kittur, A., Hong, J. I., and Faloutsos, C. Apolo: Making sense of large network data by combining rich user interaction and machine learning. In Proc. CHI '11, ACM (2011), 167--176."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012709.3012732"}, {"title": "Mining metadata from the web for AcousticBrainz", "authors": ["Alastair Porter\n,", "Dmitry Bogdanov\n,", "Xavier Serra"], "publication": "DLfM 2016: Proceedings of the 3rd International workshop on Digital Libraries for Musicology", "abstract": "ABSTRACT\nSemantic annotations of music collections in digital libraries are important for organization and navigation of the collection. These annotations and their associated metadata are useful in many Music Information Retrieval tasks, and related fields in musicology. Music collections used in research are growing in size, and therefore it is useful to use semi-automatic means to obtain such annotations. We present software tools for mining metadata from the web for the purpose of annotating music collections. These tools expand on data present in the AcousticBrainz database, which contains software-generated analysis of music audio files. Using this tool we gather metadata and semantic information from a variety of sources including both community-based services such as MusicBrainz, Last.fm, and Discogs, and commercial databases including Itunes and AllMusic. The tool can be easily expanded to collect data from a new source, and is automatically updated when new items are added to AcousticBrainz. We extract genre annotations for recordings in AcousticBrainz using our tool and study the agreement between folksonomies and expert sources. We discuss the results and explore possibilities for future work.", "references": ["D. Bogdanov and P. Herrera. Taking Advantage of Editorial Metadata to Recommend Music. In International Symposium on Computer Music Modeling and Retrieval), 2012.", "P. Cimiano, A. Hotho, and S. Staab. Learning concept hierarchies from text corpora using formal concept analysis. Journal of Artificial Intelligence Research, 24:305--339, 2005.", "A. J. Craft, G. A. Wiggins, and T. Crawford. How many beans make five? the consensus problem in music-genre classification and a new evaluation method for single-genre categorisation systems. In International Society for Music Information Retrieval Conference, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970044.2970048"}, {"title": "Optimizing Similar Item Recommendations in a Semi-structured Marketplace to Maximize Conversion", "authors": ["Yuri M. Brovman\n,", "Marie Jacob\n,", "Natraj Srinivasan\n,", "Stephen Neola\n,", "Daniel Galron\n,", "Ryan Snyder\n,", "Paul Wang"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis paper tackles the problem of recommendations in eBay's large semi-structured marketplace. eBay's variable inventory and lack of structured information about listings makes traditional collaborative filtering algorithms difficult to use. We discuss how to overcome these data limitations to produce high quality recommendations in real time with a combination of a customized scalable architecture as well as a widely applicable machine learned ranking model. A pointwise ranking approach is utilized to reduce the ranking problem to a binary classification problem optimized on past user purchase behavior. We present details of a sampling strategy and feature engineering that have been critical to achieve a lift in both purchase through rate (PTR) and revenue.", "references": ["Apache Spark, spark.apache.org/.", "D. Arya, V. Ha-Thuc, and S. Sinha. Personalized federated search at LinkedIn. In CIKM, 2015.", "Elasticsearch, www.elastic.co/products/elasticsearch."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959166"}, {"title": "Session details: Big Data and Social Media for Public Health Surveillance", "authors": ["Patty Kostkova"], "publication": "DH '16: Proceedings of the 6th International Conference on Digital Health Conference", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3257761"}, {"title": "Predicting User Engagement with Direct Displays Using Mouse Cursor Information", "authors": ["Ioannis Arapakis\n,", "Luis A. Leiva"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPredicting user engagement with direct displays (DD) is of paramount importance to commercial search engines, as well as to search performance evaluation. However, understanding within-content engagement on a web page is not a trivial task mainly because of two reasons: (1) engagement is subjective and different users may exhibit different behavioural patterns; (2) existing proxies of user engagement (e.g., clicks, dwell time) suffer from certain caveats, such as the well-known position bias, and are not as effective in discriminating between useful and non-useful components. In this paper, we conduct a crowdsourcing study and examine how users engage with a prominent web search engine component such as the knowledge module (KM) display. To this end, we collect and analyse more than 115k mouse cursor positions from 300 users, who perform a series of search tasks. Furthermore, we engineer a large number of meta-features which we use to predict different proxies of user engagement, including attention and usefulness. In our experiments, we demonstrate that our approach is able to predict more accurately different levels of user engagement and outperform existing baselines.", "references": ["I. Arapakis, M. Lalmas, B. B. Cambazoglu, M.-C. Marcos, and J. M. Jose. User engagement in online news: Under the scope of sentiment, interest, affect, and gaze. JASIST, 65(10), 2014.", "I. Arapakis, M. Lalmas, and G. Valkanas. Understanding within-content engagement through pattern analysis of mouse gestures. In Proc. CIKM, 2014.", "I. Arapakis, L. A. Leiva, and B. B. Cambazoglu. Know your onions: Understanding the user experience with the knowledge module in web search. In Proc. CIKM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911505"}, {"title": "Foodness Proposal for Multiple Food Detection by Training of Single Food Images", "authors": ["Wataru Shimoda\n,", "Keiji Yanai"], "publication": "MADiMa '16: Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management", "abstract": "ABSTRACT\nWe propose a CNN-based \"food-ness\" proposal method which requires neither pixel-wise annotation nor bounding box annotation. Some proposal methods have been proposed to detect regions with high \"object-ness\" so far. However, many of them generated a large number of candidates to raise the recall rate. Considering the recent advent of the deeper CNN, these methods to generate a large number of proposals have difficulty in processing time for practical use. Meanwhile, a fully convolutional network (FCN) was proposed the network of which localizes target objects directly. FCN saves computational cost, although FCN is essentially equivalent to the sliding window search. This approach made large progress and achieved significant success in various tasks.\nThen, in this paper we propose an intermediate approach between the traditional proposal approach and the fully convolutional approach. Especially we propose a novel proposal method which generates high \"food-ness\" regions by fully convolutional networks and back-propagation based approach with training food images gathered from the Web.", "references": ["M. Bosch, F. Zhu, N. Khanna, C. J. Boushey, and E. J. Delp. Combining global and local features for food identification in dietary assessment. In Proc. of IEEE International Conference on Image Processing, 2011.", "L. Bossard, M. Guillaumin, and L. V. Gool. Food-101 - mining discriminative components with random forests. In Proc. of European Conference on Computer Vision, 2014.", "L. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and Y. A. L. Semantic image segmentation with deep convolutional nets and fully connected CRFs. In Proc. of International Conference on Learning Representations, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2986035.2986043"}, {"title": "Current Directions for Usage Analysis and the Web of Data: The Diverse Ecosystem of Web of Data Access Mechanisms", "authors": ["Markus Luczak-Roesch\n,", "Laura Hollink\n,", "Bettina Berendt"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nUsage mining always was and still is a key topic for research in the context of the Web [16]. This is evidenced by the series of papers that appear in the scientific tracks of the WWW conference year by year. Web usage is being studied to create economic value by placing targeted ads or delivering personalized content, but also in order to better understand how people behave online in mass movements and collective action.", "references": ["B. Berendt, L. Hollink, V. Hollink, M. Luczak-Rösch, K. Möller, and D. Vallet. Usage analysis and the web of data. ACM SIGIR Forum, 45(1):63--69, 2011.", "C. Bizer, K. Eckert, R. Meusel, H. Mühleisen, M. Schuhmacher, and J. Völker. Deployment of rdfa, microdata, and microformats on the web--a quantitative analysis. In The semantic web--ISWC 2013, pages 17--32. Springer, 2013.", "C. Buil-Aranda, A. Hogan, J. Umbrich, and P.-Y. Vandenbussche. Sparql web-querying infrastructure: Ready for action? In The Semantic Web--ISWC 2013, pages 277--293. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891068"}, {"title": "Towards a Vocabulary Terms Discovery Assistant", "authors": ["Ioannis Stavrakantonakis\n,", "Anna Fensel\n,", "Dieter Fensel"], "publication": "SEMANTiCS 2016: Proceedings of the 12th International Conference on Semantic Systems", "abstract": "ABSTRACT\nThe Linked Open Vocabularies (LOV) curated directory list of vocabularies has changed radically the way that engineers are assisted to explore the vocabulary space by searching for terms and vocabularies using the provided keyword based search. Running a survey regarding the decision of the vocabulary terms that can be used to annotate a specific webpage, we realised the gap between the vocabulary creators side and the vocabulary users. In this direction, the presented framework, namely the LOVR framework, aims to facilitate the vocabulary terms discovery by providing a Web service with a set of endpoints that can be invoked to get a list of recommended terms for a given webpage. Within this work, we present the framework architecture and the fundamental parts of the prototype that implements the methodology behind the LOVR framework, which leverages the LOV search. Furthermore, the various endpoints of the Web service are described by explaining their usage scenarios.", "references": ["G. A. Atemezing and R. Troncy. Information content based ranking metric for Linked Open Vocabularies. In Proceedings of the 10th International Conference on Semantic Systems, pages 53--56. ACM, 2014.", "A. S. Butt. Ontology search: Finding the right ontologies on the Web. In Proceedings of the 24th International Conference on World Wide Web Companion, pages 487--491. International World Wide Web Conferences Steering Committee, 2015.", "M. B. Ellefi, Z. Bellahsene, and K. Todorov. Datavore: a vocabulary recommender tool assisting Linked Data modeling. Proceedings of ISWC Posters & Demonstrations Track, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2993318.2993347"}, {"title": "Learning to Account for Good Abandonment in Search Success Metrics", "authors": ["Madian Khabsa\n,", "Aidan Crook\n,", "Ahmed Hassan Awadallah\n,", "Imed Zitouni\n,", "Tasos Anastasakos\n,", "Kyle Williams"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAbandonment in web search has been widely used as a proxy to measure user satisfaction. Initially it was considered a signal of dissatisfaction, however with search engines moving towards providing answer-like results, a new category of abandonment was introduced and referred to as Good Abandonment. Predicting good abandonment is a hard problem and it was the subject of several previous studies. All those studies have focused, though, on predicting good abandonment in offline settings using manually labeled data. Thus, it remained a challenge how to have an online metric that accounts for good abandonment. In this work we describe how a search success metric can be augmented to account for good abandonment sessions using a machine learned metric that depends on user's viewport information. We use real user traffic from millions of users to evaluate the proposed metric in an A/B experiment. We show that taking good abandonment into consideration has a significant effect on the overall performance of the online metric.", "references": ["Google mobile numbers. http://adwords.blogspot.com/2015/05/building-for-next-moment.html, 2015. Last accessed 2--2-2016.", "O. Arkhipova and L. Grauer. Evaluating mobile web search performance by taking good abandonment into account. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval, pages 1043--1046. ACM, 2014.", "A. Chuklin and P. Serdyukov. Good abandonments in factoid queries. In Proceedings of the 21st international conference companion on World Wide Web, pages 483--484. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983867"}, {"title": "Meta-Prod2Vec: Product Embeddings Using Side-Information for Recommendation", "authors": ["Flavian Vasile\n,", "Elena Smirnova\n,", "Alexis Conneau"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe propose Meta-Prod2vec, a novel method to compute item similarities for recommendation that leverages existing item metadata. Such scenarios are frequently encountered in applications such as content recommendation, ad targeting and web search. Our method leverages past user interactions with items and their attributes to compute low-dimensional embeddings of items. Specifically, the item metadata is injected into the model as side information to regularize the item embeddings. We show that the new item representations lead to better performance on recommendation tasks on an open music dataset.", "references": ["Recsys 2015: Making meaningful restaurant recommendations at opentable. http://tinyurl.com/zs9at2t. Accessed: 2016-04-08.", "Venture beat article. http://venturebeat.com/2006/12/10/aggregate-knowledge-raises-5m-from-kleiner-on-a-roll/. Accessed: 2016-04-08.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '09, pages 19--28, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959160"}, {"title": "Temponym Tagging: Temporal Scopes for Textual Phrases", "authors": ["Erdal Kuzey\n,", "Jannik Strötgen\n,", "Vinay Setty\n,", "Gerhard Weikum"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nFor many NLP and IR applications, anchored temporal information extracted from textual documents is of utmost importance. Thus, temporal tagging -- the extraction and normalization of temporal expressions -- has gained a lot of attention in recent years and several tools such as HeidelTime and SUTime are proposed. However, such tools do not address textual phrases with temporal scopes like \"Clinton's time as First Lady\". While such phrases (so-called temponyms) are not temporal expressions per se, information about their temporal scopes can be helpful in many scenarios, e.g., in the context of temporal information retrieval. In this paper, we describe the integration of a wide range of temponyms to the publicly available temporal tagger HeidelTime to include temponym tagging.", "references": ["O. Alonso, J. Strötgen, R. Baeza-Yates, and M. Gertz. Temporal Information Retrieval: Challenges and Opportunities. In TempWeb, 2011.", "R. Campos, G. Dias, A. M. Jorge, and A. Jatowt. Survey of Temporal Information Retrieval and Related Applications. ACM Computing Surveys, 47(2), 2014.", "A. X. Chang and C. D. Manning. SUTime: A Library for Recognizing and Normalizing Time Expressions. In LREC, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889289"}, {"title": "Human-Recommender Systems: From Benchmark Data to Benchmark Cognitive Models", "authors": ["Patrick Shafto\n,", "Olfa Nasraoui"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe bring to the fore of the recommender system research community, an inconvenient truth about the current state of understanding how recommender system algorithms and humans influence one another, both computationally and cognitively. Unlike the great variety of supervised machine learning algorithms which traditionally rely on expert input labels and are typically used for decision making by an expert, recommender systems specifically rely on data input from non-expert or casual users and are meant to be used directly by these same non-expert users on an every day basis. Furthermore, the advances in online machine learning, data generation, and predictive model learning have become increasingly interdependent, such that each one feeds on the other in an iterative cycle. Research in psychology suggests that people's choices are (1) contextually dependent, and (2) dependent on interaction history. Thus, while standard methods of training and assessing performance of recommender systems rely on benchmark datasets, we suggest that a critical step in the evolution of recommender systems is the development of benchmark models of human behavior that capture contextual and dynamic aspects of human behavior. It is important to emphasize that even extensive real life user-tests may not be sufficient to make up for this gap in benchmarking validity because user tests are typically done with either a focus on user satisfaction or engagement (clicks, sales, likes, etc) with whatever the recommender algorithm suggests to the user, and thus ignore the human cognitive aspect. We conclude by highlighting the interdisciplinary implications of this endeavor.", "references": ["F. G. Ashby, L. A. Alfonso-Reese, and E. M. Waldron. a neuropsychological theory of multiple systems in category learning. Psychological Review, 105:442--481, 1998.", "F. G. Ashby, W. T. Maddox, and C. J. Bohil. Observational versus feedback training in rule-based and information-integration category learning. Memory & Cognition, 30:666--677, 2002.", "F. G. Ashby, S. Queller, and P. T. Berretty. On the dominance of unidimensional rules in unsupervised categorization. Perception and Psychophysics, 61:1178--1199, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959188"}, {"title": "Shenandoah: An open-source concurrent compacting garbage collector for OpenJDK", "authors": ["Christine H. Flood\n,", "Roman Kennke\n,", "Andrew Dinn\n,", "Andrew Haley\n,", "Roland Westrelin"], "publication": "PPPJ '16: Proceedings of the 13th International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools", "abstract": "ABSTRACT\nShenandoah is an open-source region-based low-pause parallel and concurrent garbage collection (GC) algorithm targeting large heap applications. Snapshot At the Beginning Concurrent Marking and Brooks-style indirection pointer concurrent compaction enable significantly shorter GC pauses with durations that are independent of the application's live data size. Our implementation of Shenandoah in OpenJDK allows us to do comparison testing with mature production quality GC algorithms.\nModern machines have more memory and more processors than ever before. Service Level Agreement (SLA) applications guarantee response times of 10-500ms. In order to meet the lower end of that goal we need garbage collection algorithms which are efficient enough to allow programs to run in the available memory, but also optimized to never interrupt the running program for more than a handful of milliseconds. Shenandoah is an open-source low-pause time collector for OpenJDK designed to move closer to those goals.", "references": ["N. S. Arora, R. D. Blumofe, and C. G. Plaxton. Thread scheduling for multiprogrammed multiprocessors. In Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures, SPAA '98, pages 119--129, New York, NY, USA, 1998. ACM.", "J. Auerbach, D. F. Bacon, P. Cheng, D. Grove, B. Biron, C. Gracie, B. McCloskey, A. Micic, and R. Sciampacone. Tax-and-spend: Democratic scheduling for real-time garbage collection. In Proceedings of the 8th ACM International Conference on Embedded Software, EMSOFT '08, pages 245--254, New York, NY, USA, 2008. ACM.", "D. F. Bacon, P. Cheng, and V. T. Rajan. A real-time garbage collector with low overhead and consistent utilization. In Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '03, pages 285--298, New York, NY, USA, 2003. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2972206.2972210"}, {"title": "Building Test Collections for Evaluating Temporal IR", "authors": ["Hideo Joho\n,", "Adam Jatowt\n,", "Roi Blanco\n,", "Haitao Yu\n,", "Shuhei Yamamoto"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nResearch on temporal aspects of information retrieval has recently gained considerable interest within the Information Retrieval (IR) community. This paper describes our efforts for building test collections for the purpose of fostering temporal IR research. In particular, we overview the test collections created at the two recent editions of Temporal Information Access (Temporalia) task organized at NTCIR-11 and NTCIR-12, report on selected results and discuss several observations we made during the task design and implementation. Finally, we outline further directions for constructing test collections suitable for temporal IR.", "references": ["R. Campos, G. Dias, A.M. Jorge, and A. Jatowt. Survey of Temporal Information Retrieval and Related Applications. In: ACM Comp. Surv., 15:1--15:41, 2014.", "C. Clarke, M. Kolla, G. Cormack, O. Vechtomova, A. Ashkan, S. Buttcher, and I. MacKinnon. Novelty and Diversity in Information Retrieval Evaluation. In: Proc. of 31st SIGIR, 659--666, 2008.", "A. Jatowt, C.M. Au Yeung and K. Tanaka. Estimating Document Focus Time. In: CIKM'13, 2273--2278."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914673"}, {"title": "Data-Driven Contextual Valence Shifter Quantification for Multi-Theme Sentiment Analysis", "authors": ["Hongkun Yu\n,", "Jingbo Shang\n,", "Meichun Hsu\n,", "Malu Castellanos\n,", "Jiawei Han"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUsers often write reviews on different themes involving linguistic structures with complex sentiments. The sentiment polarity of a word can be different across themes. Moreover, contextual valence shifters may change sentiment polarity depending on the contexts that they appear in. Both challenges cannot be modeled effectively and explicitly in traditional sentiment analysis. Studying both phenomena requires multi-theme sentiment analysis at the word level, which is very interesting but significantly more challenging than overall polarity classification. To simultaneously resolve the multi-theme and sentiment shifting problems, we propose a data-driven framework to enable both capabilities: (1) polarity predictions of the same word in reviews of different themes, and (2) discovery and quantification of contextual valence shifters. The framework formulates multi-theme sentiment by factorizing the review sentiments with theme/word embeddings and then derives the shifter effect learning problem as a logistic regression. The improvement of sentiment polarity classification accuracy demonstrates not only the importance of multi-theme and sentiment shifting, but also effectiveness of our framework. Human evaluations and case studies further show the success of multi-theme word sentiment predictions and automatic effect quantification of contextual valence shifters.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "N. Boubel, T. François, H. Naets, and I. Cental. Automatic extraction of contextual valence shifters. In RANLP, pages 98--104, 2013.", "A. M. Dai and Q. V. Le. Semi-supervised sequence learning. In NIPS, pages 3079--3087. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983793"}, {"title": "Scan path and movie trailers for implicit annotation of videos", "authors": ["Pallavi Raiturkar\n,", "Andrew Lee\n,", "Eakta Jain"], "publication": "SAP '16: Proceedings of the ACM Symposium on Applied Perception", "abstract": "ABSTRACT\nAffective annotation of videos is important for video understanding, ranking, retrieval, and summarization. We present an approach that uses excerpts that appeared in the official trailers of movies, as training data. Total scan path is computed as a metric for emotional arousal, based on previous eye tracking research. Arousal level on trailer excerpts is modeled as a Gaussian distribution, and signed distance from the mean of this distribution is used to separate out exemplars of high and low emotional arousal in movies.", "references": ["Bradley, M. M., Houbova, P., Miccoli, L., Costa, V. D., and Lang, P. J. 2011. Scan patterns when viewing natural scenes: Emotion, complexity, and repetition. Psychophysiology 48, 11, 1544--1553."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2931002.2948723"}, {"title": "Modeling User Exposure in Recommendation", "authors": ["Dawen Liang\n,", "Laurent Charlin\n,", "James McInerney\n,", "David M. Blei"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nCollaborative filtering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis (Imbens & Rubin, 2015), the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative filtering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-the-art approaches as a special case of our model (Hu et al. 2008), and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four different domains both with and without exposure covariates.", "references": ["T. Bertin-Mahieux, D. P. W. Ellis, B. Whitman, and P. Lamere. The million song dataset. In Proceedings of the 12th International Society for Music Information Retrieval Conference, pages 591--596, 2011.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. the Journal of Machine Learning Research, 3: 993--1022, 2003.", "L. Bottou, J. Peters, J. Quinonero Candela, D. X. Charles, D. M. Chickering, E. Portugaly, D. Ray, P. Simard, and E. Snelson. Counterfactual reasoning and learning systems: The example of computational advertising. Journal of Machine Learning Research, 14: 3207--3260, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883090"}, {"title": "Harnessing Music-Related Visual Stereotypes for Music Information Retrieval", "authors": ["Alexander Schindler\n,", "Andreas Rauber"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nOver decades, music labels have shaped easily identifiable genres to improve recognition value and subsequently market sales of new music acts. Referring to print magazines and later to music television as important distribution channels, the visual representation thus played and still plays a significant role in music marketing. Visual stereotypes developed over decades that enable us to quickly identify referenced music only by sight without listening. Despite the richness of music-related visual information provided by music videos and album covers as well as T-shirts, advertisements, and magazines, research towards harnessing this information to advance existing or approach new problems of music retrieval or recommendation is scarce or missing. In this article, we present our research on visual music computing that aims to extract stereotypical music-related visual information from music videos. To provide comprehensive and reproducible results, we present the Music Video Dataset, a thoroughly assembled suite of datasets with dedicated evaluation tasks that are aligned to current Music Information Retrieval tasks. Based on this dataset, we provide evaluations of conventional low-level image processing and affect-related features to provide an overview of the expressiveness of fundamental visual properties such as color, illumination, and contrasts. Further, we introduce a high-level approach based on visual concept detection to facilitate visual stereotypes. This approach decomposes the semantic content of music video frames into concrete concepts such as vehicles, tools, and so on, defined in a wide visual vocabulary. Concepts are detected using convolutional neural networks and their frequency distributions as semantic descriptions for a music video. Evaluations showed that these descriptions show good performance in predicting the music genre of a video and even outperform audio-content descriptors on cross-genre thematic tags. Further, highly significant performance improvements were observed by augmenting audio-based approaches through the introduced visual approach.", "references": ["Esra Acar, Frank Hopfgartner, and Sahin Albayrak. 2014. Understanding affective content of music videos through learned representations. In MultiMedia Modeling. Springer, 303--314.", "Eric Brochu, Nando De Freitas, and Kejie Bao. 2003. The sound of an album cover: Probabilistic multimedia and IR. In Proceedings of the Workshop on Artificial Intelligence and Statistics.", "Rui Cai, Lei Zhang, Feng Jing, Wei Lai, and Wei-Ying Ma. 2007. Automated music video generation using web image resource. In Acoustics, Speech and Signal Processing. ICASSP."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2926719"}, {"title": "Total Recall: Blue Sky on Mars", "authors": ["Charles L.A. Clarke\n,", "Gordon V. Cormack\n,", "Jimmy Lin\n,", "Adam Roegiest"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nThere are presently plans to create permanent colonies on Mars so that humanity will have a second home. These colonists will need search, email, entertainment, and indeed most services provided on the modern web. The primary challenge is network latencies, since the two planets are anywhere from 4 to 24 light minutes apart. A recent article sketches out how we might develop search technologies for Mars based on physically transporting a cache of the web to Mars, to which updates are applied via predictive models. Within this general framework, we explore the problem of high-recall retrieval, such as conducting a scientific survey. We explore simple techniques for masking speed-of-light delays and find that \"priming\" the search process with a small Martian cache is sufficient to mask a moderate amount of network latency. Simulation experiments show that it is possible to engineer high-recall search from Mars to be quite similar to the experience on Earth.", "references": ["B. Aldrin. The call of Mars. New York Times, June 2013.", "G. V. Cormack and M. R. Grossman. Evaluation of machine-learning protocols for technology-assisted review in electronic discovery. SIGIR, 2014.", "G. V. Cormack and M. R. Grossman. Autonomy and reliability of continuous active learning for technology-assisted review. arXiv:1504.06868v1, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970430"}, {"title": "Research on the Follow-up Actions of College Students' Mobile Search", "authors": ["Dan Wu\n,", "Shaobo Liang"], "publication": "JCDL '16: Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis paper focuses on the follow-up actions triggered by college students' mobile searches, which involved 30 participants conducting an uncontrolled experiment in fifteen days. We collected the mobile phone usage data by an app called AWARE, and combined with structured diary and interviews to perform a quantitative and qualitative study. The results showed that, there were three categories of follow-up actions and majority of these actions occurred within one hour after the initial search session. We also found that participants often conducted follow-up actions with different apps, and certain information needs triggered more follow-up actions. We finally discussed the characteristics and the causes of these actions, and stated further studies which include comparing follow-up actions triggered by mobile search and that of Web search, and building a model for the follow-up actions.", "references": ["Arter, D., Buchanan, G., Jones, M. and Harper, R. 2007. Incidental information and mobile search. In Proceedings of the International Conference on Human Computer Interaction with Mobile Devices & Services (Singapore, September 9--12, 2007). MobileHCI'07, ACM, New York, NY, 413--420.", "Chen, X., Sin, S. C. J., Theng, Y. L. and Lee, C. S. 2015. Why do social media users share misinformation?. In Proceedings of the Joint Conference on Digital Libraries (Knoxville, Tennessee, USA, June 21--25, 2015). JCDL'15, ACM, New York, NY, 111--114.", "Kamvar, M. and Baluja, S. 2007. Deciphering trends in mobile search. Computer, 40(8), 58--62."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2910896.2910921"}, {"title": "Is This Your Final Answer?: Evaluating the Effect of Answers on Good Abandonment in Mobile Search", "authors": ["Kyle Williams\n,", "Julia Kiseleva\n,", "Aidan C. Crook\n,", "Imed Zitouni\n,", "Ahmed Hassan Awadallah\n,", "Madian Khabsa"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAnswers on mobile search result pages have become a common way to attempt to satisfy users without them needing to click on search results. Many different types of answers exist, such as weather, flight and currency answers. Understanding the effect that these different answer types have on mobile user behavior and how they contribute to satisfaction is important for search engine evaluation. We study these two aspects by analyzing the logs of a commercial search engine and through a user study. Our results show that user click, abandonment and engagement behavior differs depending on the answer types present on a page. Furthermore, we find that satisfaction rates differ in the presence of different answer types with simple answer types, such as time zone answers, leading to more satisfaction than more complex answers, such as news answers. Our findings have implications for the study and application of user satisfaction for search systems.", "references": ["M. S. Bernstein, J. Teevan, S. Dumais, D. Liebling, and E. Horvitz. Direct answers for search queries in the long tail. In CHI, pages 237--246, 2012.", "L. B. Chilton and J. Teevan. Addressing people's information needs directly in a web search result page. In WWW, pages 27--36, 2011.", "A. Chuklin and P. Serdyukov. Potential good abandonment prediction. In WWW, pages 485--486, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914736"}, {"title": "Learning Latent Vector Spaces for Product Search", "authors": ["Christophe Van Gysel\n,", "Maarten de Rijke\n,", "Evangelos Kanoulas"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe introduce a novel latent vector space model that jointly learns the latent representations of words, e-commerce products and a mapping between the two without the need for explicit annotations. The power of the model lies in its ability to directly model the discriminative relation between products and a particular word. We compare our method to existing latent vector space models (LSI, LDA and word2vec) and evaluate it as a feature in a learning to rank setting. Our latent vector space model achieves its enhanced performance as it learns better product representations. Furthermore, the mapping from words to products and the representations of words benefit directly from the errors propagated back from the product representations during parameter estimation. We provide an in-depth analysis of the performance of our model and analyze the structure of the learned representations.", "references": ["K. Balog. On the investigation of similarity measures for product resolution. In LHD workshop at IJCAI, 2011.", "K. Balog and M. de Rijke. Determining expert profiles (with an application to expert finding). IJCAI, 7:2657--2662, 2007.", "K. Balog and R. Neumayer. A test collection for entity search in dbpedia. In SIGIR, pages 737--740. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983702"}, {"title": "Session details: Main Track - Human and Social Aspects in IS (II)", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255998"}, {"title": "Cleansing Wikipedia Categories using Centrality", "authors": ["Paolo Boldi\n,", "Corrado Monti"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nWe propose a novel general technique aimed at pruning and cleansing the Wikipedia category hierarchy, with a tunable level of aggregation. Our approach is endogenous, since it does not use any information coming from Wikipedia articles, but it is based solely on the user-generated (noisy) Wikipedia category folksonomy itself. We show how the proposed techniques can help reduce the level of noise in the hierarchy and discuss how alternative centrality measures can differently impact on the result.", "references": ["Jac M. Anthonisse. The rush in a graph. Technical report, Amsterdam: University of Amsterdam Mathematical Centre, 1971.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "A. Bavelas. A mathematical model for group structures. Human Organization, 7:16--30, 1948."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2891111"}, {"title": "Exemplar queries: a new way of searching", "authors": ["Davide Mottin\n,", "Matteo Lissandrini\n,", "Yannis Velegrakis\n,", "Themis Palpanas"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nModern search engines employ advanced techniques that go beyond the structures that strictly satisfy the query conditions in an effort to better capture the user intentions. In this work, we introduce a novel query paradigm that considers a user query as an example of the data in which the user is interested. We call these queries exemplar queries. We provide a formal specification of their semantics and show that they are fundamentally different from notions like queries by example, approximate queries and related queries. We provide an implementation of these semantics for knowledge graphs and present an exact solution with a number of optimizations that improve performance without compromising the result quality. We study two different congruence relations, isomorphism and strong simulation, for identifying the answers to an exemplar query. We also provide an approximate solution that prunes the search space and achieves considerably better time performance with minimal or no impact on effectiveness. The effectiveness and efficiency of these solutions with synthetic and real datasets are experimentally evaluated, and the importance of exemplar queries in practice is illustrated.", "references": ["Agrawal, R., Gollapudi, S., Halverson, A., Ieong, S.: Diversifying search results. In: WSDM (2009)", "Anagnostopoulos, A., Becchetti, L., Castillo, C., Gionis, A.: An optimization framework for query recommendation. In: WSDM (2010)", "Baeza-Yates, R., Boldi, P., Castillo, C.: Generalizing pagerank: damping functions for link-based ranking algorithms. In: SIGIR (2006)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0429-2"}, {"title": "Recommending Repeat Purchases using Product Segment Statistics", "authors": ["Suvodip Dey\n,", "Pabitra Mitra\n,", "Kratika Gupta"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRepeat Purchases have become increasingly important in measuring customer's satisfaction and loyalty to e-commerce websites in regard to online shopping. In this paper, we first propose a model for estimating repeat purchase frequency in a given time period from a given product category using Poisson/Gamma model. Second, we estimate the purchase probabilities of different product types in a product category for each customer using Dirichlet model. Experimental results on data collected by a real-world e-commerce website show that it can predict a user's average repeat purchase frequency along with their product types with decent accuracy. We also argue that the output of our models can be used as prior information to enhance the performance of time-sensitive recommendation.", "references": ["N. Du, Y. Wang, N. He, J. Sun, and L. Song. Time-sensitive recommendation from recurrent user activities. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 3474--3482. Curran Associates, Inc., 2015.", "A. Ehrenberg. Repeat-buying: Facts, Theory, and Applications. Charles Griffin Book. Griffin, 1988.", "J. Wang and Y. Zhang. Opportunity model for e-commerce recommendation: Right product; right time. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '13, pages 303--312, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959145"}, {"title": "Characterizing Users' Multi-Tasking Behavior in Web Search", "authors": ["Rishabh Mehrotra\n,", "Prasanta Bhattacharya\n,", "Emine Yilmaz"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nMulti-tasking within a single online search sessions is an increasingly popular phenomenon. In this work, we quantify multi-tasking behavior of web search users. Using insights from large-scale search logs, we seek to characterize user groups and search sessions with a focus on multi-task sessions. Our findings show that dual-task sessions are more prevalent than single-task sessions in online search, and that over 50\\% of search sessions have more than 2 tasks. Further, we provide a method to categorize users into focused, multi-taskers or supertaskers depending on their level of task-multiplicity and show that the search effort expended by these users varies across the groups. The findings from this analysis provide useful insights about task-multiplicity in an online search environment and hold potential value for search engines that wish to personalize and support search experiences of users based on their task behavior.", "references": ["M. A. Just, P. A. Carpenter, T. A. Keller, L. Emery, H. Zajac, and K. R. Thulborn. Interdependence of nonoverlapping cortical systems in dual cognitive tasks. NeuroImage, 14(2):417--426, 2001.", "R. Kumar and A. Tomkins. A characterization of online browsing behavior. In Proceedings of the 19th international conference on World wide web, pages 561--570. ACM, 2010.", "J. Lehmann, M. Lalmas, G. Dupret, and R. Baeza-Yates. Online multitasking and user engagement. In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management, pages 519--528. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2855006"}, {"title": "Cross-batch Reference Learning for Deep Classification and Retrieval", "authors": ["Huei-Fang Yang\n,", "Kevin Lin\n,", "Chu-Song Chen"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nLearning feature representations for image retrieval is essential to multimedia search and mining applications. Recently, deep convolutional networks (CNNs) have gained much attention due to their impressive performance on object detection and image classification, and the feature representations learned from a large-scale generic dataset (e.g., ImageNet) can be transferred to or fine-tuned on the datasets of other domains. However, when the feature representations learned with a deep CNN are applied to image retrieval, the performance is still not as good as they are used for classification, which restricts their applicability to relevant image search. To ensure the retrieval capability of the learned feature space, we introduce a new idea called cross-batch reference (CBR) to enhance the stochastic-gradient-descent (SGD) training of CNNs. In each iteration of our training process, the network adjustment relies not only on the training samples in a single batch, but also on the information passed by the samples in the other batches. This inter-batches communication mechanism is formulated as a cross-batch retrieval process based on the mean average precision (MAP) criterion, where the relevant and irrelevant samples are encouraged to be placed on top and rear of the retrieval list, respectively. The learned feature space is not only discriminative to different classes, but the samples that are relevant to each other or of the same class are also enforced to be centralized. To maximize the cross-batch MAP, we design a loss function that is an approximated lower bound of the MAP on the feature layer of the network, which is differentiable and easier for optimization. By combining the intra-batch classification and inter-batch cross-reference losses, the learned features are effective for both classification and retrieval tasks. Experimental results on various benchmarks demonstrate the effectiveness of our approach.", "references": ["R. Arandjelovic and A. Zisserman. All about vlad. In Proc. CVPR, pages 1578--1585, 2013.", "A. Babenko and V. S. Lempitsky. Aggregating deep convolutional features for image retrieval. In Proc. ICCV, pages 1269--1277, 2015.", "A. Babenko, A. Slesarev, A. Chigorin, and V. S. Lempitsky. Neural codes for image retrieval. In Proc. ECCV, pages 584--599, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2964324"}, {"title": "Managing smartphone crowdsensing campaigns through the organicity smart city platform", "authors": ["Dimitrios Amaxilatis\n,", "Evangelos Lagoudianakis\n,", "Georgios Mylonas\n,", "Evangelos Theodoridis"], "publication": "UbiComp '16: Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct", "abstract": "ABSTRACT\nWe briefly present the design and architecture of a system that aims to simplify the process of organizing, executing and administering crowdsensing campaigns in a smart city context over smartphones volunteered by citizens. We built our system on top of an Android app substrate on the end-user level, which enables us to utilize smartphone resources. Our system allows researchers and other developers to manage and distribute their \"mini\" smart city applications, gather data and publish their results through the Organicity smart city platform. We believe this is the first time such a tool is paired with a large scale IoT infrastructure, to enable truly city-scale IoT and smart city experimentation.", "references": ["G. Mylonas, E. Theodoridis and L. Munoz. Integrating Smartphones into the SmartSantander Infrastructure. IEEE Internet Computing. Issue 99, DOI 10.1109/MIC.2015.25.", "B. Guo, Z. Wang, Z. Yu, Y. Wang, N. Y. Yen, R. Huang, and X. Zhou. 2015. Mobile Crowd Sensing and Computing: The Review of an Emerging Human-Powered Sensing Paradigm. ACM Comput. Surv. 48, 1.", "E. D'Hondt, J. Zaman, E. Philips, E. Gonzalez Boix, and W. De Meuter. 2014. Orchestration support for participatory sensing campaigns. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp '14). ACM, New York, NY, USA, 727--738. DOI=http://dx.doi.org/10.1145/2632048.2632105"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2968219.2968588"}, {"title": "Plane Geometry Diagram Retrieval By Using Hierarchical Searching Strategy", "authors": ["Wenbin Gan\n,", "Xinguo Yu\n,", "Sichao Lai\n,", "Lei Xiang"], "publication": "ICIMCS'16: Proceedings of the International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThis paper presents a fast algorithm for retrieving plane geometry diagrams. Retrieving plane geometry diagrams has become an active research problem because that it is critical technology in various applications of searching the relevant materials of plane geometry such as search engine and auto tutorial system. Several existing systems use the features extracted from geometric diagram to retrieve the relevant materials of exercise problems of plane geometry, which achieve the better performance than the ones by using the keywords extracted from text. However, the existing retrieval methods do not consider the property of different features. This paper proposes a hierarchical strategy, which conducts the global-to-local bilayer retrieval. The first layer efficiently reduces the ranges by using global features; the second layer finds the relevant diagrams by using local features. This coarse-to-fine procedure can retrieve a short list of relevant diagrams with high similarity to the input diagram. This good performance lies in that the global features can describe the similarity of global structures and the local features can describe the delicate inner structure of diagrams. The experimental results demonstrate that the proposed algorithm can achieve good performance against the state-of-arts methods in terms of retrieval quality.", "references": ["Liu L., Lu X., Li K., et al. 2014. Plane geometry figure retrieval with bag of shapes. Document Analysis Systems pp. 1--5.", "Liu L., Lu X., Fu S., et al. 2014. Plane geometry figure retrieval based on bilayer geometric attributed graph matching. ICPR2014, pp. 309--314", "Feng T., Lu X. 2014. Structure analysis for plane geometry figures. Proceedings of SPIE - The Intern'l Society for Optical Engineering, 9021, pp. 303--306."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007669.3007671"}, {"title": "An Exploratory Study on Computer Literacy in Sao Paulo", "authors": ["Edmir P.V. Prado\n,", "Marco A. Wang"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nFrom time to time, it has been seen increased the dissemination of computing devices in the society. However, recent research shows situations of individuals equipped with IT devices, but technologically unprepared. Based on this context, it is evident that there is a minimal learning about computational aspects, which assigns the term Computer Literacy (CL). The objective of this study is to evaluate the relevance of CL aspects in the knowledge base formation of young Brazilians. This work is characterized by being an exploratory research using the in-depth interview technique to capture perceptions of three Brazilian institutions related to the subject of study. The research confirms the relevance of CL's knowledge and skills, identifying particulars of the most important aspects for each of the surveyed institutions.", "references": ["Bartholomew, K. W. 2004. Computer literacy: is the emperor still exposed after all these years?. J. Comput. Sci. Coll., 323-331.", "CGI.BR. 2014. TIC: Domicilios e Empresas 2013. Nucleo de Informacao e Coordenacao do Ponto BR, Sao Paulo, 658.", "Cohen, E. 1987. What is computer literacy: the imposter, the sham, and the misdirected. 15th annual conference on Computer Science, (St Louis, Missouri, USA, February 16- 19), 320-322."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022050"}, {"title": "Technological needs calling for the application of coaching in university advising: functional proposal", "authors": ["José Antonio Montero\n,", "David Fonseca\n,", "Lluís Vicent\n,", "August Climent\n,", "Xavi Canaleta\n,", "Sergi Villagrasa"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nStarting university studies in the field of engineering represents a significant change of habits of study for the majority of students. Throughout this new educational stage, the work of the academic tutor (or advisor) is essential for guiding and accompanying the student. This process should help to prevent problems such as the frustration and insecurity that can appear, mainly among students in the early stages of their studies and usually after the first tests. In this context, resources and techniques from the field of coaching are very useful for the tutor, as those resources influence the student to reflect and be more aware of the situation in which he/she is living. The objective of these processes is for the student to be more qualified to take the appropriate decisions with greater discretion, motivation and responsibility. This paper presents a first approach in the process of applying coaching techniques in the tutoring of students in their first course of engineering, and subsequently presents the design, at the functional level of a technological application, that would make it possible to use resources of the coaching to tutors without a deep formation in coaching.", "references": ["Powell, M. A. 1997. Academic Tutoring and Mentoring: A literature Review, California Research Bureau, California State Library. CRB-97-01.", "Allen, V. L. (Ed.). 2013. Children as teachers: Theory and research on tutoring. Academic Press.", "Coie, J. D., & Krehbiel, G. 1984. Effects of academic tutoring on the social status of low-achieving, socially rejected children. Child Development, 1465--1478."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012590"}, {"title": "Bayesian Performance Comparison of Text Classifiers", "authors": ["Dell Zhang\n,", "Jun Wang\n,", "Emine Yilmaz\n,", "Xiaoling Wang\n,", "Yuxin Zhou"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nHow can we know whether one classifier is really better than the other? In the area of text classification, since the publication of Yang and Liu's seminal SIGIR-1999 paper, it has become a standard practice for researchers to apply null-hypothesis significance testing (NHST) on their experimental results in order to establish the superiority of a classifier. However, such a frequentist approach has a number of inherent deficiencies and limitations, e.g., the inability to accept the null hypothesis (that the two classifiers perform equally well), the difficulty to compare commonly-used multivariate performance measures like F1 scores instead of accuracy, and so on. In this paper, we propose a novel Bayesian approach to the performance comparison of text classifiers, and argue its advantages over the traditional frequentist approach based on t-test etc. In contrast to the existing probabilistic model for F1 scores which is unpaired, our proposed model takes the correlation between classifiers into account and thus achieves greater statistical power. Using several typical text classification algorithms and a benchmark dataset, we demonstrate that the our approach provides rich information about the difference between two classifiers' performances.", "references": ["D. Barber. Are two classifiers performing equally? A treatment using Bayesian hypothesis testing. Technical report, IDIAP, 2004.", "D. Barber. Bayesian Reasoning and Machine Learning. Cambridge University Press, 2012.", "B. Carterette. Bayesian inference for information retrieval evaluation. In Proceedings of the 2015 International Conference on the Theory of Information Retrieval (ICTIR), pages 31--40, Northampton, MA, USA, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911547"}, {"title": "Local Similarity Search for Unstructured Text", "authors": ["Pei Wang\n,", "Chuan Xiao\n,", "Jianbin Qin\n,", "Wei Wang\n,", "Xiaoyang Zhang\n,", "Yoshiharu Ishikawa"], "publication": "SIGMOD '16: Proceedings of the 2016 International Conference on Management of Data", "abstract": "ABSTRACT\nWith the growing popularity of electronic documents, replication can occur for many reasons. People may copy text segments from various sources and make modifications. In this paper, we study the problem of local similarity search to find partially replicated text. Unlike existing studies on similarity search which find entirely duplicated documents, our target is to identify documents that approximately share a pair of sliding windows which differ by no more than τ tokens. Our problem is technically challenging because for sliding windows the tokens to be indexed are less selective than entire documents, rendering set similarity join-based algorithms less efficient. Our proposed method is based on enumerating token combinations to obtain signatures with high selectivity. In order to strike a balance between signature and candidate generation, we partition the token universe and for different partitions we generate combinations composed of different numbers of tokens. A cost-aware algorithm is devised to find a good partitioning of the token universe. We also propose to leverage the overlap between adjacent windows to share computation and thus speed up query processing. In addition, we develop the techniques to support the large thresholds. Experiments on real datasets demonstrate the efficiency of our method against alternative solutions.", "references": ["P. Agrawal, A. Arasu, and R. Kaushik. On indexing error-tolerant set containment. In SIGMOD Conference, pages 927--938, 2010.", "S. Agrawal, K. Chakrabarti, S. Chaudhuri, and V. Ganti. Scalable ad-hoc entity extraction from text collections. PVLDB, 1(1):945--957, 2008.", "A. Arasu, V. Ganti, and R. Kaushik. Efficient exact set-similarity joins. In VLDB, pages 918--929, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2882903.2915211"}, {"title": "Understanding Participatory Hashtag Practices on Instagram: A Case Study of Weekend Hashtag Project", "authors": ["Changhoon Oh\n,", "Taeyoung Lee\n,", "Yoojung Kim\n,", "SoHyun Park\n,", "Bongwon Suh"], "publication": "CHI EA '16: Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems", "abstract": "ABSTRACT\nInstagram, a popular global mobile photo-sharing platform, involves various user interactions centered on posting images accompanied by hashtags. Participatory hashtagging, one of these diverse tagging practices, has great potential to be a communication channel for various organizations and corporations that would like to interact with users on social media. In this paper, we aim to characterize participatory hashtagging behaviors on Instagram by conducting a case study of its representative hashtagging practice, the Weekend Hashtag Project, or #WHP. By conducting a user study using both quantitative and qualitative methods, we analyzed the way Instagram users respond to participation calls and identified factors that motivate users to take part in the project. Based on these findings, we provide design strategies for any interested parties to interact with users on social media.", "references": ["Instagram Blog. 2015. Retrieved August 15, 2015 from http://blog.instagram.com", "Morgan Ames and Mor Naaman. 2007. Why we tag: motivations for annotation in mobile and online media. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07). ACM, New York, NY, USA, 971--980. http://dx.doi.org/10.1145/1240624.1240772", "Justin Cheng, Cristian Danescu-Niculescu-Mizil, and Jure Leskovec. 2014. How community feedback shapes user behavior. In Proceedings of the 8th International AAAI Conference on Weblogs and Social Media (ICWSM '14)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851581.2892369"}, {"title": "Predicting how you respond to phone calls: towards discovering temporal behavioral rules", "authors": ["Iqbal H. Sarker\n,", "Muhammad Ashad Kabir\n,", "Alan Colman\n,", "Jun Han"], "publication": "OzCHI '16: Proceedings of the 28th Australian Conference on Computer-Human Interaction", "abstract": "ABSTRACT\nDiscovering temporal rules that capture an individual's phone call response behavior is essential to building intelligent individualized call interruption management system. The key challenge to discovering such temporal rules is identifying within a phone call log the time boundaries that delineate periods when an individual user rejects or accepts phone calls. Moreover, potential data sparsity in phone call logs imposes additional challenge in discovering applicable rules. In this paper, we address the above issues and present a hybrid approach to identify the effective time boundaries for discovering temporal behavioral rules of individual mobile phone users utilizing calendar and mobile phone data. Our preliminary experiments on real datasets show that our proposed hybrid approach dynamically identifies better time boundaries based on like behavioral patterns and outperforms the existing calendar-based approach (CBA) and log-based approach (LBA) to discovering the temporal behavior rules of individual mobile phone users.", "references": ["Agrawal, R. and Srikant, R. Fast algorithms for mining association rules. In proceedings of VLDB 1994,ACM Press (1994), 487--499.", "Halvey, M. and Keane, M. Time based patterns in mobile-internet surfing. In proceedings of the 2006 SIGCHI conference on Human Factors in computing systems, ACM Press (2006), 31--34", "Kabir, M.A., Han, J., Yu, J. and Colman, A. User-centric social context information management: an ontology-based approach and platform. Personal and Ubiquitous Computing. Springer (2014), 1061--1083."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3010915.3010979"}, {"title": "Split Migration of Large Memory Virtual Machines", "authors": ["Masato Suetake\n,", "Hazuki Kizu\n,", "Kenichi Kourai"], "publication": "APSys '16: Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems", "abstract": "ABSTRACT\nRecently, Infrastructure-as-a-Service clouds provide VMs with a large amount of memory, e.g., X1 instances with 2 TB in Amazon EC2. Such large memory VMs make VMmigration difficult because VM migration needs sufficient free memory at the destination host. Even in clouds, it is costly to always reserve hosts with a large amount of free memory. This paper proposes S-memV, which enables split migration of large memory VMs. Split migration migrates a large memory VM to multiple hosts by dividing its memory. It transfers core information and frequently accessed memory of a VM to the main host, whereas it transfers infrequently accessed memory to the sub-hosts. When the VM requires the memory stored in the sub-hosts, S-memV performs remote paging between the main host and the sub-hosts. Since split migration is aware of remote paging, S-memV can keep the performance of migrated VMs. In addition to such one-to-N migration, split migration supports N-to-one and partial migration. We have implemented S-memV in KVM and showed that migration time was much shorter than that of the traditional migration with virtual memory.", "references": ["B. Aker. memaslap -- Load Testing and Benchmarking a Server. http://docs.libmemcached.org/bin/memaslap.html.", "Apache Software Foundation. Apache Spark -- Lightning-Fast Cluster Computing. http://spark.apache.org/.", "M. Chapman and G. Heiser. vNUMA: A Virtual Shared-Memory-Multi Processor. In Proceedings of the 2009 USENIX Annual Technical Conference, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2967360.2967368"}, {"title": "A Unified Energy-based Framework for Learning to Rank", "authors": ["Yi Fang\n,", "Mengwen Liu"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nLearning to Rank (L2R) has emerged as one of the core machine learning techniques for IR. On the other hand, Energy-Based Models (EBMs) capture dependencies between variables by associating a scalar energy to each configuration of the variables. They have produced impressive results in many computer vision and speech recognition tasks. In this paper, we introduce a unified view of Learning to Rank that integrates various L2R approaches in an energy-based ranking framework. In this framework, an energy function associates low energies to desired documents and high energies to undesired results. Learning is essentially the process of shaping the energy surface so that desired documents have lower energies. The proposed framework yields new insights into learning to rank. First, we show how various existing L2R models (pointwise, pairwise, and listwise) can be cast in the energy-based framework. Second, new L2R models can be constructed based on existing EBMs. Furthermore, inspired by the intuitive learning process of EBMs, we can devise novel energy-based models for ranking tasks. We introduce several new energy-based ranking models based on the proposed framework. The experiments are conducted on the public LETOR 4.0 benchmarks and demonstrate the effectiveness of the proposed models.", "references": ["A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94(2):233--259, 2014.", "P. Brakel, D. Stroobandt, and B. Schrauwen. Training energy-based models for time-series imputation. JMLR, 14(1):2771--2797, 2013.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML, pages 89--96. ACM, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970416"}, {"title": "Accelerating search", "authors": ["Marina Krakovsky"], "publication": "Communications of the ACM", "abstract": "Abstract\nThe latest in machine learning helps high-energy physicists handle the enormous amounts of data produced by the Large Hadron Collider.", "references": ["Adam-Bourdarios, C., Cowan, G., Germain, C., Guyon, I., Kégl, B., and Rousseau, D. The Higgs boson machine learning challenge. JMLR: Workshop and Conference Proceedings 2015 http://jmlr.org/proceedings/papers/v42/cowa14.pdf.", "Baldi, P., Sadowski, P., and Whiteson, D. Searching for exotic particles in high-energy physics with deep learning, Nature Communications (2014), Vol 5, pp1-9 http://bit.ly/1RCaiOB.", "Donegà, M. ML at ATLAS and CMS: setting the stage. Data Science @ LHC 2015 Workshop (2015). https://cds.cern.ch/record/2066954."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933416"}, {"title": "Rank-at-a-Time Query Processing", "authors": ["Ahmed Elbagoury\n,", "Matt Crane\n,", "Jimmy Lin"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nQuery processing strategies for ranked retrieval have been studied for decades. In this paper we propose a new strategy, which we call rank-at-a-time query processing, that evaluates documents in descending order of quantized scores and is able to directly compute the final document ranking via a sequence of boolean intersections. We show that such a strategy is equivalent to a second-order restricted composition of per-term scores. Rank-at-a-time query processing has the advantage that it is anytime score-safe, which means that the retrieval algorithm can self-adapt to produce an exact ranking given an arbitrary latency constraint. Due to the combinatorial nature of compositions, however, a naive implementation is too slow to be of practical use. To address this issue, we introduce a hybrid variant that is able to reduce query latency to a point that is on par with state-of-the-art retrieval engines.", "references": ["V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with effective early termination. SIGIR, 2001.", "N. Asadi and J. Lin. Effectiveness/efficiency tradeoffs for candidate generation in multi-stage retrieval architectures. SIGIR, 2013.", "P. Boldi and S. Vigna. MG4J at TREC 2006. TREC, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970434"}, {"title": "MIDAS: A Middleware to Provide Interoperability between SaaS and DaaS", "authors": ["Tarcio Marinho\n,", "Vinicius Cidreira\n,", "Daniela B. Claro\n,", "Babacar Mane"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nSoftware as a Service (SaaS) and Data as a Service (DaaS) proves to be two promising areas of research in the cloud computing field, however interoperability among different cloud providers is yet poorly explored. Today, clients looking for content or services from different providers need extra time and resources to learn and implement the required adaptations from the other parties. In this paper we propose MIDAS, a novel middleware to interoperate SaaS and DaaS services seamlessly and independently from provider. That is, SaaS applications will be able to get data from DaaS datasets by sending a query to our middleware and letting it mediate the communication and return the expected results. We evaluate our proposal by developing a prototype from two case studies and by analyzing the time effort to query through our middleware. Our results presented that no important overhead were required from providers nor to the final user.", "references": ["S. Ahirrao and R. Ingle. Scalable transactions in cloud data stores. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 116-119. IEEE, 2013.", "S. Aulbach, T. Grust, D. Jacobs, A. Kemper, and J. Rittinger. Multi-tenant databases for software as a service: schema-mapping techniques. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1195-1206. ACM, 2008.", "S. Barouti, D. Alhadidi, and M. Debbabi. Symmetrically-private database search in cloud computing. In Cloud Computing Technology and Science (CloudCom), 2013 IEEE 5th International Conference on, volume 1, pages 671-678. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022023"}, {"title": "Query Expansion in Resource-Scarce Languages: A Multilingual Framework Utilizing Document Structure", "authors": ["Arjun Atreya V\n,", "Ashish Kankaria\n,", "Pushpak Bhattacharyya\n,", "Ganesh Ramakrishnan"], "publication": "ACM Transactions on Asian and Low-Resource Language Information Processing", "abstract": "Abstract\nRetrievals in response to queries to search engines in resource-scarce languages often produce no results, which annoys the user. In such cases, at least partially relevant documents must be retrieved. We propose a novel multilingual framework, MultiStructPRF, which expands the query with related terms by (i) using a resource-rich assisting language and (ii) giving varied importance to the expansion terms depending on their position of occurrence in the document. Our system uses the help of an assisting language to expand the query in order to improve system recall. We propose a systematic expansion model for weighting the expansion terms coming from different parts of the document. To combine the expansion terms from query language and assisting language, we propose a heuristics-based fusion model. Our experimental results show an improvement over other PRF techniques in both precision and recall for multiple resource-scarce languages like Marathi, Bengali, Odia, Finnish, and the like. We study the effect of different assisting languages on precision and recall for multiple query languages. Our experiments reveal an interesting fact: Precision is positively correlated with the typological closeness of query language and assisting language, whereas recall is positively correlated with the resource richness of the assisting language.", "references": ["Bashar Al-Shboul and Sung-Hyon Myaeng. 2011. Query phrase expansion using Wikipedia in patent class search. In AIRS. 115--126.", "Arjun Atreya, Yogesh Kakde, Pushpak Bhattacharyya, and Ganesh Ramakrishnan. 2013. Structure cognizant pseudo relevance feedback. In Proceedings of IJCNLP. 982--986.", "Olivier Bodenreider. 2004. The unified medical language system (UMLS): Integrating biomedical terminology. Nucleic Acids Research 32, suppl 1 (2004), D267--D270."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2997643"}, {"title": "A Dynamic 3D Performance Space for Control of Virtual Musical Instruments", "authors": ["Matthew Cox\n,", "Andrew Hollenbach\n,", "Joe Geigel"], "publication": "ISS '16: Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces", "abstract": "ABSTRACT\nThis work explores an intuitive, real-time music generation system and interface. We present a system that uses the real-time skeletal tracking provided by a Microsoft Kinect to generate complex musical compositions containing up to four tracks, with instruments represented in distinct physical spaces. The performer's position and movements are translated into cues that are relayed to Ableton Live for music generation. Finally, we experiment with an interface overlayed in physical space to provide real-time feedback to the user.", "references": ["Axel Mulder. 1994. Virtual musical instruments: Accessing the sound synthesis universe as a performer. In Proceedings of the First Brazilian Symposium on Computer Music. 243--250."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2992154.2996877"}, {"title": "SSD in-storage computing for list intersection", "authors": ["Jianguo Wang\n,", "Dongchul Park\n,", "Yang-Suk Kee\n,", "Yannis Papakonstantinou\n,", "Steven Swanson"], "publication": "DaMoN '16: Proceedings of the 12th International Workshop on Data Management on New Hardware", "abstract": "ABSTRACT\nRecently, there has been a renewed interest of in-storage computing in the context of solid state drives (SSDs), called \"Smart SSDs.\" Smart SSDs allow application-specific code to execute inside SSDs. This allows applications to take advantage of the high internal bandwidth that Smart SSDs provide. This work studies the offloading of list intersection into Smart SSDs, because intersection is prominent in both search engines and analytics queries. Furthermore, intersection is interesting because the algorithms are more complex than plain scans; they are affected by multiple parameters, as we show, and provide lessons that can be used in other operations also.\nWe are interested to know whether Smart SSDs can accelerate the processing of list intersection and reduce the consumed energy. Intuitively, the answer is yes. However, the performance tradeoffs on real devices are complex. We implement list intersection into a real Samsung Smart SSD research prototype. We also provide an analytical model to understand the key factors to the overall performance, and when list intersection can benefit from Smart SSDs. Finally, we conduct experiments on the Samsung Smart SSD. Based on the results (both analytical and experimental), we provide many suggestions for both SSD vendors on how to manufacture powerful Smart SSDs and for applications on how to make full use of the functionalities that Smart SSDs provide.", "references": ["A. Acharya, M. Uysal, and J. Saltz. Active disks: programming model, algorithms and evaluation. In ASPLOS, pages 81--91, 1998.", "D. Bae, J. Kim, S. Kim, H. Oh, and C. Park. Intelligent ssd: a turbo for big data mining. In CIKM, pages 1573--1576, 2013.", "R. Balasubramonian, J. Chang, T. Manning, J. H. Moreno, R. Murphy, R. Nair, and S. Swanson. Near-data processing: insights from a micro-46 workshop. Micro, IEEE, 34(4):36--42, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933349.2933353"}, {"title": "Exploring Patterns of Identity Usage in Tweets: A New Problem, Solution and Case Study", "authors": ["Kenneth Joseph\n,", "Wei Wei\n,", "Kathleen M. Carley"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nSociologists have long been interested in the ways that identities, or labels for people, are created, used and applied across various social contexts. The present work makes two contributions to the study of identity, in particular the study of identity in text. We first consider the following novel NLP task: given a set of text data (here, from Twitter), label each word in the text as being representative of a (possibly multi-word) identity. To address this task, we develop a comprehensive feature set that leverages several avenues of recent NLP work on Twitter and use these features to train a supervised classifier. Our model outperforms a surprisingly strong rule-based baseline by 33%. We then use our model for a case study, applying it to a large corpora of Twitter data from users who actively discussed the Eric Garner and Michael Brown cases. Among other findings, we observe that the identities used by individuals differ in interesting ways based on social context measures derived from census data.", "references": ["A. Ahmed, L. Hong, and A. J. Smola. Hierarchical geographical modeling of user locations from social media posts. In Proceedings of the 22nd international conference on World Wide Web, pages 25--36, 2013.", "A. Ahothali and J. Hoey. Good News or Bad News: Using Affect Control Theory to Analyze Readers Reaction Towards News Articles. ACL, 2015.", "J. R. Anderson. How can the human mind occur in the physical universe? Oxford University Press, Oxford {etc.}, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2883027"}, {"title": "The Method of Semi-supervised Automatic Keyword Extraction for Web Documents using Transition Probability Distribution Generator", "authors": ["Htet Myet Lynn\n,", "Chang Choi\n,", "Junho Choi\n,", "Juhyun Shin\n,", "Pankoo Kim"], "publication": "RACS '16: Proceedings of the International Conference on Research in Adaptive and Convergent Systems", "abstract": "ABSTRACT\nIn this paper, a semi-supervised method for automatic keyword extraction of web documents using unconventional Markov Chain with conditional transition matrices for each distinct feature distributed by Transition Probability Distribution Generator (TPDG) is introduced. Since keywords are the set of the most appropriate and relevant words which define the context of the document precisely and concisely, many applications such as text data mining, text analytics and other natural language processes of deriving high-quality information from text can take advantage of it. The conditional transition matrices for each distinct feature of the model is the state-of-the-art which mostly rely on the characteristics of the keywords and distribution probabilities of each feature on the state space in order to learn the sequence of behaviors of the keywords in various web documents. According to the experimental results, the proposed method outperforms the baseline methods for keyword extraction in terms of performance and semantically.", "references": ["Cohen, J.D. 1995. Highlights: Language and Domain-independent Automatic Indexing Terms for Abstracting. Journal of the American Society for Information Science, 46, 3, 162--174.", "Luhn, H. P. 1957. A Statistical Approach to Mechanized Encoding and Searching of Literary Information.IBM Journal of Research and Development, 1, 4, 309--317.", "Salton, G., Yang, C. S. and Yu, C. T. 1975. A Theory of Importance in Automatic Text Analysis. Journal of the American society for Information Science, 16, 1, 33--44."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987386.2987399"}, {"title": "Cross-Language Microblog Retrieval using Latent Semantic Modeling", "authors": ["Archana Godavarthy\n,", "Yi Fang"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nMicroblogging has become one of the major tools of sharing real-time information for people around the world. Finding relevant information across different languages on microblogs is highly desirable especially for the large number of multilingual users. However, the characteristics of microblog content pose great challenges to the existing cross-language information retrieval approaches. In this paper, we address the task of retrieving relevant tweets given another tweet in a different language. We build parallel corpora for tweets in different languages by bridging them via shared hashtags. We propose a latent semantic approach to model the parallel corpora by mapping the parallel tweets to a low-dimensional shared semantic space. The relevance between tweets in different languages is measured in this shared latent space and the model is trained on a pairwise loss function. The preliminary experiments on a Twitter dataset demonstrate the effectiveness of the proposed approach.", "references": ["I. Alegria, N. Aranberri, C. España Bonet, P. Gamallo, H. Gonçalo Oliveira, E. Martínez Garcia, I. S. V. Roncal, A. Toral, and A. Zubiaga. Overview of tweetmt: a shared task on machine translation of tweets. 2015.", "S. T. Dumais, T. A. Letsche, M. L. Littman, and T. K. Landauer. Automatic cross-language retrieval using latent semantic indexing. In AAAI, 1997.", "C. Hu, P. Resnik, Y. Kronrod, V. Eidelman, O. Buzek, and B. B. Bederson. The value of monolingual crowdsourcing in a real-world translation scenario: Simulation using haitian creole emergency sms messages. In SMT, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970436"}, {"title": "s6raph: vertex-centric graph processing framework with functional interface", "authors": ["Onofre Coll Ruiz\n,", "Kiminori Matsuzaki\n,", "Shigeyuki Sato"], "publication": "FHPC 2016: Proceedings of the 5th International Workshop on Functional High-Performance Computing", "abstract": "ABSTRACT\nParallel processing of big graph-shaped data still presents many challenges. Several approaches have appeared recently, and a strong trend focusing on understanding graph computation as iterative vertex-centric computations has emerged. There have been several systems in the vertex-centric approach, for example Pregel, Giraph, GraphLab and PowerGraph. Though programs developed in these systems run efficiently in parallel, writing vertex-programs usually results in code with poor readability, that is full of side effects and control statements unrelated to the algorithm.\nIn this paper we introduce ``s6raph'', a new vertex-centric graph processing framework with a functional interface that allows the user to write clear and concise functions. The user can choose one of several default behaviours provided for most common graph algorithms. We discuss the design of the functional interface and introduce our prototype implementation in Erlang.", "references": ["C. Avery. Giraph: Large-scale graph processing infrastructure on Hadoop. Proceedings of the Hadoop Summit, 2011.", "A. Buluc¸ and J. R. Gilbert. The combinatorial BLAS: Design, implementation, and applications. International Journal of High Performance Computing Applications, 25(4):496–509, 2011.", "K. Emoto, K. Matsuzaki, Z. Hu, A. Morihata, and H. Iwasaki. Think like a vertex, behave like a funtion! — a funtional DSL for vertex-centric big graph proessing —. In Proceedings of the International Conference on Functional Programming (ICFP2016), to appear. J. E. Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin. PowerGraph: Distributed graph-parallel computation on natural graphs. In Proc. the 10th USENIX Conference on Operating Systems Design and Implementation (OSDI’12), pp. 17–30, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2975991.2976000"}, {"title": "Session details: Web Search", "authors": ["David Hawking"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252669"}, {"title": "Coverage and diversity aware top-k query for spatio-temporal posts", "authors": ["Paras Mehta\n,", "Dimitrios Skoutas\n,", "Dimitris Sacharidis\n,", "Agnès Voisard"], "publication": "SIGSPACIAL '16: Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nLarge amounts of user-generated content are posted daily on the Web, including textual, spatial and temporal information. Exploiting this content to detect, analyze and monitor events and topics that have a potentially large span in space and time requires efficient retrieval and ranking based on criteria including all three dimensions. In this paper, we introduce a novel type of spatial-temporal-keyword query that combines keyword search with the task of maximizing the spatio-temporal coverage and diversity of the returned top-f results. We first describe a baseline algorithm based on related search results diversification problems. Then, we develop an efficient approach which exploits a hybrid spatial-temporal-keyword index to drastically reduce query execution time. To that end, we extend two state-of-the- art indices for top-f spatio-textual queries and describe how our proposed approach can be applied on top of them. We evaluate the efficiency of our algorithms by conducting experiments on two large, real-world datasets containing geotagged tweets and photos.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14, 2009.", "O. Alonso and K. Shiells. Timelines as summaries of popular scheduled events. In WWW '13 Companion, pages 1037--1044, 2013.", "O. Alonso, J. Strötgen, R. A. Baeza-Yates, and M. Gertz. Temporal information retrieval: Challenges and opportunities. In WWW Workshop on Linked Data on the Web, pages 1--8, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2996913.2996941"}, {"title": "An Improved Multileaving Algorithm for Online Ranker Evaluation", "authors": ["Brian Brost\n,", "Ingemar J. Cox\n,", "Yevgeny Seldin\n,", "Christina Lioma"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline ranker evaluation is a key challenge in information retrieval. An important task in the online evaluation of rankers is using implicit user feedback for inferring preferences between rankers. Interleaving methods have been found to be efficient and sensitive, i.e. they can quickly detect even small differences in quality. It has recently been shown that multileaving methods exhibit similar sensitivity but can be more efficient than interleaving methods. This paper presents empirical results demonstrating that existing multileaving methods either do not scale well with the number of rankers, or, more problematically, can produce results which substantially differ from evaluation measures like NDCG. The latter problem is caused by the fact that they do not correctly account for the similarities that can occur between rankers being multileaved. We propose a new multileaving method for handling this problem and demonstrate that it substantially outperforms existing methods, in some cases reducing errors by as much as 50%.", "references": ["K. Hofmann, S. Whiteson, and M. D. Rijke. Fidelity, soundness, and efficiency of interleaved comparison methods. TOIS, 31(4):17.1--17.39, 2013.", "A. Schuth, R.-J. Bruintjes, F. Büttner, J. van Doorn, C. Groenland, H. Oosterhuis, C.-N. Tran, B. Veeling, J. van der Velde, R. Wechsler, et al. Probabilistic multileave for online retrieval evaluation. phSIGIR, pages 955--958, 2015.", "A. Schuth, F. Sietsma, S. Whiteson, D. Lefortier, and M. de Rijke. Multileaved comparisons for fast online evaluation. phCIKM, pages 71--80. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914706"}, {"title": "E3: Keyphrase based News Event Exploration Engine", "authors": ["Nikita Jain\n,", "Swati Gupta\n,", "Dhaval Patel"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nThis paper presents a novel system E3 for extracting keyphrases from news content for the purpose of offering the news audience a broad overview of news events, with especially high content volume. Given an input query, E3 extracts keyphrases and enrich them by tagging, ranking and finding role for frequently associated keyphrases. Also, E3 finds the novelty and activeness of keyphrases using news publication date, to identify the most interesting and informative keyphrases.", "references": ["K. Leetaru and P. A. Schrodt, GDELT: Global data on events, location, and tone. International Studies Association Annual Convention, 2013.", "G. Leban, B. Fortuna, J. Brank, and M. Grobelnik, Event Registry: Learning About World Events from News. World Wide Web, 2014.", "J. Hoffart, D. Milchevski, and G. Weikum, STICS: Searching with Strings, Things, and Cats. Special Interest Group on Information Retrieval, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914611"}, {"title": "Crowdsourcing strategies for smart cities applications", "authors": ["Wancharle S. Quirino\n,", "Celso A.S. Santos\n,", "Juan X.E.A. Calles\n,", "Fernando Tinelli F."], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nCrowdsourcing is a problem-solving model through the contribution of a large number of people and has a low cost among its main advantages. On the other hand, smart cities today comprise a multidisciplinary challenge, where they have the objective of sustainable development and improving the quality of life of its inhabitants. Thus, we see in crowdsourcing a resource capable of contributing to building smart cities. This paper investigates the existing intersection between the fields of smart cities and crowdsourcing and discover the gaps and challenges that characterize this applications context. As a result, we propose some strategies to facilitate the development of crowdsourcing applications. These strategies are then applied to the construction of several applications of this type, two of which are discussed at the end of the article.", "references": ["Asimakopoulou, E.; Bessis, N. Buildings and Crowds: Forming Smart Cities for More Effective Disaster Management. Proc. Fifth Int. Conf. on Innovative Mobile and Internet Services in Ubiquitous Computing, IEEE (2011), 229-234.", "Botero, A.; Saad-Sulonen, J. Co-designing for New Citycitizen Interaction Possibilities: Weaving Prototypes and Interventions in the Design and Development of Urban Mediator. Indiana University (2008), 266-269.", "Caminha, C., Furtado, V., Vasconcelos, E.; Ayres, L. Uma ferramenta de autoria para criacao de mapas colaborativos para aplicacoes em egov 2.0. Proc. XXX CSBC, (2010), 20- 23."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022041"}, {"title": "Search Engine Implementation", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915040"}, {"title": "The BOLT IR Test Collections of Multilingual Passage Retrieval from Discussion Forums", "authors": ["Ian Soboroff\n,", "Kira Griffitt\n,", "Stephanie Strassel"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper describes a new test collection for passage retrieval from multilingual, informal text. The task being modeled is that of a monolingual English-speaking user who wishes to search discussion forum text in a foreign language. The system retrieves relevant short passages of text and presents them to the user, translated into English. The test collection contains more than 2 billion words of discussion thread text, 250 queries representing complex informational search needs, and manual relevance judgments of forum post passages, pooled from real systems. This information retrieval test collection is the first to combine multilingual search, passage retrieval, and informal online genre text.", "references": ["J. Allan. HARD track overview in TREC 2005: High accuracy retrieval from documents. In Proceedings of TREC 2005, pages 52--68. NIST, 2006.", "BOLT program home page. http://www.darpa.mil/program/broad-operational-language-translation, retrieved on Feb 1, 2016.", "K. Griffitt and S. Strassel. The query of everything: Developing open-domain, natural language queries for BOLT information retrieval. In Proceedings of LREC 2016, Portoro\\vz, Slovenia, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914674"}, {"title": "Effective User Relevance Feedback for Image Retrieval with Image Signatures", "authors": ["Dinesha Chathurani Nanayakkara Wasam Uluwitige\n,", "Shlomo Geva\n,", "Guido Zuccon\n,", "Vinod Chandran\n,", "Timothy Chappell"], "publication": "ADCS '16: Proceedings of the 21st Australasian Document Computing Symposium", "abstract": "ABSTRACT\nContent-based image retrieval (CBIR) has attracted much attention due to the exponential growth of digital image collections that have become available in recent years. Relevance feedback (RF) in the context of search engines is a query expansion technique, which is based on relevance judgments about the top results that are initially returned for a given query. RF can be obtained directly from end users, inferred indirectly from user interactions with a result list, or even assumed (aka pseudo relevance feedback). RF information is used to generate a new query, aiming to re-focus the query towards more relevant results.\nThis paper presents a methodology for use of signature based image retrieval with a user in the loop to improve retrieval performance. The significance of this study is twofold. First, it shows how to effectively use explicit RF with signature based image retrieval to improve retrieval quality and efficiency. Second, this approach provides a mechanism for end users to refine their image queries. This is an important contribution because, to date, there is no effective way to reformulate an image query; our approach provides a solution to this problem.\nEmpirical experiments have been carried out to study the behaviour and optimal parameter settings of this approach. Empirical evaluations based on standard benchmarks demonstrate the effectiveness of the proposed approach in improving the performance of CBIR in terms of recall, precision, speed and scalability.", "references": ["L. Azzopardi and G. Zuccon. An analysis of the cost and benefit of search interactions. In ICTIR' 16, 2016.", "J. Banda, R. Angryk, and P. Martens. On dimensionality reduction for indexing and retrieval of large-scale solar image data. Solar Physics, 283(1):113--141, 2013.", "T. Chappell and S. Geva. Topsig: A scalable system for hashing and retrieving document signatures. In IR Technology, pages 447--452. Springer, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015022.3015034"}, {"title": "Computational Creativity Based Video Recommendation", "authors": ["Wei Lu\n,", "Fu-lai Chung"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nComputational creativity, as an emerging domain of application, emphasizes the use of big data to automatically design new knowledge. Based on the availability of complex multi-relational data, one aspect of computational creativity is to infer unexplored regions of feature space and novel learning paradigm, which is particularly useful for online recommendation. Tensor models offer effective approaches for complex multi-relational data learning and missing element completion. Targeting at constructing a recommender system that can compromise between accuracy and creativity for users, a deep Bayesian probabilistic tensor framework for tag and item recommending is adopted. Empirical results demonstrate the superiority of the proposed method and indicate that it can better capture latent patterns of interaction relationships and generate interesting recommendations based on creative tag combinations.", "references": ["P. Baldi and L. Itti. Of bits and wows: a bayesian theory of surprise with applications to attention. Neural Networks, 23(5):649--666, 2010.", "Y. Bengio. Learning deep architectures for ai. Foundations and trends® in Machine Learning, 2(1):1--127, 2009.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914707"}, {"title": "Learning Music Embedding with Metadata for Context Aware Recommendation", "authors": ["Dongjing Wang\n,", "Shuiguang Deng\n,", "Xin Zhang\n,", "Guandong Xu"], "publication": "ICMR '16: Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nContextual factors can benefit music recommendation and retrieval tasks remarkably. However, how to acquire and utilize the contextual information still need to be studied. In this paper, we propose a context aware music recommendation approach, which can recommend music appropriate for users' contextual preference for music. In analogy to matrix factorization methods for collaborative filtering, the proposed approach does not require songs to be described by features beforehand, but it learns music pieces' embeddings (vectors in low-dimensional continuous space) from music playing records and corresponding metadata and infer users' general and contextual preference for music from their playing records with the learned embedding. Then, our approach can recommend appropriate music pieces. Experimental evaluations on a real world dataset show that the proposed approach outperforms baseline methods.", "references": ["S. Kabbur, X. Ning, and G. Karypis, Fism: factored item similarity models for top-n recommender systems. In Proceedings of the 19th ACM International Conference on Knowledge Discovery and Data Mining, 659--667, 2013.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, 452--461, 2009.", "D. Wang, S. Deng, S. Liu, and G. Xu, Improving Music Recommendation Using Distributed Representation. In Proceedings of the 25th International Conference Companion on World Wide Web, 125--126, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911996.2912045"}, {"title": "A Scheduling Method to Enable Fast-forwarding for Selective Contents Broadcasting", "authors": ["Daichi Fukui\n,", "Yusuke Gotoh"], "publication": "MoMM '16: Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media", "abstract": "ABSTRACT\nIn selective contents broadcasting, i.e., watching contents users selected themselves, the server can deliver several contents to many users. However, when users watch the data continuously, waiting time is occurred by decreasing the available bandwidth and increasing the number of contents. Therefore, many researchers have proposed the scheduling methods to reduce the waiting time. Although the conventional method reduces waiting time by producing the broadcast schedule in fast-forwarding, that for playing contents in normal playback becomes lengthened. In this paper, we propose a scheduling method to enable fast-forwarding for selective contents broadcasting. Our proposed method sets the number of channels based on the configuration of the program and the available bandwidth. In addition, waiting time can be reduced by dividing each content into two types of data for fast-forwarding and normal playback and scheduling them.", "references": ["T. Yoshihisa: A Scheduling Method for Bandwidth Reduction in Selective Contents Broadcasting, Proc. of IPSJ International Conference on Mobile Computing and Ubiquitous Networking (ICMU'06), pp. 60--67 (2006).", "Y. Gotoh, T. Yoshihisa, H. Taniguchi, M. Kanazawa, W. Rahayu, and Y.P.P. Chen: A Scheduling Method for Selective Contents Broadcasting with Fast-forwarding, Proc. of 2nd International Workshop on Streaming Media Delivery and Management Systems (SMDMS 2011), pp. 344--349 (2011).", "Y. Gotoh, T. Yoshihisa, M. Kanazawa, and Y. Takahashi: A Scheduling Method to Reduce Waiting Time Considering Transition Probability for Selective Contents Broadcasting, IEEE International Symposium on Wireless Communication Systems 2008 (ISWCS'08), pp. 149--153 (2008)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007120.3007124"}, {"title": "Analyzing the Perceptions of Change in a Distributed Collection of Web Documents", "authors": ["Luis Meneses\n,", "Sampath Jayarathna\n,", "Richard Furuta\n,", "Frank Shipman"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nIt is not unusual for documents on the Web to degrade and suffer from problems associated with unexpected change. In an analysis of the Association for Computing Machinery conference list, we found that categorizing the degree of change affecting digital documents over time is a difficult task. More specifically, we found that categorizing this degree of change is not a binary problem where documents are either unchanged or they have changed so dramatically that they do not fit within the scope of the collection. It is in part, a characterization of the intent of the change. In this paper, we present a case study that compares change detection methods based on machine learning algorithms against the assessment made by human subjects in a user study. Consequently, this paper will focus on two research questions. First, how can we categorize the various degrees of change that documents endure? And second, how did our automatic detection methods fare against the human assessment of change in the ACM conference list?", "references": ["M. Kobayashi and K. Takeda, \"Information retrieval on the web,\" ACM Computing Surveys, vol. 32, pp. 144--173, 2000.", "M. K. Taylor and D. Hudson, \"\" Linkrot\" and the Usefulness of Web Site Bibliographies,\" Reference & User Services Quarterly, pp. 273--277, 2000.", "P. Logasa Bogen, D. Pogue, F. Poursardar, Y. Li, R. Furuta, and F. Shipman, \"WPv4: a re-imagined Walden's paths to support diverse user communities,\" in Proceedings of the 11th annual International ACM/IEEE Joint Conference on Digital Libraries, Ottawa, Ontario, Canada, 2011, pp. 419--420."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914628"}, {"title": "Search Tactics of Images' Textual Descriptions", "authors": ["Yi-Ling Lin\n,", "Wen-Lin Lan\n,", "Ren-Yi Hong\n,", "I-Han (Sharon) Hsiao"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nThe images' textual descriptions from experts and the general public, subject headings and social tags, are provided to facilitate image search process. Search tactics represents a series of search choices and actions with the textual descriptions provided on the systems during the search process. However, integration of different textual descriptions for image finding have rarely been investigated. This study investigates whether and how two types of different textual descriptions in relation to subject headings and social tags affect user' search tactics. Thirty-six participants were recruited for this study. Multiple methods were employed to collect data, including questionnaires, interviews, and eye-tracking analysis. Eliciting participants' viewing behaviors, this study benefit benefits our understanding of different search tactics of various users and provide adaptive mechanisms to fulfill their search needs. The results of this study provided four guidelines for practitioners when designing adaptive image search interface to fulfill users search tactics.", "references": ["Aula, A. et al. 2005. Information search and re-access strategies of experienced web users. Proceedings of the 14th international conference on World Wide Web - WWW '05 (2005), 583.", "Ayres, J. et al. 2002. Sequential pattern mining using a bitmap representation. Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining (2002), 429--435.", "Bates, M.J. 1979. Information search tactics. Journal of the American Society for Information Science. 30, 4 (1979), 205--214."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914626"}, {"title": "A preliminary study on a recommender system for the job recommendation challenge", "authors": ["Mirko Polato\n,", "Fabio Aiolli"], "publication": "RecSys Challenge '16: Proceedings of the Recommender Systems Challenge", "abstract": "ABSTRACT\nIn this paper we present our method used in the RecSys '16 Challenge.\nIn particular, we propose a general collaborative filtering framework where many predictors can be cast. The framework is able to incorporate information about the content but in a collaborative fashion. Using this framework we instantiate a set of different predictors that consider different aspects of the dataset provided for the challenge. In order to merge all these aspects together, we also provide a method able to linearly combine the predictors. This method learns the weights of the predictors by solving a quadratic optimization problem.\nIn the experimental section we show the performance using different predictors combinations. Results highlight the fact that the combination always outperforms the single predictor.", "references": ["F. Aiolli. Efficient top-N recommendation for very large scale binary rated datasets. In ACM Recommender Systems Conference, pages 273--280, Hong Kong, China, 2013.", "F. Aiolli. Convex AUC optimization for top-N recommendation with implicit feedback. In ACM Recommender Systems Conference, pages 293--296, New York, USA, 2014.", "R. P. F. Abel, D. Kohlsdorf. Acm recsys challenge 2016: Training data. https://recsys.xing.com/data, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2987538.2987549"}, {"title": "Feeling lucky?: multi-armed bandits for ordering judgements in pooling-based evaluation", "authors": ["David E. Losada\n,", "Javier Parapar\n,", "Álvaro Barreiro"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nEvaluation is crucial in Information Retrieval. The Cranfield paradigm allows reproducible system evaluation by fostering the construction of standard and reusable benchmarks. Each benchmark or test collection comprises a set of queries, a collection of documents and a set of relevance judgements. Relevance judgements are often done by humans and thus expensive to obtain. Consequently, relevance judgements are customarily incomplete. Only a subset of the collection, the pool, is judged for relevance. In TREC-like campaigns, the pool is formed by the top retrieved documents supplied by systems participating in a certain evaluation task. With multiple retrieval systems contributing to the pool, an exploration/exploitation trade-off arises naturally. Exploiting effective systems could find more relevant documents, but exploring weaker systems might also be valuable for the overall judgement process. In this paper, we cast document judging as a multi-armed bandit problem. This formal modelling leads to theoretically grounded adjudication strategies that improve over the state of the art. We show that simple instantiations of multi-armed bandit models are superior to all previous adjudication strategies.", "references": ["J. Aslam and M. Montague. Models for metasearch. In Proc. of the 24th Annual Int. ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '01, pages 276--284, NY, USA, 2001.", "J. A. Aslam, V. Pavlu, and R. Savell. A unified model for metasearch, pooling, and system evaluation. In Proc. of the 12th Int. Conference on Information and Knowledge Management, pages 484--491. ACM, 2003.", "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach. Learn., 47(2-3):235--256, May 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851692"}, {"title": "You Can Check It Out But It Will Never Leave: Characterising Ebook Borrowing Patterns", "authors": ["Dana McKay\n,", "George Buchanan"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nWhat does it mean for a reader to borrow an ebook? Ebook technology means that borrowing can take different forms, for example printing and reading. We do not know, though, which of these options readers actually use. Ebook technology generates logs that allow us to understand ebook borrowing patterns over time, both by individual readers and in aggregate. Despite the ready availability of ebook logs, this area remains under-researched. In this paper we present an exploratory log analysis of ebook borrowing, comparing printing and reading, discovery patterns, single- and multiple-book sessions and identifying specific borrowing patterns.", "references": ["Adler, A., Gujar, A., Harrison, B.L., O'Hara, K., and Sellen, A., 1998. A diary study of work-related reading: design implications for digital reading devices. In Proc. CHI 98 (Los Angeles, California, United States, 1998), ACM Press, 241--248. DOI= http://dx.doi.org/10.1145/274644.274679.", "Ballard, T. and Blaine, A., 2011. User search-limiting behavior in online catalogs: Comparing classic catalog use to search behavior in next-generation catalogs. New Library World 112, 5, 261--273.", "Bates, M.J., 2002. Toward an integrated model of information seeking and searching. The New Review of Information Behaviour Research 3, 1--15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854970"}, {"title": "Vision and Language Integration Meets Multimedia Fusion: Proceedings of ACM Multimedia 2016 Workshop", "authors": ["Marie-Francine Moens\n,", "Katerina Pastra\n,", "Kate Saenko\n,", "Tinne Tuytelaars"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nMultimodal information fusion both at the signal and the semantics levels is a core part in most multimedia applications, including multimedia indexing, retrieval, summarization and others. Early or late fusion of modality-specific processing results has been addressed in multimedia prototypes since their very early days, through various methodologies including rule-based approaches, information-theoretic models and machine learning. Vision and Language are two of the predominant modalities that are being fused and which have attracted special attention in international challenges with a long history of results, such as TRECVid, ImageClef and others. During the last decade, vision-language semantic integration has attracted attention from traditionally non-interdisciplinary research communities, such as Computer Vision and Natural Language Processing. This is due to the fact that one modality can greatly assist the processing of another providing cues for disambiguation, complementary information and noise/error filtering. The latest boom of deep learning methods has opened up new directions in joint modelling of visual and co-occurring verbal information in multimedia discourse. The workshop on Vision and Language Integration Meets Multimedia Fusion has been held during the workshop weekend of the ACM Multimedia 2016 Conference and the European Conference on Computer Vision (ECCV 2016) on October 16, 2016 in Amsterdam, the Netherlands. The proceedings contain seven selected long papers, which have been orally presented at the workshop, and three abstracts of the invited keynote speeches. The papers and abstracts discuss data collection, representation learning, deep learning approaches, matrix and tensor factorization methods and graph based clustering with regard to the fusion of multimedia data. A variety of applications is presented including image captioning, summarization of news, video hyperlinking, sub-shot segmentation of user generated video, cross-modal classification, cross-modal question-answering, and the detection of misleading metadata of user generated video. The workshop is organized and supported by the EU COST action iV&L Net, the European Network on Integrating Vision and Language: Combining Computer Vision and Language Processing for Advanced Search, Retrieval, Annotation and Description of Visual Data (IC 1307--2014-2018).", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2980537"}, {"title": "Approaches for integration in system of systems: a systematic review", "authors": ["Iohan Gonçalves Vargas\n,", "Thiago Gottardi\n,", "Rosana Teresinha Vaccare Braga"], "publication": "SESoS '16: Proceedings of the 4th International Workshop on Software Engineering for Systems-of-Systems", "abstract": "ABSTRACT\nSoftware systems have become increasingly complex, and they are often formed by integrating independent systems, resulting in a new class of systems referenced as System of Systems (SoS). The System of Systems Integration (SoSI) emerges as a new challenge and aims to create a new feature by integrating constituent systems that contribute to the overall goal of the SoS. Often the constituent systems tend to be from different sources and behaviors and, as such, tend to employ different terminology and concepts. Also, when SoSI involves the integration of legacy systems, cases where the documentation and the necessary skills for the harmonious integration are readily available are very rare. However, it is observed that there is a lack of studies that are comprehensive and, at the same time, contain a detailed view of how the constituent systems are integrated in order to collectively achieve a common goal. Based on this scenario, the main contribution of this systematic review (SR) is to investigate the state of the art of SoSI and the software engineering methods that assist in the integration between constituent systems of a SoS. The SR has found 1398 studies and, at the end of the selection process, we selected 29 studies for data extraction. Most studies describe individuals and teams who have worked in isolation to develop solutions to certain problems without widespread adoption of a form of integration. Thus, there is a growing concern of researchers in the SoS context. However, it still lacks research and greater dissemination of concepts among researchers in the field.", "references": ["J. Boardman and B. Sauser. System of systems - the meaning of of. In IEEE/SMC Int. Conf. on System of Systems Engineering, pages 6 pp.--, April 2006.", "G. Botterweck. Variability and evolution in systems of systems. 1st Workshop on Advances in Systems of Systems - AISOS' 13, in Roma, Italy, pages 8--23, 2013.", "H. Cooper, L. V. Hedges, and J. C. Valentine. The handbook of research synthesis and meta-analysis. Russell Sage Foundation, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2897829.2897835"}, {"title": "Generating Pseudotransactions for Improving Sparse Matrix Factorization", "authors": ["Agung Toto Wibowo"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecent research on Recommender Systems, specifically Collaborative Filtering, has focussed on Matrix Factorization (MF) methods, which have been shown to provide good solutions to the cold start problem. However, typically the same settings are used for Matrix factorization regardless of the density of the matrix. In our experiments, we found that for MF, Root Mean Square Error (RMSE) for recommendations increases (i.e. performance drops) for sparse matrices. We propose a Two Stage MF approach so MF is run twice over the whole matrix; the first stage uses MF to generate a small percentage of pseudotransactions that are added to the original matrix to increase its density, and the second stage re-runs MF over this denser matrix to predict the user-item transactions in the testing set. We show using data from Movielens that such methods can improve on the performance of MF for sparse martrices.", "references": ["M. W. Berry, M. Browne, A. N. Langville, V. P. Pauca, and R. J. Plemmons. Algorithms and applications for approximate nonnegative matrix factorization. Computational statistics & data analysis, 52(1):155--173, 2007.", "J. Bobadilla, F. Ortega, A. Hernando, and A. Gutiérrez. Recommender systems survey. Knowledge-Based Systems, 46:109--132, 7 2013.", "R. Burke. Hybrid recommender systems: Survey and experiments. User modeling and user-adapted interaction, 12(4):331--370, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959107"}, {"title": "Geography of Emotion: Where in a City are People Happier?", "authors": ["Luciano Gallegos\n,", "Kristina Lerman\n,", "Arhur Huang\n,", "David Garcia"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nDuring the last years, researchers explored the geographic and environmental factors that affect happiness. More recently, location-sharing services provided by the social media has given an unprecedented access to geo-located data for studying the interplay between these factors on a much bigger scale. Do location-sharing services help in turn at distinguishing emotions in places within a city? Which aspects contribute better at understanding happier places? To answer these questions, we use data from Foursquare location-sharing service to identify areas within a major US metropolitan area with many check-ins, i.e., areas that people like to use. We then use data from the Twitter microblogging platform to analyze the properties of these areas. Specifically, we have extracted a large corpus of geo-tagged messages, called tweets, from a major metropolitan area and linked them US Census data through their locations. This allows us to measure the sentiment expressed in tweets that are posted from a specific area, and also use that area's demographic properties in analysis. Our results reveal that areas with many check-ins are different from other areas within the metropolitan region. In particular, these areas have happier tweets, which also encourage people living in it or from other areas to commute longer distances to these places. These findings shed light on the influence certain places play within a city regarding people's emotions and mobility, which in turn can be used for city planners for designing happier and more equitable cities.", "references": ["Happiness, geography and the environment. Ecological Economics, 65(2):386--396, Apr. 2008.", "A. Abbasi, A. Hassan, and M. Dhar. Benchmarking twitter sentiment analysis tools. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), 2014.", "A. Alshamsi, E. Awad, M. Almehrezi, V. Babushkin, P.-J. Chang, Z. Shoroye, A.-P. Toth, and I. Rahwan. Misery loves company: happiness and communication in the city. EPJ Data Science, 4(1):7, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2890084"}, {"title": "The Power of Babble", "authors": ["Pat Helland"], "publication": "Queue", "abstract": "Abstract\nExpect to be constantly and pleasantly befuddled", "references": ["Clark, D. 2009. The Apocalypse of Two Elephants, or \"what I really said.\" Advanced Network Architecture. MIT CSAIL; http://groups.csail.mit.edu/ana/People/DDC/Apocalypse.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2984629.3003188"}, {"title": "Agents, Simulated Users and Humans: An Analysis of Performance and Behaviour", "authors": ["David Maxwell\n,", "Leif Azzopardi"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMost of the current models that are used to simulate users in Interactive Information Retrieval (IIR) lack realism and agency. Such models generally make decisions in a stochastic manner, without recourse to the actual information encountered or the underlying information need. In this paper, we develop a more sophisticated model of the user that includes their cognitive state within the simulation. The cognitive state maintains data about what the simulated user knows, has done and has seen, along with representations of what it considers attractive and relevant. Decisions to inspect or judge are then made based upon the simulated user's current state, rather than stochastically. In the context of ad-hoc topic retrieval, we evaluate the quality of the simulated users and agents by comparing their behaviour and performance against 48 human subjects under the same conditions, topics, time constraints, costs and search engine. Our findings show that while naive configurations of simulated users and agents substantially outperform our human subjects, their search behaviour is notably different from actual searchers. However, more sophisticated search agents can be tuned to act more like actual searchers providing greater realism. This innovation advances the state of the art in simulation, from simulated users towards autonomous agents. It provides a much needed step forward enabling the creation of more realistic simulations, while also motivating the development of more advanced cognitive agents and tools to help support and augment human searchers. Future work will focus not only on the pragmatics of tuning and training such agents for topic retrieval, but will also look at developing agents for other tasks and contexts such as collaborative search and slow search.", "references": ["G. Amati and C.J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM TOIS, 20 (4): 357--389, 2002.", "R. Armstrong, D. Freitag, T. Joachims, and T. Mitchell. Webwatcher: A learning apprentice for the world wide web. In Proc. AAAI Spring Symp. on Info. Gathering from Heterogeneous, Distributed Environments, pages 6--12, 1995.", "L. Azzopardi. Query side evaluation: An empirical analysis of effectiveness and effort. In Proceedings of the 32nd ACM SIGIR, pages 556--563, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983805"}, {"title": "Optimization Method for Weighting Explicit and Latent Concepts in Clinical Decision Support Queries", "authors": ["Saeid Balaneshin-kordan\n,", "Alexander Kotov"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nAccurately answering verbose queries that describe a clinical case and aim at finding articles in a collection of medical literature requires capturing many explicit and latent aspects of complex information needs underlying such queries. Proper representation of these aspects often requires query analysis to identify the most important query concepts as well as query transformation by adding new concepts to a query, which can be extracted from the top retrieved documents or medical knowledge bases. Traditionally, query analysis and expansion have been done separately. In this paper, we propose a method for representing verbose domain-specific queries based on weighted unigram, bigram, and multi-term concepts in the query itself, as well as extracted from the top retrieved documents and external knowledge bases. We also propose a graduated non-convexity optimization framework, which allows to unify query analysis and expansion by jointly determining the importance weights for the query and expansion concepts depending on their type and source. Experiments using a collection of PubMed articles and TREC Clinical Decision Support (CDS) track queries indicate that applying our proposed method results in significant improvement of retrieval accuracy over state-of-the-art methods for ad hoc and medical IR.", "references": ["A. R. Aronson and F.-M. Lang. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association, 17(3):229--236, 2010.", "S. Balaneshin-kordan, A. Kotov, and R. Xisto. WSU-IR at TREC 2015 clinical decision support track: Joint weighting of explicit and latent medical query concepts from diverse sources. In Proceedings of TREC'15, 2015.", "M. Bendersky and W. B. Croft. Discovering key concepts in verbose queries. In Proceedings of SIGIR'08, pages 491--498, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970418"}, {"title": "Relationship between learning indicators in the development and result of the building engineering degree final project", "authors": ["Enric Peña\n,", "David Fonseca\n,", "Nuria Martí"], "publication": "TEEM '16: Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "abstract": "ABSTRACT\nThe present work can be included in a much broader investigation related to the content, methodology and success of the Final Degree Project (FDP) in the framework of Building and Construction Management. The aim of our proposal is to study the current FDP in Technical Architecture and Building Engineering degrees using an academic analytics approach. Here, we will focus on the first stage, in order to establish a relationship among the main academic indicators that determine the FDP outcome. The typology of the final projects in engineering degrees requires the use of abilities and technical competences described in several academic plans, in order to prepare the student for joining the job market. This work focuses on and compares the 2004--2007 and 2012--2015 periods (pre and post Bologna), in order to examine the effect of expanding the academic plan from three to four academic years. The results confirm an improvement in the final marks the students attained in the second period, which can be related to the changes in the academic plan.", "references": ["Duval, E., and Verbert, K. 2012. Learning Analytics.eleed, 8.", "Hernández-García, A., Conde, M.A., 2014. Dealing with complexity: educational data and tools for learning analytics. In Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality (TEEM '14). ACM, New York, NY, USA, 263--268.", "«BOE» núm. 260, de 30/10/2007. Real Decreto 1393/2007, 28/10/2007. Ordenación de las enseñanzas universitarias oficiales. Departamento: Ministerio de Educación y Ciencia."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3012430.3012537"}, {"title": "Unveiling smoke in social images with the SmokeBlock approach", "authors": ["Mirela T. Cazzolato\n,", "Marcos V. N. Bedo\n,", "Alceu F. Costa\n,", "Jessica Andressa de Souza\n,", "Caetano Traina\n,", "Jose F. Rodrigues\n,", "Agma J. M. Traina"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nCan we use information from social media and crowdsourced images to detect smoke and assist rescue forces? While there are computer vision methods for detecting smoke, they require movement information extracted from video data. In this paper we propose SmokeBlock: a method that is able to segment and detect smoke in still images. SmokeBlock uses superpixel segmentation and extracts local color and texture features from images to spot smoke. We used real data from Flickr and compared SmokeBlock against state-of-the-art methods for feature extraction. Our method achieved performance superior than the competitors, for the task of smoke detection. Our findings shall support further investigations in the field of image analysis, in particular, concerning images captured with mobile devices.", "references": ["R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Suesstrunk. SLIC Superpixels. Technical report, EPFL, 2010.", "R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Suesstrunk. SLIC Superpixels compared to state-of-the-art superpixel methods. TPAMI, 34(11):2274--2282, 2012.", "D. W. Aha, D. Kibler, and M. K. Albert. Instance based learning algorithms. ML, 6(1):37--66, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851634"}, {"title": "Updatable, Accurate, Diverse, and Scalable Recommendations for Interactive Applications", "authors": ["Bibek Paudel\n,", "Fabian Christoffel\n,", "Chris Newell\n,", "Abraham Bernstein"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nRecommender systems form the backbone of many interactive systems. They incorporate user feedback to personalize the user experience typically via personalized recommendation lists. As users interact with a system, an increasing amount of data about a user’s preferences becomes available, which can be leveraged for improving the systems’ performance. Incorporating these new data into the underlying recommendation model is, however, not always straightforward. Many models used by recommender systems are computationally expensive and, therefore, have to perform offline computations to compile the recommendation lists. For interactive applications, it is desirable to be able to update the computed values as soon as new user interaction data is available: updating recommendations in interactive time using new feedback data leads to better accuracy and increases the attraction of the system to the users. Additionally, there is a growing consensus that accuracy alone is not enough and user satisfaction is also dependent on diverse recommendations.\nIn this work, we tackle this problem of updating personalized recommendation lists for interactive applications in order to provide both accurate and diverse recommendations. To that end, we explore algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on efficiency and accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP3β that reranks items based on three-hop random walk transition probabilities. We show empirically that RP3β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present approximate versions of RP3β and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with an increasing number of samples.\nTo obtain interactively updatable recommendations, we additionally show how our algorithm can be extended for online updates at interactive speeds. The underlying random walk sampling technique makes it possible to perform the updates without having to recompute the values for the entire dataset.\nIn an empirical evaluation with three real-world datasets, we show that RP3β provides highly accurate and diverse recommendations that can easily be updated with newly gathered information at interactive speeds (≪ 100ms).", "references": ["Gediminas Adomavicius and YoungOk Kwon. 2011. Maximizing aggregate recommendation diversity: A graph-theoretic approach. In Proceedings of the 1st International Workshop on Novelty and Diversity in Recommender Systems (DiveRS’11). Citeseer, 3--10.", "Gediminas Adomavicius and YoungOk Kwon. 2012. Improving aggregate recommendation diversity using ranking-based techniques. IEEE Transactions on Knowledge and Data Engineering, 24, 5 (2012), 896--911.", "Charu C. Aggarwal, Joel L. Wolf, Kun-Lung Wu, and Philip S. Yu. 1999. Horting hatches an egg: A new graph-theoretic approach to collaborative filtering. In Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 201--212."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2955101"}, {"title": "Leveraging MPEG-21 user description for interoperable recommender systems", "authors": ["Sabino Metta\n,", "Paolo Casagranda\n,", "Alberto Messina\n,", "Maurizio Montagnuolo\n,", "Francesco Russo"], "publication": "SAC '16: Proceedings of the 31st Annual ACM Symposium on Applied Computing", "abstract": "ABSTRACT\nThe paper introduces the MPEG-21 User Description standard, referred to as MPEG-21 UD, aimed at enabling the horizontal integration of recommendations coming from different service providers. MPEG-21 UD specifies standard descriptions for a given user, her context and available services. In addition MPEG-21 UD specifies standard formats for recommendations. In this way a generic provider can horizontally integrate standard descriptions belonging to different recommendation services thus possibly returning to the user richer recommendations and, likely, a better fruition.", "references": ["S. Berkovsky, T. Kuik, and F. Ricci. Mediation of User Models for Enhanced Personalization in Recommender Systems. User Modeling and User-Adapted Interaction, 2008.", "Francesco Ricci, Lior Rokach, Bracha Shapira. Introduction to Recommender Systems Handbook, chapter 1, pages 1--35. Springer, 2011.", "ISO/IEC 21000-2:2005. Information technology -- Multimedia framework (MPEG-21) --Part 2: Digital Item Declaration, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2851613.2851920"}, {"title": "Statistical Significance, Power, and Sample Sizes: A Systematic Review of SIGIR and TOIS, 2006-2015", "authors": ["Tetsuya Sakai"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe conducted a systematic review of 840 SIGIR full papers and 215 TOIS papers published between 2006 and 2015. The original objective of the study was to identify IR effectiveness experiments that are seriously underpowered (i.e., the sample size is far too small so that the probability of missing a real difference is extremely high) or overpowered (i.e., the sample size is so large that a difference will be considered statistically significant even if the actual effect size is extremely small). However, it quickly became clear to us that many IR effectiveness papers either lack significance testing or fail to report p-values and/or test statistics, which prevents us from conducting power analysis. Hence we first report on how IR researchers (fail to) report on significance test results, what types of tests they use, and how the reporting practices may have changed over the last decade. From those papers that reported enough information for us to conduct power analysis, we identify extremely overpowered and underpowered experiments, as well as appropriate sample sizes for future experiments. The raw results of our systematic survey of 1,055 papers and our R scripts for power analysis are available online. Our hope is that this study will help improve the reporting practices and experimental designs of future IR effectiveness studies.", "references": ["T. G. Armstrong, A. Moffat, W. Webber, and J. Zobel. Improvements that don't add up: Ad-hoc retrieval results since 1998. In Proceedings of ACM CIKM 2009, pages 601--610, 2009.", "F. Baskaya, H. Keskustalo, and K. Jarvelin. Time drives interaction: Simulating sessions in diverse searching environments. In Proceedings of ACM SIGIR 2012, pages 105--114, 2012.", "B. Carterette. Bayesian inference for information retrieval evaluation. In Proceedings of ACM ICTIR 2015, pages 31--40, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911492"}, {"title": "The Influence of Frequency, Recency and Semantic Context on the Reuse of Tags in Social Tagging Systems", "authors": ["Dominik Kowald\n,", "Elisabeth Lex"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nIn this paper, we study factors that influence tag reuse behavior in social tagging systems. Our work is guided by the activation equation of the cognitive model ACT-R, which states that the usefulness of information in human memory depends on the three factors usage frequency, recency and semantic context. It is our aim to shed light on the influence of these factors on tag reuse. In our experiments, we utilize six datasets from the social tagging systems Flickr, CiteULike, BibSonomy, Delicious, LastFM and MovieLens, covering a range of various tagging settings. Our results confirm that frequency, recency and semantic context positively influence the reuse probability of tags. However, the extent to which each factor individually influences tag reuse strongly depends on the type of folksonomy present in a social tagging system. Our work can serve as guideline for researchers and developers of tag-based recommender systems when designing algorithms for social tagging environments.", "references": ["J. R. Anderson, D. Bothell, M. D. Byrne, S. Douglass, C. Lebiere, and Y. Qin. An integrated theory of the mind. Psychological review, 111(4):1036, 2004.", "J. R. Anderson and L. J. Schooler. Reflections of the environment in memory. Psychological science, 2(6):396--408, 1991.", "C. Cattuto, V. Loreto, and L. Pietronero. Semiotic dynamics and collaborative tagging. Proceedings of the National Academy of Sciences, 104(5):1461--1464, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914617"}, {"title": "Survey on Keyword Search over XML Documents", "authors": ["Thuy Ngoc Le\n,", "Tok Wang Ling"], "publication": "ACM SIGMOD Record", "abstract": "Abstract\nSince XML has become a standard for information exchange over the Internet, more and more data are represented as XML. XML keyword search has been attracted a lot of interests because it provides a simple and user-friendly interface to query XML documents. This paper provides a survey on keyword search over XML document. We mainly focus on the topics of defining semantics for XML keyword search and the corresponding algorithms to find answers based on these semantics. We classify existing works for XML keyword search into three main types, which are tree-based approaches, graph-based approaches and semantics-based approaches. For each type of approaches, we further classify works into sub-classes and especially we summarize, make comparison and point out the relationships among sub-classes. In addition, for each type of approach, we point out the common problems they suffer", "references": ["Z. Bao, T. W. Ling, B. Chen, and J. Lu. Efficient XML keyword search with relevance oriented ranking. In ICDE, 2009.", "G. Bhalotia, A. Hulgeri, C. Nakhe, S. Chakrabarti, and S. Sudarshan. Keyword searching and browsing in databases using BANKS. In ICDE, 2002.", "J. Camacho-Rodriguez, D. Colazzo, and I. Manolescu. Building large XML stores in the amazon cloud. In ICDEW, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3022860.3022863"}, {"title": "The Language of Deceivers: Linguistic Features of Crowdfunding Scams", "authors": ["Wafa Shafqat\n,", "Seunghun Lee\n,", "Sehrish Malik\n,", "Hyun-chul Kim"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nCrowdfunding sites with recent explosive growth are equally attractive platforms for swindlers or scammers. Though the growing number of articles on crowdfunding scams indicate that the fraud threats are accelerating, there has been little knowledge on the scamming practices and patterns. The key contribution of this research is to discover the hidden clues in the text by exploring linguistic features to distinguish scam campaigns from non-scams. Our results indicate that by providing less information and writing more carefully (and less informally), scammers deliberately try to deceive people; (i) they use less number of words, verbs, and sentences in their campaign pages. (ii) scammers make less typographical errors, 4.5-4.7 times lower than non-scammers.(iii) Expressivity of scams is 2.6-8.5 times lower as well.", "references": ["T. H. Ho. Social purpose corporations: The next targets for greenwashing practices and crowdfunding scams. Seattle J. Soc. Just., 13:935--1015, 2015.", "C. L. Toma and J. T. Hancock. Reading between the lines: linguistic cues to deception in online dating profiles. In ACM CSCW, pages 5--8, 2010.", "L. Zhou, J. K. Burgoon, J. F. Nunamaker, and D. Twitchell. Automating linguistics-based cues for detecting deception in text-based asynchronous computer-mediated communications. Group decision and negotiation, 13(1):81--106, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889356"}, {"title": "Session details: Main Track - People Management in IS", "authors": ["Claudia Cappelli\n,", "Raul Sidnei Wazlawick\n,", "Frank Siqueira\n,", "Patricia Vilain"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3255982"}, {"title": "Report on the WebQuality 2015 Workshop", "authors": ["Radoslaw Nielek\n,", "Adam Wierzbicki\n,", "Adam Jatowt\n,", "Katsumi Tanaka"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThe 5th International Workshop on Web Quality (WebQuality 2015) was held in conjunction with the 24rd International World Wide Web Conference in Florence, Italy on the 18th May 2015. This report briefly summarizes the workshop.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964797.2964809"}, {"title": "A Searching Method for Bichromatic Reverse k-Nearest Neighbor with Network Voronoi Diagram", "authors": ["Yusuke Gotoh\n,", "Chiori Okubo"], "publication": "MoMM '16: Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media", "abstract": "ABSTRACT\nDue to the recent popularization of Geographic Information System (GIS), spatial network environments that can display the changes of spatial axes in mobile phones have received much attention. Many searching methods have proposed reverse k-nearest neighbor (RkNN) searching methods that consider the inverse direction with the position between the query and target objects. In this paper, we propose and evaluate a searching method for a bichromatic reverse k-nearest neighbor (BRkNN) that has objects and queries in spatial networks. In our proposed method, we search for the BRkNN of the query using an influence zone for each object with a Network Voronoi Diagram.", "references": ["D. Taniar, and W. Rahayu, \"A Taxonomy for Nearest Neighbour Queries in Spatial Databases,\" Journal of Computer and System Sciences, vol.79, pp. 1017--1039, 2013.", "M. R. Kolahdouzan, and C. Shahabi, \"Voronoi-Based K Nearest Neighbor Search for Spatial Network Databases,\" The VLDB Journal, vol.30, pp. 840--851, 2004.", "D. Papadias, J. Zhang, N. Mamoulis, and Y. Tao, \"Quary processing in spatial network databases,\" The VLDB Journal, vol.29, pp. 802--813, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3007120.3007133"}, {"title": "Building Realistic Simulations for Interactive Information Retrieval", "authors": ["David Maxwell"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nSimulation has been used within the field of Information Retrieval (IR) for many years to evaluate retrieval models and other aspects of the wider IR process. In recent years, there has been a renewed interest towards using simulation for Interactive Information Retrieval (IIR), an area which focuses on the study of human interactions with IR systems. A variety of different interaction models (e.g. click models) associated with behavioural aspects of searchers have over time been developed and evaluated using simulation in order for us to better understand the complex processes involved. Despite these advances, such models are still relatively naïve, and further work is required to make simulations of searchers more realistic. To this end, this project seeks to build more realistic simulations, using a more Complex Searcher Model (CSM). Within the CSM, each component and decision point can be varied and customised as required. The CSM can then be instantiated using components that are grounded from empirical evidence based upon actual real-world searcher behaviour and interaction data.", "references": ["L. Azzopardi. The economics in interactive information retrieval. In Proc. 34th ACM SIGIR, pages 15--24, 2011.", "L. Azzopardi. Modelling interaction with economic models of search. In Proc. 37th ACM SIGIR, pages 3--12, 2014.", "L. Azzopardi, K. Järvelin, J. Kamps, and M.D. Smucker. Report on the sigir 2010 workshop on the simulation of interaction. SIGIR Forum, 44 (2): 35--47, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854950"}, {"title": "Comparative Evaluation of Various Indexing Techniques of Geospatial Vector Data for Processing in Distributed Computing Environment", "authors": ["Abdul Jhummarwala\n,", "Mazin Alkathiri\n,", "Miren Karamta\n,", "M. B. Potdar"], "publication": "COMPUTE '16: Proceedings of the 9th Annual ACM India Conference", "abstract": "ABSTRACT\nThe explosion of ever increasing geospatial data is today met with the challenge of maintaining it in spatial databases and utilization of traditional methods of spatial data processing. The sheer volume and complexity of spatial databases makes them an ideal candidate for use with parallel and distributed processing architectures. There is a lot of enthusiasm toward using MapReduce paradigm and distributed computing for processing of large volumes of vector data. As spatial data cannot be indexed using traditional B-tree structures used by R/DBMS, several libraries such as JSI (Java Spatial Index), libspatialindex and SpatiaLite depend upon advanced data structures such as R/R*-tree, Quad-tree and their variants for spatial indexing. These indexing mechanisms have also been natively incorporated in frameworks such as Spatial Hadoop, Hadoop GIS SATO and GeoSpark. Additionally, most widely used open source RDBMS such as MySQL, Postgres and SQLite incorporate spatial indexing using extensions/add-ons. In this paper, we benchmark and compare the performance of various spatial indexing mechanisms in addition to evaluating the performance of distributed frameworks for planet sized datasets. We conclude by highlighting the characteristics of spatial tools and frameworks for better selection and implementation of R-tree indexing in a big geo-spatial processing system.", "references": ["Jhummarwala, A., Potdar, M.B. and Chauhan, P. 2014. Parallel and Distributed GIS for Processing Geo-data: An Overview. International Journal of Computer Applications, 106(16), 9--16, (Nov. 2014). DOI= http://doi.acm.org/10.5120/18602-9881.", "The Earth Observing System Data and Information System (EOSDIS): 2016, Retrieved July 10, 2016 from BISAG: https://earthdata.nasa.gov/about.", "Planet OSM: 2016, Retrieved July 10, 2016 from BISAG: http://planet.openstreetmap.org/planet/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2998476.2998493"}, {"title": "High performance top-k processing of non-linear windows over data streams", "authors": ["Abderrahmen Kammoun\n,", "Syed Gillani\n,", "Christophe Gravier\n,", "Julien Subercaze"], "publication": "DEBS '16: Proceedings of the 10th ACM International Conference on Distributed and Event-based Systems", "abstract": "ABSTRACT\nThis year's DEBS Grand Challenge offers two very challenging queries over social networks data. These queries -- each for a different reason -- cannot be handled by traditional techniques and therefore call for the development of a specific architecture and data structures.\nIn the first query, the novelty is the non-linearity of the expiration of the elements. Since a traditional sliding window is not suitable, we investigate here the data structures offering the best tradeoffs for all the required operations.\nIn the second query, unlike traditional approaches where no persistent data is stored over the stream, we have to manage a friendship graph which is persistent throughout the system execution. Due to the centrality of this structure, a careful design is therefore required.\nThe common point of the algorithmic approaches that we developed for both queries, is the overwhelming usage of bounds -- upper and lower --, in order execute expensive computations only when required. We devise, for the Query 1, a bound based on the score decay. For the Query 2, we use Turan's theorem to limit the clique computation. The combination of lazy evaluation, careful implementation and thorough testing lead to the realization of an efficient streaming process system.", "references": ["S. Chambi, D. Lemire, O. Kaser, and R. Godin. Better bitmap performance with roaring bitmaps. Software: Practice and Experience, 2015.", "J. Chevalier, J. Subercaze, C. Gravier, and F. Laforest. Slider: an efficient incremental reasoner. In SIGMOD, pages 1081--1086. ACM, 2015.", "J. Giacomoni, T. Moseley, and M. Vachharajani. Fastforward for efficient pipeline parallelism: a cache-optimized concurrent lock-free queue. In SIGPLAN, pages 43--52. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2933267.2933507"}, {"title": "Generating responsive web pages using SuperSQL", "authors": ["Ryosuke Koshijima\n,", "Kento Goto\n,", "Motomichi Toyama"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nWith the rapid spread of smartphones and tablets, it is becoming necessary for web developers to create responsive web pages which are visually appealing on devices of various sizes. However, building responsive UIs is a very challenging task, requiring deep knowledge of HTML and CSS. In this paper, we propose an approach to generate responsive web pages using SuperSQL, which is an extension of SQL that can format data retrieved from a database into various kinds of structured documents. Our approach applies the methodology of Bootstrap, a grid-based framework for front-end development, to generate responsive web pages from SuperSQL queries. By combining SuperSQL's capability of expressing complex layout structure with the systematic use of Bootstrap, we aim to establish an uncomplicated method of developing responsive web pages that do not require expertise in front-end web development.", "references": ["\"Bootstrap - The world's most popular mobile-first and responsive front-end framework..\" http://getbootstrap.com/.", "\"Foundation | The most advanced responsive front-end framework in the world..\" http://foundation.zurb.com/.", "M. Toyama, \"Supersql: An extended sql for database publishing and presentation,\" in Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data, SIGMOD '98, (New York, NY, USA), pp. 584--586, ACM, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011162"}, {"title": "Health Information Seeking Behavior among College Students: A case in a Developing Country", "authors": ["Tesfahun Melese Yilma"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nLiterature on Health Information Seeking Behavior (HISB) are available and well documented in developed countries. People in developed countries have also better understanding and awareness on online health information sources. However, the research coverage is very limited in developing countries, especially among college students. Previous studies showed higher risks of chronic diseases, stress, and risky sexual behavior among college students. Improving their HISB has the potential to reduce these risks. Our proposed research attempts to describe HISB and its associated factors in developing country with a specific focus on a college student population. Our study will attempt to create a better understanding of HISB in developing country thereby making it available for health promotional activities. It will also have potential contribution to suggest design strategies to improve health information retrieval systems.", "references": ["Allen, S., Geiger, B.F., Howard, V.J., Ivankova, N.V., Martin, M.Y., O'neal, M., and Safford, M.M., 2013. Development and validation of a survey instrument to assess health information-seeking behaviors among African American young professionals. In Health Education/Promotion (Education) University of Alabama at Birmingham, Birmingham, 303.", "Anker, A.E., Reinhart, A.M., and Feeley, T.H., 2011. Health information seeking: a review of measures and methods. Patient Educ Couns 82, 3 (Mar), 346--354. DOI= http://dx.doi.org/10.1016/j.pec.2010.12.008.", "Biswas, A., Oh, P.I., Faulkner, G.E., Bajaj, R.R., Silver, M.A., Mitchell, M.S., and Alter, D.A., 2015. Sedentary time and its association with risk for disease incidence, mortality, and hospitalization in adults: a systematic review and meta-analysis. Ann Intern Med 162, 2 (Jan 20), 123--132. DOI= http://dx.doi.org/10.7326/m14--1651."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854947"}, {"title": "Extraction method for Anaba spots based on name recognition and user's evaluation", "authors": ["Daisuke Kitayama"], "publication": "iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services", "abstract": "ABSTRACT\nIn recent years, the importance of information on tourism is increasing because inbound tourists have a beneficial economic effect on regions that attract them. In general, the most popular method of obtaining tourism information is through guidebooks, which often consider only famous sightseeing spots. However, attractive spots are not available only in guidebooks. I consider that finding attractive spots on one's own would satisfy tourists. Therefore, I propose an extraction method for finding attractive Anaba (implying well-kept secret) spots based on users' evaluation and number of visitors. I define Anaba spots because they have low name recognition and high evaluation. In this study, I developed a prototype system by using a photo-sharing site to calculate name recognition and user's evaluation, and evaluated the proposed method.", "references": ["Y. Arase, X. Xie, T. Hara, and S. Nishio. Mining people's trips from large scale geo-tagged photos. In Proceedings of the 18th ACM International Conference on Multimedia, MM '10, pages 133--142, New York, NY, USA, 2010. ACM.", "D. J. Crandall, L. Backstrom, D. Huttenlocher, and J. Kleinberg. Mapping the world's photos. In Proceedings of the 18th International Conference on World Wide Web, WWW '09, pages 761--770, New York, NY, USA, 2009. ACM.", "M. Hirota, M. Shirai, H. Ishikawa, and S. Yokoyama. Detecting relations of hotspots using geo-tagged photographs in social media sites. In Proceedings of Workshop on Managing and Mining Enriched Geo-Spatial Data, GeoRich'14, pages 7:1--7:6, New York, NY, USA, 2007. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3011141.3011197"}, {"title": "Segmentation of Microscopic Medical Images Using Local Binary Patterns Method", "authors": ["Zuzana Loncova\n,", "Libor Hargas\n,", "Dusan Koniar"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nThis paper deals with the problems of segmentation of specific microscopic medical images for diagnostic purposes. The monitored structures are physiologically motile with right frequency and synchronization which is evaluated by analysis of high-speed video sequences containing microscopic samples. It means that the diagnostic of potential pathologies leads to analysis of particular images of the video sequence. Proper recognition of image contents and its division into objects of interests, artifacts and background is a task of image segmentation. There exist a vast range of segmentation methods in the area of image processing, however, the particularity of studied microscopic images and the requirements for precision mean significant difficulties and this opens the space for further research in this field. This paper proposes better and more precise segmentation of images containing respiratory epithelium, using the method of local binary patterns. Such technique focuses on local texture features of an image, which enables the reliable identification of even small and usually not contrast structures -- cilia. The great potential of this approach is in the possibility to identify the static cilia, which could not be recognized by standard frequency analysis of video sequences (due to the fact that they are actually not moving), and so improve the diagnostic of even more serious ciliary pathologies.", "references": ["Javorka, K. 2001. Medical physiology (Lekárska fyziológia), Osveta, Martin, Slovakia. ISBN: 80-8063-023-2.", "Koniar, D., Hargas, L., Fibich, P., Stofan, S. and Hrianka, M. 2010. Design of high speed video acquisition szstem for tissue measurement. In Proceedings of the International Conference on Applied Electronics (AE). (Pilsen, September 08-09, 2010). ISBN 978-80-7043-865-7.", "Burger W., Burge M. J. 2008. Digital Image Processing, 1st ed. Springer, New York. ISBN 978-1-84628-968-2."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015211"}, {"title": "Poster: The Future to Personalize Medicine Is in Your Smart-device", "authors": ["Sabyasachi Mohanty\n,", "Murari Toshniwal\n,", "Tanima Dutta\n,", "Hari Prabhat Gupta"], "publication": "MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion", "abstract": "ABSTRACT\nMost medicine taker may not aware of the details of a drug's brand name and manufacturer, indications, dosage, interactions, and side effects of the medicine. In order to avoid over-prescriptions, to prevent medicinal misuse and side effects of medicine, it is necessary for medicine takers to be provided with the detailed information about the medicine. This can be achieved by personalizing the medicines using smart-devices. In this work, we proposed a personalized medicine system to provide the information about a medicine through automatic text recognition from the imprints of the medicine and transmission using smart-devices. The system is fast enough to display the associated information of the medicine in real-time.", "references": ["T. Dutta. Medical Data Compression and Transmission in Wireless Ad Hoc Networks. IEEE Sensors Journal, 15(2):778--786, 2015.", "T. Dutta, D. Dogra, and B. Jana. Object Extraction Using Novel Region Merging and Multidimensional Features. In Proc. of PSIVT, pages 356--361, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2938559.2948872"}, {"title": "Inferring Social Strength from Spatiotemporal Data", "authors": ["Huy Pham\n,", "Cyrus Shahabi\n,", "Yan Liu"], "publication": "ACM Transactions on Database Systems", "abstract": "Abstract\nThe advent of geolocation technologies has generated unprecedented rich datasets of people’s location information at a very high fidelity. These location datasets can be used to study human behavior; for example, social studies have shown that people who are seen together frequently at the same place and same time are most probably socially related. In this article, we are interested in inferring these social connections by analyzing people’s location information; this is useful in a variety of application domains, from sales and marketing to intelligence analysis. In particular, we propose an entropy-based model (EBM) that not only infers social connections but also estimates the strength of social connections by analyzing people’s co-occurrences in space and time. We examine two independent methods: diversity and weighted frequency, through which co-occurrences contribute to the strength of a social connection. In addition, we take the characteristics of each location into consideration in order to compensate for cases where only limited location information is available. We also study the role of location semantics in improving our computation of social strength. We develop a parallel implementation of our algorithm using MapReduce to create a scalable and efficient solution for online applications. We conducted extensive sets of experiments with real-world datasets including both people’s location data and their social connections, where we used the latter as the ground truth to verify the results of applying our approach to the former. We show that our approach is valid across different networks and outperforms the competitors.", "references": ["Bhuvan Bamba, Ling Liu, Peter Pesti, and Ting Wang. 2008. Supporting anonymous location queries in mobile environments with privacygrid. In Proceedings of the 17th International Conference on World Wide Web. ACM, 237--246.", "Michael Barbaro, Tom Zeller, and Saul Hansell. 2006. A face is exposed for AOL searcher no. 4417749. New York Times 9, 2008 (2006), 8For.", "J. L. Bentley. 1975. Multidimensional binary search trees used for associative searching. Commun. ACM 18, 9 (1975), 509--517."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2877200"}, {"title": "Fast Feature Selection for Learning to Rank", "authors": ["Andrea Gigli\n,", "Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Raffaele Perego"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nAn emerging research area named Learning-to-Rank (LtR) has shown that effective solutions to the ranking problem can leverage machine learning techniques applied to a large set of features capturing the relevance of a candidate document for the user query. Large-scale search systems must however answer user queries very fast, and the computation of the features for candidate documents must comply with strict back-end latency constraints. The number of features cannot thus grow beyond a given limit, and Feature Selection (FS) techniques have to be exploited to find a subset of features that both meets latency requirements and leads to high effectiveness of the trained models. In this paper, we propose three new algorithms for FS specifically designed for the LtR context where hundreds of continuous or categorical features can be involved. We present a comprehensive experimental analysis conducted on publicly available LtR datasets and we show that the proposed strategies outperform a well-known state-of-the-art competitor.", "references": ["A. Agresti. Analysis of Ordinal Categorical Data (Second ed.). 2010.", "S. Baccianella, A. Esuli, and F. Sebastiani. Feature selection for ordinal text classification. Neural computation, 26(3):557--591, 2014.", "G. Capannini, C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, and N. Tonellotto. Quality versus efficiency in document scoring with learning-to-rank models. Information Processing & Management, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970433"}, {"title": "Fusing Social Media Cues: Personality Prediction from Twitter and Instagram", "authors": ["Marcin Skowron\n,", "Marko Tkalčič\n,", "Bruce Ferwerda\n,", "Markus Schedl"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nIncorporating users' personality traits has shown to be instrumental in many personalized retrieval and recommender systems. Analysis of users' digital traces has become an important resource for inferring personality traits. To date, the analysis of users' explicit and latent characteristics is typically restricted to a single social networking site (SNS). In this work, we propose a novel method that integrates text, image, and users' meta features from two different SNSs: Twitter and Instagram. Our preliminary results indicate that the joint analysis of users' simultaneous activities in two popular SNSs seems to lead to a consistent decrease of the prediction errors for each personality trait.", "references": ["F. Celli, E. Bruni, and B. Lepri. Automatic Personality and Interaction Style Recognition from Facebook Profile Pictures. In Proc. ACM Multimedia -MM '14', pages 1101--04. ACM, 2014.", "J. Golbeck, C. Robles, M. Edmondson, and K. Turner. Predicting Personality from Twitter. In Proc. PASSAT and SocialCom, pages 149--156. IEEE, 2011.", "O. P. John, E. M. Donahue, and R. L. Kentle. The big five inventory--versions 4a and 54. UCB, Inst. of Personality and Social Research, Berkeley, CA, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889368"}, {"title": "Diverse and proportional size-l object summaries using pairwise relevance", "authors": ["Georgios J. Fakas\n,", "Zhi Cai\n,", "Nikos Mamoulis"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe abundance and ubiquity of graphs (e.g., online social networks such as Google$$+$$+ and Facebook; bibliographic graphs such as DBLP) necessitates the effective and efficient search over them. Given a set of keywords that can identify a data subject (DS), a recently proposed keyword search paradigm produces a set of object summaries (OSs) as results. An OS is a tree structure rooted at the DS node (i.e., a node containing the keywords) with surrounding nodes that summarize all data held on the graph about the DS. OS snippets, denoted as size-l OSs, have also been investigated. A size-l OS is a partial OS containing l nodes such that the summation of their importance scores results in the maximum possible total score. However, the set of nodes that maximize the total importance score may result in an uninformative size-l OSs, as very important nodes may be repeated in it, dominating other representative information. In view of this limitation, in this paper, we investigate the effective and efficient generation of two novel types of OS snippets, i.e., diverse and proportional size-l OSs, denoted as DSize-l and PSize-l OSs. Namely, besides the importance of each node, we also consider its pairwise relevance (similarity) to the other nodes in the OS and the snippet. We conduct an extensive evaluation on two real graphs (DBLP and Google$$+$$+). We verify effectiveness by collecting user feedback, e.g., by asking DBLP authors (i.e., the DSs themselves) to evaluate our results. In addition, we verify the efficiency of our algorithms and evaluate the quality of the snippets that they produce.", "references": ["Agrawal, R., Gollapudi, S., Halverson, A., Ieong, S.: Diversifying search results. In: WSDM, pp. 5---14 (2009)", "Albert, A., Koudas, N.: Efficient diversity-aware search. In: SIGMOD, pp. 781---792 (2011)", "Balmin, A., Hristidis, V., Papakonstantinou, Y.: Objectrank: authority-based keyword search in databases. In: VLDB, pp. 564---575 (2004)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0433-6"}, {"title": "vitrivr: A Flexible Retrieval Stack Supporting Multiple Query Modes for Searching in Multimedia Collections", "authors": ["Luca Rossetto\n,", "Ivan Giangreco\n,", "Claudiu Tanase\n,", "Heiko Schuldt"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nvitrivr is an open source full-stack content-based multimedia retrieval system with focus on video. Unlike the majority of the existing multimedia search solutions, vitrivr is not limited to searching in metadata, but also provides content-based search and thus offers a large variety of different query modes which can be seamlessly combined: Query by sketch, which allows the user to draw a sketch of a query image and/or sketch motion paths, Query by example, keyword search, and relevance feedback. The vitrivr architecture is self-contained and addresses all aspects of multimedia search, from offline feature extraction, database management to frontend user interaction. The system is composed of three modules: a web-based frontend which allows the user to input the query (e.g., add a sketch) and browse the retrieved results (vitrivr-ui), a database system designed for interactive search in large-scale multimedia collections (ADAM), and a retrieval engine that handles feature extraction and feature-based retrieval (Cineast). The vitrivr source is available on GitHub under the MIT open source (and similar) licenses and is currently undergoing several upgrades as part of the Google Summer of Code 2016.", "references": ["S.-F. Chang, W. Chen, and H. Sundaram. VideoQ: A Fully Automated Video Retrieval System Using Motion Sketches. In Proc. Int. Workshop on Applications of Computer Vision, WACV 1998, pages 270--271, 1998.", "M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, B. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkovic, et al. Query by Image and Video Content: The QBIC system. IEEE Computer, 28(9):23--32, 1995.", "I. Giangreco, I. Al Kabary, and H. Schuldt. ADAM -- A Database and Information Retrieval System for Big Multimedia Collections. In Proc. Int. Congress on Big Data (BigData Congress), pages 406--413, Anchorage, USA, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2973797"}, {"title": "Clustering Algorithms for Intrusion Detection: A Broad Visualization", "authors": ["K. S. Anil Kumar\n,", "Anitha Mary M. O. Chacko"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nAn intrusion detection system is an intelligent system developed to identify and counteract intrusive efforts. Clustering algorithms are used in intrusion detection systems for separating normal activities from abnormal activities. The selection of an efficient clustering technique is a highly challenging job. This article analyzes the different clustering techniques that can be used in the preprocessing stage of intrusion detection systems. This paper compares the performances of three clustering techniques on DARPA dataset- K-means clustering, K-medoid clustering and Improved K-means clustering technique with optimum cluster centroid initialization algorithm. The best recognition results with an accuracy of 98.58% was achieved using the Improved K-means algorithm.", "references": ["Sahu, S. Kumar, S. Sarangi, and S. K. Jena. A detail analysis on intrusion detection datasets. Advance Computing Conference (IACC), 2014 IEEE International, 2014.", "Denning D. (1987) \"An Intrusion-Detection Model,\" IEEE Transactions on Software Engineering, Vol. SE-13, No. 2, pp. 222--232", "Kumar S., Spafford E. H. (1994) \"An Application of Pattern Matching in Intrusion Detection,\" Technical Report CSD-TR-94-013. Purdue University."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905195"}, {"title": "Recommendations in Signed Social Networks", "authors": ["Jiliang Tang\n,", "Charu Aggarwal\n,", "Huan Liu"], "publication": "WWW '16: Proceedings of the 25th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecommender systems play a crucial role in mitigating the information overload problem in social media by suggesting relevant information to users. The popularity of pervasively available social activities for social media users has encouraged a large body of literature on exploiting social networks for recommendation. The vast majority of these systems focus on unsigned social networks (or social networks with only positive links), while little work exists for signed social networks (or social networks with positive and negative links). The availability of negative links in signed social networks presents both challenges and opportunities in the recommendation process. We provide a principled and mathematical approach to exploit signed social networks for recommendation, and propose a model, RecSSN, to leverage positive and negative links in signed social networks. Empirical results on real-world datasets demonstrate the effectiveness of the proposed framework. We also perform further experiments to explicitly understand the effect of signed networks in RecSSN.", "references": ["K.-Y. Chiang, N. Natarajan, A. Tewari, and I. S. Dhillon. Exploiting longer cycles for link prediction in signed networks. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1157--1162. ACM, 2011.", "J. Cho. The mechanism of trust and distrust formation and their relational outcomes. Journal of Retailing, 82(1):25--35, 2006.", "J. Golbeck. Generating predictive movie recommendations from trust in social networks. Trust Management, pages 93--104, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872427.2882971"}, {"title": "A General Linear Mixed Models Approach to Study System Component Effects", "authors": ["Nicola Ferro\n,", "Gianmaria Silvello"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTopic variance has a greater effect on performances than system variance but it cannot be controlled by system developers who can only try to cope with it. On the other hand, system variance is important on its own, since it is what system developers may affect directly by changing system components and it determines the differences among systems. In this paper, we face the problem of studying system variance in order to better understand how much system components contribute to overall performances. To this end, we propose a methodology based on General Linear Mixed Model (GLMM) to develop statistical models able to isolate system variance, component effects as well as their interaction by relying on a Grid of Points (GoP) containing all the combinations of analysed components. We apply the proposed methodology to the analysis of TREC Ad-hoc data in order to show how it works and discuss some interesting outcomes of this new kind of analysis. Finally, we extend the analysis to different evaluation measures, showing how they impact on the sources of variance.", "references": ["D. Banks, P. Over, and N.-F. Zhang. Blind Men and Elephants: Six Approaches to TREC data. Information Retrieval, 1:7--34, May 1999.", "L. Boytsov, A. Belova, and P. Westfall. Deciding on an Adjustment for Multiplicity in IR Experiments. In SIGIR 2013, pp. 403--412, 2013.", "S. Büttcher, C. L. A. Clarke, and G. V. Cormack. Information Retrieval: Implementing and Evaluating Search Engines. The MIT Press, USA, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911530"}, {"title": "The Data Stack in Information Retrieval", "authors": ["Omar Alonso"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nI propose to look at information retrieval applications from the perspective of the data stack infrastructure that is needed in research prototypes and production systems.", "references": ["Daniel Abadi et al. \"The Beckman Report on Database Research\", Comm. of the ACM, 59(2), pp. 92--99, 2016.", "James Allan, W. Bruce Croft, Alistair Moffat, and Mark Sanderson. \"Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne\". SIGIR Forum, 46(1):2--32, 2012.", "Tony Hey, Stewart Tansley, and Kristin Tolle (Eds.). The Fourth Paradigm, Microsoft Research, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2926726"}, {"title": "Boosting Titles does not Generally Improve Retrieval Effectiveness", "authors": ["Jimmy\n,", "Guido Zuccon\n,", "Bevan Koopman"], "publication": "ADCS '16: Proceedings of the 21st Australasian Document Computing Symposium", "abstract": "ABSTRACT\nThe fields that compose structured documents such as web pages have been exploited to improve the effectiveness of information retrieval systems. Field-based retrieval methods assign different levels of importance (weights) to different fields, e.g., by boosting the score of a document when query terms are found in a specific field. An important question is how to decide which field should be boosted? It has been speculated that the title field should receive a higher weight. In this paper, we investigate whether boosting the title field of structured documents actually does improve retrieval effectiveness. Our results show that, on average, boosting titles does not improve retrieval effectiveness for field-based retrieval; this is both for ad-hoc web search and exploratory-based web search tasks. However, we do find that the boosting of titles does generally improve retrieval effectiveness for navigational queries and a small subset of ad-hoc queries. This result advocates for adaptive methods that selectively adjust boosting of specific fields based on the query.", "references": ["J. Allan. HARD Track Overview in TREC 2005 High Accuracy Retrieval from Documents. In Proceedings of TREC 2005, 2005.", "C. L. A. Clarke, E. Agichtein, S. Dumais, and R. W. White. The Influence of Caption Features on Clickthrough Patterns in Web Search. In Proceedings of ACM SIGIR 2007, pages 135--142, New York, NY, USA, 2007. ACM.", "K. Collins-Thompson, C. Macdonald, P. Bennett, F. Diaz, and E. M. Voorhees. TREC 2014 web track overview. In Proceedings of TREC 2014, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015022.3015028"}, {"title": "Multi-Rate Deep Learning for Temporal Recommendation", "authors": ["Yang Song\n,", "Ali Mamdouh Elkahky\n,", "Xiaodong He"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModeling temporal behavior in recommendation systems is an important and challenging problem. Its challenges come from the fact that temporal modeling increases the cost of parameter estimation and inference, while requiring large amount of data to reliably learn the model with the additional time dimensions. Therefore, it is often difficult to model temporal behavior in large-scale real-world recommendation systems. In this work, we propose a novel deep neural network based architecture that models the combination of long-term static and short-term temporal user preferences to improve the recommendation performance. To train the model efficiently for large-scale applications, we propose a novel pre-train method to reduce the number of free parameters significantly. The resulted model is applied to a real-world data set from a commercial News recommendation system. We compare to a set of established baselines and the experimental results show that our method outperforms the state-of-the-art significantly.", "references": ["Recurrent neural networks for collaborative filtering. http://erikbern.com/2014/06/28/recurrent-neural-networks-for-collaborative-filtering/. Accessed: 2016-01-18.", "L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In Workshop on (CARS09), 2009.", "N. Bell and M. Garland. Implementing sparse matrix-vector multiplication on throughput-oriented processors. In Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis, page 18. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914726"}, {"title": "Text Categorization", "authors": ["ChengXiang Zhai\n,", "Sean Massung"], "publication": "Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining", "abstract": "ABSTRACT\nRecent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media (such as blog articles, forum posts, product reviews, and tweets). This has led to an increasing demand for powerful software tools to help people manage and analyze vast amounts of text data effectively and efficiently. Unlike data generated by a computer system or sensors, text data are usually generated directly by humans, and capture semantically rich content. As such, text data are especially valuable for discovering knowledge about human opinions and preferences, in addition to many other kinds of knowledge that we encode in text. In contrast to structured data, which conform to well-defined schemas (thus are relatively easy for computers to handle), text has less explicit structure, requiring computer processing toward understanding of the content encoded in text. The current technology of natural language processing has not yet reached a point to enable a computer to precisely understand natural language text, but a wide range of statistical and heuristic approaches to management and analysis of text data have been developed over the past few decades. They are usually very robust and can be applied to analyze and manage text data in any natural language, and about any topic.\nThis book provides a systematic introduction to many of these approaches, with an emphasis on covering the most useful knowledge and skills required to build a variety of practically useful text information systems. Because humans can understand natural languages far better than computers can, effective involvement of humans in a text information system is generally needed and text information systems often serve as intelligent assistants for humans. Depending on how a text information system collaborates with humans, we distinguish two kinds of text information systems. The first is information retrieval systems which include search engines and recommender systems; they assist users in finding from a large collection of text data the most relevant text data that are actually needed for solving a specific application problem, thus effecively turning big raw text data into much smaller relevant text data that can be more easily processed by humans. The second is text mining application systems; they can assist users in analyzing patterns in text data to extract and discover useful actionable knowledge directly useful for task completion or decision making, thus providing more direct task support for users. This book covers the major concepts, techniques, and ideas in information retrieval and text data mining from a practical viewpoint, and includes many hands-on exercises designed with a companion software toolkit (i.e., MeTA) to help readers learn how to apply techniques of information retrieval and text mining to real-world text data and how to experiment with and improve some of the algorithms for interesting application tasks. This book can be used as a textbook for computer science undergraduates and graduates, library and information scientists, or as a reference book for practitioners working on relevant problems in managing and analyzing text data.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2915031.2915047"}, {"title": "Cross-system Recommendation: User-modelling via Social Media versus Self-Declared Preferences", "authors": ["Sultan Alanazi\n,", "James Goulding\n,", "Derek McAuley"], "publication": "HT '16: Proceedings of the 27th ACM Conference on Hypertext and Social Media", "abstract": "ABSTRACT\nIt is increasingly rare to encounter a Web service that doesn't engage in some form of automated recommendation, with Collaborative Filtering (CF) techniques being virtually ubiquitous as the means for delivering relevant content. Yet several key issues still remain unresolved, including optimal handling of cold starts and how best to maintain user-privacy within that context. Recent work has demonstrated a potentially fruitful line of attack in the form of cross-system user modelling, which uses features generated from one domain to bootstrap recommendations in another. In this paper we evidence the effectiveness of this approach through direct real-world user feedback, deconstructing a cross-system news recommendation service where user models are generated via social media data. It is shown that even when a relatively naive vector-space approach is used, it is possible to automatically generate user-models that provide statistically superior performance than when items are explicitly filtered based on a user's self-declared preferences. Detailed qualitative analysis of why such effects occur indicate that different models are capturing widely different areas within a user's preference space, and that hybrid models represent fertile ground for future research.", "references": ["F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Twitter-based user modeling for news recommendations. In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 2962--2966. AAAI Press, 2013.", "F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause. Cross-system user modeling and personalization on the social web. User Modeling and User-Adapted Interaction, 23(2):169--209, 2013.", "A. Ahmed, A. Das, and A. J. Smola. Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining, WSDM '14, pages 153--162, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2914586.2914640"}, {"title": "Multimodal-based Multimedia Analysis, Retrieval, and Services in Support of Social Media Applications", "authors": ["Rajiv Ratn Shah"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe rapid growth in the amount of user-generated content (UGCs) online necessitates for social media companies to automatically extract knowledge structures (concepts) from user-generated images (UGIs) and user-generated videos (UGVs) to provide diverse multimedia-related services. For instance, recommending preference-aware multimedia content, the understanding of semantics and sentics from UGCs, and automatically computing tag relevance for UGIs are benefited from knowledge structures extracted from multiple modalities. Since contextual information captured by modern devices in conjunction with a media item greatly helps in its understanding, we leverage both multimedia content and contextual information (eg., spatial and temporal metadata) to address above-mentioned social media problems in our doctoral research. We present our approaches, results, and works in progress on these problems.", "references": ["Apache Lucene. https://lucene.apache.org/core/, April 2016. Java API: Last Accessed April, 2016.", "FourSquare. https://developer.foursquare.com/, March 2016. API: Last Accessed March, 2016.", "B. Agarwal, S. Poria, N. Mittal, A. Gelbukh, and A. Hussain. Concept-level Sentiment Analysis with Dependency-based Semantic Parsing: A Novel Approach. In Springer Cognitive Computation, pages 1--13, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2971471"}, {"title": "Smartphone App Categorization for Interest Targeting in Advertising Marketplace", "authors": ["Vladan Radosavljevic\n,", "Mihajlo Grbovic\n,", "Nemanja Djuric\n,", "Narayan Bhamidipati\n,", "Daneo Zhang\n,", "Jack Wang\n,", "Jiankai Dang\n,", "Haiying Huang\n,"], "publication": "WWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide Web", "abstract": "ABSTRACT\nLast decade has witnessed a tremendous expansion of mobile devices, which brought an unprecedented opportunity to reach a large number of mobile users at any point in time. This resulted in a surge of interest of mobile operators and ad publishers to understand usage patterns of mobile apps and allow more relevant content recommendations. Due to a large input space, a critical step in understanding app usage patterns is reducing sparseness by classifying apps into predefined interest taxonomies. However, besides short name and noisy description majority of apps have very limited information available, which makes classification a challenging task. We address this issue and present a novel method to classify apps into interest categories by: 1) embedding apps into low-dimensional space using a neural language model applied on smartphone logs; and 2) applying k-nearest-neighbors classification in the embedding space. To validate the method we run experiments on more than one billion device logs covering hundreds of thousands of apps. To the best of our knowledge this is the first app categorization study at this scale. Empirical results show that the proposed method outperforms the current state-of-the-art.", "references": ["G. Berardi, A. Esuli, T. Fagni, and F. Sebastiani. Multi-store metadata-based supervised mobile app classification. In Proceedings of the 30th Annual ACM Symposium on Applied Computing, Salamanca, Spain, April 13-17, 2015, pages 585--588, 2015.", "N. Djuric, H. Wu, V. Radosavljevic, M. Grbovic, and N. Bhamidipati. Hierarchical neural language models for joint representation of streaming documents and their content. In International World Wide Web Conference (WWW), 2015.", "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS, pages 3111--3119, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2872518.2889411"}, {"title": "Learning to Rank User Queries to Detect Search Tasks", "authors": ["Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Gabriele Tolomei"], "publication": "ICTIR '16: Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval", "abstract": "ABSTRACT\nWe present a framework for discovering sets of web queries having similar latent needs, called search tasks, from user queries stored in a search engine log. The framework is made of two main modules: Query Similarity Learning (QSL) and Graph-based Query Clustering (GQC). The former is devoted to learning a query similarity function from a ground truth of manually-labeled search tasks. The latter represents each user search log as a graph whose nodes are queries, and uses the learned similarity function to weight edges between query pairs. Finally, search tasks are detected by clustering those queries in the graph which are connected by the strongest links, in fact by detecting the strongest connected components of the graph. To discriminate between \"strong\" and \"weak\" links also the GQC module entails a learning phase whose goal is to estimate the best threshold for pruning the edges of the graph. We discuss how the QSL module can be effectively implemented using Learning to Rank (L2R) techniques. Experiments on a real-world search engine log show that query similarity functions learned using L2R lead to better performing GQC implementations when compared to similarity functions induced by other state-of-the-art machine learning solutions, such as logistic regression and decision trees.", "references": ["P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, and S. Vigna. The query-flow graph: model and applications. In CIKM'08, pages 609--618. ACM, 2008.", "A. Broder. A taxonomy of web search. SIGIR Forum, 36:3--10, September 2002.", "G. Capannini, C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, and N. Tonellotto. Quality versus efficiency in document scoring with learning-to-rank models. Information Processing & Management, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2970398.2970407"}, {"title": "Performance Based Analysis of Novel Equilin Clustering", "authors": ["A. Joy Christy\n,", "S. Hari Ganesh"], "publication": "ICTCS '16: Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies", "abstract": "ABSTRACT\nMost of the clustering algorithms are difficult to be applied extensively in high computational complexity oriented applications because of the complexities involved in conceptualizing the existing algorithms. Moreover, the inconsistencies in the performance of the traditional algorithms over unfair data make them more complicated to be relied upon. Hence, the present system still wanted off for the invention of newer algorithms to overcome the limitations of the existing ones. In this paper, an investigation is made to ensure that the equation of geographical shapes can be extensively applied for clustering similar data. To the proof of concept we have proposed a novel Equilin clustering algorithm for clustering similar data using the standard linear equation with the statistical mean approach. This paper also evaluates the performance of the proposed algorithm with several datasets to demonstrate its efficacy. The results show that the Equlin clustering is faster and able to provide better cluster results than the traditional algorithms.", "references": ["Jain, A.K. and Dubes, R.C., 1988. Algorithms for clustering data. Prentice-Hall, Inc.. Vancouver", "Jain, A.K., Murty, M.N. and Flynn, P.J., 1999. Data clustering: a review. ACM computing surveys (CSUR), 31(3), pp. 264--323.", "Freitas, A.A., 2008. A review of evolutionary algorithms for data mining. In Soft Computing for Knowledge Discovery and Data Mining Springer US. pp. 79--111."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2905055.2905112"}, {"title": "Audio Features Affected by Music Expressiveness: Experimental Setup and Preliminary Results on Tuba Players", "authors": ["Alberto Introini\n,", "Giorgio Presti\n,", "Giuseppe Boccignone"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWithin a Music Information Retrieval perspective, the goal of the study presented here is to investigate the impact on sound features of the musician's affective intention, namely when trying to intentionally convey emotional contents via expressiveness. A preliminary experiment has been performed involving 10 tuba players. The recordings have been analysed by extracting a variety of features, which have been subsequently evaluated by combining both classic and machine learning statistical techniques. Results are reported and discussed.", "references": ["M. Barthet, G. Fazekas, and M. Sandler. Multidisciplinary perspectives on music emotion recognition: Implications for content and context-based models. In Proc. Int. Symp. Comp. Music Modeling and Retrieval (CMMR), pages 492--507, 2012.", "C. M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.", "M. Budd et al. Music and the emotions: The philosophical theories. Routledge, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914690"}, {"title": "Learning Points and Routes to Recommend Trajectories", "authors": ["Dawei Chen\n,", "Cheng Soon Ong\n,", "Lexing Xie"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe problem of recommending tours to travellers is an important and broadly studied area. Suggested solutions include various approaches of points-of-interest (POI) recommendation and route planning. We consider the task of recommending a sequence of POIs, that simultaneously uses information about POIs and routes. Our approach unifies the treatment of various sources of information by representing them as features in machine learning algorithms, enabling us to learn from past behaviour. Information about POIs are used to learn a POI ranking model that accounts for the start and end points of tours. Data about previous trajectories are used for learning transition patterns between POIs that enable us to recommend probable routes. In addition, a probabilistic model is proposed to combine the results of POI ranking and the POI to POI transitions. We propose a new F1 score on pairs of POIs that capture the order of visits. Empirical results show that our approach improves on recent methods, and demonstrate that combining points and routes enables better trajectory recommendations.", "references": ["J. Bao, Y. Zheng, D. Wilkie, and M. Mokbel. Recommendations in location-based social networks: a survey. GeoInformatica, 19(3):525--565, 2015.", "R. Baraglia, C. I. Muntean, F. M. Nardini, and F. Silvestri. LearNext: learning to predict tourists movements. CIKM '13, pages 751--756. ACM, 2013.", "C. Chen, D. Zhang, B. Guo, X. Ma, G. Pan, and Z. Wu. TripPlanner: Personalized trip planning leveraging heterogeneous crowdsourced digital footprints. IEEE Transactions on Intelligent Transportation Systems, 16(3):1259--1273, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983672"}, {"title": "Looking Good With Flickr Faves: Gaussian Processes for Finding Difference Makers in Personality Impressions", "authors": ["Xiaoyu Xiong\n,", "Maurizio Filippone\n,", "Alessandro Vinciarelli"], "publication": "MM '16: Proceedings of the 24th ACM international conference on Multimedia", "abstract": "ABSTRACT\nFlickr allows its users to generate galleries of \"faves\", i.e., pictures that they have tagged as favourite. According to recent studies, the faves are predictive of the personality traits that people attribute to Flickr users. This article investigates the phenomenon and shows that faves allow one to predict whether a Flickr user is perceived to be above median or not with respect to each of the Big-Five Traits (accuracy up to 79\\% depending on the trait). The classifier - based on Gaussian Processes with a new kernel designed for this work - allows one to identify the visual characteristics of faves that better account for the prediction outcome.", "references": ["S. Cloninger. Conceptual issues in personality theory. In P.J. Corr and G. Matthews, editors, The Cambridge handbook of personality psychology, pages 3--26. Cambridge University Press, 2009.", "D. Coutu. We googled you. Harvard Business Review, 85(6):1--8, 2007.", "M. Cristani, A. Vinciarelli, C. Segalin, and A. Perina. Unveiling the multimedia unconscious: Implicit cognitive processes and multimedia content analysis. In Proceedings of the ACM International Conference on Multimedia, pages 213--222, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2964284.2967253"}, {"title": "CaSMoS: A Framework for Learning Candidate Selection Models over Structured Queries and Documents", "authors": ["Fedor Borisyuk\n,", "Krishnaram Kenthapadi\n,", "David Stein\n,", "Bo Zhao"], "publication": "KDD '16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nUser experience at social media and web platforms such as LinkedIn is heavily dependent on the performance and scalability of its products. Applications such as personalized search and recommendations require real-time scoring of millions of structured candidate documents associated with each query, with strict latency constraints. In such applications, the query incorporates the context of the user (in addition to search keywords if present), and hence can become very large, comprising of thousands of Boolean clauses over hundreds of document attributes. Consequently, candidate selection techniques need to be applied since it is infeasible to retrieve and score all matching documents from the underlying inverted index. We propose CaSMoS, a machine learned candidate selection framework that makes use of Weighted AND (WAND) query. Our framework is designed to prune irrelevant documents and retrieve documents that are likely to be part of the top-k results for the query. We apply a constrained feature selection algorithm to learn positive weights for feature combinations that are used as part of the weighted candidate selection query. We have implemented and deployed this system to be executed in real time using LinkedIn's Galene search platform. We perform extensive evaluation with different training data approaches and parameter settings, and investigate the scalability of the proposed candidate selection model. Our deployment of this system as part of LinkedIn's job recommendation engine has resulted in significant reduction in latency (up to 25%) without sacrificing the quality of the retrieved results, thereby paving the way for more sophisticated scoring models.", "references": ["Apache Kafka. http://kafka.apache.org/.", "G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender systems handbook. Springer, 2015.", "E. Al Mashagba, F. Al Mashagba, and M. O. Nassar. Query optimization using genetic algorithms in the vector space model. International Journal of Computer Science Issues (IJCSI), 8(5), 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2939672.2939718"}, {"title": "Using TWIG: India's past versus present via topic modeling", "authors": ["Newton McCollum\n,", "Andrew Fayed\n,", "Benjamin McIntosh\n,", "James Carignan\n,", "Deepti Joshi"], "publication": "Journal of Computing Sciences in Colleges", "abstract": "Abstract\nIn this research, we look at past data collected through a Java programmed web crawler which scrapes the archives of the Indian Express (a leading national newspaper from India) for articles from 2000 until present day, and retrieves them as text files which are then stored in the MongoDB database. In addition, using TWIG (The Web Information Gatherer), we look at current data collected through Twitter and online news sources with RSS Feeds. To this dataset of past and present, we apply topic detection algorithm --- LDA, that allows us to form a generalization of an article which can be used to conclude a general idea about a region during a given time period. The result is visualized as a word cloud for every three years, from 2000 until 2016. This enables us to observe the changes and trends in the topics of interest in India. Similar analysis can be done with countries all over the world. The applications are extremely relevant to the intelligence communities.", "references": ["Aiello, Luca Maria, Georgios Petkos, Carlos Martin, David Corney, Symeon Papadopoulos, Ryan Skraba, Ayse Göker, Ioannis Kompatsiaris, and Alejandro Jaimes. \"Sensing Trending Topics in Twitter.\" IEEE Transactions on Multimedia 15.6 (October): 1268. Print.", "Blei, David M., and John D. Lafferty. \"Topic Models.\" Princeton University Department of Computer Science. 2009. Web. 16 Apr. 2016.", "Cadena, Jose, Gizem Korkmaz, Chris J. Kuhlman, Achla Marathe, Naren Ramakrishnan, and Anil Vullikanti. \"Forecasting Social Unrest Using Activity Cascades.\" The National Center for Biotechnology Information. Public Library of Science, 19 June 2015. Web. 16 Apr. 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3015063.3015085"}, {"title": "Evaluating Body-Centered Interactions in an Image Search Task", "authors": ["Roberto González-Ibáñez\n,", "José Luis Varela-Otárola\n,", "Carlos Barrera-Pulgar"], "publication": "CHIIR '16: Proceedings of the 2016 ACM on Conference on Human Information Interaction and Retrieval", "abstract": "ABSTRACT\nInteracting with information in digital environments involves a physical gap between people and information. Although current advances in interaction technology provide the means for helping bridge this gap, little is known about whether this gap affects user experience and performance in the context of information-related tasks such as information search. In this paper we present preliminary results from a larger study focused on immersive interaction with digital information objects. In particular, we report those derived from a user study designed to evaluate interactions with digital information objects through body gestures in the context of an image search task. Our results suggest that compared to traditional interactions through mouse, this type of interaction not only helps lessen cognitive workload, but also leads to achieve similar precision in terms of the information collected.", "references": ["Chang, Y. J., Der Chou, L., Wang, F. T. Y. and Chen, S. F. 2013. A kinect-based vocational task prompting system for individuals with cognitive impairments. Pers. Ubiquitous Comput. 17, 2, 351--358.", "Chang. Y. J., Han, W. Y. and Tsai, Y. C. 2013. A Kinect-based Upper Limb Rehabilitation System to Assist People with Cerebral Palsy. Res. Dev. Disabil. 34, 11, 3654--3659.", "Fang, W.-C., Lin, Y.-L., Sheu, F.-R., & Chen, N.-S. 2013. Exploring Problem Solving Performance through Natural User Interfaces. IEEE 13th Int. Conf. on Adv. Learning Tech. (Jul. 2013). 232--234."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2854946.2854998"}, {"title": "Understanding GPU Power: A Survey of Profiling, Modeling, and Simulation Methods", "authors": ["Robert A. Bridges\n,", "Neena Imam\n,", "Tiffany M. Mintz"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nModern graphics processing units (GPUs) have complex architectures that admit exceptional performance and energy efficiency for high-throughput applications. Although GPUs consume large amounts of power, their use for high-throughput applications facilitate state-of-the-art energy efficiency and performance. Consequently, continued development relies on understanding their power consumption. This work is a survey of GPU power modeling and profiling methods with increased detail on noteworthy efforts. As direct measurement of GPU power is necessary for model evaluation and parameter initiation, internal and external power sensors are discussed. Hardware counters, which are low-level tallies of hardware events, share strong correlation to power use and performance. Statistical correlation between power and performance counters has yielded worthwhile GPU power models, yet the complexity inherent to GPU architectures presents new hurdles for power modeling. Developments and challenges of counter-based GPU power modeling are discussed. Often building on the counter-based models, research efforts for GPU power simulation, which make power predictions from input code and hardware knowledge, provide opportunities for optimization in programming or architectural design. Noteworthy strides in power simulations for GPUs are included along with their performance or functional simulator counterparts when appropriate. Last, possible directions for future research are discussed.", "references": ["2014. Advanced Configuration and Power Interface (ACPI) website. Retrieved from http://www.acpi.info", "2014. Penguin Computing Releases New Power Monitoring Device. Retrieved from http://www.penguincomputing.com/resources/press-releases/penguin-computing-releases-new-power-monitoring-device.", "AMD. 2015. AMD GPU Performance API User Guide. Retrieved from http://developer.amd.com/tools-and-sdks/graphics-development/GPUperfapi/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2962131"}, {"title": "SAR Satellite Data Reduction using Dynamic 4 Path: Block Gain Tree Structured Vector Quantization", "authors": ["Hyeon-Cheol Lee\n,", "Eun SuKang\n,", "Sang Gyu Lee\n,", "SeungHoon Lee"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nA SAR payload in Satellite transmits a ground station its SAR raw data by wireless datalink for post-processing, then the efforts of reducing its SAR raw data have been studied much. Vector Quantization (VQ) among these efforts is used much with block adaptive quantization. Due to heavy data search load of Vector Quantization between codebook and image data, Tree Structured Vector Quantization (TSVQ) is introduced instead of full-search-codebook. In this paper, Dynamic 4 Path - Block Gain Tree Structured Vector Quantization (D4P-BGTSVQ) which has 4-path tree structures with block gain is introduced instead of conventional 2-path TSVQ, and we suggest the best solution by comparing SNR and calculation load.", "references": ["Gersho, A. and Gray, R.M., 1992, Vector Quantization and Signal Compression. Kluwer Academic Publisher, Boston, 1992.", "Kwok, R. and Johnson, W.T.K., 1989, Block adaptive quantization of magellan SAR data, IEEE T. Geosci. Remot., vol. 27(1989), 375--383.", "Linde, Y., Buzo, A. and Gray, R. 1980, An algorithm for vector quantizer design, IEEE T. Commun., vol. COM-28, no. 1(1980), 84--95."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015201"}, {"title": "Assessing the Impact of Vocabulary Similarity on Multilingual Information Retrieval for Bantu Languages", "authors": ["Catherine Chavula\n,", "Hussein Suleman"], "publication": "FIRE '16: Proceedings of the 8th annual meeting of the Forum on Information Retrieval Evaluation", "abstract": "ABSTRACT\nDespite the availability of massive open information and efforts to promote multilingualism on the Web, content in Bantu languages remains negligible. Additionally, Information Retrieval (IR) systems, such as the Google search engine, use algorithms that work well with languages that have the most content. Similarities across related languages such as vocabulary overlap can potentially be exploited to provide more opportunities for information access for languages with limited digital content. This study investigates how vocabulary similarity impacts on the quality of search results in Multilingual Information Retrieval (MLIR) environments. More specifically, the study evaluates indexing strategies for MLIR and their effect on the quality of retrieval for related languages. A multilingual test collection consisting of two Bantu languages, Citumbuka and Chichewa, and English was developed and used in the evaluation. The results show that when comparing related and unrelated language pairs, MLIR indexing strategies result in comparable or worse retrieval performance.", "references": ["R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval - the Concepts and Technology Behind Search, Second edition. Pearson Education Ltd., Harlow, England, 2011.", "C. Buckley, M. Mitra, J. Walz, and C. Cardie. Using Clustering and SuperConcepts Within SMART: TREC 6. Inf. Process. Manage., 36(1):109--131, Jan. 2000.", "J. J. Chavula. Verbal Derivation and Valency in Citumbuka. PhD thesis, Centre for Linguistics, Leiden University, 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015157.3015160"}, {"title": "Indexing quality and effectiveness: an exploratory analysis of electronic theses and dissertations representation", "authors": ["Daniel Alemneh\n,", "Mark Phillips"], "publication": "ASIST '16: Proceedings of the 79th ASIS&T Annual Meeting: Creating Knowledge, Enhancing Lives through Information & Technology", "abstract": "ABSTRACT\nTheses and dissertations (ETDs) represent a wealth of scholarly and artistic content created by graduate students in masters and doctoral programs in the degree-seeking process. Considering the multi-disciplinarity and interdiciplinarity characteristics of ETDs, often several subjects and indexing terms need to be supplied to adequately represent ETDs for efficient access.\nThis study analyzes the quality and effectiveness of indexing terms - both authorized terms from controlled vocabularies and free-text keywords - used to succinctly describe the content of the electronic theses and dissertations (ETDs). Based on the comparisons of the search terms entered by users to discover and access the ETDs, the authors also discuss the subjectivity and objectivity of the process and the need to distinguish functional representation from mere descriptions of a topic.", "references": ["Alemneh, D. G et.al. (2014). Metadata for ETD Lifecycle Management. Accessed June 14, 2016, from: http://digital.library.unt.edu/ark:/67531/metadc279711/", "Alemneh, D. G. & Hartsock, R. (2014) Theses and Dissertations from Print to ETD: The Nuances of Preserving and Accessing Those in Music. IGI Global, Hershey, Pennsylvania. Accessed June 22, 2016, from: http://digital.library.unt.edu/ark:/67531/metadc181675.", "Coates, M. (2014). Electronic theses and dissertations. Library Hi Tech, 32(2), 285. Accessed June 1, 2016, from: http://search.proquest.com/docview/1660948799."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3017447.3017558"}, {"title": "A holistic and principled approach for the empty-answer problem", "authors": ["Davide Mottin\n,", "Alice Marascu\n,", "Senjuti Basu Roy\n,", "Gautam Das\n,", "Themis Palpanas\n,", "Yannis Velegrakis"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWe propose a principled optimization-based interactive query relaxation framework for queries that return no answers. Given an initial query that returns an empty-answer set, our framework dynamically computes and suggests alternative queries with fewer conditions than those the user has initially requested, in order to help the user arrive at a query with a non-empty-answer, or at a query for which no matter how many additional conditions are ignored, the answer will still be empty. Our proposed approach for suggesting query relaxations is driven by a novel probabilistic framework based on optimizing a wide variety of application-dependent objective functions. We describe optimal and approximate solutions of different optimization problems using the framework. Moreover, we discuss two important extensions to the base framework: the specification of a minimum size on the number of results returned by a relaxed query and the possibility of proposing multiple conditions at the same time. We analyze the proposed solutions, experimentally verify their efficiency and effectiveness, and illustrate their advantages over the existing approaches.", "references": ["Agrawal, S., Chaudhuri, S., Das, G., Gionis, A.: Automated ranking of database query results. In: CIDR (2003)", "Ahlberg, C., Shneiderman, B.: The alphaslider: a compact and rapid selector. In: CHI, p. 226 (1994)", "Anagnostopoulos, A., Becchetti, L., Castillo, C., Gionis, A.: An optimization framework for query recommendation. In: WSDM, pp. 161---170 (2010)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-016-0431-8"}, {"title": "A Novel Clutter Suppression Technique in Pulse Radar Exploiting Adaptive Filter", "authors": ["Yuan Feng\n,", "Yuanyuan Cui\n,", "Yinkai Liu"], "publication": "ICSPS 2016: Proceedings of the 8th International Conference on Signal Processing Systems", "abstract": "ABSTRACT\nClutter suppression is essential to radar signal processing, but it still suffers from some severe problems which need to be discussed in this paper. The moving target indication (MTI) is a commonly used approach in clutter cancellation, and is very effective when radar detecting moving targets in clutter interference environment. However, the wide notch developed by MTI filter result in significant signal losses for low-velocity targets, and thereby, brings serious negative impact in the detection of these targets. In order to solve this problem, a fast block normalized least mean square (FBNLMS) method for pulse radar is proposed in this paper, and it not only can suppress the interference but also protect the energy of low-velocity target. A multichannel fast block NLMS (MC-FBNLMS) algorithm is also developed to suppress the moving clutter which has non-zero Doppler frequency and spread Doppler spectrum. The effectiveness of the proposed approaches has been verified by experimental analysis.", "references": ["Ma, X. Y. and Xiang, J. B. 1999. Radar Signal Processing. Hunan Science and Technology Press, Hunan.", "Hu, K. X. 2006. Application of an adaptive clutter rejection technique in radar. Modern Electronics Technique. 29, 8 (2006), 24--26.", "Zhong, H. L. and Chai, C. C. 2005. Study on radar clutter characteristics and clutter suppression technique. Information and Electronic Engineering. 3, 1 (2005), 66--71."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3015166.3015204"}, {"title": "Detecting and Ranking Conceptual Links between Texts Using a Knowledge Base", "authors": ["Martin Tutek\n,", "Goran Glavas\n,", "Jan Šnajder\n,", "Natasa Milić-Frayling\n,", "Bojana Dalbelo Basic"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRecent research has explored the use of Knowledge Bases (KBs) to represent documents as subgraphs of a KB concept graph and define metrics to characterize semantic relatedness of documents in terms of properties of the document concept graphs. However, none of the studies so far have examined to what degree such metrics capture a user-perceived relatedness of documents. Considering the users' explanations of how pairs of documents are related, the aim is to identify concepts in a KB graph that express the same notion of document relatedness. Our algorithm generates paths through the KB graph that originate from the terms in two documents. KB concepts where these paths intersect capture the semantic relatedness of the two starting terms and therefore the two documents. We consider how such intersecting concepts relate to the concepts in the users' explanations. The higher the users' concepts appear in the ranked list of intersecting concepts, the better the method in capturing the users' notion of document relatedness. Our experiments show that our approach outperforms a simpler graph method that uses properties of the concept nodes alone.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. Journal of machine Learning research, 3(Jan):993--1022, 2003.", "S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. Indexing by latent semantic analysis. Journal of the American society for information science, 41(6):391, 1990.", "J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K. Gray, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant, et al. Quantitative analysis of culture using millions of digitized books. Science, 331(6014):176--182, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983913"}, {"title": "Learning to Rewrite Queries", "authors": ["Yunlong He\n,", "Jiliang Tang\n,", "Hua Ouyang\n,", "Changsung Kang\n,", "Dawei Yin\n,", "Yi Chang"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIt is widely known that there exists a semantic gap between web documents and user queries and bridging this gap is crucial to advance information retrieval systems. The task of query rewriting, aiming to alter a given query to a rewrite query that can close the gap and improve information retrieval performance, has attracted increasing attention in recent years. However, the majority of existing query rewriters are not designed to boost search performance and consequently their rewrite queries could be sub-optimal. In this paper, we propose a learning to rewrite framework that consists of a candidate generating phase and a candidate ranking phase. The candidate generating phase provides us the flexibility to reuse most of existing query rewriters; while the candidate ranking phase allows us to explicitly optimize search relevance. Experimental results on a commercial search engine demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the important components of the proposed framework.", "references": ["I. Antonellis, H. G. Molina, and C. C. Chang. Simrank+: query rewriting through link analysis of the click graph. Proceedings of the VLDB Endowment, 1(1):408--421, 2008.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In Current Trends in Database Technology-EDBT 2004 Workshops, pages 588--596. Springer, 2005.", "R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern information retrieval, volume 463. ACM press New York, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983835"}, {"title": "New Collection Announcement: Focused Retrieval Over the Web", "authors": ["Ivan Habernal\n,", "Maria Sukhareva\n,", "Fiana Raiber\n,", "Anna Shtok\n,", "Oren Kurland\n,", "Hadar Ronen\n,", "Judit Bar-Ilan\n,", "Iryna Gurevych"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFocused retrieval (a.k.a., passage retrieval) is important at its own right and as an intermediate step in question answering systems. We present a new Web-based collection for focused retrieval. The document corpus is the Category A of the ClueWeb12 collection. Forty-nine queries from the educational domain were created. The $100$ documents most highly ranked for each query by a highly effective learning-to-rank method were judged for relevance using crowdsourcing. All sentences in the relevant documents were judged for relevance.", "references": ["E. Agichtein, D. Carmel, C. L. A. Clarke, P. Paritosh, D. Pelleg, and I. Szpektor. Web question answering: Beyond factoids: SIGIR 2015 workshop. In Proc. of SIGIR, page 1143, 2015.", "J. Allan. HARD track overview in TREC 2003: High accuracy retrieval from documents. In Proc. of TREC, pages 24--37, 2003.", "J. Allan. HARD track overview in TREC 2004 - high accuracy retrieval from documents. In Proc. of TREC, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2914682"}, {"title": "Fast Matrix Factorization for Online Recommendation with Implicit Feedback", "authors": ["Xiangnan He\n,", "Hanwang Zhang\n,", "Min-Yen Kan\n,", "Tat-Seng Chua"], "publication": "SIGIR '16: Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First, due to the large space of unobserved feedback, most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However, such a uniform assumption is invalid in real-world settings. Second, most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity, which is more effective and flexible than the uniform-weight assumption. However, such a non-uniform weighting poses efficiency challenge in learning the model. To address this, we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique, for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols, we show that our implemented, open-source (https://github.com/hexiangnan/sigir16-eals) eALS consistently outperforms state-of-the-art implicit MF methods.", "references": ["D. Coppersmith and S. Winograd. Matrix multiplication via arithmetic progressions. J. Symb. Comput., 9(3):251--280, 1990.", "P. Cremonesi, Y. Koren, and R. Turrin. Performance of recommender algorithms on top-n recommendation tasks. In RecSys 2010, pages 39--46.", "A. S. Das, M. Datar, A. Garg, and S. Rajaram. Google news personalization: Scalable online collaborative filtering. In WWW 2007, pages 271--280.", "R. Devooght, N. Kourtellis, and A. Mantrach. Dynamic matrix factorization with priors on unknown values. In KDD 2015, pages 189--198.", "E. Diaz-Aviles, L. Drumond, L. Schmidt-Thieme, and W. Nejdl. Real-time top-n recommendation in social streams. In RecSys 2012, pages 59--66.", "J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. J. Mach. Learn. Res., 12:2121--2159, 2011.", "R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sismanis. Large-scale matrix factorization with distributed stochastic gradient descent. In KDD 2011, pages 69--77.", "X. Geng, H. Zhang, J. Bian, and T.-S. Chua. Learning image and user features for recommendation in social networks. In ICCV 2015, pages 4274--4282.", "X. He, T. Chen, M.-Y. Kan, and X. Chen. Trirank: Review-aware explainable recommendation by modeling aspects. In CIKM 2015, pages 1661--1670.", "X. He, M. Gao, M.-Y. Kan, Y. Liu, and K. Sugiyama. Predicting the popularity of web 2.0 items based on user comments. In SIGIR 2014, pages 233--242.", "X. He, M.-Y. Kan, P. Xie, and X. Chen. Comment-based multi-view clustering of web 2.0 items. In Proc. of WWW '14, pages 771--782, 2014.", "Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In ICDM 2008, pages 263--272.", "Y. Huang, B. Cui, W. Zhang, J. Jiang, and Y. Xu. Tencentrec: Real-time stream recommendation in practice. In SIGMOD 2015, pages 227--238.", "Y. Koren. Collaborative filtering with temporal dynamics. In KDD 2009, pages 447--456.", "Y. Koren and R. Bell. Advances in collaborative filtering. In Recommender systems handbook, pages 145--186. Springer, 2011.", "O. Levy and Y. Goldberg. Neural word embedding as implicit matrix factorization. In NIPS 2014, pages 2177--2185.", "G. Ling, H. Yang, I. King, and M. R. Lyu. Online learning for collaborative filtering. In IJCNN 2012, pages 1--8.", "B. M. Marlin, R. S. Zemel, S. Roweis, and M. Slaney. Collaborative filtering and the missing at random assumption. In UAI 2007, pages 267--276.", "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS 2013, pages 3111--3119.", "R. Pan and M. Scholz. Mind the gaps: Weighting the unknown in large-scale one-class collaborative filtering. In KDD 2009, pages 667--676.", "R. Pan, Y. Zhou, B. Cao, N. Liu, R. Lukose, M. Scholz, and Q. Yang. One-class collaborative filtering. In ICDM 2008, pages 502--511.", "J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for word representation. In EMNLP 2014, pages 1532--1543.", "I. Pilászy, D. Zibriczky, and D. Tikk. Fast als-based matrix factorization for explicit and implicit feedback datasets. In RecSys 2010, pages 71--78.", "S. Rendle and C. Freudenthaler. Improving pairwise learning for item recommendation from implicit feedback. In WSDM 2014, pages 273--282.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. In UAI 2009, pages 452--461.", "S. Rendle, Z. Gantner, C. Freudenthaler, and L. Schmidt-Thieme. Fast context-aware recommendations with factorization machines. In SIGIR 2011, pages 635--644.", "S. Rendle and L. Schmidt-Thieme. Online-updating regularized kernel matrix factorization models for large scale recommender systems. In RecSys 2008, pages 251--258.", "P. Richtárik and M. Takác. Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function. Math. Prog., 2014.", "D. Sculley, G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary, and M. Young. Machine learning: The high interest credit card of technical debt. In SE4ML (NIPS 2014 Workshop), 2014.", "H. Steck. Training and testing of recommender systems on data missing not at random. In KDD 2010, pages 713--722.", "M. Volkovs and G. W. Yu. Effective latent models for binary feedback in recommender systems. In SIGIR 2015, pages 313--322.", "H. Zhang, F. Shen, W. Liu, X. He, H. Luan, and T.-S. Chua. Discrete collaborative filtering. In SIGIR 2016."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2911451.2911489"}, {"title": "Probabilistic Approaches to Controversy Detection", "authors": ["Myungha Jang\n,", "John Foley\n,", "Shiri Dori-Hacohen\n,", "James Allan"], "publication": "CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRecently, the problem of automated controversy detection has attracted a lot of interest in the information retrieval community. Existing approaches to this problem have set forth a number of detection algorithms, but there has been little effort to model the probability of controversy in a document directly. In this paper, we propose a probabilistic framework to detect controversy on the web, and investigate two models. We first recast a state-of-the-art controversy detection algorithm into a model in our framework. Based on insights from social science research, we also introduce a language modeling approach to this problem.\nWe evaluate different methods of creating controversy language models based on a diverse set of public datasets including Wikipedia, Web and News corpora. Our automatically derived language models show a significant relative improvement of 18% in AUC over prior work,and 23% over two manually curated lexicons.", "references": ["R. Awadallah, M. Ramanath, and G. Weikum. Harmony and dissonance: Organizing the people's voices on political controversies. In WSDM'12.", "M.-A. Cartright, E. Aktolga, and J. Dalton. Characterizing the subjectivity of topics. In SIGIR' 09.", "Y. Choi, Y. Jung, and S.-H. Myaeng. Identifying controversial issues and their sub-topics in news articles. In Intelligence and Security Informatics. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2983323.2983911"}, {"title": "System to Solve the Inventory Routing Problem based on Monte Carlo Techniques", "authors": ["Raucer Cardulino\n,", "Pedro Y.A.L. Alves\n,", "Karina Valdivia Delgado"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nThe Stochastic Inventory Routing Problem (SIRP) is a combination of the inventory control problem with stochastic demands for goods in commercial centers and vehicle routing problem used in their supply from a single distribution center. This paper presents an alternative to the algorithm proposed by [8] for SIRP using Monte Carlo techniques. The new algorithm was implemented and compared to the original one considering several policies, showing similar results in some cases and better results in others in terms of time efficiency and quality solution. The analysis, comparison and assessment of both algorithms were based on benchmark problems from the literature.", "references": ["Augerat el al, 1995. Capacitated VRP Instances. Networking and Emerging Optimization Research Group. Universidad de Malaga. Disponivel em. http://neo.lcc.uma.es/vrp/vrpinstances/capacitated-vrp-instances/. Acesso em: 10 de maio 2015.", "Caceres-Cruz, J., Juan, A. A., Bektas, T., Grasman, S. E., Faulin, J. 2012. Combining Monte Carlo Simulation with Heuristics for Solving the Inventory Routing Problem with Stochastic Demands. Proceedings of the 2012 Winter Simulation Conference, article n. 274, p. 1- 9, 2012", "Clarke, G., Wright, J.W. 1964. Scheduling of vehicles from a central depot to a number of delivery points. Oper. Res. v. 12, p. 568-581, 1964."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3022018"}, {"title": "Quality Analysis of Different Metrics for Data Clustering Using Bio-Inspired Algorithm and MapReduce Architecture", "authors": ["Sandro R.L. Menezes\n,", "Rafael Stubs Parpinelli"], "publication": "SBSI 2016: Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1", "abstract": "ABSTRACT\nPerforming data mining tasks such as clustering can be very complex due to the high dimensionality and volume of data being mined. This paper proposes an approach for data clustering using the Symbiotic Organisms Search algorithm (SOS) developed in the MapReduce parallel architecture. Also, the cluster quality evolution is analysed using the purity measured considering four different fitness metrics. The cluster qualities obtained by the proposed approach not only shows to be competitive with other approaches but also increased its performance using the MapReduce architecture. Another contribution of this work is to bring to light the correlation between the cluster purity and the fitness value obtained during the optimization process. It was noticed that for some fitness metrics the final purity found by the optimization algorithm is less than the purity found in an earlier stage in the optimization process.", "references": ["N. Al-Madi, I. Aljarah, and S. A. Ludwig. Parallel glowworm swarm optimization clustering algorithm based on mapreduce. In Swarm Intelligence (SIS), 2014 IEEE Symposium on, pages 1-8. IEEE, 2014.", "I. Aljarah and S. A. Ludwig. Parallel particle swarm optimization clustering algorithm based on mapreduce methodology. In Nature and Biologically Inspired Computing (NaBIC), 2012 Fourth World Congress on, pages 104-111. IEEE, 2012", "I. Aljarah and S. A. Ludwig. Mapreduce intrusion detection system based on a particle swarm optimization clustering algorithm. In Evolutionary Computation (CEC), 2013 IEEE Congress on, pages 955-962. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3021955.3021985"}, {"title": "Participation Gestalt: Analysing Participatory Qualities of Interaction in Public Space", "authors": ["Peter Dalsgaard\n,", "Kim Halskov\n,", "Ole Sejer Iversen"], "publication": "CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "abstract": "ABSTRACT\nWe introduce the participation gestalt framework for analysing participation in public interactive installations. Building on the concept of interaction gestalt, we define the participation gestalt as the unified perception and experience of participatory qualities as they unfold through interaction with the installation in a socio-cultural setting. The framework consists of five continua, mapping out the qualities of participation in relation to the degree of expressivity, exposure, investment, sociality and persistence that people experience when engaging in the interaction. Individually, the five qualities provide a vocabulary for analyzing an interactive installation. Combined, the five qualities constitute a participation gestalt framework by which HCI researchers can qualify how a certain forms of participation emerge around public installations. We exemplify the framework by analyzing four public installations in different socio-cultural contexts and examining their participation gestalt.", "references": ["Christian Ulrik Andersen, Lars Bo Løfgreen and Søren Bro Pold. 2015. A Design for Things - Planetary Pledge Pyramid.", "Sophie Esmann Andersen and Anne Ellerup Nielsen. 2011. Climate-conscious citizenship in a digital public setting. MedieKultur 50 119--142.", "Hugh Beyer and Karen Holtzblatt. 1999. Contextual design. interactions 6, 1 (January 1999), 32--42. http://doi.acm.org/10.1145/291224.291229"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2858036.2858147"}, {"title": "Assessment of rating prediction techniques under response uncertainty", "authors": ["Sergej Sizov"], "publication": "WebSci '16: Proceedings of the 8th ACM Conference on Web Science", "abstract": "ABSTRACT\nAn objective assessment of collaborative filtering techniques and recommender systems requires application of suitable predictive accuracy metrics.\nIn real life, individuals meet their decisions with considerable uncertainty. We accordingly justify underlying assumptions of quality assessment and propose and appropriate uncertainty-aware evaluation methodology for rating predictions.", "references": ["Herlocker, J. L., Konstan, J. A., Terveen, L. G., and Riedl, J. T. Evaluating collaborative filtering recommender systems. ACM Trans. Inf. Syst. 22, 1 (2004), 5--53.", "Said, A., Jain, B., Narr, S., and Plumbaum, T. Users and noise: The magic barrier of recommender systems. In User Modeling, Adaptation, and Personalization, vol. 7379. Springer Berlin / Heidelberg, 2012, pp. 237--248.", "Su, X., and Khoshgoftaar, T. M. A survey of collaborative filtering techniques. Adv. in Artif. Intell. 2009 (Jan. 2009), 4:2--4:2."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2908131.2908203"}, {"title": "Personalized Recommendations using Knowledge Graphs: A Probabilistic Logic Programming Approach", "authors": ["Rose Catherine\n,", "William Cohen"], "publication": "RecSys '16: Proceedings of the 10th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nImproving the performance of recommender systems using knowledge graphs is an important task. There have been many hybrid systems proposed in the past that use a mix of content-based and collaborative filtering techniques to boost the performance. More recently, some work has focused on recommendations that use external knowledge graphs (KGs) to supplement content-based recommendation. In this paper, we investigate three methods for making KG based recommendations using a general-purpose probabilistic logic system called ProPPR. The simplest of the models, EntitySim, uses only the links of the graph. We then extend the model to TypeSim that also uses the types of the entities to boost its generalization capabilities. Next, we develop a graph based latent factor model, GraphLF, which combines the strengths of latent factorization with graphs. We compare our approaches to a recently proposed state-of-the-art graph recommendation method on two large datasets, Yelp and MovieLens-100K. The experiments illustrate that our approaches can give large performance improvements. Additionally, we demonstrate that knowledge graphs give maximum advantage when the dataset is sparse, and gradually become redundant as more training data becomes available, and hence are most useful in cold-start settings.", "references": ["A. Azaria and J. Hong. Recommender system with personality. In Proc. RecSys, 2016.", "S. H. Bach, M. Broecheler, B. Huang, and L. Getoor. Hinge-loss markov random fields and probabilistic soft logic. arXiv:1505.04406 {cs.LG}, 2015.", "L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social networks. In Proc. WSDM '11, pages 635--644, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2959100.2959131"}]