[{"title": "Lower Search Cost", "authors": ["Dou Shen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search is actually a pretty heavy task for most users since people need to launch a search engine's portal, phrase the right query and then go through search results to find the right information or service. To lower the search cost, commercial search engines have been improved in many ways, including query suggestion, relevant search, knowledge graph, ranking algorithm, user interface, and so on. I will briefly explain the progress along these features, especially for the largest Chinese search engine - Baidu. In addition to these approaches, another important way to lower search cost is to make Web search ready whenever a user intends to start a search, which becomes more important with the popularity of mobile devices. I will talk about the progress along this direction and the technologies behind it as well.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776788"}, {"title": "Beyond Independent Relevance: Methods and Evaluation Metrics for Subtopic Retrieval", "authors": ["ChengXiang Zhai\n,", "William W. Cohen\n,", "John Lafferty"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nWe present a non-traditional retrieval problem we call subtopic retrieval. The subtopic retrieval problem is concerned with finding documents that cover many different subtopics of a query topic. In such a problem, the utility of a document in a ranking is dependent on other documents in the ranking, violating the assumption of independent relevance which is assumed in most traditional retrieval methods. Subtopic retrieval poses challenges for evaluating performance, as well as for developing effective algorithms. We propose a framework for evaluating subtopic retrieval which generalizes the traditional precision and recall metrics by accounting for intrinsic topic difficulty as well as redundancy in documents. We propose and systematically evaluate several methods for performing subtopic retrieval using statistical language models and a maximal marginal relevance (MMR) ranking strategy. A mixture model combined with query likelihood relevance ranking is shown to modestly outperform a baseline relevance ranking on a data set used in the TREC interactive track.", "references": ["J. Allan, R. Gupta, and V. Khandelwal. Temporal summaries of news topics. In Proceedings of SIGIR 2001, pages 10--18, 2001.", "J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of SIGIR 1998, pages 335--336, 1998.", "U. Feige. A threshold of ln n for approximating set cover. Journal of the ACM, 45(4):634--652, July 1998.", "D. Harman. Overview of the trec 2002 novelty track. In Proceedings of TREC 2002, 2002.", "W. Hersh and P. Over. Trec-8 interactive track report. In E. Voorhees and D. Harman, editors, The Seventh Text REtrieval Conference (TREC-8), pages 57--64, 2000. NIST Special Publication 500-246.", "K. Jarvelin and J. Kekalainen. IR evaluation methods for retrieving highly relevant documents. In Proceedings of ACM SIGIR 2000, pages 41--48, 2000.", "J. Lafferty and C. Zhai. Document language models, query models, and risk minimization for information retrieval. In Proceedings of SIGIR'2001, pages 111--119, Sept 2001.", "P. Ogilvie and J. Callan. Experiments using the lemur toolkit. In Proceedings of the 2001 Text REtrieval Conference, pages 103--108, 2002.", "P. Over. Trec-6 interactive track report. In E. Voorhees and D. Harman, editors, The Sixth Text REtrieval Conference (TREC-6), pages 73--82, 1998. NIST Special Publication 500-240.", "P. Over. Trec-7 interactive track report. In E. Voorhees and D. Harman, editors, The Sixth Text REtrieval Conference (TREC-7), pages 65--72, 1999. NIST Special Publication 500-242.", "S. E. Robertson. The probability ranking principle in IR. Journal of Documentation, 33(4):294--304, Dec. 1977.", "T. Saracevic. Relevance reconsidered. In Proceedings of the 2nd Conference on Conceptions of Library and Information Science, pages 201--218, 1996.", "H. R. Varian. Economics and search (Invited talk at SIGIR 1999). SIGIR Forum, 33(3), 1999.", "C. Zhai and J. Lafferty. Model-based feedback in the KL-divergence retrieval model. In Tenth International Conference on Information and Knowledge Management (CIKM 2001), pages 403--410, 2001.", "C. Zhai and J. Lafferty. A study of smoothing methods for language models applied to ad hoc information retrieval. In Proceedings of SIGIR'2001, pages 334--342, Sept 2001.", "Y. Zhang, J. Callan, and T. Minka. Redundancy detection in adaptive filtering. In Proceedings of SIGIR'2002, pages 81--88, Aug 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795405"}, {"title": "Push-Based Recommendations in Mobile Computing Using a Multi-Layer Contextual Approach", "authors": ["Ramón Hermoso\n,", "Sergio Ilarri\n,", "Raquel Trillo\n,", "María del Carmen Rodríguez-Hernández"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nNowadays, due to the high availability of heterogeneous data sources that can provide interesting information, users usually suffer from information overload. Therefore, the development of adaptive information systems that can offer personalized information and filter out irrelevant data for a user is required. Significant work has been developed to solve this problem in the area of the so-called recommendation systems. However, context information has only started to be considered recently to build recommendation systems, despite being key to obtain more accurate recommendations. Moreover, even with some context information, there is still a significant gap between the fields of mobile computing and recommendation systems.\nIn this paper, we focus on push-based recommendations (i.e., recommendations not explicitly requested) for mobile users, as it represents the most challenging and effective approach for recommending items in mobile environments. As opposed to existing work, a generic model that fits different domains is proposed. This model is based on the definition of the concept of environment and manages the impact of dynamic events and all the actors involved in the mobile recommendation process.", "references": ["G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Transactions on Information Systems, 23(1):103--145, 2005.", "G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Second ACM Conference on Recommender Systems (RecSys), pages 335--336. ACM, 2008.", "A. Agostini, C. Bettini, N. Cesa-Bianchi, D. Maggiorini, D. Riboni, M. Ruberl, C. Sala, and D. Vitali. Towards highly adaptive services for mobile computing. In Mobile Information Systems, volume 158 of IFIP International Federation for Information Processing, pages 121--134. Springer, 2005.", "L. Baltrunas, B. Ludwig, S. Peer, and F. Ricci. Context relevance assessment and exploitation in mobile recommender systems. Personal and Ubiquitous Computing, 16(5):507--526, 2012.", "M. J. Barranco, J. M. Noguera, J. Castro, and L. Martínez. A context-aware mobile recommender system based on location and trajectory. In Management Intelligent Systems, volume 171 of Advances in Intelligent Systems and Computing, pages 153--162. Springer, 2012.", "J. Bobadilla, F. Ortega, A. Hernando, and A. Gutiérrez. Recommender systems survey. Knowledge-Based Systems, 46:109--132, 2013.", "M. Braunhofer, M. Elahi, F. Ricci, and T. Schievenin. Context-aware points of interest suggestion with dynamic weather data management. In Information and Communication Technologies in Tourism, pages 87--100. Springer, 2013.", "G. Chen and D. Kotz. A survey of context-aware mobile computing research. Technical report, Dartmouth College, Hanover, NH, USA, 2000.", "M. del Carmen Rodríguez-Hernández and S. Ilarri. Pull-based recommendations in mobile environments. Computer Standards & Interfaces, 2015. To appear, DOI: 10.1016/j.csi.2015.08.002.", "M. del Carmen Rodríguez-Hernández, S. Ilarri, R. Trillo-Lado, and R. Hermoso. Location-aware recommendation systems: Where we are and where we recommend to go. In Workshop on Location-Aware Recommendations (LocalRec 2015), in conjunction with RecSys 2015, volume 1405, pages 1--8. CEUR Workshop Proceedings, 2015.", "D. Gallego, W. Woerndl, and G. Huecas. Evaluating the impact of proactivity in the user experience of a context-aware restaurant recommender for Android smartphones. Journal of Systems Architecture, 59(9):748--758, 2013.", "T. R. Gruber. Toward principles for the design of ontologies used for knowledge sharing. International Journal of Human-Computer Studies, 43(5--6):907--928, 1995.", "T. Gu, H. K. Pung, and D. Q. Zhang. A service-oriented middleware for building context-aware services. Journal of Network and Computer Applications, 28(1):1--18, January 2005.", "N. Györbíró, Á. Fábián, and G. Hományi. An activity recognition system for mobile phones. Mobile Networks and Applications, 14(1):82--91, 2008.", "T. Hussein, T. Linder, W. Gaulke, and J. Ziegler. Hybreed: A software framework for developing context-aware hybrid recommender systems. User Modeling and User-Adapted Interaction, 24(1-2):121--174, 2014.", "S. Kim, E. Kim, and Y. Choi. Composite context information design and model approach for adaptive service decision. In 13th International Conference on Advanced Communication Technology (ICACT), pages 1593--1598. IEEE, 2011.", "N. D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury, and A. T. Campbell. A survey of mobile phone sensing. IEEE Communications Magazine, 48(9):140--150, 2010.", "J. J. Levandoski, M. Sarwat, A. Eldawy, and M. F. Mokbel. LARS: A location-aware recommender system. In 28th International Conference on Data Engineering (ICDE), pages 450--461. IEEE, 2012.", "J. Li, Y. Bu, S. Chen, X. Tao, and J. Lu. FollowMe: on research of pluggable infrastructure for context-awareness. In 20th International Conference on Advanced Information Networking and Applications (AINA), volume 1, pages 1--6. IEEE, 2006.", "Q. Liu, H. Ma, E. Chen, and H. Xiong. A survey of context-aware mobile recommendations. International Journal of Information Technology & Decision Making, 12(1):139--172, 2013.", "C. Mettouris and G. Papadopoulos. Ubiquitous recommender systems. Computing, 96(3):223--257, 2014.", "C. Mettouris and G. A. Papadopoulos. Contextual modelling in context-aware recommender systems: A generic approach. In Web Information Systems Engineering (WISE 2011 and 2012) Workshops, pages 41--52. Springer, 2013.", "W. Na, S. Cho, E. Kim, and Y. Choi. Event detection in composite context aware-service. In Third International Conference on Ubiquitous and Future Networks (ICUFN), pages 342--345. IEEE, 2011.", "A. Ranganathan and R. H. Campbell. An infrastructure for context-awareness based on first order logic. Personal and Ubiquitous Computing, 7(6):353--364, 2003.", "S. Reddy, M. Mun, J. Burke, D. Estrin, M. Hansen, and M. Srivastava. Using mobile phones to determine transportation modes. ACM Transactions on Sensor Networks, 6(2):13:1--13:27, 2010.", "M. Sarwat, J. J. Levandoski, A. Eldawy, and M. F. Mokbel. LARS*: An efficient and scalable location-aware recommender system. IEEE Transactions on Knowledge and Data Engineering, 26(6):1384--1399, 2014.", "W. Woerndl, J. Huebner, R. Bader, and D. Gallego-Vico. A model for proactivity in mobile, context-aware recommender systems. In Fifth ACM Conference on Recommender Systems (RecSys), pages 273--276. ACM, 2011.", "H. Yin, Y. Sun, B. Cui, Z. Hu, and L. Chen. LCARS: A location-content-aware recommender system. In 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 221--229. ACM, 2013.", "H. Zhu, E. Chen, H. Xiong, K. Yu, H. Cao, and J. Tian. Mining mobile user preferences for personalized context-aware recommendation. ACM Transaction on Intelligent Systems and Technology, 5(4):58:1--58:27, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2837128"}, {"title": "Hugo: Entity-based News Search and Summarisation", "authors": ["Anaïs Cadilhac\n,", "Andrew Chisholm\n,", "Ben Hachey\n,", "Sadegh Kharazmi"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nWe describe Hugo -- a service initially available on iOS that solicits a structured, semantic query and returns entity-specific news articles. Retrieval is powered by a semantic annotation pipeline that includes named entity linking and automatic summarisation. Search and entity linking use an in-house knowledge base initialised with Wikipedia data and continually curated to include new entities. Hugo delivers timely knowledge about a user's professional network, in particular new people they want to know more about.", "references": ["J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reording documents and producing summaries. In Proceedings of SIGIR, pages 335--336, 1998.", "A. Chisholm and B. Hachey. Entity disambiguation with web links. Transactions of the Association for Computational Linguistics, 3:145--156, 2015. https://github.com/wikilinks/nel.", "T. Dawborn. DOCREP: Document Representation for Natural Language Processing. PhD thesis, The University of Sydney, 2015. To appear. https://github.com/schwa-lab/libschwa."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810144"}, {"title": "When Topic Models Disagree: Keyphrase Extraction with Multiple Topic Models", "authors": ["Lucas Sterckx\n,", "Thomas Demeester\n,", "Johannes Deleu\n,", "Chris Develder"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe explore how the unsupervised extraction of topic-related keywords benefits from combining multiple topic models. We show that averaging multiple topic models, inferred from different corpora, leads to more accurate keyphrases than when using a single topic model and other state-of-the-art techniques. The experiments confirm the intuitive idea that a prerequisite for the significant benefit of combining multiple models is that the models should be sufficiently different, i.e., they should provide distinct contexts in terms of topical word importance.", "references": ["K. Bache and M. Lichman. UCI machine learning repository, 2013.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. JMLR, 3(4--5):993--1022, 2003.", "D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. RCV1: A new benchmark collection for text categorization research. JMLR, 5:361--397, Dec. 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742731"}, {"title": "An Optimization Framework for Propagation of Query-Document Features by Query Similarity Functions", "authors": ["Maxim Zhukovskiy\n,", "Tsimafei Khatkevich\n,", "Gleb Gusev\n,", "Pavel Serdyukov"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIt is well known that a great number of query--document features which significantly improve the quality of ranking for popular queries, however, do not provide any benefit for new or rare queries since there is typically not enough data associated with those queries that is required to reliably compute the values of those features. It is a common practice to propagate the values of such features from popular to tail queries, if the queries are similar according to some predefined query similarity functions. In this paper, we propose new algorithms that facilitate and increase the effectiveness of this propagation. Given a query similarity function and a query--document relevance feature, we introduce two different approaches (linear weighting approach and tree-based approach) to learn a function of values of the similarity function and values of the feature for the similar queries w.r.t. the given document. The propagated value of the feature equals the value of the obtained function for the given query--document pair.", "references": ["E. Agichtein, E. Brill, S. Dumais, Improving web search ranking by incorporating user behavior information, Proc. SIGIR'06, pp. 19--26, 2006.", "E. Aktolga, J. Allan, Reranking Search Results for Sparse Queries, Proc. CIKM'11, pp. 173--182, 2011.", "R.M. Bell, Y. Koren, Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights, Proc. ICDM'07, pp. 43--52, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806487"}, {"title": "Qualification and acknowledgement of Information Systems professionals", "authors": ["Eliane Cristina de Freitas Rocha"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper discusses qualification and acknowledgement of IT (Information Technology) profesisonals in conceptual terms originated on psychology and sociology of work, and empirical ones originated from three researches: one run among IT Brazilian professionals about acknowledgement; another among graduated in Information Systems, about acknowledgement and qualification; a case study in an IT organization. It is concluded that social professional acknowledgement are not substantial as perceived by that professionals (social status and wages counts on that perception), despite the acknowledgement of work done by them on organizations might be good. On the other hand, required qualifications are not obtained only through regular or technological undergraduate courses, but also through personal effort and technology certifications.", "references": ["Bourdieu, P., Boltanski, L. 1998. O diploma e o cargo: relações entre o sistema de produgao e o sistema de reprodução. In: Nogueira, M. A.; Catani, A. (Orgs) Escritos de educação. Petrópolis, Vozes.", "Bourdieu, P. 2008. A Distinção: a crítica social do julgamento. São Paulo, EDUSP.", "Crivellari, H. M. T.; Melo, M.C.O. 1989. Saber Fazer - Implicações da Qualificação. Revista de Administração de Empresas. FGV, São Paulo, 29, 2 (abr./jun. 1989), 47-62.", "Downey, J. 2010. Careers in software: is there life after programming? In Proceedings of the 2010 Special Interest Group on Management Information System's 48th annual conference on Computer personnel research on Computer personnel research. (Vancouver, BC, Canada -- May 20 -22, 2010). ACM New York, NY, USA. DOI=10.1145/1796900.1796912.", "Ferreira, C. G. 1987. Processo de trabalho e relação salarial: um marco teórico-analítico para o estudo das formas capitalistas de produção industrial. Relatório impresso. Belo Horizonte: Cedeplar, UFMG.", "Ferreira, M. C. 2011. \"Chegar feliz e sair feliz do trabalho\": aportes do reconhecimento no trabalho pra uma ergonomia aplicada à qualidade de vida no trabalho. In: Mendes, A. M. (Org). Trabalho & Saúde - o sujeito entre a emancipação e a servidão. Curitiba, Juruá.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814153"}, {"title": "Fine-Grained Image Categorization by Localizing TinyObject Parts from Unannotated Images", "authors": ["Luming Zhang\n,", "Yi Yang\n,", "Roger Zimmermann"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper proposes a novel fine-grained image categorization model where no object annotation is required in the training/testing stage. The key technique is a dense graph mining algorithm that localizes multi-scale discriminative object parts in each image. In particular, to mimick human hierarchical perception mechanism, a super-pixel pyramid is generated for each image, based on which graphlets from each layer are constructed to seamlessly describe object parts. We observe that graphlets representative to each category are densely distributed in the feature space. Therefore a dense graph mining algorithm is developed to discover graphlets representative to each sub- super-category. Finally, the discovered graphlets from pairwise images are encoded into an image kernel for fine-grained recognition. Experiments on the UCB-200 [32] shown that our method performs competitively to many models relying on the annotated bird parts.", "references": ["Jinjun Wang, Jianchao Yang, Kai Yu, Fengjun Lv, Thomas Huang,Yihong Gong, Locality-constrained Linear Coding for Image Classification, CVPR, 2010.", "Li-Jia Li, Hao Su, Eric P. Xing, Li Fei-Fei, Object Bank: A High-Level Image Representation for Scene Classification and Semantic Feature Sparsification, NIPS, 2010.", "Yangqing Jia, Chang Huang, Trevor Darrell, Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features, CVPR, 2012.", "Olga Russakovsky, Yuanqing Lin, Kai Yu, Li Fei-Fei, Object-Centric Spatial Pooling for Image Classification, ECCV, 2012.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749299"}, {"title": "Evaluation of a Maturity Model for Agile Governance in ICT using Focus Group", "authors": ["Humberto Rocha de Almeida\n,", "Edviges Mariza Campos de Magalhaes\n,", "Hermano Perrelli de Moura\n,", "Jose Gilson de Almeida Teixeira\n,", "Claudia Cappelli\n,", "Luiz M. Fraga Martins"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nAgile Governance in the Information and Communication Technology (ICT) is an area on the rise and has been suggested as an innovative proposal based on the use of principles and values of the Manifesto for Agile Software Development on Governance in ICT conventional context. However, the adoption of practices to good Agile Governance in ICT is still considered a challenging task due mainly multidisciplinary and relative paucity of the area. On the one hand, there is a set of principles, practices and values of the underlying areas this domain, on the other hand, this set is not presented yet organized in a broader context in order to promote a systematic and gradual way to an increase of maturity in Agile Governance in ICT. Given this gap, this article proposes a maturity model for Agile Governance in ICT constructed from a wide bibliographic study involving the areas of Governance in ICT, agility and maturity. During construction of the proposed model, it started with a qualitative approach, with inductive method and comparative-structuralist procedures. Finally, this paper presents an evaluation of the model proposed by focus group. As a result, a number of improvements identified during the study is subsidizing the construction of a new version of the model.", "references": ["ALMEIDA NETO, H. R. DE et al. Uma Análise Comparativa envolvendo Modelos de Maturidade Ágeis. Anais: XI - Simpósio Brasileiro de Qualidade de Software - VI Workshop de Desenvolvimento Rápido de Aplicações. 2012a.", "ALMEIDA NETO, H. R. DE et al. A Comparative Analysis between Maturity Models for ITIL. IV Congreso Internacional de Computación y Telecomunicaciones. Lima, Perú: 2012b. Disponível em: ¿http://www.comtel.pe/comtel2012/callforpaper2012/P48C.pdf¿", "ALMEIDA NETO, H. R. DE et al. A Comparative Analysis between Maturity Models based on COBIT. III Encontro Anual de Tecnologia da Informação (EATI 2012). 2012c. Disponível em: ¿http://eati.info/eati/2012/selecionados/¿", "ALMEIDA NETO, H. R. DE et al. Evaluating a Maturity Model for Agile Governance in Information and Communication Technology with Survey Based on Expert Opinion. 18 Workshop em Engenharia de Software Experimental (ESELAW 2015). Lima, Perú: 2015. Disponível em: ¿http://eventos.spc.org.pe/cibse2015/sessions.html¿", "ALMEIDA NETO, H. R. DE; MOURA, H. P. DE. MAnGve Maturity Model (M3): Proposing a Maturity Model to Support Agile Governance in Information and Communication Technology. Anais: X Simpósio Brasileiro de Sistemas de Informação - Workshop de Teses e Dissertações (WTDSI). Londrina, Brasil. 2014. Disponível em: ¿http://www.lbd.dcc.ufmg.br/colecoes/wtdsi/2014/009.pdf¿.", "ALMEIDA NETO, H. R. DE; MOURA, H. P. DE; CAMPOS DE MAGALHAES, E. M. MAnGve maturity model (M3): A proposal for a doctoral thesis. Anais: 9th Iberian Conference on Information Systems and Technologies (CISTI). Barcelona, Espanha: 2014. Disponível em: ¿http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6876909¿.", "AMBLER, S. Scaling agile software development through lean governance. Software Development Governance, 2009. SDG', p. 1-2, 2009.", "BECK, K. et al. Manifesto for Agile Software Development. Disponível em: ¿http://agilemanifesto.org/¿. Acesso em: 25 abr. 2015.", "CADBURY, A. The Financial Aspects of Corporate Governance. The Committee on the Financial Aspects of Corporate Governance, UK, p. 90, 1992.", "CAPLAN, S. Using focus group methodology for ergonomic design. Ergonomics, v. 33, n. 5, p. 527-533, 1990.", "CARMEL, E. The Offshoring Stage Model: an epilogue, 2005. Disponível em: ¿auapps.american.edu/~carmel/papers/epilogue.pdf¿", "DOVE, R.; HARTMAN, S.; BENSON, S. An Agile Enterprise Reference Model with a Case Study of Remmele EngineeringForum or from Paradigm Shift International, 1996. Disponível em: ¿http://www.parshift.com/docs/aermodA0.htm¿", ""], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814062"}, {"title": "Leveraging history for faster sampling of online social networks", "authors": ["Zhuojie Zhou\n,", "Nan Zhang\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith a vast amount of data available on online social networks, how to enable efficient analytics over such data has been an increasingly important research problem. Given the sheer size of such social networks, many existing studies resort to sampling techniques that draw random nodes from an online social network through its restrictive web/API interface. While these studies differ widely in analytics tasks supported and algorithmic design, almost all of them use the exact same underlying technique of random walk - a Markov Chain Monte Carlo based method which iteratively transits from one node to its random neighbor.\nRandom walk fits naturally with this problem because, for most online social networks, the only query we can issue through the interface is to retrieve the neighbors of a given node (i.e., no access to the full graph topology). A problem with random walks, however, is the \"burn-in\" period which requires a large number of transitions/queries before the sampling distribution converges to a stationary value that enables the drawing of samples in a statistically valid manner.\nIn this paper, we consider a novel problem of speeding up the fundamental design of random walks (i.e., reducing the number of queries it requires) without changing the stationary distribution it achieves - thereby enabling a more efficient \"drop-in\" replacement for existing sampling-based analytics techniques over online social networks. Technically, our main idea is to leverage the history of random walks to construct a higher-ordered Markov chain. We develop two algorithms, Circulated Neighbors and Groupby Neighbors Random Walk (CNRW and GNRW) and rigidly prove that, no matter what the social network topology is, CNRW and GNRW offer better efficiency than baseline random walks while achieving the same stationary distribution. We demonstrate through extensive experiments on real-world social networks and synthetic graphs the superiority of our techniques over the existing ones.", "references": ["Stanford large network dataset collection http://snap.stanford.edu/data/.", "E. M. Airoldi. Sampling algorithms for pure network topologies. SIGKDD Explorations, 7:13--22, 2005.", "N. Alon, C. Avin, M. Koucky, G. Kozma, Z. Lotker, and M. R. Tuttle. Many random walks are faster than one. In SPAA, 2008.", "R. Burioni and D. Cassi. Random walks on graphs: ideas, techniques and results. Journal of Physics A: Mathematical and General, 38(8):R45, 2005.", "Y. Dodge, D. Cox, D. Commenges, P. J. Solomon, S. Wilson, et al. The Oxford dictionary of statistical terms. Oxford University Press, 2003.", "M. L. Fredman, J. Komlós, and E. Szemerédi. Storing a sparse table with 0 (1) worst case access time. Journal of the ACM (JACM), 31(3):538--544, 1984.", "M. Gjoka, M. Kurant, C. T. Butts, and A. Markopoulou. Walking in facebook: A case study of unbiased sampling of osns. In INFOCOM, 2010.", "W. K. Hastings. Monte carlo sampling methods using markov chains and their applications. Biometrika, 57(1):97--109, 1970.", "L. Jin, Y. Chen, P. Hui, C. Ding, T. Wang, A. V. Vasilakos, B. Deng, and X. Li. Albatross sampling: robust and effective hybrid vertex sampling for social graphs. In MobiArch, 2011.", "M. Kurant, M. Gjoka, C. T. Butts, and A. Markopoulou. Walking on a graph with a magnifying glass: stratified sampling via weighted random walks. In SIGMETRICS, 2011.", "C.-H. Lee, X. Xu, and D. Y. Eun. Beyond random walk and metropolis-hastings samplers: why you should not backtrack for unbiased graph sampling. In SIGMETRICS. ACM, 2012.", "J. Leskovec and C. Faloutsos. Sampling from large graphs. In SIGKDD, 2006.", "R.-H. Li, J. X. Yu, X. Huang, and H. Cheng. Random-walk domination in large graphs. In ICDE, 2014.", "J. McAuley and J. Leskovec. Learning to Discover Social Circles in Ego Networks. In NIPS, 2012.", "S. Navlakha, R. Rastogi, and N. Shrivastava. Graph summarization with bounded error. In SIGMOD, 2008.", "R. M. Neal. Improving asymptotic variance of mcmc estimators: Non-reversible chains are better. Technical Report, 2004.", "B. Ribeiro and D. Towsley. Estimating and sampling graphs with multidimensional random walks. In SIGCOMM, 2010.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2794367.2794373"}, {"title": "Mobile devices as interfaces for steering cloud-based high-performance computations", "authors": ["Young-Woo Kwon\n,", "Eli Tilevich"], "publication": "MobileDeLi 2015: Proceedings of the 3rd International Workshop on Mobile Development Lifecycle", "abstract": "ABSTRACT\nAs mobile devices have been steadily overtaking the personal computer as a primary computing platform, mobile applications deliver increasingly complex functionality. Furthermore, for next generation mobile applications to be proactive in their functionality, they need to be able to collect and process massive amounts of context-sensitive information on the fly. Leveraging high-end computing resources offers a promising avenue to address these emerging computational needs of mobile computing, both improving performance and saving battery power. These computational resources can now be conveniently accessed via standardized cloud-based interfaces. However, several research challenges must be addressed to be able to seamlessly use mobile devices as convenient interfaces for steering cloud-based high-performance computations. This position paper presents our view of the research agenda that must be followed to achieve these objectives as well as reports on our initial efforts in this endeavor.", "references": ["Y.-W. Kwon and E. Tilevich. Energy-efficient and fault-tolerant distributed mobile execution. In Proceedings of the 32nd International Conference on Distributed Computing Systems (ICDCS), June 2012.", "Y.-W. Kwon and E. Tilevich. Cloud refactoring: Automated transitioning to cloud-based services. Automated Software Engineering Journal, 2014.", "Y.-W. Kwon and E. Tilevich. Configurable and adaptive middleware for energy-efficient distributed mobile computing. In Proceedings of the 6th International Conference on Mobile Computing, Applications and Services (MobiCase 2015), November 2014.", "Y.-W. Kwon and E. Tilevich. Energy-efficient and fault-tolerant distributed mobile execution. In Proceedings of the 32nd International Conference on Distributed Computing Systems (ICDCS), June 2012.", "Y.-W. Kwon and E. Tilevich. Cloud refactoring: Automated transitioning to cloud-based services. Automated Software Engineering Journal, 2014.", "Y.-W. Kwon and E. Tilevich. Configurable and adaptive middleware for energy-efficient distributed mobile computing. In Proceedings of the 6th International Conference on Mobile Computing, Applications and Services (MobiCase 2015), November 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2846661.2846676"}, {"title": "Cost Minimization and Load Balancing Issues to Compose Web Services in a Multi Cloud Environment", "authors": ["Ouassila Hioual\n,", "Sofiane Mounine Hemam"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nThe Web services composition can be defined as a process where component services are identified and the dependencies between them are also described. The reusability of the independent components for different compositions gives flexibility. In a multi cloud environment, we need to find web services from multiple clouds, if a single cloud cannot give us all the component services that we need. In this paper, we focus on load-balancing across the replicas of services placed at different clouds. And since cloud services are payable, we try to minimize the total cost of the composed service.", "references": ["Gutierrez-Garcia, J. O. and Sim, K. M. 2012. Agents-based cloud service composition. The international Journal of Artificial Intelligence, Neural Networks and Complex Problem-solving Technologies. 22, 2 (2012).", "Bhaskaran, R. and Katz, R. H. 2003. Load Balancing and Stability Issues in Algorithms for Service Composition. IEEE INFOCOM 2003", "Windows Azure Platform. Microsoft cloud computing platform: http://www.microsoft.com/windowsazure/", "Amazon S3. Amazon Simple Storage Service cloud computing platform: http://aws.amazon.com/s3", "Zou G., Chen, Y., Yang, Y., Huang, R., Xu, Y. 2010. AI Planning and Combinatorial Optimization for Web Service Composition in Cloud Computing. In: Proc. International Conference on Cloud Computing and Virtualization, CCV Conference 2010, Singapore, May 17--18, 2010.", "Hioual, O and Boufaida, Z. 2011. An Agent Based Architecture (Using Planning) for Dynamic and Semantic Web Services Composition in an EBXML Context. International Journal of Database Management Systems (IJDMS). 3, 1 (February. 2011), 110--131.", "La, H. J. and Kim, S. D. 2010. A conceptual framework for provisioning context-aware mobile cloud services. IEEE 3rd International Conference on Cloud Computing. 466--473.", "Gutierrez-Garcia, J. O. and Sim, K. M. 2010. Agent-based service composition in cloud computing. In: Kim TH, et al (eds) GDC/CA 2010. CCIS, Springer, Heidelberg. 121 (2010), 1--10.", "Cardellini, V. and Colajanni, M. 1999. Dynamic Load Balancing on Web-server Systems. IEEE Internet Computing. 3 (1999), 28--39.", "Behera, I. and Tripathy, C. R. 2014. Performance modelling and analysis of mobile grid computing systems. International Journal of Grid and Utility Computing. 5, 1 (2014), 11--20.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816846"}, {"title": "At the forge: model relationships in django", "authors": ["Reuven M. Lerner"], "publication": "Linux Journal", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2830174.2830178"}, {"title": "Session details: Special Track - Business Process Management", "authors": ["Flavia Maria Santoro\n,", "Fernanda Baiao\n,", "Juliano Lopes de Oliveira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252442"}, {"title": "Monolingual and Cross-Lingual Information Retrieval Models Based on (Bilingual) Word Embeddings", "authors": ["Ivan Vulić\n,", "Marie-Francine Moens"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe propose a new unified framework for monolingual (MoIR) and cross-lingual information retrieval (CLIR) which relies on the induction of dense real-valued word vectors known as word embeddings (WE) from comparable data. To this end, we make several important contributions: (1) We present a novel word representation learning model called Bilingual Word Embeddings Skip-Gram (BWESG) which is the first model able to learn bilingual word embeddings solely on the basis of document-aligned comparable data; (2) We demonstrate a simple yet effective approach to building document embeddings from single word embeddings by utilizing models from compositional distributional semantics. BWESG induces a shared cross-lingual embedding vector space in which both words, queries, and documents may be presented as dense real-valued vectors; (3) We build novel ad-hoc MoIR and CLIR models which rely on the induced word and document embeddings and the shared cross-lingual embedding space; (4) Experiments for English and Dutch MoIR, as well as for English-to-Dutch and Dutch-to-English CLIR using benchmarking CLEF 2001-2003 collections and queries demonstrate the utility of our WE-based MoIR and CLIR models. The best results on the CLEF collections are obtained by the combination of the WE-based approach and a unigram language model. We also report on significant improvements in ad-hoc IR tasks of our WE-based framework over the state-of-the-art framework for learning text representations from comparable data based on latent Dirichlet allocation (LDA).", "references": ["M. Baroni, G. Dinu, and G. Kruszewski. Don't count, predict! A systematic comparison of context-counting vs context-predicting semantic vectors. In ACL, pages 238--247, 2014.", "Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137--1155, 2003.", "A. Berger and J. Lafferty. Information retrieval as statistical translation. In SIGIR, pages 222--229, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767752"}, {"title": "An Approach for Searching Semantic-based Keywords over Relational Database", "authors": ["Chien D. C Ta\n,", "Tuoi Phan Thi"], "publication": "SoICT 2015: Proceedings of the Sixth International Symposium on Information and Communication Technology", "abstract": "ABSTRACT\nOntologies apply to many applications in recent years, especially on the semantic web, information retrieval, information extraction, and question answering. The purpose of domain-specific ontology is to get rid of conceptual and terminological confusion. It accomplishes this by specifying a set of generic concepts that characterizes the domain as well as their definitions and interrelationships. There are some languages in order to represent ontologies, such as RDF, OWL. However, these languages are only suitable with ontologies having a small data. It usually uses a database for representing ontologies having big data. However, most of the databases do not sufficiently support the semantic orientated search by Structured Query Language (SQL). Therefore, this paper introduces an approach for semantic-based keyword search over relational databases. This approach can be applied to any relational database system.", "references": ["J. Atkinson, A. Gonzalez, M. Munoz, H. Astudillo, \"Web Metadata Extraction and Semantic Indexing for Learning Objects Extraction,\" in The 26th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems (IEA/AIE 2013), vol. 7906, 2013, pp. 131--140.", "M. E. Saleh, \"M. E. Saleh,\" Canadian Journal on Data, Information and KnowledgeEngineering, vol. 2, no. No. 1, January 2011", "S. Bergamaschi, F. Guerra, M. Interlandi, \"QUEST: A Keyword Search System for Relational Data based on Semantic and Machine Learning Techniques,\" in Proceedings of the VLDB Endowment, vol. 6, Trento, Italy, 2013, pp. 1222--1225..", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833258.2833263"}, {"title": "Rethinking the Destination Marketing Organization Management in the Big Data Era", "authors": ["Yu-Lan Yuan\n,", "Chaang-Iuan Ho"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nBig data is an important part of modern information management, providing new strategies for Destination Marketing Organizations (DMOs) for DMOs to gather large amount of data from tourists and stakeholders. DMOs that have the domain knowledge to analyze these data can take the opportunities presented by Big Data. This work describes the opportunities and challenges presented to DMOs in use of Big Data.", "references": ["Benckendorff, P. J., P. J. Sheldon, and D. R. Fesenmaier, Tourism information technology2014: CABI.", "Pike, S., Destination marketing organisations2007: Routledge.", "Yuan, Y.-L., U. Gretzel, and D. R. Fesenmaier, The role of information technology use in American convention and visitors bureaus. Tourism Management, 2006. 27(2): p. 326--341.", "Kim, G.-H., S. Trimi, and J.-H. Chung, Big-data applications in the government sector. Communications of the ACM, 2014. 57(3): p. 78--85.", "Pan, B., D. C. Wu, and H. Song, Forecasting hotel room demand using search engine data. Journal of Hospitality and Tourism Technology, 2012. 3(3): p. 196--210.", "Pan, B., T. MacLaurin, and J. C. Crotts, Travel blogs and the implications for destination marketing. Journal of Travel Research, 2007. 46(1): p. 35--45.", "McAfee, A., et al., Big data. The management revolution. Harvard Bus Rev, 2012. 90(10): p. 61--67.", "Desouza, K. C., Realizing the Promise of Big Data: Implementing Big Data Projects, in Using Technology Series2014, Washington, DC: IBM Center for the Business of Government: Phoenix.", "Baars, H. and H.-G. Kemper, Management support with structured and unstructured data---an integrated business intelligence framework. Information Systems Management, 2008. 25(2): p. 132--148.", "Beirman, D., Restoring tourism destinations in crisis: A strategic marketing approach2003, Australia: Allen & Unwin.", "Ryan, C. and H. Gu, Destination branding and marketing: The role of marketing organizations. Handbook of hospitality marketing management, 2008: p. 383--411.", "Gretzel, U., et al., Searching for the future: Challenges faced by destination marketing organizations. Journal of Travel Research, 2006. 45(2): p. 116--126.", "Morrison, A., Destination Management and Destination Marketing: The Platform for Excellence in Tourism Destinations. Tourism Tribune, 2012. 28(1): p. 6--9.", "Duggan, M. and L. Rainie. Mobile Phone Activities. {Web} 2012 {cited 2015; Available from: http://www.pewinternet.org/2012/11/25/cell-phone-activities-2012/.", "觀光局, 中華民國 100 年來台旅客消費及動向調查, in 來台旅客消費及動向調查 2011: 台北.", "觀光局, 中華民國 103 年來台旅客消費及動向調查, in 來台旅客消費及動向調查 2014: 台北.", "A. B. The rise of the independent tourist. The Economist, 2013.", "Morrison, A. M., Marketing and managing tourism destinations2013, London: Routledge.", "Mayer-Schönberger, V. and K. Cukier, Big data: A revolution that will transform how we live, work, and think2013: Houghton Mifflin Harcourt.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818904"}, {"title": "Learning Indicators in SCIS Tasks", "authors": ["Simon Knight"], "publication": "ECol '15: Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking", "abstract": "ABSTRACT\nEvaluation of user success, and systems to support that success, in information seeking tasks is complex. The addition of social or/and collaborative elements to task and system design adds an additional layer of complexity to such evaluation. This short paper highlights a number of simple metrics that have been used by information and learning science researchers to explore SCIS in the context of searching to learn.", "references": ["González-Ibáñez, R. et al. In press. Let's search together, but not too close! An analysis of communication and performance in collaborative information seeking. Information Processing & Management. (In press).", "Hsu, C.-Y. et al. 2013. Epistemic Beliefs, Online Search Strategies, and Behavioral Patterns While Exploring Socioscientific Issues. Journal of Science Education and Technology. (2013), 1--10.", "Knight, S. Forthcoming. Developing Learning Analytics for Epistemic Commitments in a Collaborative Information Seeking Environment. Open University."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2812376.2812378"}, {"title": "Music and Science: Parallels in Production", "authors": ["David De Roure\n,", "Graham Klyne\n,", "Kevin R. Page\n,", "John P. N. Pybus\n,", "David M. Weigl"], "publication": "DLfM '15: Proceedings of the 2nd International Workshop on Digital Libraries for Musicology", "abstract": "ABSTRACT\nThe music industry has embraced digital technology, from recording and production of music through to distribution and consumption. Meanwhile scholarly communication, including academic publishing and libraries, is also undergoing transformation thanks to the affordances of the digital. We suggest that comparing and contrasting these two sociotechnical systems will provide insights of mutual benefit. We propose a preliminary framing of that comparison, introduce a notion of Digital Music Object that is analogous to the Research Object, and discuss some implications for digital libraries for musicology.", "references": ["Regner, T., Barria, J.A., Pitt, J.V., and Neville, B. 2009. An artist life cycle model for digital media content: Strategies for the Light Web and the Dark Web, Electronic Commerce Research and Applications, Volume 8, Issue 6, Nov--Dec, Pages 334--342, DOI=10.1016/j.elerap.2009.05.002.", "Vandermerwe, S. 2000. How increasing value to consumers improves business results. Sloan Management Review, 42, 3, 2000, 27--37.", "Naughton, J. 2014. Lecture: Getting from here to there. MedieKultur. Journal of media and communication research, v. 30, n. 57, p. 14 p., nov. 2014. Available at: http://ojs.statsbiblioteket.dk/index.php/mediekultur/article/view/18609. Date accessed: 10 May 2015.", "Pras, A., Guastavino, C. and Lavoie, M. 2013. The impact of technological advances on recording studio practices. J. Am. Soc. Inf. Sci., 64: 612--626. DOI=10.1002/asi.22840", "Bird, C. and Frey, J.G. 2013. Chemical information matters: an e-Research perspective on information and data sharing in the chemical sciences. Chemical Society Reviews, 42, (16), 6754--6775. DOI=10.1039/C3CS60050E.", "Neylon, C. 2009. Science in Society. NESTA Crucible Workshop, Lancaster, 28 June. Available as http://commons.wikimedia.org/wiki/File:Research_cycle.png", "Frey, J.G., De Roure, D. and Carr, L. 2002. Publication at Source: Scientific Communication from a Publication Web to a Data Grid. In Proc. EuroWeb, (Oxford, UK, Dec 2002), British Computer Society.", "Bechhofer, S., Buchan, I., De Roure, D., Missier, P. et al. 2013. Why Linked Data is Not Enough for Scientists, Future Generation Computer Systems, Vol. 29, No. 2. pp. 599--611.", "De Roure, D., Bechhofer, S., Goble, C. and Newman, D. 2011. Scientific Social Objects: The Social Objects and Multidimensional Network of the my Experiment Website, In Proc. IEEE Third International Conference on Social Computing (Boston, MA, USA, 9--11 Oct), SocialCom. pp.1398--1402, DOI=10.1109/PASSAT/SocialCom.2011.245", "Yee-King, M., Krivenski, M., Brenton, H., Grimalt-Reynes, A, and d'Inverno, M. 2014. Designing educational social machines for effective feedback. In Proc. 8th International Conference on e-learning. (Lisbon, Portugal, 15--18 July).", "Downie, J.S., Ehmann, A.F., Bay, M. and Jones, M.C. 2010. The Music Information Retrieval Evaluation eXchange: Some Observations and Insights. Advances in Music Information Retrieval Vol. 274, pp. 93--115.", "Page, K.R., Fields, B., De Roure, D., Crawford, T., Downie, J.S. 2013. Capturing the workflows of music information retrieval for repeatability and reuse. J. Intell. Inf. Syst. 41(3): 435--459.", "De Roure, D. 2014. Executable Music Documents. In Proceedings of the 1st International Workshop on Digital Libraries for Musicology (London, United Kingdom, 12 Sep). DLfM '14. DOI=10.1145/2660168.2660183", "Nurmikko-Fuller, T., Page, K., Willcox, P., Jett, J. Maden, C., Cole, T., Fallaw, C., Senseney, M., Downie, J.S. 2015. Building Complex Research Collections in Digital Libraries: A Survey of Ontology Implications. In Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (Knoxville, USA, June 2015).", "Cook, N. 2014. Beyond the Score: Music as Performance. Oxford University Press, Oxford.", "Wiggins, G.A. 2009. Semantic Gap?? Schemantic Schmap!! Methodological Considerations in the Scientific Study of Music, 11th IEEE International Symposium on Multimedia, 2009 (San Diego, California, 14--16 Dec.) ISM '09. pp.477,482, DOI=10.1109/ISM.2009.36", "Haraway, D. 1988. Situated knowledges: The science question in feminism and the privilege of partial perspective. Feminist Studies, 14(3), 575--599.", "De Roure, D. 2010. Replacing the Paper: The Twelve Rs of the e-Research Record. e-Research, Nature blogs. Available at: http://www.scilogs.com/eresearch/replacing-the-paper-the-twelve-rs-of-the-e-research-record/. Date accessed: 10 May 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2785527.2785530"}, {"title": "Video Recommendation System Based on Personalized Ontology and Social Network", "authors": ["Rung-Ching Chen\n,", "Hua-Yuan Shih\n,", "Yu-Siang Lin\n,", "Hendry"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nUsers often use browser, media or mobile device to watch video. In these platforms, most of recommendation through hit icon to calculate grade. In this study, we design on ontology which combined with social networks or video recommendation. Users and their friend's data will be added to the ontology. According to user and friend's preferences, the system calculates the similarity of interests. The system uses a rule generating algorithm to create dynamic inference rules. Video are recommended to users by a JENA Inference Engine. Over time, the content of personal ontology will be updated. The ontology content at mobile device will be kept in the newest update states of owl to let recommender increase the accurate results.", "references": ["Juang, C. H. 2005. Collaborative filtering recommendation Groups. National Central University Department of Information Management Master's Thesis, Taiwan.", "Studer, R., Benjamins, V. R., and Fensei, D. 1998. Knowledge engineering: principles and methods. Data & Knowledge Engineering, Vol. 25, No. 1-2, pp. 161--197.", "http://jena.apache.org/.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818921"}, {"title": "Improving Concept-Based Image Retrieval with Training Weights Computed from Tags", "authors": ["Vasileios Papapanagiotou\n,", "Christos Diou\n,", "Anastasios Delopoulos"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nThis article presents a novel approach to training classifiers for concept detection using tags and a variant of Support Vector Machine that enables the usage of training weights per sample. Combined with an appropriate tag weighting mechanism, more relevant samples play a more important role in the calibration of the final concept-detector model. We propose a complete, automated framework that (i) calculates relevance scores for each image-concept pair based on image tags, (ii) transforms the scores into relevance probabilities and automatically annotates each image according to this probability, (iii) transforms either the relevance scores or the probabilities into appropriate training weights and finally, (iv) incorporates the training weights and the visual features into a Fuzzy Support Vector Machine classifier to build the concept-detector model. The framework can be applied to online public collections, by gathering a large pool of diverse images, and using the calculated probability to select a training set and the associated training weights. To evaluate our argument, we experiment on two large annotated datasets. Experiments highlight the retrieval effectiveness of the proposed approach. Furthermore, experiments with various levels of annotation error show that using weights derived from tags significantly increases the robustness of the resulting concept detectors.", "references": ["Avi Arampatzis and Jaap Kamps. 2009. A signal-to-noise approach to score normalization. In Proceedings of the 18th ACM Conference on Information and Knowledge Management. ACM, 797--806.", "Avi Arampatzis and Stephen Robertson. 2011. Modeling score distributions in information retrieval. Information Retrieval 14, 1, 26--46.", "Avi Arampatzis and André van Hameran. 2001. The score-distributional threshold optimization for adaptive binary classification tasks. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 285--293.", "Gerlof Bouma. 2009. Normalized (pointwise) mutual information in collocation extraction. In Proceedings of the Biennial GSCL Conference. 31--40.", "Francesca Bovolo, Lorenzo Bruzzone, and Lorenzo Carlin. 2010. A novel technique for subpixel image classification based on support vector machine. IEEE Transactions on Image Processing 19, 11, 2983--2999.", "Christopher J. C. Burges. 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery 2, 2, 121--167.", "Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yantao Zheng. 2009. NUS-WIDE: A real-world web image database from National University of Singapore. In Proceedings of the ACM International Conference on Image and Video Retrieval. ACM, 48.", "Ritendra Datta, Jia Li, and James Z. Wang. 2005. Content-based image retrieval: Approaches and trends of the new age. In Proceedings of the 7th ACM SIGMM International Workshop on Multimedia Information Retrieval. ACM, 253--262.", "Christos Diou, George Stephanopoulos, Panagiotis Panagiotopoulos, Christos Papachristou, Nikos Dimitriou, and Anastasios Delopoulos. 2010. Large-scale concept detection in multimedia data using small training sets and cross-domain concept fusion. IEEE Transactions on Circuits and Systems for Video Technology 20, 12, 1808--1821.", "Ralph Ewerth, Khalid Ballafkir, M. Muhling, Dominik Seiler, and Bernd Freisleben. 2012. Long-term incremental web-supervised learning of visual concepts via random savannas. IEEE Transactions on Multimedia 14, 4, 1008--1020.", "Amirhossein Habibian and Cees G. M. Snoek. 2014. Recommendations for recognizing video events by concept vocabularies. Computer Vision and Image Understanding 124, 110--122.", "Mark J. Huiskes and Michael S. Lew. 2008. The MIR flickr retrieval evaluation. In Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval. ACM, 39--43.", "Mark J. Huiskes, Bart Thomee, and Michael S. Lew. 2010. New trends and ideas in visual concept detection: The MIR flickr retrieval evaluation initiative. In Proceedings of the International Conference on Multimedia Information Retrieval. ACM, 527--536.", "Yu-Gang Jiang, Chong-Wah Ngo, and Jun Yang. 2007. Towards optimal bag-of-features for object categorization and semantic video retrieval. In Proceedings of the 6th ACM International Conference on Image and Video Retrieval. ACM, 494--501.", "Yu-Gang Jiang, Jun Yang, Chong-Wah Ngo, and Alexander G. Hauptmann. 2010. Representations of keypoint-based semantic concept detection: A comprehensive study. IEEE Transactions on Multimedia 12, 1, 42--53.", "Xue-Ming Leng and Yi-Ding Wang. 2008. Gender classification based on fuzzy SVM. In Proceedings of the 2008 International Conference on Machine Learning and Cybernetics, Vol. 3. IEEE, 1260--1264.", "Han-Xiong Li, Jing-Lin Yang, Geng Zhang, and Bi Fan. 2013. Probabilistic support vector machines for classification of noise affected data. Information Sciences 221, 60--71.", "Chun-Fu Lin and Sheng-De Wang. 2002. Fuzzy support vector machines. IEEE Transactions on Neural Networks 13, 2, 464--471.", "Chun-fu Lin and Sheng-de Wang. 2004. Training algorithms for fuzzy support vector machines with noisy data. Pattern Recognition Letters 25, 14, 1647--1656."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790230"}, {"title": "Multi-Emotion Estimation in Narratives from Crowdsourced Annotations", "authors": ["Lei Duan\n,", "Satoshi Oyama\n,", "Haruhiko Sato\n,", "Masahito Kurihara"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nEmotion annotations are important metadata for narrative texts in digital libraries. Such annotations are necessary for automatic text-to-speech conversion of narratives and affective education support and can be used as training data for machine learning algorithms to train automatic emotion detectors. However, obtaining high-quality emotion annotations is a challenging problem because it is usually expensive and time-consuming due to the subjectivity of emotion. Moreover, due to the multiplicity of \"emotion\", emotion annotations more naturally fit the paradigm of multi-label classification than that of multi-class classification since one instance (such as a sentence) may evoke a combination of multiple emotion categories. We thus investigated ways to obtain a set of high-quality emotion annotations ({instance, multi-emotion} paired data) from variable-quality crowdsourced annotations. A common quality control strategy for crowdsourced labeling tasks is to aggregate the responses provided by multiple annotators to produce a reliable annotation. Given that the categories of \"emotion\" have characteristics different from those of other kinds of labels, we propose incorporating domain-specific information of emotional consistencies across instances and contextual cues among emotion categories into the aggregation process. Experimental results demonstrate that, from a limited number of crowdsourced annotations, the proposed models enable gold standards to be more effectively estimated than the majority vote and the original domain-independent model.", "references": ["C. O. Alm. Characteristics of high agreement affect annotation in text. In Proceedings of the Fourth Linguistic Annotation Workshop (LAW), pages 118--122. Association for Computational Linguistics, 2010.", "C. O. Alm, D. Roth, and R. Sproat. Emotions from text: Machine learning for text-based emotion prediction. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 579--586. Association for Computational Linguistics, 2005.", "L. F. Barrett, B. Mesquita, K. N. Ochsner, and J. J. Gross. The experience of emotion. Annual Review of Psychology, 58:373, 2007.", "K. Bischoff, C. S. Firan, W. Nejdl, and R. Paiu. How do you feel about dancing queen?: deriving mood & theme annotations from user tags. In Proceedings of the 9th ACM/IEEE-CS Joint Conference on Digital libraries, pages 285--294. ACM, 2009.", "R. A. Calvo and S. D'Mello. Affect detection: An interdisciplinary review of models, methods, and their applications. Affective Computing, IEEE Transactions on, 1(1):18--37, 2010.", "C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. Information Theory, IEEE Transactions on, 14(3):462--467, 1968.", "A. P. Dawid and A. M. Skene. Maximum likelihood estimation of observer error-rates using the em algorithm. Applied Statistics, pages 20--28, 1979.", "M. d. R. D. Dias, S. d. S. B. L. d. Faria, S. C. M. Ibrahim, et al. I'm like a river: a health education instrument for stuttering. Revista de Psicologia da IMED, 5(2), 2013.", "P. Donmez, J. G. Carbonell, and J. Schneider. Efficiently learning the accuracy of labeling sources for selective sampling. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 259--268. ACM, 2009.", "L. Duan, S. Oyama, H. Sato, and M. Kurihara. Separate or joint? estimation of multiple labels from crowdsourced annotations. Expert Systems with Applications, 41(13):5723--5732, 2014.", "P. Ekman. An argument for basic emotions. Cognition & Emotion, 6(3-4):169--200, 1992.", "S. Ertekin, C. Rudin, and H. Hirsh. Approximating the crowd.", "J. Howe. Crowdsourcing: A definition. Crowdsourcing: Tracking the Rise of the Mmateur, 2006.", "X. Hu and J. S. Downie. Improving mood classification in music digital libraries by combining lyrics and audio. In Proceedings of the 10th annual Joint Conference on Digital libraries, pages 159--168. ACM, 2010.", "S. Kim, F. Li, G. Lebanon, and I. Essa. Beyond sentiment: The manifold of human emotions. International Conference on Artificial Intelligence and Statistics (AISTATS), pages 360--369, 2013.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756910"}, {"title": "Social Personal Data Stores: the Nuclei of Decentralised Social Machines", "authors": ["Max Van Kleek\n,", "Daniel A. Smith\n,", "Dave Murray-Rust\n,", "Amy Guy\n,", "Kieron O'Hara\n,", "Laura Dragan\n,", "Nigel R. Shadbolt"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nPersonal Data Stores are among the many efforts that are currently underway to try to re-decentralise the Web, and to bring more control and data management and storage capability under the control of the user. Few of these architectures, however, have considered the needs of supporting decentralised social software from the user's perspective. In this short paper, we present the results of our design exercise, focusing on two key design needs for building decentralised social machines: that of supporting heterogeneous social apps and multiple, separable user identities. We then present the technical design of a prototype social machine platform, INDX, which realises both of these requirements, and a prototype heterogeneous microblogging application which demonstrates its capabilities.", "references": ["R. Bendrath and M. Mueller. The end of the net as we know it? deep packet inspection and internet governance. New Media & Society, 13(7):1142--1160, 2011.", "D. Brickley and L. Miller. Foaf vocabulary specification 0.98. Namespace document, 9, 2012.", "P. A. Champin and A. Passant. Sioc in action representing the dynamics of online communities. In Proceedings of the 6th International Conference on Semantic Systems, page 12. ACM, 2010.", "L. Clark. Tim berners-lee: we need to re-decentralise the web, 2014.", "R. T. G. Collins. Privacy implications of deep packet inspection technology: Why the next wave in online advertising shouldn't rock the self-regulatory boat, the. Ga. L. Rev., 44:545, 2009.", "R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-generation onion router. Technical report, DTIC Document, 2004.", "W. Heath, D. Alexander, and P. Booth. Digital enlightenment, mydex, and restoring control over personal data to the individual. In Digital Enlightenment Forum Yearbook 2013: The Value of Personal Data, pages 253--269, 2013.", "J. Hendler and T. Berners-Lee. From the semantic web to social machines: A research challenge for ai on the world wide web. Artificial Intelligence, 174(2):156--161, 2010.", "B. Kersey. The troubled history behind diaspora, the$200,000 facebook killer launched on kickstarter, 2012.", "M. V. Kleek, D. Murray-Rust, A. Guy, D. A. Smith, and N. Shadbolt. Self curation, social partitioning, escaping from prejudice and harassment: the many dimensions of lying online. Jan 2015.", "A. E. Marwick et al. I tweet honestly, i tweet passionately: Twitter users, context collapse, and the imagined audience. New media & society, 13(1):114--133, 2011.", "N. Mott. The era of third-party apps is ending, as security risks prompt whatsapp and snapchat to shut down their apis, 01 2015.", "D. Murray-Rust, M. Van Kleek, L. Dragan, and N. Shadbolt. Social palimpsests--clouding the lens of the personal panopticon. 2014.", "J. J. W. Presbrey. Linked data platform for web applications. PhD thesis, Massachusetts Institute of Technology, 2014.", "L. Ross and R. E. Nisbett. The person and the situation. T. Nadelhoffer, E. Nahmias, & S. Nichols, Moral psychology: Historical and contemporary readings, pages 187--196, 2010.", "P. Saint-Andre. Streaming xml with jabber/xmpp. Internet Computing, IEEE, 9(5):82--89, 2005.", "A. V. Sambra, S. Hawke, T. Berners-Lee, L. Kagal, and A. Aboulnaga. Cimba-client-integrated microblogging architecture.", "M. Sporny, G. Kellogg, and M. Lanthaler. Json-ld 1.0-a json-based serialization for linked data. W3C Working Draft, 2013.", "M. Van Kleek and K. OHara. The future of social is personal: The potential of the personal data store. In Social Collective Intelligence, pages 125--158. Springer, 2014.", "M. Van Kleek, D. A. Smith, N. Shadbolt, et al. A decentralized architecture for consolidating personal information ecosystems: The webbox. 2012.", "M. Van Kleek, D. A. Smith, R. Tinati, K. O'Hara, W. Hall, and N. R. Shadbolt. 7 billion home telescopes: observing social machines through personal data stores. In Proceedings of the companion publication of the 23rd international conference on World wide web companion, pages 915--920. International World Wide Web Conferences Steering Committee, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743975"}, {"title": "It is not What but Who you Know: A Time-Sensitive Collaboration Impact Measure of Researchers in Surrounding Communities", "authors": ["Luigi Di Caro\n,", "Mario Cataldi\n,", "Myriam Lamolle\n,", "Claudio Schifanella"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn the last decades, many measures and metrics have been proposed with the goal of automatically providing quantitative rather than qualitative indications over researchers' academic productions. However, when evaluating a researcher, most of the commonly-applied measures do not consider one of the key aspect of every research work: the collaborations among researchers and, more specifically, the impact that each co-author has on the scientific production of another. In fact, in an evaluation process, some co-authored works can unconditionally favor researchers working in competitive research environments surrounded by experts able to lead high-quality research projects, where state-of-the-art measures usually fail in trying to distinguish co-authors from their pure publication history. In the light of this, instead of focusing on a pure quantitative/qualitative evaluation of curricula, we propose a novel temporal model for formalizing and estimating the dependence of a researcher on individual collaborations, over time, in surrounding communities. We then implemented and evaluated our model with a set of experiments on real case scenarios and through an extensive user study.", "references": ["M. Ausloos. A scientometrics law about co-authors and their ranking: the co-author core. Scientometrics, 95(3):895--909, 2013.", "L. D. Caro, M. Cataldi, and C. Schifanella. The d-index: Discovering dependences among scientific collaborators from their bibliographic data records. Scientometrics, 93(3):583--607, 2012.", "C. P. Dancey and J. Reidy. Statistics without maths for psychology. Pearson Education, 2007.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742023"}, {"title": "The Uncertain Web: Concepts, Challenges, and Current Solutions", "authors": ["Djamal Benslimane\n,", "Quan Z. Sheng\n,", "Mahmoud Barhamgi\n,", "Henri Prade"], "publication": "ACM Transactions on Internet Technology", "abstract": "", "references": ["Serge Abiteboul, Paris Kanellakis, and Gosta Grahne. 1987. On the representation and querying of sets of possible worlds. SIGMOD Record 16, 3, 34--48.", "Salem Benferhat and Zied Bouraoui. 2013. Possibilistic DL-Lite. In Proceedings of the 7th International Conference on Scalable Uncertainty Management (SUM’13), Weiru Liu, V. S. Subrahmanian, and J. Wijsen (Eds.), Lecture Notes in Computer Science, Vol. 8078, Springer, Berlin, 346--359.", "Patrick Bosc and Olivier Pivert. 2010. Modeling and querying uncertain relational databases: A survey of approaches based on the possible worlds semantics. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 18, 5, 565--603.", "Nilesh Dalvi and Dan Suciu. 2007. Efficient query evaluation on probabilistic databases. The VLDB Journal 16, 4, 523--544.", "Xin Luna Dong, Alon Y. Halevy, and Cong Yu. 2009. Data integration with uncertainty. The VLDB Journal 18, 2, 469--500.", "Avigdor Gal and Pavel Shvaiko. 2009. Advances in ontology matching. In: T. S. Dillon, E. Chang, R. Meersman, K. P. Sycara (Eds.), Advances in Web Semantics I -- Ontologies, Web Services and Applied Semantic Web. Lecture Notes in Computer Science, Vol. 4891, Springer, Berlin, 176--198.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2847252"}, {"title": "SAM: Dynamic and Social Content Delivery for Second Screen Interaction", "authors": ["Atta Badii\n,", "Marco Tiemann\n,", "Andreas Menychtas\n,", "Christina Santzaridou\n,", "Alexandros Psychas\n,", "David Tomas\n,", "Stuart Campbell\n,", "Juan Vicente Vidagany Espert"], "publication": "TVX '15: Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video", "abstract": "ABSTRACT\nSocial media services offer a wide range of opportunities for businesses and developers to exploit the vast amount of information and user-generated content produced via social media. In addition, the notion of TV second screen usage -- the interleaved usage of TV and smart devices such as smartphones -- appears ever more prominent, with viewers continuously seeking further information and deeper engagement while watching movies, TV shows or event coverage. In this work-in-progress contribution, we present SAM, an innovative platform that combines social media, content syndication and targets second screen usage to enhance media content provisioning and advance the user experience. SAM incorporates modern technologies and novel features in the areas of content management, dynamic social media, social mining, semantic annotation and multi-device representation to facilitate an advanced business environment for broadcasters, content and metadata providers and editors to better exploit their assets and increase revenues.", "references": ["Second Screen Society. 2014. Second Screen Journal - Advancing the mobile viewing experience. Second Screen Society. Retrieved February 26, 2015 from http://www.2ndscreensociety.com/", "C. Courtois and E. D'heer. 2012. Second screen applications and tablet users: constellation, awareness, experience, and interest. In Proceedings of the 10th European Conference on Interactive TV and Video, 153--156.", "E. Tsekleves, L. Cruickshank, A. Hill, K. Kondo and R. Witham. 2007. Interacting with digital media at home via second screen. In Proceedings of the 9th IEEE International Symposium, 201--206.", "SAM EU Research Project. 2015. Retrieved February 26, 2015 from http://socialisingaroundmedia.com/", "N. Heino, S. Tramp and S. Auer. 2011. Managing web content using linked data principles-combining semantic structure with dynamic content syndication. In Proceedings of the Conference on Computer Software and Applications (COMPSAC), 245--250.", "TIE Kinetix. 2015. TIE Kinetix Website. Retrieved February 26, 2015 from http://tiekinetix.com/", "Zift. 2015. Content Syndication: Zift Solutions. Retrieved February 26, 2015 from http://www.ziftsolutions.com/products/contentsyndication/", "Web Collage. 2015. Web Collage. Retrieved February 26, 2015 from http://www.webcollage.com/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745197.2755511"}, {"title": "The Concentric Nature of News Semantic Snapshots: Knowledge Extraction for Semantic Annotation of News Items", "authors": ["José Luis Redondo García\n,", "Giuseppe Rizzo\n,", "Raphaël Troncy"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nThe Web enables to have access to silo-ed information describing news articles, often offering a multitude of viewpoints that, once combined, can provide a broader picture of the story being reported on the news. In this paper, we propose an approach that automatically extracts representative features of a news item, namely named entities, from textual content attached to a video item (subtitles) and from a set of documents from the Web collected using entity expansion techniques. Approaches relying on entity expansion generally try to collect and process the important facts behinds a particular news item, but they are often too dependent on frequency-based functions and information retrieval techniques thus neglecting the multi-dimensional relationships that are established among the entities. We propose a concentric-based approach that enables to represent the context of a news item, by harmonizing into a single model the representative entities, which can be extracted using information retrieval and natural language processing techniques (Core), and other entities that get prominent according to different dimensions such as informativeness, semantic connectivity, or popularity (Crust). We compare our approach with a baseline by analyzing the compactness of the generated summary on an existing gold standard available on the Web. Results of the experiments show that our approach converges faster to the ideal compact news snapshot with an improvement of 36.9% over the baseline.", "references": ["S. Chhabra. Entity-centric Summarization: Generating Text Summaries for Graph Snippets. In 23rd ACM International Conference on World Wide Web (WWW), pages 33--38, Seoul, Korea, 2014.", "W. B. Croft, D. Metzler, and T. Strohman. Search engines: Information retrieval in practice. Addison-Wesley Reading, 2010.", "L. De Vocht, S. Coppens, R. Verborgh, M. Vander Sande, E. Mannens, and R. Van de Walle. Discovering Meaningful Connections between Resources in the Web of Data. In 6th International Workshop on Linked Data on the Web (LDOW), 2013.", "N. Fernandez, J. A. Fisteus, L. Sanchez, and G. Lopez. IdentityRank: Named entity disambiguation in the news domain. Expert Systems with Applications, 39(10):9207--9221, 2012.", "Y. Li, G. Rizzo, J. L. Redondo Garcia, and R. Troncy. Enriching media fragments with named entities for video classification. In 1st Worldwide Web Workshop on Linked Media (LIME), Rio de Janeiro, Brazil, 2013.", "J. L. Moore, F. Steinke, and V. Tresp. A novel metric for information retrieval in semantic networks. In 3rd International Workshop on Inductive Reasoning and Machine Learning for the Semantic Web (IRMLeS), pages 65--79, 2011.", "L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: bringing order to the web. Technical report, Stanford InfoLab, 1999.", "J. L. Redondo García, L. De Vocht, R. Troncy, E. Mannens, and R. Van de Walle. Describing and Contextualizing Events in TV News Show. In 2nd International Workshop on Social News on the Web (SNOW), pages 759--764, Seoul, Korea, 2014.", "J. L. Redondo García, M. Hildebrand, L. Romero, and R. Troncy. Augmenting TV Newscasts via Entity Expansion. In 11th Extended Semantic Web Conference (ESWC), pages 472--476, 2014.", "J. L. Redondo García, G. Rizzo, L. Perez Romero, M. Hildebrand, and R. Troncy. Generating the Semantic Snapshot of Newscasts using Entity Expansion. In 15th International Conference on Web Engineering (ICWE), 2015.", "G. Rizzo, M. van Erp, and R. Troncy. Benchmarking the Extraction and Disambiguation of Named Entities on the Semantic Web. In 9th International Conference on Language Resources and Evaluation (LREC), Reykjavik, Iceland, 2014.", "N. K. Tran, A. Ceroni, N. Kanhabua, and C. Niederée. Back to the Past: Supporting Interpretations of Forgotten Stories by Time-aware Re-Contextualization. In 8th ACM International Conference on Web Search and Data Mining, pages 339--348, Shanghai, China, 2015.", "N. K. Tran, A. Ceroni, N. Kanhabua, and C. Niederée. Time-travel Translator: Automatically Contextualizing News Articles. In 24th ACM International World Wide Web Conference (WWW), pages 247--250, Florence, Italy, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815836"}, {"title": "Reliable diversity-based spatial crowdsourcing by moving workers", "authors": ["Peng Cheng\n,", "Xiang Lian\n,", "Zhao Chen\n,", "Rui Fu\n,", "Lei Chen\n,", "Jinsong Han\n,", "Jizhong Zhao"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith the rapid development of mobile devices and the crowdsourcing platforms, the spatial crowdsourcing has attracted much attention from the database community, specifically, spatial crowdsourcing refers to sending a location-based request to workers according to their positions. In this paper, we consider an important spatial crowdsourcing problem, namely reliable diversity-based spatial crowdsourcing (RDB-SC), in which spatial tasks (such as taking videos/photos of a landmark or firework shows, and checking whether or not parking spaces are available) are time-constrained, and workers are moving towards some directions. Our RDB-SC problem is to assign workers to spatial tasks such that the completion reliability and the spatial/temporal diversities of spatial tasks are maximized. We prove that the RDB-SC problem is NP-hard and intractable. Thus, we propose three effective approximation approaches, including greedy, sampling, and divide-and-conquer algorithms. In order to improve the efficiency, we also design an effective cost-model-based index, which can dynamically maintain moving workers and spatial tasks with low cost, and efficiently facilitate the retrieval of RDB-SC answers. Through extensive experiments, we demonstrate the efficiency and effectiveness of our proposed approaches over both real and synthetic datasets.", "references": ["https://www.google.com/maps/views/streetview.", "http://mediaqv3.cloudapp.net/MediaQ_MVC_V3/.", "https://foursquare.com.", "https://www.google.com/maps/views/streetview.", "http://mediaqv3.cloudapp.net/MediaQ_MVC_V3/.", "https://foursquare.com.", "https://www.waze.com.", "https://www.mturk.com/mturk/welcome.", "http://arxiv.org/abs/1412.0223.", "http://www.gmissionhkust.com.", "http://youtu.be/FfNoeqFc084.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794372"}, {"title": "Analysis of Scientific Collaboration Network as a Management Tool for Graduate Programs", "authors": ["Aurelio Ribeiro Costa\n,", "Celia Ghedini Ralha"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe performance of a graduate program is assessed by CAPES partly by their level of publication. Therefore, it is necessary that the program chair has instruments to analyze the quality of publication produced by the associated researchers. In the context of co-authoring relationships in publications, network analysis has been proved to be an appropriate tool to evaluate the relationships already formed, and to stimulate the formation of new relationships. This paper presents a network analysis tool applied to real data of a graduate program from a Brazilian Federal University. The data was modeled in a NoSQL graph oriented database including all associated researchers' publication. We emphasize the usefulness of the partners' recommendation module to the program chair, as well as associated researchers. The development of this research work used the Design Science Research methodology to guide both the construction of the artfact and the associated documentation. Preliminary, using data from a graduate program, we can note the recommendation potential to integrate new partners to the scientific network already formed.", "references": ["Hector N. Melo, Ruben A. Perorazio, and Jonice Oliveira. Ambiente analítico web para análise da colaboração científica no cenário médico. X Simpósio Brasileiro de Sistemas de Informação (SBSI), 2014.", "Mathieu Bastian, Sebastien Heymann, and Mathieu Jacomy. Gephi: An open source software for exploring and manipulating networks. 2009.", "Edeilson M. Silva, Ricardo A. Costa, Mario Godoy Neto, Robson Y. S. Oliveira, and Silvio R. L. Meira. Promovendo melhorias na comunicação e colaboração em uma plataforma de gestão de conhecimento através de recomendações. V Simpósio Brasileiro de Sistemas de Informação (SBSI), 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814103"}, {"title": "Machine-interpretable dataset and service descriptions for heterogeneous data access and retrieval", "authors": ["Anastasia Dimou\n,", "Ruben Verborgh\n,", "Miel Vander Sande\n,", "Erik Mannens\n,", "Rik Van de Walle"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nThe rdf data model allows the description of domain-level knowledge that is understandable by both humans and machines. rdf data can be derived from different source formats and diverse access points, ranging from databases or files in csv format to data retrieved from Web apis in json, Web Services in xml or any other speciality formats. To this end, machine-interpretable mapping languages, such as rml, were introduced to uniformly define how data in multiple heterogeneous sources is mapped to the rdf data model, independently of their original format. However, the way in which this data is accessed and retrieved still remains hard-coded, as corresponding descriptions are often not available or not taken into account. In this paper, we introduce an approach that takes advantage of widely-accepted vocabularies, originally used to advertise services or datasets, such as Hydra or dcat, to define how to access Web-based or other data sources. Consequently, the generation of rdf representations is facilitated and further automated, while the machine-interpretable descriptions of the connectivity to the original data remain independent and interoperable, offering a granular solution for accessing and mapping data.", "references": ["K. Alexander, R. Cyganiak, M. Hausenblas, and J. Zhao. Describing Linked Datasets with the VoID Vocabulary. W3C Interest Group Note, Mar. 2011. http://www.w3.org/TR/void/.", "S. Auer, S. Dietzold, J. Lehmann, S. Hellmann, and D. Aumueller. Triplify: Light-weight Linked Data Publication from Relational Databases. In Proceedings of the 18th International Conference on World Wide Web, WWW '09. ACM, 2009.", "T. Berners-Lee, J. Hendler, and O. Lassila. The Semantic Web. Scientific American, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814873"}, {"title": "An Improved Web Page Recommendation System Using Partitioning and Web Usage Mining", "authors": ["Jyotsna Chanda\n,", "B. Annappa"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nThere are different types of hypertext documents available on the Internet. Accessing relevant information and serving useful information to the user from the Internet has become a complex and expensive task. To make this process simpler, one of the widely used recommendation systems is item based collaborative filtering recommendation system which predicts web pages based on the browsing activity of the user on the Internet and recommends web pages as per their interests. There are certain challenges in these systems like sparsity and scalability, the proposed approach overcomes these problems. The proposed approach uses weighted k-mean clustering instead of simple k-mean clustering and the obtained clusters are partitioned on the basis of similarity which helps in reducing the processing time of recommendation generation. Clustering and partitioning enhances the existing item based collaborative filtering recommendation system. The MovieLens data set is used for demonstrating the proposed approach. The performance of the proposed approach is evaluated using various metrics. The result shows that the proposed approach is 30% efficient in terms of root mean square error and 21% effective in respect of mean absolute error analysis and the accuracy measures factors like precision, recall and F-measure are found to have higher values than the existing item based collaborative filtering recommendation systems.", "references": ["B. Mobasher. Web usage mining. Web data mining: Exploring hyperlinks, contents and usage data, 12, 2006.", "S. G. Walunj and K. Sadafale. An online recommendation system for e-commerce based on apache mahout framework. In Proceedings of the 2013 annual conference on Computers and people research, pages 153--158. ACM, 2013.", "K. Verbert, H. Drachsler, N. Manouselis, M. Wolpers, R. Vuorikari, and E. Duval. Dataset-driven research for improving recommender systems for learning. In Proceedings of the 1st International Conference on Learning Analytics and Knowledge, pages 44--53. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816910"}, {"title": "k-regret queries with nonlinear utilities", "authors": ["Taylor Kessler Faulkner\n,", "Will Brackenbury\n,", "Ashwin Lall"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn exploring representative databases, a primary issue has been finding accurate models of user preferences. Given this, our work generalizes the method of regret minimization as proposed by Nanongkai et al. to include nonlinear utility functions. Regret minimization is an approach for selecting k representative points from a database such that every user's ideal point in the entire database is similar to one of the k points. This approach combines benefits of the methods top-k and skyline; it controls the size of the output but does not require knowledge of users' preferences. Prior work with k-regret queries assumes users' preferences to be modeled by linear utility functions. In this paper, we derive upper and lower bounds for nonlinear utility functions, as these functions can better fit occurrences such as diminishing marginal returns, propensity for risk, and substitutability of preferences. To model these phenomena, we analyze a broad subset of convex, concave, and constant elasticity of substitution functions. We also run simulations on real and synthetic data to prove the efficacy of our bounds in practice.", "references": ["O. Barndorff-Nielsen and M. Sobel. On the distribution of the number of admissible points in a vector random sample. Theory of Probability and its Applications, 11(2):249--269, 1966.", "S. Börzsönyi, D. Kossmann, and K. Stocker. The skyline operator. In ICDE, 2001.", "I. Catallo, E. Ciceri, P. Fraternali, D. Martinenghi, and M. Tagliasacchi. Top-k diversity queries over bounded regions. ACM Transactions on Database Systems (TODS), 38(2):10, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2831360.2831364"}, {"title": "Online Recommender Systems based on Data Stream Management Systems", "authors": ["Cornelius A. Ludmann"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this paper, I present a novel approach for implementing a stream-based Recommender System (RecSys). I propose to add RecSys operators to an application-independent Data Stream Management System (DSMS) to allow writing continuous queries over data streams that calculate personalized sets of recommendations. That empowers RecSys providers to create a custom RecSys by writing queries in a declarative query language. This approach ensures a flexible and extendable usage of RecSys functions in different settings and benefits from matured features of DSMSs.", "references": ["M. Ali, C. C. Johnson, and A. K. Tang. Parallel collaborative filtering for streaming data. University of Texas Austin, Tech. Rep, 2011.", "H.-J. Appelrath, D. Geesen, M. Grawunder, T. Michelsen, and D. Nicklas. Odysseus: A highly customizable framework for creating efficient event stream management systems. In DEBS'12, pages 367--368. ACM, 2012.", "A. Arasu, S. Babu, and J. Widom. The CQL continuous query language: semantic foundations and query execution. VLDB Journal, 15(2):121--142, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796544"}, {"title": "Searcher in a Strange Land: Understanding Web Search from Familiar and Unfamiliar Locations", "authors": ["Elad Kravi\n,", "Eugene Agichtein\n,", "Ido Guy\n,", "Yaron Kanza\n,", "Avihai Mejer\n,", "Dan Pelleg"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWith mobile devices, web search is no longer limited to specific locations. People conduct search from practically anywhere, including at home, at work, when traveling and when on vacation. How should this influence search tools and web services? In this paper, we argue that information needs are affected by the familiarity of the environment. To formalize this idea, we propose a new contextualization model for activities on the web. The model distinguishes between a search from a familiar place (F-search) and a search from an unfamiliar place (U-search). We formalize the notion of familiarity, and propose a method to identify familiar places. An analysis of a query log of millions of users, demonstrates the differences between search activities in familiar and in unfamiliar locations. Our novel take on search contextualization has the potential to improve web applications, such as query autocompletion and search personalization.", "references": ["P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz. Inferring and using location metadata to personalize web search. In Proc. of SIGIR, 2011.", "K. Church and B. Smyth. Understanding the Intent Behind Mobile Information Needs. In International Conf. on Intelligent User Interfaces, 2009.", "M. Kamvar and S. Baluja. A Large Scale Study of Wireless Search Behavior: Google Mobile Search. In Proc. of SIGCHI, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767782"}, {"title": "Fusing Pointwise and Pairwise Labels for Supporting User-adaptive Image Retrieval", "authors": ["Lin Chen\n,", "Peng Zhang\n,", "Baoxin Li"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nUser-adaptive image retrieval/recommendation has drawn a lot of research interests in recent years, owing to fast development of various Web applications where retrieving images is a key enabling task. Existing challenges include the lack of user-adaptive training data, the ambiguity of user query and the real-time interactivity of a system. This paper proposes a hybrid learning strategy that fuses knowledge from both pointwise and pairwise training data into one framework for attribute-based, user-adaptive image retrieval. Under this framework, we develop an online learning algorithm for updating the ranking performance based on user feedback. Furthermore, we derive the framework into a kernel form, allowing easy application of kernel techniques. The proposed approach is evaluated on two image datasets and experimental results show that it achieves obvious performance gains over ranking and zero-shot learning from either type of training data independently. In addition, the online learning algorithm is able to deliver much better performance than batch learning, given the same elapsed running time, or can achieve better performance in much less time.", "references": ["T. L. Berg, A. C. Berg, and J. Shih. Automatic attribute discovery and characterization from noisy web data. In Proc. of ECCV'10, pages 663--676, Berlin, Heidelberg, 2010. Springer-Verlag.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proc. of ICML '05, pages 89--96. ACM, 2005.", "Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang, and H.-W. Hon. Adapting ranking svm to document retrieval. In Proc. of SIGIR '06, pages 186--193. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749358"}, {"title": "The Role of User Location in Personalized Search and Recommendation", "authors": ["Ido Guy"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWith mobile devices, users no longer access the web from specific locations, but virtually from anywhere. How does this affect our ability to provide personalized information for users' In this talk, I will discuss the influence of location activity on users' information needs and how a better understanding of these needs can help enhance web applications in which personalization plays a central role.", "references": ["Guy, I., Avraham, U., Carmel, D., Ur, S., Jacovi, M., and Ronen, I. 2013. Mining expertise and interests from social media. Proc. WWW '13, 515--526.", "Guy, I., Hashavit, A., and Corem, Y. 2015. Games for crowds: A crowdsourcing game platform for the enterprise. Proc. CSCW '15, 1860--1871.", "Guy, I., Levin, R., Daniel, T., and Bolshinsky, E. 2015. Islands in the Stream: A study of item recommendation within an enterprise social stream. Proc. SIGIR '15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799502"}, {"title": "Controversy Detection and Stance Analysis", "authors": ["Shiri Dori-Hacohen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAlerting users about controversial search results can encourage critical literacy, promote healthy civic discourse and counteract the \"filter bubble\" effect. Additionally, presenting information to the user about the different stances or sides of the debate can help her navigate the landscape of search results. Our existing work made strides in the emerging niche of controversy detection and analysis; we propose further work on automatic stance detection.", "references": ["R. Awadallah, M. Ramanath, and G. Weikum. Harmony and Dissonance: Organizing the People's Voices on Political Controversies. Proc. WSDM, 2012.", "S. Das and A. Lavoie. Automated inference of point of view from user interactions in collective intelligence venues. In Workshop on Social Computing and User Generated Content, EC 2013.", "S. Dori-Hacohen and J. Allan. Detecting controversy on the web. In Proc. CIKM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767844"}, {"title": "How to design and build new musical interfaces", "authors": ["Michael Lyons\n,", "Sidney Fels"], "publication": "SA '15: SIGGRAPH Asia 2015 Courses", "abstract": "ABSTRACT\nNo abstract available.", "references": ["{Poupyrev et al. 2001} New interfaces for musical expression. Extended Abstracts, CHI-2001, ACM Conference on Human Factors in Computing Systems, pp. 309--310.", "{Wanderley & Battier, 2000} Wanderley, M. and Battier, M. 2000. Trends in gestural control of music, IRCAM.", "{Miranda & Wanderley, 2006} Miranda, E. R. and Wanderley, M. M. 2006. New digital musical instruments: control and interaction beyond the keyboard. AR Editions."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818143.2818145"}, {"title": "An Optimization Framework for Weighting Implicit Relevance Labels for Personalized Web Search", "authors": ["Yury Ustinovskiy\n,", "Gleb Gusev\n,", "Pavel Serdyukov"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nImplicit feedback from users of a web search engine is an essential source providing consistent personal relevance labels from the actual population of users. However, previous studies on personalized search employ this source in a rather straightforward manner. Basically, documents that were clicked on get maximal gain, and the rest of the documents are assigned the zero gain. As we demonstrate in our paper, a ranking algorithm trained using these gains directly as the ground truth relevance labels leads to a suboptimal personalized ranking.\nIn this paper we develop a framework for automatic reweighting of these labels. Our approach is based on more subtle aspects of user interaction with the result page. We propose an efficient methodology for deriving confidence levels for relevance labels that relies directly on the objective ranking measure. All our algorithms are evaluated on a large-scale query log provided by a major commercial search engine. The results of the experiments prove that the current state-of-the-art personalization approaches could be significantly improved by enriching relevance grades with weights extracted from post-impression user behavior.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, pages 19--26, New York, NY, USA, 2006. ACM.", "A. Aitken. On least squares and linear combination of observations. volume 55 of Proc. R. Soc. Edinb, pages 42--48, 1934.", "P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz. Inferring and using location metadata to personalize web search. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '11, pages 135--144, New York, NY, USA, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741105"}, {"title": "Multi-source Information Fusion for Personalized Restaurant Recommendation", "authors": ["Jing Sun\n,", "Yun Xiong\n,", "Yangyong Zhu\n,", "Junming Liu\n,", "Chu Guan\n,", "Hui Xiong"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we study the problem of personalized restaurant recommendations. Specifically, we develop a probabilistic factor analysis framework, named RMSQ-MF, which has the ability in exploiting multi-source information, such as the users' task, their friends' preferences, and human mobility patterns, for personalized restaurant recommendations. The rationale of this work is motivated by two observations. First, people's preferences can be affected by their friends. Second, human mobility patterns can reflect the popularity of restaurants to a certain degree. Finally, empirical studies on real-world data demonstrate that the proposed method outperforms benchmark methods with a significant margin.", "references": ["D.D.Lee and H. Seung. Algorithms for non-negative matrix factorization. In Advances in Neural Information Processing Systems, 20:1257--1264, 2001.", "F.Yanjie, L.Bin, G.Yong, and X.Hui. User preference learning with multiple information fusion for restaurant recommendation. In SDM2014 Conference Proceedings, pages 470--478, April 2014.", "H.H.Lee and G.W.Teng. Incorporating multi-criteria ratings in recommendation systems. In IRI2007 Conference Proceedings, pages 273--278, August 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767818"}, {"title": "Making the Most of Preference Feedback by Modeling Feature Dependencies", "authors": ["S Chandra Mouli\n,", "Sutanu Chakraborti"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nConversational recommender systems help users navigate through the product space by exploiting feedback. In conversational systems based on preference-based feedback, the user selects the most preferred item from a list of recommended products. Modelling user's preferences then becomes important in order to recommend relevant items. Several existing recommender systems accomplish this by assuming the features to be independent. Here we will attempt to forego this assumption and exploit the dependencies between the features to build a robust user preference model.", "references": ["L. Chen and P. Pu. Preference-based organization interfaces: aiding user critiques in recommender systems. In User Modeling 2007, pages 77--86. Springer, 2007.", "M. R. Hestenes. Multiplier and gradient methods. Journal of optimization theory and applications, 4(5):303--320, 1969.", "L. Mc Ginty and B. Smyth. Evaluating preference-based feedback in recommender systems. In Artificial Intelligence and Cognitive Science, pages 209--214. Springer, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799678"}, {"title": "Identifying Regrettable Messages from Tweets", "authors": ["Lu Zhou\n,", "Wenbo Wang\n,", "Keke Chen"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nInappropriate tweets may cause severe damages on the authors' reputation or privacy. However, many users do not realize the potential damages when publishing such tweets. Published tweets have lasting effects that may not be completely eliminated by simple deletion, because other users may have read them or third-party tweet analysis platforms have cached them. In this paper, we study the problem of identifying regrettable tweets from normal individual users, with the ultimate goal of reducing the occurrences of regrettable tweets. We explore the contents of a set of tweets deleted by sample normal users to understand the regrettable tweets. With a set of features describing the identifiable reasons, we can develop classifiers to effectively distinguish such regrettable tweets from normal tweets.", "references": ["H. Almuhimedi, S. Wilson, B. Liu, N. Sadeh, and A. Acquisti. Tweets are forever: a large-scale quantitative analysis of deleted tweets. In Proceedings of CSCW, pages 897{908. ACM, 2013.", "W. Wang, L. Chen, K. Thirunarayan, and A. P. Sheth. Cursing in english on twitter. In Proceedings of CSCW, pages 415{425. ACM, 2014.", "Y. Wang, G. Norcie, S. Komanduri, A. Acquisti, P. G. Leon, and L. F. Cranor. I regretted the minute i pressed share: A qualitative study of regrets on facebook. In Proceedings of the Symposium on Usable Privacy and Security, page 10. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742735"}, {"title": "Effective, Efficient, and Scalable Unsupervised Distance Learning in Image Retrieval Tasks", "authors": ["Lucas Pascotti Valem\n,", "Daniel Carlos Guimarães Pedronette\n,", "Ricardo da S. Torres\n,", "Edson Borin\n,", "Jurandy Almeida"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nVarious unsupervised learning methods have been proposed with significant improvements in the effectiveness of image search systems. However, despite the relevant effectiveness gains, these approaches commonly require high computation efforts, not addressing properly efficiency and scalability requirements. In this paper, we present a novel unsupervised learning approach for improving the effectiveness of image retrieval tasks. The proposed method is also scalable and efficient as it exploits parallel and heterogeneous computing on CPU and GPU devices. Extensive experiments were conducted considering five different public image collections and several descriptors. This rigorous experimental protocol evaluates the effectiveness, efficiency, and scalability of the proposed approach, and compares it with previous methods. Experimental results demonstrate that high effectiveness gains (up to +29%) can be obtained requiring small run times.", "references": ["J. Almeida, R. da S. Torres, and N. J. Leite. BP-tree: An efficient index for similarity search in high-dimensional metric spaces. In CIKM, pages 1365--1368, 2010.", "J. Almeida, D. C. G. Pedronette, and O. A. B. Penatti. Unsupervised manifold learning for video genre retrieval. In CIARP, pages 604--612, 2014.", "N. Arica and F. T. Y. Vural. BAS: a perceptual shape descriptor based on the beam angle statistics. Pattern Recognition Letters, 24(9-10):1627--1639, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749336"}, {"title": "Topic Modeling in Semantic Space with Keywords", "authors": ["Xiaojia Pu\n,", "Rong Jin\n,", "Gangshan Wu\n,", "Dingyi Han\n,", "Gui-Rong Xue"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA common and convenient approach for user to describe his information need is to provide a set of keywords. Therefore, the technique to understand the need becomes crucial. In this paper, for the information need about a topic or category, we propose a novel method called TDCS(Topic Distilling with Compressive Sensing) for explicit and accurate modeling the topic implied by several keywords. The task is transformed as a topic reconstruction problem in the semantic space with a reasonable intuition that the topic is sparse in the semantic space. The latent semantic space could be mined from documents via unsupervised methods, e.g. LSI. Compressive sensing is leveraged to obtain a sparse representation from only a few keywords. In order to make the distilled topic more robust, an iterative learning approach is adopted. The experiment results show the effectiveness of our method. Moreover, with only a few semantic concepts remained for the topic, our method is efficient for subsequent text mining tasks.", "references": ["M. W. Berry. Large scale sparse singular value computations. International Journal of Supercomputer Applications, 6:13--49, 1992.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "E. J. Candes, J. Romberg, and T. Tao. Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. IEEE Transactions on Information Theory, 52(2):489--509, Feb. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806584"}, {"title": "Important Events in the Past, Present, and Future", "authors": ["Abdalghani Abujabal\n,", "Klaus Berberich"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe address the problem of identifying important events in the past, present, and future from semantically-annotated large-scale document collections. Semantic annotations that we consider are named entities (e.g., persons, locations, organizations) and temporal expressions (e.g., during the 1990s). More specifically, for a given time period of interest, our objective is to identify, rank, and describe important events that happened. Our approach P2F Miner makes use of frequent itemset mining to identify events and group sentences related to them. It uses an information-theoretic measure to rank identified events. For each of them, it selects a representative sentence as a description. Experiments on ClueWeb09 using events listed in Wikipedia year articles as ground truth show that our approach is effective and outperforms a baseline based on statistical language models.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of the Second ACM International Conference on Web Search and Data Mining, pages 5--14. ACM, 2009.", "R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In SIGMOD Conference, pages 207--216, 1993.", "J. Allan. Introduction to topic detection and tracking. In J. Allan, editor, Topic Detection and Tracking, volume 12 of The Information Retrieval Series, pages 1--16. Springer US, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741692"}, {"title": "LSM-Based Storage and Indexing: An Old Idea with Timely Benefits", "authors": ["Sattam Alsubaiee\n,", "Michael J. Carey\n,", "Chen Li"], "publication": "GeoRich'15: Second International ACM Workshop on Managing and Mining Enriched Geo-Spatial Data", "abstract": "ABSTRACT\nWith the social-media data explosion, near real-time queries, particularly those of a spatio-temporal nature, can be challenging. In this paper, we show how to efficiently answer queries that target recent data within very large data sets. We describe a solution that exploits a natural partitioning property that LSM-based indexes have for components, allowing us to filter out many components when answering queries. Our solution is generalizable to any LSM-based index structure, and can be applied not just on temporal fields (e.g., based on recency), but on any \"time-correlated fields\" such as Universally Unique Identifiers (UUIDs), user-provided integer ids, etc. We have implemented and experimentally evaluated the solution in the context of the AsterixDB system.", "references": ["S. Alsubaiee. Spatial Indexing in the Era of Social Media. Ph.D. thesis, UC Irvine, 2014.", "S. Alsubaiee et al. AsterixDB: A scalable, open source BDMS. VLDB, 2014.", "S. Alsubaiee et al. Storage management in AsterixDB. VLDB, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786006.2786007"}, {"title": "Zen and the art of website maintenance", "authors": ["Paul Haimes"], "publication": "Interactions", "abstract": "Abstract\nNo abstract available.", "references": ["Koren, L. Wabi-sabi for Artists, Designers, Poets & Philosophers. Imperfect Pub, 2008.", "Theroux, M. In Search of Wabi-Sabi. British Broadcasting Corporation, London, 2009.", "Cyr, D. and Trevor-Smith, H. Localization of Web design: An empirical comparison of German, Japanese, and United States Web site characteristics. Journal of the American Society for Information Science and Technology 55, 13 (2004), 1199--1208. DOI: 10.1002/asi.20075"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2847596"}, {"title": "A Context-sensitive Metacognitive Conflict Management Approach for Collaborative Systems", "authors": ["Heremita Brasileiro Lira\n,", "Patricia Azevedo Tedesco"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe advent of virtual and dispersed organizations increases the demand for collaborative systems and encourages research in the area of Computer Supported Cooperative Work (CSCW). Conflicts are inherent to collaborative work and can motivate reflection and interaction among stakeholders. However, current approaches to conflict management does not provide mechanisms to stimulate these processes. Moreover, only few use the context in supporting the resolution of the conflict. The aim of this work is to present a Context Sensitive Metacognitive Conflict Management (GCSC) approach for collaborative planning systems that promote reflection and interaction among stakeholders in order to improve collaboration. The approach evaluation was performed by using a prototype implementation of an ontology and an experimental study.", "references": ["Aiken, R. M. et al. 2005. Interaction and Collaboration using an Intelligent Collaborative Learning Environment. Revue Education and Information Technologies, v. 10, p. 65-80.", "Biolchini, J. et al. 2005. A Systematic Review Process to Software Engineering. In: ESELAW05 - Experimental Software Engineering Latin American Workshop, Uberlandia. Proceedings of the ESELAW05, v. 1.", "Brézillon, P. 2007. Context modeling: Task model and model of practices. In: Proc. of the 6th International and Interdisciplinary Conference on Modeling and Using Context (CONTEXT'07), LNAI 4635, p. 122-135, Roskilde."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814104"}, {"title": "One-Pass Ranking Models for Low-Latency Product Recommendations", "authors": ["Antonino Freno\n,", "Martin Saveski\n,", "Rodolphe Jenatton\n,", "Cédric Archambeau"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nPurchase logs collected in e-commerce platforms provide rich information about customer preferences. These logs can be leveraged to improve the quality of product recommendations by feeding them to machine-learned ranking models. However, a variety of deployment constraints limit the naive applicability of machine learning to this problem. First, the amount and the dimensionality of the data make in-memory learning simply not possible. Second, the drift of customers' preference over time require to retrain the ranking model regularly with freshly collected data. This limits the time that is available for training to prohibitively short intervals. Third, ranking in real-time is necessary whenever the query complexity prevents us from caching the predictions. This constraint requires to minimize prediction time (or equivalently maximize the data throughput), which in turn may prevent us from achieving the accuracy necessary in web-scale industrial applications. In this paper, we investigate how the practical challenges faced in this setting can be tackled via an online learning to rank approach. Sparse models will be the key to reduce prediction latency, whereas one-pass stochastic optimization will minimize the training time and restrict the memory footprint. Interestingly, and perhaps surprisingly, extensive experiments show that one-pass learning preserves most of the predictive performance. Additionally, we study a variety of online learning algorithms that enforce sparsity and provide insights to help the practitioner make an informed decision about which approach to pick. We report results on a massive purchase log dataset from the Amazon retail website, as well as on several benchmarks from the LETOR corpus.", "references": ["F. Bach, R. Jenatton, J. Mairal, and G. Obozinski. Optimization with sparsity-inducing penalties. Foundations and Trends in Machine Learning, 4(1):1--106, 2011.", "L. Bottou and Y. LeCun. Large scale online learning. In Advances in Neural Information Processing Systems, volume 16, pages 217--224, 2004.", "C. J. C. Burges, R. Ragno, and Q. V. Le. Learning to rank with nonsmooth cost functions. In Advances in Neural Information Processing Systems (NIPS), pages 193--200, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788579"}, {"title": "A method for enhancing audibility in a noisy environment using HRTF technique", "authors": ["Shraddha Phadnis\n,", "Periyasamy Paramasivam"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nVarious techniques have been evolved over the years to improve the audibility of voice call. Many of them use noise suppression or noise cancellation techniques. The improvements in the binaural audio processing in the last decade have provided models that can emulate the position of a given audio source virtually anywhere in the 3D space accurately. The placing of audio source virtually in various positions is gaining attraction for various applications such as gaming, noise reduction etc... We propose to improve the audibility of voice call by allowing the user to virtually move around the person speaking from the far end of the call to a place where he will get minimum interference from the ambient noise. Our paper demonstrates the proposed concept at the theoretical level and then evaluates it using HRTF function available in openAL library.", "references": ["Czyzewski, A. Automatic identification of sound source position employing neural networks and rough sets. DOI=http://www.multimed.org/papers/automatic_identification_of_sound_source.pdf", "Cheng, C. I. Visualization, Measurement and Interpolation of HRTF'S with applications in electro-acoustic music. DOI=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7794&rep=rep1&type=pdf", "Creative OpenAL Programmer's Reference. DOI=http://open-activewrl.sourceforge.net/data/OpenAL_PGuide.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818683"}, {"title": "Photo linker: a system for finding your old photos based on fragmentary memories", "authors": ["Shikui Wei\n,", "Fan Yang\n,", "Tao Ruan\n,", "Ruoyu Liu\n,", "Zhenfeng Zhu\n,", "Yao Zhao"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nWith the rapid spread of image capture devices, the size of family album grows quickly up. It is difficult for family members to find out an expected photo just based on their fragmentary memory. In this paper, we attempt to develop a system named Photo Linker, to help people quickly get their expected photos by fully exploring the clues remembered by themselves. The key idea is to build the relationship among all photos by shared faces and scenes. The system includes three key components: (1) face detection and recognition; (2) scene classification; (3) association searching. In particular, an algorithm called \"Association Correction\" based on FP-Growth is discovered to improve the face recognition rate of family members. Moreover, a friendly interface is designed and implemented to facilitate the photo searching process. The experimental results show that the system can effectively and efficiently build the relationship among photos and make the photo finding process more convenient.", "references": ["C. Zhang, and Z. Zhang. A survey of recent advances in face detection. Technical Report, Microsoft Research, 2010.", "M. H. Yang, D. J. Kriegman, and N. Ahuja. Detecting faces in images: A survey. TPAMI, 24(1):34--58, 2002.", "P. Viola, and M. Jones. Rapid object detection using a boosted cascade of simple features. In CVPR, volume 1, pages I--511, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808550"}, {"title": "Infrastructure for In Situ System Monitoring and Application Data Analysis", "authors": ["Jim Brandt\n,", "Karen Devine\n,", "Ann Gentile"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nWe present an architecture for high-performance computers that integrates in situ analysis of hardware and system monitoring data with application-specific data to reduce application runtimes and improve overall platform utilization. Large-scale high-performance computing systems typically use monitoring as a tool unrelated to application execution. Monitoring data flows from sampling points to a centralized off-system machine for storage and post-processing when root-cause analysis is required. Along the way, it may also be used for instantaneous threshold-based error detection. Applications can know their application state and possibly allocated resource state, but typically, they have no insight into globally shared resource state that may affect their execution. By analyzing performance data in situ rather than off-line, we enable applications to make real-time decisions about their resource utilization. We address the particular case of in situ network congestion analysis and its potential to improve task placement and data partitioning. We present several design and analysis considerations.", "references": ["Blue Waters. https://bluewaters.ncsa.illinois.edu.", "A. Agelastos, B. Allan, J. Brandt, P. Cassella, J. Enos, J. Fullop, A. Gentile, S. Monk, N. Naksinehaboon, J. Ogden, M. Rajan, M. Showerman, J. Stevenson, N. Taerat, and T. Tucker. Lightweight Distributed Metric Service: A scalable infrastructure for continuous monitoring of large scale computing systems and applications. In Proc. Int'l Conf. for High Perf. Storage, Networking, & Analysis (SC14), 2014.", "H. M. Aktulga, C. Yang, E. G. Ng, P. Maris, and J. P. Vary. Topology-aware mappings for large-scale eigenvalue problems. In Euro-Par 2012 Parallel Processing, pages 830--842. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828621"}, {"title": "A Test Collection for Spoken Gujarati Queries", "authors": ["Douglas W. Oard\n,", "Rashmi Sankepally\n,", "Jerome White\n,", "Aren Jansen\n,", "Craig Harman"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe development of a new test collection is described in which the task is to search naturally occurring spoken content using naturally occurring spoken queries. To support research on speech retrieval for low-resource settings, the collection includes terms learned by zero-resource term discovery techniques. Use of a new tool designed for exploration of spoken collections provides some additional insight into characteristics of the collection.", "references": ["T. Akiba et al. Overview of the NTCIR-11 spoken query and doc task. In NTCIR-11, 2014.", "X. Anguera et al. The spoken web search task. In MediaEval, 2013.", "P. Comas et al. Sibyl, a factoid question-answering system for spoken documents. ACM TOIS, 30 (3): 19, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767791"}, {"title": "An Ontological Approach for Information Management of Public Transport Networks", "authors": ["Ernesto Fonseca Veiga\n,", "Renato de Freitas Bulcao"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents an approach based on ontologies and Semantic Web specifications for information management of intelligent transport systems. The methodology includes the creation of an ontology-based model for representing spatio-temporal information as well as the model validation by means of the development of an urban transportation management system for a Brazilian metropolis. The authors argue that the combined use of ontologies and Semantic Web standard specifications for interchange and query makes it easier the development of intelligent transport systems concerning homogeneous and shared semantic representation among applications.", "references": ["S. Batsakis and E. G. Petrakis. Sowl: spatio-temporal representation, reasoning and querying over the semantic web. In Proceedings of the 6th International Conference on Semantic Systems, page 15. ACM, 2010.", "B. DuCharme. Learning Sparql. \"O'Reilly Media, Inc.\", 2013.", "B. Ferris, K. Watkins, and A. Borning. Location-aware tools for improving public transit usability. Pervasive Computing, IEEE, 9(1):13-19, Jan 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814138"}, {"title": "Load balancing by requests redistribution In failure nodes context", "authors": ["Sofiane Mounine Hemam\n,", "Ouassila Hioual"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nLoad balancing consists in distributing the work of a dedicated server on two or more other systems in order to optimize resource utilization, and response time.\nIn the context of Peer To Peer system, nodes can join or leave the system at any time which affect negatively on the distribution of the load between nodes that provide the Web Service.\nIn this paper, we propose an algorithm which allows balancing the load between nodes, and takes into consideration the probability of nodes failure in selecting the Web server in order to give a strong chance to requests to be executed without problem.", "references": ["Milojicic, D-D.S., Kalogeraki, V., Lukose, R., Nagaraja, K., Pruyne, J., Richard B., Rollins S. and Xu, Z. 2002. P2P Computing. http://www.hpl.hp.com/techreports/2002/HPL-2002-57.pdf", "Shirky, C. 2001. What is P2P and What Isn't. In O'Reilly Peer to Peer and Web Service Conference, Washington. http://conferences.oreillynet.com/p2p/.", "Theotokis, S. A. and Spinellis D. 2004. A survey of peer-to-peer content distribution technologies. ACM Computing Surveys. 36, 4 (2004), 335--371."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816847"}, {"title": "Methodology for Generation of Business Intelligence Platforms to University Evaluation Committees", "authors": ["Caio Eduardo Ribeiro\n,", "Anna Izabel Joao Tostes Ribeiro"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nBusiness Intelligence techniques aim to extract strategic knowledge from great data volumes in organizations. With the need to manage and handle timely this data, a Business Intelligence Platform becomes necessary. This paper presents a methodology for generation of platforms for automation of organizational process from University Evaluation Committees, which automate part of the process and support strategic knowledge generation. The proposed methodology comprehends from specification to evaluation of the platform prototype, made according to ISO/IEC 9126 standard. A case study in an University Evaluation Committee was made, and the developed platform had an 88.9% approval rate, considered ready for deployment.", "references": ["Abran, A. 2010. Software Metrics and Software Metrology. John Wiley & Sons Inc.", "Barbieri, C. 2001. BI-Business Intelligence: modelagem e tecnologia. Axcel Books.", "Carr, J. 2011. Case study: Developing a Sharepoint 2010 strategy... or how setting it up and getting it out there is not a strategy. Bulletin of the American Society for Information Science and Technology, v. 37, p. 26-28."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814089"}, {"title": "Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection", "authors": ["Ricardo J. G. B. Campello\n,", "Davoud Moulavi\n,", "Arthur Zimek\n,", "Jörg Sander"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nAn integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.", "references": ["N. Abe, B. Zadrozny, and J. Langford. 2006. Outlier detection by active learning. In Proceedings of the 12th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD).Philadelphia, PA. 504--509. DOI:http://dx.doi.org/10.1145/1150402.1150459", "E. Achtert, H.-P. Kriegel, E. Schubert, and A. Zimek. 2013. Interactive data mining with 3D-parallel-coordinate-trees. In Proceedings of the ACM International Conference on Management of Data (SIGMOD). New York City, NY. 1009--1012. DOI:http://dx.doi.org/10.1145/2463676.2463696", "C. C. Aggarwal and P. S. Yu. 2001. Outlier detection for high dimensional data. In Proceedings of the ACM International Conference on Management of Data (SIGMOD). Santa Barbara, CA. 37--46. DOI:http://dx.doi.org/10.1145/375663.375668"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733381"}, {"title": "LocalRec'15: Workshop on Location-Aware Recommendations", "authors": ["Panagiotis Bouros\n,", "Neal Lathia\n,", "Matthias Renz\n,", "Francesco Ricci\n,", "Dimitris Sacharidis"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe amount of available geo-referenced data has seen a dramatic explosion over the past few years. Human activities now generate digital traces that are annotated with location data, enabling the collection of rich information about people's interests and habits. This torrent of geo-referenced data provides a tremendous potential to augment recommender systems. The LocalRec'15 workshop brings together scholars from location-based services and recommender systems, and seeks to set out new trends and research directions.", "references": ["P. Bouros, N. Lathia, M. Renz, F. Ricci, and D. Sacharidis, editors. Proceedings of the 1st Workshop on Location-Aware Recommendations (LocalRec'15), in ACM RecSys Conference, number 1405 in CEUR Workshop Proceedings, Aachen, 2015. URL: http://ceur-ws.org/Vol-1405/.", "M. del Carmen Rodríguez-Hernández, S. Ilarri, R. Trillo-Lado, and R. Hermoso. Location-aware recommendation systems: Where we are and where we recommend to go. In Bouros et al. LocalRec2015. URL: http://ceur-ws.org/Vol-1405/paper-01.pdf.", "G. Giannopoulos, N. Karagiannakis, D. Skoutas, and S. Athanasiou. Automatic recommendations of categories for geospatial entities. In Bouros et al. LocalRec2015. URL: http://ceur-ws.org/Vol-1405/paper-02.pdf."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798720"}, {"title": "Combination Effects of Word-based and Extended Co-citation Search Algorithms", "authors": ["Masaki Eto"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIn the field of academic document search, citations are often used for measuring implicit relationships between documents. Recently, some studies have attempted to extend co-citation searching. However, these studies mainly focus on comparisons of traditional co-citation and extended co-citation search methods; combination effects of word-based and extended co-citation search algorithms have not yet been sufficiently evaluated. This paper empirically evaluates the search performance of the combination search by using a test collection comprising about 152,000 documents and a metric 'precision at k.' The experimental results indicate that the combination search outperforms two baseline methods: a word-based search and a combination search of word-based and traditional co-citation search algorithms.", "references": ["Eto, M. 2013. Evaluations of context-based co-citation searching, Scientometrics 94, 2, 651--673.", "Eto, M. 2014. Document retrieval method using random walk with restart on weighted co-citation network, In Proceedings of the 77th ASIS&T Annual Meeting.", "Gipp, B. and Beel, J. 2009. Citation proximity analysis (CPA) - A new approach for identifying related work based on co-citation analysis. In Proceedings of the 12th ISSI Conference. 2, 571--575."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756957"}, {"title": "Personalized Recommendation Meets Your Next Favorite", "authors": ["Qiang Song\n,", "Jian Cheng\n,", "Ting Yuan\n,", "Hanqing Lu"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA comprehensive understanding of user's item selection behavior is not only essential to many scientific disciplines, but also has a profound business impact on online recommendation. Recent researches have discovered that user's favorites can be divided into 2 categories: long-term and short-term. User's item selection behavior is a mixed decision of her long and short-term favorites. In this paper, we propose a unified model, namely States Transition pAir-wise Ranking Model (STAR), to address users' favorites mining for sequential-set recommendation. Our method utilizes a transition graph for collaborative filtering that accounts for mining user's short-term favorites, jointed with a generative topic model for expressing user's long-term favorites. Furthermore, a user's specific prior is introduced into our unified model for better modeling personalization. Technically, we develop a pair-wise ranking loss function for parameters learning. Empirically, we measure the effectiveness of our method using two real-world datasets and the results show that our method outperforms state-of-the-art methods.", "references": ["T. L. Griffiths, M. Steyvers, D. M. Blei, and J. B. Tenenbaum. Integrating topics and syntax. In Advances in neural information processing systems, pages 537--544, 2004.", "R. Krestel, P. Fankhauser, and W. Nejdl. Latent dirichlet allocation for tag recommendation. In Proceedings of the third ACM conference on Recommender systems, pages 61--68. ACM, 2009.", "S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web, pages 811--820. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806598"}, {"title": "Session details: Session 8B: Memory Management", "authors": ["Alper Buyuktosunoglu"], "publication": "ACM SIGPLAN Notices", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3261652"}, {"title": "Know Your Onions: Understanding the User Experience with the Knowledge Module in Web Search", "authors": ["Ioannis Arapakis\n,", "Luis A. Leiva\n,", "B. Barla Cambazoglu"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe increasing availability of large volumes of human-curated content is shifting web search towards a paradigm that introduces seamlessly more semantic information to search engine result pages. This trend has resulted in the design of a new element known as the knowledge module (KM) where certain facts about named entities, obtained from various knowledge bases, are shown to users. So far, little has been done to uncover the role that this module plays on user experience in web search and whether it is perceived by users as a useful aid for their search tasks. Our work is an early attempt to bridge this gap. To this end, we conducted a crowdsourcing study aimed at understanding the effect of the KM on users' search experience and its overall utility. In particular, our study is the first to provide insights about the noticeability and usefulness of the KM in web search, together with comprehensive analyses of usability and workload.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A nucleus for a web of open data. In Proc. ISWC, 722--735, 2007.", "B. Bi, H. Ma, B.-J. P. Hsu, W. Chu, K. Wang, and J. Cho. Learning to recommend related entities to search users. In Proc. WSDM, 139--148, 2015.", "R. Blanco, B. B. Cambazoglu, P. Mika, and N. Torzec. Entity recommendations in web search. In Proc. ISWC, 33--48. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806591"}, {"title": "Towards Hierarchies of Search Tasks & Subtasks", "authors": ["Rishabh Mehrotra\n,", "Emine Yilmaz"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nCurrent search systems do not provide adequate support for users tackling complex tasks due to which the cognitive burden of keeping track of such tasks is placed on the searcher. As opposed to recent approaches to search task extraction, a more naturalistic viewpoint would involve viewing query logs as hierarchies of tasks with each search task being decomposed into more focussed sub-tasks. In this work, we propose an efficient Bayesian nonparametric model for extracting hierarchies of such tasks & subtasks. The proposed approach makes use of the multi-relational aspect of query associations which are important in identifying query-task associations. We describe a greedy agglomerative model selection algorithm based on the Gamma-Poisson conjugate mixture that take just one pass through the data to learn a fully probabilistic, hierarchical model of trees that is capable of learning trees with arbitrary branching structures as opposed to the more common binary structured trees. We evaluate our method based on real world query log data based on query term prediction. To the best of our knowledge, this work is the first to consider hierarchies of search tasks and subtasks.", "references": ["C. Blundell and Y. W. Teh. Bayesian hierarchical community discovery. In NIPS 2013.", "Hua, Song, and Wang. Identifying users' topical tasks in web search. In ACM WSDM 2013.", "Kotov, Bennett, White, Dumais, and Teevan. Modeling and analysis of cross-session search tasks. In ACM SIGIR 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742777"}, {"title": "Building User Profiles from Shared Photos", "authors": ["Dhiraj Joshi\n,", "Matthew Cooper\n,", "Francine Chen\n,", "Yan-ying Chen"], "publication": "MMCommons '15: Proceedings of the 2015 Workshop on Community-Organized Multimodal Mining: Opportunities for Novel Solutions", "abstract": "ABSTRACT\nIn this paper, we analyze the association between a social media user's photo content and their interests. Visual content of photos is analyzed using state-of-the-art deep learning based automatic concept recognition. We compute an aggregate visual concept signature for each user. User tags that have been manually applied to their photos are also used to construct a tf-idf based signature per user. We also obtain social groups that users join to represent their social interests. In an effort to compare the visual-based versus tag-based user profiles with social interests, we compare corresponding similarity matrices with a reference similarity matrix based on users' group memberships. A random baseline is also included that groups users by random sampling while preserving the actual group sizes. A difference metric is proposed and it is shown that the combination of visual and text features better approximates the group-based similarity matrix than either modality individually. We also validate the visual analysis against the reference inter-user similarity using the Spearman rank correlation coefficient. Finally we cluster users by their visual signatures and rank clusters using a cluster uniqueness criteria.", "references": ["P.K. Atrey, M.A. Hossain, A.El. Saddik, M.S. Kankanhalli. Multimodal fusion for multimedia analysis: a survey. Multimedia Systems 16(6): 345--379, 2010.", "M. De Choudhury, H. Sundaram, Y.-R. Lin, A. John, and D. Seligmann. Connecting content to community in social media via image content, user tags and user communication. In Multimedia and Expo, 2009. ICME 2009. IEEE International Conference on, pages 1238--1241, June 2009.", "H. Feng and X. Qian. Mining user-contributed photos for personalized product recommendation. Neurocomputing, 129:409--420, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814815.2814818"}, {"title": "Recommending Short-lived Dynamic Packages for Golf Booking Services", "authors": ["Robin Swezey\n,", "Young-joo Chung"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe introduce an approach to recommending short-lived dynamic packages for golf booking services. Two challenges are addressed in this work. The first is the short life of the items, which puts the system in a state of a permanent cold start. The second is the uninformative nature of the package attributes, which makes clustering or figuring latent packages challenging. Although such settings are fairly pervasive, they have not been studied in traditional recommendation research, and there is thus a call for original approaches for recommender systems. In this paper, we introduce a hybrid method that leverages user analysis and its relation to the packages, as well as package pricing and environmental analysis, and traditional collaborative filtering. The proposed approach achieved appreciable improvement in precision compared with baselines", "references": ["Chu, W., and Park, S.-T. Personalized recommendation on dynamic content using predictive bilinear models. In Proceedings of the 18th International Conference on World Wide Web (New York, NY, USA, 2009), WWW '09, ACM, pp. 691--700.", "Koenigstein, N., Dror, G., and Koren, Y. Yahoo! music recommendations: Modeling music ratings with temporal dynamics and item taxonomy. In Proceedings of the Fifth ACM Conference on Recommender Systems (New York, NY, USA, 2011), RecSys '11, ACM, pp. 165--172.", "Saveski, M., and Mantrach, A. Item cold-start recommendations: Learning local collective embeddings. In Proceedings of the 8th ACM Conference on Recommender Systems (New York, NY, USA, 2014), RecSys '14, ACM, pp. 89--96."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806608"}, {"title": "Maturing, Consolidation and Performance of NoSQL Databases: Comparative Study", "authors": ["Vanessa Cristina Oliveira de Souza\n,", "Marcus Vinicius Carli dos Santos"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents a study on the NoSQL (Not Only SQL), a new dimension in databases. Lately witnesses an expansion in the number of generated data, and the relational model cannot deal with this data growth. The NoSQL comes as a solution to this problem. This paper aims to conduct a study on the architecture of DBMS, demonstrate why they can deal with this large volume of data and show some properties that NoSQL is based to make your data management. Therefore, DBMSs Redis and Cassandra were used and compared to the relational database MySQL. The maturity and consolidation of NoSQL DBMSs were qualitatively assessed on the parameters online documentation, software help, support virtual community and academic articles, so this work presents a perception of a user already familiar with relational approach taking their first steps with NoSQL. The results showed recognition of the relational database, but also showed a strong consolidation of NoSQL technology market and academic research environments, especially with Cassandra. The horizontal scale was tested with the DBMS Cassandra, who proved to be an excellent tool in this regard.", "references": ["Elmasri, R; Navathe, S. B. Sistemas de banco de dados. 6 ed. São Paulo: Pearson 2011.", "Korth, H. F. ; Silberschatz, A. ; Sudarshan, S. Sistema de banco de dados. 5 ed. Rio de Janeiro: Elsevier, 2006. 781 p.", "Vieira, M. ; Figueiredo, J. Bancos de Dados NoSQL: Conceitos, Ferramentas, Linguagens e Estudos de Casos no Contexto de Big Data. In Anais do Simpósio Brasileiro de Bancos de Dados (São Paulo/SP - Brasil, 15-18/10/2012). Disponível em: http://data.ime.usp.br/sbbd2012/artigos/pdfs/sbbd_min_01.pdf. Acesso em: 31 Jan. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814097"}, {"title": "Theory of Retrieval: The Retrievability of Information", "authors": ["Leif Azzopardi"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nRetrievability is an important and interesting indicator that can be used in a number of ways to analyse Information Retrieval systems and document collections. Rather than focusing totally on relevance, retrievability examines what is retrieved, how often it is retrieved, and whether a user is likely to retrieve it or not. This is important because a document needs to be retrieved, before it can be judged for relevance. In this tutorial, we shall explain the concept of retrievability along with a number of retrievability measures, how it can be estimated and how it can be used for analysis. Since retrieval precedes relevance, we shall also provide an overview of how retrievability relates to effectiveness - describing some of the insights that researchers have discovered thus far. We shall also show how retrievability relates to efficiency, and how the theory of retrievability can be used to improve both effectiveness and efficiency. Then we shall provide an overview of the different applications of retrievability such as Search Engine Bias, Corpus Profiling, etc., before wrapping up with challenges and opportunities. The final session will look at example problems and ways to analyse and apply retrievability to other problems and domains. Participants are invited to bring their own problems to be discussed after the tutorial. This half-day tutorial is ideal for: (i) researchers curious about retrievability and wanting to see how it can impact their research, (ii) researchers who would like to expand their set of analysis techniques, and/or (iii) researchers who would like to use retrievability to perform their own analysis.", "references": ["L. Azzopardi. Query side evaluation: an empirical analysis of effectiveness and effort. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 556--563. ACM, 2009.", "L. Azzopardi. The economics in interactive information retrieval. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '11, pages 15--24, 2011.", "L. Azzopardi. Searching for unlawful carnal knowledge. In Proceedings of the SIGIR Workshop: Search for Fun, volume 11, pages 17--18, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809444"}, {"title": "Scheduled approximation for Personalized PageRank with Utility-based Hub Selection", "authors": ["Fanwei Zhu\n,", "Yuan Fang\n,", "Kevin Chen-Chuan Chang\n,", "Jing Ying"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nAs Personalized PageRank has been widely leveraged for ranking on a graph, the efficient computation of Personalized PageRank Vector (PPV) becomes a prominent issue. In this paper, we propose FastPPV, an approximate PPV computation algorithm that is incremental and accuracy-aware. Our approach hinges on a novel paradigm of scheduled approximation: the computation is partitioned and scheduled for processing in an \"organized\" way, such that we can gradually improve our PPV estimation in an incremental manner and quantify the accuracy of our approximation at query time. Guided by this principle, we develop an efficient hub-based realization, where we adopt the metric of hub length to partition and schedule random walk tours so that the approximation error reduces exponentially over iterations. In addition, as tours are segmented by hubs, the shared substructures between different tours (around the same hub) can be reused to speed up query processing both within and across iterations. Given the key roles played by the hubs, we further investigate the problem of hub selection. In particular, we develop a conceptual model to select hubs based on the two desirable properties of hubs--sharing and discriminating, and present several different strategies to realize the conceptual model. Finally, we evaluate FastPPV over two real-world graphs, and show that it not only significantly outperforms two state-of-the-art baselines in both online and offline phrases, but also scales well on larger graphs. In particular, we are able to achieve near-constant time online query processing irrespective of graph size.", "references": ["Andersen, R., Chung, F., Lang, K.: Local graph partitioning using pagerank vectors. In: FOCS, pp. 475---486 (2006)", "Baeza-Yates, R., Tiberi, A.: Extracting semantic relations from query logs. In: Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 76---85 (2007)", "Bahmani, B., Chakrabarti, K., Xin, D.: Fast personalized PageRank on MapReduce. In: SIGMOD, pp. 973---984 (2011)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-014-0376-8"}, {"title": "Discovery of Environmental Web Resources Based on the Combination of Multimedia Evidence", "authors": ["Theodora Tsikrika\n,", "Antonis Latas\n,", "Anastasia Moumtzidou\n,", "Elisavet Chatzilari\n,", "Stefanos Vrochidis\n,", "Yiannis Kompatsiaris"], "publication": "EMR '15: Proceedings of the 2nd International Workshop on Environmental Multimedia Retrieval", "abstract": "ABSTRACT\nThis work proposes a framework for the discovery of environmental Web resources providing air quality measurements and forecasts. Motivated by the frequent occurrence of heatmaps in such Web resources, it exploits multimedia evidence at different stages of the discovery process. Domain-specific queries generated using empirical information and machine learning driven query expansion are submitted both to the Web and Image search services of a general-purpose search engine. Post-retrieval filtering is performed by combining textual and visual (heatmap-related) evidence in a supervised machine learning framework. Our experimental results indicate improvements in the effectiveness when performing heatmap recognition based on SURF and SIFT descriptors using VLAD encoding and when combining multimedia evidence in the discovery process.", "references": ["H. Bay, T. Tuytelaars, and L. Van Gool. SURF: Speeded Up Robust Features. In Proc. of the 9th European Conference on Computer Vision (ECCV), pages 404--417. 2006.", "R. Cao and C. Tan. Text/graphics separation in maps. In Proc. of 4th IAPR International Workshop on Graphics Recognition (GREC), pages 167--177. 2002.", "C. C. Chang and C. J. Lin. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2764873.2764876"}, {"title": "Real-time interactive music in Haskell", "authors": ["Paul Hudak\n,", "Donya Quick\n,", "Mark Santolucito\n,", "Daniel Winograd-Cort"], "publication": "FARM 2015: Proceedings of the 3rd ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design", "abstract": "ABSTRACT\nEuterpea and UISF are two recently released Haskell libraries on Hackage that facilitate the creation of interactive musical programs. We show an example of using these two libraries in combination with Haskell's support for parallelism to create a complex application that generates music in real time in response to user input from MIDI controllers.", "references": ["G. Giorgidze. HCodecs, 2014. URL https://hackage.haskell. org/package/HCodecs.", "P. Hudak. Euterpea, 2014. URL http://haskell.cs.yale.edu/ euterpea/.", "P. H. Liu. PortMidi, 2015. URL https://hackage.haskell.org/ package/PortMidi."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808083.2808087"}, {"title": "Aggregation of Crowdsourced Ordinal Assessments and Integration with Learning to Rank: A Latent Trait Model", "authors": ["Pavel Metrikov\n,", "Virgil Pavlu\n,", "Javed A. Aslam"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nExisting approaches used for training and evaluating search engines often rely on crowdsourced assessments of document relevance with respect to a user query. To use such assessments for either evaluation or learning, we propose a new framework for the inference of true document relevance from crowdsourced data---one simpler than previous approaches and achieving better performance. For each assessor, we model assessor quality and bias in the form of Gaussian distributed class conditionals of relevance grades. For each document, we model true relevance and difficulty as continuous variables. We estimate all parameters from crowdsourced data, demonstrating better inference of relevance as well as realistic models for both documents and assessors.\nA document-pair likelihood model works best, and it is extended to pairwise learning to rank. Utilizing more information directly from the input data, it shows better performance as compared to existing state-of-the-art approaches for learning to rank from crowdsourced assessments. Experimental validation is performed on four TREC datasets.", "references": ["D. Andrich. A rating formulation for ordered response categories. Psychometrika, 43:561--573, 1978.", "Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). 2006.", "C.J.C. Burges. From ranknet to lambdarank to lambdamart: An overview, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806492"}, {"title": "Science Navigation Map: an Interactive Data Mining Tool for Literature Analysis", "authors": ["Yu Liu\n,", "Zhen Huang\n,", "Yizhou Yan\n,", "Yufeng Chen"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the advances of all research fields and web 2.0, scientific literature has been widely observed in digital libraries, citation databases, and social media. Its new properties, such as large volume, wide exhibition, and the complicated citation relationship in papers bring challenges to the management, analysis and exploring knowledge of scientific literature. In addition, although data mining techniques have been imported to scientific literature analysis tasks, they typically requires expert input and guidance, and returns static results to users after process, which makes them inflexible and not smart. Therefore, there is the need of a tool, which highly reflects article-level-metrics and combines human users and computer systems for analysis and exploring knowledge of scientific literature, as well as discovering and visualizing underlying interesting research topics. We design an online tool for literature navigation, filtering, and interactive data mining, named Science Navigation Map (SNM), which integrates information from online paper repositories, citation databases, etc. SNM provides visualization of article level metrics and interactive data mining which takes advantage of effective interaction between human users and computer systems to explore and extract knowledge from scientific literature and discover underlying interesting research topics. We also propose a multi-view non-negative matrix factorization and apply it to SNM as an interactive data mining tool, which can make better use of complicated multi-wise relationships in papers. In experiments, we visualize all the papers published at the journal of PLOS Biology from 2003 to 2012 in the navigation map and explore six relationship in papers for data mining. From this map, one can easily filter, analyse and explore knowledge of the papers through an interactive way.", "references": ["E. Adie and W. Roe. Altmetric: enriching scholarly content with article-level discussion and metrics. Learned Publishing, 26(1):11--17, 2013.", "J. Demsar, B. Zupan, G. Leban, and T. Curk. Orange: From experimental machine learning to interactive data mining. Springer, 2004.", "D. M. Dunlavy, T. G. Kolda, and W. P. Kegelmeyer. Multilinear algebra for analyzing data with multiple linkages. Graph Algorithms in the Language of Linear Algebra, J. Kepner and J. Gilbert, eds., Fundamentals of Algorithms, SIAM, Philadelphia, pages 85--114, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741733"}, {"title": "PIKM 2015: The 8th ACM Workshop for Ph.D. Students in Information and Knowledge Management", "authors": ["Mouna Kacimi\n,", "Nicoleta Preda\n,", "Maya Ramanath"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe PIKM workshop offers Ph.D. students the opportunity to bring their work to an international and interdisciplinary research community, and create a network of young researchers to exchange and develop new and promising ideas. Similar to the CIKM, the PIKM workshop covers a wide range of topics in the areas of databases, information retrieval and knowledge management.", "references": ["L. A. Matos Da Silva and V. Braganholo. Adaptive Virtual Partitioning for Efficient Query Processing in Distributed XML Database Systems.In PIKM '15, 2015.", "S. Gandhi and T. Oates and A. Boedihardjo and C. Chen and J. Lin and P. Senin and S. Frankenstein and X. Wang. A Generative Model for Time Series Discretization Based on Multiple Normal Distributions. In PIKM '15, 2015.", "S. Rathee and M. Kaul and A. Kashyap.R-Apriori : An Efficient Apriori Based Algorithm on Spark. In PIKM '15, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806873"}, {"title": "Transfer of predictive models for classification of statutory texts in multi-jurisdictional settings", "authors": ["Jaromír Šavelka\n,", "Kevin D. Ashley"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nIn this paper we use statistical machine learning to classify statutory texts in terms of highly specific functional categories. We focus on regulatory provisions from multiple US state jurisdictions, all dealing with the same general topic of public health system emergency preparedness and response. In prior work we have established that one can improve classification performance on one jurisdiction's statutory texts using texts from another jurisdiction. Here we describe a framework facilitating transfer of predictive models for classification of statutory texts among multiple state jurisdictions. Our results show that the classification performance improves as we employ an increasing number of models trained on data coming from different states.", "references": ["I. Batal, C. Hong, and M. Hauskrecht. An efficient probabilistic framework for multi-dimensional classification. In CIKM, pages 2417--2422, 2013.", "C. Biagioli, E. Francesconi, A. Passerini, S. Montemagni, and C. Soria. Automatic semantics extraction in law documents. In ICAIL '05, pages 133--140. ACM, 2005.", "G. Boella, L. D. Caro, L. Lesmo, D. Rispoli, and L. Robaldo. Multi-label classification of legislative text into eurovoc. In B. Schäfer, editor, JURIX 2012, pages 21--30. IOS Press, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746109"}, {"title": "Addressing Instance Ambiguity in Web Harvesting", "authors": ["Zhixu Li\n,", "XiangLiang Zhang\n,", "Hai Huang\n,", "Qing Xie\n,", "Jia Zhu\n,", "Xiaofang Zhou"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nWeb Harvesting enables the enrichment of incomplete data sets by retrieving required information from the Web. However, the ambiguity of instances may greatly decrease the quality of the harvested data, given that any instance in the local data set may become ambiguous when attempting to identify it on the Web. Although plenty of disambiguation methods have been proposed to deal with the ambiguity problems in various settings, none of them are able to handle the instance ambiguity problem in Web Harvesting. In this paper, we propose to do instance disambiguation in Web Harvesting with a novel disambiguation method inspired by the idea of collaborative identity recognition. In particular, we expect to find some common properties in forms of latent shared attribute values among instances in the list, such that these shared attribute values can differentiate instances within the list against those ambiguous ones on the Web. Our extensive experimental evaluation illustrates the utility of collaborative disambiguation for a popular Web Harvesting application, and shows that it substantially improves the accuracy of the harvested data.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 17(6):734--749, 2005.", "E. Agichtein and L. Gravano. Snowball: Extracting relations from large plain-text collections. In ACM DL, pages 85--94, 2000.", "E. Agirre, A. Soroa, and M. Stevenson. Graph-based word sense disambiguation of biomedical documents. Bioinformatics, 26(22):2889--2896, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767114"}, {"title": "TEXTOMAP: determining geographical window for texts", "authors": ["Geoffrey Brun\n,", "Catherine Dominguès\n,", "M.-D. Van Damme"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nIn newspapers or scholar manuals, numerous texts are accompanied by maps. In these map/text couples, maps give a spatial portrayal of the text issues, thus they make the spatial issues easier to understand. TEXTOMAP aims to design the geographical window of the text, based on the notion of important toponyms according to text issues. The important toponym selection is based on indicators which may be spatial, linguistic or semantic. Examples of geographical window calculation are shown and compared with the corresponding CLAVIN geographical focus. The work is in progress and perspectives are offered.", "references": ["E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-where: Geotagging web content. In Proceedings of the 27th Annual International ACM, SIGIR '04, pages 273--280, New York, NY, USA, 2004. ACM.", "E. Z. C. D'Ignazio, R. Bhargava and L. Beck. Cliff-clavin: Determining geographic focus for news. NewsKDD: Data Science for News Publishing, at KDD 2014, 2014.", "J. O. Wallgrün, F. Hardisty, A. M. MacEachren, M. Karimzadeh, Y. Ju, and S. Pezanowski. Construction and first analysis of a corpus for the evaluation and training of microblog/twitter geoparsers. In Proceedings of the 8th Workshop on Geographic Information Retrieval, GIR 2014, Dallas/Fort Worth, TX, USA, November 4-7, 2014, pages 4:1--4:8, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837703"}, {"title": "Opinion Spammer Detection in Web Forum", "authors": ["Yu-Ren Chen\n,", "Hsin-Hsi Chen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, a real case study on opinion spammer detection in web forum is presented. We explore user profiles, maximum spamicity of first posts of users, burstiness of registration of user accounts, and frequent poster set to build a model with SVM with RBF kernel and frequent itemset mining. The proposed model achieves 0.6753 precision, 0.6190 recall, and 0.6460 F1 score. The result is promising because the ratio of opinion spammers in the test set is only 0.98%.", "references": ["Janez Demšar, Tomaž Curk, Aleš Erjavec, Črt Gorup, Orange: Data mining toolbox in python. Journal of Machine Learning Research, 14:2349--2353, 2013.", "Geli Fei, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. Exploiting burstiness in reviews for review spammer detection. In Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media (ICWSM), pages 175--184, AAAI, 2013.", "Nathan Halko, Per-Gunnar Martinsson, and Joel A Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review, 53(2):217--288, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767766"}, {"title": "Web page revisiting by coordinate page discovery", "authors": ["Yusuke Takeda\n,", "Hiroaki Ohshima\n,", "Katsumi Tanaka"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nA recent study on information refinding reported that 44% of Web page visits and 33% of Web queries involved revisiting previously browsed pages. We propose methods for finding previously browsed pages regarded as coordinate pages of currently browsed pages. Intuitively, the notion of coordinate pages means that both of them belong to an identical class. To find the coordinate pages for given pages, we use a user's browsing and search behavior, such as her query log and tab usage, as well as link navigation. Our page revisiting methods were implemented within a Web browser, so that users can find those previously browsed pages while browsing and searching. We conducted experiments in which our methods outperformed conventional baseline methods in terms of page revisiting.", "references": ["https://developer.mdozilla.org/en-US/docs/Mozilla/Tech/Placesd/Frecency_algorithm.", "E. Adar, J. Teevan, and S. T. Dumais. Large scale analysis of web revisitation patterns. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems, pages 1197--1206, 2008.", "A. Aula, R. M. Khan, Z. Guan, P. Fontes, and P. Hong. A comparison of visual and textual page previews in judging the helpfulness of web pages. In Proceedings of the 19th international conference on World wide web, pages 51--60, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837200"}, {"title": "Supporting Multilingual Semantic Web Services Discovery by Consuming Data from DBpedia Knowledge Base", "authors": ["Nasredine Cheniki\n,", "Abdelkader Belkhir\n,", "Yacine Atif"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nThe Web is becoming a truly multilingual hub in which speakers from different languages and cultures are producing, interacting and consuming information. Web services are an essential part of the Web which nowadays attract more and more people around the world. So, supporting multilingual Web services discovery is a crucial goal to achieve, so that providers and users publish or consume Web services independently from their culture and native language. In this paper, we propose to overcome language barrier by supporting multilingual Web services discovery using DBpedia, which is a cross-domain multilingual knowledge base. DBpedia is used to annotate services with semantic entities called resources as well as their categories and types. We take advantage of semantic and multilingual information provided by DBpedia to enable cross-language semantic Web services discovery. Implementation shows that DBpedia offers a valuable information source to achieve our goal.", "references": ["Internet Usage and Social Media Statistics. Accessed: 2015-02-09.", "T. Berners-Lee, J. Hendler, O. Lassila, et al. The semantic web. Scientific american, 284(5):28--37, 2001.", "C. Bizer, T. Heath, and T. Berners-Lee. Linked data-the story so far. International Journal on Semantic Web and Information Systems (IJSWIS), 5(3):1--22, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816862"}, {"title": "Deep Dependency Substructure-Based Learning for Multidocument Summarization", "authors": ["Su Yan\n,", "Xiaojun Wan"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nMost extractive style topic-focused multidocument summarization systems generate a summary by ranking textual units in multiple documents and extracting a proper subset of sentences biased to the given topic. Usually, the textual units are simply represented as sentences or n-grams, which do not carry deep syntactic and semantic information. This article presents a novel extractive topic-focused multidocument summarization framework. The framework proposes a new kind of more meaningful and informative units named frequent Deep Dependency Sub-Structure (DDSS) and a topic-sensitive Multi-Task Learning (MTL) model for frequent DDSS ranking. Given a document set, first, we parse all the sentences into deep dependency structures with a Head-driven Phrase Structure Grammar (HPSG) parser and mine the frequent DDSSs after semantic normalization. Then we employ a topic-sensitive MTL model to learn the importance of these frequent DDSSs. Finally, we exploit an Integer Linear Programming (ILP) formulation and use the frequent DDSSs as the essentials for summary extraction. Experimental results on two DUC datasets demonstrate that our proposed approach can achieve state-of-the-art performance. Both the DDSS information and the topic-sensitive MTL model are validated to be very helpful for topic-focused multidocument summarization.", "references": ["C. Aksoy, A. Bugdayci, T. Gur, I. Uysal, and F. Can. 2009. Semantic argument frequency-based multidocument summarization. In Proceedings of the 24th International Symposium on IEEE. 460--464.", "E. Aktolga, J. Allan, and D. A. Smith. 2011. Passage reranking for question answering using syntactic structures and answer types. Advances in Information Retrieval. 617--628.", "R. K. Ando and T. Zhang. 2005. A framework for learning predictive structures from multiple tasks and unlabeled data. The Journal of Machine Learning Research 1817--1853."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766447"}, {"title": "A Verbal Anchor based Fuzzy System to help business managers build Balanced Scorecards Strategy Maps", "authors": ["Marcelo Ladeira\n,", "Fernando de Albuquerque Linhares"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe Balanced Scorecard (BSC) methodology was proposed to help companies create simple strategy plans that can be explained to all employees. The core of this tool is the strategy map that shows a collection of strategic objectives a company needs to achieve its mission. Small and medium companies find it difficult to create their own strategies without the help of a management consultant, which is not always affordable. This paper presents the Mistral Solutions, a system that supports entrepreneurs and their teams to create their own BSC initial strategy maps. The system proposed is based on fuzzy logic. Initially the user takes a online survey about his/her enterprise. During the knowledge acquisition a verbal anchor scale can be used to represent numeric information if the entrepreneur does not know the exact values for each question answer. The Mistral Solutions uses the answers to ground fuzzy rules for creating business strategies in the shape of BSC strategy maps. The system proposes eight strategic objectives, two for each of the four classic BSC perspectives. These strategic objectives are chosen from a set of forty-five possibilities. The knowledge base has one-hundred-eleven variables and one hundred-twenty-six fuzzy rules. This system was applied to institutions representing the public sector, the private sector and a public concession. In the empirical evaluation, the system performed better when applied to private sector institution when all the eight strategic objectives were considered adequate by the manager in charge of the strategic planning of this institution.", "references": ["W.-C. C. Amy H.I. Lee and C.-J. Chang. A fuzzy ahp and bsc approach for evaluating performance of it department in the manufacturing industry in taiwan. Expert Systems with Applications, 34:96-107, 2006.", "U. Cebeci. Fuzzy ahp-based decision support system for selecting erp systems in textile industry by using balanced scorecard. Expert Systems with Applications, pages 8900-8909, 2009.", "S. R. Cilia Witteman and P. Koele. Medicine in words and numbers: a cross-sectional survey comparing probability assessment scales. BMC Medical Informatics and Decision Making, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814145"}, {"title": "Complex event processing for reactive security monitoring in virtualized computer systems", "authors": ["Lars Baumgärtner\n,", "Christian Strack\n,", "Bastian Hoßbach\n,", "Marc Seidemann\n,", "Bernhard Seeger\n,", "Bernd Freisleben"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nThe number of security incidents in computer systems is steadily increasing, despite intrusion detection and prevention mechanisms deployed as countermeasures. Many existing intrusion detection and prevention systems struggle to keep up with new threats posed by zero-day attacks and/or have serious performance impacts through extensive monitoring, questioning their effectiveness in most real-life scenarios. In this paper, we present a new approach for reactive security monitoring in a virtualized computer environment based on minimally-intrusive dynamic sensors deployed vertically across virtualization layers and horizontally within a virtual machine instance. The sensor streams are analyzed using a novel federation of complex event processing engines and an optimized query index to maximize the performance of continuous queries, and the results of the analysis are used to trigger appropriate actions on different virtualization layers in response to detected security anomalies. Furthermore, a novel event store that supports fast event logging is utilized for offline analysis of collected historical data. Experiments show that the proposed system can execute tens of thousands of complex, stateful detection rules simultaneously and trigger actions efficiently and with low latency.", "references": ["M. K. Aguilera, R. E. Strom, D. C. Sturman, M. Astley, and T. D. Chandra. Matching events in a content-based subscription system. In Proc. of the Symposium on Principles of Distributed Computing, pages 53--61, 1999.", "A. Ailamaki, D. J. DeWitt, M. D. Hill, and M. Skounakis. Weaving relations for cache performance. In Proc. of the Int. Conf. on Very Large Data Bases (VLDB), VLDB '01, pages 169--180, 2001.", "M. A. Bender, M. Farach-Colton, J. T. Fineman, Y. R. Fogel, B. C. Kuszmaul, and J. Nelson. Cache-oblivious streaming b-trees. In Proc. of the Symposium on Parallel Algorithms and Architectures, pages 81--92, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2771829"}, {"title": "2015: the year of internet governance", "authors": ["C. Dianne Martin"], "publication": "ACM Inroads", "abstract": "", "references": ["Drake, W. J. ed. Reforming Internet Governance: Perspectives from the UN Working Group on Internet Governance (WGIG). New York: United Nations Information and Communication Technologies Task Force, 2005.", "Dutton, W. H. and Peltu, M.\" The emerging Internet governance mosaic: Connecting the pieces\". Information Polity: The International Journal of Government & Democracy in the Information Age 12 (1/2) (March 2007): 63--81.", "Hu, Q. \"Internationalized Oversight of Internet Resource Management,\" from Drake, W. J. ed. Reforming Internet Governance: Perspectives from the UN Working Group on Internet Governance. New York: United Nations Information and Communication Technologies Task Force, 2005: 185--6."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2794295"}, {"title": "Predicting User Behavior in Display Advertising via Dynamic Collective Matrix Factorization", "authors": ["Sheng Li\n,", "Jaya Kawale\n,", "Yun Fu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nConversion prediction and click prediction are two important and intertwined problems in display advertising, but existing approaches usually look at them in isolation. In this paper, we aim to predict the conversion response of users by jointly examining the past purchase behavior and the click response behavior. Additionally, we model the temporal dynamics between the click response and purchase activity into a unified framework. In particular, a novel matrix factorization approach named dynamic collective matrix factorization (DCMF) is proposed to address this problem. Our model considers temporal dynamics of post-click conversions and also takes advantages of the side information of users, advertisements, and items. Experiments on a real-world marketing dataset show that our model achieves significant improvements over several baselines.", "references": ["Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. Laser: a scalable response prediction platform for online advertising. In WSDM, pages 173--182, 2014.", "Kuang chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. Estimating conversion rate in display advertising from past performance data. In KDD, pages 768--776, 2012.", "Amr Ahmed, Abhimanyu Das, and Alexander J. Smola. Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising. In WSDM, pages 153--162, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767781"}, {"title": "Design of the Outer-tuning framework: self-tuning and ontology for relational databases", "authors": ["Rafael Pereira de Oliveira\n,", "Sergio Lifschitz\n,", "Ana Carolina Almeida\n,", "Edward Hermann Haeusler"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn this paper, we discuss the architectural project and construction of a framework called Outer-Tuning, which supports (semi) automatic tuning of database systems through a specific ontology. The architectural aspects componentbased, interface design, and especially the approach taken to include both a domain ontology and an ontology tasks in an integrative information system. We also discuss aspects of machine inference rules and issues related to the use of logical languages. Finally, some experimental results allow an assessment of the expected framework contributions.", "references": ["A. C. B. d. Almeida. Framework para apoiar a sintonia fina de banco de dados. PhD thesis, Pontifícia Universidade Católica do Rio de Janeiro - PUC-RIO, 2013.", "K. Aouiche, P.-E. Jouve, and J. Darmont. Clustering-based materialized view selection in data warehouses. In 10th E.E. Conf. on Advances in Databases and Information Systems, ADBIS'06, pages 81-95, Berlin, Heidelberg, 2006. Springer-Verlag.", "L. G. Azevedo, F. A. Baião, and F. Santoro. Identificação de Serviços a partir da Modelagem de Processos de Negócio. V Simpósio Brasileiro de Sistemas de Informação, pages 133-144, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814087"}, {"title": "Toward Dual Roles of Users in Recommender Systems", "authors": ["Suhang Wang\n,", "Jiliang Tang\n,", "Huan Liu"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUsers usually play dual roles in real-world recommender systems. One is as a reviewer who writes reviews for items with rating scores, and the other is as a rater who rates the helpfulness scores of reviews. Traditional recommender systems mainly consider the reviewer role while not taking into account the rater role. However, the rater role allows users to express their opinions toward reviews about items; hence it may indirectly indicate their opinions about items, which could be complementary to the reviewer role. Since most real-world recommender systems provide convenient mechanisms for the rater role, recent studies show that typically there are much more helpfulness ratings from the rater role than item ratings from the reviewer role. Therefore, incorporating the rater role of users may have the potentials to mitigate the data sparsity and cold-start problems in traditional recommender systems. In this paper, we investigate how to exploit dual roles of users in recommender systems. In particular, we provide a principled way to exploit the rater role mathematically and propose a novel recommender system DualRec, which captures both the reviewer role and the rater role of users simultaneously for recommendation. Experimental results on two real world datasets demonstrate the effectiveness of the proposed framework, and further experiments are conducted to understand the importance of the rater role of users in recommendation.", "references": ["M. Balabanović and Y. Shoham. Fab: content-based, collaborative recommendation, 1997.", "H. Gao, J. Tang, X. Hu, and H. Liu. Exploring temporal effects for location recommendation on location-based social networks. In Proceedings of the 7th ACM conference on Recommender systems, pages 93--100. ACM, 2013.", "A. Ghose and P. G. Ipeirotis. Estimating the helpfulness and economic impact of product reviews: Mining text and reviewer characteristics. Knowledge and Data Engineering, IEEE Transactions on, 23(10):1498--1512, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806520"}, {"title": "Spoken Conversational Search: Information Retrieval over a Speech-only Communication Channel", "authors": ["Johanne R. Trippas"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["L. Dybkjaer, N. O. Bernsen, and W. Minker. Evaluation and usability of multimodal spoken language dialogue systems. Speech Communication, 43 (1): 33--54, 2004.", "J. Lai and N. Yankelovich. Speech interface design. In Encyclopedia of Language & Linguistics (Second Edition), pages 764--770. Elsevier, 2006.", "J. Rubin and D. Chisnell. Handbook of Usability Testing: Howto Plan, Design, and Conduct Effective Tests. Wiley, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767850"}, {"title": "Report on the Seventh Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR'14)", "authors": ["Omar Alonso\n,", "Jaap Kamps\n,", "Jussi Karlgren"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThere is an increasing amount of structure on the Web as a result of modern Web languages, user tagging and annotation, emerging robust NLP tools, and an ever growing volume of linked data. These meaningful, semantic, annotations hold the promise to significantly enhance information access, by enhancing the depth of analysis of today's systems. The goal of the ESAIR'14 workshop remained to advance the general research agenda on this core problem, with an explicit focus on one of the most challenging aspects to address in the coming years. The main remaining challenge is on the user's side---the potential of rich document annotations can only be realized if matched by more articulate queries exploiting these powerful retrieval cues---and a more dynamic approach is emerging by exploiting new forms of query autosuggest. How can the query suggestion paradigm be used to encourage searcher to articulate longer queries, with concepts and relations linking their statement of request to existing semantic models? How do entity results and social network data in \"graph search\" change the classic division between searchers and information and lead to extreme personalization---are you the query? How to leverage transaction logs and recommendation, and how adaptive should we make the system? What are the privacy ramifications and the UX aspects---how to not creep out users.\nThere was a strong feeling that we made substantial progress. Specifically, the discussion contributed to our understanding of the way forward. First, for notable (head, shoulder, but not tail) entities in semantic search we have reached the level of quality at minimal costs allowing for deployment in major web search engines---the dream has become a reality. Second, entity detection is moving fast into domain specific, personal, and business domains, and has become a vital component for a range of applications. Third, semantic web has exchanged logic for machine learning approaches, and machine learning is the natural unification of semantic web and information retrieval approaches.", "references": ["S. Cotelo, A. Makowski, L. Chiruzzo, and D. Wonsever. Documents search using semantics criteria. In Proceedings of the 7th International Workshop on Exploiting Semantic Annotations in Information Retrieval, ESAIR '14, pages 5--7, New York, NY, USA, 2014. ACM. URL http://doi.acm.org/10.1145/2663712.2666187.", "S. P. Cucerzan. Linking to web knowledge bases and applications to web search. In Proceedings of the 7th International Workshop on Exploiting Semantic Annotations in Information Retrieval, ESAIR '14, pages 3--3, New York, NY, USA, 2014. ACM. URL http://doi.acm.org/10.1145/2663712.2666199.", "T. De Nies, C. Beecks, W. De Neve, T. Seidl, E. Mannens, and R. Van de Walle. Towards named-entity-based similarity measures: Challenges and opportunities. In Proceedings of the 7th International Workshop on Exploiting Semantic Annotations in Information Retrieval, ESAIR '14, pages 9--11, New York, NY, USA, 2014. ACM. URL http://doi.acm.org/10.1145/2663712.2666194."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795412"}, {"title": "Crowdsourcing Urban Accessibility:: Some Preliminary Experiences with Results", "authors": ["P. Salomoni\n,", "C. Prandi\n,", "M. Roccetti\n,", "V. Nisi\n,", "N. Jardim Nunes"], "publication": "CHItaly 2015: Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter", "abstract": "ABSTRACT\nThis short paper presents some preliminary results (both quantitative and qualitative) gathered from field trials with three different mobile apps that allow walkers to map urban accessibility barriers/facilities, while wandering around. The three apps were designed based on different gamification mechanisms, respectively exploiting: i) intrinsic (i.e., altruistic) motivations, ii) extrinsic motivations expressed in terms of a concrete reward, and iii) extrinsic motivations expressed in terms of fun/entertainment. These preliminary results reveal that the apps designed on the basis of extrinsic motivations are able to drive users to provide a larger amount of contributions. Interesting differences between concrete rewards and fun used as effective means to motivate contributors are discussed.", "references": ["Office of National Statistics, 2002, Living in Britain: Results from the 2001 General Household Survey, HMSO, Norwich.", "Ding, C., Wald, M., Wills. G., 2014. A Survey of Open Accessibility Data. In: Proc. W4A '14. ACM, pp. 37:1--37:4.", "Seaborn, K., Fels, D. I., 2015. Gamification in Theory and Action: A survey. Int. J. Hum. Comput. Stud., 74, 14--31."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808435.2808443"}, {"title": "Session details: Special Track - Information Systems Education", "authors": ["Fatima de L. Santos Nunes\n,", "Vinicius Sebba Patto"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252440"}, {"title": "The Propensity Of Users To Technologies Adoption: A Study With Users and Not Users of the \"Nota Legal\" Program In The Federal District", "authors": ["Josivania Silva Farias\n,", "Paula Valente Lins\n,", "Pedro H. M. Albuquerque"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis study aims to verify the existence of significant differences in propensity to technology adoption, considering users and not users of the \"Nota legal\". To achieve the goal, among several other methodologies, we opted for the employment of the Technology Adoption Propensity Index (TAP-I). The study was carried out from a quantitative approach, through survey with convenience sampling, obtaining the return of 201 valid questionnaires, and at the end, we used the nonparametric method Mann-Whitney U test for the comparison between groups. At the end of the study it can be concluded that there are statistically significant differences between users and non-users of the program \"Nota Legal\", when searched for the technology adoption propensity.", "references": ["Portal EBC. Estados abrem prazo para abatimento das notas fiscais - Disponível em: ¿http://www.ebc.com.br/noticias/economia/galeria/videos/2013/01/estados-abrem-prazo-para-abatimento-das-notasfiscais¿ Acesso: abril/2014.", "Secretaria de Estado de Fazenda do Distrito Federal - Nota Legal - Disponível em: ¿http://www.notalegal.df.gov.br/¿ Acesso: jul.2014.", "RATCHFORD, M. BARNHART, M. Development and validation of the technology adoption propensity (TAP) index. Journal of Business Research, Volume 65, Issue 8, pp. 209-1215, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814156"}, {"title": "Teaching big data through project-based learning in computational linguistics and information retrieval", "authors": ["Richard Gruss\n,", "Mohamed Farag\n,", "Tarek Kanan\n,", "Mary C. English\n,", "Xuan Zhang\n,", "Edward A. Fox"], "publication": "Journal of Computing Sciences in Colleges", "abstract": "Abstract\nIn Project Based Learning (PBL), students acquire knowledge just-in-time while completing a large project driven by a particular question. We demonstrate that this approach is particularly well suited to courses in two computer science (CS) domains pertaining to Big Data: Computational Linguistics and Information Retrieval. The courses presented here proved successful, as evidenced by both the high quality of the student projects and the positive responses on end-of-semester surveys.", "references": ["Agrawal, D., Das S., El Abbadi, A., Big Data and Cloud Computing: Current State and Future Opportunities. Proceedings of the 14th International Conference on Extending Database Technology, 530--533, 2011.", "Barg, M., Fekete, A., Greening, T., Hollands, O., Kay, J., Kingston, J., Problem-Based Learning for Foundation Computer Science Courses, Computer Science Education, 10, 109--128, 2000.", "Blumenfeld, P., Soloway, E., Marx, R., Krajcik, J., Guzdial, M., Palincsar, A., Motivating project-based learning: sustaining the doing, supporting the learning, Educational Psychologist, 26, 369--398, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2831432.2831475"}, {"title": "Content Based Audiobooks Indexing using Apache Hadoop Framework", "authors": ["Sonal Shetty\n,", "Akash Sabarad\n,", "Harish Hebballi\n,", "Moula Husain\n,", "S. M. Meena\n,", "Shiddu Nagaralli"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nIn recent years, content based audio indexing has become the key research area, as the audio content defines the content more precisely and has comparatively subservient density. In this paper, we present conversion of audio books into textual information using CMU SPHINX-4 speech transcriber and efficient indexing of audio books using term frequency-inverse document frequency (tf-idf) weights on Apache Hadoop MapReduce framework. In the first phase, audiobook datasets are converted into textual words by training CMU SPHINX-4 speech recognizer with acoustic models. In the next phase, the keywords present in the text file generated from the speech recognizer are filtered using tf-idf weights. Finally, we index audio files based on the keywords extracted from the speech converted text file. As, conversion of speech to text and indexing of audio are space and time intensive tasks, we ported execution of these algorithms on Hadoop MapReduce Framework. Porting content based indexing of audio books on to a Hadoop distributed framework resulted in considerable improvement in time and space utilization. As the amount of data being uploaded and downloaded is escalating, this can be further extended to indexing of image, video and other multimedia forms.", "references": ["Youtube statitics. https://www.youtube.com/yt/press/statistics.html.", "LR Rabiner and RW Schafer. Digital speech processing. The Froehlich/Kent Encyclopedia of Telecommunications, 6:237--258, 2011.", "Paul Lamere, Philip Kwok, Evandro Gouvea, Bhiksha Raj, Rita Singh, William Walker, Manfred Warmuth, and Peter Wolf. The cmu sphinx-4 speech recognition system. 1:2--5, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791485"}, {"title": "Linked data-driven decision support for accessible travelling", "authors": ["Chaohai Ding\n,", "Mike Wald\n,", "Gary Wills"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nWith the aim of addressing the gap between users' needs of accessible travelling and complex environmental barriers of physical places in the real world, this paper summarizes the research of investigating the use of Linked Data principles for enhanced accessible travelling decision support. Firstly, this paper reviews current research and projects to identify some problems and challenges. Then a conceptual model and the reference architecture of Linked Data-driven decision support system (DSS) for accessible travelling are proposed to address such problems to enhance the accessible travelling for people with disabilities (PwD), especially for people with mobility difficulties. As a result, this research would not only benefit PwD, but also contribute to the research of a novel model to address accessibility information barriers by applying the Linked Data principles to DSSs for enhanced accessible travelling.", "references": ["Berners-Lee, T. 2011. Linked data-design issues (2006). http://www.w3.org/DesignIssues/LinkedData.html. Accessed: 2013-12-10.", "Bizer, C. et al. 2009. Linked data-the story so far. International Journal on Semantic Web and Information Systems (IJSWIS). 5, 3 (2009), 1--22.", "Cardonha, C. and Gallo, D. 2013. A crowdsourcing platform for the construction of accessibility maps. Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility - W4A '13. (2013), 1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746681"}, {"title": "A low-cost adaptive data separation method for the flash translation layer of solid state drives", "authors": ["Wei Xie\n,", "Yong Chen\n,", "Philip C. Roth"], "publication": "DISCS '15: Proceedings of the 2015 International Workshop on Data-Intensive Scalable Computing Systems", "abstract": "ABSTRACT\nSolid state drives (SSDs) have shown great potential for data-intensive computing due to their much higher throughput and lower energy consumption compared to traditional hard disk drives. Within an SSD, its Flash Translation Layer (FTL) is responsible for exposing the SSD's flash memory storage to the computer system as a simple block device. The FTL design is one of the dominant factors determining an SSD's lifespan and the amount of performance degradation. To deliver better performance, we propose a new, low-cost, adaptive separation-aware flash translation layer (ASA-FTL) that combines data clustering and selective caching of recency information to accurately identify and separate hot/cold data while incurring minimal overhead. Using simulations of ASA-FTL with real-world workloads, we have shown that our proposed approach reduces the garbage collection overhead by up to 28% and the overall response time by 15% compared to one of the most advanced existing FTLs.", "references": ["S. M. Strande, P. Cicotti, R. S. Sinkovits, W. S. Young, R. Wagner, M. Tatineni, E. Hocks, A. Snavely, and M. Norman, \"Gordon: Design, performance, and experiences deploying and supporting a data intensive supercomputer,\" in XSEDE '12, 2012, pp. 3:1--3:8.", "\"Flash Technology in High-Performance Computing Accelerates Scientific Discovery,\" http://download.intel.com/newsroom/kits/xeon/phi/pdfs/SSD_HPC_SDSC_CaseStudy.pdf.", "P. Desnoyers, \"Analytic Modeling of SSD Write Performance,\" in Proceedings of the 5th Annual International Systems and Storage Conference. ACM, 2012, p. 12."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2831244.2831250"}, {"title": "Originalism, hypothesis testing and big data", "authors": ["John O. McGinnis\n,", "Branden Stein"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nIn this paper, we describe how data mining and hypothesis testing can advance the analysis of originalism in American constitutional law.", "references": ["Viktor Mayer-Schoenberger, Kenneth Cukier, Big Data, A Revolution That Will Transform How We Live, Work, and Think, 6 (2013).", "District of Columbia v. Heller, 444 U. S. 570 (2008).", "Ilan Wurman, The Founder's Originalism, 19 National Affairs (2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746117"}, {"title": "Robust Seed Localization and Growing with Deep Convolutional Features for Scene Text Detection", "authors": ["Hailiang Xu\n,", "Feng Su"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nText detection in natural scene images is an open and challenging problem due to the significant variations of the appearance of the text itself and its interaction with the context. In this paper, we present a novel text detection method based on robust localization and adaptive growing of seed text components. The method consists of two main ingredients. First, convolutional neural network is exploited to localize seed candidate characters from the maximally stable extremal regions of the image with learned discriminative deep convolutional features. Next, an iterative and adaptive growing algorithm is employed to grow from seed characters to search for other degraded text components in same text line based on their conformity to the seed, and an associative quality is learned to measure the conformity combining both the geometric and appearance constraints between two neighbouring text components. The effectiveness of the proposed method is demonstrated by the state-of-the-art results achieved on the public datasets.", "references": ["X. Chen and A. L. Yuille. Detecting and reading text in natural scenes. In CVPR, pages II-366-II-373 Vol.2, 2004.", "B. Epshtein, E. Ofek, and Y. Wexler. Detecting text in natural scenes with stroke width transform. In CVPR, pages 2963--2970, 2010.", "W. Huang, Y. Qiao, and X. Tang. Robust scene text detection with convolution neural network induced mser trees. In ECCV, pages 497--511, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749370"}, {"title": "Towards Analysing the Scope and Coverage of Educational Linked Data on the Web", "authors": ["Davide Taibi\n,", "Giovanni Fulantelli\n,", "Stefan Dietze\n,", "Besnik Fetahu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe diversity of datasets published according to Linked Data (LD) principles has increased in the last few years and also led to the emergence of a wide range of data suitable in educational settings. However, sufficient insights into the state, coverage and scope of available educational Linked Data seem to be missing, for instance, about represented resource types or domains and topics. In this work, we analyse the scope and coverage of educational linked data on the Web, identifying the most popular resource types and topics, apparent gaps and underlining the strong correlation of resource types and topics. Our results indicate a prevalent bias to-wards data in areas such as the life sciences as well as computing-related topics.", "references": ["Fetahu, B., Dietze, S., Nunes, B. P., Taibi, D., Casanova, M. A.. 2013. Generating structured Profiles of Linked Data Graphs. In Proceedings of the 12th International Semantic Web Conference (ISWC2013),(Sydney, Australia, 2013).", "D'Aquin, M., Adamou, A., Dietze, S. 2013. Assessing the Educational Linked Data Landscape. In Proceedings of ACM Web Science 2013 (WebSci2013), Paris, France, May 2013.", "Fetahu, B., Dietze, S., Nunes, B. P., Casanova, Taibi, D., M. A., Nejdl, W. 2014. A Scalable Approach for Efficiently Generating Structured Dataset Topic Profiles. In Proceedings of 11th Extended Semantic Web Conference (ESWC2014), Heraklion, Crete, Greece, (2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741741"}, {"title": "Moodler: a digital modular synthesiser with an analogue user interface", "authors": ["Dan Piponi"], "publication": "FARM 2015: Proceedings of the 3rd ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design", "abstract": "ABSTRACT\nMoodler is a code-generating virtual modular synthesiser, implemented in Haskell, with a physical patch panel allowing users to generate audio synthesis code by physically connecting wires and adjusting potentiometers. In effect it is a compiler that compiles code written in a language of physical cables and knobs.", "references": ["{Noble} Noble, James and Jones, Timothy. LittleBits Synth Kit As a Physically-embodied, Domain Specific Functional Programming Language In FARM ’14, Workshop on Functional Art, Music, Modeling and Design, 2015 {Vail} Vail, Mark. The Synthesizer. A Comprehensive Guide to Understanding, Programming, Playing, and Recording the Ultimate Electronic Music Instrument. Oxford University Press, 2014.", "{Cycling74} MaxMSP. Cycling ’74. URL https://cycling74.com {Fantinatto} I Dream of Wires. Dir. Robert Fantinatto. Distributed by First Run Features, 2014. URL http://www.idreamofwires.org/ {Korg} Korg. http://i.korg.com/LegacyMS20 {OSC} Wright, M. and Freed A. Open Sound Control: A New Protocol for Communicating with Sound Synthesizers. International Computer Music Conference, Thessaloniki, Greece, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808083.2808088"}, {"title": "Pooled Evaluation Over Query Variations: Users are as Diverse as Systems", "authors": ["Alistair Moffat\n,", "Falk Scholer\n,", "Paul Thomas\n,", "Peter Bailey"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nEvaluation of information retrieval systems with test collections makes use of a suite of fixed resources: a document corpus; a set of topics; and associated judgments of the relevance of each document to each topic. With large modern collections, exhaustive judging is not feasible. Therefore an approach called pooling is typically used where, for example, the documents to be judged can be determined by taking the union of all documents returned in the top positions of the answer lists returned by a range of systems. Conventionally, pooling uses system variations to provide diverse documents to be judged for a topic; different user queries are not considered. We explore the ramifications of user query variability on pooling, and demonstrate that conventional test collections do not cover this source of variation. The effect of user query variation on the size of the judging pool is just as strong as the effect of retrieval system variation. We conclude that user query variation should be incorporated early in test collection construction, and cannot be considered effectively post hoc.", "references": ["P. Bailey, A. Moffat, F. Scholer, and P. Thomas. User variability and IR system evaluation. In Proc. SIGIR, 2015.", "C. Buckley and J. Walz. The TREC-8 query track. In Proc. TREC, 1999.", "C. Buckley, D. Dimmick, I. Soboroff, and E. Voorhees. Bias and the limits of pooling for large collections. J. Inf. Ret., 10 (6): 491--508, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806606"}, {"title": "SnapToQuery: providing interactive feedback during exploratory query specification", "authors": ["Lilong Jiang\n,", "Arnab Nandi"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nA critical challenge in the data exploration process is discovering and issuing the \"right\" query, especially when the space of possible queries is large. This problem of exploratory query specification is exacerbated by the use of interactive user interfaces driven by mouse, touch, or next-generation, three-dimensional, motion capture-based devices; which, are often imprecise due to jitter and sensitivity issues. In this paper, we propose SnapToQuery, a novel technique that guides users through the query space by providing interactive feedback during the query specification process by \"snapping\" to the user's likely intended queries. These intended queries can be derived from prior query logs, or from the data itself, using methods described in this paper. In order to provide interactive response times over large datasets, we propose two data reduction techniques when snapping to these queries. Performance experiments demonstrate that our algorithms help maintain an interactive experience while allowing for accurate guidance. User studies over three kinds of devices (mouse, touch, and motion capture) show that SnapToQuery can help users specify queries quicker and more accurately; resulting in a query specification time speedup of 1.4× for mouse and touch-based devices and 2.2× for motion capture-based devices.", "references": ["BMW Demonstrates Future iDrive with Touchscreen, Gesture and Tablet Control. CES 2015.", "Gartner Says Worldwide Traditional PC, Tablet, Ultramobile and Mobile Phone Shipments to Grow 4.2 Percent in 2014. Gartner, 2014.", "A. Abouzied, J. Hellerstein, and A. Silberschatz. DataPlay: Interactive Tweaking and Example-driven Correction of Graphical Database Queries. UIST, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809986"}, {"title": "Bridging the Utilitarian-Hedonic Divide in Crowdsourcing Applications", "authors": ["Mark Melenhorst\n,", "Jasminko Novak\n,", "Isabel Micheel\n,", "Martha Larson\n,", "Martin Boeckle"], "publication": "CrowdMM '15: Proceedings of the Fourth International Workshop on Crowdsourcing for Multimedia", "abstract": "ABSTRACT\nThis paper introduces a novel perspective on the gamification of crowdsourcing tasks by conceptualizing it as the introduction of hedonic quality into the solution of utilitarian tasks and into the design of corresponding systems. We demonstrate how such a conceptualization can enable crowdsourcing applications to involve new kinds of crowds in everyday contexts that cannot be reached with existing models. We illustrate its application with the design of TrendRack, a gamified crowdsourcing application in the domain of fashion. We then discuss the results from a first evaluation, suggesting successful engagement of fashion customers in everyday contexts.", "references": ["Ahn, L.v. and Dabbish, L., 2008. Designing games with a purpose. Communications of the ACM, 51, 8, 58--67.", "Bergvall-Kåreborn, B. and Howcroft, D., 2014. Amazon Mechanical Turk and the commodification of labour. New Technology, Work and Employment 29, 3, 213--223.", "Deterding, S., Dixon, D., Khaled, R., and Nacke, L., 2011. From game design elements to gamefulness: defining \"gamification\". In Proc. of the 15th International Academic MindTrek Conference: Envisioning Future Media Environments (Tampere, Finland, 2011), ACM, 9--15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810188.2810191"}, {"title": "Hidden Genes: Understanding cancer data with matrix factorization", "authors": ["Marinka Zitnik"], "publication": "XRDS: Crossroads, The ACM Magazine for Students", "abstract": "", "references": ["Hudson, T. J. et al. International network of cancer genome projects. Nature 464, 7291 (2010), 993--998.", "Lee, D. D., and Seung, H. S. Learning the parts of objects by non-negative matrix factorization. Nature 401, 6755(1999), 788--791.", "Lee, D. D., and Seung, H. S. Algorithms for non-negative matrix factorization. NIPS (2001), 556--562."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788526"}, {"title": "Case Study of Waiting List on WPLC Digital Library", "authors": ["Wooseob Jeong\n,", "Hyejung Han\n,", "Laura Ridenour"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWith the increasing popularity of e-books and audiobooks provided by public libraries in the U.S., the demand does not seem to be met with sufficient supply, as many popular titles require months of waiting time. In this study, we collected data from the Wisconsin Public Library Consortium's digital libraries service once a day for more than two months for selected popular titles. This data reflects the current supply and demand of popular titles in public libraries' digital library services. Based on our data analysis and observation, we suggest ways to achieve faster circulation, which ultimately allows for better services to library users.", "references": ["Library Journal. 2015. 2014 Survey of Ebook Usage in U.S. Public Libraries: http://www.thedigitalshift.com/research/ebook-usage-u-s-public-libraries-2014-report/", "Tefko, S. 2000. Digital library evaluation: Toward evolution of concepts. Library Trends 49, 2, 350--369.", "Human Factors International. 2000. Human interaction speed. Newsletter. August. http://www.humanfactors.com/newsletters/human_interaction_speeds.asp"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756961"}, {"title": "Determining Influential Users with Supervised Random Walks", "authors": ["Georgios Katsimpras\n,", "Dimitrios Vogiatzis\n,", "Georgios Paliouras"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe emergence of social media and the enormous growth of social networks have initiated a great amount of research in social influence analysis. In this regard, many approaches take into account only structural information while a few have also incorporated content. In this study we propose a new method to rank users according to their topic-sensitive influence which utilizes a priori information by employing supervised random walks. We explore the use of supervision in a PageRank-like random walk while also exploiting textual information from the available content. We perform a set of experiments on Twitter datasets and evaluate our findings.", "references": ["L. Backstrom and J. Leskovec. Supervised Random Walks: Predicting and Recommending Links in Social Networks. Nov. 2010.", "B. Bi, Y. Tian, Y. Sismanis, A. Balmin, and J. Cho. Scalable topic-specific influence analysis on microblogs. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining, WSDM '14, pages 513--522, New York, NY, USA, 2014. ACM.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742472"}, {"title": "ESC: Dataset for Environmental Sound Classification", "authors": ["Karol J. Piczak"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nOne of the obstacles in research activities concentrating on environmental sound classification is the scarcity of suitable and publicly available datasets. This paper tries to address that issue by presenting a new annotated collection of 2000 short clips comprising 50 classes of various common sound events, and an abundant unified compilation of 250000 unlabeled auditory excerpts extracted from recordings available through the Freesound project. The paper also provides an evaluation of human accuracy in classifying environmental sounds and compares it to the performance of selected baseline classifiers using features derived from mel-frequency cepstral coefficients and zero-crossing rate.", "references": ["BBC sound effects library. http://www.sound-ideas.com/sound-effects/bbc-sound-effects.html. (Aug. 5, 2015).", "E. Alexandre et al. Feature selection for sound classification in hearing aids through restricted search driven by genetic algorithms. IEEE Transactions on Audio, Speech, and Language Processing, 15(8):2249--2256, 2007.", "L. Ballan et al. Deep networks for audio event classification in soccer videos. In Proceedings of the IEEE International Conference on Multimedia and Expo, pages 474--477, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806390"}, {"title": "Geospatial event analytics leveraging reactive programming", "authors": ["Christoph Doblander\n,", "Thomas Parsch\n,", "Hans-Arno Jacobsen"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nIn this paper, we present a solution to this year's DEBS Grand Challenge based on concepts from reactive systems. Reactive systems is a system architecture style with the following properties: Responsive, resilient, elastic, and message driven. When systems are built based on these properties, they tend to be more flexible, loosely-coupled, and scaleable. In this paper, we describe how to combine the operators given in the ReactiveX API to realize the individual challenge queries using asynchronous data-flows and evaluate the performance.", "references": ["Reactive Programming in the Netflix API with RxJava. http://techblog.netflix.com/2013/02/rxjava-netflix-api.html.", "Reactive Systems. http://www.reactivemanifesto.org/.", "ReactiveX. http://reactivex.io/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2776757"}, {"title": "Mining StackOverflow to filter out off-topic IRC discussion", "authors": ["Shaiful Alam Chowdhury\n,", "Abram Hindle"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nInternet Relay Chat (IRC) is a commonly used tool by OpenSource developers. Developers use IRC channels to discuss programming related problems, but much of the discussion is irrelevant and off-topic. Essentially if we treat IRC discussions like email messages, and apply spam filtering, we can try to filter out the spam (the off-topic discussions) from the ham (the programming discussions). Yet we need labelled data that unfortunately takes time to curate.\nTo avoid costly curration in order to filter out off-topic discussions, we need positive and negative data-sources. Online discussion forums, such as StackOverflow, are very effective for solving programming problems. By engaging in open-data, StackOverflow data becomes a powerful source of labelled text regarding programming. This work shows that we can train classifiers using StackOverflow posts as positive examples of on-topic programming discussion. YouTube video comments, notorious for their lack of quality, serve as training set of off-topic discussion. By exploiting these datasets, accurate classifiers can be built, tested and evaluated that require very little effort for end-users to deploy and exploit.", "references": ["C. C. Aggarwal and C. Zhai. A survey of text classification algorithms. In Mining Text Data, pages 163--222. Springer, 2012.", "S. Bird. Nltk: The natural language toolkit. In COLING-ACL, pages 69--72, Sydney, Australia, Jul. 2006.", "P. Cao, D. Zhao, and O. Zaiane. An optimized cost-sensitive svm for imbalanced data learning. In Advances in Knowledge Discovery and Data Mining, volume 7819, pages 280--292. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820577"}, {"title": "TDV-based Filter for Novelty and Diversity in a Real-time Pub/Sub System", "authors": ["Zeinab Hmedeh\n,", "Cedric du Mouza\n,", "Nicolas Travers"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nPublish/Subscribe (Pub/Sub) systems have been designed to face the exponential growth of information published on the Web by subscribing to sources of interest which produce flows of items. However users may receive some information several times, or information that does not contain any new content, and conversely miss some information of interest hidden in all information received. Pub/Sub systems are consequently witnessing a real challenge to efficiently filter relevant information. We propose in this paper a scalable approach for filtering news (items) which match the user interests (expressed as subscriptions). Introducing for the first time Term Discrimination Value (TDV) in this context, which allows to measure how a term discrimines an item, we filter out in real-time items whose content has already been notified recently to the user, either in another item (filtering by novelty) or globally in his recent history (filtering by diversity). Our experiments illustrate the impact of our different parameters and confirm the scalability of our approach and the relevance of the results notified.", "references": ["S. Abbar, S. Amer-Yahia, P. Indyk, and S. Mahabadi. Real-time Recommendation of Diverse Related Articles. In World Wide Web Conference (WWW), pages 1--12, 2013.", "A. Angel and N. Koudas. Efficient Diversity-Aware Search. In International Conference on Management of Data (SIGMOD), pages 781--792, 2011.", "R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval. ACM Press / Addison-Wesley, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790768"}, {"title": "Attention Please! A Hybrid Resource Recommender Mimicking Attention-Interpretation Dynamics", "authors": ["Paul Seitlinger\n,", "Dominik Kowald\n,", "Simone Kopeinik\n,", "Ilire Hasani-Mavriqi\n,", "Elisabeth Lex\n,", "Tobias Ley"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nClassic resource recommenders like Collaborative Filtering (CF) treat users as being just another entity, neglecting non-linear user-resource dynamics shaping attention and interpretation. In this paper, we propose a novel hybrid recommendation strategy that refines CF by capturing these dynamics. The evaluation results reveal that our approach substantially improves CF and, depending on the dataset, successfully competes with a computationally much more expensive Matrix Factorization variant.", "references": ["P. Adamopoulos and A. Tuzhilin. On over-specialization and concentration bias of recommendations. In Proc. of RecSys'14, RecSys '14, pages 153--160, New York, NY, USA, 2014. ACM.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734--749, 2005.", "A. Bar, L. Rokach, G. Shani, B. Shapira, and A. Schclar. Improving simple collaborative filtering models using ensemble methods. In Multiple Classifier Systems, pages 1--12. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743057"}, {"title": "Discovering Subsumption Relationships for Web-Based Ontologies", "authors": ["Dana Movshovitz-Attias\n,", "Steven Euijong Whang\n,", "Natalya Noy\n,", "Alon Halevy"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nAs search engines are becoming smarter at interpreting user queries and providing meaningful responses, they rely on ontologies to understand the meaning of entities. Creating ontologies manually is a laborious process, and resulting ontologies may not reflect the way users think about the world, as many concepts used in queries are noisy, and not easily amenable to formal modeling. There has been considerable effort in generating ontologies from Web text and query streams, which may be more reflective of how users query and write content. In this paper, we describe the LATTE system that automatically generates a subconcept--superconcept hierarchy, which is critical for using ontologies to answer queries. LATTE combines signals based on word-vector representations of concepts and dependency parse trees; however, LATTE derives most of its power from an ontology of attributes extracted from the Web that indicates the aspects of concepts that users find important. LATTE achieves an F1 score of 74%, which is comparable to expert agreement on a similar task. We additionally demonstrate the usefulness of LATTE in detecting high quality concepts from an existing resource of IsA links.", "references": ["K. Bellare, P. P. Talukdar, G. Kumaran, F. Pereira, M. Liberman, A. McCallum, and M. Dredze. Lightly-supervised attribute extraction. NIPS 2007 Workshop on Machine Learning for Web Search, 2007.", "J. Bhogal, A. Macfarlane, and P. Smith. A review of ontology based query expansion. Information processing &amp; management, 43(4):866--886, 2007.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247--1250. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767111"}, {"title": "From Chirps to Whistles: Discovering Event-specific Informative Content from Twitter", "authors": ["Debanjan Mahata\n,", "John R. Talburt\n,", "Vivek Kumar Singh"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nTwitter has brought a paradigm shift in the way we produce and curate information about real-life events. Huge volumes of user-generated tweets are produced in Twitter, related to events. Not, all of them are useful and informative. A sizable amount of tweets are spams and colloquial personal status updates, which does not provide any useful information about an event. Thus, it is necessary to identify, rank and segregate event-specific informative content from the tweet streams. In this paper, we develop a novel generic framework based on the principle of mutual reinforcement, for identifying event-specific informative content from Twitter. Mutually reinforcing relationships between tweets, hashtags, text units, URLs and users are defined and represented using TwitterEventInfoGraph. An algorithm - TwitterEventInfoRank is proposed, that simultaneously ranks tweets, hashtags, text units, URLs and users producing them, in terms of event-specific informativeness by leveraging the semantics of relationships between each of them as represented by TwitterEventInfoGraph. Experiments and observations are reported on four million (approx) tweets collected for five real-life events, and evaluated against popular baseline techniques showing significant improvement in performance.", "references": ["Alejandro, M., and Paloma, M. The use of metrics for measuring informality levels in web 2.0 texts.", "Baeza-Yates, R., Ribeiro-Neto, B., et al. Modern information retrieval, vol. 463. ACM press New York, 1999.", "Barrons, G. Śsuleiman: Mubarak decided to step down# egypt# jan25 oh my godŠ: Examining the use of social media in the 2011 egyptian revolution. Contemporary Arab Affairs 5, 1 (2012), 54--67."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786476"}, {"title": "Towards automatic constraints elicitation in pair-wise testing based on a linguistic approach: elicitation support using coupling strength", "authors": ["Hiroyuki Nakagawa\n,", "Tatsuhiro Tsuchiya"], "publication": "RET '15: Proceedings of the Second International Workshop on Requirements Engineering and Testing", "abstract": "ABSTRACT\nThis paper focuses on the constraints elicitation in the combinatorial test design. Pair-wise testing, a common combinatorial testing approach, is an effective test planning technique to find interaction faults from the relatively small set of test cases. The test space is modeled by a set of parameters, their individual values, and constraints on the value combinations. Constraints reduce the test space; however, little consideration has been given to the process of finding them. The goal of our study is to establish an automatic constraints acquisition from the requirements document. We try to establish a constraints elicitation mechanism that helps to extract constraints from the requirements document based on a linguistic approach. In this paper, as the first step, we attempt to extract the coupling strength between parameters from the requirements document. We conducted a preliminary experiment on an ATM system example and evaluated the feasibility of our approach.", "references": ["D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. Patton, \"The AETG system: An approach to testing based on combinatorial design,\" IEEE Transactions on Software Engineering, vol. 23, no. 7, pp. 437--444, Jul. 1997. {Online}. Available: http://dx.doi.org/10.1109/32.605761", "C. Nie and H. Leung, \"A survey of combinatorial testing,\" ACM Computing Surveys (CSUR), vol. 43, no. 2, pp. 11:1--11:29, Feb. 2011. {Online}. Available: http://doi.acm.org/10.1145/1883612.1883618", "D. Blue, I. Segall, R. Tzoref-Brill, and A. Zlotnick, \"Interaction-based test-suite minimization,\" in Proc. of the 2013 International Conference on Software Engineering (ICSE 2013). Piscataway, NJ, USA: IEEE Press, 2013, pp. 182--191. {Online}. Available: http://dl.acm.org/citation.cfm?id=2486788.2486813"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820704.2820714"}, {"title": "Machine Learning in Textual Content-Based Recommendation Systems: A Systematic Review", "authors": ["Lucas F. Brunialti\n,", "Sarajane M. Peres\n,", "Valdinei Freire\n,", "Clodoaldo A. M. Lima"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nContent-based Recommendation Systems (CbRS) is a research area in which Machine Learning (ML) strategies can be applied with success. However, specifically in textual CbRS, the use of ML has not been expressive in recent years. To contribute to the evolution of the intersection of such areas, we present a Systematic Review to identify, interpret and evaluate how the ML strategies have been applied to CbRS.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. 17(6):734-749, 2005.", "W. Afzal, R. Torkar, and R. Feldt. A systematic review of search-based testing for nonfunctional system properties. 51(6):957-976, 2009.", "D. Bell, J. Guan, and Y. Bi. On combining classifier mass functions for text categorization. 17(10):1307-1319, Oct 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814092"}, {"title": "Session details: Session 2D: Clustering", "authors": ["Ravi Kumar"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252287"}, {"title": "An Introduction to Click Models for Web Search: SIGIR 2015 Tutorial", "authors": ["Aleksandr Chuklin\n,", "Ilya Markov\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this introductory tutorial we give an overview of click models for web search. We show how the framework of probabilistic graphical models help to explain user behavior, build new evaluation metrics and perform simulations. The tutorial is augmented with a live demo where participants have a chance to implement a click model and to test it on a publicly available dataset.", "references": ["O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In WWW, pages 1--10, 2009. 10.1145/1526709.1526711.", "A. Chuklin, I. Markov, and M. de Rijke. Click Models for Web Search. Morgan & Claypool, 2015. To appear.", "N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An experimental comparison of click position-bias models. In WSDM, pages 87--94, 2008. 10.1145/1341531.1341545."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767881"}, {"title": "Media Synchronization and Sub-Event Detection in Multi-User Image Collections", "authors": ["Maia Zaharieva\n,", "Michael Riegler"], "publication": "HuEvent '15: Proceedings of the 2nd ACM International Workshop on Human-centered Event Understanding from Multimedia", "abstract": "ABSTRACT\nPersonal media capturing devices, such as smartphones or personal image and video cameras, are rarely synchronized. As a result, common tasks, like event detection and summarization across different multi-user media galleries, are considerably impeded and error-prone. In this paper, we investigate different approaches for the synchronization of image collections using visual information only. We perform a thorough evaluation of the performance of several global features on three datasets. Additionally, we explore the feasibility of common clustering algorithms for the detection of sub-events in the presence of synchronization misalignment.", "references": ["M. Ba\\c stan, H.c Cam, U. Güdükbay, and O. Ulusoy. Bilvideo-7: an MPEG-7-compatible video indexing and retrieval system. IEEE MultiMedia, 17(3):62--73, 2010.", "H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust features (surf). Computer Vision and Image Understanding, 110(3):346--359, 2008.", "G. Blakowski and R. Steinmetz. A media synchronization survey: reference model, specification, and case studies. IEEE J. on Selected Areas in Communications, 14(1):5--35, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815244.2815248"}, {"title": "The MovieLens Datasets: History and Context", "authors": ["F. Maxwell Harper\n,", "Joseph A. Konstan"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nThe MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.", "references": ["Shuo Chang, F. Maxwell Harper, and Loren Terveen. 2015. Using groups of items for preference elicitation in recommender systems. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing (CSCW&rsquo;’15). ACM, New York, NY, 1258--1269. DOI:http://dx.doi.org/10.1145/2675133.2675210", "Dan Cosley, Dan Frankowski, Sara Kiesler, Loren Terveen, and John Riedl. 2005. How oversight improves member-maintained communities. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’05). ACM, New York, NY, 11--20. DOI:http://dx.doi.org/10.1145/1054972.1054975", "Dan Cosley, Shyong K. Lam, Istvan Albert, Joseph A. Konstan, and John Riedl. 2003. Is seeing believing?: How recommender system interfaces affect users’ opinions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’03). ACM, New York, NY, 585--592. DOI:http://dx.doi.org/10.1145/642611.642713", "Abhinandan S. Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram. 2007. Google news personalization: scalable online collaborative filtering. In Proceedings of the 16th International Conference on World Wide Web (WWW’07). ACM, New York, NY, 271--280. DOI:http://dx.doi.org/10.1145/1242572.1242610", "Mukund Deshpande and George Karypis. 2004. Item-based top-N recommendation algorithms. ACM Transactions on Information Systems 22, 1, 143--177. DOI:http://dx.doi.org/10.1145/963770.963776", "Sara Drenner, Max Harper, Dan Frankowski, John Riedl, and Loren Terveen. 2006. Insert movie reference here: A system to bridge conversation and item-oriented web sites. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI’06). ACM, New York, NY, 951--954. DOI:http://dx.doi.org/10.1145/1124772.1124914", "Gideon Dror, Yahoo Labs, Noam Koenigstein, Yehuda Koren, and Markus Weimer. 2012. The Yahoo&excl; music dataset and KDDCup11. In Journal of Machine Learning Research Workshop and Conference Proceedings: Proceedings of KDD Cup 2011. 3--18.", "Michael D. Ekstrand, Daniel Kluver, F. Maxwell Harper, and Joseph A. Konstan. 2015. Letting users choose recommender algorithms: An experimental study. In Proceedings of the 9th ACM Conference on Recommender Systems (RecSys’15). ACM, New York, NY, 11--18. DOI:http://dx.doi.org/10.1145/2792838.2800195", "Michael D. Ekstrand, Michael Ludwig, Joseph A. Konstan, and John T. Riedl. 2011. Rethinking the recommender research ecosystem: Reproducibility, openness, and lenskit. In Proceedings of the 5th ACM Conference on Recommender Systems (RecSys’11). ACM, New York, NY, 133--140. DOI:http://dx.doi.org/10.1145/2043932.2043958", "Malcolm Gladwell. 1999. The science of the sleeper. The New Yorker. Retrieved November 13, 2015 from http://gladwell.com/the-science-of-the-sleeper/.", "Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. 2001. Eigentaste: A constant time collaborative filtering algorithm. Information Retrieval 4, 2, 133--151. DOI:http://dx.doi.org/10.1023/A:1011419012209", "F. Maxwell Harper, Dan Frankowski, Sara Drenner, Yuqing Ren, Sara Kiesler, Loren Terveen, Robert Kraut, and John Riedl. 2007a. Talk amongst yourselves: Inviting users to participate in online conversations. In Proceedings of the 12th International Conference on Intelligent User Interfaces (IUI’07). ACM, New York, NY, 62--71. DOI:http://dx.doi.org/10.1145/1216295.1216313", "F. Maxwell Harper, Shilad Sen, and Dan Frankowski. 2007b. Supporting social recommendations with activity-balanced clustering. In Proceedings of the 2007 ACM Conference on Recommender Systems (RecSys’07). ACM, New York, NY, 165--168. DOI:http://dx.doi.org/10.1145/1297231.1297262", "F. Maxwell Harper, Funing Xu, Harmanpreet Kaur, Kyle Condiff, Shuo Chang, and Loren Terveen. 2015. Putting users in control of their recommendations. In Proceedings of the 9th ACM Conference on Recommender Systems (RecSys’15). ACM, New York, NY, 3--10. DOI:http://dx.doi.org/10.1145/2792838.2800179", "George Karypis. 2001. Evaluation of item-based top-N recommendation algorithms. In Proceedings of the 10th International Conference on Information and Knowledge Management (CIKM’01). ACM, New York, NY, 247--254. DOI:http://dx.doi.org/10.1145/502585.502627", "Joseph A. Konstan, Bradley N. Miller, David Maltz, Jonathan L. Herlocker, Lee R. Gordon, and John Riedl. 1997. GroupLens: Applying collaborative filtering to Usenet news. Communications of the ACM 40, 3, 77--87. DOI:http://dx.doi.org/10.1145/245108.245126", "Joseph A. Konstan, J. D. Walker, D. Christopher Brooks, Keith Brown, and Michael D. Ekstrand. 2014. Teaching recommender systems at large scale: Evaluation and lessons learned from a hybrid MOOC. In Proceedings of the 1st ACM Conference on Learning @ Scale Conference (L@S’14). ACM, New York, NY, 61--70. DOI:http://dx.doi.org/10.1145/2556325.2566244", "John G. Lynch, Jr., Dipankar Chakravarti, and Anusree Mitra. 1991. Contrast effects in consumer judgments: Changes in mental representations or in the anchoring of rating scales? Journal of Consumer Research 18, 3, 284--297.", "Paolo Massa and Paolo Avesani. 2007. Trust-aware recommender systems. In Proceedings of the 2007 ACM Conference on Recommender Systems (RecSys’07). ACM, New York, NY, 17--24. DOI:http://dx.doi.org/10.1145/1297231.1297235", "Julian McAuley, Rahul Pandey, and Jure Leskovec. 2015a. Inferring networks of substitutable and complementary products. In Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’15). ACM, New York, NY, 785--794. DOI:http://dx.doi.org/10.1145/2783258.2783381", "Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015b. Image-based recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’15). ACM, New York, NY, 43--52. DOI:http://dx.doi.org/10.1145/2766462.2767755", "Bradley Norman Miller. 2003. Toward a Personal Recommender System. Ph.D. dissertation. University of Minnesota, Minneapolis, MN. Retrieved from http://search.proquest.com/dissertations/docview/305324342/abstract/A46BCC87FC4D4DD4PQ/1?accountid&equals;14586.", "Mark O’Connor, Dan Cosley, Joseph A. Konstan, and John Riedl. 2001. PolyLens: A recommender system for groups of users. In Proceedings of the 7th Conference on European Conference on Computer Supported Cooperative Work (ECSCW’01). Kluwer Academic Publishers, Norwell, MA, 199--218.", "John O’Donovan and Barry Smyth. 2005. Trust in recommender systems. In Proceedings of the 10th International Conference on Intelligent User Interfaces (IUI’05). ACM, New York, NY, 167--174. DOI:http://dx.doi.org/10.1145/1040830.1040870", "Nick Pentreath. 2015. Machine Learning with Spark. Packt Publishing Ltd, Birmingham, UK.", "Reid Priedhorsky, Mikhil Masli, and Loren Terveen. 2010. Eliciting and focusing geographic volunteer work. In Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work (CSCW’10). ACM, New York, NY, 61--70. DOI:http://dx.doi.org/10.1145/1718918.1718931", "Al Mamunur Rashid, Istvan Albert, Dan Cosley, Shyong K. Lam, Sean M. McNee, Joseph A. Konstan, and John Riedl. 2002. Getting to know you: Learning new user preferences in recommender systems. In Proceedings of the 7th International Conference on Intelligent User Interfaces (IUI’02). ACM, New York, NY, 127--134. DOI:http://dx.doi.org/10.1145/502716.502737", "Al Mamunur Rashid, George Karypis, and John Riedl. 2008. Learning preferences of new users in recommender systems: An information theoretic approach. ACM SIGKDD Explorations Newsletter 10, 2, 90--100. DOI:http://dx.doi.org/10.1145/1540276.1540302", "Yuqing Ren, F. Harper, Sara Drenner, Loren Terveen, Sara Kiesler, John Riedl, and Robert Kraut. 2012. Building member attachment in online communities: Applying theories of group identity and interpersonal bonds. Management Information Systems Quarterly 36, 3 (Sept. 2012), 841--864.", "Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, and John Riedl. 1994. GroupLens: An open architecture for collaborative filtering of Netnews. In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work (CSCW’94). ACM, New York, NY, 175--186. DOI:http://dx.doi.org/10.1145/192844.192905", "Eric Ries. 2011. The Lean Startup: How Today’s Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses. Crown Business, New York, NY.", "Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2000. Application of Dimensionality Reduction in Recommender System—A Case Study. Technical Report. DTIC Document. Retrieved from http://oai.dtic.mil/oai/oai?verb&equals;getRecord&metadataPrefix&equals;&equals;html&identifier&equals;&equals;ADA439541.", "Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th International Conference on World Wide Web (WWW’01). ACM, New York, NY, 285--295. DOI:http://dx.doi.org/10.1145/371920.372071", "Andrew I. Schein, Alexandrin Popescul, Lyle H. Ungar, and David M. Pennock. 2002. Methods and metrics for cold-start recommendations. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’02). ACM, New York, NY, 253--260. DOI:http://dx.doi.org/10.1145/564376.564421", "Toby Segaran. 2007. Programming Collective Intelligence: Building Smart Web 2.0 Applications. O’Reilly Media, Inc., Sebastopol, CA.", "Shilad Sen, F. Maxwell Harper, Adam LaPitz, and John Riedl. 2007. The quest for quality tags. In Proceedings of the 2007 International ACM Conference on Supporting Group Work (GROUP’07). ACM, New York, NY, 361--370. DOI:http://dx.doi.org/10.1145/1316624.1316678", "Shilad Sen, Shyong K. Lam, Al Mamunur Rashid, Dan Cosley, Dan Frankowski, Jeremy Osterhouse, F. Maxwell Harper, and John Riedl. 2006. Tagging, communities, vocabulary, evolution. In Proceedings of the 2006 20th Anniversary Conference on Computer Supported Cooperative Work (CSCW’06). ACM, New York, NY, 181--190. DOI:http://dx.doi.org/10.1145/1180875.1180904", "Shilad Sen, Jesse Vig, and John Riedl. 2009. Learning to recognize valuable tags. In Proceedings of the 14th International Conference on Intelligent User Interfaces (IUI’09). ACM, New York, NY, 87--96. DOI:http://dx.doi.org/10.1145/1502650.1502666", "Guy Shani and Asela Gunawardana. 2011. Evaluating recommendation systems. In Recommender Systems Handbook, Francesco Ricci, Lior Rokach, Bracha Shapira, and Paul B. Kantor (Eds.). Springer US, New York, NY, 257--297. http://link.springer.com/chapter/10.1007/978-0-387-85820-3_8", "Jesse Vig, Shilad Sen, and John Riedl. 2012. The tag genome: Encoding community knowledge to support novel interaction. ACM Transactions on Interactive Intelligent Systems 2, 3, 13:1--13:44. DOI:http://dx.doi.org/10.1145/2362394.2362395", "Jesse Vig, Matthew Soukup, Shilad Sen, and John Riedl. 2010. Tag expression: Tagging with feeling. In Proceedings of the 23rd Annual ACM Symposium on User Interface Software and Technology (UIST’10). ACM, New York, NY, 323--332. DOI:http://dx.doi.org/10.1145/1866029.1866079", "Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. 2005. Improving recommendation lists through topic diversification. In Proceedings of the 14th International Conference on World Wide Web (WWW’05). ACM, New York, NY, 22--32. DOI:http://dx.doi.org/10.1145/1060745.1060754"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2827872"}, {"title": "Web Search Credibility Assessment for Individuals who are Blind", "authors": ["Ali Abdolrahmani\n,", "Ravi Kuber\n,", "William Easley"], "publication": "ASSETS '15: Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility", "abstract": "ABSTRACT\nWhile screen reading technologies offer considerable promise to individuals who are blind by providing an accessible overview of web-based content, difficulties can be faced determining the credibility of sites and their respective contents. This can impact the user's behavior, particularly if sensitive information needs to be entered (e.g. into a web-based form). In this paper, we describe an exploratory study examining the criteria which blind screen reader users utilize to assess credibility. More specifically, we have focused on the common task of web searching and exploring search results. Findings from the study have suggested that mismatches between the title of the search results and their respective snippets, along with the richness and accessibility of the content when search results are selected, can lead to users determining whether sites are indeed credible.", "references": ["Chandrashekar, S., 2010. Is Hearing Believing-- Perception of Online Information Credibility by Screen Reader Users who are Blind or Visually Impaired. Doctoral thesis, University of Toronto, Canada.", "Fogg, B.J. 2003. Persuasive Technology: Using Computers to Change What We Think and Do. Morgan Kaufmann.", "Leuthold, S., Bargas-Avila, J.A., and Opwis, K., 2008. Beyond web content accessibility guidelines: Design of enhanced text user interfaces for blind internet users--. Int J Hum Comput Stud 66, 4, 257--270."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700648.2811349"}, {"title": "Reformulation-based query answering in RDF: alternatives and performance", "authors": ["Damian Bursztyn\n,", "François Goasdoué\n,", "Ioana Manolescu"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nAnswering queries over Semantic Web data, i.e., RDF graphs, must account for both explicit data and implicit data, entailed by the explicit data and the semantic constraints holding on them. Two main query answering techniques have been devised, namely Saturation-based (Sat) which precomputes and adds to the graph all implicit information, and Reformulation-based (Ref) which reformulates the query based on the graph constraints, so that evaluating the reformulated query directly against the explicit data (i.e., without considering the constraints) produces the query answer.\nWhile Sat is well known, Ref has received less attention so far. In particular, reformulated queries often perform poorly if the query is complex. Our demonstration showcases a large set of Ref techniques, including but not limited to one we proposed recently. The audience will be able to 1: test them against different datasets, constraints and queries, as well as different well-established systems, 2: analyze and understand the performance challenges they raise, and 3: alter the scenarios to visualize the impact on performance. In particular, we show how a cost-based Ref approach allows avoiding reformulation performance pitfalls.", "references": ["S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases. Addison-Wesley, 1995.", "M. Arenas, C. Gutierrez, and J. Pérez. Foundations of rdf databases. In Reasoning Web, 2009.", "F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi, and P. F. Patel-Schneider, editors. The Description Logic Handbook: Theory, Implem., and Applications, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824093"}, {"title": "A Survey of Architectural Techniques for Near-Threshold Computing", "authors": ["Sparsh Mittal"], "publication": "ACM Journal on Emerging Technologies in Computing Systems", "abstract": "Abstract\nEnergy efficiency has now become the primary obstacle in scaling the performance of all classes of computing systems. Low-voltage computing, specifically, near-threshold voltage computing (NTC), which involves operating the transistor very close to and yet above its threshold voltage, holds the promise of providing many-fold improvement in energy efficiency. However, use of NTC also presents several challenges such as increased parametric variation, failure rate, and performance loss. This article surveys several recent techniques that aim to offset these challenges for fully leveraging the potential of NTC. By classifying these techniques along several dimensions, we also highlight their similarities and differences. It is hoped that this article will provide insights into state-of-the-art NTC techniques to researchers and system designers and inspire further research in this field.", "references": ["Jaume Abella, Javier Carretero, Pedro Chaparro, Xavier Vera, and Antonio González. 2009. Low Vccmin fault-tolerant cache with highly predictable performance. In International Symposium on Microarchitecture. 111--121.", "Jaume Abella, Pedro Chaparro, Xavier Vera, Javier Carretero, and Antonio González. 2010. High-performance Low-Vcc in-order core. In International Symposium on High Performance Computer Architecture (HPCA’10). 1--11.", "Vishal Ahuja, Dipak Ghosal, and Matthew Farrens. 2012. Minimizing the data transfer time using multicore end-system aware flow bifurcation. In IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid’12). 595--602."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2821510"}, {"title": "Is Stack Overflow Overflowing With Questions and Tags", "authors": ["R. K. Ranjitha\n,", "Sanjay Singh"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nProgramming question and answer (Q&A) websites, such as Quora, Stack Overflow, and Yahoo! Answer etc. helps us to understand the programming concepts easily and quickly in a way that has been tested and applied by many software developers. Stack Overflow is one of the most frequently used programming Q&A website where the questions and answers posted are presently analyzed manually, which requires a huge amount of time and resource. To save the effort, we present a topic modeling based technique to analyze the words of the original texts to discover the themes that run through them. We also propose a method to automate the process of reviewing the quality of questions on Stack Overflow dataset in order to avoid ballooning the stack overflow with insignificant questions. The proposed method also recommends the appropriate tags for the new post, which averts the creation of unnecessary tags on Stack Overflow.", "references": ["L. A. Adamic, J. Zhang, E. Bakshy, and M. S. Ackerman. Knowledge sharing and yahoo answers: Everyone knows something. In Proceedings of the 17th International Conference on World Wide Web, WWW '08, pages 665--674, New York, NY, USA, 2008. ACM.", "A. E. H. Anton Barua, Stephen W. Thomas. What are developers talking about? an analysis of topics and trends in stack overflow. Empirical Software Engineering, 19(3):619--654, June 2014.", "S. K. Bajracharya and C. V. Lopes. Analyzing and mining a code search engine usage log. Empirical Softw. Engg., 17(4-5):424--466, Aug 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791537"}, {"title": "Query-by-Emoji Video Search", "authors": ["Spencer Cappallo\n,", "Thomas Mensink\n,", "Cees G.M. Snoek"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis technical demo presents Emoji2Video, a query-by-emoji interface for exploring video collections. Ideogram-based video search and representation presents an opportunity for an intuitive, visual interface and concise non-textual summary of video contents, in a form factor that is ideal for small screens. The demo allows users to build search strings comprised of ideograms which are used to query a large dataset of YouTube videos. The system returns a list of the top-ranking videos for the user query along with an emoji summary of the video contents so that users may make an informed decision whether to view a video or refine their search terms. The ranking of the videos is done in a zero-shot, multi-modal manner that employs an embedding space to exploit semantic relationships between user-selected ideograms and the video's visual and textual content.", "references": ["S. Cappallo, T. Mensink, and C. G. M. Snoek. Image2emoji: Zero-shot emoji prediction for visual media. In ACM MM. ACM, 2015.", "A. Habibian, T. Mensink, and C. G. M. Snoek. Videostory: A new multimedia embedding for few-example recognition and translation of events. In ACM MM. ACM, 2014.", "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807961"}, {"title": "WikiKreator: automatic authoring of Wikipedia content", "authors": ["Siddhartha Banerjee\n,", "Prasenjit Mitra"], "publication": "AI Matters", "abstract": "Abstract\nThis article describes ongoing dissertation work on the automatic generation of Wikipedia articles. The goal of this work is to build an AI system to automatically summarize existing web content and utilize the resulting text to improve incomplete Wikipedia articles.", "references": ["Banerjee, S., Caragea, C., & Mitra, P. (2014). Playscript Classification and Automatic Wikipedia Play Articles Generation. In 22nd International Conference on Pattern Recognition (ICPR), Stockholm.", "Banerjee, S., & Mitra, P. (2015a). Filling the Gaps: Improving Wikipedia Stubs. In the 15th ACM SIGWEB International Symposium on Document Engineering (DocEng). Laussanne, Switzerland: ACM.", "Banerjee, S., & Mitra, P. (2015b). WikiKreator: Improving Wikipedia Stubs Automatically. In the 53rd Annual Meeting of the Association for Computational Linguistics (ACL). Beijing, China: ACL."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813536.2813538"}, {"title": "Using Context to Get Novel Recommendation in Internet Message Streams", "authors": ["Doina Alexandra Dumitrescu\n,", "Simone Santini"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nNovelty detection algorithms usually employ similarity measures with the previous seen and relevant documents to decide if a document is of user's interest. The problem that arises by using this approach is that the system might recommend redundant documents. Thus, it has become extremely important to be able to distinguish between \"redundant\" and \"novel\" information. To address this limitation, we apply a contextual and semantic approach by building the user profile using self-organizing maps that have the advantage to easily follow the changes in the users interests.", "references": ["C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Büttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '08, pages 659--666, New York, NY, USA, 2008. ACM.", "K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. Eigentaste: A constant time collaborative filtering algorithm. Inf. Retr., 4(2):133--151, July 2001.", "S. Kaski. Computationally efficient approximation of a probabilistic model for document representation in the websom full-text analysis method. Neural Processing Letters, 5(2):69--81, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742473"}, {"title": "Session details: Special Track - Experience Reports in Industry and Case Studies", "authors": ["Claudia Cappelli\n,", "Arnaldo Alves Ferreira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252438"}, {"title": "The DBpedia wayback machine", "authors": ["Javier D. Fernández\n,", "Patrik Schneider\n,", "Jürgen Umbrich"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nDBpedia is one of the biggest and most important focal point of the Linked Open Data movement. However, in spite of its multiple services, it lacks a wayback mechanism to retrieve historical versions of resources at a given timestamp in the past, thus preventing systems to work on the full history of RDF documents. In this paper, we present a framework that serves this mechanism and is publicly offered through a Web UI and a RESTful API, following the Linked Open Data principles.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. In Proc. of ISWC, 2007.", "S. Bischof, C. Martin, A. Polleres, and P. Schneider. Open City Data Pipeline - Collecting, Integrating, and Predicting Open City Data. In Proc. of Know@LOD, 2015.", "D. Brickley, R. Guha, and (eds.). RDF Vocabulary Description Language 1.0: RDF Schema. W3C Recommendation, W3C, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814889"}, {"title": "Contour trees of uncertain terrains", "authors": ["Wuzhou Zhang\n,", "Pankaj K. Agarwal\n,", "Sayan Mukherjee"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nWe study contour trees of terrains, which encode the topological changes of the level set of the height value ℓ as we raise ℓ from -∞ to +∞ on the terrains, in the presence of uncertainty in data. We assume that the terrain is represented by a piecewise-linear height function over a planar triangulation M, by specifying the height of each vertex. We study the case when M is fixed and the uncertainty lies in the height of each vertex in the triangulation, which is described by a probability distribution. We present efficient sampling-based Monte Carlo methods for estimating, with high probability, (i) the probability that two points lie on the same edge of the contour tree, within additive error; (ii) the expected distance of two points p, q and the probability that the distance of p, q is at least ℓ on the contour tree, within additive error, where the distance of p, q on a contour tree is defined to be the difference between the maximum height and the minimum height on the unique path from p to q on the contour tree. The main technical contribution of the paper is to prove that a small number of samples are sufficient to estimate these quantities. We present two applications of these algorithms, and also some experimental results to demonstrate the effectiveness of our approach.", "references": ["P. K. Agarwal, L. Arge, T. Mølhave, M. Revsbæk, and J. Yang. Maintaining contour trees of dynamic terrains. In Proc. 31st SoCG, 796--811, 2015.", "P. K. Agarwal, L. Arge, and K. Yi. I/O-efficient batched union-find and its applications to terrain analysis. ACM Trans. Algs., 7:11:1--11:21, 2010.", "P. K. Agarwal and M. Sharir. Arrangements and their applications. (J.-R. Sack and J. Urrutia, eds.), Handbook of Computational Geometry, 49--119. Elsevier, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820823"}, {"title": "Generating Music from an Image", "authors": ["Gwenaelle C. Sergio\n,", "Rammohan Mallipeddi\n,", "Jun-Su Kang\n,", "Minho Lee"], "publication": "HAI '15: Proceedings of the 3rd International Conference on Human-Agent Interaction", "abstract": "ABSTRACT\nImages can convey emotion just like music. If that's so, then it might be possible that, given an image, one can obtain a music that can produce a similar reaction from the listener/viewer. The challenge lies in how to do that. In this paper, we analyze the image using the HSV color space model and assume that each one of the three components have a relation with basic music elements, like tone, pitch, rhythm and loudness. The image is then scanned from left to right and top to bottom in order to generate a sequence of notes. In the end, the emotional Mean Opinion Score (MOS) is used to evaluate the performance of the proposed method. This work could prove to be a very important contribution to the field of HCI because it can improve the interaction between computers and humans who are visually and/or hearing impaired. In the current work, we only consider two emotions; positive and negative.", "references": ["Adamson, J. C. Hue, saturation & value : The characteristics of color, 2012. Retrieved May 13, 2015 from The Muser Physics & Physiology of Color, http://www.greatreality.com/color/ColorHVC.htm.", "Bell, C. Art. New York Frederick A. Stokes Company Publishers, 1913.", "Dan-Glauser, E. S., and Scherer, K. R. The geneva affective picture database (gaped): a new 730-picture database focusing on valence and normative significance. Behavior Research Methods 43, 2 (2011), 468--477. Downloaded May 21, 2015, http://www.affective-sciences.org/system/files/webpage/GAPED_2.zip."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814940.2814978"}, {"title": "An Eye-Tracking Study of Query Reformulation", "authors": ["Carsten Eickhoff\n,", "Sebastian Dungs\n,", "Vu Tran"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation about a user's domain knowledge and interest can be important signals for many information retrieval tasks such as query suggestion or result ranking. State-of-the-art user models rely on coarse-grained representations of the user's previous knowledge about a topic or domain. In this paper, we study query refinement using eye-tracking in order to gain precise and detailed insight into which terms the user was exposed to in a search session and which ones they showed a particular interest in. We measure fixations on the term level, allowing for a detailed model of user attention. To allow for a wide-spread exploitation of our findings, we generalize from the restrictive eye-gaze tracking to using more accessible signals: mouse cursor traces. Based on the public API of a popular search engine, we demonstrate how query suggestion candidates can be ranked according to traces of user attention and interest, resulting in significantly better performance than achieved by an attention-oblivious industry solution. Our experiments suggest that modelling term-level user attention can be achieved with great reliability and holds significant potential for supporting a range of traditional IR tasks.", "references": ["M. Ageev, D. Lagun, and E. Agichtein. Improving search result summaries by using searcher behavior data. In SIGIR 2013.", "A. Ajanki, D. Hardoon, S. Kaski, K. Puolamaki, and J. Shawe-Taylor. Can eyes reveal interest? implicit queries from gaze patterns. User Modeling and User-Adapted Interaction, 2009.", "S. Banerjee and T. Pedersen. An adapted lesk algorithm for word sense disambiguation using wordnet. In Computational linguistics and intelligent text processing. Springer, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767703"}, {"title": "Smart Crawler: Using Committee Machines for\\\\Web Pages Continuous Classification", "authors": ["Luiz Henrique Zambom Santana\n,", "Ronaldo dos Santos Mello\n,", "Mauro Roisenberg"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe speed of information publishing in WWW is unprecedented. The individuals and organizations struggle to be up to date and find relevant knowledge from a tsunami of news, videos, posts, and comments. In the other hand, these contents (mostly bound to HTML pages) are unstructured and not explicitly classified. In this context, machine-learning techniques can be very handy to automatic separate useful information from irrelevant noise. The present paper describes a novel approach for Web Pages crawling. The Smart Crawler employs two techniques for improving the information classification: massive Web page crawling and continuous classification through committee machines. These ideas are implemented using Big Data and cloud-ready technologies, whose the cornerstone is a framework that enables memory-intensive processing, high scalability, and streaming processing. The results indicates a significant classification capability and that the classification rate can scale linearly according to the size of the dataset.", "references": ["O. Y. Al-Jarrah, P. D. Yoo, S. Muhaidat, G. K.Karagiannidis, and K. Taha. Efficient machine learningfor big data: A review. Big Data Research, 2015.", "R. B. Altman and E. A. Ashley. Using bigdata to dissect clinical heterogeneity. Circulation,131(3):232--233, 2015.", "G. Anthes. Html5 leads a web revolution.Communications of the ACM, 55(7):16--17, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820437"}, {"title": "Searching Live Meeting Documents \"Show me the Action\"", "authors": ["Laurent Denoue\n,", "Scott Carter\n,", "Matthew Cooper"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nLive meeting documents require different techniques for effectively retrieving important pieces of information. During live meetings, people share web sites, edit presentation slides, and share code editors. A simple approach is to index with Optical Character Recognition (OCR) the video frames, or key-frames, being shared and let user retrieve them. Here we show that a more useful approach is to look at what actions users take inside the live document streams. Based on observations of real meetings, we focus on two important signals: text editing and mouse cursor motion. We describe the detection of text and cursor motion, their implementation in our WebRTC (Web Real-Time Communication)-based system, and how users are better able to search live documents during a meeting based on these extracted actions.", "references": ["Cooper, M. (2013, March). Presentation video retrieval using automatically recovered slide and spoken text. In IS&T/SPIE Electronic Imaging (pp. 86670E--86670E). International Society for Optics and Photonics.", "Denoue, L., Carter, S., & Cooper, M. (2013, September). Content-based copy and paste from video documents. In Proceedings of the 2013 ACM symposium on Document engineering (pp. 215--218). ACM.", "Hauptmann, A. G., Jin, R., & Ng, T. D. (2003, January). Video retrieval using speech and image information. In Electronic Imaging 2003 (pp. 148--159). International Society for Optics and Photonics."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797082"}, {"title": "A declarative foundation for comprehensive history querying", "authors": ["Reinout Stevens"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 2", "abstract": "ABSTRACT\nResearchers in the field of Mining Software Repositories perform studies about the evolution of software projects. To this end, they use the version control system storing the changes made to a single software project. Such studies are concerned with the source code characteristics in one particular revision, the commit data for that revision, how the code evolves over time and what concrete, fine-grained changes were applied to the source code between two revisions. Although tools exist to analyse an individual concern, scripts and manual work is required to combine these tools to perform a single experiment. We present a general-purpose history querying tool named QwalKeko that enables expressing these concerns in a single uniform language, and having them detected in a git repository. We have validated our work by means of replication studies as well as through MSR studies of our own.", "references": ["R. Stevens, \"Source code archeology using logic program queries across version repositories,\" Master's thesis, Vrije Universiteit Brussel, 2011.", "A. Kellens, C. De Roover, C. Noguera, R. Stevens, and V. Jonckers, \"Reasoning over the evolution of source code using quantified regular path expressions,\" in Proceedings of the 18th Working Conference on Reverse Engineering (WCRE11), 2011, pp. 389--393.", "R. Stevens, C. De Roover, C. Noguera, and V. Jonckers, \"A history querying tool and its application to detect multi-version refactorings,\" in Proceedings of the 17th European Conference on Software Maintenance and Reengineering (CSMR13), 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819009.2819211"}, {"title": "Still Haven't Found What I'm Looking For: Suggestions for Next Generation Search User Interfaces", "authors": ["Marti Hearst"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nThe fundamental nature of how people engage with online information is changing with the move from desktop to mobile, from web pages to social, and from text to video. How should all of this affect search user interfaces and research into these topics? I'll discuss these questions as well as argue for researchers to consider some less popular, \"orphan\" search problems.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810360"}, {"title": "Fake Twitter accounts: profile characteristics obtained using an activity-based pattern detection approach", "authors": ["Supraja Gurajala\n,", "Joshua S. White\n,", "Brian Hudson\n,", "Jeanna N. Matthews"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nIn Online Social Networks (OSNs), the audience size commanded by an organization or an individual is a critical measure of that entity's popularity. This measure has important economic and/or political implications. Organizations can use information about their audience, such as age, location etc., to tailor their products or their message appropriately. But such tailoring can be biased by the presence of fake profiles on these networks. In this study, analysis of 62 million publicly available Twitter user profiles was conducted and a strategy to retroactively identify automatically generated fake profiles was established. Using a pattern-matching algorithm on screen-names with an analysis of tweet update times, a highly reliable sub-set of fake user accounts were identified. Analysis of profile creation times and URLs of these fake accounts revealed distinct behavior of the fake users relative to a ground truth data set. The combination of this scheme with established social graph analysis will allow for time-efficient detection of fake profiles in OSNs.", "references": ["Parmelee, J. H., and Bichard S. L. 2011. Politics and the Twitter revolution: How tweets influence the relationship between political leaders and the public. Lexington Books.", "Douceur, J. R. 2002. The sybil attack. Peer-to-peer Systems, Springer, 251--260.", "Yang, Z., Wilson, C., Wang, X., Gao, T., Zhao, B. Y., and Dai, Y. 2011. Uncovering Social Network Sybils in the Wild. ACM Trans. Knowl. Discov. from Data 8, 1, 7."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789206"}, {"title": "OLAP-enabled web search of complex objects", "authors": ["Alfredo Cuzzocrea\n,", "Guandong Xu\n,", "Giorgio Mario Grasso"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nInspired by the actual trend of empowering traditional Web search methodologies by means of novel computational paradigms, in this paper we propose and experimentally assess WebClustCube, a novel system that allows OLAP-enabled Web search of complex objects, thus adding new value to the potentialities of current Web search paradigms. In particular, WebClustCube supports the building and the interactive manipulation of OLAP-enabled Web views over complex objects extracted from distributed databases. The data management, OLAP-like support of WebClustCube is provided by ClustCube, a state-of-the-art framework for coupling OLAP methodologies and clustering algorithms with the goal of analyzing and mining of complex database objects. A case study that clearly shows the potentialities of WebClustCube in the context of next-generation Web search environments is provided. We complement of analytical contribution by means of an experimental assessment and analysis of WebClustCube according to several metric perspectives.", "references": ["M. Armbrust, A. Fox, R. Griffith, A.-D. Joseph, R.-H. Katz, A. Konwinski, G. Lee, D.-A. Patterson, A. Rabkin, I. Stoica, M. Zaharia, \"A View of Cloud Computing\", Communications of the ACM, vol. 53, no. 4, pp. 50--58, 2010.", "A. Z. Broder, \"A Taxonomy of Web Search\", SIGIR Forum, vol. 36, no. 2, pp. 3--10, 2002.", "R. Cattell, \"Scalable SQL and NoSQL Data Stores\", SIGMOD Record, vol. 39, no. 4, pp. 12--27, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837243"}, {"title": "Build Emotion Lexicon from Microblogs by Combining Effects of Seed Words and Emoticons in a Heterogeneous Graph", "authors": ["Kaisong Song\n,", "Shi Feng\n,", "Wei Gao\n,", "Daling Wang\n,", "Ling Chen\n,", "Chengqi Zhang"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nAs an indispensable resource for emotion analysis, emotion lexicons have attracted increasing attention in recent years. Most existing methods focus on capturing the single emotional effect of words rather than the emotion distributions which are helpful to model multiple complex emotions in a subjective text. Meanwhile, automatic lexicon building methods are overly dependent on seed words but neglect the effect of emoticons which are natural graphical labels of fine-grained emotion. In this paper, we propose a novel emotion lexicon building framework that leverages both seed words and emoticons simultaneously to capture emotion distributions of candidate words more accurately. Our method overcomes the weakness of existing methods by combining the effects of both seed words and emoticons in a unified three-layer heterogeneous graph, in which a multi-label random walk (MLRW) algorithm is performed to strengthen the emotion distribution estimation. Experimental results on real-world data reveal that our constructed emotion lexicon achieves promising results for emotion classification compared to the state-of-the-art lexicons.", "references": ["P. P. Alexander Pak. Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of the International Conference on Language Resources and Evaluation, pages 1320--1326, 2010.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Computer Networks, 30(1--7):101--117, 1998.", "E. Cambria, R. Speer, C. Havasi, and A. Hussain. enticnet: A publicly available semantic resource for opinion mining. In Proceedings of AAAI Fall Symposium on Commonsense Knowledge, pages 417--422, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791035"}, {"title": "Learning Asymmetric Co-Relevance", "authors": ["Fiana Raiber\n,", "Oren Kurland\n,", "Filip Radlinski\n,", "Milad Shokouhi"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nSeveral applications in information retrieval rely on asymmetric co-relevance estimation; that is, estimating the relevance of a document to a query under the assumption that another document is relevant. We present a supervised model for learning an asymmetric co-relevance estimate. The model uses different types of similarities with the assumed relevant document and the query, as well as document-quality measures. Empirical evaluation demonstrates the merits of using the co-relevance estimate in various applications, including cluster-based and graph-based document retrieval. Specifically, the resultant performance transcends that of using a wide variety of alternative estimates, mostly symmetric inter-document similarity measures that dominate past work.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D., and C. Wade. UMASS at TREC 2004 - novelty and hard. In Proc. of TREC, 2004.", "J. A. Aslam and M. Frost. An information-theoretic measure for document similarity. In Proc. of SIGIR, pages 449--450, 2003.", "J. A. Aslam and M. Montague. Models for metasearch. In Proc. of SIGIR, pages 276--284, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809454"}, {"title": "AVER: Random Walk Based Academic Venue Recommendation", "authors": ["Zhen Chen\n,", "Feng Xia\n,", "Huizhen Jiang\n,", "Haifeng Liu\n,", "Jun Zhang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nAcademic venues act as the main platform of communities in academia and the bridge of connecting researchers, which have rapidly developed in recent years. However, information overload in big scholarly data creates tremendous challenges for mining useful and effective information in order to recommend researchers to acknowledge high quality and fruitful academic venues, thereby enabling them to participate in relevant academic conferences as well as contributing to important/influential journals. In this work, we propose AVER, a novel random walk based Academic VEnue Recommendation model. AVER runs a random walk with restart model on a co-publication network which contains two kinds of associations, coauthor relations and author-venue relations. Moreover, we define a transfer matrix with bias to drive the random walk by exploiting three academic factors, co-publication frequency, weight of relations and researchers' academic level. AVER is inspired from the fact that researchers are more likely to contact those who have high co-publication frequency and similar academic levels. Additionally, in AVER, we consider the difference of weights between two kinds of associations. We conduct extensive experiments on DBLP data set in order to evaluate the performance of AVER. The results demonstrate that, in comparison to relevant baseline approaches, AVER performs better in terms of precision, recall and F1.", "references": ["Zaihan Yang, Dawei Yin, and Brian D Davison. Recommendation in academia: A joint multi-relational model. In ASONAM, pages 566--571. IEEE, 2014.", "Manh Cuong Pham, Yiwei Cao, Ralf Klamma, and Matthias Jarke. A clustering approach for collaborative filtering recommendation using social network analysis. J. UCS, 17(4):583--604, 2011.", "Zaihan Yang and Brian D Davison. Venue recommendation: Submitting your paper with style. In ICMLA, volume 1, pages 681--686. IEEE, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741738"}, {"title": "Android Augmented Reality Applications in Extensible, Flexible, and Adaptable Architecture", "authors": ["Tiago Araujo\n,", "Carlos Santos\n,", "Nikolas Carneiro\n,", "Bianchi Meiguins"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis work aims to present an architecture for Android Mobile Augmented Reality (MAR) applications which has to be extensible, flexible and adaptable. Extensible to allow the addition of new functionalities in the application; flexible to allow the change of content/data generating custom applications; and adaptable to the many mobile devices screen sizes. For this reason, we considered an architecture based on the MVC pattern adapted to the context of Android mobile platform, in this adaptation the business logic get out the controller layer and reaches the view layer, in so doing, the controller layer becomes responsible only for managing the request between the model and view layers, ensuring the application modularization. Also, the Fragments user interface pattern was utilized, aiming to a better adaptation to the many mobile devices screen sizes. Furthermore, we applied the Remote Proxy design pattern, for abstraction of data source (local or remote), and the Facade design pattern to facilitate the use of queries and filters in data. Finally, we present usage scenarios with different data and screen size devices to validate the proposed architecture.", "references": ["Cawood, S., Fiala, M. 2008. Augmented Reality: A Pratical Guide. Pragmatic Bookshelf, (Dallas, Texas, USA, Jan, 2008).", "de Sá, M., Churchill, E. 2012. Mobile Augmented Reality: A Design Perspective. Human Factors in Augmented Reality Environments. Springer, (New York, NY, USA), 139-164.", "Dünser, A. et al. 2007. Applying HCI principles to AR systems design. Mixed Reality User Interfaces: Specification, Authoring, Adaptation (MRUI'07) Workshop Proceedings. (Charlotte, NC, USA), 37-42."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814069"}, {"title": "\"Answer ka type kya he?\": Learning to Classify Questions in Code-Mixed Language", "authors": ["Khyathi Chandu Raghavi\n,", "Manoj Kumar Chinnakotla\n,", "Manish Shrivastava"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nCode-Mixing (CM) is defined as the embedding of linguistic units such as phrases, words, and morphemes of one language into an utterance of another language. CM is a natural phenomenon observed in many multilingual societies. It helps in speeding-up communication and allows wider variety of expression due to which it has become a popular mode of communication in social media forums like Facebook and Twitter. However, current Question Answering (QA) research and systems only support expressing a question in a single language which is an unrealistic and hard proposition especially for certain domains like health and technology. In this paper, we take the first step towards the development of a full-fledged QA system in CM language which is building a Question Classification (QC) system. The QC system analyzes the user question and infers the expected Answer Type (AType). The AType helps in locating and verifying the answer as it imposes certain type-specific constraints. In this paper, we present our initial efforts towards building a full-fledged QA system for CM language. We learn a basic Support Vector Machine (SVM) based QC system for English-Hindi CM questions. Due to the inherent complexities involved in processing CM language and also the unavailability of language processing resources such POS taggers, Chunkers, Parsers, we design our current system using only word-level resources such as language identification, transliteration and lexical translation. To reduce data sparsity and leverage resources available in a resource-rich language, in stead of extracting features directly from the original CM words, we translate them commonly into English and then perform featurization. We created an evaluation dataset for this task and our system achieves an accuracy of 63% and 45% in coarse-grained and fine-grained categories of the question taxanomy. The idea of translating features into English indeed helps in improving accuracy over the unigram baseline.", "references": ["B. Alex. Automatic Detection of English Inclusions in Mixed-lingual Data with an Application toParsing. Ph.D Thesis, School of Informatics, The University of Edinburgh, UK, 2008.", "P. Auer. Code-Switching in Conversation: Language, Interaction and Identity. Routledge, 2013.", "U. Barman, A. Das, J. Wagner, and J. Foster. Code Mixing: A Challenge for Language Identification in the Language of Social Media. In ACL 2014, pages 13--23."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743006"}, {"title": "Feature fusion for 3D model retrieval based on fuzzy clustering", "authors": ["Kuansheng Zou\n,", "Qian Zhang\n,", "Zhaojun Zhang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThe popularization of 3D scanning, 3D modeling and 3D printing had created an urgent demand for effective and useful 3D model retrieval methods and systems. In this paper, a novel feature fusing method by using fuzzy clustering is proposed for 3D model retrieval. Given two 3D descriptors, where the dimension of one is short and of the other is long, fuzzy clustering is conducted for the short feature dataset in advance, in order to generate a weighted index by classifying the features into several clusters, different clusters are given different weights based on the centroid of the cluster with the query model. Then, the long feature is used for similarity matching embedded within the generated weighted index. Experimental results demonstrate that the retrieval performance can be highly improved by using the proposed feature fusion scheme.", "references": ["Bustos, B., Keim, D. A., Saupe, D., Schreck, T. 2007. Content-based 3D object retrieval, IEEE Computer Graphics and Applications. 27 (Aug. 2007), 22--27.", "Tangelder, W. H., Veltkamp, R. C. 2004. A survey of content based 3D shape retrieval methods, Proceedings of International Conference on Shape Modeling Applications. (June. 2004), 145--156.", "Osada, R., Funkhouser, T., Chazelle, B., Dobkin, D. 2002. Shape distributions, ACM Trans Graph. 21 (Oct. 2002), 807--832."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808505"}, {"title": "A Network-Aware Approach for Searching As-You-Type in Social Media", "authors": ["Paul Lagrée\n,", "Bogdan Cautis\n,", "Hossein Vahabi"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe present in this paper a novel approach for as-you-type top-k keyword search over social media. We adopt a natural \"network-aware\" interpretation for information relevance, by which information produced by users who are closer to the seeker is considered more relevant. In practice, this query model poses new challenges for effectiveness and efficiency in online search, even when a complete query is given as input in one keystroke. This is mainly because it requires a joint exploration of the social space and classic IR indexes such as inverted lists. We describe a memory-efficient and incremental prefix-based retrieval algorithm, which also exhibits an anytime behavior, allowing to output the most likely answer within any chosen running-time limit. We evaluate it through extensive experiments for several applications and search scenarios, including searching for posts in micro-blogging (Twitter and Tumblr), as well as searching for businesses based on reviews in Yelp. They show that our solution is effective in answering real-time as-you-type searches over social media.", "references": ["B. Bahmani and A. Goel. Partitioned multi-indexing: bringing order to social search. In WWW, 2012.", "H. Bast, C. W. Mortensen, and I. Weber. Output-sensitive autocompletion search. Inf. Retr., 11(4):269--286, 2008.", "H. Bast and I. Weber. Type less, find more: Fast autocompletion search with a succinct index. In SIGIR, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806435"}, {"title": "Fast and Accurate Content-based Semantic Search in 100M Internet Videos", "authors": ["Lu Jiang\n,", "Shoou-I Yu\n,", "Deyu Meng\n,", "Yi Yang\n,", "Teruko Mitamura\n,", "Alexander G. Hauptmann"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nLarge-scale content-based semantic search in video is an interesting and fundamental problem in multimedia analysis and retrieval. Existing methods index a video by the raw concept detection score that is dense and inconsistent, and thus cannot scale to \"big data\" that are readily available on the Internet. This paper proposes a scalable solution. The key is a novel step called concept adjustment that represents a video by a few salient and consistent concepts that can be efficiently indexed by the modified inverted index. The proposed adjustment model relies on a concise optimization framework with interpretations. The proposed index leverages the text-based inverted index for video retrieval. Experimental results validate the efficacy and the efficiency of the proposed method. The results show that our method can scale up the semantic search while maintaining state-of-the-art search performance. Specifically, the proposed method (with reranking) achieves the best result on the challenging TRECVID Multimedia Event Detection (MED) zero-example task. It only takes 0.2 second on a single CPU core to search a collection of 100 million Internet videos.", "references": ["E. Apostolidis, V. Mezaris, M. Sahuguet, B. Huet, B.vCervenková, D. Stein, S. Eickeler, J. L. Redondo Garcia, R. Troncy, and L. Pikora. Automatic fine-grained hyperlinking of videos within a closed collection using scene segmentation. In MM, 2014.", "S. Bhattacharya, F. X. Yu, and S.-F. Chang. Minimally needed evidence for complex event recognition in unconstrained videos. In ICMR, 2014.", "E. F. Can and R. Manmatha. Modeling concept dependencies for event detection. In ICMR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806237"}, {"title": "The Best Published Result is Random: Sequential Testing and its Effect on Reported Effectiveness", "authors": ["Ben Carterette"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nReusable test collections allow researchers to rapidly test different algorithms to find the one that works \"best\". But because of randomness in the topic sample, or in relevance judgments, or in interactions among system components, extreme results can be seen entirely due to chance, particularly when a collection becomes very popular. We argue that the best known published effectiveness on any given collection could be measured as much as 20% higher than its \"true\" intrinsic effectiveness, and that there are many other systems with lower measured effectiveness that could have substantially higher intrinsic effectiveness.", "references": ["B. Carterette. Multiple testing in statistical analysis of systems-based information retrieval experiments. ACM TOIS, 30(1), 2012.", "S. Coles. An Introduction to Statistical Modeling of Extreme Values. Springer, 2001.", "M. Smucker, J. Allan, and B. Carterette. A comparison of statistical significance tests for information retrieval evaluation. In Proceedings of CIKM, pages 623--632, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767812"}, {"title": "Crowd and laboratory testing can they co-exist?: an exploratory study", "authors": ["Fabio Guaiani\n,", "Henry Muccini"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nCrowd testing has gained a great attention in recent years, for its cost-effectiveness, impartiality, diversity, and high device and configuration coverage. Still, a number of challenges hamper its full success, such as lack of standards, limited information on critical features coverage, duplicate defect management, inappropriate reword mechanisms. Our intuition is that combining crowd testing with (a more traditional) laboratory testing, may compensate each other limitations. In order to explore how practitioners look at this possibility, we run a survey with crowd testers to understand their perception on this matter. Preliminary results are illustrated in this work.", "references": ["World Quality Report, 2013-2014. http://www.capgemini.com/thought-leadership/world-quality-report-2013-14 (last access: February 01, 2015)", "Henry Muccini, Antonio Di Francesco and Patrizio Esposito, Software Testing of Mobile Applications: Challenges and Future Research Directions, in: 7th IEEE/ACM International Workshop on Automation of Software Test (AST 2012) @ ICSE 2012, IEEE Digital Library, 2012.", "Anthony I. Wasserman: Software engineering issues for mobile application development. FoSER 2010: 397-400"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820123"}, {"title": "How Random Decisions Affect Selective Distributed Search", "authors": ["Zhuyun Dai\n,", "Yubin Kim\n,", "Jamie Callan"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSelective distributed search is a retrieval architecture that reduces search costs by partitioning a corpus into topical shards such that only a few shards need to be searched for each query. Prior research created topical shards by using random seed documents to cluster a random sample of the full corpus. The resource selection algorithm might use a different random sample of the corpus. These random components make selective search non-deterministic. This paper studies how these random components affect experimental results. Experiments on two ClueWeb09 corpora and four query sets show that in spite of random components, selective search is stable for most queries.", "references": ["R. Aly, T. Demeester, and D. Hiemstra. Taily: Shard selection using the tail of score distributions. In Proceedings of SIGIR, 2013.", "C. L. Clarke, N. Craswell, I. Soboroff, and E. M. Voorhees. Overview of the trec 2011 web track. In Proceedings of TREC 2011, 2011.", "G. K. Jayasinghe, W. Webber, M. Sanderson, L. S. Dharmasena, and J. S. Culpepper. Evaluating non-deterministic retrieval systems. In Proceedings of SIGIR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767796"}, {"title": "Understanding web applications using component based visual patterns", "authors": ["Dan C. Cosma\n,", "Petru F. Mihancea"], "publication": "ICPC '15: Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension", "abstract": "ABSTRACT\nThis paper introduces our approach for high-level system understanding that uses software visualization to analyze the presentation layer of Web applications. The technique is driven by static analysis, relies on state-of-the art concepts, and is technology-aware, so that it focuses on those precise particularities of the application's presentation layer that define its Web presence. By combining an approach initially developed for software testing with visualization, the essential structural dependencies between and within the Web components are extracted and reviewed. Initial evaluation shows that the technique is able to provide a comprehensive view that is very useful in spotting new and interesting visual patterns that give significant insight for software comprehension.", "references": ["J. Offutt and Y. Wu, \"Modeling presentation layers of web applications for testing,\" Software&Systems Modeling, vol. 9, no. 2, pp. 257--280, 2010.", "Yes Software, \"Gotocode applications,\" http://web.archive.org/web/20110430192101/http://gotocode.com/.", "F. Ricca and P. Tonella, \"Using clustering to support the migration from static to dynamic web pages,\" in IWPC '03. IEEE CS Press, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820282.2820324"}, {"title": "Exploring the Jenolan Caves: bringing the physical world to 3D online education", "authors": ["Matt Adcock\n,", "Stuart Anderson\n,", "Shlomo Berkovsky\n,", "Paul Flick\n,", "Dennis Frousheger\n,", "Brett Grandbois\n,", "Chris Gunn\n,", "David Haddon\n,", "Jane Li\n,"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nIn August 2014, CSIRO and 3P Learning (through subsidiary IntoScience) launched what is probably Australia's biggest (and arguably coolest) school excursion ever. In classrooms around the country, students can now set out to explore the spectacular Jenolan Caves located in the scenic Blue Mountains. Students are immersed, via the web, in an authentic 3D digital recreation of the Jenolan Caves to discover the science behind cave formation.", "references": ["Bosse, M., Zlot, R. and Flick, P. 2012. Zebedee: Design of a spring-mounted 3-d range sensor with application to mobile mapping. IEEE Transactions on Robotics, 28(5).", "Zlot, R. and Bosse, M. 2014. Three-dimensional mobile mapping of caves, Journal of Cave and Karst Studies, 76(3)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2778298"}, {"title": "Detecting similar news tickers in the area of natural gas trading: improving decision support in uncertain situations", "authors": ["Susann Dreikorn\n,", "Carsten Felden\n,", "Marco Pospiech\n,", "Claudia Koschtial"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nThe volatility of the natural gas market founded a need for the ability to analyze upcoming events in real time in order to manage profits and risks for participants. News ticker provide information being of utmost importance for the analysis. The research presented among this paper describes features of a software prototype supporting the analytical price prognosis tasks for gas traders. By knowing market development at the time of a certain past situation, the outcome of that situation can be used to predict the future market development of a current analyzed situation with similar content. For that, similar situations have to be detected in order to reduce uncertainty about future. Fitting into design science, we use task-technology-fit theory and technology-acceptance-model to identify information needs and to evaluate the artifact. This novel approach serves as a further step to gain a decision support with integrated structured and unstructured data.", "references": ["Aamodt, A. and Plaza, E. 1994. Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. AI Communications. 7, 1 (March 1994), 39--59.", "Agbon, I. S. and Araque, J. C. 2003. Predicting Oil and Gas Spot Prices Using Chaos Time Series Analysis and Fuzzy Neural Network Model. In SPE Hydrocarbon Economics and Evaluation Symposium (Dallas, USA, April 05-08, 2003). 1--8. DOI = http://dx.doi.org/10.2118/82014-MS.", "Alić, I., Muntermann, J., Gregory, R. 2012. State of the Art of Financial Decision Support Systems based on Problem, Requirement, Component and Evaluation Categories. In 25th BLED eConference 2012 Proceedings, (Bled, Slovenia, June 17--20, 2012). 280--293."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857238"}, {"title": "Automatic Recognition of Eventfulness and Pleasantness of Soundscape", "authors": ["Jianyu Fan\n,", "Miles Thorogood\n,", "Bernhard E. Riecke\n,", "Philippe Pasquier"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nA soundscape is the sound environment perceived by a given listener at a given time and space. An automatic soundscape affect recognition system will be beneficial for composers, sound designers, and audio researchers. Previous work on an automatic soundscape affect recognition system has demonstrated the effectiveness of predicting valence and arousal on responses from one expert user. Thus, further validations of multi-users' data are necessary for testing the generalizability of the system. We generated a gold standard by averaging responses from people provided people agreed with each other enough. Here, we model a set of common audio features extracted from a corpus of 120 soundscape recording samples that were labeled for valence and arousal in an online study with human subjects. The contribution of this manuscript is threefold: (1) study the inter-rater agreement showing the high level agreement between participants' responses regarding valence and arousal, (2) train stepwise linear regression models with the average responses of participants for soundscape affect recognition, which obtains better results than the previous study, (3) test the correlation between the level of pleasantness and the level of eventfulness based upon the gold standard.", "references": ["Berglund, B., Nilsson. M. and Axelsson. O.2007. Soundscape Psychophysics in Place, In Proceedings of the 36th International Congress and Exhibition on Noise Control Engineering, page 3704--3712, Istanbul, Turkey.", "Brocolini, L., Waks, L., Lavandier. C., Marquis-Favre. C., Quoy, M. and Lavandier. M. 2010. Comparison between Multiple Linear Regressions and Artificial Neural Net works to Predict Urban Sound Quality, In Proceedings of the 20th International Congress on Acoustics, page 2121--2126, Nates, France.", "Thorogood, M. and Pasquier, P. 2013. Impress: A machine learning approach to soundscape affect classification for a music performance environment. In Proceedings of the International Conference on New Interfaces for Musical Expression, page 256--260, Daejeon, Republic of Korea."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814927"}, {"title": "Session details: Main Track - Prediction Methods and Recommender Systems", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252429"}, {"title": "Chronological Citation Recommendation with Information-Need Shifting", "authors": ["Zhuoren Jiang\n,", "Xiaozhong Liu\n,", "Liangcai Gao"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAs the volume of publications has increased dramatically, an urgent need has developed to assist researchers in locating high-quality, candidate-cited papers from a research repository. Traditional scholarly-recommendation approaches ignore the chronological nature of citation recommendations. In this study, we propose a novel method called \"Chronological Citation Recommendation\" which assumes initial user information needs could shift while users are searching for papers in different time slices. We model the information-need shifts with two-level modeling: dynamic time-related ranking feature construction and dynamic evolving feature weight training. In more detail, we employed a supervised document influence model to characterize the content \"time-varying\" dynamics and constructed a novel heterogeneous graph that encapsulates dynamic topic-based information, time-decay paper/topic citation information, and word-based information. We applied multiple meta-paths for different ranking hypotheses which carried different types of information for citation recommendation in various time slices, along with information-need shifting. We also used multiple learning-to-rank models to optimize the feature weights for different time slices to generate the final \"Chronological Citation Recommendation\" rankings. The use of Chronological Citation Recommendation suggests time-series ranking lists based on initial user textual information need and characterizes the information-need shifting. Experiments on the ACM corpus show that Chronological Citation Recommendation can significantly enhance citation recommendation performance.", "references": ["David M Blei and John D Lafferty. Dynamic topic models. In Proceedings of the 23rd international conference on Machine learning, pages 113--120. ACM, 2006.", "David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "Peter Brusilovsky, Oliviero Stock, and Carlo Strapparava. Adaptive hypermedia and adaptive Web-based systems. Springer, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806567"}, {"title": "Adapting Recommendations to Contextual Changes Using Hierarchical Hidden Markov Models", "authors": ["Mehdi Hosseinzadeh Aghdam\n,", "Negar Hariri\n,", "Bamshad Mobasher\n,", "Robin Burke"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender systems help users find items of interest by tailoring their recommendations to users' personal preferences. The utility of an item for a user, however, may vary greatly depending on that user's specific situation or the context in which the item is used. Without considering these changes in preferences, the recommendations may match the general preferences of a user, but they may have small value for the user in his/her current situation. In this paper, we introduce a hierarchical hidden Markov model for capturing changes in user's preferences. Using a user's feedback sequence on items, we model the user as a hierarchical hidden Markov process and the current context of the user as a hidden variable in this model. For a given user, our model is used to infer the maximum likelihood sequence of transitions between contextual states and to predict the probability distribution for the context of the next action. The predicted context is then used to generate recommendations. Our evaluation results using Last.fm music playlist data, indicate that this approach achieves significantly better performance in terms of accuracy and diversity compared to baseline methods.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-aware recommender systems. AI Magazine, 32(3):67--80, 2011.", "O. Celma. Music Recommendation and Discovery - The Long Tail, Long Fail, and Long Play in the Digital Music Space. Springer, 2010.", "F. G. D. Jannach, L. Lerche and G. Bonnin. What recommenders recommend - an analysis of accuracy, popularity, and sales diversity effects. In User Modeling, Adaptation, and Personalization. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799684"}, {"title": "Dynamic Poisson Factorization", "authors": ["Laurent Charlin\n,", "Rajesh Ranganath\n,", "James McInerney\n,", "David M. Blei"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nModels for recommender systems use latent factors to explain the preferences and behaviors of users with respect to a set of items (e.g., movies, books, academic papers). Typically, the latent factors are assumed to be static and, given these factors, the observed pref- erences and behaviors of users are assumed to be generated without order. These assumptions limit the explorative and predictive capabilities of such models, since users' interests and item popularity may evolve over time. To address this, we propose dPF, a dynamic matrix factorization model based on the recent Poisson factorization model for recommendations. dPF models the time evolving latent factors with a Kalman filter and the actions with Poisson distributions. We derive a scalable variational inference algorithm to infer the latent factors. Finally, we demonstrate dPF on 10 years of user click data from arXiv.org, one of the largest repository of scientific papers and a formidable source of information about the behavior of scientists. Empirically we show performance improvement over both static and, more recently proposed, dynamic recommendation models. We also provide a thorough exploration of the inferred posteriors over the latent variables.", "references": ["A. Acharya, J. Ghosh, and M. Zhou. Nonparametric bayesian factor analysis for dynamic count matrices. In Proceedings of the 18th Conference on Artificial Intelligence and Statistics, 2015.", "C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.", "D. M. Blei. Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1 (1): 203--232, 2014. 10.1146/annurev-statistics-022513--115657."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800174"}, {"title": "Session details: Main Track - Security in Information Systems", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252434"}, {"title": "Top-N Recommendation with Missing Implicit Feedback", "authors": ["Daryl Lim\n,", "Julian McAuley\n,", "Gert Lanckriet"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn implicit feedback datasets, non-interaction of a user with an item does not necessarily indicate that an item is irrelevant for the user. Thus, evaluation measures computed on the observed feedback may not accurately reflect performance on the complete data. In this paper, we discuss a missing data model for implicit feedback and propose a novel evaluation measure oriented towards Top-N recommendation. Our evaluation measure admits unbiased estimation under our missing data model, unlike the popular Normalized Discounted Cumulative Gain (NDCG) measure. We also derive an efficient algorithm to optimize the measure on the training data. We run several experiments which demonstrate the utility of our proposed measure.", "references": ["Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In Proc. IEEE ICDM (2008), pages 263--272, 2008.", "Y. Kim and S. Choi. Bayesian binomial mixture model for collaborative prediction with non-random missing data. In RecSys '14, pages 201--208, 2014.", "Y. Koren, R. M. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. IEEE Computer, 42(8):30--37, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799671"}, {"title": "Search-based entity disambiguation with document-centric knowledge bases", "authors": ["Stefan Zwicklbauer\n,", "Christin Seifert\n,", "Michael Granitzer"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nEntity disambiguation is the task of mapping ambiguous terms in natural-language text to its entities in a knowledge base. One possibility to describe these entities within a knowledge base is via entity-annotated documents (document-centric knowledge base). It has been shown that entity disambiguation with search-based algorithms that use document-centric knowledge bases perform well on the biomedical domain. In this context, the question remains how the quantity of annotated entities within documents and the document count used for entity classification influence disambiguation results. Another open question is whether disambiguation results hold true on more general knowledge data sets (e.g. Wikipedia). In our work we implement a search-based, document-centric disambiguation system and explicitly evaluate the mentioned issues on the biomedical data set CALBC and general knowledge data set Wikipedia, respectively. We show that the number of documents used for classification and the amount of annotations within these documents must be well-matched to attain the best result. Additionally, we reveal that disambiguation accuracy is poor on Wikipedia. We show that disambiguation results significantly improve when using shorter but more documents (e.g. Wikipedia paragraphs). Our results indicate that search-based, document-centric disambiguation systems must be carefully adapted with reference to the underlying domain and availability of user data.", "references": ["N. Charbel, J. Tekli, R. Chbeir, and G. Tekli. Resolving XML semantic ambiguity. In Proceedings of the 18th International Conference on Extending Database Technology, EDBT 2015, Brussels, Belgium, March 23-27, 2015., pages 277--288, 2015.", "Z. Guo and D. Barbosa. Robust entity linking via random walks. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 499--508. ACM, 2014.", "X. Han and L. Sun. An entity-topic model for entity linking. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 105--115. Association for Computational Linguistics, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809618"}, {"title": "Attribute Guided Dictionary Learning", "authors": ["Wei Wang\n,", "Yan Yan\n,", "Nicu Sebe"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAttributes have shown great potential in visual recognition recently since they, as mid-level features, can be shared across different categories. However, existing attribute learning methods are prone to learning the correlated attributes which results in the difficulties of selecting attribute specific features. In this paper, we propose an attribute specific dictionary learning approach to address this issue. Category information is incorporated into our framework while learning the over-complete dictionary, which encourages the samples from the same category to have similar distributions over the dictionary bases. A novel scheme is developed to select the attribute specific dictionaries. The attribute specific dictionary consists of the bases which are only shared among the positive samples or the negative samples. The experiments on the Animals with Attributes (AwA) dataset show the effectiveness of our proposed method.", "references": ["A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183--202, 2009.", "X. Chang, F. Nie, Y. Yang, and H. Huang. A convex formulation for semi-supervised multi-label feature selection. In AAAI, 2014.", "X. Chang, H. Shen, S. Wang, J. Liu, and X. Li. Semi-supervised feature analysis for multimedia annotation by mining label correlation. In PAKDD. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749337"}, {"title": "The Effects of Cross-modal Collaboration on the Stages of Information Seeking", "authors": ["Dena Al-Thani\n,", "Tony Stockman\n,", "Anastasios Tombros"], "publication": "Interacción '15: Proceedings of the XVI International Conference on Human Computer Interaction", "abstract": "ABSTRACT\nPrevious studies of users with visual impairments access to the web have focused on human-web interaction. This study explores the under investigated area of cross-modal collaborative information seeking (CCIS), that is, the challenges and opportunities that exist in supporting visually impaired (VI) users to take an effective part in collaborative web search tasks with sighted peers. We conducted an observational study to investigate the process with fourteen pairs of VI and sighted users in co-located and distributed settings. The study examined the effects of cross-modal collaborative interaction on the stages of the individual Information Seeking (IS) process. The findings showed that the different stages of the process were performed individually most of the time; however it was observed that some collaboration took place in the results exploration and management stages. The accessibility challenges faced by VI users affected their individual and collaborative interaction and also enforced certain points of collaboration. The paper concludes with some recommendations towards improving the accessibility of cross-modal collaborative search.", "references": ["Al-Thani, D., Stockman, T., Tombros, A., (2013) Cross-Modal Collaborative Information Seeking (CCIS): An Exploratory Study. In Proceeding of the 27th International British Computer Society Human Computer Interaction Conference. London, UK.", "Andronico, P., Buzzi, M., Castillo, C., & Leporini, B. (2006). Improving search engine interfaces for blind users: a case study. Universal Access in the Information Society.", "Caldwell, B. (2008). Web content accessibility guidelines (WCAG) 2.0. W3C."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2829875.2829925"}, {"title": "Fast, multicore-scalable, low-fragmentation memory allocation through large virtual memory and global data structures", "authors": ["Martin Aigner\n,", "Christoph M. Kirsch\n,", "Michael Lippautz\n,", "Ana Sokolova"], "publication": "OOPSLA 2015: Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nWe demonstrate that general-purpose memory allocation involving many threads on many cores can be done with high performance, multicore scalability, and low memory consumption. For this purpose, we have designed and implemented scalloc, a concurrent allocator that generally performs and scales in our experiments better than other allocators while using less memory, and is still competitive otherwise. The main ideas behind the design of scalloc are: uniform treatment of small and big objects through so-called virtual spans, efficiently and effectively reclaiming free memory through fast and scalable global data structures, and constant-time (modulo synchronization) allocation and deallocation operations that trade off memory reuse and spatial locality without being subject to false sharing.", "references": ["Y. Afek, G. Korland, and E. Yanovsky. Quasi-linearizability: Relaxed consistency for improved concurrency. In Proc. Conference on Principles of Distributed Systems (OPODIS), pages 395–410. Springer, 2010. doi: 10.1007/978-3-642-17653-1_ 29.", "M. Aigner and C. Kirsch. ACDC: Towards a universal mutator for benchmarking heap management systems. In Proc. International Symposium on Memory Management (ISMM), pages 75–84. ACM, 2013. doi: 10.1145/2464157.2464161.", "E. Berger, K. McKinley, R. Blumofe, and P. Wilson. Hoard: a scalable memory allocator for multithreaded applications. In Proc. International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 117–128. ACM, 2000. doi: 10.1145/384264.379232."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814270.2814294"}, {"title": "KATARA: reliable data cleaning with knowledge bases and crowdsourcing", "authors": ["Xu Chu\n,", "John Morcos\n,", "Ihab F. Ilyas\n,", "Mourad Ouzzani\n,", "Paolo Papotti\n,", "Nan Tang\n,", "Yin Ye"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nData cleaning with guaranteed reliability is hard to achieve without accessing external sources, since the truth is not necessarily discoverable from the data at hand. Furthermore, even in the presence of external sources, mainly knowledge bases and humans, effectively leveraging them still faces many challenges, such as aligning heterogeneous data sources and decomposing a complex task into simpler units that can be consumed by humans. We present Katara, a novel end-to-end data cleaning system powered by knowledge bases and crowdsourcing. Given a table, a kb, and a crowd, Katara (i) interprets the table semantics w.r.t. the given kb; (ii) identifies correct and wrong data; and (iii) generates top-k possible repairs for the wrong data. Users will have the opportunity to experience the following features of Katara: (1) Easy specification: Users can define a Katara job with a browser-based specification; (2) Pattern validation: Users can help the system to resolve the ambiguity of different table patterns (i.e., table semantics) discovered by Katara; (3) Data annotation: Users can play the role of internal crowd workers, helping Katara annotate data. Moreover, Katara will visualize the annotated data as correct data validated by the kb, correct data jointly validated by the kb and the crowd, or erroneous tuples along with their possible repairs.", "references": ["X. Chu, I. F. Ilyas, and P. Papotti. Holistic data cleaning: Putting violations into context. In ICDE, 2013.", "X. Chu, J. Morcos, I. F. Ilyas, M. Ouzzani, P. Papotti, N. Tang, and Y. Ye. KATARA: a data cleaning system powered by knowledge bases and crowdsourcing. In SIGMOD, 2015.", "O. Deshpande, D. S. Lamba, M. Tourn, S. Das, S. Subramaniam, A. Rajaraman, V. Harinarayan, and A. Doan. Building, maintaining, and using knowledge bases: a report from the trenches. In SIGMOD Conference, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824109"}, {"title": "Updating Graph Indices with a One-Pass Algorithm", "authors": ["Dayu Yuan\n,", "Prasenjit Mitra\n,", "Huiwen Yu\n,", "C. Lee Giles"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nIndices are commonly built into graph databases in order to support fast searches. Any given graph database and the distribution of queries will change over time. Therefore, the cost of processing queries using a static graph index increases because the index is built to optimize old snapshots of the database. There is growing research interest in determining how to update a graph index with the purpose of adapting to database and query changes. Updating features in a graph index is typically an NP-hard problem. In addition, because the features are chosen from a large number of frequent subgraphs, a multi-pass algorithm is not scalable to big datasets. In order to address this issue, we propose a time-efficient one-pass algorithm that is designed to update a graph index by scanning each frequent subgraph at most once. The algorithm replaces a feature with a new subgraph if the latter is ``better\" than the former one. We use the branch and bound technique to skip subgraphs that cannot outperform any of the features in the graph index. We further use a decomposed index and reduce the space complexity from O(|G||Q|) to O(|G| + |Q|), where G is database graphs and Q is a query workload. Through the empirical study, we show that the one-pass algorithm is 5--100 times faster than all previous algorithms for updating graph indices. In addition, the one-pass algorithm guarantees the return of a close to optimum solution. Our experiments show that when the one-pass algorithm is used to update an index, the query-processing speed is $1$--$2$ times faster than that of other cutting-edge indices, i.e., the FGindex and the gIndex.", "references": ["G. Ausiello, N. Boria, A. Giannakos, G. Lucarelli, and V. T. Paschos. Online maximum k-coverage. In FCT, 2011.", "A. Bifet, G. Holmes, B. Pfahringer, and R. Gavaldà. Mining frequent closed graphs on evolving data streams. In KDD, pages 591--599, 2011.", "C. Chen, X. Yan, P. S. Yu, J. Han, D.-Q. Zhang, and X. Gu. Towards graph containment search and indexing. In VLDB, pages 926--937, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2746482"}, {"title": "RUBIK: efficient threshold queries on massive time series", "authors": ["Eleni Tzirita Zacharatou\n,", "Farhan Tauheed\n,", "Thomas Heinis\n,", "Anastasia Ailamaki"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nAn increasing number of applications from finance, meteorology, science and others are producing time series as output. The analysis of the vast amount of time series is key to understand the phenomena studied, particularly in the simulation sciences, where the analysis of time series resulting from simulation allows scientists to refine the model simulated. Existing approaches to query time series typically keep a compact representation in main memory, use it to answer queries approximately and then access the exact time series data on disk to validate the result. The more precise the in-memory representation, the fewer disk accesses are needed to validate the result. With the massive sizes of today's datasets, however, current in-memory representations oftentimes no longer fit into main memory. To make them fit, their precision has to be reduced considerably resulting in substantial disk access which impedes query execution today and limits scalability for even bigger datasets in the future.\nIn this paper we develop RUBIK, a novel approach to compressing and indexing time series. RUBIK exploits that time series in many applications and particularly in the simulation sciences are similar to each other. It compresses similar time series, i.e., observation values as well as time information, achieving better space efficiency and improved precision. RUBIK translates threshold queries into two dimensional spatial queries and efficiently executes them on the compressed time series by exploiting the pruning power of a tree structure to find the result, thereby outperforming the state-of-the-art by a factor of between 6 and 23. As our experiments further indicate, exploiting similarity within and between time series is crucial to make query execution scale and to ultimately decouple query execution time from the growth of the data (size and number of time series).", "references": ["G. Anciaux, S. B. Ramisetti, and J. F. Molinari. A Finite Temperature Bridging Domain Method for MD-FE Coupling and Application to a Contact Problem. Computer Methods in Applied Mechanics and Engineering, 205--208(1):204--212, 2012.", "N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. The R*-tree: an Efficient and Robust Access Method for Points and Rectangles. In SIGMOD '90.", "Y. Cai and R. Ng. Indexing Spatio-temporal Trajectories with Chebyshev Polynomials. In Proceedings of the 2004 ACM SIGMOD International Conference on Management of Data, SIGMOD '04."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791372"}, {"title": "Constructing Complex Search Tasks with Coherent Subtask Search Goals", "authors": ["Ting-Xuan Wang\n,", "Wen-Hsiang Lu"], "publication": "ACM Transactions on Asian and Low-Resource Language Information Processing", "abstract": "Abstract\nNowadays, due to the explosive growth of web content and usage, users deal with their complex search tasks by web search engines. However, conventional search engines consider a search query corresponding only to a simple search task. In order to accomplish a complex search task, which consists of multiple subtask search goals, users usually have to issue a series of queries. For example, the complex search task “travel to Dubai” may involve several subtask search goals, including reserving hotel room, surveying Dubai landmarks, booking flights, and so forth. Therefore, a user can efficiently accomplish his or her complex search task if search engines can predict the complex search task with a variety of subtask search goals. In this work, we propose a complex search task model (CSTM) to deal with this problem. The CSTM first groups queries into complex search task clusters, and then generates subtask search goals from each complex search task cluster. To raise the performance of CSTM, we exploit four web resources including community question answering, query logs, search engine result pages, and clicked pages. Experimental results show that our CSTM is effective in identifying the comprehensive subtask search goals of a complex search task.", "references": ["E. Agichtein, R. W. White, S. T. Dumais, and P. N. Bennett. 2012. Search, interrupted: Understanding and predicting search task continuation. In Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 315--324). ACM.", "L. M. Aiello, D. Donato, U. Ozertem, and F. Menczer. 2011. Behavior-driven clustering of queries into topics. In Proceedings of the 20th ACM (pp. 1373--1382). ACM.", "E. Barsky and J. Bar-llan. 2012. The impact of task phrasing on the choice of search keywords and on the search process and success. Journal of the American Society for Information Science and Technology 63, 10, 1987--2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742547"}, {"title": "Malicious software classification based on relations of system-call groups", "authors": ["Stavros D. Nikolopoulos\n,", "Iosif Polenakis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this paper we present a graph-based algorithmic technique for classifying unknown malware samples. In order for our model to be resistant against strong mutation of malicious software, we apply our classification technique on a weighted directed graph, which we call Group Relation Graph - GrG, resulting from System-call Dependency Graphs - ScDG after grouping disjoint subsets of its vertices.", "references": ["D. Babic, D. Reynaud, and D. Song. Malware analysis with tree automata inference. In Computer Aided Verification (CAV'11), pages 116--131, 2011.", "U. Bayer, P. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda. Scalable behavior-based malware clustering. In Network and Distributed System Security Symposium (NDSS'09), pages 8--11, 2009.", "X. Hu, T. Chiueh, and K. G. Shin. Large-scale malware indexing using function-call graphs. In 16th ACM Conference on Computer and Communications Security (CCS'09), pages 611--620, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802017"}, {"title": "Online shared dictionary learning for visual tracking", "authors": ["Jingjing Wang\n,", "Liansheng Zhuang\n,", "Nenghai Yu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nDue to the superior representation ability and robustness to noise, sparse representation has been applied to visual tracking by many researchers. However, the dictionary learning strategies of previous methods suffer from the difficulty of seeking a balance of reconstructive and discriminative abilities of the learned dictionary. In this work, we propose to learn a shared dictionary in addition to the target and background specific dictionaries for robust visual tracking. With the shared dictionary modeling the commonality between the target and background, and specific dictionaries capturing the difference, our learned dictionary is both reconstructive and discriminative which can better distinguish the target from the background. The best candidate is selected as the tracking result based on the reconstruction error and discriminative ability. Experimental results on eight public challenging video sequences demonstrate our proposed algorithm outperforms eight state-of-the-art trackers.", "references": ["A. Adam, E. Rivlin, and I. Shimshoni. Robust fragments-based tracking using the integral histogram. In Computer vision and pattern recognition, 2006 IEEE Computer Society Conference on, volume 1, pages 798--805. IEEE, 2006.", "M. Aharon, M. Elad, and A. Bruckstein. K-svd: An algorithm for designing overcomplete dictionaries for sparse representation. Signal Processing, IEEE Transactions on, 54(11):4311--4322, 2006.", "B. Babenko, M.-H. Yang, and S. Belongie. Robust object tracking with online multiple instance learning. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 33(8):1619--1632, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808514"}, {"title": "Social Glass: A Platform for Urban Analytics and Decision-making Through Heterogeneous Social Data", "authors": ["Stefano Bocconi\n,", "Alessandro Bozzon\n,", "Achilleas Psyllidis\n,", "Christiaan Titos Bolivar\n,", "Geert-Jan Houben"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis demo presents Social Glass, a novel web-based platform that supports the analysis, valorisation, integration, and visualisation of large-scale and heterogeneous urban data in the domains of city planning and decision-making. The platform systematically combines publicly available social datasets from municipalities together with social media streams (e.g. Twitter, Instagram and Foursquare) and resources from knowledge repositories. It further enables the mapping of demographic information, human movement patterns, place popularity, traffic conditions, as well as citizens' and visitors' opinions and preferences with regard to specific venues in the city. Social Glass will be demonstrated through several real-world case studies, that exemplify the framework's conceptual properties, and its potential value as a solution for urban analytics and city-scale event monitoring and assessment.", "references": ["M. Balduini, A. Bozzon, E. D. Valle, Y. Huang, and G. Houben. Recommending venues using continuous predictive social media analytics. IEEE Internet Computing, 18(5):28--35, 2014.", "Z. Cheng, J. Caverlee, K. Lee, and D. Z. Sui. Exploring millions of footprints in location sharing services. In 5th International AAAI Conference on Weblogs and Social Media (ICWSM'11), pages 81--88. AAAI, 2011.", "B. Hawelka, I. Sitko, E. Beinat, S. Sobolevsky, P. Kazakopoulos, and C. Ratti. Geo-located twitter as proxy for global mobility patterns. Cartography and Geographic Information Science, 41(3):260--271, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742826"}, {"title": "Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks", "authors": ["Aliaksei Severyn\n,", "Alessandro Moschitti"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLearning a similarity function between pairs of objects is at the core of learning to rank approaches. In information retrieval tasks we typically deal with query-document pairs, in question answering -- question-answer pairs. However, before learning can take place, such pairs needs to be mapped from the original space of symbolic words into some feature space encoding various aspects of their relatedness, e.g. lexical, syntactic and semantic. Feature engineering is often a laborious task and may require external knowledge sources that are not always available or difficult to obtain. Recently, deep learning approaches have gained a lot of attention from the research community and industry for their ability to automatically learn optimal feature representation for a given task, while claiming state-of-the-art performance in many tasks in computer vision, speech recognition and natural language processing. In this paper, we present a convolutional neural network architecture for reranking pairs of short texts, where we learn the optimal representation of text pairs and a similarity function to relate them in a supervised way from the available training data. Our network takes only words in the input, thus requiring minimal preprocessing. In particular, we consider the task of reranking short text pairs where elements of the pair are sentences. We test our deep learning system on two popular retrieval tasks from TREC: Question Answering and Microblog Retrieval. Our model demonstrates strong performance on the first task beating previous state-of-the-art systems by about 3\\% absolute points in both MAP and MRR and shows comparable results on tweet reranking, while enjoying the benefits of no manual feature engineering and no additional syntactic parsers.", "references": ["A. Agarwal, H. Raghavan, K. Subbian, P. Melville, D. Gondek, and R. Lawrence. Learning to rank for robust question answering. In CIKM, 2012.", "J. W. Antoine Bordes and N. Usunier. Open question answering with weakly supervised embedding models. In ECML, Nancy, France, September 2014.", "Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. A neural probabilistic language model. Journal of Machine Learning Research, 3: 1137--1155, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767738"}, {"title": "Explaining query answers with explanation-ready databases", "authors": ["Sudeepa Roy\n,", "Laurel Orr\n,", "Dan Suciu"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith the increased generation and availability of big data in different domains, there is an imminent requirement for data analysis tools that are able to 'explain' the trends and anomalies obtained from this data to a range of users with different backgrounds. Wu-Madden (PVLDB 2013) and Roy-Suciu (SIGMOD 2014) recently proposed solutions that can explain interesting or unexpected answers to simple aggregate queries in terms of predicates on attributes. In this paper, we propose a generic framework that can support much richer, insightful explanations by preparing the database offline, so that top explanations can be found interactively at query time. The main idea in such explanation-ready databases is to pre-compute the effects of potential explanations (called interventions), and efficiently re-evaluate the original query taking into account these effects. We formalize this notion and define an explanation-query that can evaluate all possible explanations simultaneously without having to run an iterative process, develop algorithms and optimizations, and evaluate our approach with experiments on real data.", "references": ["http://www.nsf.gov/awardsearch/download.jsp.", "http://grad-schools.usnews.rankingsandreviews.com/best-graduate-schools/top-science-schools/computer-science-rankings.", "http://www.dbtoaster.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2856318.2856329"}, {"title": "Temporal rules discovery for web data cleaning", "authors": ["Ziawasch Abedjan\n,", "Cuneyt G. Akcora\n,", "Mourad Ouzzani\n,", "Paolo Papotti\n,", "Michael Stonebraker"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nDeclarative rules, such as functional dependencies, are widely used for cleaning data. Several systems take them as input for detecting errors and computing a \"clean\" version of the data. To support domain experts, in specifying these rules, several tools have been proposed to profile the data and mine rules. However, existing discovery techniques have traditionally ignored the time dimension. Recurrent events, such as persons reported in locations, have a duration in which they are valid, and this duration should be part of the rules or the cleaning process would simply fail.\nIn this work, we study the rule discovery problem for temporal web data. Such a discovery process is challenging because of the nature of web data; extracted facts are (i) sparse over time, (ii) reported with delays, and (iii) often reported with errors over the values because of inaccurate sources or non robust extractors. We handle these challenges with a new discovery approach that is more robust to noise. Our solution uses machine learning methods, such as association measures and outlier detection, for the discovery of the rules, together with an aggressive repair of the data in the mining step itself. Our experimental evaluation over real-world data from Recorded Future, an intelligence company that monitors over 700K Web sources, shows that temporal rules improve the quality of the data with an increase of the average precision in the cleaning process from 0.37 to 0.84, and a 40% relative increase in the average F-measure.", "references": ["Z. Abedjan, P. Schulze, and F. Naumann. DFD: efficient functional dependency discovery. In CIKM, pages 949--958, 2014.", "B. Alexe, M. Roth, and W.-C. Tan. Preference-aware integration of temporal data. PVLDB, 8(4):365--376, 2014.", "G. Beskales, I. F. Ilyas, and L. Golab. Sampling the repairs of functional dependency violations under hard constraints. PVLDB, 3(1):197--207, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2856318.2856328"}, {"title": "The hyperdyadic index and generalized indexing and query with PIQUE", "authors": ["David A. Boyuka\n,", "Houjun Tang\n,", "Kushal Bansal\n,", "Xiaocheng Zou\n,", "Scott Klasky\n,", "Nagiza F. Samatova"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nMany scientists rely on indexing and query to identify trends and anomalies within extreme-scale scientific data. Compressed bitmap indexing (e.g., FastBit) is the go-to indexing method for many scientific datasets and query workloads. Recently, the ALACRITY compressed inverted index was shown as a viable alternative approach. Notably, though FastBit and ALACRITY employ very different data structures (inverted list vs. bitmap) and binning methods (bit-wise vs. decimal-precision), close examination reveals marked similarities in index structure.\nMotivated by this observation, we ask two questions. First, \"Can we generalize FastBit and ALACRITY to an index model encompassing both?\" And second, if so, \"Can such a generalized framework enable other, new indexing methods?\" This paper answers both questions in the affrmative.\nFirst, we present PIQUE, a Parallel Indexing and Query Unified Engine, based on formal mathematical decomposition of the indexing process. PIQUE factors out commonalities in indexing, employing algorithmic/data structure \"plugins\" to mix orthogonal indexing concepts such as FastBit compressed bitmaps with ALACRITY binning, all within one framework.\nSecond, we define the hyperdyadic tree index, distinct from both bitmap and inverted indexes, demonstrating good index compression while maintaining high query performance. We implement the hyperdyadic tree index within PIQUE, reinforcing our unified indexing model.\nWe conduct a performance study of the hyperdyadic tree index vs. WAH compressed bitmaps, both within PIQUE and compared to FastBit, a state-of-the-art bitmap index system. The hyperdyadic tree index shows a 1.14-1.90x storage reduction vs. compressed bitmaps, with comparable or better query performance under most scenarios tested.", "references": ["T. Apaydin, G. Canahuate, H. Ferhatosmanoglu, and A. S. Tosun. Approximate encoding for direct access and query processing over compressed bitmaps. In Very Large Data Bases (VLDB), 2006.", "G. Bernardo, S. Álvarez García, N. Brisaboa, G. Navarro, et al. Compact querieable representations of raster data. In String Processing and Information Retrieval (SPIR), volume 8214, pages 96--108. 2013.", "K. J. Bowers, B. J. Albright, L. Yin, B. Bergen, et al. Ultrahigh performance three-dimensional electromagnetic relativistic kinetic plasma simulationa). Physics of Plasmas, 15(5), 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791374"}, {"title": "Adaptation and Evaluation of Recommendations for Short-term Shopping Goals", "authors": ["Dietmar Jannach\n,", "Lukas Lerche\n,", "Michael Jugovac"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAn essential characteristic in many e-commerce settings is that website visitors can have very specific short-term shopping goals when they browse the site. Relying solely on long-term user models that are pre-trained on historical data can therefore be insufficient for a suitable next-basket recommendation. Simple \"real-time\" recommendation approaches based, e.g., on unpersonalized co-occurrence patterns, on the other hand do not fully exploit the available information about the user's long-term preference profile. In this work, we aim to explore and quantify the effectiveness of using and combining long-term models and short-term adaptation strategies. We conducted an empirical evaluation based on a novel evaluation design and two real-world datasets. The results indicate that maintaining short-term content-based and recency-based profiles of the visitors can lead to significant accuracy increases. At the same time, the experiments show that the choice of the algorithm for learning the long-term preferences is particularly important at the beginning of new shopping sessions.", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender Systems Handbook, pages 217--253. 2011.", "S. R. Aghabozorgi and T. Y. Wah. Recommender systems: Incremental clustering on web log data. In Proc. ICIS '09, pages 812--818, 2009.", "Y. AlMurtadha, N. B. Sulaiman, N. Mustapha, N. I. Udzir, and Z. Muda. ARS: Web page recommendation system for anonymous users based on web usage mining. In Proc. ECS '10, pages 115--120, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800176"}, {"title": "LightLDA: Big Topic Models on Modest Computer Clusters", "authors": ["Jinhui Yuan\n,", "Fei Gao\n,", "Qirong Ho\n,", "Wei Dai\n,", "Jinliang Wei\n,", "Xun Zheng\n,", "Eric Po Xing\n,", "Tie-Yan Liu\n,", "Wei-Ying Ma"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWhen building large-scale machine learning (ML) programs, such as massive topic models or deep neural networks with up to trillions of parameters and training examples, one usually assumes that such massive tasks can only be attempted with industrial-sized clusters with thousands of nodes, which are out of reach for most practitioners and academic researchers. We consider this challenge in the context of topic modeling on web-scale corpora, and show that with a modest cluster of as few as 8 machines, we can train a topic model with 1 million topics and a 1-million-word vocabulary (for a total of 1 trillion parameters), on a document collection with 200 billion tokens --- a scale not yet reported even with thousands of machines. Our major contributions include: 1) a new, highly-efficient O(1) Metropolis-Hastings sampling algorithm, whose running cost is (surprisingly) agnostic of model size, and empirically converges nearly an order of magnitude more quickly than current state-of-the-art Gibbs samplers; 2) a model-scheduling scheme to handle the big model challenge, where each worker machine schedules the fetch/use of sub-models as needed, resulting in a frugal use of limited memory capacity and network bandwidth; 3) a differential data-structure for model storage, which uses separate data structures for high- and low-frequency words to allow extremely large models to fit in memory, while maintaining high inference speed. These contributions are built on top of the Petuum open-source distributed ML framework, and we provide experimental evidence showing how this development puts massive data and models within reach on a small cluster, while still enjoying proportional time cost reductions with increasing cluster size.", "references": ["A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In WSDM, pages 123--132, 2012.", "E. Airoldi, D. Blei, S. Fienberg, and E. Xing. Mixed membership stochastic blockmodels. J. Mach. Learn. Res., 9:1981--2014, 2008.", "C. Andrieu, N. D. Freitas, A. Doucet, and M. I. Jordan. An introduction to MCMC for machine learning. Machine learning, 50(1):5--43, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741115"}, {"title": "The semantic web: interacting with the unknown", "authors": ["Steffen Staab"], "publication": "EICS '15: Proceedings of the 7th ACM SIGCHI Symposium on Engineering Interactive Computing Systems", "abstract": "ABSTRACT\nWhen developing user interfaces for interacting with data and content one typically assumes that one knows the type of data and one knows how to interact with such type of data. The core idea of the Semantic Web is that data is self-describing, which implies from a data consumer's point of view that its semantics is not designed and described according to its use, but according to possibly orthogonal concerns of a data publisher and that its usage semantics emerges over time. The ensued flexibility is one of the greatest assets of the Semantic Web, but it also severely handicaps intelligent interaction with its data.", "references": ["C. Bizer, T. Heath, and T. Berners-Lee. 2009. Linked Data - The Story So Far. Int. J. Semantic Web Inf. Syst. 5, 3 (2009), 1--22.", "M. H. de Souza Bomfim and D. Schwabe. 2011. Design and implementation of linked data applications using SHDM and SYNTH. In Proc. of ICWE-2011 (LNCS), Vol. 6757. Springer, 121--136.", "R. Delbru, S. Campinas, and G. Tummarello. 2012. Searching web data: An entity retrieval and high-performance indexing model. J. Web Sem. 10 (2012), 33--58."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2774225.2777465"}, {"title": "Discovering Canonical Correlations between Topical and Topological Information in Document Networks", "authors": ["Yuan He\n,", "Cheng Wang\n,", "Changjun Jiang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDocument network is a kind of intriguing dataset which can provide both topical (textual content) and topological (relational link) information. A key point in viably modeling such datasets is to discover proper denominators beneath the two different types of data, text and link. Most previous work introduces the assumption that documents closely linked with each other share common latent topics. However, the heterophily (i.e., tendency to link to different others) of nodes is neglected, which is pervasive in social networks. In this paper, we simultaneously incorporate community detection and topic modeling in a unified framework, and appeal to Canonical Correlation Analysis (CCA) to capture the latent semantic correlations between the two heterogeneous latent factors, community and topic. Despite of the homophily (i.e., tendency to link to similar others) or heterophily, CCA can properly capture the inherent correlations which fit the dataset itself without any prior hypothesis. Logistic normal prior is also employed in modeling network to better capture the community correlations. We derive efficient inference and learning algorithms based on variational EM methods. The effectiveness of our proposed model is comprehensively verified on three different types of datasets which are namely hyperlinked networks of web pages, social networks of friends and coauthor networks of publications. Experimental results show that our approach achieves significant improvements on both topic modeling and community detection compared with the current state of the art. Meanwhile, our model is impressive in discovering correlations between extracted topics and communities.", "references": ["E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels. In Advances in Neural Information Processing Systems 21. Curran Associates, Inc., 2009.", "J. Aitchison. The statistical analysis of compositional data. 1986.", "F. R. Bach and M. I. Jordan. A probabilistic interpretation of canonical correlation analysis. 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806518"}, {"title": "Twitter-based Election Prediction in the Developing World", "authors": ["Nugroho Dwi Prasetyo\n,", "Claudia Hauff"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nElections are the main instrument of democracy. Citizens decide which entity or entities (a political party or a particular politician) should represent them. Traditionally, pre-election polls have been used to learn about trends and likely election outcomes. Predicting an election outcome based on user activity on Twitter has been shown to be a cheap alternative. While past research has focused on election prediction in the developed world (where its use is debatable), in this paper we provide a comprehensive argument for the use of Twitter-based election forecasting in the developing world. For our use case of Indonesia's presidential elections 2014, the most basic Twitter-predictor outperforms the majority of traditional polls, while the best performing predictor outperforms all traditional polls on the national level.", "references": ["K. Arzheimer and J. Evans. A new multinomial accuracy measure for polling bias. Political Analysis, 22(1):31--44, 2014.", "N. Beauchamp. Predicting and interpolating state-level polling using Twitter textual data. In New Directions in Analyzing Text as Data Workshop, 2013.", "A. Bermingham and A. F. Smeaton. On using Twitter to monitor political sentiment and predict election results. In SAAI '11, 2011.", "A. Boutet, H. Kim, E. Yoneki, et al. What's in Your Tweets? I Know Who You Supported in the UK 2010 General Election. In ICWSM '12, pages 411--414, 2012.", "A. Bruns, J. Burgess, et al.# ausvotes: How Twitter covered the 2010 Australian federal election. Communication, Politics & Culture, 44(2):37--56, 2011.", "J. D. Burger, J. Henderson, G. Kim, and G. Zarrella. Discriminating gender on Twitter. In EMNLP '11, pages 1301--1309, 2011.", "A. Ceron, L. Curini, and S. M. Iacus. Using Sentiment Analysis to Monitor Electoral Campaigns Method Matters: Evidence From the United States and Italy. Social Science Computer Review, 33(1):3--20, 2015.", "A. Ceron, L. Curini, S. M. Iacus, and G. Porro. Every tweet counts? How sentiment analysis of social media can improve our knowledge of citizens' political preferences with an application to Italy and France. New Media & Society, 16(2):340--358, 2014.", "M. Choy, M. Cheong, M. N. Laik, and K. P. Shung. US presidential election 2012 prediction using a census corrected Twitter model. arXiv preprint arXiv:1211.0938, 2012.", "M. Choy, M. L. Cheong, M. N. Laik, and K. P. Shung. A sentiment analysis of Singapore Presidential Election 2011 using Twitter data with census correction. arXiv preprint arXiv:1108.5520, 2011.", "Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia. Who is tweeting on Twitter: human, bot, or cyborg? In ACSAC '10, pages 21--30, 2010.", "J. E. Chung and E. Mustafaraj. Can collective sentiment expressed on Twitter predict political elections? In AAAI '11, pages 1770--1771, 2011.", "D. M. Cook, B. Waugh, M. Abdipanah, O. Hashemi, and S. Abdul Rahman. Twitter Deception and Influence: Issues of Identity, Slacktivism, and Puppetry. Journal of Information Warfare, 13(1):58--71, 2014.", "J. Down and S. Duke. Sms polling. a methodological review. In ASC, pages 277--286, 2003.", "C. Fink, N. Bos, A. Perrone, E. Liu, and J. Kopecky. Twitter, Public Opinion, and the 2011 Nigerian Presidential Election. In SocialCom '13, pages 311--320, 2013.", "L. Fumagalli and E. Sala. The total survey error paradigm and pre-election polls: The case of the 2006 Italian general elections. Technical report, Iser Working paper Series (No. 2011--29), 2011.", "M. Gaurav, A. Srivastava, A. Kumar, and S. Miller. Leveraging candidate popularity on Twitter to predict election outcome. In SNA-KDD Workshop, 2013.", "D. Gayo-Avello. Don't turn social media into another 'Literary Digest' poll. Communications of the ACM, 54(10):121--128, 2011.", "D. Gayo-Avello. A meta-analysis of state-of-the-art electoral prediction from Twitter data. Social Science Computer Review, 31(6):649--679, 2013.", "D. Gayo-Avello, P. Metaxas, and E. Mustafaraj. Limits of electoral predictions using social media data. In ICWSM '11, pages 490--493, 2011.", "Y. He and D. Zhou. Self-training from labeled features for sentiment analysis. Information Processing & Management, 47(4):606--616, 2011.", "D. S. Hillygus. The evolution of election polling in the United States. Public opinion quarterly, 75(5):962--981, 2011.", "M. J. Jensen and N. Anstead. Psephological investigations: Tweets, votes, and unknown unknowns in the republican nomination process. Policy & Internet, 5(2):161--182, 2013.", "A. Jungherr, P. Jürgens, and H. Schoen. Why the pirate party won the German election of 2009 or the trouble with predictions: A response to ... Social Science Computer Review, 30(2):229--234, 2012.", "M. S. Lewis-Beck. Election forecasting: principles and practice. The British Journal of Politics & International Relations, 7(2):145--164, 2005.", "A. Makazhanov, D. Rafiei, and M. Waqar. Predicting political preference of Twitter users. Social Network Analysis and Mining, 4(1):1--15, 2014.", "Y. Mejova, P. Srinivasan, and B. Boynton. GOP primary season on Twitter: popular political sentiment in social media. In WSDM 13, pages 517--526, 2013.", "P. T. Metaxas, E. Mustafaraj, and D. Gayo-Avello. How (not) to predict elections. In SocialCom, pages 165--171. IEEE, 2011.", "M. Naaman, J. Boase, and C.-H. Lai. Is it really about me?: Message content in social awareness streams. In CSCW 10, pages 189--192, 2010.", "D. Nguyen, R. Gravel, D. Trieschnigg, and T. Meder. \"How Old Do You Think I Am?\" A Study of Language and Age in Twitter. In ICWSM '13, pages 439--448, 2013.", "F. Nooralahzadeh, V. Arunachalam, and C. Chiru. 2012 Presidential Elections on Twitter--An Analysis of How the US and French Election were Reflected in Tweets. In CSCS '13, pages 240--246, 2013.", "B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?: Sentiment classification using machine learning techniques. In EMNLP '02, pages 79--86, 2002.", "E. T. K. Sang and J. Bos. Predicting the 2011 Dutch Senate Election Results with Twitter. In Workshop on Semantic Analysis in Social Media, pages 53--60, 2012.", "M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and M. Stede. Lexicon-based methods for sentiment analysis. Computational linguistics, 37(2):267--307, 2011.", "A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe. Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment. In ICWSM \"10, pages 178--185, 2010.", "B. Waugh, M. Abdipanah, O. Hashemi, S. A. Rahman, and D. M. Cook. The Influence and Deception of Twitter: the authenticity of the narrative and slacktivism in the Australian electoral process. In 14th Australian Information Warfare Conference, pages 28--38, 2013.", "F. M. F. Wong, C. W. Tan, S. Sen, and M. Chiang. Quantifying Political Leaning from Tweets and Retweets. In ICWSM \"13, pages 640--649, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791033"}, {"title": "Big Data, IoT, .... Buzz Words for Academia or Reality for Industry?", "authors": ["Rui Luis Aguiar\n,", "Nora Benhabiles\n,", "Tobias Pfeiffer\n,", "Pablo Rodriguez\n,", "Harish Viswanathan\n,", "Jia Wang\n,", "Hui Zang"], "publication": "MobiCom '15: Proceedings of the 21st Annual International Conference on Mobile Computing and Networking", "abstract": "ABSTRACT\nThe concepts of Big Data have became intertwined with those of the Internet of Things, creating mental pictures of a fully connected, all-encompassing, cyber-physical world, where each and every object will contribute with information to a \"fully aware\" society. Academic works are presenting this as the natural evolution for our current technologies. The panel looks at these promises from the hard perspective of reality: what is being done, how much it cost, what needs to be developed, and what can be expected in the near and mid-term.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789168.2802150"}, {"title": "The use of text retrieval and natural language processing in software engineering", "authors": ["Venera Arnaoudova\n,", "Sonia Haiduc\n,", "Andrian Marcus\n,", "Giuliano Antoniol"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 2", "abstract": "ABSTRACT\nThis technical briefing presents the state of the art Text Retrieval and Natural Language Processing techniques used in Software Engineering and discusses their applications in the field.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819009.2819224"}, {"title": "Restructuring Information Technology Area: an experience report in the public service", "authors": ["Fernando Szimanski\n,", "Anivaldo S. Vale\n,", "George H. Kuroki\n,", "Celia G. Ralha"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nOne of the biggest challenges for an organizations IT area is to provide support so effective and efficient that the finalistics areas can achieve their missions, goals, indicators and compliance with legal requirements. The key to this problem is associated to information systems which are based on business models, being properly analyzed and specified, originating products that are close to business objectives and strategies. This article presents the experience with a complete restructuring proposal of the IT area, which includes changing internal processes, customization and deployment of software tools, involving organizational cultural changes. The proposal was implemented with the help of a framework, being used in many IT projects at the Ministry of Science, Technology and Innovation. When Complete the first execution cycle some organization benefits were verified, such as IT services quality, customer satisfaction and engagement, as well as transparency on IT projects.", "references": ["Organizational Project Management Maturity Model (Opm3) Overview. Project Management Institute, 1st edition, 2003. ISBN 1930699042.", "F. M. M. da Silva, V. Sun, J. P. de Albuquerque, and E. P. V. Prado. O Funil de Inovação como Modelo para Priorizar e Executar Projetos de Tecnologia da Informação. In Simpósio Brasileiro de Sistemas de Informação - SBSI, 2014.", "G. D. Garson and A. Pavlichev. Digital government: principles and best practices, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814134"}, {"title": "Obtaining General Chord Types from Chroma Vectors", "authors": ["Marcelo Queiroz\n,", "Maximos Kaliakatsos-Papakostas\n,", "Emilios Cambouropoulos"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis paper presents two novel strategies for processing chroma vectors corresponding to polyphonic audio, and producing a symbolic representation known as GCT (General Chord Type). This corresponds to a fundamental step in the conversion of general polyphonic audio files to this symbolic representation, which is required for enlarging the current corpus of harmonic idioms used for conceptual blending in the context of the COINVENT project. Preliminary results show that the strategies proposed produce correct results, even though harmonic ambiguities (e.g. between a major chord with added major 6th and a minor chord with minor 7th) might be resolved differently according to each strategy.", "references": ["N. Boulanger-Lewandowski, Y. Bengio, and P. Vincent. Audio chord recognition with recurrent neural networks. In Proceedings of the 13th International Society for Music Information Retrieval Conference, (ISMIR 2012), pages 335--340, Porto, Portugal, October 8-12 2013.", "E. Cambouropoulos, M. Kaliakatsos-Papakostas, and C. Tsougras. An idiom-independent representation of chords for computational music analysis and generation. In Proceeding of the joint 11th Sound and Music Computing Conference (SMC) and 40th International Computer Music Conference (ICMC), ICMC--SMC 2014, 2014.", "R. Chen, W. Shen, A. Srinivasamurthy, and P. Chordia. Chord recognition using duration-explicit hidden markov models. In Proceedings of the 13th International Society for Music Information Retrieval Conference, (ISMIR 2012), pages 445--450, Porto, Portugal, October 8-12 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814932"}, {"title": "On organising multimedia performance corpora for musicological study using Linked Data", "authors": ["Terhi Nurmikko-Fuller\n,", "David M. Weigl\n,", "Kevin R. Page"], "publication": "DLfM '15: Proceedings of the 2nd International Workshop on Digital Libraries for Musicology", "abstract": "ABSTRACT\nThe wide availability of digital technologies has increased the quantity and diversity of information that can be collected from and about a musical performance. Making this data easily accessible for study by musicologists requires the development of supporting methodologies and tools to assist and automate its systematic cataloguing, archiving, and investigation. We report on the curation of a rich digital multimedia dataset captured from a complete performance of Richard Wagner's Ring Cycle, supplemented by observations annotated by a musicologist during the course of the event. We describe the application of ontologies to codify the physical and temporal relationships between the events, artefacts, and their creators or annotators; and the method and tools to publish these performance corpora as Linked Data hyperstructures abiding by this schema. Finally we discuss the implications for hosting this data within a Digital Library infrastructure and how it can be used to support musicological investigation.", "references": ["D. Bainbridge, X. Hu, and J. S. Downie. A Musical Progression with Greenstone: How Music Content Analysis and Linked Data is Helping Redefine the Boundaries to a Music Digital Library. In Proceedings of the 1st International Workshop on Digital Libraries for Musicology, pages 1--8. ACM, 2014.", "M. Doerr, C. Bekiari, P. LeBoeuf, and B. nationale de France. FRBRoo, a conceptual model for performing arts. In Proceedings of the 2008 Annual Conference of CIDOC, Athens, pages 06--18, 2008.", "L. Dreyfus and C. Rindeisch. Using Digital Libraries in the Research of the Reception and Interpretation of Richard Wagner's Leitmotifs. In Proceedings of the 1st International Workshop on Digital Libraries for Musicology, pages 1--3. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2785527.2785532"}, {"title": "Content Analysis of Social Tags Generated by Health Consumers", "authors": ["Soohyung Joo\n,", "Yunseon Choi"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis poster presents preliminary findings of user tag analysis in the domain of consumer health information. To obtain user terms, 36,205 tags from 38 consumer health information sites were collected from delicious.com. Content analysis was applied to identify the dimensions and types of the collected tags. The preliminary findings showed that user generated tags covers a variety of aspects of health information, ranging from general terms, subject terms, knowledge type, and to audience. General terms and subject terms were observed dominantly by showing 31.7% and 22.8% respectively.", "references": ["Y. Choi. Traditional versus Emerging Knowledge Organization Systems: Consistency of Subject Indexing of the Web by Indexers and Taggers. Proceedings of ASIST annual meeting. 2010.", "L.A. Ferguson and R. Pawlak. Health literacy: the road to improved health outcomes 2011, International Journal of Nursing Practice, 7(2): 123--129. 2011.", "S. Sen, S. Lam, A.M. Rashid, D. Cosley, D. Frankowski, J. Osterhouse, M. Harper, & J. Riedl. Tagging, communites, vocabulary, evolution. Proceedings of CSCW'06. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756959"}, {"title": "CRMActive: An Active Learning Based Approach for Effective Video Annotation and Retrieval", "authors": ["Moitreya Chatterjee\n,", "Anton Leuski"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nConventional multimedia annotation/retrieval systems such as Normalized Continuous Relevance Model (NormCRM)[7] require a fully labeled training data for a good performance. Active Learning, by determining an order for labeling the training data, allows for a good performance even before the training data is fully annotated. In this work we propose an active learning algorithm, which combines a novel measure of sample uncertainty with a novel clustering-based approach for determining sample density and diversity and integrate it with NormCRM. The clusters are also iteratively refined to ensure both feature and label-level agreement among samples. We show that our approach outperforms multiple baselines both on a new, open dataset and on the popular TRECVID corpus at both the tasks of annotation and text-based retrieval of videos.", "references": ["Trecvid 2007: Trec video retrieval evaluation. link: http://www-nlpir.nist.gov/projects/tv2007/tv2007.html.", "K. Brinker. Incorporating diversity in active learning with support vector machines. In Proceedings of ICML, volume 3, pages 59--66, 2003.", "C. K. Dagli et al. Leveraging active learning for relevance feedback using an information theoretic diversity measure. In Image and Video Retrieval. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749342"}, {"title": "Automated Metadata Construction to Support Portable Building Applications", "authors": ["Arka A. Bhattacharya\n,", "Dezhi Hong\n,", "David Culler\n,", "Jorge Ortiz\n,", "Kamin Whitehouse\n,", "Eugene Wu"], "publication": "BuildSys '15: Proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Built Environments", "abstract": "ABSTRACT\nCommercial buildings consume nearly 19\\% of delivered energy in the U.S, nearly half (42%) of which is consumed in buildings with digital control systems comprised of wired sensor networks. These sensors have scant metadata, and are represented by ``tags'' which are obscure, building-specific and not machine parseable. We develop a human-in-the-loop synthesis technique which uses syntactic and data-driven steps to parse these sensor tags into a common namespace, which can enable portable building applications. We show that our technique allows an expert to fully parse a large fraction (~70%) of the tags with 24, 15 and 43 examples for three large commercial buildings comprising 1586, 2522 and 1865 sensors respectively, and deploy three portable applications on two buildings with less than 30 examples.", "references": ["Project haystack. http://project-haystack.org/.", "ALC. Automated logic corporation. http://www.automatedlogic.com/.", "A. Bhattacharya, D. Culler, D. Hong, K. Whitehouse, and J. Ortiz. Writing scalable building efficiency applications using normalized metadata: demo abstract. In Proceedings of the 1st ACM Conference on Embedded Systems for Energy-Efficient Buildings, pages 196--197. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2821650.2821667"}, {"title": "LBMCH: Learning Bridging Mapping for Cross-modal Hashing", "authors": ["Yang Wang\n,", "Xuemin Lin\n,", "Lin Wu\n,", "Wenjie Zhang\n,", "Qing Zhang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nHashing has gained considerable attention on large-scale similarity search, due to its enjoyable efficiency and low storage cost. In this paper, we study the problem of learning hash functions in the context of multi-modal data for cross-modal similarity search. Notwithstanding the progress achieved by existing methods, they essentially learn only one common hamming space, where data objects from all modalities are mapped to conduct similarity search. However, such method is unable to well characterize the flexible and discriminative local (neighborhood) structure in all modalities simultaneously, hindering them to achieve better performance. Bearing such stand-out limitation, we propose to learn heterogeneous hamming spaces with each preserving the local structure of data objects from an individual modality. Then, a novel method to learning bridging mapping for cross-modal hashing, named LBMCH, is proposed to characterize the cross-modal semantic correspondence by seamlessly connecting these distinct hamming spaces. Meanwhile, the local structure of each data object in a modality is preserved by constructing an anchor based representation, enabling LBMCH to characterize a linear complexity w.r.t the size of training set. The efficacy of LBMCH is experimentally validated against real-world cross-modal datasets.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. In NIPS, 2001.", "S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.", "M. Bronstein, A. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767825"}, {"title": "Semantics-Assisted Deep Web Query Interface Classification", "authors": ["Chichang Jou"], "publication": "C3S2E '15: Proceedings of the Eighth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nHuge amounts of structured data sources are hidden in the databases behind web forms. Volumes of deep web contents were estimated to be around 500 times those of surface web. However, many web forms are not deep web query interfaces. To retrieve contents in the web databases, an important task is to identify those web forms that are deep web query interfaces. Deep web contents normally are associated with a specific domain, and many domain semantics are embedded in the web forms. Additionally, returned HTML pages of deep web queries contain particular patterns, which could assist identifying query interfaces. Thus, we collect the following semantics to assist the classification: (1) feature words: for non-query forms and for keyword fields in deep web query interfaces; (2) common fields in a particular domain: their valid values and relationships, and their synonyms. We design and implement a Semantics-Assisted deep Web Query Interface Classifier (SAWQIC) system based on heuristics. In the pre-query analysis of SAWQIC, feature words of non-query form attributes are combined with heuristics to filter out non-query forms. For web forms passing the filtering, we utilize semantics in filling in valid input data for their components to submit the form. In the post-query analysis of SAWQIC, we then use heuristics in analyzing the returned HTML pages to identify the deep web query interfaces. The SAWQIC system is evaluated against web forms for the \"Book\" and \"Job\" domains. The experimental results illustrate that SAWQIC could generate highly effective classification measures.", "references": ["Barbosa, L. & Freire, J. (2004). Siphoning hidden-web data through keyword-based interfaces. Proceedings of the 19th Brazilian Symposium on Databases (SBBD), pp. 309--321.", "Barbosa, L. & Freire, J. (2007). Combining classifiers to identify online databases. Proceedings of the 16th International Conference on World Wide Web, pp. 431--440.", "Bergholz, A. & Chidlovskii, B. (2003). Crawling for domain-specific hidden web resources. Proceedings of the 4th International Conference on Web Information Systems Engineering (WISE), pp. 125--133."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790798.2790810"}, {"title": "Entity and Aspect Extraction for Organizing News Comments", "authors": ["Radityo Eko Prasojo\n,", "Mouna Kacimi\n,", "Werner Nutt"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNews websites give their users the opportunity to participate in discussions about published articles, by writing comments. Typically, these comments are unstructured making it hard to understand the flow of user discussions. Thus, there is a need for organizing comments to help users to (1) gain more insights about news topics, and (2) have an easy access to comments that trigger their interests. In this work, we address the above problem by organizing comments around the entities and the aspects they discuss. More specifically, we propose an approach for entity and aspect extraction from user comments through the following contributions. First, we extend traditional Named-Entity Recognition approaches, using coreference resolution and external knowledge bases, to detect more occurrences of entities in comments. Second, we exploit part-of-speech tag, dependency tag, and lexical databases to extract explicit and implicit aspects around discussed entities. Third, we evaluate our entity and aspect extraction approach, on manually annotated data, showing that it highly increases precision and recall compared to baseline approaches.", "references": ["M. Asahara and Y. Matsumoto. Japanese named entity extraction with redundant morphological analysis.In Conference of the North American. ACL, 2003.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "D. M. Bikel, S. Miller, R. Schwartz, and R. Weischedel. Nymble: a high-performance learning name-finder.In 5th conference on Applied natural language processing. ACL, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806576"}, {"title": "Head pose 3D data web-based visualization", "authors": ["Grigorios Kalliatakis\n,", "Georgios Triantafyllidis\n,", "Nikolaos Vidakis"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nAn approach build on discriminative random regression forests was followed in order to achieve fast, accurate and reliable estimation of head pose in uncontrolled environment. Data representing the changes of a person's head direction, concerning two Degrees of Freedom (DOF), pitch and yaw, are collected and stored adopting a lightweight data exchange format (JavaScript Object Notation-JSON). After that, a web visualization approach is proposed in order to improve the understanding and the analysis of the captured 3D data.", "references": ["Fanelli, Gabriele, Dantone, Matthias, Gall, Juergen, Fossati, Andrea, and Van Gool, Luc. Random forests for real time 3D face analysis. International Journal of Computer Vision, 3, 101 (August 2012), 437--458.", "Fanelli, Gabriele, Weise, Fanelli, Gall, Juergen, and Van Gool, Luc. Real Time Head Pose Estimation from Consumer Depth Cameras. In Heidelberg, Springer-Verlag Berlin, ed., Computer Vision and Pattern Recognition (CVPR). Springer Berlin Heidelberg, 2011.", "jQuery. http://jquery.com/, Mar 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2778304"}, {"title": "Diverse and Proportional Size-l Object Summaries for Keyword Search", "authors": ["Georgios Fakas\n,", "Zhi Cai\n,", "Nikos Mamoulis"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nThe abundance and ubiquity of graphs (e.g., Online Social Networks such as Google+ and Facebook; bibliographic graphs such as DBLP) necessitates the effective and efficient search over them. Given a set of keywords that can identify a Data Subject (DS), a recently proposed relational keyword search paradigm produces, as a query result, a set of Object Summaries (OSs). An OS is a tree structure rooted at the DS node (i.e., a tuple containing the keywords) with surrounding nodes that summarize all data held on the graph about the DS. OS snippets, denoted as size-l OSs, have also been investigated. Size-l OSs are partial OSs containing l nodes such that the summation of their importance scores results in the maximum possible total score. However, the set of nodes that maximize the total importance score may result in an uninformative size-l OSs, as very important nodes may be repeated in it, dominating other representative information. In view of this limitation, in this paper we investigate the effective and efficient generation of two novel types of OS snippets, i.e. diverse and proportional size-l OSs, denoted as DSize-l and PSize-l OSs. Namely, apart from the importance of each node, we also consider its frequency in the OS and its repetitions in the snippets. We conduct an extensive evaluation on two real graphs (DBLP and Google+). We verify effectiveness by collecting user feedback, e.g. by asking DBLP authors (i.e. the DSs themselves) to evaluate our results. In addition, we verify the efficiency of our algorithms and evaluate the quality of the snippets that they produce.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages 5--14, 2009.", "A. Angel and N. Koudas. Efficient diversity-aware search. In SIGMOD, pages 781--792, 2011.", "A. Balmin, V. Hristidis, and Y. Papakonstantinou. Objectrank: Authority-based keyword search in databases. In VLDB, pages 564--575, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2737783"}, {"title": "Mining Measured Information from Text", "authors": ["Arun S. Maiya\n,", "Dale Visser\n,", "Andrew Wan"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present an approach to extract measured information from text (e.g., a $1370~^{\\circ}C$ melting point, a BMI greater than 29.9 kg/m$^2$). Such extractions are critically important across a wide range of domains --- especially those involving search and exploration of scientific and technical documents. We first propose a rule-based entity extractor to mine measured quantities (i.e., a numeric value paired with a measurement unit), which supports a vast and comprehensive set of both common and obscure measurement units. Our method is highly robust and can correctly recover valid measured quantities even when significant errors are introduced through the process of converting document formats like PDF to plain text. Next, we describe an approach to extracting the properties being measured (e.g., the property ``pixel pitch'' in the phrase ``a pixel pitch as high as $352~\\mu m$''). Finally, we present MQSearch: the realization of a search engine with full support for measured information.", "references": ["A. Bakalov, A. Fuxman, P. P. Talukdar, and S. Chakrabarti. Scad: collective discovery of attribute values. In WWW '11.", "E. Brill. A Simple Rule-based Part of Speech Tagger. In ANLC '92.", "L. Chiticariu, Y. Li, and F. R. Reiss. Rule-based Information Extraction is Dead! Long Live Rule-based Information Extraction Systems! In EMNLP '13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767789"}, {"title": "PITAGORA: Recommending Users and Local Experts in an Airport Social Network", "authors": ["Andrea Ferracani\n,", "Daniele Pezzatini\n,", "Andrea Benericetti\n,", "Marco Guiducci\n,", "Alberto Del Bimbo"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this demo we present PITAGORA\\footnote{Demo video available at http://bit.ly/1GgtUrN}: a mobile web contextual social network designed for the check-in area of an airport. The app provides recommendation of potential friends, local experts and targeted services. Recommendation is hybrid and combines social media analysis and collaborative filtering techniques. Users' recommendation has been evaluated through a user study with good results.", "references": ["Z. Rubin. Disclosing oneself to a stranger: Reciprocity and its limits. Journal of Experimental Social Psychology, 11(3):233 -- 260, 1975.", "Y. Zheng, L. Zhang, X. Xie, and W.-Y. Ma. Mining correlation between locations using human location history. In Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS '09, pages 472--475, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807980"}, {"title": "An investigation of the suitability of heterogeneous social network data for use in mobile tourist guides", "authors": ["Giorgos Papadimitriou\n,", "Andreas Komninos\n,", "John Garofalakis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nSocial Networking Sites (SNS) are used daily by billions of people worldwide to keep them informed about the latest news, to help them interact with other people as well as to provide them with Points of Interest (POIs) to visit. In this paper we examine to what extent the information from SNSs such as likes, tags, check-ins can influence the visitors or locals of a city in choosing venues to visit. Next, we implement an Android application, Social City, for mobile devices, which collects and evaluates the information from Facebook and Foursquare in order to recommend to users venues to visit in the city of Patras, Greece. Finally, we discuss an evaluation of Social City. Our results indicate that the combination of SNS data from multiple social networking sites into a single rating, appears to lead to more efficient recommendations for the users, helping them choose faster and easier and with more confidence about the quality of their choice.", "references": ["Chatzipetrou, C. A. 2011. Online Social Networks, Master's dissertation, University of Macedonia, Thessaloniki, Greece.", "Chittaro, L. Visualizing information on mobile devices. IEEE Computer, vol. 39, issue 3, 2006, 40--45.", "Church, K., Smyth, B., Bradley, K. and Cotter, P. A large scale study of European mobile search behavior. In Proc. MobileHCI 2008, ACM Press (2008), 13--22."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801970"}, {"title": "Modeling Cognitive Processes in Social Tagging to Improve Tag Recommendations", "authors": ["Dominik Kowald"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the emergence of Web 2.0, tag recommenders have become important tools, which aim to support users in finding descriptive tags for their bookmarked resources. Although current algorithms provide good results in terms of tag prediction accuracy, they are often designed in a data-driven way and thus, lack a thorough understanding of the cognitive processes that play a role when people assign tags to resources. This thesis aims at modeling these cognitive dynamics in social tagging in order to improve tag recommendations and to better understand the underlying processes. As a first attempt in this direction, we have implemented an interplay between individual micro-level (e.g., categorizing resources or temporal dynamics) and collective macro-level (e.g., imitating other users' tags) processes in the form of a novel tag recommender algorithm. The preliminary results for datasets gathered from BibSonomy, CiteULike and Delicious show that our proposed approach can outperform current state-of-the-art algorithms, such as Collaborative Filtering, FolkRank or Pairwise Interaction Tensor Factorization. We conclude that recommender systems can be improved by incorporating related principles of human cognition.", "references": ["J. R. Anderson, M. D. Byrne, S. Douglass, C. Lebiere, and Y. Qin. An integrated theory of the mind. Psychological Review, 111(4):1036--1050, 2004.", "J. R. Anderson and L. J. Schooler. Reflections of the environment in memory. Psychological Science, 2(6):396--408, 1991.", "P. G. Campos, F. Dıez, and I. Cantador. Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols. User Modeling and User-Adapted Interaction, pages 1--53, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741746"}, {"title": "Metis: a smart memory allocator using historical reclamation information", "authors": ["Shijie Xu\n,", "Qi Guo\n,", "Gerhard Dueck\n,", "David Bremner\n,", "Yang Wang"], "publication": "ICOOOLPS '15: Proceedings of the 10th Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems", "abstract": "ABSTRACT\nDynamic memory management has received extensive attention in the last decade. Reducing memory fragmentation is a major design consideration to achieve efficient memory management. However, for some loop intensive applications (e.g., Apache HTTP and Ngnix), state-of-the-art dynamic memory allocators are not capable of reducing fragmentation efficiently due to repeatedly allocations and deallocations of objects with varying size. To address this problem, we propose a smart memory allocator, called Metis, designed for loop intensive applications. In Metis, a program's runtime is divided into two phases: profiling phase and activation phase. For the former, Metis builds a model to group historical allocation instructions, the objects created which are interconnected and likely to be reclaimed together during the same Garbage Collection (GC) cycle. For the latter, a region group (a contiguous piece of memory that can be reclaimed as a whole) is created to serve allocation instructions from one instruction group in the model. Our experiment with extended SPECjvm2008 traces shows that 79% of true fragmentation in the global heap can be reduced and a larger fraction of false fragmentation in region groups.", "references": ["Doug Lea Allocator. http://gee.cs.oswego.edu/dl/html/malloc.html.", "FreeBSD Allocator. http://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf.", "Google TCMalloc. http://goog-perftools.sourceforge.net/doc/tcmalloc.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2843915.2843920"}, {"title": "TotalCOW: Unleash the Power of Copy-On-Write for Thin-provisioned Containers", "authors": ["Xingbo Wu\n,", "Wenguang Wang\n,", "Song Jiang"], "publication": "APSys '15: Proceedings of the 6th Asia-Pacific Workshop on Systems", "abstract": "ABSTRACT\nModern file systems leverage the Copy-on-Write (COW) technique to efficiently create snapshots. COW can significantly reduce demand on disk space and I/O bandwidth by not duplicating entire files at the time of making the snapshots. However, memory space and I/O requests demanded by applications cannot benefit from this technique. In existing systems, a disk block shared by multiple files due to COW would be read from the disk multiple times. Each block in the reads is treated as an independent one in different files and is cached as a sperate block in memory. This issue is due to the fact that current file access and caching are based on logic file addresses. It poses a significant challenge on the emerging light-weight container virtualization techniques, such as Linux Container and Docker, which rely on COW to quickly spawn a large number of thin-provisioned container instances. We propose a lightweight approach to address this issue by leveraging knowledge about files produced by COW. Experimental results show that a prototyped system using the approach, named TotalCOW, can significantly remove redundant disk reads and caching without compromising efficiency of accessing COW files.", "references": ["Automatic ballooning. http://www.linux-kvm.org/page/Projects/auto-ballooning.", "Docker. https://www.docker.com/.", "Kernel samepage merging. http://www.linux-kvm.org/page/KSM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797022.2797024"}, {"title": "Mining successful answers in stack overflow", "authors": ["Fabio Calefato\n,", "Filippo Lanubile\n,", "Maria Concetta Marasciulo\n,", "Nicole Novielli"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nRecent research has shown that drivers of success in online question answering encompass presentation quality as well as temporal and social aspects. Yet, we argue that also the emotional style of a technical contribution influences its perceived quality. In this paper, we investigate how Stack Overflow users can increase the chance of getting their answer accepted. We focus on actionable factors that can be acted upon by users when writing an answer and making comments. We found evidence that factors related to information presentation, time and affect all have an impact on the success of answers.", "references": ["A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec. 2012. Discovering value from community activity on focused question answering sites: a case study of stack overflow. Proc. of KDD '12. ACM, 850--858.", "M. Asaduzzaman, A. S. Mashiyat, C. K. Roy, K. A. Schneider. 2013. Answering questions about unanswered questions of Stack Overflow, Proc. of MSR 2013, 97--100.B.", "Bazelli, A. Hindle, E. Stroulia, 2013. On the Personality Traits of StackOverflow Users. In Proc. of ICSM '13, IEEE, 460--463."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820579"}, {"title": "A GPS Tracking Device Embedded in Prayer Beads for Early-Stage Dementia Detection", "authors": ["Yang-Yen Ou\n,", "Ta-Wen Kuan\n,", "Jhing-Fa Wang\n,", "An-Chao Tsai\n,", "Pin-Chieh Chen"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper proposes a prototyping of a prayer beads embedded with a GPS device, which is applied for tracking the trajectory of elderly to possibly detect the early stage of Dementia, of which the chronic diseases for elderly will lead to the deterioration in memory, thinking, behavior and ability, thus caused to the forgetfulness, losing track or losing familiar places gradually in their daily life. The prototyping mainly consists of two blocks, including, the power supply block and the computation & communication block, in which three modules, i.e. microcontroller, GSM/GPRS module and GPS module are functional and enabled by the power supply block. To timely transmit the GPS trajectory from the prototyping wore on elderly to the caregiver on their smart device or laptop anytime and anywhere, a cloud service system is proposed to coordinate the GPS information processed among the proposed GPS-based prayer beads, the cloud service system and the caregiver's mobile device. Eventually, the simulation result is shown that the trajectory of elderly can be detected and recorded through the proposed framework at a convenience manner, however, some obstacles e.g. trees, building, viaduct etc. during the tracking will tentatively lose connection and influence the positioning accuracy, that will be overcome in the future work.", "references": ["WHO. (2015). Dementia, fact sheet N°362. Available: http://www.who.int/mediacentre/factsheets/fs362/en/", "Wikipedia. Prayer beads. Available: https://en.wikipedia.org/wiki/Prayer_beads", "B. Xiao, M. Z. Asghar, T. Jamsa, and P. Pulii, \"\" Canderoid\": A mobile system to remotely monitor travelling status of the elderly with dementia,\" in Awareness Science and Technology and Ubi-Media Computing (iCAST-UMEDIA), 2013 International Joint Conference on, 2013, pp. 648--654."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818928"}, {"title": "Gray computing: an analysis of computing with background JavaScript tasks", "authors": ["Yao Pan\n,", "Jules White\n,", "Yu Sun\n,", "Jeff Gray"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 1", "abstract": "ABSTRACT\nWebsites routinely distribute small amounts of work to visitors' browsers in order to validate forms, render animations, and perform other computations. This paper examines the feasibility, cost effectiveness, and approaches for increasing the workloads offloaded to web visitors' browsers in order to turn them into a large-scale distributed data processing engine, which we term gray computing. Past research has looked primarily at either non-browser based volunteer computing or browser-based volunteer computing where the visitors keep their browsers open to a single web page for a long period of time. This paper provides a deep analysis of the architectural, cost effectiveness, user experience, performance, security, and other issues of gray computing distributed data processing engines with high heterogeneity, non-uniform page view times, and high computing pool volatility.", "references": ["J. Dean and S. Ghemawat, \"Mapreduce: simplified data processing on large clusters,\" Communications of the ACM, vol. 51, no. 1, pp. 107--113, 2008.", "L. F. Sarmenta, \"Volunteer computing,\" Ph.D. dissertation, Citeseer, 2001.", "\"Youtube statistics,\" https://www.youtube.com/yt/press/statistics.html."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2818754.2818777"}, {"title": "Advantages of extending wiki pages with knowledge-based recommendations", "authors": ["Stefan Reiterer\n,", "Martin Stettinger\n,", "Michael Jeran\n,", "Wolfgang Eixelsberger\n,", "Manfred Wundara"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nIn this paper we present WeeVis, a knowledge-based recommender system embedded in a Wiki environment. Since Wikis are used since quite a long time for knowledge management and retrieval in many companies, we show how MediaWiki pages can be extended with knowledge bases for deriving recommendations for items. The WeeVis extension reduces the time to discover relevant information from Wiki pages by adding recommender functionality to the page content. Two examples (one from the e-government domain and one from the nutrition domain) of real world applications of WeeVis are shown and outline the advantages of the system.", "references": ["J. Baumeister, J. Reutelshoefer, and F. Puppe. Knowwe: a semantic wiki for knowledge engineering. Applied Intelligence, 35(3):323--344, 2011.", "D. Billsus and M. J. Pazzani. Learning collaborative information filters. In ICML, volume 98, pages 46--54, 1998.", "A. Felfernig and R. Burke. Constraint-based recommender systems: technologies and research issues. In Proceedings of the 10th international conference on Electronic commerce, page 3. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809611"}, {"title": "FiND: a real-time filtering by novelty and diversity for publish/subscribe systems", "authors": ["Zeinab Hmedeh\n,", "Cedric du Mouza\n,", "Nicolas Travers"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nContent syndication has become a popular way for timely delivery of frequently updated information on the Web. It essentially enhances traditional pull-oriented searching and browsing of web pages with push-oriented protocols. However many Web syndication applications imply a tight coupling between feed producers and consumers and do not help users to find, in all information they received, items with interesting and new content. We present the FiND Pub/Sub system which integrates an in-memory filtering process based on keyword subscriptions. Unlike existing proposals, FiND is designed for real-time notifications on item streams. This demonstration illustrates the main features of the FiND system namely (i) a scalable real-time notification process when the most important terms of the subscription are matched, (ii) a tunable filtering by novelty and diversity to reduce user flooding.", "references": ["Y. Diao, P. M. Fischer, M. J. Franklin, and R. To. Yfilter: Efficient and scalable filtering of xml documents. In ICDE, page 341, 2002.", "M. Drosou and E. Pitoura. Disc diversity: result diversification based on dissimilarity and coverage. PVLDB, 6(1):13--24, 2012.", "M. Drosou and E. Pitoura. Dynamic diversification of continuous data. In EDBT, pages 216--227, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791356"}, {"title": "A semi-supervised tweet classification method using news articles", "authors": ["Beomseok Hong\n,", "Youngsub Han\n,", "Yanggon Kim"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nAs the Internet and social media became more popular, the demand for Online Reputation Management (ORM) has increased. For ORM in social media, it is a priority to recognize whether a content of a social message means the named entity. Since Twitter exchanges 500 million tweets per day, it is impossible for a human to analyze this enormous amount of tweet. Because of this, an automated system for tweet disambiguation is necessary. In this paper, we propose a semi-supervised and automated system for the named entity disambiguation in Twitter based on the news articles. A classifier is built with keywords from news articles which are related to a company. The keywords are extracted based on the document frequency. For the keywords that help to discriminate company tweets, a proper threshold was found in a heuristic way. From the experiment, we found that news articles can be used to disambiguate a named entity on tweets as an external source and we verified our system performed well in some cases.", "references": ["Amigó, E., Artiles, J., Gonzalo, J., Spina, D., Liu, B., and Corujo, A. 2010. WePS-3 evaluation campaign: Overview of the on-line reputation management task. In: CLEF 2010 Labs and Workshops Notebook Papers.", "Yerva, S. R., Miklós, Z., and Aberer, K. 2010. It was easy, when apples and blackberries were only fruits. In: CLEF 2010 Labs and Workshops Notebook Papers.", "Yoshida, M., Matsushima, S., Ono, S., Sato, I., and Nakagawa, H. 2010. ITC-UT: Tweet categorization by query categorization for on-line reputation management. In: CLEF 2010 Labs and Workshops Notebook Papers."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811478"}, {"title": "ECOLE: Student Knowledge Assessment in the Education Process", "authors": ["Dmitry Mouromtsev\n,", "Fedor Kozlov\n,", "Liubov Kovriguina\n,", "Olga Parkhimovich"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe paper concerns estimation of students' knowledge based on their learning results in the ECOLE system. ECOLE is the online eLearning system which functionality is based on several ontologies. This system allows to interlink terms from different courses and domains and calculates several educational rates: term knowledge rate, total knowledge rate, domain knowledge rate and term significance rate. All of these rates are used to give the student recommendations about the activities he has to undertake to pass a course successfully.", "references": ["Dmitry Mouromtsev, Fedor Kozlov, Liubov Kovriguina, and Olga Parkhimovich. A combined method for e-learning ontology population based on nlp and user activity analysis. CEUR Workshop Proceedings: LILE 2014 Workshop Proceedings: Linked Learning Meets Linked Up: Learning and Education with the Web of Data, 1254(5), 2014.", "Ali Khalili, Sören Auer, Darya Tarasowa, and Ivan Ermilov. Slidewiki: elicitation and sharing of corporate knowledge using presentations. In Knowledge Engineering and Knowledge Management, pages 302{316. Springer, 2012.", "Maurice Hendrix, Aristidis Protopsaltis, Ian Dunwell, Sara de Freitas, Panagiotis Petridis, Sylvester Arnab, Nikolas Dovrolis, Eleni Kaldoudi, Davide Taibi, S Dietze, et al. Technical evaluation of the meducator 3.0 linked data-based environment for sharing medical educational resources. In 2nd International Workshop on Learning and Education with the Web of Data, Lyon, France, volume 4, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741743"}, {"title": "Search Query Categorization at Scale", "authors": ["Michal Laclavik\n,", "Marek Ciglan\n,", "Sam Steingold\n,", "Martin Seleng\n,", "Alex Dorman\n,", "Stefan Dlugolinsky"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nState of the art query categorization methods usually exploit web search services to retrieve the best matching web documents and map them to a given taxonomy of categories. This is effective but impractical when one does not own a web corpus and has to use a 3rd party web search engine API. The problem lies in performance and in financial costs. In this paper, we present a novel, fast and scalable approach to categorization of search queries based on a limited intermediate corpus: we use Wikipedia as the knowledge base. The presented solution relies on two steps: first a query is mapped to the relevant Wikipedia pages; second, the retrieved documents are categorized into a given taxonomy. We approach the first challenge as an entity search problem and present a new document categorization approach for the second step. On a standard data set, our approach achieves results comparable to the state-of-the-art approaches while maintaining high performance and scalability.", "references": ["M. Ciglan, M. Laclavik, and A. Dorman. Reusing knowledge hidden in wikipedia for scalable text categorization. In Proceedings of WSDM Workshops: WSCBD, WSDM'14 Workshops, 2014.", "E. Diemert and G. Vandelle. Unsupervised query categorization using automatically-built concept graphs. WWW '09, pages 461--470, 2009.", "S. Dlugolinsky, G. Nguyen, M. Laclavik, and M. Seleng. Character gazetteer for named entity recognition with linear matching complexity. In Proceedings of WICT, WICT'13, pages 364--368, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741995"}, {"title": "Incremental knowledge base construction using DeepDive", "authors": ["Jaeho Shin\n,", "Sen Wu\n,", "Feiran Wang\n,", "Christopher De Sa\n,", "Ce Zhang\n,", "Christopher Ré"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nPopulating a database with unstructured information is a long-standing problem in industry and research that encompasses problems of extraction, cleaning, and integration. Recent names used for this problem include dealing with dark data and knowledge base construction (KBC). In this work, we describe DeepDive, a system that combines database and machine learning ideas to help develop KBC systems, and we present techniques to make the KBC process more efficient. We observe that the KBC process is iterative, and we develop techniques to incrementally produce inference results for KBC systems. We propose two methods for incremental inference, based respectively on sampling and variational techniques. We also study the tradeoff space of these methods and develop a simple rule-based optimizer. DeepDive includes all of these contributions, and we evaluate DeepDive on five KBC systems, showing that it can speed up KBC inference tasks by up to two orders of magnitude with negligible impact on quality.", "references": ["U. A. Acar, A. Ihler, R. Mettu, and O. Sümer. Adaptive inference on general graphical models. In UAI, 2008.", "C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan. An introduction to MCMC for machine learning. Machine Learning, 2003.", "G. Angeli, S. Gupta, M. Jose, C. D. Manning, C. Ré, J. Tibshirani, J. Y. Wu, S. Wu, and C. Zhang. Stanford's 2014 slot filling systems. TAC KBP, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809991"}, {"title": "An insight into the unresolved questions at stack overflow", "authors": ["Mohammad Masudur Rahman\n,", "Chanchal K. Roy"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nFor a significant number of questions at Stack Overflow, none of the posted answers were accepted as solutions. Acceptance of an answer indicates that the answer actually solves the discussed problem in the question, and the question is answered sufficiently. In this paper, we investigate 3,956 such unresolved questions using an exploratory study where we analyze four important aspects of those questions, their answers and the corresponding users that partially explain the observed scenario. We then propose a prediction model by employing five metrics related to user behaviour, topics and popularity of question, which predicts if the best answer for a question at Stack Overflow might remain unaccepted or not. Experiments using 8,057 questions show that the model can predict unresolved questions with 78.70% precision and 76.10% recall.", "references": ["Stack Exchange Data Explorer. URL http://data.stackexchange.com/stackoverflow.", "WEKA Toolkit. URL http://www.cs.waikato.ac.nz/ml/weka.", "L. A. Adamic, J. Zhang, E. Bakshy, and M. S. Ackerman. Knowledge Sharing and Yahoo Answers: Everyone Knows Something. In Proc. WWW, pages 665--674, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820578"}, {"title": "A Study on the Use of Word Embeddings and PageRank for Vietnamese Text Summarization", "authors": ["Viet Phung\n,", "Lance De Vine"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nAutomatic text summarization is the process of automatically reducing the length of documents without losing the primary ideas. Due to the flood of digital text-based information, there is a great demand for summarization systems. In this paper, we investigate a number of word-embedding based approaches for sentence representation which are combined with the PageRank algorithm to select sentences for summary construction. We compare these new methods with a range of other current approaches to summarization. While the same summarization approaches can generally be applied across different languages, we target Vietnamese because of the relative lack of previous work in this space and also because it provides a good example of a language which generally requires word segmentation. Our experiments find that a word-embedding and graph based approach is an effective strategy for Vietnamese summarization and that word segmentation is not necessary for achieving good summarization results.", "references": ["S. Aji and R. Kaimal. Document summarization using positive pointwise mutual information. International Journal of Computer Science & Information Technology (IJCSIT), 4(2):47--55, 2012.", "R. Arora and R. Balaraman. Latent dirichlet allocation and singular value decomposition based multi-document summarization. In Data Mining, 2008. ICDM'08 Eighth IEE International Conference on, pages 713--718. IEEE, 2008.", "M. Bansal, K. Gimpel, and K. Livescu. Tailoring continuous word representations for dependency parsing. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838935"}, {"title": "Latent Factors of Visual Popularity Prediction", "authors": ["Spencer Cappallo\n,", "Thomas Mensink\n,", "Cees G.M. Snoek"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nPredicting the popularity of an image on social networks based solely on its visual content is a difficult problem. One image may become widely distributed and repeatedly shared, while another similar image may be totally overlooked. We aim to gain insight into how visual content affects image popularity. We propose a latent ranking approach that takes into account not only the distinctive visual cues in popular images, but also those in unpopular images. This method is evaluated on two existing datasets collected from photo-sharing websites, as well as a new proposed dataset of images from the microblogging website Twitter. Our experiments investigate factors of the ranking model, the level of user engagement in scoring popularity, and whether the discovered senses are meaningful. The proposed approach yields state of the art results, and allows for insight into the semantics of image popularity on social networks.", "references": ["Z. Akata, F. Perronnin, Z. Harchaoui, and C. Schmid. Good practice in large-scale learning for image classification. IEEE Trans. PAMI, 36(3):507--520, 2014.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In MM, 2013.", "E. F. Can, H. Oktay, and R. Manmatha. Predicting retweet count using visual cues. In CIKM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749405"}, {"title": "Learning to Detect Event-Related Queries for Web Search", "authors": ["Nattiya Kanhabua\n,", "Tu Ngoc Nguyen\n,", "Wolfgang Nejdl"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn many cases, a user turns to search engines to find information about real-world situations, namely, political elections, sport competitions, or natural disasters. Such temporal querying behavior can be observed through a significant number of event-related queries generated in web search. In this paper, we study the task of detecting event-related queries, which is the first step for understanding temporal query intent and enabling different temporal search applications, e.g., time-aware query auto-completion, temporal ranking, and result diversification. We propose a two-step approach to detecting events from query logs. We first identify a set of event candidates by considering both implicit and explicit temporal information needs. The next step further classifies the candidates into two main categories, namely, event or non-event. In more detail, we leverage different machine learning techniques for query classification, which are trained using the feature set composed of time series features from signal processing, along with features derived from click-through information, and standard statistical features. In order to evaluate our proposed approach, we conduct an experiment using two real-world query logs with manually annotated relevance assessments for 837 events. To this end, we provide a large set of event-related queries made available for fostering research on this challenging task.", "references": ["G. E. P. Box and G. Jenkins. Time Series Analysis, Forecasting and Control. Holden-Day, Incorporated, 1990.", "R. Burghartz and K. Berberich. MPI-INF at the NTCIR-11 Temporal Query Classification Task. In Proceedings of the 11th NTCIR Conference, 2014.", "R. Campos, G. Dias, A. Jorge, and C. Nunes. GTE: A distributional second-order co-occurrence approach to improve the identification of top relevant dates in web snippets. In Proceedings of CIKM '12, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741698"}, {"title": "Improving Ranking Consistency for Web Search by Leveraging a Knowledge Base and Search Logs", "authors": ["Jyun-Yu Jiang\n,", "Jing Liu\n,", "Chin-Yew Lin\n,", "Pu-Jen Cheng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we propose a new idea called ranking consistency in web search. Relevance ranking is one of the biggest problems in creating an effective web search system. Given some queries with similar search intents, conventional approaches typically only optimize ranking models by each query separately. Hence, there are inconsistent rankings in modern search engines. It is expected that the search results of different queries with similar search intents should preserve ranking consistency. The aim of this paper is to learn consistent rankings in search results for improving the relevance ranking in web search. We then propose a re-ranking model aiming to simultaneously improve relevance ranking and ranking consistency by leveraging knowledge bases and search logs. To the best of our knowledge, our work offers the first solution to improving relevance rankings with ranking consistency. Extensive experiments have been conducted using the Freebase knowledge base and the large-scale query-log of a commercial search engine. The experimental results show that our approach significantly improves relevance ranking and ranking consistency. Two user surveys on Amazon Mechanical Turk also show that users are sensitive and prefer the consistent ranking results generated by our model.", "references": ["P. N. Bennett, D. M. Chickering, and A. Mityagin. Learning consensus opinion: mining data from a labeling game. In Proc. of WWW, pages 121--130. ACM, 2009.", "P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz. Inferring and using location metadata to personalize web search. In Proc. of SIGIR, pages 135--144. ACM, 2011.", "P. N. Bennett, K. Svore, and S. T. Dumais. Classification-enhanced ranking. In Proc. of WWW, pages 111--120. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806479"}, {"title": "Joint Modeling of Users' Interests and Mobility Patterns for Point-of-Interest Recommendation", "authors": ["Hongzhi Yin\n,", "Bin Cui\n,", "Zi Huang\n,", "Weiqing Wang\n,", "Xian Wu\n,", "Xiaofang Zhou"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nPoint-of-Interest (POI) recommendation has become an important means to help people discover interesting places, especially when users travel out of town. However, extreme sparsity of user-POI matrix creates a severe challenge. To cope with this challenge, we propose a unified probabilistic generative model, Topic-Region Model (TRM), to simultaneously discover the semantic, temporal and spatial patterns of users' check-in activities, and to model their joint effect on users' decision-making for POIs. We conduct extensive experiments to evaluate the performance of our TRM on two real large-scale datasets, and the experimental results clearly demonstrate that TRM outperforms the state-of-art methods.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734 -- 749, june 2005.", "Z. Cheng, J. Caverlee, K. Lee, and D. Z. Sui. Exploring millions of footprints in location sharing services. In ICWSM, 2011.", "G. Ference, M. Ye, and W.-C. Lee. Location recommendation for out-of-town users in location-based social networks. In CIKM, pages 721--726, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806339"}, {"title": "Sentiment-based User Profiles in Microblogging Platforms", "authors": ["Francisco J. Gutierrez\n,", "Barbara Poblete"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nTwitter has become one of the major platforms for self-expression in the Social Web, mostly due to its adoption by mobile users and its short message format. This presents endless possibilities for social behavior researchers that, for the first time, have access to massive amounts of data generated by humans. Nevertheless, most of the current research on emotions in social platforms focuses on reactions to particular events, or crowd behavior. In this article we present our research in the identification and characterization of user sentiment profiles in online social media. By analyzing a dataset of more than 36,000 users, we identify several distinctive groups, according to similarities in their sentiment behavior. We study differences and similarities between these profile clusters and present detailed statistics. We found that a large number of Twitter users can be grouped in nine distinct profiles according to the strength and polarity of their sentiment. Researchers and practitioners can benefit from our approach to characterize Twitter users in several scenarios, such as social recommendation, and mood estimation.", "references": ["C. A. Bliss, I. M. Kloumann, K. D. Harris, C. M. Danforth, and P. S. Dodds. Twitter reciprocal reply networks exhibit assortativity with respect to happiness. Journal of Computational Science, 3(5):388 -- 397, 2012. Advanced Computing Solutions for Health Care and Medicine.", "J. Bollen, B. Gonçalves, G. Ruan, and H. Mao. Happiness is assortative in online social networks. Artificial Life, 17(3):237--251, 2011.", "J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1--8, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791027"}, {"title": "DataXFormer: An Interactive Data Transformation Tool", "authors": ["John Morcos\n,", "Ziawasch Abedjan\n,", "Ihab Francis Ilyas\n,", "Mourad Ouzzani\n,", "Paolo Papotti\n,", "Michael Stonebraker"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nWhile syntactic transformations require the application of a formula on the input values, such as unit conversion or date format conversions, semantic transformations, such as \"zip code to city\", require a look-up in some reference data. We recently presented DataXFormer, a system that leverages Web tables, Web forms, and expert sourcing to cover a wide range of transformations. In this demonstration, we present the user-interaction with DataXFormer and show scenarios on how it can be used to transform data and explore the effectiveness and efficiency of several approaches for transformation discovery, leveraging about 112 million tables and online sources.", "references": ["Z. Abedjan, J. Morcos, M. Gubanov, I. Ilyas, M. Stonebraker, P. Papotti, and M. Ouzzani. Dataxformer: Leveraging the web for semantic data transformations. In CIDR, 2015.", "B. Aditya, G. Bhalotia, S. Chakrabarti, A. Hulgeri, C. Nakhe, P. Parag, and S. Sudarshan. Banks: Browsing and keyword searching in relational databases. In VLDB, pages 1083--1086, 2002.", "S. Agrawal, S. Chaudhuri, and G. Das. Dbxplorer: A system for keyword-based search over relational databases. In ICDE, pages 5--16, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735366"}, {"title": "GPU Accelerated Generalised Subclass Discriminant Analysis for Event and Concept Detection in Video", "authors": ["Stavros Arestis-Chartampilas\n,", "Nikolaos Gkalelis\n,", "Vasileios Mezaris"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper a discriminant analysis (DA) technique called accelerated generalised subclass discriminant analysis (AGSDA) and its GPU implementation are presented. This method identifies a discriminant subspace of the input space in three steps: a) Gram matrix computation, b) eigenvalue decomposition of the between subclass factor matrix, and c) computation of the solution of a linear matrix system with symmetric positive semidefinite (SPSD) matrix of coefficients. Based on the fact that the computationally intensive parts of AGSDA, i.e. Gram matrix computation and identification of the SPSD linear matrix system solution, are highly parallelisable, a GPU implementation of AGSDA is proposed. Experimental results on large-scale datasets of TRECVID for event and concept detection show that our GPU-AGSDA method combined with LSVM outperforms LSVM alone in training time, memory consumption, and detection accuracy.", "references": ["E. Agullo et al. Faster, cheaper, better -- a hybridization methodology to develop linear algebra software for GPUs. GPU Computing Gems, 2, 2010.", "A. Athanasopoulos et al. GPU acceleration for support vector machines. In WIAMIS, Delft, NL, April 13--15, 2011.", "C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Trans. Intell. Syst. Technol., 2(3):27:1--27:27, May 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806321"}, {"title": "Identifying Health Domain URLs using SVM", "authors": ["R. Rajalakshmi"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nWorld Wide Web contains large volume of information on various topics. Especially, in health domain, people surf the net before consulting experts. But it is not guaranteed that, only the relevant health related pages are retrieved. So there is a need for an automated system that could assist in identifying health related web pages. In this paper, an URL based approach is proposed to identify health domain URLs that will help to avoid fetching irrelevant web pages. One of the issues in URL based topic classification is difficulty in selection of suitable URL features. In this paper, only the 4-grams derived from URLs are used as features to determine the health related web page, without using any medical repository. Statistical dictionary based methods have been reported in the literature, but construction of such dictionary is not automatic. A machine learning technique to automatically learn statistical dictionary of terms from the training URLs is proposed. To classify a web page either as a health page or not, SVM binary classifier is designed with a dictionary of 4-grams derived from URLs. The bench mark dataset ODP has been used for evaluating the performance by conducting various experiments. With the proposed URL based approach, 87% of precision has been achieved, which is a significant improvement over the existing techniques.", "references": ["E. Baykan, M. Henzinger, L. Marian, and I. Weber. A Comprehensive study of features and algorithms for URL-based Topic classification. ACM Trans. Web, 5(3):15:1--15:29, July 2011.", "S. Chakrabarti, K. Punera, and M. Subramanyam. Accelerated focused crawling through online relevance feedback. In Proceedings of the 11th International Conference on World Wide Web, WWW '02, pages 148--159, New York, NY, USA, 2002. ACM.", "I. Guyon, N. J. Weston, S. Barhill, and V. Vapnik. Gene selection for cancer classification using support vector machines. Machine Learning, 46:389--922, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791441"}, {"title": "DBSCAN Revisited: Mis-Claim, Un-Fixability, and Approximation", "authors": ["Junhao Gan\n,", "Yufei Tao"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nDBSCAN is a popular method for clustering multi-dimensional objects. Just as notable as the method's vast success is the research community's quest for its efficient computation. The original KDD'96 paper claimed an algorithm with O(n log n) running time, where n is the number of objects. Unfortunately, this is a mis-claim; and that algorithm actually requires O(n2) time. There has been a fix in 2D space, where a genuine O(n log n)-time algorithm has been found. Looking for a fix for dimensionality d ≥ 3 is currently an important open problem.\nIn this paper, we prove that for d ≥ 3, the DBSCAN problem requires Ω(n4/3) time to solve, unless very significant breakthroughs---ones widely believed to be impossible---could be made in theoretical computer science. This (i) explains why the community's search for fixing the aforementioned mis-claim has been futile for d ≥ 3, and (ii) indicates (sadly) that all DBSCAN algorithms must be intolerably slow even on moderately large n in practice. Surprisingly, we show that the running time can be dramatically brought down to O(n) in expectation regardless of the dimensionality d, as soon as slight inaccuracy in the clustering results is permitted. We formalize our findings into the new notion of ρ-approximate DBSCAN, which we believe should replace DBSCAN on big data due to the latter's computational intractability.", "references": ["P. K. Agarwal, H. Edelsbrunner, and O. Schwarzkopf. Euclidean minimum spanning trees and bichromatic closest pairs. Discrete & Computational Geometry, 6:407--422, 1991.", "M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. OPTICS: Ordering points to identify the clustering structure. In SIGMOD, pages 49--60, 1999.", "S. Arya and D. M. Mount. Approximate range searching. Computational Geometry, 17(3--4):135--152, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2737792"}, {"title": "Understanding social media users via attributes and links", "authors": ["Mohammad Ali Abbasi"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808000.2808003"}, {"title": "Identification of Web Spam through Clustering of Website Structures", "authors": ["Filippo Geraci"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSpam websites are domains whose owners are not interested in using them as gates for their activities but they are parked to be sold in the secondary market of web domains. To transform the costs of the annual registration fees in an opportunity of revenues, spam websites most often host a large amount of ads in the hope that someone who lands on the site by chance clicks on some ads. Since parking has become a widespread activity, a large number of specialized companies have come out and made parking a straightforward task that simply requires to set the domain's name servers appropriately.\nAlthough parking is a legal activity, spam websites have a deep negative impact on the information quality of the web and can significantly deteriorate the performances of most web mining tools. For example these websites can influence search engines results or introduce an extra burden for crawling systems. In addition, spam websites represent a cost for ad bidders that are obliged to pay for impressions or clicks that have a negligible probability to produce revenues.\nIn this paper, we experimentally show that spam websites hosted by the same service provider tend to have similar look-and-feel. Exploiting this structural similarity we face the problem of the automatic identification of spam websites. In addition, we use the outcome of the classification for compiling the list of the name servers used by spam websites so that they can be discarded before the first connection just after the first DNS query. A dump of our dataset (including web pages and meta information) and the corresponding manual classification is freely available upon request.", "references": ["M. Almishari and X. Yang. Ads-portal domains: Identifcation and measurements. ACM Trans. Web, 4(2):4:1-4:34, Apr. 2010.", "C. Castillo, D. Donato, L. Becchetti, P. Boldi, S. Leonardi, M. Santini, and S. Vigna. A reference collection for web spam. SIGIR Forum, 40(2):11-24, Dec. 2006.", "C. Castillo, D. Donato, A. Gionis, V. Murdock, and F. Silvestri. Know your neighbors: Web spam detection using the web topology. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '07, pages 423-430, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742127"}, {"title": "Bottom-Up Fault Management in Service-Based Systems", "authors": ["Amal Alhosban\n,", "Khayyam Hashmi\n,", "Zaki Malik\n,", "Brahim Medjahed\n,", "Salima Benbernou"], "publication": "ACM Transactions on Internet Technology", "abstract": "Abstract\nService Oriented Architecture (SOA) enables the creation of distributed applications from independently developed and deployed services. As with any component-based system, the overall performance and quality of the system is an aggregate function of its component services. In this article, we present a novel approach for managing bottom-up faults in service-based systems. Bottom-up faults are a special case of system-wide exceptions that are defined as abnormal conditions or defects occurring in component services, which if not detected and/or managed, may lead to runtime failures. Examples of bottom-up faults include network outage, server disruption, and changes to service provisioning (e.g., new operation parameter required) that may have an impact on the way component services are consumed. We propose a soft-state signaling-based approach to propagate these faults from participants to composite services. Soft-state refers to a class of protocols where the state of a service is constantly refreshed by periodic messages, and user/service takes up the responsibility of communicating and maintaining its state. Soft-state-based protocols have a number of advantages including implicit error recovery and easier fault management, resulting in high availability for systems. Although soft-state has been widely used in various Internet protocols, this work is the first (to the best of our knowledge) to adopt soft-state for fault management in composite services. The proposed approach includes protocols for fault propagation (pure soft-state and soft-state with explicit removal) and fault reaction (rule-based). We also present experiment results to assess the performance and applicability of our approach.", "references": ["Akram, M. S., Medjahed, B., and Bouguettaya, A. 2003. Supporting dynamic changes in Web service environments. In Proceedings of ICSOC. 319--334.", "Alhosban, A., Hashmi, K., Malik, Z., and Medjahed, B. 2011. Assessing fault occurrence likelihood for service-oriented systems. In Proceedings of ICWE. 59--73.", "Ali, M. S. and Reiff-Marganiec, S. 2012. Autonomous failure-handling mechanism for WF long running transactions. In Proceedings of the IEEE 9th International Conference on Services Computing (SCC). 562--569."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2739045"}, {"title": "Shiny on Your Crazy Diagonal", "authors": ["Giorgio Maria Di Nunzio"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this demo, we present a web application which allows users to interact with two retrieval models, namely the Binary Independence Model (BIM) and the BM25 model, on a standard TREC collection. The goal of this demo is to give students deeper insight into the consequences of modeling assumptions (BIM vs. BM25) and the consequences of tuning parameter values by means of a two-dimensional representation of probabilities. The application was developed in R, and it is accessible at the following link: http://gmdn.shinyapps.io/shinyRF04.", "references": ["Giorgio Maria Di Nunzio. A new decision to take for cost-sensitive naıve bayes classifiers. Information Processing & Management, 50(5):653 -- 674, 2014.", "S. E. Robertson. The Probability Ranking Principle in IR. Journal of Documentation, 33(4):294--304, 1977.", "Stephen E. Robertson and Karen Sparck Jones. Relevance weighting of search terms. In Peter Willett, editor, Document retrieval systems, pages 143--160. Taylor Graham Publishing, London, UK,, 1988."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767867"}, {"title": "Relaxation of subgraph queries delivering empty results", "authors": ["Elena Vasilyeva\n,", "Maik Thiele\n,", "Adrian Mocan\n,", "Wolfgang Lehner"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nGraph databases with the property graph model are used in multiple domains including social networks, biology, and data integration. They provide schema-flexible storage for data of a different degree of a structure and support complex, expressive queries such as subgraph isomorphism queries. The exibility and expressiveness of graph databases make it difficult for the users to express queries correctly and can lead to unexpected query results, e.g. empty results. Therefore, we propose a relaxation approach for subgraph isomorphism queries that is able to automatically rewrite a graph query, such that the rewritten query is similar to the original query and returns a non-empty result set. In detail, we present relaxation operations applicable to a query, cardinality estimation heuristics, and strategies for prioritizing graph query elements to be relaxed. To determine the similarity between the original query and its relaxed variants, we propose a novel cardinality-based graph edit distance. The feasibility of our approach is shown by using real-world queries from the DBpedia query log.", "references": ["N. Bidoit, M. Herschel, and K. Tzompanaki. Query-based Why-Not provenance with NedExplain. In Proc. EDBT, pages 145--156, 2014.", "C. Bornhövd, R. Kubis, W. Lehner, H. Voigt, and H. Werner. Flexible information management, exploration and analysis in SAP HANA. In DATA, pages 15--28, 2012.", "A. Chapman and H. V. Jagadish. Why Not? In Proc. SIGMOD, pages 523--534. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791382"}, {"title": "Development of an expert system for personalized crop planning", "authors": ["Asanee Kawtrakul\n,", "Rudeemas Amorntarant\n,", "Hutchatai Chanlekha"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nIn this paper, we propose an effective rice crop planning system based on a knowledge engineering approach with hybrid knowledge representation, i.e., ontologies and rules, to help farmers make decisions in choosing their rice variety and planning cultivation. A critical challenge is to develop a recommendation system that supports and fulfills farmers' satisfaction, i.e., reducing risk from climate conditions and disease while improving productivity to meet market demand. To fulfill these needs, our recommendation system is separated into two parts: a rice variety suggestion system, which will help to suggest which variety to grow; and a personalized crop calendar generation system, which will help farmers in planning their activities toward higher production.", "references": ["Chien-Yeh Hsu, Ph.D., Li-Chieh Huang, M. S., Tzuo Ming Chen, Ph.D., Li-Fu Chen, M. S., and Jane C.-J. Chao, Ph.D. 2011. A Web-Based Decision Support System for Dietary Analysis and Recommendations. University of Taiwan at Taipei Medical. DOI=10.1089/tmj.2010.0104", "Chandra Prakash, Amar Singh Rathor, Gaur Sunder Mitra Thakur. 2014. Fuzzy based Agriculture expert system for Soyabean. University of India at Lovely Professional. DOI: 10.13140/2.1.1765.0567", "Constantine P. Yialouris, Vassiliki Kollias, Nikos A. Lorentzos, Dionisios Kalivas and Alexander B. Sideridis, 1997. An integrated expert geographical information system for soil suitability and soil evaluation. University of Athens. Journal of Geographic Information and Decision Analysis, vol. 1, no. 2, pp. 90--100."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857272"}, {"title": "Query Scheduling Techniques and Power-Latency Trade-off Model for Large-Scale Search Engines", "authors": ["Ana Freire"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nWeb search engines have to deal with a huge increase of information, demanded by high incoming query traffic. This situation has driven companies to build large, geographically distributed data centres housing thousands of servers and consuming enormous amounts of electricity. At this scale, even minor efficiency improvements may result in large financial and power savings.\nThis thesis represents a novel contribution to the state-of-the-art of Query Scheduling and Green Information Retrieval (Green IR), by assisting large-scale data centres to build more efficient and environmentally-friendly search engines.\nThe main contributions of this work are the following:\nQuery Scheduling. We introduce query efficiency predictors as suitable estimators to improve Query Scheduling. We estimate the processing time of the queries waiting in each query server and we calculate an approximate time that a new query must spend in each queue. Based on this estimation, the fastest query server is selected.\nGreen IR. Once we have developed new methods to improve the average response time of a search engine, we focus on reducing the power consumption of the whole system. This thesis proposes a mathematical model that establishes a trade-off between latency and power consumption. This model attempts to automatically adapt the number of active servers in the system based on the fluctuations of a daily query traffic flow.\nQueueing Theory. We prove the limitation of Queueing Theory models for estimating the latency in search engines. As a consequence, we develop our trade-off model by predicting the latency using historical data. Results show the good performance of this approach.\nIR evaluation. We attest that Simulation platforms are suitable for IR experimentation. We support this conclusion by establishing an exhaustive analysis of the current IR evaluation platforms.\n.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795418"}, {"title": "Decision Making in Public Administration Supported by Knowledge Discovery: A Case Study in Project Management", "authors": ["Caue R. do Prado\n,", "Sarajane M. Peres\n,", "Marcelo Fantinato"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn this paper, we report a case study carried out in order to analyze the potential of applying knowledge discovery as a strategy to support decision making in public administration. The discovery of knowledge was implemented by using a binary classifier to predict the success of failure concerning cost and deadline plans. The prediction was made analyzing descriptive data of the plans. The dataset was obtained from a project management system that was built based on the practices of the PMBOK guide. The strategies used in this case study, the difficulties faced during the classifier modeling process and the results are discussed herein.", "references": ["A Guide to the Project Management Body of Knowledge: PMBOK(R) Guide. Project Management Institute, 5th edition, 2013.", "N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. Smote: Synthetic minority oversampling technique. Journal of Artificial Intelligence Research, 16:321-357, 2002.", "U. Fayyad. From Data Mining to Knowledge Discovery in Databases. American Association for Artificial Inteligence, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814124"}, {"title": "EXPOSÉ: EXploring Past news fOr Seminal Events", "authors": ["Arunav Mishra\n,", "Klaus Berberich"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecent increases in digitization and archiving efforts on news data have led to overwhelming amounts of online information for general users, thus making it difficult for them to retrospect on past events. One dimension along which past events can be effectively organized is time. Motivated by this idea, we introduce EXPOSÉ, an exploratory search system that explicitly uses temporal information associated with events to link different kinds of information sources for effective exploration of past events. In this demonstration, we use Wikipedia and news articles as two orthogonal sources. Wikipedia is viewed as an event directory that systematically lists seminal events in a year; news articles are viewed as a source of detailed information on each of these events. To this end, our demo includes several time-aware retrieval approaches that a user can employ for retrieving relevant news articles, as well as a timeline tool for temporal analysis and entity-based facets for filtering results.", "references": ["The New York Times Annotated Corpus http://corpus.nytimes.com.", "K. Berberich, S. Bedathur, O. Alonso, and G. Weikum. A language modeling approach for temporal information needs. In ECIR, 2010.", "G. Marchionini. Exploratory search: From finding to understanding. Commun. ACM, 49(4), 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742844"}, {"title": "Social Event Mining in Large Photo Collections", "authors": ["Maia Zaharieva\n,", "Matthias Zeppelzauer\n,", "Manfred Del Fabro\n,", "Daniel Schopfhauser"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nA significant part of publicly available photos on the Internet depicts a variety of different social events. In order to organize this steadily growing media content and to make it easily accessible, novel indexing methods are required. Essential research questions in this context concern the efficient detection (clustering), classification, and retrieval of social events in large media collections. In this paper we explore two aspects of social events mining. First, the initial clustering of a given photo collection into single events and, second, the retrieval of relevant social events based on user queries. For both aspects we employ commonly available metadata information, such as user, time, GPS data, and user-generated textual descriptions. Performed evaluations in the context of social event detection demonstrate the strong generalization ability of our approach and the potential of contextual data such as time, user, and location. Experiments with social event retrieval clearly indicate the open challenge of mapping between previously detected event clusters and heterogeneous user queries.", "references": ["B.-K. Bao, W. Min, K. Lu, and C. Xu. Social event detection with robust high-order co-clustering. In ACM Int. Conf. on Multimedia Retrieval, pages 135--142, 2013.", "H. Becker, M. Naaman, and L. Gravano. Learning similarity metrics for event identification in social media. In ACM Int. Conf. on Web Search and Data Mining, pages 291--300, 2010.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749313"}, {"title": "Image Retrieval by User-oriented Ranking", "authors": ["Xueming Qian\n,", "Dan Lu\n,", "Xiaoxiao Liu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nTag-based image search is an important method to process images contributed by social users in social media sharing websites like Flickr. However, existing ranking methods for tag-based image search frequently return results that are irrelevant, low-diversity or time-consuming. In this paper, we propose a user-oriented image ranking system with the consideration of image relevance, diversity and computation complexity, aiming to automatically rank images according to their visual information, semantic information and social clues. When you input a query in the user-oriented image search engine, images tagged with query are obtained as the initial results. The initial results include images contributed by different social users. Usually each user contributes several images. First we sort these users by inter-user ranking. Users that have a higher contribution to the given query rank higher. Then we sequentially implement intra-user ranking on the ranked user's image set, and only the most relevant image in each user's image set is selected. These selected images compose the final retrieval results. Experimental results on Flickr dataset show that our user-oriented ranking method is effective and efficient.", "references": ["D. Cai, X. He, Z. Li, W. Y. Ma, J. R. Wen. \"Hierarchical clustering of WWW image search results using visual, textual and link information,\" In Proceedings of the 12th annual ACM international conference on Multimedia, pp. 952--959, 2004.", "X. Qian, G. Liu, D. Guo. Object categorization using hierarchical wavelet packet texture descriptors. in Proc. ISM 2009, pp.44--51.", "D. Liu, X. S. Hua, M. Wang. \"Boost search relevance for tag-based social image retrieval,\" In IEEE International Conference, pp. 1636--1639, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749326"}, {"title": "Privacy and Personalization Perceptions of the Indian Demographic with respect to Online Searches", "authors": ["Saraswathi Punagin\n,", "Arti Arya"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nMost internet users' browsing starts with a query submit on a web search engine. Search engine usage has become so extensive that it seems like second nature in today's online world. Customized search results enhance user experience but they bring up the eternal debate of privacy vs. personalization into focus. Users are usually unaware of the implications of disclosing sensitive personal information during their web searches. Those who are aware may take measures to protect their privacy. We argue and hypothesize that in spite of the technological advancement and increased internet usage, an average Indian consumer is less likely to be aware of the privacy and personalization implications of web searches. We also argue that an educated consumer, armed with awareness will change his privacy and personalization perceptions with respect to web searches. The results of a study conducted with 660 participants render support to most of the proposed hypotheses. Results indicate that while there are a very low percentage of Indian consumers who are Fully Privacy Aware (11%), there exist a moderate number of consumers who are Fully Customization/Personalization Aware (55%). Percentage of consumers who dislike being tracked online is 37% and consumers who took some action to protect their online privacy during web searches were 25%. Also, of the 102 participants who were part of group discussions, 56% of them changed their privacy and personalization perceptions slightly or significantly after their increased awareness about this tradeoff in online searches.", "references": ["Barbaro M., Zellar T., A Face is Exposed For AOL Searcher No. 4417749, nytimes.com, 08/09/2006, Web, 04/08/2015, http://www.nytimes.com/2006/08/09/technology/09aol.html?pagewanted=all&_r=2&", "Gupta, Babita, Lakshmi S. Iyer, and Robert S. Weisskirch. \"Facilitating global e-commerce: a comparison of consumers' willingness to disclose personal information online in the US and in India.\" Journal of electronic commerce research 11.1 (2010): 41--52.", "Hofstede, Geert. \"Culture's consequences. Beverly Hills.\" (1980)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791427"}, {"title": "“Introducing Capisco: a semantically-enhanced search and discovery system for large-scale text corpora”", "authors": ["Annika Hinze\n,", "Craig Taube-Schock\n,", "David Bainbridge\n,", "Sally Jo Cunningham\n,", "J. Stephen Downie"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nThis article discusses a new approach to scholarly search and discovery in large-scale text corpora. While lexicographic search is at present the predominant means to access large document corpora, it cannot directly address the inherent ambiguity of natural language. As a pragmatic solution, many scholars manually build their own list of suitable search terms to be used in repeated searches in digital libraries and other online resources; however, scholars then have to resolve on a case-by-case basis issues caused by synonyms, homonyms and OCR errors. Our approach differs from this by supporting scholars in developing and refining a set of relevant concepts, searches a large document collection using semantic concepts, and categorizes the potentially relevant documents from search results into worksets. The developed technique revisits the notion of semantic search and redesigns both the underlying data representation and interface support. This is achieved through an end-to-end design that relies centrally on a Concept-in-Context network sourced through the link structure of Wikipedia. We discuss here the principles of our approach, its implementation in the Capisco prototype, and the relationship between established search techniques and our approach.", "references": ["Aasman, J. 2006. Allegro graph: RDF triple database. Tech. rep., White paper. Franz Incorporated, 2006. http://www.franz.com/agraph/allegrograph.", "Basile, V., Bos, J., Evang, K., and Venhuizen, N. 2012. Developing a large semantically annotated corpus. In LREC. Vol. 12. 3196--3200.", "Cunningham, S. J., Hinze, A., Bainbridge, D., Taube-Schock, C., and Ryan, T. 2015. Building heritage document collections for pacific island nations using semantic-enriched search. In Samoa III Conference."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833219.2833223"}, {"title": "SeeDB: efficient data-driven visualization recommendations to support visual analytics", "authors": ["Manasi Vartak\n,", "Sajjadur Rahman\n,", "Samuel Madden\n,", "Aditya Parameswaran\n,", "Neoklis Polyzotis"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nData analysts often build visualizations as the first step in their analytical workflow. However, when working with high-dimensional datasets, identifying visualizations that show relevant or desired trends in data can be laborious. We propose SeeDB, a visualization recommendation engine to facilitate fast visual analysis: given a subset of data to be studied, SeeDB intelligently explores the space of visualizations, evaluates promising visualizations for trends, and recommends those it deems most \"useful\" or \"interesting\". The two major obstacles in recommending interesting visualizations are (a) scale: evaluating a large number of candidate visualizations while responding within interactive time scales, and (b) utility: identifying an appropriate metric for assessing interestingness of visualizations. For the former, SeeDB introduces pruning optimizations to quickly identify high-utility visualizations and sharing optimizations to maximize sharing of computation across visualizations. For the latter, as a first step, we adopt a deviation-based metric for visualization utility, while indicating how we may be able to generalize it to other factors influencing utility. We implement SeeDB as a middleware layer that can run on top of any DBMS. Our experiments show that our framework can identify interesting visualizations with high accuracy. Our optimizations lead to multiple orders of magnitude speedup on relational row and column stores and provide recommendations at interactive time scales. Finally, we demonstrate via a user study the effectiveness of our deviation-based utility metric and the value of recommendations in supporting visual analytics.", "references": ["Tableau public, www.tableaupublic.com. {Online; accessed 3-March-2014}.", "S. Agarwal, R. Agrawal, P. Deshpande, A. Gupta, J. F. Naughton, R. Ramakrishnan, and S. Sarawagi. On the computation of multidimensional aggregates. VLDB '96, pages 506--521, 1996.", "C. Ahlberg. Spotfire: An information exploration environment. SIGMOD Rec., 25(4):25--29, Dec. 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2831360.2831371"}, {"title": "VizTrails: An Information Visualization Tool for Exploring Geographic Movement Trajectories", "authors": ["Martin Becker\n,", "Philipp Singer\n,", "Florian Lemmerich\n,", "Andreas Hotho\n,", "Denis Helic\n,", "Markus Strohmaier"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nUnderstanding the way people move through urban areas represents an important problem that has implications for a range of societal challenges such as city planning, public transportation, or crime analysis. In this paper, we present an interactive visualization tool called VizTrails for exploring and understanding such human movement. It features visualizations that show aggregated statistics of trails for geographic areas that correspond to grid cells on a map, e.g., on the number of users passing through or on cells commonly visited next. Amongst other features, system allows to overlay the map with the results of SPARQL queries in order to relate the observed trajectory statistics with its geo-spatial context, e.g., considering a city's points of interest. The systems functionality is demonstrated using trajectory examples extracted from the social photo sharing platform Flickr. Overall, VizTrails facilitates deeper insights into geo-spatial trajectory data by enabling interactive exploration of aggregated statistics and providing geo-spatial context.", "references": ["M. Becker, P. Singer, F. Lemmerich, A. Hotho, D. Helic, and M. Strohmaier. Photowalking the city: Comparing hypotheses about urban photo trails on flickr. 2015. under review http://dmir.org/pub/2015/photowalking.pdf.", "P. Singer, D. Helic, A. Hotho, and M. Strohmaier. Hyptrails: A bayesian approach for comparing hypotheses about human trails on the web. In International Conference on World Wide Web, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791021"}, {"title": "Boosting Prediction of Geo-location for Web Images Through Integrating Multiple Knowledge Sources", "authors": ["Hao Kuang\n,", "Shiai Zhu\n,", "Abdulmotaleb El Saddik"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nEstimating geographical information of a given photo is a challenging task due to the massive spread of candidate locations on the earth. With the help of freely available geo-tagged Web images, the problem can be addressed by propagating geo-coordinates (latitude and longitude) of geo-related training data, which is obtained using document retrieval techniques. The state-of-the-art approach adopts language modeling technique to estimate the probability distribution of image associated tags in a local region. Under this framework, we propose to differentiate the tags based on the knowledge explored from multiple sources. Finally, a set of geo-informative tags are identified and further emphasized during the model learning and geo-location prediction. In addition, accurate geo-coordinates are estimated by incorporating the image visual information. Experiments on a large-scale geo-tagged Flickr image dataset demonstrate the effectiveness of proposed method at different levels of evaluation granularity.", "references": ["S. Ardeshir, A. R. Zamir, A. Torroella, and M. Shah. Gis-assisted object detection and geospatial localization. In ECCV, 2014.", "D. J. Crandall, L. Backstrom, D. P. Huttenlocher, and J. M. Kleinberg. Mapping the world's photos. In WWW, 2009.", "Q. Fang, J. Sang, and C. Xu. Giant: geo-informative attributes for location recognition and exploration. In ACM Multimedia, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749351"}, {"title": "Matching Physical Sites with Web Sites for Semantic Localization", "authors": ["Rufeng Meng\n,", "Sheng Shen\n,", "Romit Roy Choudhury\n,", "Srihari Nelakuditi"], "publication": "WPA '15: Proceedings of the 2nd workshop on Workshop on Physical Analytics", "abstract": "ABSTRACT\nLocations are often expressed in physical coordinates such as an [X, Y] tuple in some coordinate system. Unfortunately, a vast majority of location-based applications desire the semantic translation of coordinates, i.e., store-names like Starbucks, Macy's, Panera. Past work has mostly focused on achieving localization accuracy, while assuming that the translation of physical to semantic coordinates will be done manually. In this paper, we explore an opportunity for automatic semantic localization -- the presence of a website corresponding to each physical store. We propose to correlate the information seen in a physical store with that found in websites of the stores around that location, to recognize that store. Specifically, we assume a repository of crowdsourced WiFi-tagged pictures from different stores. By correlating words inside the pictures, against words extracted from store websites, our proposed system can automatically label clusters of pictures, and the corresponding WiFi APs, with the store name. Later, when a user enters a store, her smartphone can scan the WiFi APs and consult a lookup table to recognize the store she is in. Our preliminary experiments with 18 stores in a shopping mall show that, our prototype system could correctly match the text from the physical stores with the text extracted from the corresponding web sites and hence label WiFi APs with store names with an accuracy upwards of 90%, which encourages us to pursue this study further. Moreover, we believe the core idea of correlating physical and web sites has broader applications beyond semantic localization, leading to better product placement and shopping experience, yielding benefits for both store owners and shoppers.", "references": ["Truc D Le, Thong M Doan, Han N Dinh, and Nam T Nguyen. Isil: Instant search-based indoor localization. In Consumer Communications and Networking Conference (CCNC), pages 143--148. IEEE, 2013.", "Google goggles. www.google.com/mobile/goggles.", "E Garcia. Cosine similarity and term weight tutorial. Information retrieval intelligence, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2753497.2753501"}, {"title": "Session details: Session 4 -- Big Data Analytics and Crowdsourcing for Public Health 1", "authors": ["Philip Abdelmalik"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3246859"}, {"title": "Discovering Opinion Spammer Groups by Network Footprints", "authors": ["Junting Ye\n,", "Leman Akoglu"], "publication": "COSN '15: Proceedings of the 2015 ACM on Conference on Online Social Networks", "abstract": "ABSTRACT\nOnline reviews are an important source for consumers to evaluate products/services on the Internet (e.g. Amazon, Yelp, etc.). However, more and more fraudulent reviewers write fake reviews to mislead users. To maximize their impact and share effort, many spam attacks are organized as campaigns, by a group of spammers. In this paper, we propose a new two-step method to discover spammer groups and their targeted products. First, we introduce NFS (Network Footprint Score), a new measure that quantifies the likelihood of products being spam campaign targets. Second, we carefully devise GroupStrainer to cluster spammers on a 2-hop subgraph induced by top ranking products. Our approach has four key advantages: (i) unsupervised detection; both steps require no labeled data, (ii) adversarial robustness; we quantify statistical distortions in the review network, of which spammers have only a partial view, and avoid any side information that spammers can easily evade, (iii) sensemaking; the output facilitates the exploration of the nested hierarchy (i.e., organization) among the spammers, and finally (iv) scalability; both steps have complexity linear in network size, moreover, GroupStrainer operates on a carefully induced subnetwork. We demonstrate the efficiency and effectiveness of our approach on both synthetic and real-world datasets from two different domains with millions of products and reviewers. Moreover, we discover interesting strategies that spammers employ through case studies of our detected groups.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2817946.2820606"}, {"title": "A Platform for the Recommendation of Points of Interest in Brazilian Cities: Architecture and Case Study", "authors": ["Marcos Aurélio Domingues\n,", "Thais Emanuele Santos\n,", "Raíza Hanada\n,", "Bruna C.R. Cunha\n,", "Solange Oliveira Rezende\n,", "Maria da Graça Campos Pimentel"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe tourism sector in Brazil has grown considerably in recent years. Despite this growth, the sector still presents several problems such as the lack of information in Portuguese and in other languages for Brazilian and foreign tourists. The absence of information about tourist sites and ordinary services also affects individuals when settling in a new city, as it is the case when freshman students move to a new city to start their studies in a college or university. In this work, we propose an innovative vision of a context-aware platform for recommending points of interest in Brazilian cities, designed with mechanisms for collecting data from the web, for extracting points of interest and background information, and for learning context-aware recommendation models. The platform is accessed by a mobile application. To validate our proposal, we ran a case study where freshman students used the platform during their first months in a new city.", "references": ["L. Baltrunas, B. Ludwig, S. Peer, and F. Ricci. Context-aware places of interest recommendations for mobile users. In A. Marcus, editor, Design, User Experience, and Usability. Theory, Methods, Tools and Practice, volume 6769 of Lecture Notes in Computer Science, pages 531--540. Springer Berlin Heidelberg, 2011.", "T. Bray, J. Paoli, C. M. Sperberg-McQueen, E. Maler, and F. Yergeau. Extensible markup language (xml) 1.0 (fourth edition). technical report, world wide web consortium, http://www.w3.org/tr/xml, 2006. Access date: 23/06/2015.", "B. D. Carolis, I. Mazzotta, N. Novielli, and V. Silvestri. Using common sense in providing personalized recommendations in the tourism domain. In Proceedings of the Workshop on Context-Aware Recommender Systems, CARS '09, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820448"}, {"title": "QoS-Aware Autonomic Resource Management in Cloud Computing: A Systematic Review", "authors": ["Sukhpal Singh\n,", "Inderveer Chana"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nAs computing infrastructure expands, resource management in a large, heterogeneous, and distributed environment becomes a challenging task. In a cloud environment, with uncertainty and dispersion of resources, one encounters problems of allocation of resources, which is caused by things such as heterogeneity, dynamism, and failures. Unfortunately, existing resource management techniques, frameworks, and mechanisms are insufficient to handle these environments, applications, and resource behaviors. To provide efficient performance of workloads and applications, the aforementioned characteristics should be addressed effectively. This research depicts a broad methodical literature analysis of autonomic resource management in the area of the cloud in general and QoS (Quality of Service)-aware autonomic resource management specifically. The current status of autonomic resource management in cloud computing is distributed into various categories. Methodical analysis of autonomic resource management in cloud computing and its techniques are described as developed by various industry and academic groups. Further, taxonomy of autonomic resource management in the cloud has been presented. This research work will help researchers find the important characteristics of autonomic resource management and will also help to select the most suitable technique for autonomic resource management in a specific application along with significant future research directions.", "references": ["Omar A. Rahman, Masaharu Munetomo, and Kiyoshi Akama. 2011. Multi-level autonomic architecture for the management of virtualized application environments in cloud platforms. In Proceedings of the IEEE International Conference on Cloud Computing (CLOUD’11). IEEE, 754--755. DOI:http://dx.doi.org/10.1109/CLOUD.2011.58", "Bernardetta Addis, Danilo Ardagna, Barbara Panicucci, and Li Zhang. 2010. Autonomic management of cloud service centers with availability guarantees. In Proceedings of the IEEE 3rd International Conference on Cloud Computing (CLOUD ’10). IEEE, 220--227. DOI:http://dx.doi.org/10.1109/CLOUD.2010.19", "Amazon Web Services. 2013. Amazon EC2 instances. Retrieved from http://aws.amazon.com/ec2/instance-types/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2843889"}, {"title": "Exclusive Constrained Discriminative Learning for Weakly-Supervised Semantic Segmentation", "authors": ["Peng Ying\n,", "Jin Liu\n,", "Hanqing Lu\n,", "Songde Ma"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHow to import image-level labels as weak supervision to direct the region-level labeling task is the core task of weakly-supervised semantic segmentation. In this paper, we focus on designing an effective but simple weakly-supervised constraint, and propose an exclusive constrained discriminative learning model for image semantic segmentation. To be specific, we employ a discriminative linear regression model to assign subsets of superpixels with different labels. During the assignment, we construct an exclusive weakly-supervised constraint term to suppress the labeling responses of each superpixel on the labels outside its parent image-level label set. Besides, a spectral smoothing term is integrated to encourage that both visually and semantically similar superpixels have similar labels. Combining these terms, we formulate the problem as a convex objective function, which can be easily optimized via alternative iterations. Extensive experiments on MSRC-21 and LabelMe datasets demonstrate the effectiveness of the proposed model.", "references": ["R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Susstrunk. Slic superpixels compared to state-of-the-art superpixel methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(11):2274--2282, 2012.", "L. Ladicky, C. Russell, P. Kohli, and P. H. Torr. Associative hierarchical crfs for object class image segmentation. In ICCV, 2009, pages 739--746, 2009.", "L.-J. Li, R. Socher, and L. Fei-Fei. Towards total scene understanding: Classification, annotation and segmentation in an automatic framework. In CVPR 2009., pages 2036--2043. IEEE, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806329"}, {"title": "The role of evaluation in AI and law: an examination of its different forms in the AI and law journal", "authors": ["Jack G. Conrad\n,", "John Zeleznikow"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nThis paper explores the presence and forms of evaluation in articles published in the journal Artificial Intelligence and Law for the ten-year period from 2005 through 2014. It represents a meta-level study of some the most significant works produced by the AI and Law community, in this case nearly 140 research articles published in the AI and Law journal. It also compares its findings to previous work conducted on evaluation appearing in the Proceedings of the International Conference on Artificial Intelligence and Law (ICAIL). In addition, the paper highlights works harnessing performance evaluation as one of their chief scientific tools and the means by which they use it. It extends the argument for why evaluation is essential in formal Artificial Intelligence and Law reports such as those in the journal. As in the case of two earlier works on the topic, it pursues answers to the questions: how good is the system, algorithm or proposal?, how reliable is the approach or technique?, and, ultimately, does the method work? The paper investigates the role of performance evaluation in scientific research reports, underscoring the argument that a performance-based 'ethic' signifies a level of maturity and scientific rigor within a community. In addition, the work examines recent publications that address the same critical issue within the broader field of Artificial Intelligence.", "references": ["F. J. Bex, H. Prakken, and B. Verheij:. Formalising argumentative story-based analysis of evidence. In Proceedings of the 12th International Conference on Artificial Intelligence and Law (ICAIL 2007) (Stanford, CA), pages 1--10. IAAIL, ACM Press, 2007.", "M. Caminada and L. Amgoud. On the evaluation of argumentation formalisms. Artificial Intelligence, 17(5): 286--310, 2007.", "P. R. Cohen and A. E. Howe. How evaluation guides AI research. AI Magazine, 9(4): 35--43, Winter 1988."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746116"}, {"title": "Toward an Automatic Evaluation of Retrieval Performance with Large Scale Image Collections", "authors": ["Adrian Popescu\n,", "Eleftherios Spyromitros-Xioufis\n,", "Symeon Papadopoulos\n,", "Hervé Le Borgne\n,", "Ioannis Kompatsiaris"], "publication": "MMCommons '15: Proceedings of the 2015 Workshop on Community-Organized Multimodal Mining: Opportunities for Novel Solutions", "abstract": "ABSTRACT\nThe public availability of large-scale multimedia collections, such as YFCC, facilitates the evaluation of image retrieval approaches in real-life conditions. However, due to their size, the creation of exhaustive ground truth would require huge annotation effort, even for limited sets of queries. This paper investigates whether it is possible to estimate retrieval performance in absence of manually created ground truth data. Our hypothesis is that it is possible to leverage existing weak user annotations (tags) to automatically build ground truth data. To test our hypothesis, we implemented a large-scale retrieval pipeline based on two state-of-the-art image descriptors and two compressed versions of each. The top 50 results obtained with each configuration are manually annotated in order to estimate their performance. Alternately, we produce an automatic performance estimation that is based on pre-existing user tags. The automatic performance estimations exhibit strong positive correlation with the manual ones and the systems rankings obtained in the two evaluation settings are found to be similar. This indicates that, although incomplete and sometimes imprecision, weak user annotations can be effectively exploited to assess retrieval performance. As a by-product, we release state-of-the-art image features, as well as a reusable evaluation package that will encourage the use of YFCC in the community.", "references": ["H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust features (surf). Computer vision and image understanding, 110(3):346--359, 2008.", "J. Choi and al. The placing task: A large-scale geo-estimation challenge for social-media videos and images. In GeoMM 2014 workshop.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In ACM CIVR 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814815.2814819"}, {"title": "Scalable local feature matching without visual codebook training", "authors": ["Wengang Zhou\n,", "Houqiang Li\n,", "Qi Tian"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn partial-duplicate image retrieval using scale-invariant feature transform (SIFT) features, the key problem is local feature matching between images, which can be formulated as a ε-neighborhood problem. Traditional approaches usually adopt the Bag-of-Visual-Words model and achieve local feature matching by training a large visual codebook with clustering techniques. This paradigm has demonstrated impressive performance, but suffers tedious training efforts and somewhat overfitting to the limited training data. To avoid those issues, we approach the scalable feature matching problem with a novel perspective and address it without training visual codebook. We will discuss two solutions on this new paradigm, i.e., binary SIFT based quantization and dual cascaded scalar quantization.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, pages 2911--2918, 2012.", "L. Chu, S. Jiang, S. Wang, Y. Zhang, and Q. Huang. Robust spatial consistency graph model for partial duplicate image retrieval. IEEE Trans. Multimedia (TMM), 15(8):1982--1996, 2013.", "O. Chum, A. Mikulik, M. Perdoch, and J. Matas. Total recall II: Query expansion revisited. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, pages 889--896, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808575"}, {"title": "Image-regulated graph topic model for cross-media topic detection", "authors": ["Zhiyi Wang\n,", "Liang Li\n,", "Chunjie Zhang\n,", "Qingming Huang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn recent years, pictures and videos have become ubiquitous on the Internet, which encourage the development of algorithm that analyze their semantic contents for detecting topics. Among them, topic modeling plays an essential role in discovering topics from document collections. However, with rich auxiliary information (such as geo-information, user-annotated tags, pictures and videos) rising up around the text, traditional topic models show their limitations to discover latent topics effectively from the cross-media data. To address this problem, we propose a novel Image-regulated Graph Topic Model (IGTM), which combines cross-media data together in the modeling process. By utilizing auxiliary relation information among images, IGTM can achieve higher quality underlying topics as image relationships could serve as weakly-supervised information for topic modeling. Experimental results over two cross-media datasets demonstrate the effectiveness of our model.", "references": ["D. M. Blei and M. I. Jordan. Modeling annotated data. In ACM SIGIR, pages 127--134, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3: 993--1022, 2003.", "I. Bordino, C. Castillo, D. Donato, and A. Gionis. Query similarity by projecting the query-flow graph. In ACM SIGIR, pages 515--522, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808569"}, {"title": "Modeling Website Topic Cohesion at Scale to Improve Webpage Classification", "authors": ["Dhivya Eswaran\n,", "Paul N. Bennett\n,", "Joseph J. Pfeiffer"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nConsiderable work in web page classification has focused on incorporating the topical structure of the web (e.g., the hyperlink graph) to improve prediction accuracy. However, the majority of work has primarily focused on relational or graph-based methods that are impractical to run at scale or in an online environment. This raises the question of whether it is possible to leverage the topical structure of the web while incurring nearly no additional prediction-time cost. To this end, we introduce an approach which adjusts a page content-only classification from that obtained with a global prior to the posterior obtained by incorporating a prior which reflects the topic cohesion of the site. Using ODP data, we empirically demonstrate that our approach yields significant performance increases over a range of topics.", "references": ["P. Bennett et al. Modeling the impact of short- and long-term behavior on search personalization. In SIGIR '12, 2012.", "P. N. Bennett, K. Svore, and S. T. Dumais. Classification-enhanced ranking. In WWW '10, 2010.", "S. Dumais, E. Cutrell, and H. Chen. Bringing order to the web: Optimizing search by showing results in context. In CHI'01, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767834"}, {"title": "Processing and optimizing main memory spatial-keyword queries", "authors": ["Taesung Lee\n,", "Jin-woo Park\n,", "Sanghoon Lee\n,", "Seung-Won Hwang\n,", "Sameh Elnikety\n,", "Yuxiong He"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nImportant cloud services rely on spatial-keyword queries, containing a spatial predicate and arbitrary boolean keyword queries. In particular, we study the processing of such queries in main memory to support short response times. In contrast, current state-of-the-art spatial-keyword indexes and relational engines are designed for different assumptions. Rather than building a new spatial-keyword index, we employ a cost-based optimizer to process these queries using a spatial index and a keyword index. We address several technical challenges to achieve this goal. We introduce three operators as the building blocks to construct plans for main memory query processing. We then develop a cost model for the operators and query plans. We introduce five optimization techniques that efficiently reduce the search space and produce a query plan with low cost. The optimization techniques are computationally efficient, and they identify a query plan with a formal approximation guarantee under the common independence assumption. Furthermore, we extend the framework to exploit interesting orders. We implement the query optimizer to empirically validate our proposed approach using real-life datasets. The evaluation shows that the optimizations provide significant reduction in the average and tail latency of query processing: 7- to 11-fold reduction over using a single index in terms of 99th percentile response time. In addition, this approach outperforms existing spatial-keyword indexes, and DBMS query optimizers for both average and high-percentile response times.", "references": ["PostGIS, PostGIS Spatial and Geographic Objects for PostgreSQL. http://postgis.net/.", "PostgreSQL, SQL Compliant, Open Source Object-Relational Database Management System. http://www.postgresql.org/.", "W. G. Aref and H. Samet. Efficient processing of window queries in the pyramid data structure. In PODS, pages 265--272, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2850583.2850588"}, {"title": "Predicting Temporal Intention in Resource Sharing", "authors": ["Hany M. SalahEldeen\n,", "Michael L. Nelson"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWhen users post links to web pages in Twitter there is a time delta between when the post was shared (t tweet ) and when it was read (t click ). Ideally, when this time delta is small there is often no change in the page's state. However upon reading shared content in the past and due to the dynamic nature of the web, the page's state could change and the intention of the author need to be inferred. In this work, we enhance a prior temporal intention model and tackle its shortcomings by incorporating extended linguistic feature analysis, replacing the prior textual similarity measure with semantic similarity one based on latent topic detection trained on Wikipedia English corpus, and finally by enriching and balancing the training dataset. We uncovered three different intention behaviors in respect to time: Stable Intention, Changing Intention from current to past, and Undefined intention. Using these classes and only the information available at posting time from the tweet and the current state of the resource, we correctly predict the temporal intention classification and strength with 77% accuracy.", "references": ["E. Adar, J. Teevan, S. T. Dumais, and J. L. Elsas. The Web Changes Everything: Understanding The Dynamics Of Web Content. In WSDM '09: Proceedings Of The Second ACM International Conference On Web Search and Data Mining, pages 282--291, 2009.", "N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. SMOTE: Synthetic Minority Over-Sampling Technique. Journal Of Artificial Intelligence Research, 16(1):321--357, June 2002.", "T. Chen, D. Lu, M.-Y. Kan, and P. Cui. Understanding and Classifying Image Tweets. In Proceedings Of The 21st ACM International Conference On Multimedia, MM '13, pages 781--784, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756921"}, {"title": "IRIS: A Robust Information System Against Insider DoS Attacks", "authors": ["Martina Eikel\n,", "Christian Scheideler"], "publication": "ACM Transactions on Parallel Computing", "abstract": "Abstract\nIn this work, we present the first scalable distributed information system, that is, a system with low storage overhead, that is provably robust against denial-of-service (DoS) attacks by a current insider. We allow a current insider to have complete knowledge about the information system and to have the power to block any ε-fraction of its servers by a DoS attack, where ε can be chosen up to a constant. The task of the system is to serve any collection of lookup requests with at most one per nonblocked server in an efficient way despite this attack. Previously, scalable solutions were only known for DoS attacks of past insiders, where a past insider only has complete knowledge about some past time point t0 of the information system. Scheideler et al. [Awerbuch and Scheideler 2007; Baumgart et al. 2009] showed that in this case, it is possible to design an information system so that any information that was inserted or last updated after t0 is safe against a DoS attack. But their constructions would not work at all for a current insider. The key idea behind our IRIS system is to make extensive use of coding. More precisely, we present two alternative distributed coding strategies with an at most logarithmic storage overhead that can handle up to a constant fraction of blocked servers.", "references": ["R. Ahlswede, N. Cai, S-y. R. Li, and R. W. Yeung. 2000. Network information flow. IEEE Trans. Inf. Theory 46, 4 (2000), 1204--1216.", "B. Awerbuch and C. Scheideler. 2006. Towards a scalable and robust DHT. In Proc. of SPAA. 318--327.", "B. Awerbuch and C. Scheideler. 2007. A denial-of-service resistant DHT. In Proc. of DISC. 33--47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809806"}, {"title": "Using Encyclopedic Knowledge to Understand Queries", "authors": ["Kejun Zhao\n,", "Xiaofeng Meng\n,", "Hehan Li\n,", "Zhongyuan Wang"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nQuery understanding is a challenging but beneficial task. In this paper, we propose a context-aware method to use the encyclopedic knowledge to aid in query understanding. Given a query, we first use a dictionary constructed from the encyclopedic knowledge bases to detect the possible entities and their associated categories. Then, we use a topic based ethod to derive semantic information from the query. By comparing the topical similarity between various candidate phrases, we get the most likely entities and their related categories. Experimental results show that our method has achieved a great improvement over previous approaches and the efficiency is acceptable for online search.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "J. R. Finkel, T. Grenager, and C. D. Manning. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-30 June 2005, University of Michigan, USA, 2005.", "G. Fu and K. Luke. Chinese named entity recognition using lexicalized hmms. SIGKDD Explorations, 7(1):19--25, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810358"}, {"title": "A Multistage Credibility Analysis Model for Microblogs", "authors": ["Majed AlRubaian\n,", "Muhammad Al-Qurishi\n,", "Mabrook Al-Rakhami\n,", "Sk Md Mizanur Rahman\n,", "Atif Alamri"], "publication": "ASONAM '15: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015", "abstract": "ABSTRACT\nCurrently, microblogs such as the well-known social network Twitter are one of the most important sources of information in an era of information overload, restiveness and uncertainty. Consequently, developing models to verify information from Twitter has become both a challenging and necessary task. In this paper, we propose a novel multi-stage credibility analysis framework to identify implausible content in Twitter in order to prevent the proliferation of fake or malicious information. We used Naïve Bayes classifier and it is enhanced by considering the relative importance of the used features to improve the classification accuracy. We examine the classifier with 1000 unique tweets along with 700 account. The result quite motivating with accuracy 90.3%, 86.24% Precision and 98.8% recall.", "references": ["A. J. Flanagin and M. J. Metzger, \"Digital media and youth: Unparalleled opportunity and unprecedented responsibility,\" Digital media, youth, and credibility, pp. 5--27, 2008.", "M. Indrawan-Santiago, H. Han, H. Nakawatase, and K. Oyama, \"Evaluating credibility of interest reflection on Twitter,\" International Journal of Web Information Systems, vol. 10, pp. 343--362, 2014.", "C. Castillo, M. Mendoza, and B. Poblete, \"Information credibility on twitter,\" presented at the Proceedings of the 20th international conference on World wide web, Hyderabad, India, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808797.2810065"}, {"title": "Cost-Effective and Reliable Cloud Storage for Big Data", "authors": ["Chun-Hsin Wu\n,", "Pu Hsu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nEfficiency and reliability are critical to the performance of big data computing. Hadoop is one of the most popular cloud platforms to support big data analysis. To improve data availability, the Hadoop distributed file system usually stores blocks of files in triplicate, but it incurs high storage costs and high information-leakage risks. In this paper we propose a new cost-effective approach in xHDFS: paired blocks from two machines are erasure-coded to generate redundant blocks that are intelligently managed. We evaluate that xHDFS can effectively improve the reliability of cloud storage and tolerate network or site failures with lower storage costs.", "references": ["Shvachko, K., Kuang, H., Radia, S., and Chansler, R. 2010. The Hadoop distributed file system. In Proceedings of the 26th IEEE Symposium on Mass Storage Systems and Technologies (May. 2010).", "Ghemawat, S., Gobioff, H., and Leung, S.-T. 2003. The Google file system In Proceedings of the 19th ACM Symposium on Operating Systems Principles (Oct. 2003).", "HDFS RAID. http://wiki.apache.org/hadoop/HDFS-RAID"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818884"}, {"title": "Mining Affective Context in Short Films for Emotion-Aware Recommendation", "authors": ["Claudia Orellana-Rodriguez\n,", "Ernesto Diaz-Aviles\n,", "Wolfgang Nejdl"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nEmotion is fundamental to human experience and impacts our daily activities and decision-making processes where, e.g., the affective state of a user influences whether or not she decides to consume a recommended item - movie, book, product or service. However, information retrieval and recommendation tasks have largely ignored emotion as a source of user context, in part because emotion is difficult to measure and easy to misunderstand. In this paper we explore the role of emotions in short films and propose an approach that automatically extracts affective context from user comments associated to short films available in YouTube, as an alternative to explicit human annotations. We go beyond the traditional polarity detection (i.e., positive/negative), and extract for each film four opposing pairs of primary emotions: joy-sadness, anger-fear, trust-disgust, and anticipation-surprise. Finally, in our empirical evaluation, we show how the affective context extracted automatically can be leveraged for emotion-aware film recommendation.", "references": ["About Tropfest. http://tropfest.com/about/. Accessed: 2015-04.", "Academy of Motion Picture Arts (AMPAS). http://www.oscars.org/oscars/rules-eligibility. Accessed: 2015-03.", "Amazon Mechanical Turk. https://www.mturk.com/mturk/welcome. Accessed: 2015-04."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791042"}, {"title": "Speculative Approximations for Terascale Distributed Gradient Descent Optimization", "authors": ["Chengjie Qin\n,", "Florin Rusu"], "publication": "DanaC'15: Proceedings of the Fourth Workshop on Data analytics in the Cloud", "abstract": "ABSTRACT\nModel calibration is a major challenge faced by the plethora of statistical analytics packages that are increasingly used in Big Data applications. Identifying the optimal model parameters is a time-consuming process that has to be executed from scratch for every dataset/model combination even by experienced data scientists. We argue that the incapacity to evaluate multiple parameter configurations simultaneously and the lack of support to quickly identify sub-optimal configurations are the principal causes.\nIn this paper, we develop two database-inspired techniques for efficient model calibration. Speculative parameter testing applies advanced parallel multi-query processing methods to evaluate several configurations concurrently. Online aggregation is applied to identify sub-optimal configurations early in the processing by incrementally sampling the training dataset and estimating the objective function corresponding to each configuration. We design concurrent online aggregation estimators and define halting conditions to accurately and timely stop the execution.\nWe apply the proposed techniques to distributed gradient descent optimization -- batch and incremental -- for support vector machines and logistic regression models. We implement the resulting solutions in GLADE PF-OLA -- a state-of-the-art Big Data analytics system -- and evaluate their performance over terascalesize synthetic and real datasets. The results confirm that as many as 32 configurations can be evaluated concurrently almost as fast as one, while sub-optimal configurations are detected accurately in as little as a 1/20th fraction of the time.", "references": ["A. Agarwal et al. A Reliable Effective Terascale Linear Learning System. JMLR, 15(1), 2014.", "A. Dobra et al. Turbo-Charging Estimate Convergence in DBO. PVLDB, 2009.", "A. Ghoting et al. SystemML: Declarative Machine Learning on MapReduce. In ICDE 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2799562.2799563"}, {"title": "IOrchestra: supporting high-performance data-intensive applications in the cloud via collaborative virtualization", "authors": ["Ron C. Chiang\n,", "H. Howie Huang\n,", "Timothy Wood\n,", "Changbin Liu\n,", "Oliver Spatscheck"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nMulti-tier data-intensive applications are widely deployed in virtualized data centers for high scalability and reliability. As the response time is vital for user satisfaction, this requires achieving good performance at each tier of the applications in order to minimize the overall latency. However, in such virtualized environments, each tier (e.g., application, database, web) is likely to be hosted by different virtual machines (VMs) on multiple physical servers, where a guest VM is unaware of changes outside its domain, and the hypervisor also does not know the configuration and runtime status of a guest VM. As a result, isolated virtualization domains lend themselves to performance unpredictability and variance. In this paper, we propose IOrchestra, a holistic collaborative virtualization framework, which bridges the semantic gaps of I/O stacks and system information across multiple VMs, improves virtual I/O performance through collaboration from guest domains, and increases resource utilization in data centers. We present several case studies to demonstrate that IOrchestra is able to address numerous drawbacks of the current practice and improve the I/O latency of various distributed cloud applications by up to 31%.", "references": ["I. Ahmad, A. Gulati, and A. Mashtizadeh. vIC: Interrupt Coalescing for Virtual Machine Storage Device IO. In USENIX Annual Technical Conference, 2011.", "M. Alizadeh, A. Kabbani, T. Edsall, B. Prabhakar, A. Vahdat, and M. Yasuda. Less is More: Trading a Little Bandwidth for Ultra-low Latency in the Data Center. In USENIX Symposium on Networked Systems Design and Implementation (NSDI 12), 2012.", "S. F. Altschul, W. Gish, W. Miller, E. W. Myers, and D. J. Lipman. Basic Local Alignment Search Tool. Journal of molecular biology, 215(3):403--410, Oct. 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807633"}, {"title": "Unconscious Physiological Effects of Search Latency on Users and Their Click Behaviour", "authors": ["Miguel Barreda-Ángeles\n,", "Ioannis Arapakis\n,", "Xiao Bai\n,", "B. Barla Cambazoglu\n,", "Alexandre Pereda-Baños"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUnderstanding the impact of a search system's response latency on its users' searching behaviour has been recently an active research topic in the information retrieval and human-computer interaction areas. Along the same line, this paper focuses on the user impact of search latency and makes the following two contributions. First, through a controlled experiment, we reveal the physiological effects of response latency on users and show that these effects are present even at small increases in response latency. We compare these effects with the information gathered from self-reports and show that they capture the nuanced attentional and emotional reactions to latency much better. Second, we carry out a large-scale analysis using a web search query log obtained from Yahoo to understand the change in the way users engage with a web search engine under varying levels of increasing response latency. In particular, we analyse the change in the click behaviour of users when they are subject to increasing response latency and reveal significant behavioural differences.", "references": ["I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proc. 37th Int'l ACM SIGIR Conf. Research and Development in Information Retrieval, pages 103--112, 2014.", "L. Azzopardi. Modelling interaction with economic models of search. In Proc. 37th Int'l ACM SIGIR Conf. Research and Development in Information Retrieval, pages 3--12, 2014.", "L. Azzopardi, D. Kelly, and K. Brennan. How query cost affects search behavior. In Proc. 36th Int'l ACM SIGIR Conf. Research and Development in Information Retrieval, pages 23--32, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767719"}, {"title": "SafeStreet: empowering women against street harassment using a privacy-aware location based application", "authors": ["Mohammed Eunus Ali\n,", "Shabnam Basera Rishta\n,", "Lazima Ansari\n,", "Tanzima Hashem\n,", "Ahamad Imtiaz Khan"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nSexual harassment of women in public places (e.g., foot-paths, buses, and shopping malls) of major cities in developing countries is a growing concern. These harassments can happen in various forms ranging from commenting, catcalling, and staring to touching and groping, to attacking and raping. Though, the most severe form of harassments such as attacking and raping get some attention from the society, NGOs and law-enforcement agencies, unfortunately, other forms of harassments that are more widespread in public places remain largely un-attended or ignored in our conservative society. However, these harassments are more common and can have various negative psychological impacts on women that include a persistent feeling of insecurity, loss of self-esteem, restricted participation in daily life activities in public places. In this paper, we propose a crowd-powered privacy-aware location based mobile application, SafeStreet, that empowers women in public places against sexual harassments. SafeStreet allows a women to privately capture and share her own experiences in the street. SafeStreet enables a women to find a safe path, i.e., the path to a destination that has less harassment hazard, at any point of time.", "references": ["http://en.prothom-alo.com/bangladesh/news/55656/Cities-are-not-safe-for-women.", "Bangladesh telecommunication regulatory commission. http://www.btrc.gov.bd/search/node/.", "Harass map. http://harassmap.org/en/what-we-do/the-map/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2737870"}, {"title": "Capturing Researcher Expertise through MeSH Classification", "authors": ["Yong-Bin Kang\n,", "Yuan-Fang Li\n,", "Ross L. Coppel"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nFor a large research institution and a broad research discipline such as the life sciences, it is a highly important and very challenging task to capture each researcher's expertise, and to match researchers by expertise to assist in identifying inter-disciplinary collaboration opportunities and in making informed policy decisions. The challenges are multi-dimensional, stemming from the needs to (a) provide thorough coverage of the breadth and depth of the disciplinary areas, (b) develop accurate representation of researcher's expertise, and (c) process large volumes of data efficiently. Medical Subject Headings (MeSH), a comprehensive taxonomy for the life sciences, has been widely used for indexing MEDLINE publications. In this paper, we present a novel framework for capturing and matching research expertise based on knowledge encoded in MeSH. Specifically, (1) we design a novel and effective hybrid MeSH classification algorithm by combining state-of-the-art methods, and (2) using MeSH terms aggregated from a researcher's publications, we design a researcher matching algorithm based on semantic similarity that takes into consideration the structure of the MeSH taxonomy.", "references": ["On optimization of expertise matching with various constraints. Neurocomputing, 76(1):71 -- 83, 2012.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, 2005.", "B. Aljaber, D. Martinez, N. Stokes, and J. Bailey. Improving MeSH classification of biomedical articles using citation contexts. Journal of Biomedical Informatics, 44(5):881--896, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815837"}, {"title": "The World Conversation: Web Page Metadata Generation From Social Sources", "authors": ["Omar Alonso\n,", "Sushma Bannur\n,", "Kartikay Khandelwal\n,", "Shankar Kalyanaraman"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOver the past couple of years, social networks such as Twitter and Facebook have become the primary source for consuming information on the Internet. One of the main differentiators of this content from traditional information sources available on the Web is the fact that these social networks surface individuals' perspectives. When social media users post and share updates with friends and followers, some of those short fragments of text contain a link and a personal comment about the web page, image or video. We are interested in mining the text around those links for a better understanding of what people are saying about the object they are referring to. Capturing the salient keywords from the crowd is rich metadata that we can use to augment a web page. This metadata can be used for many applications like ranking signals, query augmentation, indexing, and for organizing and categorizing content. In this paper, we present a technique called social signatures that given a link to a web page, pulls the most important keywords from the social chatter around it. That is, a high level representation of the web page from a social media perspective. Our findings indicate that the content of social signatures differs compared to those from a web page and therefore provides new insights. This difference is more prominent as the number of link shares increase. To showcase our work, we present the results of processing a dataset that contains around 1 Billion unique URLs shared in Twitter and Facebook over a two month period. We also provide data points that shed some light on the dynamics of content sharing in social media.", "references": ["Omar Alonso and Kartikay Khandelwal. Kondenzer: Exploration and visualization of archived social media. In Proceedings of ICDE, 2014.", "Einat Amitay, Adam Darlow, David Konopnicki, and Uri Weiss. Queries as anchors: selection by association. In Proceedings of Hypertext, pages 193--201, 2005.", "Peter Anick. Exploiting anchor text as a lexical resource. In LREC, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2745397"}, {"title": "An overview of the tourpedia linked dataset with a focus on relations discovery among places", "authors": ["Davide Gazzè\n,", "Angelica Lo Duca\n,", "Andrea Marchetti\n,", "Maurizio Tesconi"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nTourpedia (http://tour-pedia.org) is an open initiative which contains a linked dataset of tourism places, i.e. accommodations, attractions, points of interest (POIs) and restaurants. Tourpedia extracts and integrates information about places from four different social social media: Facebook, Foursquare, Google Places and Booking.com. The resulting knowledge base currently consists of more than 6M RDF triples and describes almost 500.000 places, each of which is identified by a globally unique identifier, which can be dereferenced over the Web into a RDF description. This paper gives an overview of the Tourpedia knowledge base and illustrates how new relations are discovered among places through Named Entity Recognition (NER) tools.", "references": ["C. K. Anderson. The impact of social media on lodging performance. Cornell Hospitality Report, 12(15), 2012.", "C. Bacciu, A. Lo Duca, A. Marchetti, and M. Tesconi. Accommodations in Tuscany as Linked Data. In LREC 2014, pages 3542--3545, May, 26-31 2014.", "T. Berners-Lee. Linked Data - Design Issues, July 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814876"}, {"title": "Automated Recommendation of Healthy, Personalised Meal Plans", "authors": ["Morgan Harvey\n,", "David Elsweiler"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPoor health due to a lack of understanding of nutrition is a major problem in the modern world, one which could potentially be addressed via the use of recommender systems. In this demo we present a system to generate meal plans for users which they will not only like, based on their taste preferences, but will also conform to daily nutritional guidelines. The interface allows the selection of recipes for breakfast, lunch and dinner and can automatically complete a daily meal plan or can generate entire plans itself.", "references": ["D. Ornish et al. Can lifestyle changes reverse coronary heart disease?: The lifestyle heart trial. The Lancet, 336(8708):129 -- 133, 1990.", "J. F. Guthrie, B. M. Derby, and A. S. Levy. America's Eating Habits: Changes and Consequences Agriculture Information Bulletin No. (AIB750), pages 243--280. US Dept. for Agriculture, 1999.", "M. Harvey, B. Ludwig, and D. Elsweiler. You are what you eat: Learning user tastes for rating prediction. In SPIRE, pages 153--164, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796551"}, {"title": "SimSearch: similarity search framework based on indexing techniques in metric spaces", "authors": ["David Zaragoza\n,", "Yudith Cardinale\n,", "Marta Rukoz"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nSimilarity search in metric spaces refers to searching elements in data repositories that are similar to an element supplied by the user (query example). Similarity functions are used to determine which elements in the data repositories are similar to the query example and indexing mechanisms are used to improve the efficiency in the search. Classic indexation mechanisms such as LSH, M-Index, and M-Tree behave different according to the dimensionality in the metric space, volume of data repositories, and query strategies. In this paper, we describe SimSearch, a modular and flexible framework for similarity search in metric spaces, which allows to use, analyse, compare, and add several indexation mechanisms, search approaches, and query strategies. SimSearch allows doing queries given one or more example elements to obtain the set of elements more similar to the query examples, using query composition and Skyline. We show the variability of performance of several indexation mechanisms, including LSH-ML (our proposed variant of LSH), with experimental study in the domain of images represented by a feature vector in a high dimensionality metric space and Web Services represented by a vector with the values of Quality of Service (QoS) parameters.", "references": ["C. Akgül, D. Rubin, S. Napel, C. Beaulieu, H. Greenspan, and B. Acar. Content-based image retrieval in radiology: Current status and future directions. J. of Digital Imaging, 24(2):208--222, 2011.", "E. Al-Masri and Q. H. Mahmoud. Qos-based discovery and ranking of web services. In Proc. of the 16th Internat. Conf. on Computer Communications and Networks (ICCCN), pages 529--534. IEEE, 2007.", "A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857233"}, {"title": "Cost-Aware Result Caching for Meta-Search Engines", "authors": ["Emre Bakkal\n,", "Ismail Sengor Altingovde\n,", "Ismail Hakki Toroslu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOur goal in this paper is to design cost-aware result caching approaches for meta-search engines. We introduce different levels of eviction, namely, query-, resource- and entry-level, based on the granularity of the entries to be evicted from the cache when it is full. We also propose a novel entry-level caching approach that is tailored for the meta-search scenario and superior to alternative approaches.", "references": ["M. Arlitt, L. Cherkasova, J. Dilley, R. Friedrich, and T. Jin. Evaluating content management techniques for web proxy caches. SIGMETRICS Performance Evaluation Review, 27(4):3--11, Mar. 2000.", "R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. The impact of caching on search engines. In SIGIR 2007, pages 183--190, 2007.", "P. Cao and S. Irani. Cost-aware www proxy caching algorithms. In USITS 1997, pages 18--18, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767813"}, {"title": "Improving Researcher Homepage Classification with Unlabeled Data", "authors": ["Sujatha Das Gollapalli\n,", "Cornelia Caragea\n,", "Prasenjit Mitra\n,", "C. Lee Giles"], "publication": "ACM Transactions on the Web", "abstract": "Abstract\nA classifier that determines if a webpage is relevant to a specified set of topics comprises a key component for focused crawling. Can a classifier that is tuned to perform well on training datasets continue to filter out irrelevant pages in the face of changing content on the Web? We investigate this question in the context of identifying researcher homepages. We show experimentally that classifiers trained on existing datasets of academic homepages underperform on “non-homepages” present on current-day academic websites. As an alternative to obtaining labeled datasets to retrain classifiers for the new content, in this article we ask the following question: “How can we effectively use the unlabeled data readily available from academic websites to improve researcher homepage classification?”\nWe design novel URL-based features and use them in conjunction with content-based features for representing homepages. Within the co-training framework, these sets of features can be treated as complementary views enabling us to effectively use unlabeled data and obtain remarkable improvements in homepage identification on the current-day academic websites. We also propose a novel technique for “learning a conforming pair of classifiers” that mimics co-training. Our algorithm seeks to minimize a loss (objective) function quantifying the difference in predictions from the two views afforded by co-training. We argue that this loss formulation provides insights for understanding co-training and can be used even in the absence of a validation dataset.\nOur next set of findings pertains to the evaluation of other state-of-the-art techniques for classifying homepages. First, we apply feature selection (FS) and feature hashing (FH) techniques independently and in conjunction with co-training to academic homepages. FS is a well-known technique for removing redundant and unnecessary features from the data representation, whereas FH is a technique that uses hash functions for efficient encoding of features. We show that FS can be effectively combined with co-training to obtain further improvements in identifying homepages. However, using hashed feature representations, a performance degradation is observed possibly due to feature collisions.\nFinally, we evaluate other semisupervised algorithms for homepage classification. We show that although several algorithms are effective in using information from the unlabeled instances, co-training that explicitly harnesses the feature split in the underlying instances outperforms approaches that combine content and URL features into a single view.", "references": ["Maria F. Balcan, Avrim Blum, and Ke Yang. 2005. Co-training and expansion: Towards bridging theory and practice. In Proceedings of Neural Information Processing Systems (NIPS’05).", "Krisztian Balog, Toine Bogers, Leif Azzopardi, M. de Rijke, and Antal van den Bosch. 2007. Broad expertise retrieval in sparse data environments. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’07). 551--558.", "Ziv Bar-Yossef, Idit Keidar, and Uri Schonfeld. 2009. Do not crawl in the DUST: Different URLs with similar text. ACM Transactions on the Web 3, 1, 3:1--3:31."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767135"}, {"title": "Open data for competitive advantage: insights from open data use by companies", "authors": ["Anneke Zuiderwijk\n,", "Marijn Janssen\n,", "Kostas Poulis\n,", "Geerten van de Kaa"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nPoliticians have high expectations for commercial open data use. Yet, companies appear to challenge the assumption that open data can be used to create competitive advantage, since any company can access open data and since open data use requires scarce resources. In this paper we examine commercial open data use for creating competitive advantage from the perspective of Resource Based Theory (RBT) and Resource Dependency Theory (RDT). Based on insights from a scenario, interviews and a survey and from RBT and RDT as a reference theory, we derive seven propositions. Our study suggests that the generation of competitive advantage with open data requires a company to have in-house capabilities and resources for open data use. The actual creation of competitive advantage might not be simple. The propositions also draw attention to the accomplishment of unique benefits for a company through the combination of internal and external resources. Recommendations for further research include testing the propositions.", "references": ["G. Magalhaes, C. Roseira, and L. Manley, \"Business Models for Open Government Data,\" presented at the International Conference on Theory and Practice of Electronic Governance, Guimarães, Portugal, 2014.", "L. A. Streeter, R. E. Kraut, H. C. Lucas, and L. Caby, \"How open data networks influence business performance and market structure,\" Communications of the ACM, vol. 39, pp. 62--73, 1996.", "K. Janssen, \"The Influence of the PSI Directive on Open Government Data: An Overview of Recent Developments,\" Government Information Quarterly, vol. 28, pp. 446--456, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757411"}, {"title": "Tweeting live shows: a content analysis of live-tweets from three entertainment programs", "authors": ["Qihao Ji\n,", "Danyang Zhao"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nIn this paper, we explored whether (and if so, how) live-tweets vary across different entertainment television programs in terms of the tweets' content. Using the 2013 Oscars, the Season 3 finale of Downton Abbey, and the 2014 Super Bowl as case studies, we collected over 200,000 live tweets sent during these three live entertainment programs and performed a content analysis of 4,400 of them. Results indicated that live-tweets, in general, reflect the features of the entertainment programs in many ways, suggesting that practitioners should incorporate more tailored social media strategies to better engage audiences. Theoretical implications and limitations were discussed in detail.", "references": ["Abbruzzese, J. 2014. Facebook is watching how you watch TV (Feburary 2014). Retrieved April 12, 2015 from: http://mashable.com/2014/02/10/facebooks-tv-data/?utm_campaign=Feed%3A+Mashable+%28Mashable%29&utm_cid=Mash-Prod-RSS-Feedburner-All-Partial&utm_medium=feed&utm_source=feedburner", "Adashed, A. 2014. Nielsen reveals the TV season's top shows on Twitter. (June 2014). Retrieved August 20, 2014 from: https://blog.twitter.com/2014/nielsen-reveals-the-tv-seasons-top-shows-on-twitter", "Bibel, S. 2014. 'Pretty Little Liars' is the Most Tweeted TV Series of 2013. (January 2014). Retrieved September 10, 2014 from: http://tvbythenumbers.zap2it.com/2014/01/09/pretty-little-liars-is-the-most-tweeted-tv-series-of-2013/228058/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789195"}, {"title": "EmergencyFire: An Ontology for Fire Emergency Situations", "authors": ["Kattiuscia Bitencourt\n,", "Frederico Durão\n,", "Manoel Mendonça"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe emergency response process is quite complex since there is a wide variety of elements to be evaluated for taking decisions. Uncertainties generated by subjectivity and imprecision affect the safety and effectiveness of actions. The aim of this paper is to develop an ontology for emergency response protocols, in particular, to fires in buildings. This developed ontology supports the knowledge sharing, evaluation and review of the protocols used, contributing to the tactical and strategic planning of organizations. The construction of the ontology was based on the methodology Methontology. The domain specification and conceptualization were based in qualitative research, in which were extracted 131 terms with definitions, of which 85 were assessed by specialists. From there, in the Protégé tool, the domain's taxonomy and the axioms were created. The specialists validated the ontology using the assessment by human approach (taxonomy, application and structure). Thus, a sustainable ontology model to the rescue tactical phase was ensured.", "references": ["DiRes Ontology. http://www.disaster20.eu/dires; accessed 23 May 2014.", "EMERGEL Ontology. http://vocab.ctic.es/emergel; accessed 20 May 2014.", "FEMA. http://www.fema.gov; accessed 19 June 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820453"}, {"title": "Timbre identification of instrumental music via energy distribution modeling", "authors": ["Jinxi Guo\n,", "Mengying Ding\n,", "Xiaohong Guan\n,", "Youtian Du\n,", "Jicheng Feng\n,", "Qinping Gao\n,", "Zheng Liu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThe traditional evaluation of instrumental music is generally based on experts. However, the expert-based evaluation strategy is seriously affected by a number of factors such as human's subjectivity and then decreases the evaluation reliability. This paper aims at automatically identifying the timbre of saxophone music, and proposes a new method based on the energy distribution in frequency domain of music signals. First, we transform music signals into frequency domain using short-time Fourier transformation (STFT). Then, we compute the spectral envelope, which may describe the rule of frequency attitude, based on linear predictive coding (LPC). At last, we find that the energy distribution can be approximated by an exponential function, and present a ONE-dimensional feature named average linearity value (ALV). The ALV feature measures the extent of closeness between the energy distribution and exponential functions and is used to distinguish high-level timbres from low-level timbres in our work. The experiment is conducted on 9 groups of data, and the experimental results demonstrate the effectiveness of this method.", "references": ["Y. H. Hsiao and C. T. Su. Multiclass mts for saxophone timbre quality inspection using waveform-shape-based features. IEEE Transactions on Systems, Man, and Cybernetics Part B: Cybernetics, 39(3):690--704, 2009.", "X. Cao, H. Meng, and J. Xu. Timbre model of software musical instrument based on sine interpolation. In Image Analysis and Signal Processing, pages 358--361. IEEE, April 2009.", "J. D. Deng, C. Simmermacher, and S. Cranefield. A study of feature analysis for musical instrument classification. IEEE Transactions on Systems, Man, and Cybernetics Part B: Cybernetics, 38(2):429--438, April 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808559"}, {"title": "Patent Mining: A Survey", "authors": ["Longhui Zhang\n,", "Lei Li\n,", "Tao Li"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nPatent documents are important intellectual resources of protecting interests of individuals, organizations and companies. Different from general web documents, patent documents have a well-defined format including frontpage, description, nclaims, and figures. However, they are lengthy and rich in technical terms, which requires enormous human efforts for analysis. Hence, a new research area, called patent mining, emerges in recent years, aiming to assist patent analysts in investigating, processing, and analyzing patent documents. Despite the recent advances in patent mining, it is still far from being well explored in research communities. To help patent analysts and interested readers obtain a big picture of patent mining, we thus provide a systematic summary of existing research efforts along this direction. In this survey, we first present an overview of the technical trend in patent mining. We then investigate multiple research questions related to patent documents, including patent retrieval, patent classification, and patent visualization, and provide summaries and highlights for each question by delving into the corresponding research efforts.", "references": ["S. Adams. Comparing the ipc and the us classification systems for the patent searcher. World Patent Information, 23(1):15--23, 2001.", "B. Al-Shboul and S. Myaeng. Query phrase expansion using wikipedia in patent class search. Information Retrieval Technology, pages 115--126, 2011.", "M. Albert, D. Avery, F. Narin, and P. McAllister. Direct validation of citation counts as indicators of industrially important patents. Research Policy, 20(3):251--259, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783702.2783704"}, {"title": "SearchPlus: a new search results clustering approach", "authors": ["Erfan Najmi\n,", "Khayyam Hashmi\n,", "Zaki Malik\n,", "Mohammed Alodib"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nSearch engines are the fastest way to find and retrieve information on the web. Their usefulness is evident from the fact that three of the most visited web sites on internet are search engines. With advanced algorithms and the ability to go over millions of records in mere milliseconds, the most time consuming part of searching for the required information is not the search itself but the time it takes to sort through the searched results. Specially when the search query is vague, too broad or simply ill defined. This leads the user to a situation where the search results becomes unmanageably large and confusing. In this paper we present a novel search result clustering technique that relies on the information returned by the search query to extract keywords and to cluster the search results. Unlike most of the search result clustering techniques our proposed solution does not rely on any external knowledge bases, predefined categories or any peripheral knowledge. Thus our technique could be applied on any search domain. We developed a prototype to conduct experiments. Our preliminary results show the applicability and effectiveness of our approach.", "references": ["Jordi Castellà-Roca, Alexandre Viejo, and Jordi Herrera-Joancomartí. Preserving userâĂ&Zacute;s privacy in web search engines. Computer Communications, 32(13):1541--1551, 2009.", "Yi-heng Chen, Bing Qin, Fan Song, Ting Liu, and Sheng Li. Search result clustering based on centroid optimization by ontology extraction. Acta Electronica Sinica, page S1, 2008.", "Douglass R. Cutting, David R. Karger, Jan O. Pedersen, and John W. Tukey. Scatter/gather: A cluster-based approach to browsing large document collections. In Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval, pages 318--329. ACM, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857236"}, {"title": "Privacy-Preserving IR 2015: When Information Retrieval Meets Privacy and Security", "authors": ["Hui Yang\n,", "Ian Soboroff"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation retrieval (IR) and information privacy/security are two fast-growing computer science disciplines. There are many synergies and connections between these two disciplines. However, there have been very limited efforts to connect the two important disciplines. On the other hand, due to lack of mature techniques in privacy-preserving IR, concerns about information privacy and security have become serious obstacles that prevent valuable user data to be used in IR research such as studies on query logs, social media, tweets, and medical record retrieval. We propose this privacy-preserving IR workshop to connect the two disciplines of information retrieval and information privacy and security. We look forward to spurring research that aims to bring together the research fields of IR and privacy/security. Last year, the first privacy-preserving IR workshop focused on mitigating privacy threats in information retrieval by novel algorithms and tools that enable web users to better understand associated privacy risks.", "references": ["W. Jiang, L. Si, and J. Li. Protecting source privacy in federated search. In W. Kraaij, A. P. de Vries, C. L. A. Clarke, N. Fuhr, and N. Kando, editors, SIGIR, pages 761--762. ACM, 2007.", "A. Khoshgozaran and C. Shahabi. Privacy in location-based applications. chapter Private Information Retrieval Techniques for Enabling Location Privacy in Location-Based Services, pages 59--83. Springer-Verlag, Berlin, Heidelberg, 2009.", "L. Si and H. Yang. Pir 2014 the first international workshop on privacy-preserving ir: When information retrieval meets privacy and security. SIGIR Forum, 48(2):83--88, Dec. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767857"}, {"title": "Evaluation of the use of creation platform of electronic medical records SANA platform for basic health experts", "authors": ["Tais Bedendo do Valle\n,", "Darlinton Barbosa Feres Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nAlthough digital computerization is already quite common, the use of health information systems is still very poor in most of the places. From a regional demand for support of health professionals working in basic health units (BHU) in the city of Sao Joao del Rei/MG, a research was conceived for development of an information system for sharing electronic health records among various BHU. In this article we present a review of the use of SANA, a standard-focused open-source platform to facilitate the creation and sharing electronic health records, for the development of an information system. For this, we developed and evaluated a prototype representing electronic records as requested by health experts. Finally, lessons learned are presented as well as solutions to problems encountered during development, including a reflection on the utility and convenience of the prototype generated by SANA platform considering the application context, and recommendations for future development.", "references": ["Alves, P.H. C. e Lucena, C. J. P. (2013). Extensão sana mobile - engenharia de software em telessáude. III Workshop do Projeto Telemedicina, Laboratório de Engenharia de Software, PUC-Rio. Disponível em: http://www.les.inf.puc-rio.br/wiki/images/1/11/Txt04PauloHenriqueSana_Mobile_EngdeSoftwareemTelessa%C3%83%C2%BAde_V5.pdf Acessado em 6 Jan. 2015.", "Apache Tomcat. Disponível em: http://tomcat.apache.org/. Acessado em 7 Jan. 2015.", "Cirilo, E., Nunes, I., Carvalho, D., Carvalho, G., Veiga, A., and Lucena, C. (2012). Engenharia de software em Telessaúde: aplicações e desafios. In: Ivan Mathias, Alexandra Monteiro. (Org.). Gold book [recurso eletrônico] : inovação tecnológica em educação e saúde. 1ed. Rio de Janeiro: EdUERJ, 2012, v. 1, p. 371-404."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814128"}, {"title": "Characterizing and Predicting Voice Query Reformulation", "authors": ["Ahmed Hassan Awadallah\n,", "Ranjitha Gurunath Kulkarni\n,", "Umut Ozertem\n,", "Rosie Jones"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nVoice interactions are becoming more prevalent as the usage of voice search and intelligent assistants gains more popularity. Users frequently reformulate their requests in hope of getting better results either because the system was unable to recognize what they said or because it was able to recognize it but was unable to return the desired response. Query reformulation has been extensively studied in the context of text input. Many of the characteristics studied in the context of text query reformulation are potentially useful for voice query reformulation. However, voice query reformulation has its unique characteristics in terms of the reasons that lead users to reformulating their queries and how they reformulate them. In this paper, we study the problem of voice query reformulation. We perform a large scale human annotation study to collect thousands of labeled instances of voice reformulation and non-reformulation query pairs. We use this data to compare and contrast characteristics of reformulation and non-reformulation queries over a large a number of dimensions. We then train classifiers to distinguish between reformulation and non-reformulation query pairs and to predict the rationale behind reformulation. We demonstrate through experiments with the human labeled data that our classifiers achieve good performance in both tasks.", "references": ["Ageev., M., Guo, Q., Lagun, D., and Agichtein, E. (2011). Find it if you can: a game for modeling different types of web search success using interaction data. In Proc. SIGIR, 345--354.", "Anick, P. (2003). Using terminological feedback for web search refinement:a log-based study. In Proc. SIGIR, 88--95.", "Arlitt, M. (2000). Characterizing Web user sessions. ACM SIGMETRICS Performance Eval Review, 28(2), 50--63."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806491"}, {"title": "TriAL-QL: Distributed Processing of Navigational Queries", "authors": ["Martin Przyjaciel-Zablocki\n,", "Alexander Schätzle\n,", "Georg Lausen"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nNavigational queries are among the most natural query patterns for RDF data, but yet most existing RDF query languages fail to cover all the varieties inherent to its triple-based model, including SPARQL 1.1 and its derivatives. As a consequence, the development of more expressive RDF languages is of general interest. With TriAL* [14], there exists an expressive algebra which subsumes many previous approaches, while adding novel features that are not expressible in most other RDF query languages based on the standard graph model. However, its algebraic notation is inappropriate for practical usage and it is not supported by any existing RDF triple store. In this paper, we propose TriAL-QL, an easy to write and grasp language for TriAL*, preserving its compositional algebraic structure. We present an implementation based on Impala, a massive parallel SQL query engine on Hadoop, using an optimized semi-naive evaluation for the recursive fragments of TriAL*. This way, we support both data-intensive ETL-like workloads and explorative ad-hoc style queries. To demonstrate the scalability and expressiveness of our approach, we conducted experiments on generated social networks with up to 1.8 billion triples and compared different execution strategies to a Hive-based solution.", "references": ["D. J. Abadi, A. Marcus, S. R. Madden, and K. Hollenbach. Scalable Semantic Web Data Management Using Vertical Partitioning. In VLDB, pages 411--422, 2007.", "F. N. Afrati, V. R. Borkar, M. J. Carey, N. Polyzotis, and J. D. Ullman. Map-reduce extensions and recursive queries. In EDBT 2011, Sweden, March 21-24, 2011.", "F. N. Afrati and J. D. Ullman. Transitive closure and recursive datalog implemented on clusters. In EDBT'12, Berlin, Germany, March 27-30, 2012, pages 132--143, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767115"}, {"title": "A new Feature Selection method for face recognition based on general data field", "authors": ["Long Zhao\n,", "Shuliang Wang\n,", "Yi Lin"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nFeature selection is an important step when building a classifier for face recognition. It is difficult to classify the high dimensional and small sample data sets such as face data sets pose. Because the high dimensions increase the risk of over fitting and the small samples decrease the accuracy. A new feature selection method for face recognition based on general data field is proposed in this paper. This method adopts the Sw (potential value within class) and Sb (potential value between different classes) to calculate the information entropy of each feature. The representative features have been selected to structure classifier. Well known feature selection techniques for face data sets are implemented and compared with our present method to show its effectiveness. The experiments show that our algorithm effectively reduces the dimensionality of face data sets and keeps the classifier performance.", "references": ["Huawen Liu, Jigui Sun, Lei Liu, and Huijie Zhang. 2009. Feature selection with dynamic mutual information. Pattern Recogn. 42, 7 (July 2009), 1330--1339. DOI=10.1016/j.patcog.2008.10.028 http://dx.doi.org/10.1016/j.patcog.2008.10.028.", "Mike Wasikowski and Xue-wen Chen. 2010. Combating the Small Sample Class Imbalance Problem Using Feature Selection. IEEE Trans. on Knowl. and Data Eng. 22, 10 (October 2010), 1388--1400. DOI=10.1109/TKDE.2009.187 http://dx.doi.org/10.1109/TKDE.2009.187", "Isabelle Guyon and André Elisseeff. 2003. An introduction to variable and feature selection. J. Mach. Learn. Res. 3 (March 2003), 1157--1182."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818896"}, {"title": "Interactive Tango Milonga: designing internal experience", "authors": ["Courtney Brown\n,", "Garth Paine"], "publication": "MOCO '15: Proceedings of the 2nd International Workshop on Movement and Computing", "abstract": "ABSTRACT\nThe Argentine tango concept of connection refers to the experience of complete synchronicity between self, partner, and music. This paper presents Interactive Tango Milonga, an interactive system giving tango dancers agency over music in order to increase this sense of relation between both partners and music. Like an improvising musician in an ensemble, each dancer receives musical feedback from both her movements and her partner's. Thus, each dancer can respond to the music, driving musical feedback, thereby heightening awareness and agency in both the sound and her partner's movements. Via presentation of this system, this paper illustrates methods for developing interactive systems engaging with distinct musical, movement, and social traditions as well for composing sound-movement relationships leading to specific internal experiences within these social contexts.", "references": ["Olszewski, B. El cuerpo del baile: The kinetic and social fundaments of tango. Body & society 14, 2 (2008), 63--81.", "Cara, A. Entangled tangos: Passionate displays, intimate dialogues, Journal of American folklore 122, 486, (2009), 438--465.", "Castro, D. Argentine tango as social history 1880--1955. Mellen Research University Press, San Francisco, CA, USA, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790994.2791013"}, {"title": "Indoor3D: a WebGL based open source framework for 3D indoor maps visualization", "authors": ["Meng Gai\n,", "Guoping Wang"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nIn this paper, we present Indoor3D, an open source framework for 3D indoor maps visualization. It takes advantage of the WebGL technique of modern browsers, so it can work on any platform which supports the WebGL feature, including desktop computers and mobile devices. An extensible data structure is designed to describe the indoor scene. The proper default view is generated automatically according to the principal direction. A priority based algorithm is employed to control the visibility of the texts and icons. This library is well designed and easy to use. Developers can create an indoor map and customize its behaviour with only a few codes. Designers also benefit from this framework since they can change its visual style by providing a new theme. We believe our Indoor3D will be useful in many cases, such as airports, subway stations and shopping malls.", "references": ["Bostock, M., Ogievetsky, V., and Heer, J. 2011. D3 data-driven documents. Visualization and Computer Graphics, IEEE Transactions on 17, 12, 2301--2309.", "Cabello, R. 2010. Three. js. URL: https://github.com/mrdoob/three.js.", "Contributors, P., 2009--2014. poly2tri.js. http://code.google.com/p/poly2tri/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2775310"}, {"title": "Castle game engine: game engine using X3D as a scene graph", "authors": ["Michalis Kamburelis"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nCastle Game Engine (http://castle-engine.sourceforge.net/) is a modern, open-source game engine closely connected with the X3D standard. It uses X3D as a scene graph, and also as it's main 3D and 2D interchange format. In this poster we would like to highlight some engine architectural advantages.", "references": ["Kamburelis, M. 2010. Shadow maps and projective texturing in X3D. In Proceedings of the 15th International Conference on Web 3D Technology, ACM, New York, NY, USA, Web3D '10, 17--26.", "Kamburelis, M. 2011. Compositing Shaders in X3D. In Theory and Practice of Computer Graphics, The Eurographics Association, I. Grimstead and H. Carr, Eds."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2778296"}, {"title": "Early Detection of Spam Mobile Apps", "authors": ["Suranga Seneviratne\n,", "Aruna Seneviratne\n,", "Mohamed Ali Kaafar\n,", "Anirban Mahanti\n,", "Prasant Mohapatra"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIncreased popularity of smartphones has attracted a large number of developers to various smartphone platforms. As a result, app markets are also populated with spam apps, which reduce the users' quality of experience and increase the workload of app market operators. Apps can be \"spammy\" in multiple ways including not having a specific functionality, unrelated app description or unrelated keywords and publishing similar apps several times and across diverse categories. Market operators maintain anti-spam policies and apps are removed through continuous human intervention. Through a systematic crawl of a popular app market and by identifying a set of removed apps, we propose a method to detect spam apps solely using app metadata available at the time of publication. We first propose a methodology to manually label a sample of removed apps, according to a set of checkpoint heuristics that reveal the reasons behind removal. This analysis suggests that approximately 35% of the apps being removed are very likely to be spam apps. We then map the identified heuristics to several quantifiable features and show how distinguishing these features are for spam apps. Finally, we build an Adaptive Boost classifier for early identification of spam apps using only the metadata of the apps. Our classifier achieves an accuracy over 95% with precision varying between 85%-95% and recall varying between 38%-98%. By applying the classifier on a set of apps present at the app market during our crawl, we estimate that at least 2.7% of them are spam apps.", "references": ["Language Detection API. http://detectlanguage.com, 2013.", "PrivMetrics. http://privmetrics.org/publications, 2014.", "I. Androutsopoulos, G. Paliouras, V. Karkaletsis, G. Sakkis, C. D. Spyropoulos, and P. Stamatopoulos. Learning to filter spam e-mail: A comparison of a naive bayesian and a memory-based approach. arXiv preprint cs/0009009, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741084"}, {"title": "A Fuzzy Similarity Matching Model for Interior Design Drawing Recommendation", "authors": ["Kuo-Sui Lin\n,", "Chih-Chung Chiu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn our previous study, we proposed a recommender system for interior design drawing retrieval. The yes-no binary measurement scale is used in that paper for binary bit string cosine similarity matching. In further practical application, we found that the design features could be interval, nominal, ordinal or ratio scales. However, current cosine similarity measure scarcely deals with mixed interval, nominal, ordinal and ratio scales. The cosine similarity measure function fails to measure mixed qualitative and quantitative scales simultaneously. Therefore, in this study a new fuzzy similarity matching model for mixed measurement scales is proposed and applied to the recommender system. Finally, a numerical case study is carried out to demonstrate the effectiveness and capabilities of the proposed similarity matching model for handling interior design drawing recommendation problems.", "references": ["Ricci, F., Rokach, L.and Shapira, B. 2011. Introduction to Recommender Systems Handbook, Recommender Systems Handbook, Springer, 1--35.", "Lin, K. S. and Ke, M. C. 2015. A Virtual Reality Based Recommender System for Interior Design Prototype Drawing Retrieval. In New Trends in Intelligent Information and Database Systems, Studies in Computational Intelligence, Dariusz Barbucha, Ngoc Thanh Nguyen John Batubara, Ed. Springer International Publishing, Vol. 598, 141--150.", "Larsen, B. and Aone C. 1999. Fast and Effective Text Mining Using Linear-Time Document Clustering. In Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 16--22, San Diego, California."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818924"}, {"title": "A Weighted Correlation Index for Rankings with Ties", "authors": ["Sebastiano Vigna"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nUnderstanding the correlation between two different scores for the same set of items is a common problem in graph analysis and information retrieval. The most commonly used statistics that quantifies this correlation is Kendall's tau; however, the standard definition fails to capture that discordances between items with high rank are more important than those between items with low rank. Recently, a new measure of correlation based on average precision has been proposed to solve this problem, but like many alternative proposals in the literature it assumes that there are no ties in the scores. This is a major deficiency in a number of contexts, and in particular when comparing centrality scores on large graphs, as the obvious baseline, indegree, has a very large number of ties in social networks and web graphs. We propose to extend Kendall's definition in a natural way to take into account weights in the presence of ties. We prove a number of interesting mathematical properties of our generalization and describe an O(n\\log n) algorithm for its computation. We also validate the usefulness of our weighted measure of correlation using experimental data on social networks and web graphs.", "references": ["Alex Bavelas. Communication patterns in task-oriented groups. J. Acoust. Soc. Am., 22(6):725--730, 1950.", "Paolo Boldi and Sebastiano Vigna. Axioms for centrality. Internet Math., 10(3--4):222--262, 2014.", "Nick Craswell, David Hawking, and Trystan Upstill. Predicting fame and fortune: PageRank or indegree? In In Proceedings of the Australasian Document Computing Symposium, ADCS2003, pages 31--40, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741088"}, {"title": "Promoting User Engagement and Learning in Amorphous Search Tasks", "authors": ["Piyush Arora"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMuch research in information retrieval (IR) focuses on optimization of the rank of relevant retrieval results for single shot ad hoc IR tasks. Relatively little research has been carried out on user engagement to support more complex search tasks. We seek to improve user engagement for IR tasks by providing richer representation of retrieved information. It is our expectation that this strategy will promote implicit learning within search activities. Specifically, we plan to explore methods of finding semantic concepts within retrieved documents, with the objective of creating improved document surrogates. Further, we would like to study search effectiveness in terms of different facets such as the user's search experience, satisfaction, engagement and learning. We intend to investigate this in an experimental study, where our richer document representations are compared with the traditional document surrogates for the same user queries.", "references": ["L. Freund, H. O'Brien, and R. Kopak. Getting the big picture: supporting comprehension and learning in search. 2014.", "J. Jiang, D. He, and J. Allan. Searching, browsing, and clicking in a search session: changes in user behavior by task and over time. In Proc. of SIGIR, pages 607--616, 2014.", "Y. Li and N. J. Belkin. A faceted approach to conceptualizing tasks in information seeking. Information Processing & Management, 44(6):1822--1837, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767848"}, {"title": "Diversity Analysis of Web Search Results", "authors": ["Suneel Kumar Kingrani\n,", "Mark Levene\n,", "Dell Zhang"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nAre web search results usually dominated by major websites and therefore lacking diversity? In this paper, we aim to answer this question by quantitatively modelling the diversity of search results for popular queries using two diversity measures well-studied in ecology, namely Simpson's diversity index and Shannon's diversity index. Our theoretical analysis shows how the diversity of search results is determined by the Zipfian distribution of websites. Our empirical analysis reveals that comparing Google and Bing, the former is more diverse in the top-50 search results, while the latter is more diverse in the top-10 search results.", "references": ["C. Anderson. The Long Tail: Why the Future of Business is Selling Less of More. Hyperion Books, 2006.", "A. E. Magurran. Ecological Diversity and Its Measurement. Princeton University Press, 1988.", "S. E. Page. Diversity and Complexity. Princeton University Press, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786502"}, {"title": "Deep Compositional Cross-modal Learning to Rank via Local-Global Alignment", "authors": ["Xinyang Jiang\n,", "Fei Wu\n,", "Xi Li\n,", "Zhou Zhao\n,", "Weiming Lu\n,", "Siliang Tang\n,", "Yueting Zhuang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nCross-modal retrieval is a very hot research topic that is imperative to many applications involving multi-modal data. Discovering an appropriate representation for multi-modal data and learning a ranking function are essential to boost the cross-media retrieval. Motivated by the assumption that a compositional cross-modal semantic representation (pairs of images and text) is more attractive for cross-modal ranking, this paper exploits the existing image-text databases to optimize a ranking function for cross-modal retrieval, called deep compositional cross-modal learning to rank (C2MLR). In this paper, C2MLR considers learning a multi-modal embedding from the perspective of optimizing a pairwise ranking problem while enhancing both local alignment and global alignment. In particular, the local alignment (i.e., the alignment of visual objects and textual words) and the global alignment (i.e., the image-level and sentence-level alignment) are collaboratively utilized to learn the multi-modal embedding common space in a max-margin learning to rank manner. The experiments demonstrate the superiority of our proposed C2MLR due to its nature of multi-modal compositional embedding.", "references": ["B. Bai, J. Weston, D. Grangier, R. Collobert, K. Sadamasa, Y. Qi, O. Chapelle, and K. Weinberger. Learning to rank with (a lot of) word features. Inf. Retr., 13(3):291--314, June 2010.", "D. M. Blei and M. I. Jordan. Modeling annotated data. In Proceedings of Internetional ACM SIGIR Conference on Research and Development in Informaion Retrieval, pages 127--134, 2003.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N Hamilton, and G. Hullender. Learning to rank using gradient descent. In ICML, pages 89--96, New York, NY, USA, 2005. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806240"}, {"title": "Topical Word Importance for Fast Keyphrase Extraction", "authors": ["Lucas Sterckx\n,", "Thomas Demeester\n,", "Johannes Deleu\n,", "Chris Develder"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe propose an improvement on a state-of-the-art keyphrase extraction algorithm, Topical PageRank (TPR), incorporating topical information from topic models. While the original algorithm requires a random walk for each topic in the topic model being used, ours is independent of the topic model, computing but a single PageRank for each text regardless of the amount of topics in the model. This increases the speed drastically and enables it for use on large collections of text using vast topic models, while not altering performance of the original algorithm.", "references": ["E. D'Avanzo, B. Magnini, and A. Vallin. Keyphrase extraction for summarization purposes: The LAKE system at DUC-2004. In Proceedings of the 2004 DUC, 2004.", "Z. Liu, W. Huang, Y. Zheng, and M. Sun. Automatic keyphrase extraction via topic decomposition. In Proceedings of the 2010 Conference on EMNLP, pages 366--376, 2010.", "R. Mihalcea and P. Tarau. TextRank: Bringing Order into Texts. In Proceedings of the 2004 conference on EMNLP, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742730"}, {"title": "Prediction of Artists' Rankings by Regression", "authors": ["Felipe L. M. Faria\n,", "Alvaro R. Pereira\n,", "Luiz H. C. Merschmann"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe construction of rankings consists of ordering retrieved results according to certain criteria. Rankings can provide relevant information to analysts from different sectors of industry. For the music industry, rankings enable understanding how musical genres and popularity of artists and their songs evolve over time, allowing analyses of history data and trends. Due to the importance of building rankings in the musical scope, data mining techniques have been used to predict rankings by using information from social media. This work evaluates regression models for prediction of artists' rankings using historical data (daily rankings of artists) extracted from website Vagalume. Three regression techniques (k-Nearest Neighbors - k-NN, Multiple Linear Regression - MLR and Random Forests - RF) were evaluated in this study considering different scenarios. Results obtained from experiments showed that predictions with low error rates can be obtained, indicating that data mining techniques can be used to obtain information to assist the music industry in decision making.", "references": ["D. W. Aha. Tolerating noisy, irrelevant and novel attributes in instance-based learning algorithms. International Journal of Man-Machine Studies, 36(2):267-287, 1992.", "L. Breiman. Random forests. Machine Learning, 45(1):5-32, 2001.", "N. J. Bryan and G. Wang. Musical influence network analysis and rank of sample-based music. In Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR, pages 329-334, Miami, Florida, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814076"}, {"title": "Information Gain Study for Visual Vocabulary Construction", "authors": ["Huu Ton Le\n,", "Syntyche Gbèhounou\n,", "Thierry Urruty\n,", "François Lecellier\n,", "Christine Fernandez"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nContent Based Image Retrieval (CBIR) systems retrieve the most similar images to a query image in a collection. One of the most popular models and widely applied in this task is the Bag of Visual Words model (BoVW). In this paper, we introduce an evaluation study of different information gain models used for the construction of a visual word vocabulary. In the proposed framework, the information gain is used as discriminative information to index image features and select the ones that have the highest values of information gain. The empirical experiments made for this study evaluate the effect of four different information gain models: tf-idf, entropy, bm25, tfc with respect to different descriptors and image databases. The results show that selecting the image features based on at least one of the studied information gain model allows the retrieval process to be more accurate than the classical Bag of Visual Words model.", "references": ["H. Bay, T. Tuytelaars, and L. Gool. Surf: Speeded up robust features. In A. Leonardis, H. Bischof, and A. Pinz, editors, Computer - Vision - ECCV - 2006, volume 3951 of Lecture Notes in Computer Science, pages 404--417. Springer Berlin Heidelberg, 2006.", "G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. Workshop on Statistical Learning in Computer Vision, ECCV, pages 1--22, 2004.", "M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/-VOC/voc2012/workshop/index.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749319"}, {"title": "Controlling physical memory fragmentation in mobile systems", "authors": ["Sang-Hoon Kim\n,", "Sejun Kwon\n,", "Jin-Soo Kim\n,", "Jinkyu Jeong"], "publication": "ISMM '15: Proceedings of the 2015 International Symposium on Memory Management", "abstract": "ABSTRACT\nSince the adoption of hardware-accelerated features (e.g., hardware codec) improves the performance and quality of mobile devices, it revives the need for contiguous memory allocation. However, physical memory in mobile systems is highly fragmented due to the frequent spawn and exit of processes and the lack of proactive anti-fragmentation scheme. As a result, the memory allocation for large and contiguous I/O buffers suffer from the highly fragmented memory, thereby incurring high CPU usage and power consumption. This paper presents a proactive anti-fragmentation approach that groups pages with the same lifetime, and stores them contiguously in fixed-size contiguous regions. When a process is killed to secure free memory, a set of contiguous regions are freed and subsequent contiguous memory allocations can be easily satisfied without incurring additional overhead. Our prototype implementation on a Nexus 10 tablet with the Android kernel shows that the proposed scheme greatly alleviates fragmentation, thereby reducing the I/O buffer allocation time, associated CPU usage, and energy consumption.", "references": ["Android kernel features. URL http://elinux.org/ Android_Kernel_Features.", "N. Amit, M. Ben-Yehuda, and B.-A. Yassour. Iommu: Strategies for mitigating the iotlb bottleneck. In Proceedings of the 2010 International Conference on Computer Architecture (ISCA ’10), pages 256–274, 2012.", "Android. Managing the activity lifecycle, October 2013. URL http://developer.android.com/training/basics/ activity-lifecycle/index.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2754169.2754179"}, {"title": "3D Sketch-Based 3D Model Retrieval", "authors": ["Bo Li\n,", "Yijuan Lu\n,", "Azeem Ghumman\n,", "Bradley Strylowski\n,", "Mario Gutierrez\n,", "Safiyah Sadiq\n,", "Scott Forster\n,", "Natacha Feola\n,", "Travis Bugerin"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nHow to draw 3D sketches in a three-dimensional space and how to use a hand-drawn 3D sketch to search similar 3D models are brand new and challenging research topics. In this paper, we make an initial study on 3D sketching and propose a novel 3D sketch-based 3D model retrieval system. Our system allows users to freely draw 3D sketches in the air as well as to find similar 3D models given human-drawn 3D sketches. Promising retrieval performance has been achieved in experiments based on 300 collected 3D sketches and a recent large scale sketch-based 3D shape retrieval benchmark.", "references": ["M. Ankerst, G. Kastenmüller, and et al. 3D shape histograms for similarity search and classification in spatial databases. In SSD, pages 207--226, 1999.", "B. Li, Y. Lu, and et al. SHREC'13 track: Large scale sketch-based 3D shape retrieval. In 3DOR, pages 89--96, 2013.", "B. Li, Y. Lu, and et al. A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries. CVIU, 131:1--27, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749349"}, {"title": "Waldo: Data Producers Registry and Discovery Service for Smart Cities Middleware", "authors": ["Marcelo Iury S. Oliveira\n,", "Kiev Santos da Gama\n,", "Bernadette Farias Loscio"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe smart cities concept has emerged from the combination of digital environments with real communities, thus making more efficient the urban spaces management. The majority of proposed solutions are focused on the proposition of middleware that interconnects devices, collects and mediates data. However, these solutions lack of effective mechanisms for publication and discovery of data producers. This paper presents the Waldo, a service for registry and discovery of data producers in the context of smart cities. Waldo follows the Service-Oriented Computing paradigm and adopts NoSQL database solutions and SensorML specification. Through simulations, we attested the feasibility of Waldo as a solution for publishing and discovery of heterogeneous data producers.", "references": ["KOMNINOS, Nicos. Intelligent cities: innovation, knowledge systems, and digital spaces. Taylor & Francis, 2002.", "SCHAFFERS, Hans et al. Smart cities and the future internet: Towards cooperation frameworks for open innovation. Springer Berlin Heidelberg, 2011.", "GAMA, K., TOUSEAU, L., e DONSEZ, D. (2012). Combining heterogeneous service technologies for building an Internet of Things middleware. Computer Communications, 35(4), 405-417."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814071"}, {"title": "The Knowledge Web Meets Big Scholars", "authors": ["Kuansan Wang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nHuman is the only species on earth that has mastered the technologies in writing and printing to capture ephemeral thoughts and scientific discoveries. The capabilities to pass along knowledge, not only geographically but also generationally, have formed the bedrock of our civilizations. We are in the midst of a silent revolution driven by the technological advancements: no longer are computers just a fixture of our physical world but have they been so deeply woven into our daily routines that they are now occupying the center of our lives. No where are the phenomena more prominent than our reliance on the World Wide Web. More and more often, the web has become the primary source of fresh information and knowledge. In addition to general consumption, the availability of large amount of contents and behavioral data has also instigated new interdisciplinary research activities in the areas of information retrieval, natural language processing, machine learning, behavioral studies, social computing and data mining. This talk will use web search as an example to demonstrate how these new research activities and technologies have help the web evolve from a collection of documents to becoming the largest knowledge base in our history. During this evolution, the web is transformed from merely reacting to our needs to a living entity that can anticipate and push timely information to wherever and whenever we need it. How the scholarly activities and communications can be impacted will also be illustrated and elaborated, and some observations derived from a web scale data set, newly release to the public, will also be shared.", "references": ["J. Allen, C. I. Guinn, and E. Horvtz. Mixed-initiative interaction. Intelligent Systems and their Applications, IEEE, 14(5):14--23, 1999.", "T. Berners-Lee, J. Hendler, O. Lassila, et al. The semantic web. Scientific American, 284(5):28--37, 2001.", "V. Bush. As we may think. SIGPC Note., 1(4):36--44, April 1979."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741739"}, {"title": "Do specialized distributed frameworks for bioinformatics applications obtain better performance over generic ones?", "authors": ["Kanak Mahadik\n,", "Wei Tang\n,", "Saurabh Bagchi\n,", "Folker Meyer"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nThe most popular approach to tackle the data deluge due to high throughput sequencing instruments is parallelizing applications and distributing the large datasets across cluster of computers to achieve scalability and performance. Hadoop is a generic and Shock-AWE is a customized platform for genomic data for development of such applications. In this work we compare and contrast performance of protein similarity search application based on these platforms.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2811452"}, {"title": "Getting fast, free, and anonymous answers to questions asked by people with visual impairments", "authors": ["Erin Brady"], "publication": "ACM SIGACCESS Accessibility and Computing", "abstract": "Abstract\nMuch of the information we encounter in daily life is visual. For people with visual impairments, this information is not inherently accessible. Technology can be used to provide access to this visual information, through automated tools like currency identifiers, object recognizers, and optical character recognition, which allow for immediate access to visual information in a users' environment. However, these tools are often are limited to a specific domain, and can fail in non-ideal conditions (e.g., an optical character recognition tool trying to identify handwritten text).\nBy incorporating people into the information access pipeline, human-powered tools can allow for more complex information to be extracted from the user's surroundings. Human-powered access tools connect people who have disabilities to other people who can access information on their behalf. While people may not be as quick as automated tools, the person answering can make inferences based on prior knowledge and experiences, ask for clarification, and reason over the information provided.\nIn this article, we explore the long-term public deployment and lessons learned from VizWiz Social, a human-powered access tool that connects people with visual impairments to sighted workers or friends and family members who can answer their visual questions. By analyzing the use of this service, and running controlled experiments to determine how users value different answer sources, we have been able to build upon the original VizWiz design to create social microvolunteering, a method for getting fast, free, and anonymous answers to visual questions.", "references": ["Asakawa, C. and Itoh, T. User Interface of a Home Page Reader. Proceedings of the ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), (1998).", "Bernstein, M., Tan, D., Smith, G., Czerwinski, M., and Horvitz, E. Collabio: A Game for Annotating People within Social Networks. UIST 2009, (2009).", "Bigham, J.P., Jayant, C., Ji, H., et al. VizWiz: Nearly Real-time Answers to Visual Questions. Proceedings of the ACM Symposium on User Interface Software and Technology (UIST), (2010)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809915.2809918"}, {"title": "Top-K structural diversity search in large networks", "authors": ["Xin Huang\n,", "Hong Cheng\n,", "Rong-Hua Li\n,", "Lu Qin\n,", "Jeffrey Xu Yu"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nSocial contagion depicts a process of information (e.g., fads, opinions, news) diffusion in the online social networks. A recent study reports that in a social contagion process, the probability of contagion is tightly controlled by the number of connected components in an individual's neighborhood. Such a number is termed structural diversity of an individual, and it is shown to be a key predictor in the social contagion process. Based on this, a fundamental issue in a social network is to find top-$$k$$k users with the highest structural diversities. In this paper, we, for the first time, study the top-$$k$$k structural diversity search problem in a large network. Specifically, we study two types of structural diversity measures, namely, component-based structural diversity measure and core-based structural diversity measure. For component-based structural diversity, we develop an effective upper bound of structural diversity for pruning the search space. The upper bound can be incrementally refined in the search process. Based on such upper bound, we propose an efficient framework for top-$$k$$k structural diversity search. To further speed up the structural diversity evaluation in the search process, several carefully devised search strategies are proposed. We also design efficient techniques to handle frequent updates in dynamic networks and maintain the top-$$k$$k results. We further show how the techniques proposed in component-based structural diversity measure can be extended to handle the core-based structural diversity measure. Extensive experimental studies are conducted in real-world large networks and synthetic graphs, and the results demonstrate the efficiency and effectiveness of the proposed methods.", "references": ["Agrawal, R., Gollapudi, S., Halverson, A., Ieong, S.: Diversifying search results. In: WSDM, pp. 5---14 (2009)", "Angel, A., Koudas, N.: Efficient diversity-aware search. In: SIGMOD, pp. 781---792 (2011)", "Backstrom, L., Huttenlocher, D.P., Kleinberg, J.M., Lan, X.: Group formation in large social networks: membership, growth, and evolution. In: KDD, pp. 44---54 (2006)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0379-0"}, {"title": "SUPER: Towards the use of Social Sensors for Security Assessments and Proactive Management of Emergencies", "authors": ["Richard McCreadie\n,", "Karolin Kappler\n,", "Andreas Kaltenbrunner\n,", "Magdalini Kardara\n,", "Craig Macdonald\n,", "John Soldatos\n,", "Iadh Ounis"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSocial media statistics during recent disasters (e.g. the 20 million tweets relating to 'Sandy' storm and the sharing of related photos in Instagram at a rate of 10/sec) suggest that the understanding and management of real-world events by civil protection and law enforcement agencies could benefit from the effective blending of social media information into their resilience processes. In this paper, we argue that despite the widespread use of social media in various domains (e.g. marketing/branding/finance), there is still no easy, standardized and effective way to leverage different social media streams -- also referred to as social sensors -- in security/emergency management applications. We also describe the EU FP7 project SUPER (Social sensors for secUrity assessments and Proactive EmeRgencies management), started in 2014, which aims to tackle this technology gap.", "references": ["M.-A. Abbasi, S.-K. Chai, H. Liu, and K. Sagoo. Real-world behavior analysis through a social media lens. Social Computing, Behavioral-Cultural Modeling and Prediction, pages 18--26, 2012.", "E. Ackerman and E. Guizzo. 5 technologies that will shape the web. IEEE Spectrum, 48(6):40--45, 2011.", "A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and R. Passonneau. Sentiment analysis of Twitter data. In Proc. of LSM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741723"}, {"title": "Demo: AsthmaGuide: An Ecosystem for Asthma Monitoring and Advice", "authors": ["Ho-Kyeong Ra\n,", "Asif Salekin\n,", "Hee Jung Yoon\n,", "Jeremy Kim\n,", "Shahriar Nirjon\n,", "David Stone\n,", "Sujeong Kim\n,", "Jong-Myung Lee\n,", "Sang Hyuk Son\n,"], "publication": "SenSys '15: Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems", "abstract": "ABSTRACT\nAsthmaGuide is a smartphone and cloud based asthma system in which a smart phone is used as a hub for collecting a comprehensive collection of information. The data, including data over time, is then displayed in a cloud web application for both patients and healthcare providers to view. AsthmaGuide also provides an advice and alarm infrastructure based on the collected data and parameters set by healthcare providers. With these components, AsthmaGuide provides a comprehensive ecosystem that allows patients to be involved in their own health and also allows doctors to provide more effective day to day care. Using real asthma patient wheezing sounds we develop a new combination of classifiers that is 96% accurate at automatically detecting wheezing. This abstract provides an overview of the design and implementation of AsthmaGuide and provides empirical evidence that AsthmaGuide is 3% - 11% more accurate in detecting wheezing sounds than standard techniques.", "references": ["A. Alic, I. Lackovic, V. Bilas, D. Sersic, and R. Magjarevic. A Novel Approach to Wheeze Detection, volume 14 of IFMBE Proceedings. Springer Berlin Heidelberg, 2007.", "Centers for Disease Control and Prevention. Asthma in the US: growing every year. http://www.cdc.gov, 2011.", "Centers for Disease Control and Prevention. Common asthma triggers. http://www.cdc.gov, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809695.2817849"}, {"title": "Paper-based web connected objects and the internet of things through EKKO", "authors": ["John Mills\n,", "Paul Egglestone\n,", "Mark Lochrie\n,", "Martin Skelly"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nPaper has existed as a communications 'platform' for thousands of years. It's 'versioning history' spans papyrus, parchment and pulp, and when paper became a scalable and mass-production item, most famously via the Guttenberg press, it sparked unparalleled social and political change. It's a technology that's had 'impact'. More recently, News and Information - a sector with paper at its core - has seen substantial editorial and commercial disruption from digital communications networks. This paper outlines a collaborative project between journalism, media and technology researchers, and commercial product designers, exploring the potential of paper-based web-connected objects. Our work examines how emergent conductive ink technologies could offer a disruptive alternative to existing media products, and explores how to create, power and populate a connected paper platform, and analyse user activity. Through a range of industry partnerships with newspaper, magazine and book publishers, our research creates new paper affordances and interactions, and positions paper as a digital disruptor.", "references": ["Deuze, M., Bruns, A., Neuberger, C., (2007), Preparing for an age of participatory news, Journalism Practice, volume 1, issue 3, pp322--328", "Dittrich. Y., Burnett. M., Morch., Redmiles. D., (2013), End-User Development: 4th International Symposium, ISEUD 2013, Copenhagen", "Meyer, P., (2009), The Vanishing Newspaper: saving journalism in the information age, Univerity of Missouri, Columbia"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783610"}, {"title": "Revisiting the Foundations of IR: Timeless, Yet Timely", "authors": ["Paul B. Kantor"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAs we face an explosion of potential new applications for the fundamental concepts and technologies of information retrieval, ranging from ad ranking to social media, from collaborative recommending to question answering systems, many researchers are spending unnecessary time reinventing ideas and relationships that are buried in the prehistory of information retrieval (which, for many researchers, means anything published before they entered graduate school). Much of today's received wisdom may be nothing more than the fossilized residue of lively debates concerning such things as . estimation of value and evaluation of systems. Returning to those discussions may open the door to genuinely new insights. On the other hand, of the ideas that surface as \"new\" in today's super-heated research environment have very firm roots in earlier developments in fields as diverse as citation analysis, statistics, and pattern recognition. The purpose of this tutorial is to survey those roots, and their relation to the contemporary fruits on the tree of information retrieval, and to separate, as much as is possible in an era of increasing commercial secrecy about methods, the problems to be solved, the algorithms for solving them, and the heuristics that are the bread and butter of a working operation.\nAmong the important new topics whose foundations will be explored are the use of social media in search and advertising, and the growing management of personal image collections for search and for commercial purposes.\nWhile some might think that an examination of the roots is of merely historical interest, it has practical value as well. When you know which earlier research has provided the origins for the things that you are interested in, you can use that fact to trace its other descendents, and often find rich and rewarding ideas in a literature that you would not normally reach, because it was not considered important by your instructors when you were learning about the problems. In addition to pattern recognition and citation analysis, the tutorial will also expose and review some of the relations to the fields of statistics and operations research.\nParticipants will become familiar with roots in Pattern Analysis, Statistics, Information Science and other sources of key ideas that reappear in the current development of Information Retrieval as it applies to Search Engines, Social Media, and Collaborative Systems. They will be able to separate problems from algorithms, and algorithms from heuristics, in the application of these ideas to their own research and/or development activities. Course materials will be made available on a Web site two weeks prior to the tutorial. They will include links to relevant software; links to publications that will be discussed; and mechanisms for chat among the tutorial participants, before, during and after the tutorial.", "references": ["R.O. Duda, P.E. Hart, and D.G. Stork. Pattern classification. 2001.", "Geman, S. & Geman, D., 1984. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (6), pp.721--741.", "I.J. Good. Probability and the Weighing of Evidence. Griffin, 1950."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767878"}, {"title": "Using Sensor Metadata Streams to Identify Topics of Local Events in the City", "authors": ["M-Dyaa Albakour\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we study the emerging Information Retrieval (IR) task of local event retrieval using sensor metadata streams. Sensor metadata streams include information such as the crowd density from video processing, audio classifications, and social media activity. We propose to use these metadata streams to identify the topics of local events within a city, where each event topic corresponds to a set of terms representing a type of events such as a concert or a protest. We develop a supervised approach that is capable of mapping sensor metadata observations to an event topic. In addition to using a variety of sensor metadata observations about the current status of the environment as learning features, our approach incorporates additional background features to model cyclic event patterns. Through experimentation with data collected from two locations in a major Spanish city, we show that our approach markedly outperforms an alternative baseline. We also show that modelling background information improves event topic identification.", "references": ["M.-D. Albakour, C. Macdonald, and I. Ounis. Identifying local events by using microblogs as social sensors. In Proc. of OAIR'13.", "P. K. Atrey, M. Maddage, and M. S. Kankanhalli. Audio based event detection for multimedia surveillance. In Proc. of ICASSP'06.", "L. Breiman. Random forests. Machine learning, 45(1):5--32, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767837"}, {"title": "Differences in the Use of Search Assistance for Tasks of Varying Complexity", "authors": ["Robert Capra\n,", "Jaime Arguello\n,", "Anita Crescenzi\n,", "Emily Vardell"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we study how users interact with a search assistance tool while completing tasks of varying complexity. We designed a novel tool referred to as the search guide (SG) that displays the search trails (queries issued, results clicked, pages bookmarked) from three previous users who completed the task. We report on a laboratory study with 48 participants that investigates different factors that may influence user interaction with the SG and the effects of the SG on different outcome measures. Participants were asked to find and bookmark pages for four tasks of varying complexity and the SG was made available to half the participants. We collected log data and conducted retrospective stimulated recall interviews to learn about participants' use of the SG. Our results suggest the following trends. First, interaction with the SG was greater for more complex tasks. Second, the a priori determinability of the task (i.e., whether the task was perceived to be well-defined) helped predict whether participants gained a bookmark from the SG. Third, participants who interacted with the SG, but did not gain a bookmark, felt less system support than those who gained a bookmark and those who did not interact. Finally, a qualitative analysis of our interviews suggests differences in motivation and benefits from SG use for different levels of task complexity. Our findings extend prior research on search assistance tools and provide insights for the design of systems to help users with complex search tasks.", "references": ["L. W. Anderson and D. R. Krathwohl. A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of educational objectives. New York: Longman, 2001.", "J. Arguello. Predicting search task difficulty. In ECIR. Springer-Verlag, 2014.", "J. Arguello, W.-C. Wu, D. Kelly, and A. Edwards. Task complexity, vertical display and user interaction in aggregated search. In SIGIR, pages 435--444. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767741"}, {"title": "The Query Change Model: Modeling Session Search as a Markov Decision Process", "authors": ["Hui Yang\n,", "Dongyi Guan\n,", "Sicong Zhang"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nModern information retrieval (IR) systems exhibit user dynamics through interactivity. These dynamic aspects of IR, including changes found in data, users, and systems, are increasingly being utilized in search engines. Session search is one such IR task—document retrieval within a session. During a session, a user constantly modifies queries to find documents that fulfill an information need. Existing IR techniques for assisting the user in this task are limited in their ability to optimize over changes, learn with a minimal computational footprint, and be responsive. This article proposes a novel query change retrieval model (QCM), which uses syntactic editing changes between consecutive queries, as well as the relationship between query changes and previously retrieved documents, to enhance session search. We propose modeling session search as a Markov decision process (MDP). We consider two agents in this MDP: the user agent and the search engine agent. The user agent’s actions are query changes that we observe, and the search engine agent’s actions are term weight adjustments as proposed in this work. We also investigate multiple query aggregation schemes and their effectiveness on session search. Experiments show that our approach is highly effective and outperforms top session search systems in TREC 2011 and TREC 2012.", "references": ["Mikhail Ageev, Qi Guo, Dmitry Lagun, and Eugene Agichtein. 2011. Find it if you can: A game for modeling different types of Web search success using interaction data. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’11). ACM, New York, NY, 345--354. DOI:http://dx.doi.org/10.1145/2009916.2009965", "M-Dyaa Albakour and Udo Kruschwitz. 2012. University of Essex at the TREC 2012 session track. In Proceedings of the 21st Text Retrieval Conference (TREC’12).", "M-Dyaa Albakour, Kruschwitz Udo, Nanas Nikolaos, Neville Brendan, Lungely Deirdre, and Fasli Maria. 2011. University of Essex at the TREC 2011 session track. In Proceedings of the 20th Text Retrieval Conference (TREC’11)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2747874"}, {"title": "Exploring Opportunities to Facilitate Serendipity in Search", "authors": ["Ataur Rahman\n,", "Max L. Wilson"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSerendipitously discovering new information can bring many benefits. Although we can design systems to highlight serendipitous information, serendipity cannot be easily orchestrated and is thus hard to study. In this paper, we deployed a working search engine that matched search results with Facebook 'Like' data, as a technology probe to examine naturally occurring serendipitous discoveries. Search logs and diary entries revealed the nature of these occasions in both leisure and work contexts. The findings support the use of the micro-serendipity model in search system design.", "references": ["P. André, J. Teevan, and S. T. Dumais. From x-rays to silly putty via uranus: serendipity and its role in web search. In Proc. CHI, pages 2033--2036. ACM, 2009.", "P. André, J. Teevan, S. T. Dumais, et al. Discovery is never by chance: designing for (un) serendipity. In Proc. C&C, pages 305--314. ACM, 2009.", "S. S. Bateman, C. A. Gutwin, and G. I. McCalla. Social navigation for loosely-coupled information seeking in tightly-knit groups using webwear. In Proc. ACM CSCW 2013, pages 955--966. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767783"}, {"title": "Automatic and transparent I/O optimization with storage integrated application runtime support", "authors": ["Noah Watkins\n,", "Zhihao Jia\n,", "Galen Shipman\n,", "Carlos Maltzahn\n,", "Alex Aiken\n,", "Pat McCormick"], "publication": "PDSW '15: Proceedings of the 10th Parallel Data Storage Workshop", "abstract": "ABSTRACT\nTraditionally storage has not been part of a programming model's semantics and is added only as an I/O library interface. As a result, programming models, languages, and storage systems are limited in the optimizations they can perform for I/O operations, as the semantics of the I/O library is typically at the level of transfers of blocks of uninterpreted bits, with no accompanying knowledge of how those bits are used by the application. For many HPC applications where I/O operations for analyzing and checkpointing large data sets are a non-negligible portion of the overall execution time, such a \"know nothing\" I/O design has negative performance implications.\nWe propose an alternative design where the I/O semantics are integrated as part of the programming model, and a common data model is used throughout the entire memory and storage hierarchy enabling storage and application level co-optimizations. We demonstrate these ideas through the integration of storage services within the Legion [2] runtime and present preliminary results demonstrating the integration.", "references": ["Introduction to hdf5. https://www.hdfgroup.org/HDF5/doc/H5.intro.html, 2010.", "M. Bauer, S. Treichler, E. Slaughter, and A. Aiken. Legion: Expressing locality and independence with logical regions. In I'12, Los Alamitos, CA, USA, 2012.", "M. Bauer, S. Treichler, E. Slaughter, and A. Aiken. Structure slicing: Extending logical regions with fields. In SC '14, New Orleans, LA, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834976.2834983"}, {"title": "TouchNoise: A New Multitouch Interface for Creative Work with Noise", "authors": ["Axel Berndt\n,", "Nadia Al-Kassab\n,", "Raimund Dachselt"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nTouchNoise is a multitouch noise modulation interface designed for musical live performance. It allows the direct and indirect manipulation of sound particles in the stereophonic frequency spectrum. In order to increase TouchNoise's playability we conducted a comprehensive interface revision retaining only its core interaction concept. New interaction techniques and gestures for radial menus, effect range settings, and frequency band effects are introduced. The revision paved the way for a series of new functionalities, such as flocking, flow fields, and MIDI connectivity, making TouchNoise a fully-fledged, powerful interface for creative work with noise. This paper introduces the new TouchNoise interface and functionalities through a discussion of the revision process and derives interaction principles and design recommendations for musical multitouch interfaces in general.", "references": ["C. Ó Nuanáin and L. O'Sullivan. Real-time Algorithmic Composition with a Tabletop Musical Interface---A First Prototype and Performance. In Audio Mostly 2014: 9th Conf. on Interaction with Sound---Imagining Sound and Music, Aalborg, Denmark, Oct. 2014. Aalborg University, Interactive Institute/Sonic Studio PiteÅ, ACM.", "A. Berndt, N. Al-Kassab, and R. Dachselt. TouchNoise: A Particle-based Multitouch Noise Modulation Interface. In Proc. of New Interfaces for Musical Expression (NIME) 2014, pages 323--326, London, UK, June 2014. Goldsmiths, University of London.", "T. Blackwell. Swarming and Music. In E. R. Miranda and J. A. Biles, editors, Evolutionary Computer Music, chapter 9, pages 194--217. Springer, London, UK, April 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814896"}, {"title": "Diversity-Aware Top-k Publish/Subscribe for Text Stream", "authors": ["Lisi Chen\n,", "Gao Cong"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nMassive amount of text data are being generated by a huge number of web users at an unprecedented scale. These data cover a wide range of topics. Users are interested in receiving a few up-to-date representative documents (e.g., tweets) that can provide them with a wide coverage of different aspects of their query topics. To address the problem, we consider the Diversity-Aware Top-k Subscription (DAS) query. Given a DAS query, we continuously maintain an up-to-date result set that contains k most recently returned documents over a text stream for the query. The DAS query takes into account text relevance, document recency, and result diversity. We propose a novel solution to efficiently processing a large number of DAS queries over a stream of documents. We demonstrate the efficiency of our approach on real-world dataset and the experimental results show that our solution is able to achieve a reduction of the processing time by 60--75% compared with two baselines. We also study the effectiveness of the DAS query.", "references": ["S. Abbar, S. Amer-Yahia, P. Indyk, and S. Mahabadi. Real-time recommendation of diverse related articles. In WWW, pages 1--12, 2013.", "G. Amati, G. Amodeo, and C. Gaibisso. Survival analysis for freshness in microblogging search. In CIKM, pages 2483--2486. ACM, 2012.", "A. Angel and N. Koudas. Efficient diversity-aware search. In SIGMOD, pages 781--792, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2749451"}, {"title": "\"My Day in Review\": Visually Summarising Noisy Lifelog Data", "authors": ["Soumyadeb Chowdhury\n,", "Philip J. McParlane\n,", "Md. Sadek Ferdous\n,", "Joemon Jose"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nLifelogging devices, which seamlessly gather various data about a user as they go about their daily life, have resulted in users amassing large collections of noisy photographs (e.g. visual duplicates, image blur), which are difficult to navigate, especially if they want to review their day in photographs. Social media websites, such as Facebook, have faced a similar information overload problem for which a number of summarization methods have been proposed (e.g. news story clustering, comment ranking etc.). In particular, Facebook's Year in Review received much user interest where the objective for the model was to identify key moments in a user's year, offering an automatic visual summary based on their uploaded content. In this paper, we follow this notion by automatically creating a review of a user's day using lifelogging images. Specifically, we address the quality issues faced by the photographs taken on lifelogging devices and attempt to create visual summaries by promoting visual and temporal-spatial diversity in the top ranks. Conducting two crowdsourced evaluations based on 9k images, we show the merits of combining time, location and visual appearance for summarization purposes.", "references": ["Doherty, A., Kelly, P., & Foster, C. \"Wearable Cameras: Identifying Healthy Transportation Choices.\" IEEE Pervasive Computing 12.1 (2013): 44--47.", "Doherty, Aiden R., et al. \"Experiences of aiding autobiographical memory using the SenseCam.\" Human-Computer Interaction 27. 1-2 (2012): 151--174.", "Anguera, X., Xu, J., & Oliver, N. \"Multimodal photo annotation and retrieval on a mobile phone.\" ACM MIR, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749393"}, {"title": "Minimization of Instructions to Access Memory by Color Flipping in the Interference Graph", "authors": ["Felipe L. Silva\n,", "Marcelo F. Luna\n,", "Wesley Attrot"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nGraph coloring is one of the most effectiveness approaches to perform register allocation. This work describes a new approach to flip colors in an interference graph to minimize the code insertion for accessing memory. To evaluate the impact of using this strategy in the graph coloring register allocator, a George and Appel allocator has been developed in two ways - flipping the colors and without flipping the colors in the interference graph. Experiments with a set of 27,921 graphs of real programs were performed. In some cases, our results showed over 12% of reduction in number of variables sent to memory.", "references": ["A. W. Appel and L. George. Sample graph coloring problems, 1996. Access date: 18 Nov. 2014.", "P. Bergner, P. Dahl, D. Engebretsen, and M. O'Keefe. Spill code minimization via interference region spilling. In Proceedings of the ACM SIGPLAN 1997 Conference on Programming Language Design and Implementation, PLDI'97 pages 287-295, New York, NY, USA, 1997. ACM.", "D. Bernstein, M. Golumbic, y. Mansour, R. Pinter, D. Goldin, H. Krawczyk, and I. Nahshon. Spill code minimization techniques for optimizing compliers. In Proceedings of the ACM SIGPLAN 1989 Conference on Programming Language Design and Implementation, PLDI'89, pages 258-263, New York, NY, USA, 1989. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814136"}, {"title": "Improving Automatic Name-Face Association using Celebrity Images on the Web", "authors": ["Zhineng Chen\n,", "Bailan Feng\n,", "Chong-Wah Ngo\n,", "Caiyan Jia\n,", "Xiangsheng Huang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper investigates the task of automatically associating faces appearing in images (or videos) with their names. Our novelty lies in the use of celebrity Web images to facilitate the task. Specifically, we first propose a method named Image Matching (IM), which uses the faces in images returned from name queries over an image search engine as the gallery set of the names, and a probe face is classified as one of the names, or none of them, according to their matching scores and compatibility characterized by a proposed Assigning-Thresholding (AT) pipeline. Noting IM could provide guidance for association for the well-established Graph-based Association (GA), we further propose two methods that jointly utilize the two kinds of complementary cues. They are: the early fusion of IM and GA (EF-IMGA) that takes the IM score as an additional information source to help the association in GA, and the late fusion of IM and GA (LF-IMGA) that combines the scores from both IM and GA obtained individually to make the association. Evaluations on datasets of captioned news images and Web videos both show the proposed methods, especially the two fused ones, provide significant improvements over GA.", "references": ["T. L. Berg, A. C. Berg, et al, Name and face in the news, IEEE CVPR, pp. 848--854, 2004.", "M. Guillaumin, T. Mensink, J. Verbeek, Face recognition from caption-based supervision. Int. J. Comput. Vis., 96(1): 64--82, 2012.", "J. Bu, B. Xu, C. Wu, et al, Unsupervised face-name association via commute distance. ACM Multimedia, pp. 219--228, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749401"}, {"title": "Service Oriented Architecture and Distributed Computing using LASAGNE", "authors": ["Jonathan Boan\n,", "Derek Dominish\n,", "Garry Brown"], "publication": "ASWEC ' 15 Vol. II: Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference", "abstract": "ABSTRACT\nWith the adoption of a service oriented architectural (SOA) approach to application development within defence there is a need to provide architectural guidance coupled with infrastructure mechanisms to assist developers through the implementation process. Applications developed under a SOA approach are more akin to an assemblage rather than the more traditional development methodology of construct and execute. There is a growing collection of common services that are available for the tactical defence environment. However there exists the need to manage the availability of these services and their usage by applications through a common approach to infrastructure, configuration and deployment.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811681.2817754"}, {"title": "Comparative I/O workload characterization of two leadership class storage clusters", "authors": ["Raghul Gunasekaran\n,", "Sarp Oral\n,", "Jason Hill\n,", "Ross Miller\n,", "Feiyi Wang\n,", "Dustin Leverman"], "publication": "PDSW '15: Proceedings of the 10th Parallel Data Storage Workshop", "abstract": "ABSTRACT\nThe Oak Ridge Leadership Computing Facility (OLCF) is a leader in large-scale parallel file system development, design, deployment and continuous operation. For the last decade, the OLCF has designed and deployed two large center-wide parallel file systems. The first instantiation, Spider 1, served the Jaguar supercomputer and its predecessor, Spider 2, now serves the Titan supercomputer, among many other OLCF computational resources. The OLCF has been rigorously collecting file and storage system statistics from these Spider systems since their transition to production state.\nIn this paper we present the collected I/O workload statistics from the Spider 2 system and compare it to the Spider 1 data. Our analysis show that the Spider 2 workload is more more write-heavy I/O compared to Spider 1 (75% vs. 60%, respectively). The data also show the OLCF storage policies such as periodic purges are effectively managing the capacity resource of Spider 2. Furthermore, due to improvements in tdm_multipath and ib_srp software, we are utilizing the Spider 2 system bandwidth and latency resources more effectively. The Spider 2 bandwidth usage statistics shows that our system is working within the design specifications. However, it is also evident that our scientific applications can be more effectively served by a burst buffer storage layer. All the data has been collected by monitoring tools developed for the Spider ecosystem. We believe the observed data set and insights will help us better design the next-generation Spider file and storage system. It will also be helpful to the larger community for building more effective large-scale file and storage systems.", "references": ["A. S. Bland, J. C. Wells, O. E. Messer, O. R. Hernandez, and J. H. Rogers. Titan: Early Experience with the Cray XK6 at Oak Ridge National Laboratory. In Proceedings of Cray User Group Conference (CUG 2012), 2012.", "P. Carns, K. Harms, W. Allcock, C. Bacon, S. Lang, R. Latham, and R. Ross. Understanding and improving computational science storage access through continuous characterization. Trans. Storage, 7(3):8:1--8:26, Oct. 2011.", "DataDirect Networks. SFAOS ReAct Cache. http://www.ddn.com/pdfs/SFA12KX\\_Whitepaper.pdf."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834976.2834985"}, {"title": "Puma: pooling unused memory in virtual machines for I/O intensive applications", "authors": ["Maxime Lorrillere\n,", "Julien Sopena\n,", "Sébastien Monnet\n,", "Pierre Sens"], "publication": "SYSTOR '15: Proceedings of the 8th ACM International Systems and Storage Conference", "abstract": "ABSTRACT\nWith the advent of cloud architectures, virtualization has become a key mechanism. In clouds, virtual machines (VMs) offer both isolation and flexibility. This is the foundation of cloud elasticity, but it induces fragmentation of the physical resources, including memory. While each VM memory needs evolve during time, existing mechanisms used to dynamically adjust VMs memory are inefficient, and it is currently impossible to take benefit of the unused memory of VMs hosted by another host. In this paper we propose Puma, a mechanism that improves I/O intensive applications performance by providing the ability for a VM to entrust clean page-cache pages to other VMs having unsused memory. By reusing the existing page-cache data structures, Puma is very efficient to reclaim the memory lent to another VM. By being distributed, Puma increases the memory consolidation at the scale of a data center. In our evaluations made with TPC-C, TPC-H, BLAST and Postmark, we show that Puma can significantly boost the performance without impacting potential activity peaks on the lender.", "references": ["{Altschul 1990} Stephen F. Altschul, Warren Gish, Webb Miller, Eugene W. Myers, and David J. Lipman. Basic local alignment search tool. Journal of molecular biology, 215(3): 403--410, 1990.", "{Annapureddy 2005} Siddhartha Annapureddy, Michael J. Freedman, and David Mazières. Shark: scaling file servers via cooperative caching. In Proceedings of the 2nd Symposium on Networked Systems Design & Implementation, volume 2 of NSDI'05, pages 129--142, Berkeley, CA, USA, 2005.", "{Barham 2003} Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, and Andrew Warfield. Xen and the art of virtualization. In Proceedings of the 9th ACM Symposium on Operating Systems Principles, SOSP '03, pages 164--177, New York, NY, USA, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757667.2757669"}, {"title": "A Taxonomy of Semantic Web Data Retrieval Techniques", "authors": ["Anila Sahar Butt\n,", "Armin Haller\n,", "Lexing Xie"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nThe Semantic Web provides access to an increasing amount of structured information in a wide variety of domains. Information overload due to the large amount of structured data is as much a problem as on the traditional Web. To solve this problem, ample research has been proposed on Semantic Web data retrieval techniques and after more than a decade of research in this domain it is now reasonable to consider the questions: is the field of Semantic Web data retrieval making progress? What are the directions that have been taken? and what are some of the promising significant directions to pursue future research? To answer these questions, we review the state-of-the-art Semantic Web data retrieval techniques and define a taxonomy of these techniques to classify the ongoing research and find potential future research directions.", "references": ["H. Alani, C. Brewster, and N. Shadbolt. Ranking ontologies with aktiverank. In The Semantic Web-ISWC 2006, pages 1--15. Springer, 2006.", "K. Anyanwu, A. Maduko, and A. Sheth. Semrank: ranking complex relationship search results on the semantic web. In Proc. of the 14th international conference on World Wide Web, pages 117--127. ACM, 2005.", "A. Batzios, C. Dimou, A. L. Symeonidis, and P. A. Mitkas. Biocrawler: An intelligent crawler for the semantic web. Expert Systems with Applications, 35(1):524--530, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815846"}, {"title": "Condensed List Relevance Models", "authors": ["Fernando Diaz"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nPseudo-relevance feedback has traditionally been implemented as an expensive re-retrieval of documents from the target corpus. In this work, we demonstrate that, for high precision metrics, re-ranking the original feedback set provides nearly identical performance to re-retrieval with significantly lower latency.", "references": ["R. Attar and A. S. Fraenkel. Local feedback in full-text retrieval systems. J. ACM, 24(3):397--417, July 1977.", "M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In WSDM, 2012.", "A. Z. Broder, D. Carmel, M. Herscovici, A. Soffer, and J. Zien. Efficient query evaluation using a two-level retrieval process. In CIKM, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809491"}, {"title": "Egocentric Video Summarization of Cultural Tour based on User Preferences", "authors": ["Patrizia Varini\n,", "Giuseppe Serra\n,", "Rita Cucchiara"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we propose a new method to obtain customized video summarization according to specific user preferences. Our approach is tailored on Cultural Heritage scenario and is designed on identifying candidate shots, selecting from the original streams only the scenes with behavior patterns related to the presence of relevant experiences, and further filtering them in order to obtain a summary matching the requested user's preferences. Our preliminary results show that the proposed approach is able to leverage user's preferences in order to obtain a customized summary, so that different users may extract from the same stream different summaries.", "references": ["F. Crété-Roffet, T. Dolmiere, P. Ladret, M. Nicolas, et al. The blur effect: Perception and estimation with a new no-reference perceptual blur metric. In Proc. of SPIE, 2007.", "L. Ertöz, M. Steinbach, and V. Kumar. Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data. In Proc. of SDM, 2003.", "J. M. Henderson. Regarding scenes. Current Directions in Psychological Science, 16(4):219--222, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806367"}, {"title": "Correspondence Autoencoders for Cross-Modal Retrieval", "authors": ["Fangxiang Feng\n,", "Xiaojie Wang\n,", "Ruifan Li\n,", "Ibrar Ahmad"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nThis article considers the problem of cross-modal retrieval, such as using a text query to search for images and vice-versa. Based on different autoencoders, several novel models are proposed here for solving this problem. These models are constructed by correlating hidden representations of a pair of autoencoders. A novel optimal objective, which minimizes a linear combination of the representation learning errors for each modality and the correlation learning error between hidden representations of two modalities, is used to train the model as a whole. Minimizing the correlation learning error forces the model to learn hidden representations with only common information in different modalities, while minimizing the representation learning error makes hidden representations good enough to reconstruct inputs of each modality. To balance the two kind of errors induced by representation learning and correlation learning, we set a specific parameter in our models. Furthermore, according to the modalities the models attempt to reconstruct they are divided into two groups. One group including three models is named multimodal reconstruction correspondence autoencoder since it reconstructs both modalities. The other group including two models is named unimodal reconstruction correspondence autoencoder since it reconstructs a single modality. The proposed models are evaluated on three publicly available datasets. And our experiments demonstrate that our proposed correspondence autoencoders perform significantly better than three canonical correlation analysis based models and two popular multimodal deep models on cross-modal retrieval tasks.", "references": ["Muhammet Bastan, Hayati Cam, Ugur Gdkbay, and Özgür Ulusoy. 2010. Bilvideo-7: An MPEG-7-compatible video indexing and retrieval system. IEEE MultiMedia 17, 3, 62--73.", "Yoshua Bengio. 2009. Learning deep architectures for AI. Found. Trends Machine Learn. 2, 1, 1--127.", "Steven Bird. 2006. NLTK: the natural language toolkit. In Proceedings of the COLING/ACL on Interactive Presentation Sessions (COLING-ACL'06). 69--72."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808205"}, {"title": "Document Comprehensiveness and User Preferences in Novelty Search Tasks", "authors": ["Ashraf Bah\n,", "Praveen Chandar\n,", "Ben Carterette"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDifferent users may be attempting to satisfy different information needs while providing the same query to a search engine. Addressing that issue is addressing Novelty and Diversity in information retrieval. Novelty and Diversity search task models the task wherein users are interested in seeing more and more documents that are not only relevant, but also cover more aspects (or subtopics) related to the topic of interest. This is in contrast with the traditional IR task where topical relevance is the only factor in evaluating search results. In this paper, we conduct a user study where users are asked to give a preference between one of two documents B and C given a query and also given that they have already seen a document A. We then test a total of ten hypotheses pertaining to the relationship between the \"comprehensiveness\" of documents (i.e. the number of subtopics a document is relevant to) and real users' preference judgments. Our results show that users are inclined to prefer documents with higher comprehensiveness, even when the prior document A already covers more aspects than the two documents being compared, and even when the least preferred has a higher relevance grade. In fact, users are inclined to prefer documents with higher overall aspect-coverage even in cases where B and C are relevant to the same number of novel subtopics.", "references": ["Amazon mechanical turk. http://www.mturk.com.", "Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N., Hullen-der, G.: Learning to rank using gradient descent. In ICML. (2005)", "Carterette, B., Bennett, P. N., Chickering, D. M., & Dumais, S. T.: Here or there. In ECIR. (2008)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767820"}, {"title": "SCAN++: efficient algorithm for finding clusters, hubs and outliers on large-scale graphs", "authors": ["Hiroaki Shiokawa\n,", "Yasuhiro Fujiwara\n,", "Makoto Onizuka"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nGraph clustering is one of the key techniques for understanding the structures present in graphs. Besides cluster detection, identifying hubs and outliers is also a key task, since they have important roles to play in graph data mining. The structural clustering algorithm SCAN, proposed by Xu et al., is successfully used in many application because it not only detects densely connected nodes as clusters but also identifies sparsely connected nodes as hubs or outliers. However, it is difficult to apply SCAN to large-scale graphs due to its high time complexity. This is because it evaluates the density for all adjacent nodes included in the given graphs. In this paper, we propose a novel graph clustering algorithm named SCAN++. In order to reduce time complexity, we introduce new data structure of directly two-hop-away reachable node set (DTAR). DTAR is the set of two-hop-away nodes from a given node that are likely to be in the same cluster as the given node. SCAN++ employs two approaches for efficient clustering by using DTARs without sacrificing clustering quality. First, it reduces the number of the density evaluations by computing the density only for the adjacent nodes such as indicated by DTARs. Second, by sharing a part of the density evaluations for DTARs, it offers efficient density evaluations of adjacent nodes. As a result, SCAN++ detects exactly the same clusters, hubs, and outliers from large-scale graphs as SCAN with much shorter computation time. Extensive experiments on both real-world and synthetic graphs demonstrate the performance superiority of SCAN++ over existing approaches.", "references": ["Apache Giraph. http://giraph.apache.org/.", "V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast Unfolding of Communities in Large Networks. Journal of Statistical Mechanics: Theory and Experiment, 2008:P10008, October 2008.", "A. Clauset, M. E. J. Newman, and C. Moore. Finding Community Structure in Very Large Networks. Phys. Rev. E, 70:066111, Dec 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809980"}, {"title": "Using gamification to improve treatment adherence", "authors": ["Matheus Batista Nascimento\n,", "Eduardo Simoes de Albuquerque"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents an ongoing research on the difficulties in treatment adherence and the use of gamification in health. A system is proposed to adapt and apply gamification techniques to the specific case of hypertension, focusing in inspiring motivation.", "references": ["A. Ahtinen, P. Huuskonen, and J. Häkkilä. Let's all get up and walk to the north pole: Design and evaluation of a mobile wellness application. In Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, NordiCHI '10, pages 3-12, New York, NY, USA, 2010. ACM.", "Bazian Ltd. The effects of education on patient adherence to medication. Evidence-based Healthcare and Public Health, 9(6):398 - 404, 2005.", "R. Bénabou and J. Tirole. Incentives and prosocial behavior. American Economic Review, 96(5):1652-1678, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814122"}, {"title": "Getting the Agenda Right: Measuring Media Agenda using Topic Models", "authors": ["Damir Korenčić\n,", "Strahil Ristov\n,", "Jan Šnajder"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nAgenda setting is the theory of how issue salience is transferred from the media to media audience. An agenda-setting study requires one to define a set of issues and to measure their salience. We propose a semi-supervised approach based on topic modeling for exploring a news corpus and measuring the media agenda by tagging news articles with issues. The approach relies on an off-the-shelf Latent Dirichlet Allocation topic model, manual labeling of topics, and topic model customization. In preliminary evaluation, the tagger achieves a micro F1-score of 0.85 and outperforms the supervised baselines, suggesting that it could be successfully used for agenda-setting studies.", "references": ["S. Bird. NLTK: The Natural Language Toolkit. In Proceedings of the COLING/ACL Interactive presentation sessions, pages 69--72, 2006.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. The Journal of Machine Learning Research, 3:993--1022, 2003.", "J. Chuang, S. Fish, D. Larochelle, W. P. Li, and R. Weiss. Large-scale topical analysis of multiple online news sources with Media Cloud. NewsKDD: Data Science for News Publishing, at KDD, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809942"}, {"title": "Skyline Queries with Noisy Comparisons", "authors": ["Benoit Groz\n,", "Tova Milo"], "publication": "PODS '15: Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems", "abstract": "ABSTRACT\nWe study in this paper the computation of skyline queries - a popular tool for multicriteria data analysis - in the presence of noisy input. Motivated by crowdsourcing applications, we present the first algorithms for skyline evaluation in a computation model where the input data items can only be compared through noisy comparisons. In this model comparisons may return wrong answers with some probability, and confidence can be increased through independent repetitions of a comparison. Our goal is to minimize the number of comparisons required for computing or verifying a candidate skyline, while returning the correct answer with high probability. We design output-sensitive algorithms, namely algorithms that take advantage of the potentially small size of the skyline, and analyze the number of comparison rounds of our solutions. We also consider the problem of predicting the most likely skyline given some partial information in the form of noisy comparisons, and show that optimal prediction is computationally intractable.", "references": ["F. N. Afrati, P. Koutris, D. Suciu, and J. D. Ullman. Parallel skyline queries. In ICDT, pages 274--284, 2012.", "P. Afshani. Fast computation of output-sensitive maxima in a word ram. In SODA, pages 1414--1423, 2014.", "P. Afshani, P. K. Agarwal, L. Arge, K. G. Larsen, and J. M. Phillips. (approximate) uncertain skylines. Theory Comput. Syst., 52(3):342--366, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745754.2745775"}, {"title": "MERC: Match at Edge and Route intra--Cluster for Content-based Publish/Subscribe Systems", "authors": ["Shuping Ji\n,", "Chunyang Ye\n,", "Jun Wei\n,", "Hans-Arno Jacobsen"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nDespite suffering from inefficiency and flexibility limitations, the filter-based routing (FBR) algorithm is widely used in content-based publish/subscribe (pub/sub) systems. To address its limitations, we propose a dynamic destination-based routing algorithm called D-DBR, which decomposes pub/sub into two independent parts: Content-based matching and destination-based multicasting. D-DBR exhibits low event matching cost and high efficiency, flexibility, and robustness for event routing in small scale overlays. To boost scalability, we further complement D-DBR with a new routing algorithm called MERC. MERC divides the overlay into interconnected clusters and applies content-based and destination-based mechanisms to route events inter- and intra-cluster, respectively. We implemented all algorithms in the PADRES pub/sub system. Experimental results show that our algorithms outperform FBR in terms of improving event dissemination throughput by up to 700% and reducing the end-to-end latency by up to 55%.", "references": ["M. Adler, Z. Ge, J. F. Kurose, D. Towsley, and S. Zabele. Channelization problem in large scale data dissemination. In ICNP'01, 2001.", "G. Banavar, T. Chandra, B. Mukherjee, J. Nagarajarao, R. E. Strom, and D. C. Sturman. An efficient multicast protocol for content-based publish-subscribe systems. In ICDCS'99, 1999.", "L.-F. Cabrera, M. B. Jones, and M. Theimer. Herald: Achieving a global event notification service. In Hot Topics in Operating Systems Workshop, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814801"}, {"title": "An automatic detection and segmentation algorithm of video multiple moving targets for computer vision", "authors": ["Kun Zhang\n,", "Cuirong Wang\n,", "Shaoheng Li"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn this paper an automatic detection and segmentation algorithm of video multiple moving targets is proposed for the problem of computer vision in intelligent monitoring system. The algorithm improved the adaptive clustering by defining the pixel spatial connectivity rate. We design the perpendicular split method, initial cluster adaptive splitting and merging self-organizing the iterative clustering segmentation algorithm. It improved the active contour model to complete the edge detection. Experimental results show that multiple moving targets segmentation results are consistent with the human visual judgment, take use of space connectivity information improves the accuracy of clustering segmentation, take use of sparse matrix block operation for active contour model that improves multiple moving targets edge detection result, comparison and analysis the experimental results show that the proposed algorithm is feasible, rapid and effective.", "references": ["Koç, G., Sarıogu, B. 2014. Statistical analysis of threshold algorithms in image processing based cancer cell detection. In Signal Processing and Communications Applications Conference, 2014 22nd (Trabzon, Turkey, April 23--25, 2014). SIU'14. IEEE, Piscataway, NJ, USA, 481--484. DOI= 10.1109/SIU.2014.6830270.", "K. Takahashi, K. Abe. 1999. Color image segmentation using ISODATA clustering algorithm. IEICE Trans on Information and Systems, J82D-II (April 1999), 751--762.", "Zexuan Ji, Yong Xia, Qiang Chen, et al., 2012. Fuzzy c-means clustering with weighted image patch for image segmentation. Applied Soft Computing. 12, 6 (June 2012), 1659--1667. DOI= 10.1016/j.asoc.2012.02.010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808540"}, {"title": "Exploiting Wikipedia for Information Retrieval Tasks", "authors": ["Bracha Shapira\n,", "Nir Ofek\n,", "Victor Makarenkov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWikipedia - the online encyclopedia - has long been used as a source of information for researchers, as well as being a subject of research itself. Wikipedia has been shown to be effective in recommender systems, sentiment analysis, validation and multiple domains in information retrieval. One of the reasons for Wikipedia's popularity among researchers and practitioners is the multiple types of information it contains, which enables practitioners to select the right \"tool\" for their respective tasks. In addition to its great potential, this multitude of information sources also poses a challenge: which sources of information are best suited for a specific problem and how can different types of data be combined? This tutorial aims to provide a holistic view of Wikipedia's different features - text, links, categories, page views, editing history etc. - and explore the different ways they can be utilized in a machine learning framework. By presenting and contrasting the latest works that utilize Wikipedia in multiple domains, this tutorial aims to increase the awareness among researchers and practitioners in these fields to the benefits of utilizing Wikipedia in their respective domains, in particular to the use of multiple sources of information simultaneously.", "references": ["B. Al-Shboul and S.-H. Myaeng. Query phrase expansion using wikipedia in patent class search. In Information Retrieval Technology, pages 115--126. Springer, 2011.", "O. Arazy, N. Kumar, and B. Shapira. A theory-driven design framework for social recommender systems. journal of the association for information research article, 2010.", "D. Buscaldi and P. Rosso. Mining knowledge from wikipedia for the question answering task. In Proceedings of the International Conference on Language Resources and Evaluation, pages 727--730, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767879"}, {"title": "Learning user preferences by adaptive pairwise comparison", "authors": ["Li Qian\n,", "Jinyang Gao\n,", "H. V. Jagadish"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nUsers make choices among multi-attribute objects in a data set in a variety of domains including used car purchase, job search and hotel room booking. Individual users sometimes have strong preferences between objects, but these preferences may not be universally shared by all users. If we can cast these preferences as derived from a quantitative user-specific preference function, then we can predict user preferences by learning their preference function, even though the preference function itself is not directly observable, and may be hard to express.\nIn this paper we study the problem of preference learning with pairwise comparisons on a set of entities with multiple attributes. We formalize the problem into two subproblems, namely preference estimation and comparison selection. We propose an innovative approach to estimate the preference, and introduce a binary search strategy to adaptively select the comparisons. We introduce the concept of an orthogonal query to support this adaptive selection, as well as a novel S-tree index to enable efficient evaluation of orthogonal queries.\nWe integrate these components into a system for inferring user preference with adaptive pairwise comparisons. Our experiments and user study demonstrate that our adaptive system significantly outperforms the naïve random selection system on both real data and synthetic data, with either simulated or real user feedback. We also show our preference learning approach is much more effective than existing approaches, and our S-tree can be constructed efficiently and perform orthogonal query at interactive speeds.", "references": ["R. Agrawal and E. L. Wimmers. A framework for expressing and combining preferences. SIGMOD, 29(2):297--306, 2000.", "C. F. Barnes, S. A. Rizvi, and N. M. Nasrabadi. Advances in residual vector quantization: a review. TIP, 1996.", "N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. The R*-tree: an efficient and robust access method for points and rectangles. ACM, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809992"}, {"title": "Kernelizing Spatially Consistent Visual Matches for Fine-Grained Classification", "authors": ["Vaentin Leveau\n,", "Alexis Joly\n,", "Olivier Buisson\n,", "Patrick Valduriez"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper introduces a new image representation relying on the spatial pooling of geometrically consistent visual matches. We therefore introduce a new match kernel based on the inverse rank of the shared nearest neighbors combined with local geometric constraints. To avoid overfitting and reduce processing costs, the dimensionality of the resulting over-complete representation is further reduced by hierarchically pooling the raw consistent matches according to their spatial position in the training images. The final image representation is obtained by concatenating the resulting feature vectors at several resolutions. Learning from these representations using a logistic regression classifier is shown to provide excellent fine-grained classification performances outperforming the results reported in the literature on several classification tasks.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2911--2918. IEEE, 2012.", "S. Boughorbel, J. P. Tarel, and N. Boujemaa. The intermediate matching kernel for image local features. In Neural Networks, 2005. IJCNN'05. Proceedings. 2005 IEEE International Joint Conference on, volume 2, pages 889--894. IEEE, 2005.", "Y. Chai, V. Lempitsky, and A. Zisserman. Symbiotic segmentation and part localization for fine-grained categorization. In Computer Vision (ICCV), 2013 IEEE International Conference on, pages 321--328. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749328"}, {"title": "Recognition of Compromised Accounts on Twitter", "authors": ["Rodrigo Augusto Igawa\n,", "Alex Marino Goncalves de Almeida\n,", "Bruno Bogaz Zarpelao\n,", "Sylvio Barbon"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn this work, we propose an approach for recognition of compromised Twitter accounts based on Authorship Verification. Our solution can detect accounts that became compromised by analysing their user writing styles. This way, when an account content does not match its user writing style, we affirm that the account has been compromised, similar to Authorship Verification. Our approach follows the profile-based paradigm and uses N-grams as its kernel. Then, a threshold is found to represent the boundary of an account writing style. Experiments were performed using a subsampled dataset from Twitter. Experimental results showed that the developed model is very suitable for compromised recognition of Online Social Networks accounts due to the capability of recognize user styles over 95% accuracy.", "references": ["S.-A. Bahrainian and A. Dengel. Sentiment analysis and summarization of twitter data. In Computational Science and Engineering (CSE), 2013 IEEE 16th International Conference on, pages 227-234. IEEE, 2013.", "S. Y. Bhat and M. Abulaish. Community-based features for identifying spammers in online social networks. In Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, pages 100-107. ACM, 2013.", "C. A. Bliss, I. M. Kloumann, K. D. Harris, C. M. Danforth, and P. S. Dodds. Twitter reciprocal reply networks exhibit assortativity with respect to happiness. Journal of Computational Science, 3(5):388-397, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814061"}, {"title": "Top-N Recommendation for Shared Accounts", "authors": ["Koen Verstrepen\n,", "Bart Goethals"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nStandard collaborative filtering recommender systems assume that every account in the training data represents a single user. However, multiple users often share a single account. A typical example is a single shopping account for the whole family. Traditional recommender systems fail in this situation. If contextual information is available, context aware recommender systems are the state-of-the-art solution. Yet, often no contextual information is available. Therefore, we introduce the challenge of recommending to shared accounts in the absence of contextual information. We propose a solution to this challenge for all cases in which the reference recommender system is an item-based top-N collaborative filtering recommender system, generating recommendations based on binary, positive-only feedback. We experimentally show the advantages of our proposed solution for tackling the problems that arise from the existence of shared accounts on multiple datasets.", "references": ["S. Anand and B. Mobasher. Contextual recommendation. In WebMine, pages 142--160, 2006.", "M. Deshpande and G. Karypis. Item-based top-n recommendation algorithms. TOIS, 22(1):143--177, 2004.", "C. Desrosiers and G. Karypis. A comprehensive survey of neighborhood-based recommendation methods. In F. Ricci, L. Rokach, B. Shapira, and P. Kantor, editors, Recommender Systems Handbook. Springer, Boston, MA, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800170"}, {"title": "Identifying Top-k Consistent News-Casters on Twitter", "authors": ["Sahisnu Mazumder\n,", "Sameep Mehta\n,", "Dhaval Patel"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNews-casters are Twitter users who periodically pick up interesting news from online news media and spread it to their followers' network. Existing works on Twitter user analysis have only analysed a pre-defined set of users for user modeling, influence analysis and news recommendation. The problem of identifying prominent, trustworthy and consistent news-casters is unaddressed so far. In this paper, we present a framework, NCFinder, to discover top-k consistent news-casters directly from Twitter. NCFinder uses news headlines published in online news sources to periodically collect authentic news-tweets and processes them to discover news-casters, news sources and news concepts. Next, NCFinder builds a tripartite graph among news-casters, news source and news concepts and employs HITS algorithm on it to score the news-casters on daily basis. The daily score profiles of the news-casters collected over a time-period are then used to infer top-$k$ consistent news-casters. We run NCFinder from 11th Nov. to 24th Nov., 2014 and discover top-100 consistent news-casters and their profile information.", "references": ["F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user modeling on twitter for personalized news recommendations. In User Modeling, Adaption and Personalization, 2011.", "C. Castillo, M. Mendoza, and B. Poblete. Information credibility on twitter. In WWW, 2011.", "J. M. Kleinberg. Authoritative sources in a hyperlinked environment. JACM, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806649"}, {"title": "Context- and Content-aware Embeddings for Query Rewriting in Sponsored Search", "authors": ["Mihajlo Grbovic\n,", "Nemanja Djuric\n,", "Vladan Radosavljevic\n,", "Fabrizio Silvestri\n,", "Narayan Bhamidipati"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch engines represent one of the most popular web services, visited by more than 85% of internet users on a daily basis. Advertisers are interested in making use of this vast business potential, as very clear intent signal communicated through the issued query allows effective targeting of users. This idea is embodied in a sponsored search model, where each advertiser maintains a list of keywords they deem indicative of increased user response rate with regards to their business. According to this targeting model, when a query is issued all advertisers with a matching keyword are entered into an auction according to the amount they bid for the query, and the winner gets to show their ad. One of the main challenges is the fact that a query may not match many keywords, resulting in lower auction value, lower ad quality, and lost revenue for advertisers and publishers. Possible solution is to expand a query into a set of related queries and use them to increase the number of matched ads, called query rewriting. To this end, we propose rewriting method based on a novel query embedding algorithm, which jointly models query content as well as its context within a search session. As a result, queries with similar content and context are mapped into vectors close in the embedding space, which allows expansion of a query via simple K-nearest neighbor search in the projected space. The method was trained on more than 12 billion sessions, one of the largest corpuses reported thus far, and evaluated on both public TREC data set and in-house sponsored search data set. The results show the proposed approach significantly outperformed existing state-of-the-art, strongly indicating its benefits and the monetization potential.", "references": ["M. Aly, A. Hatch, V. Josifovski, and V. K. Narayanan. Web-scale user modeling for targeting. WWW, 2012.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In Proceedings of the 2004 International Conference on Current Trends in Database Technology, EDBT'04, pages 588--596, Berlin, Heidelberg, 2004. Springer-Verlag.", "R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern information retrieval, volume 463. ACM press New York, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767709"}, {"title": "Location Prediction of Social Images via Generative Model", "authors": ["Xiaoming Zhang\n,", "Zhoujun Li\n,", "Senzhang Wang\n,", "Yang Yang\n,", "Xueqiang Lv"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe vast amount of geo-tagged social images has attracted great attention in research of predicting location using the plentiful content of images, such as visual content and textual description. Most of the existing researches use the text-based or vision-based method to predict location. There still exists a problem: how to effectively exploit the correlation between different types of content as well as their geographical distributions for location prediction. In this paper, we propose to predict image location by learning the latent relation between geographical location and multiple types of image content. In particularly, we propose a geographical topic model GTMSI (geographical topic model of social image) to integrate multiple types of image content as well as the geographical distributions. In GTMI, image topic is modeled on both text vocabulary and visual feature. Each region has its own distribution over topics and hence has its own language model and vision pattern. The location of a new image is estimated based on the joint probability of image content and similarity measure on topic distribution between images. Experiment results demonstrate the performance of location prediction based on GTMSI.", "references": ["J. Hays, and A. Efros. im2gps: estimating geographic information from a single image. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 1--8. IEEE Press, New York, 2008.", "D. Crandall, L. Backstrom, D. Huttenlocher, and J. Kleinberg. Mapping the world's photos. In WWW, 2009.", "Z. Yin, L. Cao, J. Han, C. Zhai, and T. Huang. Geographical topic discovery and comparison. In WWW, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749308"}, {"title": "A patent quality classification model based on artificial immune system", "authors": ["Cheng-Chin Tsao\n,", "Chin-Yuan Fan\n,", "Pei-Chann Chang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nPatents for companies are potentially a business and financial asset which can place competitors' development, thus patent analysis is important of defining business strategies and supporting decision making in organizations. However, patent information is consisted of vast data sets of information. Therefore, the main propose of this study is to apply an artificial immune system (AIS) hybrid collaborative filtering to build a patent quality classification model to predict patent quality of RFID industry. We defined each patent data as an antibody, then compute the affinities of the target patent to all immune networks. If the affinity is larger than the given threshold, the antibody was cloned to the related immune network. After immune networks constructed, the quality of target patent was predicted by the immune networks which with high affinity to the target patent. Finally, a series of experiments are conducted, and the results the proposed model can accurately predict the quality of new patent. By this study, we can provide an automatic patent quality classification model to assist manufacturers to provide excellent sight into a company's product direction and long-term vision.", "references": ["Trappey, A. J. C., Trappey, C. V., Wu, C. Y. and Lin, C. L. 2012. A patent quality analysis for innovative technology and product development. Adv Eng Inform. 26, 26--34.", "Trappey, A. J. C., Trappey, C. V., Wu, C. Y. W., Fan, C. Y. and Lin, Y. L. 2013. Intelligent patent recommendation system for Innovative design collaboration. Journal of Network and Computer Applications. 36, 1441--1450.", "Abbas, A., Zhang, L. and Khan, S. U. 2014. A literature review on the state-of-the-art in patent analysis. World Patent Information. 37, 3--13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818872"}, {"title": "Estimating the Uncertainty of Average F1 Scores", "authors": ["Dell Zhang\n,", "Jun Wang\n,", "Xiaoxue Zhao"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn multi-class text classification, the performance (effectiveness) of a classifier is usually measured by micro-averaged and macro-averaged F1 scores. However, the scores themselves do not tell us how reliable they are in terms of forecasting the classifier's future performance on unseen data. In this paper, we propose a novel approach to explicitly modelling the uncertainty of average F1 scores through Bayesian reasoning.", "references": ["C. Goutte and E. Gaussier. A probabilistic interpretation of precision, recall and F-score, with implication for evaluation. In Proceedings of the 27th European Conference on IR Research (ECIR), pages 345--359, Santiago de Compostela, Spain, 2005.", "D. Koller and N. Friedman. Probabilistic Graphical Models - Principles and Techniques. MIT Press, 2009.", "J. K. Kruschke. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. Academic Press, 2nd edition, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809488"}, {"title": "A Framework for Enhancing the Query and Medical Record Representations for Patient Search", "authors": ["Nut Limsopatham"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThis thesis focuses on enhancing the search of electronic medical records (EMRs), with the aim of identifying patients with medical histories relevant to the medical conditions stated in a text query. During retrieval, a healthcare practitioner indicates a number of inclusion criteria describing the medical conditions of the patients of interest. However, finding patients with particular medical conditions is challenging, due to the implicit knowledge inherent within the patients' medical records and queries - such knowledge may be known by medical practitioners, but may be hidden from an information retrieval (IR) system. For instance, the mention of a treatment such as a drug may indicate to a practitioner that a particular diagnosis has been made for the patient, but this diagnosis may not be explicitly mentioned in the patient's medical records. Moreover, the use of negated language (e.g. 'without', 'no') to describe a medical condition of a patient (e.g. the patient has no fever) may cause a search system to erroneously retrieve that patient for a query when searching for patients with that medical condition (e.g. find patients with fever). To attain effective retrieval performance, we hypothesise that, in a patient search system, both the information needs and patients' histories should be represented based upon the medical decision process. In particular, this thesis argues that since the medical decision process typically encompasses four aspects (symptom, diagnostic test, diagnosis and treatment), a patient search system should take into account these aspects and apply inferences to recover the possible implicit knowledge. We postulate that considering these aspects and their derived implicit knowledge at three different levels of the retrieval process (namely, sentence, medical record and interrecord levels) enhances the retrieval performance. Indeed, we propose a novel framework that can gain insights from EMRs and queries, by modelling and reasoning upon informationduring retrieval in terms of the four aforementioned aspects at the three levels of the retrieval process, and can use these insights to enhance patient search.\nFirstly, at the sentence level, we extract the medical conditions in the medical records and queries. In particular, we propose to represent only the medical conditions related to the four medical aspects in order to improve the accuracy of our search system. In addition, we identify the context (negative/positive) of terms, which leads to an accurate representation of the medical conditions both in the EMRs and queries. In particular, we aim to prevent patients whose EMRs state the medical conditions in the contexts different from the query from being ranked highly. For example, preventing patients whose EMRs state \"no history of dementia\" from being retrieved for a query searching for patients with dementia.\nSecondly, at the medical record level, using external knowledge-based resources (e.g. ontologies and health-related websites), we leverage the relationships between medical terms to infer the wider medical history of the patient in terms of the four medical aspects. In particular, we estimate the relevance of a patient to the query by exploiting association rules that we extract from the semantic relationships between medical terms using the four aspects of the medical process. For example, patients with a medical history involving a CABG surgery (treatment) can be inferred as relevant to a query searching for a patient suffering from heart disease (diagnosis), since a CABG surgery is a treatment of heart disease.\nThirdly, at the inter-record level, we enhance the retrieval of patients in two different manners. First, we exploit knowledge about how the four medical aspects are handled by different hospital departments to gain a better understanding about the appropriateness of EMRs created by different departments for a given query. We propose to aggregate EMRs at the department level (i.e. inter-record level) to extract implicit knowledge (i.e. the expertise of each department) and model this department's expertise, while ranking patients. For instance, patients having EMRs from the cardiology department are likely to be relevant to a query searching for patients who suffered from a heart attack. Second, as a medical query typically contains several medical conditions that the relevant patients should satisfy, we propose to explicitly model the relevance towards multiple query medical conditions in the EMRs related to a particular patient during retrieval. In particular, we rank highly those patients that match all the stated medical conditions in the query by adapting coverage-based diversification approaches originally proposed for the web search domain.\nFinally, we examine the combination of our aforementioned approaches that exploit the implicit knowledge at the three levels of the retrieval process to further improve the retrieval performance by adapting techniques from the fields of data fusion and machine learning. In particular, data fusion techniques, such as CombSUM and CombMNZ, are used to combine the relevance scores computed by the different approaches of the proposed framework. On the other hand, we deploy state-of-the-art learning to rank approaches (e.g. LambdaMART and AdaRank) to learn from a set of training data an effective combination of the relevance scores computed by the approaches of the framework. In addition, we introduce a novel selective ranking approach that uses a classifier to effectively apply one of the approaches of the framework on a per-query basis.\nThis thesis draws insights from a thorough evaluation and analysis of the proposed framework using a standard test collection provided by the TREC Medical Records track. The experimental results show the effectiveness of the framework. In particular, the results demonstrate the importance of dealing with the implicit knowledge in patient search by focusing on the medical decision criteria aspects at the three levels of the retrieval process.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795420"}, {"title": "Spatial online sampling and aggregation", "authors": ["Lu Wang\n,", "Robert Christensen\n,", "Feifei Li\n,", "Ke Yi"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe massive adoption of smart phones and other mobile devices has generated humongous amount of spatial and spatio-temporal data. The importance of spatial analytics and aggregation is ever-increasing. An important challenge is to support interactive exploration over such data. However, spatial analytics and aggregation using all data points that satisfy a query condition is expensive, especially over large data sets, and could not meet the needs of interactive exploration. To that end, we present novel indexing structures that support spatial online sampling and aggregation on large spatial and spatio-temporal data sets. In spatial online sampling, random samples from the set of spatial (or spatio-temporal) points that satisfy a query condition are generated incrementally in an online fashion. With more and more samples, various spatial analytics and aggregations can be performed in an online, interactive fashion, with estimators that have better accuracy over time. Our design works well for both memory-based and disk-resident data sets, and scales well towards different query and sample sizes. More importantly, our structures are dynamic, hence, they are able to deal with insertions and deletions efficiently. Extensive experiments on large real data sets demonstrate the improvements achieved by our indexing structures compared to other baseline methods.", "references": ["S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Madden, and I. Stoica. BlinkDB: queries with bounded errors and bounded response times on very large data. In EuroSys, 2013.", "S. Agarwal, A. Panda, B. Mozafari, A. P. Iyer, S. Madden, and I. Stoica. Blink and it's done: Interactive queries on very large data. In PVLDB, volume 5, 2012.", "L. Arge. The buffer tree: A technique for designing batched external data structures. Algorithmica, 37(1):1--24, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2850583.2850584"}, {"title": "Towards OLAP Analysis of Multidimensional Tweet Streams", "authors": ["Alfredo Cuzzocrea\n,", "Carmen De Maio\n,", "Giuseppe Fenza\n,", "Vincenzo Loia\n,", "Mimmo Parente"], "publication": "DOLAP '15: Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP", "abstract": "ABSTRACT\nSocial media and networks are used by millions of people to share with their friends across the world: tastes, opinions, ideas, etc. The volume and the speed at which these data are produced make it a challenging task to discover meaningful patterns in the data. Nevertheless, very interesting business goals could be achieved collecting these data and performing analytics on social media data streams, such as: addressing marketing strategies, targeting advertisements, and so forth. We emphasize that there is a need to investigate and define suitable knowledge mining approaches to go beyond explicitly available metadata by analyzing unstructured data to provide intelligent analytics services. Specifically, in this paper we provide first results on applying OLAP analysis to multidimensional Tweet streams.", "references": ["S. Bringay, N. Béchet, F. Bouillot, P. Poncelet, M. Roche, M. Teisseire, Towards an on-line analysis of tweets processing, in: Database and Expert Systems Applications, Springer, 2011, pp. 154--161.", "P. Buitelaar, D. Olejnik, M. Sintek. A Protg plug-in for ontology extraction from text based on linguistic analysis. The Semantic Web: Research and Applications. Springer Berlin Heidelberg, 2004, 31--44.", "W. C. Cho and D. Richards. 2007. Ontology construction and concept reuse with formal concept analysis for improved web document retrieval. Web Intelli. and Agent Sys. 5, 1 (January 2007), 109--126."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811222.2811233"}, {"title": "RecSys Challenge 2015: ensemble learning with categorical features", "authors": ["Peter Romov\n,", "Evgeny Sokolov"], "publication": "RecSys '15 Challenge: Proceedings of the 2015 International ACM Recommender Systems Challenge", "abstract": "ABSTRACT\nIn this paper, we describe the winning approach for the RecSys Challenge 2015. Our key points are (1) two-stage classification, (2) massive usage of categorical features, (3) strong classifiers built by gradient boosting and (4) threshold optimization based directly on the competition score. We describe our approach and discuss how it can be used to build scalable personalization systems.", "references": ["D. Ben-Shimon, A. Tsikinovsky, M. Friedman, B. Shapira, L. Rokach, and J. Hoerle. Recsys challenge 2015 and the yoochoose dataset. In Proceedings of the 9th ACM conference on Recommender systems. ACM, September 2015.", "J. Friedman. Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29:1189--1232, 2000.", "A. Gulin. Matrixnet. Technical report, 2012. http://www.slideshare.net/yandex/matrixnet."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813448.2813510"}, {"title": "Twitter use by politicians during social uprisings: an analysis of Gezi park protests in Turkey", "authors": ["Naci Karkın\n,", "Nilay Yavuz\n,", "İsmet Parlak\n,", "Özlem Özdeşim İkiz"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nSocial uprisings clearly show that social media tools, especially Twitter, help news spread more than the press does recently. In some cases Twitter substitutes traditional media if censorship is enlarged to such a level that the mainstream media channels prefer not to reflect the actual volume of the protests. Twitter is also utilized by politicians during such events to reinforce \"us vs. them\" division, and to gain support and legitimization for their own actions. Using critical discourse analysis, this paper aims to investigate the recurring speech patterns in the tweets of top-level politicians during the Gezi Park protests that started in Istanbul Turkey in June 2013 and spread the country rapidly. We study the tweets to draw conclusions on whether the politicians' statements represent marginalization and polarization efforts during the Gezi Park protests. In this paper, we consider social uprising as a communal expression of both political and apolitical opposition to the party in power. Our analysis reveals that the politicians' tweets are mainly characterized by a discourse that guides the public into some conscious direction that may reproduce marginalization and polarization among the public at large.", "references": ["Azab, N. A. 2012. The Role of the Internet in Shaping the Political Process in Egypt, International Journal of E-Politics, vol. 3, no. 2, pp. 31--51.", "Baker, S. Alice. 2012. \"From the criminal crowd to the \"mediated crowd\": the impact of social media on the 2011 English riots,\" Safer Communities (11:1), 40--49.", "Barberá, P., & Metzger, M. (2013). A breakout role for Twitter? The role of social media in the Turkish protests. Social media and political participation lab data report, New York University. Retrieved from: http://smapp.nyu.edu/reports/turkey_data_report.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757430"}, {"title": "Discovery of Spatiotemporal Chaining Patterns", "authors": ["Bo-Heng Chen\n,", "Ai-Wei Chuang\n,", "Kun-Ta Chuang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nSpatiotemporal pattern mining attempts to discover unknown, potentially interesting and useful event sequences where events occur within a specific time interval and region. Previous works use partition-based or ill-defined representation of spatial objects which will miss some spatial properties in original spatiotemporal data. Moreover, the problem of non-transactional spatiotemporal database can not be resolved by traditional sequential pattern mining. In this paper, we propose an practical approach to retain the disappearance of spatial correlation which is caused by improper data representation, called Spatiotemporal Frequent Pattern Mining (abbreviated as STFPM), to discover frequent sequential spatiotemporal pattern. Finally, with a case study of crime pattern analysis, our experimental studies show that the proposed (STFPM) framework effectively discovers high-quality spatiotemporal patterns.", "references": ["R. Agrawal, C. Faloutsos, and A. N. Swami. Efficient similarity search in sequence databases. In Proceedings of International Conference on Foundations of Data Organization and Algorithms, 1993.", "R. Agrawal, K. ip Lin, H. S. Sawhney, and K. Shim. Fast similarity search in the presence of noise, scaling, and translation in time-series databases. In Proceedings of International Conference on Very Large Data Bases, 1995.", "R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In Proceedings of International Conference on Very Large Data Bases, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818876"}, {"title": "Statistical Significance Testing in Information Retrieval: Theory and Practice", "authors": ["Ben Carterette"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe past 20 years have seen a great improvement in the rigor of information retrieval experimentation, due primarily to two factors: high-quality, public, portable test collections such as those produced by TREC (the Text REtrieval Conference [28]), and the increased practice of sta- tistical hypothesis testing to determine whether measured improvements can be ascribed to something other than random chance. Together these create a very useful standard for reviewers, program committees, and journal editors; work in information retrieval (IR) increasingly cannot be published unless it has been evaluated using a well-constructed test collection and shown to produce a statistically significant improvement over a good baseline.\nBut, as the saying goes, any tool sharp enough to be useful is also sharp enough to be dangerous. Statistical tests of significance are widely misunderstood. Most researchers and developers treat them as a \"black box\": evaluation results go in and a p-value comes out. But because significance is such an important factor in determining what research directions to explore and what is published, using p-values obtained without thought can have consequences for everyone doing research in IR. Ioannidis has argued that the main consequence in the biomedical sciences is that most published research findings are false [12]; could that be the case in IR as well?", "references": ["Timothy G. Armstrong, Alistair Moffat, William Webber, and Justin Zobel. Improvements that don't add up: ad-hoc retrieval results since 1998. In Proceedings of CIKM, pages 601--610, 2009.", "James O. Berger. Could Fisher, Jeffreys and Neyman have agreed on testing? Statistical Science, 18(1):1--32.", "Leonid Boytsov, Anna Belova, and Peter Westfall. Deciding on an adjustment for multiplicity in IR experiments. In Proceedings of SIGIR, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809445"}, {"title": "CrowdBuild: a methodology for enterprise software development using crowdsourcing", "authors": ["Anurag Dwarakanath\n,", "Upendra Chintala\n,", "Shrikanth N. C.\n,", "Gurdeep Virdi\n,", "Alex Kass\n,", "Anitha Chandran\n,", "Shubhashis Sengupta\n,", "Sanjoy Paul"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nWe present and evaluate a software development methodology that addresses key challenges for the application of Crowdsourcing to an enterprise application development. Our methodology presents a mechanism to systematically break the overall business application into small tasks such that the tasks can be completed independently and in parallel by the crowd. Our methodology supports automated testing and automatic integration. We evaluate our methodology by developing a web application through Crowdsourcing. The methodology was tested through two Crowdsourcing models: one through contests and the other through hiring freelancers. We present various metrics of the Crowdsourcing experiment and compare against the estimate for the traditional software development methodology.", "references": ["apps.topcoder.com/wiki/display/docs/Styx+-+MCS+Upgrade+Conceptualization (Retrieved on 22nd Jan. 2015).", "apps.topcoder.com/wiki/display/docs/Styx+MCS+Thick+Client+System+Architecture (Retrieved on 22nd Jan. 2015).", "apps.topcoder.com/wiki/display/docs/Styx+MCS+Thick+Client+RIA+Build (Retrieved on 30th Jan 2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820118"}, {"title": "Improvement of Collaborative Filtering Systems through Resource Description Framework", "authors": ["Kharroubi Sahraoui\n,", "Dahmani youcef\n,", "Nouali Omar"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nThe huge mass of data generated continuously leads to information overload which limit the tools available to manage, store and secure this traffic on the web. The situation is paradoxical, a need for timely relevant information and the difficulty to btain this information because it is lost in the mass. The use of fully search engine based on the formulation of the request by users show some limitations. The trend is to improve the information filtering approaches to better answer the user's expectations. In this work, we modelled a collaborative filtering system by Friend Of A Friend (FOAF) formalism for the representation of the users and the Dublin Core (DC) vocabulary to represent the resources \" items\". In addition, and to ensure the interoperability and openness of this model, we adopted the Resource Description Framework (RDF) syntax to describe the various modules of the system. A hybrid function was introduced for the calculation of prediction. The empirical tests on various real data sets (Book-Crossing, FoafPub) showed satisfactory performances in relevance and precision.", "references": ["Adomavicius, G. and Tuzhilin, A. 2005. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering. 17, 6, 734--749.", "Hassanzadeh, H., Keyvanpour, M. R 2012. Semantic Web Requirements through Web Mining Techniques., IJCTE. 4, 4 (August 2012), 616--620.", "Meyffret, S., Medini, L., Laforest, F. 2013. Confidence on Collaborative Filtering and Trust-Based Recommendations. Chapter in Ec-Web technologies spinger, 156, 162--173."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816863"}, {"title": "SPS'15: 2015 International Workshop on Social Personalization & Search", "authors": ["Christoph Trattner\n,", "Denis Parra\n,", "Peter Brusilovsky\n,", "Leandro Marinho"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["A. Bellogın, I. Cantador, and P. Castells. A comparative study of heterogeneous item recommendations in social systems. Inf. Sci., 221:142--169, 2013.", "E. Lacic, D. Kowald, L. Eberhard, C. Trattner, D. Parra, and L. B. Marinho. Utilizing online social network and location-based data to recommend products and categories in online marketplaces. In Mining, Modeling, and Recommending 'Things' in Social Media, pages 96--115. 2015.", "D. Lee and P. Brusilovsky. Recommending talks at research conferences using users' social networks. IJCIS, 23(02), 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767859"}, {"title": "Bringing CUPID Indoor Positioning System to Practice", "authors": ["Souvik Sen\n,", "Dongho Kim\n,", "Stephane Laroche\n,", "Kyu-Han Kim\n,", "Jeongkeun Lee"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWiFi based indoor positioning has recently gained more attention due to the advent of the IEEE 802.11v standard, requirements by the FCC for E911 calls, and increased interest in location-based services. While there exist several indoor localization techniques, we find that these techniques tradeoff either accuracy, scalability, pervasiveness or cost -- all of which are important requirements for a truly deployable positioning solution. Wireless signal-strength based approaches suffer from location errors, whereas time-of-flight (ToF) based solutions provide good accuracy but are not scalable. Recent solutions address these issues by augmenting WiFi with either smartphone sensing or mobile crowdsourcing. However, they require tight coupling between WiFi infrastructure and a client device, or they can determine the client's location only if it is mobile. In this paper, we present CUPID2.0 which improved our previously proposed CUPID indoor positioning system to overcome these limitations. We achieve this by addressing the fundamental limitations in Time-of-Flight based localization and combining ToF with signal strength to address scalability. Experiments from $6$ cities using $40$ different mobile devices, comprising of more than $2.5$ million location fixes demonstrate feasibility. CUPID2.0 is currently under production, and we expect CUPID2.0 to ignite the wide adoption of WLAN-based positioning systems and their services.", "references": ["Techcrunch. How the 49ers are using beacons to help you find hot dogs. URL http://techcrunch.com/2014/11/04/how-the-49ers-are-using-beacons-to-help-you-find-hot-dogs-and-beer/, 2014.", "Shopkick. Shopkick retail platform. URL http://www.shopkick.com/.", "Techcrunch. Wifarer brings indoor navigation to the royal bc museum. URL http://techcrunch.com/2012/08/01/wifarer-brings-indoor-navigation-to-the-royal-bc-museum/, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741686"}, {"title": "Finding top-k relevant groups of spatial web objects", "authors": ["Anders Skovsgaard\n,", "Christian S. Jensen"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe web is increasingly being accessed from geo-positioned devices such as smartphones, and rapidly increasing volumes of web content are geo-tagged. In addition, studies show that a substantial fraction of all web queries has local intent. This development motivates the study of advanced spatial keyword-based querying of web content. Previous research has primarily focused on the retrieval of the top-k individual spatial web objects that best satisfy a query specifying a location and a set of keywords. This paper proposes a new type of query functionality that returns top-k groups of objects while taking into account aspects such as group density, distance to the query, and relevance to the query keywords. To enable efficient processing, novel indexing and query processing techniques for single and multiple keyword queries are proposed. Empirical performance studies with an implementation of the techniques and real data suggest that the proposals are viable in practical settings.", "references": ["Amitay, E., Har'El, N., Sivan, R., Soffer, A.: Web-a-where: geotagging web content. In: SIGIR, 273---280 (2004)", "BØgh, K., Skovsgaard, A., Jensen, C.S.: Groupfinder: a new approach to top-k point-of-interest group retrieval. PVLDB 6(12), 1226---1229 (2013)", "Cao, X., Chen, L., Cong, G., Jensen, C.S., Qu, Q., Skovsgaard, A., Wu, D., Yiu, M. L.: Spatial keyword querying. In: Atzeni P., Cheung, D., Ram S. (eds.) Conceptual Modeling. Proceedings of the 31st International Conference ER 2012, Florence, Italy, October 15---18, 2012. Lecture Notes in Computer Science, vol. 7532, pp 16---29. Springer, Berlin, Heidelberg (2012)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0388-z"}, {"title": "Finding the Right Social Media Site for Questions", "authors": ["Zhen Yang\n,", "Isaac Jones\n,", "Xia Hu\n,", "Huan Liu"], "publication": "ASONAM '15: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015", "abstract": "ABSTRACT\nSocial media has become a part of our daily life and we use it for many reasons. One of its uses is to get our questions answered. Given a multitude of social media sites, however, one immediate challenge is to pick the most relevant site for a question. This is a challenging problem because (1) questions are usually short, and (2) social media sites evolve. In this work, we propose to utilize topic specialization to find the most relevant social media site for a given question. In particular, semantic knowledge is considered for topic specialization as it can not only make a question more specific, but also dynamically represent the content of social sites, which relates a given question to a social media site. Thus, we propose to rank social media sites based on combined search engine query results. Our algorithm yields compelling results for providing a meaningful and consistent site recommendation. This work helps further understand the innate characteristics of major social media platforms for the design of social Q&A systems.", "references": ["R. Zafarani and H. Liu, \"Users joining multiple sites: Distributions and patterns,\" in Proceedings of the Eighth International AAAI Conference on Weblogs and Social Media, (Ann Arbor, MI), pp. 635--638, AAAI Press, June 2014.", "M. Efron and M. Winget, \"Questions are content: A taxonomy of questions in a microblogging environment,\" in Proceedings of the American Society for Information Science and Technology, (Austin, Texas), pp. 1--10, AAAI Press, August 2010.", "A. Paul, L. Hong, and H. Chi, \"Is twitter a good place for asking questions?: A characterization study,\" in Proceedings of the International Conference on Weblogs and Social Media, (Barcelona, Spain), pp. 17-- 21, AAAI Press, July 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808797.2809391"}, {"title": "Improving the Accuracy of Document Similarity Approach using Word Sense Disambiguation", "authors": ["G. Veena\n,", "U. B. Umesha Sree Veni"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nThe aspects of Artificial Intelligence and statistics such as Text mining, Data Mining can provide solutions to the area of concept mining. It provides powerful insights into the meaning and documents similarity without exploiting the semantics of the terms or phrases in the document. Our work determines the similarity of documents using semantic processing namely Word Sense Disambiguation by annotating the senses of the words in the documents and then performs traditional PageRank algorithm over it. The Algorithm ranks the possible senses and finds the correct sense according to the context. Our paper proposes the method of disambiguating the ambiguous words in order to find the document similarity. Moreover it is compared with the cosine similarity approach, which is frequently used to determine similarity between two documents to prove the accuracy of our work.", "references": ["Veena, G., and N. K. Lekha. \"A concept based clustering model for document similarity.\" Data Science & Engineering (ICDSE), 2014 International Conference on. IEEE, 2014.", "Veena G., and N. K. Lekha. \"An Extended Chameleon Algorithm for Document Clustering.\" Advances in Intelligent Informatics. Springer International Publishing, 2015. 335--348.", "Agirre, Eneko, and Aitor Soroa. \"Using the Multilingual Central Repository for Graph-Based Word Sense Disambiguation.\" LREC. 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791426"}, {"title": "UWB Indoor Tracking System for Visually Impaired People", "authors": ["Suheer Alhadhrami\n,", "Ahmad Alnafessah\n,", "Mai Al-Ammar\n,", "Abdulrahman Alarifi\n,", "Hend Al-khalifa\n,", "Mansour Alsaleh"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nTracking is a process that captures knowledge of the path of an object's movement and its current location. This paper proposes an ultra-wideband (UWB) indoor tracking system for blind people in a high interference environment such as facilities with communication equipment. To the best of our knowledge, our proposed system is the first that offers two features (1) server-based tracking, in which the administrator can get the current position and the path of the blind person in question; and (2) situation awareness, in which the blind person can get voice information about existing and surrounding places. The system has shown satisfactory results when it was used and evaluated by some blind participants.", "references": ["M. Al-Ammar, S. Alhadhrami, A. Al-Salman, A. Alarifi, H. S. Al-Khalifa, A. Alnafessah, M. Alsaleh, et al. Comparative survey of indoor positioning technologies, techniques, and algorithms. In Cyberworlds (CW), 2014 International Conference on, pages 245--252. IEEE, 2014.", "M. A. Al-Ammar, H. S. Al-Khalifa, and A. S. Al-Salman. A proposed indoor navigation system for blind individuals. In Proceedings of the 13th International Conference on Information Integration and Web-based Applications and Services, pages 527--530. ACM, 2011.", "S. A. Alhadhrami, A. Alarifi, A. S. Al-Ammar, Mai A Al-Salman, A. Alnafeesa, H. S. Al-Khalifa, and M. Alsaleh. Ultra wideband positioning: An analytical study of emerging technologies. In SENSORCOMM 2014: The Eighth International Conference on Sensor Technologies and Applications, pages 66--74. IARIA, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2837141"}, {"title": "Cross-media Topic Detection with Refined CNN based Image-Dominant Topic Model", "authors": ["Zhiyi Wang\n,", "Liang Li\n,", "Qingming Huang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nOnline heterogenous data is springing up while the data has the rich auxiliary information (e.g. pictures and videos) around the text. However, traditional topic models are suffering from the limitations to discover the topics effectively from the cross-media data. Incorporating with the convolutional neural network (CNN) feature, we propose a novel image dominant topic model, which projects both the text modality and the visual modality into a semantic simplex. Further, an improved CNN feature is introduced to capture more visual details by fusing the convolutional layer and fully-connected layer. Experimental comparisons with state-of-the-art methods in the cross-media topic detection task show the effectiveness of our model.", "references": ["D. M. Blei and M. I. Jordan. Modeling annotated data. In ACM SIGIR, pages 127--134, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "J. Cao, Y. D. Zhang, Y. C. Song, Z. N. Chen, X. Zhang, and J. T. Li. Mcg-webv: A benchmark dataset for web video analysis. Beijing: Institute of Computing Technology, 10:324--334, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806309"}, {"title": "The HathiTrust Research Center: Providing analytic access to the HathiTrust Digital Library's 4.7 billion pages", "authors": ["J. Stephen Downie"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis lecture provides an update on the recent developments and activities of the HathiTrust Research Center (HTRC). The HTRC is the research arm of the HathiTrust, an online repository dedicated to the provision of access to a comprehensive body of published works for scholarship and education. The HathiTrust is a partnership of over 100 major research institutions and libraries working to ensure that the cultural record is preserved and accessible long into the future. Membership is open to institutions worldwide. Over 13.1 million volumes (4.7 billion pages) have been ingested into the HathiTrust digital archive from sources including Google Books, member university libraries, the Internet Archive, and numerous private collections. The HTRC is dedicated to facilitating scholarship by enabling analytic access to the corpus, developing research tools, fostering research projects and communities, and providing additional resources such as enhanced metadata and indices that will assist scholars to more easily exploit the HathiTrust materials.\nThis talk will outline the mission, goals and structure of the HTRC. It will also provide an overview of recent work being conducted on a range of projects, partnerships and initiatives. Projects include Workset Creation for Scholarly Analysis project (WCSA, funded by the Andrew W. Mellon Foundation) and the HathiTrust + Bookworm project (HT+BW, funded by the National Endowment for the Humanities). HTRC's involvement with the NOVEL(TM) text mining project and the Single Interface for Music Score Searching and Analysis (SIMSSA) project, both funded by the SSHRC Partnership Grant programme, will be introduced. The HTRC's new feature extraction and Data Capsule initiatives, part of its ongoing work its ongoing efforts to enable the non-consumptive analyses of the approximately 8 million volumes under copyright restrictions will also be discussed. The talk will conclude with some suggestions on how the non-consumptive research model might be improved upon and possibly extended beyond the HathiTrust context.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2771494"}, {"title": "PocketTrend: Timely Identification and Delivery of Trending Search Content to Mobile Users", "authors": ["Gennady Pekhimenko\n,", "Dimitrios Lymberopoulos\n,", "Oriana Riva\n,", "Karin Strauss\n,", "Doug Burger"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nTrending search topics cause unpredictable query load spikes that hurt the end-user search experience, particularly the mobile one, by introducing longer delays. To understand how trending search topics are formed and evolve over time, we analyze 21 million queries submitted during periods where popular events caused search query volume spikes. Based on our findings, we design and evaluate PocketTrend, a system that automatically detects trending topics in real time, identifies the search content associated to the topics, and then intelligently pushes this content to users in a timely manner. In that way, PocketTrend enables a client-side search engine that can instantly answer user queries related to trending events, while at the same time reducing the impact of these trends on the datacenter workload. Our results, using real mobile search logs, show that in the presence of a trending event, up to 13-17% of the overall search traffic can be eliminated from the datacenter, with as many as 19% of all users benefiting from PocketTrend.", "references": ["M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data Center TCP (DCTCP). In Proc. of SIGCOMM, pages 63--74, 2010.", "R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. The impact of caching on search engines. In Proc. of SIGIR, pages 183--190, 2007.", "R. Baeza-yates, F. Junqueira, V. Plachouras, and H. F. Witschel. Admission policies for caches of search engine results. In Proc. of the 14th String Processing and Information Retrieval Symposium, volume 4726 of LNCS, pages 74--85, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741641"}, {"title": "Unsupervised learning of an extensive and usable taxonomy for DBpedia", "authors": ["Marco Fossati\n,", "Dimitris Kontokostas\n,", "Jens Lehmann"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nIn the digital era, Wikipedia represents a comprehensive cross-domain source of knowledge with millions of contributors. The DBpedia project transforms Wikipedia content into RDF and currently plays a crucial role in the Web of Data as a central multilingual interlinking hub. However, its main classification system depends on human curation, which causes it to lack coverage, resulting in a large amount of untyped resources. We present an unsupervised approach that automatically learns a taxonomy from the Wikipedia category system and extensively assigns types to DBpedia entities, through the combination of several interdisciplinary techniques. It provides a robust backbone for DBpedia knowledge and has the benefit of being easy to understand for end users. Crowdsourced online evaluations demonstrate that our strategy outperforms state-of-the-art approaches both in terms of coverage and intuitiveness.", "references": ["A. P. Aprosio, C. Giuliano, and A. Lavelli. Towards an automatic creation of localized versions of dbpedia. In The Semantic Web--ISWC 2013, pages 494--509. Springer, 2013.", "C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. Dbpedia - a crystallization point for the web of data. Web Semantics: Science, Services and Agents on the World Wide Web, 7(3):154--165, 2009.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the international conference on Management of data, pages 1247--1250. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814881"}, {"title": "IBEX: Harvesting Entities from the Web Using Unique Identifiers", "authors": ["Aliaksandr Talaika\n,", "Joanna Biega\n,", "Antoine Amarilli\n,", "Fabian M. Suchanek"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nIn this paper we study the prevalence of unique entity identifiers on the Web. These are, e.g., ISBNs (for books), GTINs (for commercial products), DOIs (for documents), email addresses, and others. We show how these identifiers can be harvested systematically from Web pages, and how they can be associated with humanreadable names for the entities at large scale.\nStarting with a simple extraction of identifiers and names from Web pages, we show how we can use the properties of unique identifiers to filter out noise and clean up the extraction result on the entire corpus. The end result is a database of millions of uniquely identified entities of different types, with an accuracy of 73--96% and a very high coverage compared to existing knowledge bases. We use this database to compute novel statistics on the presence of products, people, and other entities on the Web.", "references": ["R. Agrawal and S. Ieong. Aggregating Web offers to determine product prices. In KDD, 2012.", "A. Arasu and H. Garcia-Molina. Extracting structured data from Web pages. In SIGMOD, 2003.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. G. Ives. DBpedia: A nucleus for a Web of open data. In ISWC, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767116"}, {"title": "Urgent question detection based on the review points and sentiment words", "authors": ["Koji Wajima\n,", "Tetsuji Satoh"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nTo response to customers during business activities, it is required to quickly find out the important question articles that need to be responded to promptly. This paper offers a proposal of priority judgment method based on the sentiment words inside these question articles in cases of large amounts of questions to services or products.\nThe proposed method uses LDA which is known as an \"unsupervised learning technique\" to extract question articles as the \"question target\", and then the question target part referred in questions, known as the \"review points\" are extracted by KeyGraph based on question targets. For those emotions of question articles' authors from extracted review points, evaluation expression dictionary is used to give \"sentiment words\" to question articles. For the composition of question targets and review points, question articles with more negative emotions are considered higher priority. The proposed method is applied to the question articles registered in the online support community to perform a priority judgment experiment of them. After comparing the ranking of priorities given by users with support center experience, it is proved that the proposed method could correctly judge articles with high priority and the sentiment words given to articles with medium priority are also effective. In addition, its accuracy has also been improved while comparing to previous studies.", "references": ["Yokoyama, Y., Hochin, T., Nomiya, H., and Satoh, T.: Improvement of Estimation Accuracy of Factor Scores from Feature Values of Statements, IIAI/ACIS IEIS 2012, pp. 300--305, 2012.", "Oh, J.-H., Torisawa, K., Hashimoto, C., Kawada, T., Saeger, S., Kazama, J., and Wang, Y.: Why question answering using sentiment analysis and word classes. EMNLP-CoNLL '12, pp. 368--378, 2012.", "Harada, M., Kato, Y., Takehara, K., Kawamata, M., Sugimura, K., and Kawaguchi, J.: QA System Metis Based on Semantic Graph Matching. NTCIR-6, pp. 448--459, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837252"}, {"title": "A Framework for Collocation Error Correction in Web Pages and Text Documents", "authors": ["Alan Varghese\n,", "Aparna S. Varde\n,", "Jing Peng\n,", "Eileen Fitzpatrick"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nMuch of the English in text documents today comes from nonnative speakers. Web searches are also conducted very often by non-native speakers. Though highly qualified in their respective fields, these speakers could potentially make errors in collocation, e.g., \"dark money\" and \"stock agora\" (instead of the more appropriate English expressions \"black money\" and \"stock market\" respectively). These may arise due to literal translation from the respective speaker's native language or other factors. Such errors could cause problems in contexts such as querying over Web pages, correct understanding of text documents and more. This paper proposes a framework called CollOrder to detect such collocation errors and suggest correctly ordered collocated responses for improving the semantics. This framework integrates machine learning approaches with natural language processing techniques, proposing suitable heuristics to provide responses to collocation errors, ranked in the order of correctness. We discuss the proposed framework with algorithms and experimental evaluation in this paper. We claim that it would be useful in semantically enhancing Web querying e.g., financial news, online shopping etc. It would also help in providing automated error correction in machine translated documents and offering assistance to people using ESL tools.", "references": ["Cohen, W.W., Fast effective rule induction. ICML 1995, pp. 115--123.", "Bollegala, D., Matsuo,Y. and Ishizuka,M., Measuring the similarity between implicit semantic relations using web search engines, WSDM 2009, pp. 104--113.", "Dahlmeier, D. and Tou, H. N., Correcting semantic collocation errors with L1-induced paraphrases. Conference on Empirical Methods in Natural Language Processing, 2011, pp. 107--117"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830544.2830548"}, {"title": "Initial Encryption of large Searchable Data Sets using Hadoop", "authors": ["Feng Wang\n,", "Mathias Kohler\n,", "Andreas Schaad"], "publication": "SACMAT '15: Proceedings of the 20th ACM Symposium on Access Control Models and Technologies", "abstract": "ABSTRACT\nWith the introduction and the widely use of external hosted infrastructures, secure storage of sensitive data becomes more and more important. There are systems available to store and query encrypted data in a database, but not all applications may start with empty tables rather than having sets of legacy data. Hence, there is a need to transform existing plaintext databases to encrypted form. Usually existing enterprise databases may contain terabytes of data. A single machine would require many months for the initial encryption of a large data set. We propose encrypting data in parallel using a Hadoop cluster which is a simple five step process including the Hadoop set up, target preparation, source data import, encrypting the data, and finally exporting it to the target. We evaluated our solution on real world data and report on performance and data consumption. The results show that encrypting data in parallel can be done in a very scalable manner. Using a parallelized encryption cluster compared to a single server machine reduces the encryption time from months down to days or even hours.", "references": ["Popa, R. A., Redfield, C., Zeldovich, N., & Balakrishnan, H. 2011. Cryptdb: protecting confidentiality with encrypted query processing. In Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles.", "Boldyreva, A., Chenette, N., Lee, Y., & O'neill, A. 2009. Order-preserving symmetric encryption. In Advances in Cryptology - EUROCRYPT.", "Paillier, P. 1999. Public-key cryptosystems based on composite degree residuosity classes. In Advances in cryptology - EUROCRYPT."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2752952.2752960"}, {"title": "RDF Keyword Search based on Keywords-To-SPARQL Translation", "authors": ["Katerina Gkirtzou\n,", "George Papastefanatos\n,", "Theodore Dalamagas"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nIn this paper, we present a summary of our work on RDF keyword search. Given a set of keywords, our method automatically generates a set of candidate SPARQL queries, and their natural language description, to be evaluated on the RDF data graph. We discuss our approach, highlighting current and future directions.", "references": ["K. Gkirtzou, K. Karozos, V. Vassalos, and T. Dalamagas. Keywords-to-sparql translation for rdf data search and exploration. In Proceedings of TPDL'15, Poznań, Poland, Sep 14-18, 2015 (to appear).", "M. Meimaris, G. Alexiou, K. Gkirtzou, G. Papastefanatos, and T. Dalamagas. RDF resource search and exploration with LinkZoo. In Proceedings of DATA'15, Colmar, Alsace, France, July 20-22, 2015.", "A. C. Unger, J. Lehmann, D. Gerber. Sorry, I Don'T Speak SPARQL: Translating SPARQL Queries into Natural Language. In Proceedings of WWW'13, Rio de Janeiro, Brazil, May 13 - 17, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810357"}, {"title": "An Initial Investigation into Fixed and Adaptive Stopping Strategies", "authors": ["David Maxwell\n,", "Leif Azzopardi\n,", "Kalervo Järvelin\n,", "Heikki Keskustalo"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMost models, measures and simulations often assume that a searcher will stop at a predetermined place in a ranked list of results. However, during the course of a search session, real-world searchers will vary and adapt their interactions with a ranked list. These interactions depend upon a variety of factors, including the content and quality of the results returned, and the searcher's information need. In this paper, we perform a preliminary simulated analysis into the influence of stopping strategies when query quality varies. Placed in the context of ad-hoc topic retrieval during a multi-query search session, we examine the influence of fixed and adaptive stopping strategies on overall performance. Surprisingly, we find that a fixed strategy can perform as well as the examined adaptive strategies, but the fixed depth needs to be adjusted depending on the querying strategy used. Further work is required to explore how well the stopping strategies reflect actual search behaviour, and to determine whether one stopping strategy is dominant.", "references": ["L. Azzopardi. Modelling interaction with economic models of search. In Proc. 37th ACM SIGIR, pages 3--12, 2014.", "F. Baskaya, H. Keskustalo, and K. Jarvelin. Time drives interaction: Simulating sessions in diverse searching environments. In Proc. 35th ACM SIGIR, pages 105--114, 2012.", "F. Baskaya, H. Keskustalo, and K. Jarvelin. Modeling behavioral factors in interactive information retrieval. In Proc. 22nd ACM CIKM, pages 2297--2302, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767802"}, {"title": "Discount Sensitive Recommender System for Retail Business", "authors": ["Masahiro Sato\n,", "Hidetaka Izumo\n,", "Takashi Sonoda"], "publication": "EMPIRE '15: Proceedings of the 3rd Workshop on Emotions and Personality in Personalized Systems 2015", "abstract": "ABSTRACT\nUser preferences for items are not the only determinant of purchase. Price promotion influences user's buying habits and changes items that are put in a basket. Such a reaction to discount depends on the user personality. In this paper, we propose a recommendation algorithm with personalized discount sensitivity. The effectiveness of the proposed model was verified using a public retail dataset. Correlation between personal persistence in repeat purchases and discount sensitivity of users was also investigated.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Trans. on Knowl. and Data Eng. 17, 6 (June 2005), 734--749. DOI=10.1109/TKDE.2005.99 http://dx.doi.org/10.1109/TKDE.2005.99.", "Robert C. Blattberg, Richard Briesch, and Edward J. Fox. 1995. How promotions work. Marketing Science. 14, 3 (August 1995), 122--132. http://dx.doi.org/10.1287/mksc.14.3.G122.", "Ailawadi, Kusum L. and Donthu, Naveen and Gauri, Dinesh K. and Shankar, Venkatesh and Beauchamp, Jonathan Pierre. 2009. Communication and Promotion Decisions in Retailing: A Review and Directions for Future Research. Journal of Retailing. 85, 1 (March 2009), 42--55. Available at SSRN: http://ssrn.com/abstract=2061803."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809643.2809646"}, {"title": "On Learning Prediction Models for Tourists Paths", "authors": ["Cristina Ioana Muntean\n,", "Franco Maria Nardini\n,", "Fabrizio Silvestri\n,", "Ranieri Baraglia"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nIn this article, we tackle the problem of predicting the “next” geographical position of a tourist, given her history (i.e., the prediction is done accordingly to the tourist’s current trail) by means of supervised learning techniques, namely Gradient Boosted Regression Trees and Ranking SVM. The learning is done on the basis of an object space represented by a 68-dimension feature vector specifically designed for tourism-related data. Furthermore, we propose a thorough comparison of several methods that are considered state-of-the-art in recommender and trail prediction systems for tourism, as well as a popularity baseline. Experiments show that the methods we propose consistently outperform the baselines and provide strong evidence of the performance and robustness of our solutions.", "references": ["Shane Ahern, Mor Naaman, Rahul Nair, and Jeannie Hui-I Yang. 2007. World explorer: Visualizing aggregate data from unstructured text in geo-referenced collections. In Proceedings of the 7th ACM/IEEE-CS Joint Conference on Digital Libraries. ACM, 1--10.", "Yuki Arase, Xing Xie, Takahiro Hara, and Shojiro Nishio. 2010. Mining people’s trips from large scale geo-tagged photos. In Proceedings of the International Conference on Multimedia (MM’10). ACM, New York, NY, 133--142. DOI:http://dx.doi.org/10.1145/1873951.1873971", "Ricardo Baeza-Yates, Berthier Ribeiro-Neto, and others. 1999. Modern information retrieval. Vol. 463. ACM Press, New York."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766459"}, {"title": "Hand gesture recognition for a virtual mouse application using geometric feature of finger's trajectories", "authors": ["Behnam Maleki\n,", "Hossein Ebrahimnezhad\n,", "Min Xu\n,", "Xiangjian He"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nWe aim to enable a computer to comprehend and perform the mouse functions by analyzing a video with hand motions. For this purpose, dynamic gestures are captured by a web cam and are recognized as pre-defined gestures which are used to suggest mouse functions. The proposed algorithm initially detects the hand. Then, it tracks fingertips' trajectories within a frame sequence. Finally, hand gestures are recognized through computing a set of proposed geometric features of fingers' trajectories and comparing with our collected gestures dataset. In this paper, four types of descriptors are defined for a dynamic gesture. Each descriptor includes different number of features, which compose a feature vector with 135 dimensions. Different classification algorithms (e.g. KNN, LDA, Naïve Bayes and SVM) are applied to compare the detection results. The minimal misclassification error rate (MCR) reaches about 4% (i.e. Correct Recognition rate of 96%). Furthermore, we applied Principle Component Analysis (PCA) to reduce the number of features. With 30 dimensional features (principle components), LDA classifier can achieve about 0.09% misclassification error rate.", "references": ["C. Weng, C. Tseng, M. Ho and C. Huang, \"A Vision-Based Hand Motion Parameter Capturing for HCI,\" in ICALIP, 2008.", "M. de La Gorce and N. Paragios, \"A variational approach to monocular hand-pose estimation,\" Computer Vision and Image Understanding, no. 114, pp. 363--372, 2010.", "M. de La Gorce, D. J. Fleet and N. Paragios, \"Model-Based 3D Hand Pose Estimation from Monocular Video,\" IEEE transactions on pattern analysis and machine intelligence, vol. 33, no. 9, pp. 1793--1804, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808566"}, {"title": "Semi- and Weakly- Supervised Semantic Segmentation with Deep Convolutional Neural Networks", "authors": ["Yuhang Wang\n,", "Jing Liu\n,", "Yong Li\n,", "Hanqing Lu"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nSuccessful semantic segmentation methods typically rely on the training datasets containing a large number of pixel-wise labeled images. To alleviate the dependence on such a fully annotated training dataset, in this paper, we propose a semi- and weakly-supervised learning framework by exploring images most only with image-level labels and very few with pixel-level labels, in which two stages of Convolutional Neural Network (CNN) training are included. First, a pixel-level supervised CNN is trained on very few fully annotated images. Second, given a large number of images with only image-level labels available, a collaborative-supervised CNN is designed to jointly perform the pixel-level and image-level classification tasks, while the pixel-level labels are predicted by the fully-supervised network in the first stage. The collaborative-supervised network can remain the discriminative ability of the fully-supervised model learned with fully labeled images, and further enhance the performance by importing more weakly labeled data. Our experiments on two challenging datasets, i.e, PASCAL VOC 2007 and LabelMe LMO, demonstrate the satisfactory performance of our approach, nearly matching the results achieved when all training images have pixel-level labels.", "references": ["M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303--338, 2010.", "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.", "L. Ladicky, C. Russell, P. Kohli, and P. H. Torr. Associative hierarchical crfs for object class image segmentation. In ICCV, pages 739--746, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806322"}, {"title": "Answer Quality Characteristics and Prediction on an Academic Q&A Site: A Case Study on ResearchGate", "authors": ["Lei Li\n,", "Daqing He\n,", "Wei Jeng\n,", "Spencer Goodwin\n,", "Chengzhi Zhang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nDespite various studies on examining and predicting answer quality on generic social Q&A sites such as Yahoo! Answers, little is known about why answers on academic Q&A sites are voted on by scholars who follow the discussion threads to be high quality answers. Using 1021 answers obtained from the Q&A part of an academic social network site ResearchGate (RG), we firstly explored whether various web-captured features and human-coded features can be the critical factors that influence the peer-judged answer quality. Then using the identified critical features, we constructed three classification models to predict the peer-judged rating. Our results identify four main findings. Firstly, responders' authority, shorter response time and greater answer length are the critical features that positively associate with the peer-judged answer quality. Secondly, answers containing social elements are very likely to harm the peer-judged answer quality. Thirdly, an optimized SVM algorithm has an overwhelming advantage over other models in terms of accuracy. Finally, the prediction based on web-captured features had better performance when comparing to prediction on human-coded features. We hope that these interesting insights on ResearchGate's answer quality can help the further design of academic Q&A sites.", "references": ["Liu, Y., Bian, J., & Agichtein, E. (2008, July). Predicting information seeker satisfaction in community question answering. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval (pp. 483--490). ACM.DOI=10.1145/1390334.1390417", "Harper, F. M., Raban, D., Rafaeli, S., & Konstan, J. A. (2008, April). Predictors of answer quality in online Q&A sites. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(pp. 865--874). ACM. DOI= 10.1145/1357054.1357191.", "Shah, C., & Pomerantz, J. (2010, July). Evaluating and predicting answer quality in community QA. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval (pp. 411--418). ACM. DOI= 10.1145/1835449.1835518"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742129"}, {"title": "Improving Latent Factor Models via Personalized Feature Projection for One Class Recommendation", "authors": ["Tong Zhao\n,", "Julian McAuley\n,", "Irwin King"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLatent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users' and items' latent factors to be of the same size and use an inner product to represent a user's \"compatibility\" with an item. Intuitively, users' factors encode \"preferences\" while item factors encode \"properties\", so that the inner product encodes how well an item matches a user's preferences. However, a user's opinion of an item may be more complex, for example each dimension of each user's opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user's preference as a personalized projection of an item's properties so that the preference model can capture complex relationships between items' properties and users' preferences.\nTherefore, in this paper we propose a novel personalized feature projection method to model users' preferences over items. Specifically, for each user, we define a personalized projection matrix, which takes the place of user-specific factors from existing models. This matrix describes a mapping between items' factors and users' preferences in order to build personalized preference models for each user and item. The proposed personalized feature projection method is quite general and existing latent factor models, for example, can be cast as a special case. We present three objective functions to optimize predictions in the form of ranked lists of users' preferences over items, and demonstrate how each can be used to improve one-class recommendation performance. Experiments are conducted on four real-world datasets and our results show that our personalized feature projection method outperforms several state-of-the-art methods on various evaluation metrics.", "references": ["L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In Workshop on context-aware recommender systems, 2009.", "J. Davis, B. Kulis, P. Jain, S. Sra, and I. Dhillon. Information-theoretic metric learning. In Proceedings of ICML, 2007.", "L. Du, X. Li, and Y.-D. Shen. User graph regularized pairwise matrix factorization for item recommendation. In Proceedings of ADMA, pages 372--385, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806511"}, {"title": "On the Relation Between Assessor's Agreement and Accuracy in Gamified Relevance Assessment", "authors": ["Olga Megorskaya\n,", "Vladimir Kukushkin\n,", "Pavel Serdyukov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nExpert judgments (labels) are widely used in Information Retrieval for the purposes of search quality evaluation and machine learning. Setting up the process of collecting such judgments is a challenge of its own, and the maintenance of judgments quality is an extremely important part of the process. One of the possible ways of controlling the quality is monitoring inter-assessor agreement level. But does the agreement level really reflect the quality of assessor's judgments? Indeed, if a group of assessors comes to a consensus, to what extent should we trust their collective opinion? In this paper, we investigate, whether the agreement level can be used as a metric for estimating the quality of assessor's judgments, and provide recommendations for the design of judgments collection workflow. Namely, we estimate the correlation between assessors' accuracy and agreement in the scope of several workflow designs and investigate which specific workflow features influence the accuracy of judgments the most.", "references": ["O. Alonso and R. Baeza-Yates. Design and implementation of relevance assessments using crowdsourcing. In Advances in Information Retrieval. 33rd European Conference on IR Research, ECIR 2011, Dublin, Ireland, April 18--21, 2011. Proceedings, pages 153--164. Springer, 2011.", "P. Bailey, N. Craswell, I. Soboroff, P. Thomas, A. P. de Vries, and E. Yilmaz. Relevance assessment: Are judges exchangeable and does it matter. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '08, pages 667--674, New York, NY, USA, 2008. ACM.", "K. Gwet. Inter-rater reliability: dependency on trait prevalence and marginal homogeneity. Statistical Methods for Inter-Rater Reliability Assessment Series, 2:1--9, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767727"}, {"title": "Similarity measurement with mesh distance fourier transform in 2D binary image", "authors": ["Ravi Kasaudhan\n,", "Tae K. Heo\n,", "Soon Ik Jeon\n,", "Seong Ho Son"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nShape based feature is a widely used method in Content based Image Retrieval (CBIR) for similarity measurements because contours of an image provide relevant information for similarity. In this paper, we propose a novel shape feature named Mesh Distance Fourier Descriptor (MDFD) which takes into account the contour information of each of the boundary points with respect to other contour points in the images such that the relationship of one boundary point is evaluated with respect to all other boundary points in 2D space. In this paper we have used binary images which are classified into single objects using known classification methods such as K-means and SVM algorithms. The proposed method has been compared with Sectorized Object Matching (SOM) and the result shows that the proposed algorithm outperforms SOM in terms of matching of similar images.", "references": ["Celebi, M. E. and Aslandogan, Y. A., 2005. A comparative study of three moment-based shape descriptors. In Information Technology: Coding and Computing, 2005. ITCC 2005. International Conference on IEEE, 788--793.", "El-ghazal, A., Basir, O., and Belkasim, S., 2009. Farthest point distance: A new shape signature for Fourier descriptors. Signal Processing: Image Communication 24, 7, 572--586.", "El-Kwae, E. A., Xu, H., and Kabuka, M. R., 2000. Content-based retrieval in picture archiving and communication systems. J Digit Imaging 13, 2 (May), 70--81."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811506"}, {"title": "Deep Collaborative Filtering via Marginalized Denoising Auto-encoder", "authors": ["Sheng Li\n,", "Jaya Kawale\n,", "Yun Fu"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nCollaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.", "references": ["Xiaoyuan Su and Taghi M. Khoshgoftaar. A survey of collaborative filtering techniques. Adv. Artificial Intellegence, 2009.", "Yehuda Koren, Robert M. Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. IEEE Computer, 42(8):30--37, 2009.", "Sotirios Chatzis. Nonparametric bayesian multitask collaborative filtering. In CIKM, pages 2149--2158, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806527"}, {"title": "Unleashing the True Power of Mobile Systems: Big Data and Analytics", "authors": ["Pablo Vidales"], "publication": "MSWiM '15: Proceedings of the 18th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems", "abstract": "ABSTRACT\nMobile systems have continuously evolved in the last years. However, user demand really smart phones that will assist them in daily activities. The new developments in processing and analyzing data are a new chance to make a quantum jump in mobile systems. Every two years the available data duplicates and in combination with existing machine learning and unstructured data analysis closed doors have been open. Today we can really personalized mobile applications to meet the specific needs of each customer, we have more than enough data to develop true context aware mobile solutions; it is just a matter of connecting the dots. This keynote will explore the challenge and opportunities that Big Data and Advanced Analytics are facing, and will present some examples of how we can combine the power of processing and analyzing unstructured and structure data to unleash the true power of mobile systems.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811587.2823534"}, {"title": "Mining High Utility Sequential Patterns from Evolving Data Streams", "authors": ["Morteza Zihayat\n,", "Cheng-Wei Wu\n,", "Aijun An\n,", "Vincent S. Tseng"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn this paper, we define the problem of mining high utility sequential patterns (HUSPs) over high-velocity streaming data and propose an efficient algorithm for mining HUSPs over a data stream. The main challenges we tackle include how to maintain a compact summary of the data stream to reflect the evolution of sequence utilities over time and how to overcome the problem of combinatorial explosion of a search space. We propose a compact data structure named HUSP-Tree to maintain the essential information for mining HUSPs in an online fashion. An efficient and single-pass algorithm named HUSP-Stream is proposed to generate HUSPs from HUSP-Tree. HUSP-Stream uses a new utility estimation model to more effectively prune the search space. Experimental results on real and synthetic datasets show that our algorithm serves as an efficient solution to the new problem of mining high utility sequential patterns over data streams.", "references": ["Agrawal, R. and Srikant, R. 1995. Mining sequential patterns. In In Proc. of ICDE Conf., pages 3--14.", "Ahmed, C., Tanbeer, S. and Jeong, B. 2010. A novel approach for mining high-utility patterns in sequence databases. In ETRI Journal, 32:676--686.", "Ahmed, C., Tanbeer, S. and Jeong, B. 2011. A framework for mining high utility web access sequences. In IETE Journal, 28:3--16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818883"}, {"title": "Indoor location systems in emergency scenarios: A Survey", "authors": ["Arivan S. Bastos\n,", "Vaninha Vieira\n,", "Antonio L. ApolinArio"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIndoor location data are critical in emergency situations. Command centers need to monitor their operational forces. Rescuers need to find potential victims to carry proper care and the building's occupants need to find the way for fast evacuation. Despite the growing body of research in indoor location, no technique is considered appropriate for different situations. Furthermore, few studies have analyzed the applicability of these techniques in an emergency setting, which has particular characteristics. This survey reviews works in indoor location applied to emergency scenarios, analyzing their applicability in relation to existing requirements in these types of situations.", "references": ["A. Amanatiadis, A. Gasteratos, and D. Koulouriotis. \"An intelligent multi-sensor system for first responder indoor navigation\". In: Measurement Science and Technology 22.11 (2011).", "S. Beauregard. \"Omnidirectional pedestrian navigation for first responders\". In: 4th Workshop on Positioning, Navigation and Communication 2007, WPNC'07 - Workshop Proceedings. Hannover, Germany, 2007, pp. 33-36.", "D.M. Do, M.H. Hyun, and Y.B. Choi. \"RFID-based indoor location recognition system for emergency rescue evacuation support\". In: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). Vol. 7861 LNCS. Seoul, Korea, Republic of, 2013, pp. 899-906."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814099"}, {"title": "Automatic Online Evaluation of Intelligent Assistants", "authors": ["Jiepu Jiang\n,", "Ahmed Hassan Awadallah\n,", "Rosie Jones\n,", "Umut Ozertem\n,", "Imed Zitouni\n,", "Ranjitha Gurunath Kulkarni\n,", "Omar Zia Khan"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nVoice-activated intelligent assistants, such as Siri, Google Now, and Cortana, are prevalent on mobile devices. However, it is challenging to evaluate them due to the varied and evolving number of tasks supported, e.g., voice command, web search, and chat. Since each task may have its own procedure and a unique form of correct answers, it is expensive to evaluate each task individually. This paper is the first attempt to solve this challenge. We develop consistent and automatic approaches that can evaluate different tasks in voice-activated intelligent assistants. We use implicit feedback from users to predict whether users are satisfied with the intelligent assistant as well as its components, i.e., speech recognition and intent classification. Using this approach, we can potentially evaluate and compare different tasks within and across intelligent assistants ac-cording to the predicted user satisfaction rates. Our approach is characterized by an automatic scheme of categorizing user-system interaction into task-independent dialog actions, e.g., the user is commanding, selecting, or confirming an action. We use the action sequence in a session to predict user satisfaction and the quality of speech recognition and intent classification. We also incorporate other features to further improve our approach, including features derived from previous work on web search satisfaction prediction, and those utilizing acoustic characteristics of voice requests. We evaluate our approach using data collected from a user study. Results show our approach can accurately identify satisfactory and unsatisfactory sessions.", "references": ["Ageev, M., Guo, Q., Lagun, D. and Agichtein, E. (2011). Find it if you can: a game for modeling different types of web search success using interaction data. Proc. SIGIR '11, 345--354.", "Smith R.W. and Hipp, D.R. (1995). Spoken Natural Language Dialog Systems: A Practical Approach. Oxford University Press.", "Feild, H.A., Allan, J. and Jones, R. (2010). Predicting searcher frustration. Proc. SIGIR '10, 34--41."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741669"}, {"title": "Improving the Internet with ICN", "authors": ["Van Jacobson"], "publication": "ACM-ICN '15: Proceedings of the 2nd ACM Conference on Information-Centric Networking", "abstract": "ABSTRACT\nEfficient static content distribution is the focus of most ICN efforts. But content distribution is just one of many Internet pain points. An Information Centric approach could potentially spur major advances on most of the Internet's most pressing problems. This talk will discuss where, why, and how ICN could make a difference on a broader scale.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810156.2810157"}, {"title": "Predicting Relevance Feedback Effectiveness with the Help of the Principle of Polyrepresentation in MIR", "authors": ["David Zellhöfer"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe principle of polyrepresentation - a representative of the cognitive viewpoint on IR, takes a holistic perspective on interactive IR research.\nOne of the principle's core hypotheses is that a document is described by different representations such as visual low-level features, textual content, or relational metadata.\nThe conjunctive combination of these representations, the so-called cognitive overlap, is assumed to compensate the inherent insecurity in relevance assessments of documents w.r.t. an information need.\nRecently, the cognitively motivated principle of polyrepresentation has been shown to correlate with quantum mechanics-inspired IR models. However, the principle's effectiveness has not been examined in relevance feedback-based interactive MIR. In this work, the principle's utility is studied in interactive MIR in order to investigate whether its main hypothesis can serve as a predictor of retrieval performance during relevance feedback.\nIn order to obtain resilient results all experiments have been carried out with 6 different standard test sets that provide evidence of the utility of the presented approach and the underlying polyrepresentative hypothesis.", "references": ["S. Balko and I. Schmitt. Signature Indexing and Self-Refinement in Metric Spaces. Cottbus, 2012.", "A. S. Chatzichristofis and S. Y. Boutalis. CEDD: Color and Edge Directivity Descriptor: A Compact Descriptor for Image Indexing and Retrieval. In Proc. of the 6th Int. Conference on Computer Vision Systems, pages 312--322. Springer-Verlag, 2008.", "A. S. Chatzichristofis and S. Y. Boutalis. FCTH: Fuzzy Color and Texture Histogram - A Low Level Feature for Accurate Image Retrieval. In Proc. of the 2008 9th Int. Workshop on Image Analysis for Multimedia Interactive Services, WIAMIS '08, pages 191--196. IEEE Computer Society, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809485"}, {"title": "Joint Matrix Factorization and Manifold-Ranking for Topic-Focused Multi-Document Summarization", "authors": ["Jiwei Tan\n,", "Xiaojun Wan\n,", "Jianguo Xiao"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nManifold-ranking has proved to be an effective method for topic-focused multi-document summarization. As basic manifold-ranking based summarization method constructs the relationships between sentences simply by the bag-of-words cosine similarity, we believe a better similarity metric will further improve the effectiveness of manifold-ranking. In this paper, we propose a joint optimization framework, which integrates the manifold-ranking process with a similarity metric learning process. The joint framework aims at learning better sentence similarity scores and better sentence ranking scores simultaneously. Experiments on DUC datasets show the proposed joint method achieves better performance than the manifold-ranking baselines and several popular methods.", "references": ["Xiaoyan Cai and Wenjie Li. Mutually reinforced manifold-ranking based relevance propagation model for query-focused multi-document summarization. Audio, Speech, and Language Processing, 20(5):1597--1607, 2012.", "Hoa Trang Dang. Overview of duc 2006. In Document Understanding Conference. New York City, 2006.", "Weiwei Guo and Mona Diab. Modeling sentences in the latent space. In ACL, pages 864--872. Association for Computational Linguistics, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767765"}, {"title": "Transfer Learning for Information Retrieval", "authors": ["Pengfei Li"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["Peng Cai, Wei Gao, K.F. Wong, and Aoying Zhou. Weight-based boosting model for cross-domain relevance ranking adaptation. Adv. Inf. Retr., pages 562--567, 2011.", "Sinno Jialin Pan and Qiang Yang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22 (10): 1345--1359, October 2010.", "Shangkun Ren, Yuexian Hou, Peng Zhang, and Xueru Liang. Importance Weighted AdaRank. Adv. Intell. Comput., pages 448--455, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767845"}, {"title": "Symbolic trajectories and application challenges", "authors": ["Maria Luisa Damiani\n,", "Hamza Issa\n,", "Ralf Hartmut Güting\n,", "Fabio Valdes"], "publication": "SIGSPATIAL Special", "abstract": "Abstract\nDescribing the location history of moving objects exclusively in geometric terms is no longer sufficient, whereas more expressive data models capturing the complexity and heterogeneity of movement data are needed. Following this trend, the data model of symbolic trajectories has been recently proposed for the representation of content-rich trajectories in databases. The model provides a simple notation and a powerful and fully operational pattern-based query language for trajectory matching and rewriting. In this paper, we overview the key features of the model and sketch two applications cases, the former regarding the integration of heterogeneous mobility data (GPS and transportation modes), the latter the representation of migration patterns in animal ecology. The goal is to show the flexibility of the model and, at the same time, to prospect possible directions of research.", "references": ["L. Alvares, V. Bogorny, B. Kuijpers, J. de Macedo, B. Moelans, and A. Vaisman. A model for enriching trajectories with semantic geographical information. In Proc. ACM GIS, page 22, 2007.", "G. Cong, H. Lu, B. Chin-Ooi, D. Zhang, and M. Zhang. Efficient spatial keyword search in trajectory databases. CoRR, abs/1205.2880, 2012.", "M. L. Damiani, H. Issa, and F. Cagnacci. Extracting stay regions with uncertain boundaries from gps trajectories: A case study in animal ecology. In Proc. SIGSPATIAL, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2782759.2782768"}, {"title": "Topic Models Regularization and Initialization for Regression Problems", "authors": ["Evgeny Sokolov\n,", "Lev Bogolubsky"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nWe propose a new method of feature extraction for regression problems with text data that transforms the sparse texts to dense features using regularized topic models. We also discuss the problem of topic model initialization, and propose a new approach based on Naive Bayes. This approach is compared to many others, and it achieves a quality comparable to vector space models using as little as ten topics. It also outperforms other methods for feature generation based on topic modeling, such as PLSA and Supervised LDA.", "references": ["B. Pang and L. Lee.Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.In Proceedings of the ACL, 2005.", "D. Newman, C. Chemudugunta, P. Smyth, and M. Steyvers. Analyzing entities and topics in news articles using statistical topic models. In Intelligence and Security Informatics, Lecture Notes in Computer Science. 2006.", "T. Griffiths, M. Steyvers. Finding scientific topics. Proceedings of the National Academy of Sciences 101 (Suppl 1): 5228--35. 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809940"}, {"title": "Relevance-aware Filtering of Tuples Sorted by an Attribute Value via Direct Optimization of Search Quality Metrics", "authors": ["Nikita V. Spirin\n,", "Mikhail Kuznetsov\n,", "Julia Kiseleva\n,", "Yaroslav V. Spirin\n,", "Pavel A. Izhutov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSorting tuples by an attribute value is a common search scenario and many search engines support such capabilities, e.g. price-based sorting in e-commerce, time-based sorting on a job or social media website. However, sorting purely by the attribute value might lead to poor user experience because the relevance is not taken into account. Hence, at the top of the list the users might see irrelevant results. In this paper we choose a different approach. Rather than just returning the entire list of results sorted by the attribute value, additionally we suggest doing the relevance-aware search results (post-) filtering. Following this approach, we develop a new algorithm based on the dynamic programming that directly optimizes a given search quality metric. It can be seamlessly integrated as the final step of a query processing pipeline and provides a theoretical guarantee on optimality. We conduct a comprehensive evaluation of our algorithm on synthetic data and real learning to rank data sets. Based on the experimental results, we conclude that the proposed algorithm is superior to typically used heuristics and has a clear practical value for the search and related applications.", "references": ["R. Bellman. Dynamic Programming. Dover Books on Computer Science, USA, 2003.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. CIKM'09.", "A. Chuklin, P. Serdyukov, and M. de Rijke. Click model-based information retrieval metrics. SIGIR'13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767822"}, {"title": "Multi-layered semantic search for open innovation needs", "authors": ["The-Vinh Phan\n,", "Hong-Quang Nguyen\n,", "Hoang-Minh Nguyen"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nUnder open-innovation paradigm, firms may gain beneficial from cost reductions and external-workforce collaborations. These advantages have increasingly drawn researchers' attentions to the ways that technology solutions could be retrieved to address firms' technology needs. However, prior studies were either (i) manual and effort-intensive or (ii) focused on data analytics instead of providing a technology solution for a technology need. In this paper, we propose a novel multi-layered semantic search to tackle the above problems. First, we propose a multi-layered search approach in which each layer encompasses a semantic capability for acquiring relevant technology solutions. Second, we propose a novel multi-layered similarity-measurement strategy, called NSk, to estimate the relatedness between a technology <u>n</u>eed and a technology <u>s</u>olution, with respect to the layer k. Our prototype OIG (short for <u>O</u>pen <u>I</u>nnovation <u>G</u>ate) is evaluated through a case study of finding technology solutions for a real-world technology need requiring \"facial recognition\". The study conveyed the feasibility of applying our proposed approach to search for technology solutions under open-innovation paradigm.", "references": ["InnoCentive At-a-Glance: Leader in Challenge Driven Innovation. Available: http://www.innocentive.com/. Accessed: 2015-09-01.", "T. Y. Bakici, E. Almirall, and J. Wareham. The underlying mechanisms of open innovation intermediaries. January 2010.", "H. W. Chesbrough. Open innovation: The new imperative for creating and profiting from technology. Harvard Business Press, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837214"}, {"title": "Better health information exploration", "authors": ["Patrick Cheong-Iao Pang\n,", "Karin Verspoor\n,", "Shanton Chang\n,", "Jon Pearce"], "publication": "APCHIUX '15: Proceedings of the Asia Pacific HCI and UX Design Symposium", "abstract": "ABSTRACT\nThe provision of health information has to be clear and appealing to users. Research has shown that health information seekers do not all have the same attributes, skills or needs. In any given health-related app or website, there is a need to provide tools for accessing information in ways that appeal to users. This is not always supported by current web technologies. As such, based on prior research on health information seeking behaviour and needs, we designed and created a proof-of-concept website named Better Health Explorer to experiment on health information seekers. The pilot results show a positive effect on supporting and improving the experience of seekers with exploratory search behaviour.", "references": ["Basil Alzougool, Shanton Chang, and Kathleen Gray. 2008. Towards a comprehensive understanding of health information needs. electronic Journal of Health Informatics 3, 2.", "Mike Benigeri, and Pierre Pluye. 2003. Shortcomings of health information on the Internet. Health Promotion International 18, 4: 381--386. http://dx.doi.org/10.1093/heapro/dag409", "Gretchen K. Berland, et al. 2001. Health information on the Internet: Accessibility, quality, and readability in English and Spanish. JAMA 285, 20: 2612--2621. http://dx.doi.org/10.1001/jama.285.20.2612"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2846439.2846444"}, {"title": "WATTS: a Web Annotation Tool for Surveillance Scenarios", "authors": ["Federico Bartoli\n,", "Lorenzo Seidenari\n,", "Giuseppe Lisanti\n,", "Svebor Karaman\n,", "Alberto Del Bimbo"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we present a web based annotation tool we developed allowing creating collaboratively a detailed ground truth for datasets related to visual surveillance and behavior understanding. The system persistence is based on a relational database and the user interface is designed using HTML5, Javascript and CSS. Our tool can easily manage datasets with multiple cameras. It allows annotating a person location in the image, its identity, its body and head gaze, as well as a potential occlusion or group membership. We justify each annotation type with regards to current trends of research in the computer vision community. We further detail how our interface can be used to annotate each of these annotations type. We conclude the paper with an usability evaluation of our system.", "references": ["M. Amer, P. Lei, and S. Todorovic. Hirf: Hierarchical random field for collective activity recognition in videos. In Proc of ECCV, 2014.", "F. Bartoli, G. Lisanti, S. Seidenari, Lorenzo Karaman, and A. Del Bimbo. Museumvisitors: a dataset for pedestrian and group detection, gaze estimation and behavior understanding. In Proc. of CVPR Int.'l Workshop on Group And Crowd Behavior Analysis And Understanding, Boston, USA, 2015.", "L. Bazzani, V. Murino, and M. Cristani. Decentralized particle filter for joint individual-group tracking. In Proc. of CVPR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807411"}, {"title": "Query Length, Retrievability Bias and Performance", "authors": ["Colin Wilkie\n,", "Leif Azzopardi"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPast work has shown that longer queries tend to lead to better retrieval performance. However, this comes at the cost of increased user effort effort and additional system processing. In this paper, we examine whether there are benefits of longer queries beyond performance. We posit that increasing the query length will also lead to a reduction in the retrievability bias. Additionally, we speculate that to minimise retrievability bias as queries become longer, more length normalisation must be applied to account for the increase in the length of documents retrieved. To this end, we perform a retrievability analysis on two TREC collections using three standard retrieval models and various lengths of queries (one to five terms). From this investigation we find that increasing the length of queries reduces the overall retrievability bias but at a decreasing rate. Moreover, once the query length exceeds three terms the bias can begin to increase (and the performance can start to drop). We also observe that more document length normalisation is typically required as query length increases, in order to minimise bias. Finally, we show that there is a strong correlation between performance and retrieval bias. This work raises some interesting questions regarding query length and its affect on performance and bias. Further work will be directed towards examining longer and more verbose queries, including those generated via query expansion methods, to obtain a more comprehensive understanding of the relationship between query length, performance and retrievability bias.", "references": ["E. Agapie, G. Golovchinsky, and P. Qvarfordt. Leading people to longer queries. In Proc. of ACM SIGCHI, pages 3019--3022, 2013.", "L. Azzopardi. Query side evaluation: an empirical analysis of effectiveness and effort. In Proc. of the 32nd ACM SIGIR, pages 556--563, 2009.", "L. Azzopardi and V. Vinay. Retrievability: An evaluation measure for higher order information access tasks. In Proc. of the 17th ACM CIKM, pages 561--570, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806604"}, {"title": "Dynamic Query Modeling for Related Content Finding", "authors": ["Daan Odijk\n,", "Edgar Meij\n,", "Isaac Sijaranamual\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhile watching television, people increasingly consume additional content related to what they are watching. We consider the task of finding video content related to a live television broadcast for which we leverage the textual stream of subtitles associated with the broadcast. We model this task as a Markov decision process and propose a method that uses reinforcement learning to directly optimize the retrieval effectiveness of queries generated from the stream of subtitles. Our dynamic query modeling approach significantly outperforms state-of-the-art baselines for stationary query modeling and for text-based retrieval in a television setting. In particular we find that carefully weighting terms and decaying these weights based on recency significantly improves effectiveness. Moreover, our method is highly efficient and can be used in a live television setting, i.e., in near real time.", "references": ["J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. Topic detection and tracking pilot study final report. Computer Science Department Paper 341, Carnegie Mellon University, 1998.", "N. Balasubramanian, G. Kumaran, and V. R. Carvalho. Exploring reductions for long web queries. In SIGIR '10, pages 571--578. ACM, 2010.", "A. G. Barto, R. S. Sutton, and P. S. Brouwer. Associative search network: A reinforcement learning associative memory. Biological cybernetics, 40 (3): 201--211, 1981."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767715"}, {"title": "BACR: set similarities with lower bounds and application to spatial trajectories", "authors": ["Martin Werner"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nThis paper proposes a length-independent feature representation of sets of strings based on Bloom filters called BACR for similarity search in databases. Further, we show how a Z-curve-based discretization of geospatial trajectories can be used in order to search for similar trajectories in large databases. Additionally to the already-known estimation of the size of the union and the intersection of sets from Bloom filters, we propose a way to calculate an upper bound for the intersection and a lower bound for the union of sets. Consequently, we show that the Jaccard distance and many other similarity measures allow for a lower bound. This makes exact similarity search on large databases of this type feasible. Finally, we show that the Jaccard distance is incompatible with the union of sets and replace the Jaccard distance appropriately in a way such that even collections of sets of strings can be represented with a single BACR feature vector at least for similarity search applications. The algorithms are thoroughly evaluated and motivated by real-world examples.", "references": ["B. H. Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13(7):422--426, 1970.", "A. Broder and M. Mitzenmacher. Network applications of bloom filters: A survey. Internet mathematics, 1(4):485--509, 2004.", "A. Z. Broder, M. Charikar, A. M. Frieze, and M. Mitzenmacher. Min-wise independent permutations. In Proceedings of the thirtieth annual ACM symposium on Theory of computing, pages 327--336. ACM, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820802"}, {"title": "Accio: A Data Set for Face Track Retrieval in Movies Across Age", "authors": ["Esam Ghaleb\n,", "Makarand Tapaswi\n,", "Ziad Al-Halah\n,", "Hazim Kemal Ekenel\n,", "Rainer Stiefelhagen"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nVideo face recognition is a very popular task and has come a long way. The primary challenges such as illumination, resolution and pose are well studied through multiple data sets. However there are no video-based data sets dedicated to study the effects of aging on facial appearance. We present a challenging face track data set, Harry Potter Movies Aging Data set (Accio1), to study and develop age invariant face recognition methods for videos. Our data set not only has strong challenges of pose, illumination and distractors, but also spans a period of ten years providing substantial variation in facial appearance. We propose two primary tasks: within and across movie face track retrieval; and two protocols which differ in their freedom to use external data. We present baseline results for the retrieval performance using a state-of-the-art face track descriptor. Our experiments show clear trends of reduction in performance as the age gap between the query and database increases. We will make the data set publicly available for further exploration in age-invariant video face recognition.", "references": ["FG-NET Aging Database.", "M. Bäuml, M. Tapaswi, and R. Stiefelhagen. Semi-supervised Learning with Constraints for Person Identification in Multimedia Data. In CVPR, 2013.", "B.-C. Chen, C.-S. Chen, and W. H. Hsu. Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval. In ECCV, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749296"}, {"title": "DiagramFlyer: A Search Engine for Data-Driven Diagrams", "authors": ["Zhe Chen\n,", "Michael Cafarella\n,", "Eytan Adar"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nA large amount of data is available only through data-driven diagrams such as bar charts and scatterplots. These diagrams are stylized mixtures of graphics and text and are the result of complicated data-centric production pipelines. Unfortunately, neither text nor image search engines exploit these diagram-specific properties, making it difficult for users to find relevant diagrams in a large corpus. In response, we propose DiagramFlyer, a search engine for finding data-driven diagrams on the web. By recovering the semantic roles of diagram components (e.g., axes, labels, etc.), we provide faceted indexing and retrieval for various statistical diagrams. A unique feature of DiagramFlyer is that it is able to \"expand\" queries to include not only exactly matching diagrams, but also diagrams that are likely to be related in terms of their production pipelines. We demonstrate the resulting search system by indexing over 300k images pulled from over 150k PDF documents.", "references": ["Apache Lucene, http://lucene.apache.org/java/docs/index.html.", "S. Bhatia, P. Mitra, and C. L. Giles. Finding algorithms in scientific articles. In WWW, 2010.", "M. Cafarella and D. Cutting. Building nutch: Open source search. ACM Queue, 2, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742831"}, {"title": "Herakles: real-time sport analysis using a distributed data stream management system", "authors": ["Timo Michelsen\n,", "Michael Brand\n,", "Carsten Cordes\n,", "H.-Jürgen Appelrath"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nTactical decisions profoundly characterize team sports like soccer or basketball. Analyses of matches and training sessions (e.g., mileage or pass completion rate of a player) become more and more important for those tactical decisions. Most of the analyses are video-based, resulting in high operating expenses. Additionally, a highly specialized system with a huge amount of system resources like processors and memory is needed. Typically, analysts present the results of the video data analysis in time-outs (e.g., in the half-time break of a soccer match). However, coaches often desire to view statistics in real-time during the match.\nIn this paper, we demonstrate Herakles, a system for live sport analysis using streaming sensor data and a Peer-to-Peer network of conventional and low-cost private machines. Since sensor data is typically of high volume and velocity, Herakles uses OdysseusP2P, a distributed data stream management system, for processing these streams in real-time. Since the results of the data stream processing are intended for coaches, the front-end of Herakles is an application for mobile devices like smartphones or tablets. With Herakles, a coach is able to view individual sport statistics during the game at the sideline to make immediate tactical decisions.", "references": ["Debs 2013. http://www.orgs.ttu.edu/debs2013 (visited: 04/30/15).", "Improving performance with smarter soccer analytics using sap hana. http://hana.sap.com/customers/customer-stories/tsg1899hoffenheim.html (visited: 29/04/15).", "Keymotion automated sports production. http://www.keemotion.com/ (visited: 04/29/15)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2776775"}, {"title": "Processing manufacturing knowledge with ontology-based annotations and cognitive architectures", "authors": ["Rebekka Alm\n,", "Mario Aehnelt\n,", "Bodo Urban"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nAdvanced manufacturing promises an evolution of industrial production processes. However, today's manufacturing systems lack a common strategy on how to combine factual, procedural, and conceptual knowledge in order to streamline production processes. This specifically applies for manufacturing assembly assistance where the major share of procedural and conceptual knowledge is not yet automatically processable.\nIn our paper we propose the usage of ontology-based annotations as missing link between the tacit knowledge of the worker and the intelligent assistance system. We show the deeper integration of conceptual knowledge modeled in ontology-based annotations with procedural knowledge in cognitive architectures. Additionally, in our approach annotations act as a mean of communication between the workers and with the system. We show key aspects of a prototypical integration of our approach within a smart assembly assistance system which supplies the worker with task related information.", "references": ["G. D. Abowd, A. K. Dey, P. J. Brown, N. Davies, M. Smith, and P. Steggles. Towards a better understanding of context and context-awareness. In Proc. of the International Symposium on Handheld and Ubiquitous Computing, pages 304--307, 1999.", "M. Aehnelt and B. Urban. The knowledge gap: providing situation-aware information assistance on the shop floor. In Proceedings of the 17th International Conference on Human-Computer Interaction: 2-7 August 2015, Los Angeles, USA. 2015.", "R. Alm, M. Aehnelt, S. Hadlak, and B. Urban. Annotated domain ontologies for the visualization of heterogeneous manufacturing data. In HCI International 2015. Los Angeles, USA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809576"}, {"title": "Recommendation approaches for e-learners: a survey", "authors": ["Nauman Sharif\n,", "Muhammad Tanvir Afzal"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nRecommending relevant content to the learner is a challenging task for any e-Learning management system. This paper has critically reviewed the literature and identified the strategies being used to recommend relevant content to learners.\nThis paper highlights the strength and limitations of prominent approaches and has presented challenging tasks which will be useful for the e-Learning research community to focus for the future research.", "references": ["Holenko Dlab, M. and Hoic Bozic, N. 2014. Recommender system for web 2.0 supported elearning. In Global Engineering Education Conference (EDUCON), 2014 IEEE (pp. 953--956). IEEE.", "Waßmann, I., Schönfeldt, C. and Tavangarian, D. 2014. WIKI-LEARNIA: SOCIAL E-LEARNING IN A WEB 3.0 ENVIRONMENT. Engineering Sciences & Technologies/Nauki Inzynierskie i Technologie, 4(1).", "Pazzani, M. J. and Billsus, D. 2007. Content-based recommendation systems. In The adaptive web. Springer Berlin Heidelberg.", "Holenko Dlab, M. and Hoic Bozic, N. 2014. Recommender system for web 2.0 supported elearning. In Global Engineering Education Conference (EDUCON), 2014 IEEE (pp. 953--956). IEEE.", "Waßmann, I., Schönfeldt, C. and Tavangarian, D. 2014. WIKI-LEARNIA: SOCIAL E-LEARNING IN A WEB 3.0 ENVIRONMENT. Engineering Sciences & Technologies/Nauki Inzynierskie i Technologie, 4(1).", "Pazzani, M. J. and Billsus, D. 2007. Content-based recommendation systems. In The adaptive web. Springer Berlin Heidelberg.", "Wu, D., Zhang, G. and Lu, J. 2014. A fuzzy tree matching-based personalised e-learning recommender system. In Fuzzy Systems (FUZZ-IEEE), 2014 IEEE International Conference on (pp. 1898--1904). IEEE.", "Kurilovas, E., Zilinskiene, I. and Dagiene, V. 2014. Recommending suitable learning paths according to learners' preferences: Experimental research results. Computers in Human Behavior.", "Romero, C. and Ventura, S. 2007. Educational data mining: A survey from 1995 to 2005. Expert systems with applications, 33(1), 135--146.", "Chandrasekaran, K., Gauch, S., Lakkaraju, P. and Luong, H. P. 2008. Concept-based document recommendations for citeseer authors. In Adaptive Hypermedia and Adaptive Web-Based Systems (pp. 83--92). Springer Berlin Heidelberg.", "Sugiyama, K. and Kan, M. Y. 2010. Scholarly paper recommendation via user's recent research interests. In Proceedings of the 10th annual joint conference on Digital libraries (pp. 29--38). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857251"}, {"title": "Modelling Time-aware Search Tasks for Search Personalisation", "authors": ["Thanh Tien Vu\n,", "Alistair Willis\n,", "Dawei Song"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecent research has shown that mining and modelling search tasks helps improve the performance of search personalisation. Some approaches have been proposed to model a search task using topics discussed in relevant documents, where the topics are usually obtained from human-generated online ontology such as Open Directory Project. A limitation of these approaches is that many documents may not contain the topics covered in the ontology. Moreover, the previous studies largely ignored the dynamic nature of the search task; with the change of time, the search intent and user interests may also change.\nThis paper addresses these problems by modelling search tasks with time-awareness using latent topics, which are automatically extracted from the task's relevance documents by an unsupervised topic modelling method (i.e., Latent Dirichlet Allocation). In the experiments, we utilise the time-aware search task to re-rank result list returned by a commercial search engine and demonstrate a significant improvement in the ranking quality.", "references": ["P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short- and long-term behavior on search personalization. In SIGIR, pages 185--194. ACM, 2012.", "Z. Liao, Y. Song, L.-w. He, and Y. Huang. Evaluating the effectiveness of search task trails. In WWW, pages 489--498. ACM, 2012.", "T. Vu, A. Willis, S. N. Tran, and D. Song. Temporal latent topic user profiles for search personalisation. In ECIR, pages 605--616, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742714"}, {"title": "Toward a Scoring Schema to Rank Candidate Instances of Ontological Classes: Extracting Brazilian Portuguese Texts from the Web", "authors": ["Fabio dos Santos Lima\n,", "Lais do Nascimento Salvador"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nWith the emergence of Information Extraction Systems driven by ontologies, boosted by the Semantic Web, there is a need for the development of scoring schemas that enable the automatic classification of information. These schemas, even so little explored in the Portuguese language, provide measures used in the stage of classification of relevant instances to ontological classes. In this way, this paper presents: (i) a brief discussion about existing scoring measures based on PMI (Pointwise Mutual Information); (ii) new scoring measures based on PMI and Standard Deviation Calculation; and (iii) an evaluation of all discussed measures in the context of Brazilian Portuguese texts from the web.", "references": ["P. Cimiano, S. Handschuh, and S. Staab. Towards the self-annotating web. Proceedings of the 13th conference on World Wide Web - WWW '04, page 462, 2004.", "O. Etzioni, S. Kok, S. Soderland, M. Cafarella, A. m. Popescu, D. S. Weld, D. Downey, T. Shaked, and A. Yates. Web-Scale Information Extraction in KnowItAll (Preliminary Results). pages 100--110, 2004.", "M. A. Hearst. Automatic Acquisition of Hyponyms from Large Text Corpora. pages 23--28, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820465"}, {"title": "Daily-Aware Personalized Recommendation based on Feature-Level Time Series Analysis", "authors": ["Yongfeng Zhang\n,", "Min Zhang\n,", "Yi Zhang\n,", "Guokun Lai\n,", "Yiqun Liu\n,", "Honghui Zhang\n,", "Shaoping Ma"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe frequently changing user preferences and/or item profiles have put essential importance on the dynamic modeling of users and items in personalized recommender systems. However, due to the insufficiency of per user/item records when splitting the already sparse data across time dimension, previous methods have to restrict the drifting purchasing patterns to pre-assumed distributions, and were hardly able to model them rather directly with, for example, time series analysis. Integrating content information helps to alleviate the problem in practical systems, but the domain-dependent content knowledge is expensive to obtain due to the large amount of manual efforts.\nIn this paper, we make use of the large volume of textual reviews for the automatic extraction of domain knowledge, namely, the explicit features/aspects in a specific product domain. We thus degrade the product-level modeling of user preferences, which suffers from the lack of data, to the feature-level modeling, which not only grants us the ability to predict user preferences through direct time series analysis, but also allows us to know the essence under the surface of product-level changes in purchasing patterns. Besides, the expanded feature space also helps to make cold-start recommendations for users with few purchasing records.\nTechnically, we develop the Fourier-assisted Auto-Regressive Integrated Moving Average (FARIMA) process to tackle with the year-long seasonal period of purchasing data to achieve daily-aware preference predictions, and we leverage the conditional opportunity models for daily-aware personalized recommendation. Extensive experimental results on real-world cosmetic purchasing data from a major e-commerce website (JD.com) in China verified both the effectiveness and efficiency of our approach.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-Aware Recommender Systems. Recommender systems handbook, pages 217--253, 2011.", "L. Baltrunas and X. Amatriain. Towards Time Dependant Recommendation based on Implicit Feedback. CARS, 2009.", "G. E. P. Box, G. M. Jenkins, and G. C. Reinsel. Time Series Analysis: Forecasting and Control. John Wiley & Sons, 2013.", "K. P. Burnham and D. R. Anderson. Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach. Springer, 2002.", "P. G. Campos, F. Diez, and I. Cantador. Time-aware Recommender Systems: A Comprehensive Survey and Analysis of Existing Evaluation Protocols. User modeling & user-adapted interaction, 24:67--119, 2014.", "T. Chen, W. Han, H. Wang, Y. Zhou, B. Xu, and B. Zang. Content Recommendation System based on Private Dynamic User Profiling. ICMLC, 2007.", "W. Chen, W. Hsu, and M. Lee. Modeling User's Receptiveness Over Time for Recommendation. SIGIR, pages 373--382, 2013.", "H. Choi and H. Varian. Predicting the Present with Google Trends. Economic Record, 88(s1):2--9, 2012.", "W. Chu and S. Park. Personalized Recommendation on Dynamic Content Using Predictive Bilinear Models. WWW, pages 691--700, 2009.", "X. Ding, B. Liu, and P. S. Yu. A Holistic Lexicon Based Approach to Opinion Mining. WSDM, 2008.", "G. Dror, N. Koenigstein, and Y. Koren. Yahoo! music recommendations: Modeling music ratings with temporal dynamics and item taxonomy. RecSys, 2011.", "Z. Gantner, S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. MyMediaLite: A Free Recommender System Library. RecSys, 2011.", "Z. Gantner, S. Rendle, and L. Schmidt-Thieme. Factorization Models for Context-/Time-Aware Movie Recommendations. CAMRa, pages 14--19, 2010.", "S. Gauch, M. Speretta, A. Chandramouli, and A. Micarelli. User Profiles for Personalized Information Access. The Adaptive Web, pages 54--89, 2007.", "A. Karatzoglou, X. Amatriain, L. Baltrunas, and N. Oliver. Multiverse Recommendation: N-dimensional Tensor Factorization for Context-aware Collaborative Filtering. RecSys, pages 79--86, 2010.", "Y. Koren. Collaborative Filtering with Temporal Dynamics. KDD, pages 447--455, 2009.", "D. D. Lee and H. S. Seung. Algorithms for Non-negative Matrix Factorization. NIPS, 2001.", "Y. Lu, M. Castellanos, U. Dayal, and C. Zhai. Automatic construction of a context-aware sentiment lexicon: An optimization approach. WWW, 2011.", "Z. Lu, D. Agarwal, and I. Dhillon. A Spatio Temporal Approach to Collaborative Filtering. RecSys, 2009.", "K. Oku, S. Nakajima, J. Miyazaki, S. Uemura, and H. Kato. A Recommendation Method Considering Users' Time Series Contexts. ICUIMC, 2009.", "M. J. Pazzani and D. Billsus. Content-Based Recommendation Systems. The Adaptive Web LNCS, pages 325--341, 2007.", "A. M. Popescu and O. Etzioni. Extracting Product Features and Opinions from Reviews. EMNLP, 2005.", "S. Rendle, C. Freudenthaler, Z. Gantner, and L. S. Thieme. BPR: Bayesian Personalized Ranking from Implicit Feedback. UAI, 2009.", "F. Ricci, L. Rokach, and B. Shapira. Introduction to Recommender Systems Handbook. Springer US, 2011.", "Y. Shi, M. Larson, and A. Hanjalic. Mining Mood-specific Movie Similarity with Matrix Factorization for Context-aware Recommendation. CAMRa, pages 34--40, 2010.", "R. H. Shumway and D. S. Stoffer. Time Series Analysis and Its Application. Springer, 2010.", "X. Su and T. M. Khoshgoftaar. A Survey of Collaborative Filtering Techniques. Advances in Artificial Intelligence, 4, 2009.", "G. Takacs, I. Pilaszy, B. Nemeth, and D. Tikk. Investigation of Various Matrix Factorization Methods for Large Recommender Systems. Proc. ICDM, 2008.", "D. Tang, F. Wei, B. Qin, M. Zhou, and T. Liu. Building Large-Scale Twitter-Specific Sentiment Lexicon: A Representation Learning Approach. COLING, pages 172--182, 2014.", "C. Vaca, A. Mantrach, A. Jaimes, and M. Saerens. A Time-based Collective Factorization for Topic Discovery and Monitoring in News. WWW, 2014.", "J. Wang and Y. Zhang. Is It Time For a Career Switch? WWW, pages 1377--1387, 2013.", "J. Wang and Y. Zhang. Opportunity Models for E-commerce Recommendation: Right Product, Right Time. SIGIR, pages 303--312, 2013.", "Y. Wu and M. Ester. FLAME: A Probabilistic Model Combining Aspect Based Opinion Mining and Collaborative Filtering. WSDM, pages 199--208, 2015.", "L. Xiang, Q. Yuan, S. Zhao, L. Chen, X. Zhang, Q. Yang, and J. Sun. Temporal Recommendation on Graphs via Long- and Short-term Preference Fusion. KDD, pages 723--731, 2010.", "D. Xu, Y. Liu, M. Zhang, S. Ma, A. Cui, and L. Ru. Predicting Epidemic Tendency through Search Behavior Analysis. IJCAI, pages 2361--2366, 2011.", "A. Yessenalina, Y. Yue, et al. Multi-level structured models for document-level sentiment classification. EMNLP, pages 1046--1056, 2010.", "Q. Yuan, G. Cong, Z. Ma, A. Sun, and N. M. Thalmann. Time-aware Point-of-interest Recommendation. SIGIR, pages 363--372, 2013.", "Y. Zhang, G. Lai, M. Zhang, Y. Zhang, Y. Liu, and S. Ma. Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis. SIGIR, pages 83--92, 2014.", "Y. Zhang, H. Zhang, M. Zhang, Y. Liu, et al. Do Users Rate or Review? Boost Phrase-level Sentiment Labeling with Review-level Sentiment Classification. SIGIR, pages 1027--1030, 2014.", "Y. Zhang, M. Zhang, Y. Zhang, Y. Liu, and S. Ma. Understanding the Sparsity: Augmented Matrix Factorization with Sampled Constraints on Unobservables. CIKM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741087"}, {"title": "About the 'Compromised Information Need' and Optimal Interaction as Quality Measure for Search Interfaces", "authors": ["Eduard C. Hoenkamp"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTaylor's concept of levels of information need has been cited in over a hundred IR publications since his work was first published. It concerns the phases a searcher goes through, starting with the feeling that information seems missing, to expressing a query to the system that hopefully will provide that information. As every year more IR publications reference Taylor's work, but none of these so much as attempt to formalize the concept they use, it is doubtful that the term is always used with the same connotation. Hence we propose a formal definition of levels of information need, as especially in IR with its formal underpinnings, there is no excuse to leave frequently used terms undefined.\nWe cast Taylor's informally defined levels of information need --- and the transitions between them --- as an evolving dynamical system subsuming two subsystems: the searcher and the search engine. This moves the focus from optimizing the search engine to optimizing the search interface. We define the quality of an interface by how much users need to compromise in order to fill their information need. We show how a theoretical optimum can be calculated that assumes the least compromise from the user.\nThis optimum can be used to establish a base-line for measuring how much a search interface deviates from the ideal, given actual search behavior, and by the same token offers a measure of comparison among competing interfaces.", "references": ["J. Allan, W. B. Croft, A. Moffat, and M. Sanderson. Frontiers, challenges, and opportunities for information retrieval. SIGIR Forum, 46(1):2--32, June 2012.", "L. Azzopardi. The economics in interactive information retrieval. In Proceedings of SIGIR-11, pages 15--24, New York, NY, USA, 2011. ACM.", "N. J. Belkin. Anomalous states of knowledge as a basis for information retrieval. The Canadian Journal of Information Science, 5:133--143, 1980.", "N. J. Belkin, P. Marchetti, and C. Cool. BRAQUE: Design of an interface to support user interaction in information retrieval. Information Processing and Management, 29(3):325--344, 1993.", "A. Binet. The mind and the brain. London: Kegan Paul, Trench, Trübner, 1907.", "A. Broder. A taxonomy of web search. SIGIR FORUM, 36(2):3--10, 2002.", "Y.-W. Chang. The influence of taylors paper, question-negotiation and information-seeking in libraries. Information Processing and Management, 49(5):983 -- 994, 2013.", "F. Crestani and H. Du. Written versus spoken queries: A qualitative and quantitative comparative analysis. JASIST, 57(7):881--890, 2006.", "S. Guiasu. Joint probability distribution of composite quantum systems. International Journal of Theoretical Physics, 26(1):11--20, 1987.", "E. Hoenkamp. On the notion of \"an Information Need\". In L. Azzopardi, G. Kazai, S. Robertson, S. Ruger, M. Shokouhi, D. Song, and E. Yilmaz, editors, Second International Conference on the Theory of Information Retrieval, ICTIR 2009, pages 354--357, 2009.", "E. Hoenkamp. Taming the terabytes: a human-centered approach to surviving the information-deluge. In J. Strother, J. Ulijn, and Z. Fazal, editors, Information Overload : A Challenge to Professional Engineers and Technical Communicators, IEEE PCS professional engineering communication series, pages 147--170. John Wiley & Sons, Ltd, Hoboken, New Jersey, November 2012.", "E. Hoenkamp and P. Bruza. How everyday language can and will boost effective information retrieval. JASIST doi: 10.1002/asi.23279.", "E. T. Jaynes. Information theory and statistical mechanics. Phys. Rev., 106:620--630, May 1957.", "D. Kelly, V. D. Dollu, and X. Fu. The loquacious user: a document-independent source of terms for query expansion. In R. A. Baeza-Yates, N. Ziviani, G. Marchionini, A. Moffat, and J. Tait, editors, SIGIR, pages 457--464. ACM, 2005.", "F. Radlinski, M. Szummer, and N. Craswell. US Patent No. 20110289063. Washington, DC: U.S. Patent and Trademark Office., 2011.", "R. S. Taylor. The process of asking questions. American Documentation, 13(4):391 -- 396, 1962.", "R. S. Taylor. Question-negotiation and information seeking in libraries. College and Research Libraries, 29(3):178--194, 1968.", "S. Verberne, M. van der Heijden, M. Hinne, M. Sappelli, S. Koldijk, E. Hoenkamp, and W. Kraaij. Reliability and validity of query intent assessments. JASIST, 64(11):2224--2237, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767800"}, {"title": "iDiary: From GPS Signals to a Text- Searchable Diary", "authors": ["Dan Feldman\n,", "Cynthia Sung\n,", "Andrew Sugaya\n,", "Daniela Rus"], "publication": "ACM Transactions on Sensor Networks", "abstract": "Abstract\nThis article describes iDiary, a system that takes as input GPS data streams generated by users’ phones and turns them into textual descriptions of the trajectories. The system features a user interface similar to Google Search that allows users to type text queries on their activities (e.g., “Where did I buy books?”) and receive textual answers based on their GPS signals. iDiary uses novel algorithms for semantic compression and trajectory clustering of massive GPS signals in parallel to compute the critical locations of a user. We encode these problems as follows. The k-segment mean is a k-piecewise linear function that minimizes the regression distance to the signal. The (k,m)-segment mean has an additional constraint that the projection of the k segments on Rd consists of only m ≤ k segments. A coreset for this problem is a smart compression of the input signal that allows computation of a (1+ε)-approximation to its k-segment or (k,m)-segment mean in O(nlogn) time for arbitrary constants ε, k, and m. We use coresets to obtain a parallel algorithm that scans the signal in one pass, using space and update time per point that is polynomial in log n. Using an external database, we then map these locations to textual descriptions and activities so that we can apply text mining techniques on the resulting data (e.g., LSA or transportation mode recognition). We provide experimental results for both the system and algorithms and compare them to existing commercial and academic state of the art. This is the first GPS system that enables text-searchable activities from GPS data.", "references": ["M. A. Abam, M. de Berg, P. Hachenberger, and A. Zarei. 2010. Streaming algorithms for line simplification. Discrete & Computational Geometry 43, 3, 497--515.", "ACM SIGSPATIAL Cup training data set. 2012. Retrieved from http://depts.washington.edu/giscup/trainingdata.", "Pankaj K. Agarwal and Nabil H. Mustafa. 2004. k-means projective clustering. In PODS, Alin Deutsch (Ed.). ACM, 155--165.", "J. Allan and others. 2012. Frontiers, Challenges, and Opportunities for Information Retrieval. Report. The Second Strategic Workshop on Information Retrieval in Lorne.", "Luis Otavio Alvares, Vania Bogorny, Bart Kuijpers, Jose Antonio Fernandes de Macedo, Bart Moelans, and Alejandro Vaisman. 2007. A model for enriching trajectories with semantic geographical information. In Proceedings of the 15th Annual ACM International Symposium on Advances in Geographic Information Systems. ACM, 22.", "T. Asano and N. Katoh. 1993. Number theory helps line detection in digital images. In Proceedings of the 4th Annual Internationnal Symposium on Algorithms and Computing. 313--322.", "D. Ashbrook and T. Starner. 2003. Using GPS to learn significant locations and predict movement across multiple users. Personal and Ubiquitous Computing 7, 5, 275--286.", "L. Bao and S. Intille. 2004. Activity recognition from user-annotated acceleration data. Pervasive Computing, 1--17.", "Richard Bellman. 1961. On the approximation of curves by line segments using dynamic programming. Communications of the ACM 4, 6, 284. DOI:http://dx.doi.org/10.1145/366573.366611", "H. Cao, O. Wolfson, and G. Trajcevski. 2006. Spatio-temporal data reduction with deterministic error bounds. The VLDB Journal 15, 3, 211--228.", "G. Chen, B. Chen, and Y. Yu. 2010. Mining frequent trajectory patterns from GPS tracks. In 2010 International Conference on Computer Intelligence and Software Engineering.", "M. Chen, M. Xu, and P. Franti. 2012. Compression of GPS trajectories. In Data Compression Conference (DCC), 2012. IEEE, 62--71.", "Yohan Chon, Nicholas D. Lane, Fan Li, Hojung Cha, and Feng Zhao. 2012. Automatically characterizing places with opportunistic crowdsensing using smartphones. In Proceedings of the 2012 ACM Conference on Ubiquitous Computing. ACM, 481--490.", "Sam Costello. 2015. The 6 Sensors That Make the iPhone So Cool, URL:http://ipod.about.com/od/ipodiphonehardwareterms/qt/iphone-sensors.htm. Last updated: Jan. 13, 2015.", "D. H. Douglas and T. K. Peucker. 1973. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Cartographica 10, 2, 112--122.", "Q. Du, M. Emelianenko, and L. Ju. 2006. Convergence of the Lloyd algorithm for computing centroidal Voronoi tessellations. SIAM Journal on Numerical Analysis, 102--119.", "Lifan Fei and Jin He. 2009. A three-dimensional Douglas--Peucker algorithm and its application to automated generalization of DEMs. International Journal of Geographical Information Science 23, 6, 703--718.", "D. Feldman and M. Langberg. 2010. A unified framework for approximating and clustering data. In Proceedings of the 41st Annual ACM Symposium on Theory of Computing. M anuscript available at arXiv.org.", "D. Feldman, M. Schmidt, and C. Sohler. 2013. Turning big data into tiny data: Constant-size coresets for k-means, PCA and projective clustering. Proceedings of ACM-SIAM Symposium on Discrete Algorithms (SODA). 1434--1454.", "D. Feldman, A. Sugaya, and D. Rus. 2012. An effective coreset compression algorithm for large scale sensor networks. In Proceedings of the 11th International Conference on Information Processing in Sensor Networks. 257--268.", "Dan Feldman, Andrew Sugaya, Cynthia Sung, and Daniela Rus. 2013. iDiary: From GPS signals to a text-searchable diary. In Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems (SenSys’13). Article 6, 12 pages. DOI:http://dx.doi.org/10.1145/2517351.2517366", "D. Feldman, C. Sung, and D. Rus. 2012. The single pixel GPS: Learning big data signals from tiny coresets. In Proceedings of the 20th International Conference on Advances in Geographic Information Systems. ACM, 23--32.", "Dan Feldman, Mikhail V. Volkov, and Daniela Rus. 2015. Dimensionality reduction of massive sparse datasets using coresets. CoRR abs/1503.01663. http://arxiv.org/abs/1503.01663", "I. Foster. 1995. Designing and Building Parallel Programs. Vol. 95. Addison-Wesley Reading, MA.", "Foursquare. 2015. Homepage. Retrieved from https://foursquare.com/.", "Z. Fu, W. Hu, and T. Tan. 2005. Similarity based vehicle trajectory clustering and anomaly detection. In Proceedings of the 2005 IEEE International Conference on Image Processing (ICIP), Vol. 2. II--602.", "M. C. Gonzalez, C. A. Hidalgo, and A. L. Barabási. 2008. Understanding individual human mobility patterns. Nature 453, 7196, 779--782.", "S. Har-Peled. 2006. Coresets for discrete integration and clustering. Proceedings of the 26th International Conference on Foundations of Software Technology and Theoretical Computer Science, 33--44.", "D. M. Hawkins. 1976. Point estimation of the parameters of piecewise regression models. Applied Statistics, 51--57.", "N. Hönle, M. Grossmann, S. Reimann, and B. Mitschang. 2010. Usability analysis of compression algorithms for position data streams. In Proceedings of the 18th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 240--249.", "S. Johansen and K. Juselius. 1990. Maximum likelihood estimation and inference on cointegration with applications to the demand for money. Oxford Bulletin of Economics and Statistics 52, 2, 169--210.", "M. Langberg and L. J. Schulman. 2010. Universal &epsiv; approximators for integrals. Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA). 598--607.", "J. G. Lee, J. Han, and K. Y. Whang. 2007. Trajectory clustering: A partition-and-group framework. In Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data. 593--604.", "P. M. Lerman. 1980. Fitting segmented regression models by grid search. Applied Statistics, 77--84.", "L. Liao. 2006. Location-based Activity Recognition. Ph.D. Dissertation. University of Washington.", "L. Liao, D. Fox, and H. Kautz. 2007. Extracting places and activities from GPS traces using hierarchical conditional random fields. International Journal of Robotics Research 26, 1, 119--134.", "K. Lund and C. Burgess. 1996. Producing high-dimensional semantic spaces from lexical co-occurrence. Behavior Research Methods, Instruments and Computers 28, 203--208.", "C. C. Miller. 2006. A beast in the field: The Google Maps mashup as GIS/2. Cartographica 41, 3, 187--199.", "M. Mun, S. Reddy, K. Shilton, N. Yau, J. Burke, D. Estrin, M. Hansen, E. Howard, R. West, and P. Boda. 2009. PEIR, the personal environmental impact report, as a platform for participatory sensing systems research. In Proceedings of the 7th International Conference on Mobile Systems, Applications, and Services. ACM, 55--68.", "S. Phithakkitnukoon, T. Horanont, G. Di Lorenzo, R. Shibasaki, and C. Ratti. 2010. Activity-aware map: Identifying human daily activity pattern using mobile phone data. Human Behavior Understanding, 14--25.", "Michal Piorkowski, Natasa Sarafijanovic-Djukic, and Matthias Grossglauser. 2009. CRAWDAD data set epfl/mobility (v. 2009-02-24), URL:http://crawdad.cs.dartmouth.edu/epfl/mobility. (Feb. 2009).", "S. Reddy, J. Burke, D. Estrin, M. Hansen, and M. Srivastava. 2007. A framework for data quality and feedback in participatory sensing. In Procedings of the 5th International Conference on Embedded Networked Sensor Systems. ACM, 417--418.", "K. F. Richter, F. Schmid, and P. Laube. 2012. Semantic trajectory compression: Representing urban movement in a nutshell. Journal of Spatial Information Science 4, 3--30.", "Guy Rosman, Mikhail Volkov, Dan Feldman, John W. Fisher, and Daniela Rus. 2014. Coresets for k-segmentation of streaming data. In Advances in Neural Information Processing Systems. 559--567.", "D. Sacharidis, K. Patroumpas, M. Terrovitis, V. Kantere, M. Potamias, K. Mouratidis, and T. Sellis. 2008. On-line discovery of hot motion paths. In Proceedings of the 11th International Conference on Extending DB Technology. ACM, 392--403.", "M. Sharir and P. K. Agarwal. 1995. Davenport-Schinzel Sequences and Their Geometric Applications. Cambridge University Press, New York.", "M. G. Siegler. 2010. Google Latitude Has 3 Million active users. TechCrunch.com. May.", "Richard Szeliski. 2010. Computer Vision: Algorithms and Applications. Springer Science & Business Media.", "TechCrunch. 2012. Foursquare Gets Its Own Searchable Timeline with New History Page. Retrieved from http://techcrunch.com/2012/05/04/foursquare-gets-its-own-searchable-timeline-with-new-history-page/.", "G. Trajcevski, H. Cao, P. Scheuermanny, O. Wolfsonz, and D. Vaccaro. 2006. On-line data reduction and the quality of history in moving objects databases. In Proceedings of the 5th ACM International Workshop on Data Engineering for Wireless and Mobile Access. 19--26.", "F. Van Diggelen. 1998. Innovation: GPS accuracy-lies, damn lies, and statistics. GPS WORLD 9, 41--45.", "V. N. Vapnik and A. Y. Chervonenkis. 1971. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications 16, 2, 264--280.", "Mikhail V. Volkov, Guy Rosman, Dan Feldman, John W. Fisher III, and Daniela Rus. 2015. Coresets for visual summarization with applications to loop closure. In IEEE International Conference on Robotics and Automation, ICRA. Seattle, WA, 26--30 May 2015. IEEE, 3638--3645. DOI:http://dx.doi.org/10.1109/ICRA.2015.7139704", "Z. Yan, D. Chakraborty, C. Parent, S. Spaccapietra, and K. Aberer. 2011. SeMiTri: A framework for semantic annotation of heterogeneous trajectories. In Proceedings of the 14th International Conference on Extending Database Technology. ACM, 259--270.", "Mao Ye, Dong Shou, Wang-Chien Lee, Peifeng Yin, and Krzysztof Janowicz. 2011. On the semantic annotation of places in location-based social networks. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 520--528.", "Yelp. 2015. Yelp Academic Dataset. Retrieved from http://www.yelp.com/academic_dataset.", "J. J. C. Ying, W. C. Lee, T. C. Weng, and V. S. Tseng. 2011. Semantic trajectory mining for location prediction. In Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 34--43."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814569"}, {"title": "Mining Potential High-Utility Itemsets over Uncertain Databases", "authors": ["Jerry Chun-Wei Lin\n,", "Wensheng Gan\n,", "Philippe Fournier-Viger\n,", "Tzung-Pei Hong\n,", "Vincent S. Tseng"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nTraditional high-utility itemsets mining (HUIM) incorporates the concept of utility (e.g., profit) over certain databases. However, an item or itemset is not only present or absent in the transactions but also associated with an existing probability especially the data is collected from the sensor environment. The topic of HUIM from uncertain databases has not yet been addressed though it is commonly seen in real-world applications. In this paper, we propose a novel framework for mining potential high-utility itemsets (PHUIs) over uncertain databases. The upper-bound-based PHUI-UP algorithm is firstly presented to level-wisely mine PHUIs. Based on the probability-utility (PU)-list structure, an improved (PHUI-List) algorithm is further developed to mine PHUIs directly without candidate generation. Substantial experiments are conducted on both real-life and synthetic datasets to show the performance of two designed algorithms in terms of runtime, number of patterns, and scalability.", "references": ["http://fimi.ua.ac.be/data/. 2012.", "C. C. Aggarwal, Y. Li, J. Wang, and J. Wang. Frequent pattern mining with uncertain data. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 29--38, 2009.", "R. Agrawal and R. Srikant. Quest synthetic data generator, 1994. http://www.Almaden.ibm.com/cs/quest/syndata.htm."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818895"}, {"title": "Scalable Multimedia Retrieval by Deep Learning Hashing with Relative Similarity Learning", "authors": ["Lianli Gao\n,", "Jingkuan Song\n,", "Fuhao Zou\n,", "Dongxiang Zhang\n,", "Jie Shao"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nLearning-based hashing methods are becoming the mainstream for approximate scalable multimedia retrieval. They consist of two main components: hash codes learning for training data and hash functions learning for new data points. Tremendous efforts have been devoted to designing novel methods for these two components, i.e., supervised and unsupervised methods for learning hash codes, and different models for inferring hashing functions. However, there is little work integrating supervised and unsupervised hash codes learning into a single framework. Moreover, the hash function learning component is usually based on hand-crafted visual features extracted from the training images. The performance of a content-based image retrieval system crucially depends on the feature representation and such hand-crafted visual features may degrade the accuracy of the hash functions. In this paper, we propose a semi-supervised deep learning hashing (DLH) method for fast multimedia retrieval. More specifically, in the first component, we utilize both visual and label information to learn an relative similarity graph that can more precisely reflect the relationship among training data, and then generate the hash codes based on the graph. In the second stage, we apply a deep convolutional neural network (CNN) to simultaneously learn a good multimedia representation and hash functions. Extensive experiments on three popular datasets demonstrate the superiority of our DLH over both supervised and unsupervised hashing methods.", "references": ["L. Gao, J. Song, F. Nie, Y. Yan, N. Sebe, and H. T. Shen. Optimal graph leaning with partial tags and multiple features. In CVPR, 2015.", "Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. TPAMI, 35(12):2916--2929, 2013.", "K. He, F. Wen, and J. Sun. K-means hashing: An affinity-preserving quantization method for learning binary compact codes. In CVPR, 2013.", "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.", "A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.", "H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In CVPR, 2015.", "G. Lin, C. Shen, Q. Shi, A. van den Hengel, and D. Suter. Fast supervised hashing with decision trees for high-dimensional data. In CVPR, 2014.", "W. Liu, J. Wang, R. Ji, Y. Jiang, and S. Chang. Supervised hashing with kernels. In CVPR, 2012.", "J. Song, Y. Yang, Z. Huang, H. T. Shen, and R. Hong. Multiple feature hashing for real-time large scale near-duplicate video retrieval. In ACM Multimedia, 2011.", "J. Wan, D. Wang, S. C. H. Hoi, P. Wu, J. Zhu, Y. Zhang, and J. Li. Deep learning for content-based image retrieval: A comprehensive study. In ACM Multimedia, 2014.", "J. Wang, H. T. Shen, J. Song, and J. Ji. Hashing for similarity search: A survey. CoRR, abs/1408.2927, 2014.", "Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2008.", "R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, 2014.", "S. Zhang, M. Yang, T. Cour, K. Yu, and D. N. Metaxas. Query specific fusion for image retrieval. In ECCV, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806360"}, {"title": "SHOE: Sibling Hashing with Output Embeddings", "authors": ["Sravanthi Bondugula\n,", "Varun Manjunatha\n,", "Larry S. Davis\n,", "David Doermann"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present a supervised binary encoding scheme for image retrieval that learns projections by taking into account similarity between classes obtained from output embeddings. Our motivation is that binary hash codes learned in this way improve the visual quality of retrieval results by ranking related (or ``sibling'') class images before unrelated class images. We employ a sequential greedy optimization that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors. We develop a joint optimization framework to learn projections which improve the accuracy of supervised hashing over the current state of the art with respect to standard and sibling evaluation metrics. We further obtain discriminative features learned from correlations of kernelized input CNN features and output embeddings, which significantly boosts performance. Experiments are performed on three datasets: CUB-2011, SUN-Attribute and ImageNet ILSVRC 2010, where we show significant improvement in sibling performance metrics over state-of-the-art supervised hashing techniques, while maintaining performance with respect to standard metrics.", "references": ["M. S. Charikar. Similarity estimation techniques from rounding algorithms. STOC, 2002.", "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR, 2009.", "Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In CVPR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806340"}, {"title": "An Interface Sketch for Queripidia: Query-driven Knowledge Portfolios from the Web", "authors": ["Laura Dietz\n,", "Michael Schuhmacher"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nWe aim to augment textual knowledge resources such as Wikipedia with information from the World Wide Web and at the same time focus on a given information need. We demonstrate a solution based on what we call knowledge portfolios. A knowledge portfolio is a query-specific collection of relevant entities together with associated passages from the Web that explain how the entity is relevant for the query. Knowledge portfolios are extracted through a combination of retrieval from World Wide Web and Wikipedia with a reasoning process on mutual relevance. A key ingredient are entity link annotations that tie abstract entities from the knowledge base into their context on the Web. We demonstrate the results of our fully automated system Queripidia, which is capable to create a knowledge portfolios for any web-style query, on data from the TREC Web track. The online demo is available via http://smart-cactus.org/~dietz/knowport/.", "references": ["Evgeniy Gabrilovich, Michael Ringgaard, and Amarnag Subramanya. Facc1: Freebase annotation of clueweb corpora, version 1, 2013.", "Laura Dietz, Michael Schuhmacher, and Simone Paolo Ponzetto. Queripidia: Query-specific Wikipedia construction. In Proc. of AKBC-14, 2014.", "Krisztian Balog, Pavel Serdyukov, and Arjen P de Vries. Overview of the trec 2010 entity track. In Proceedings of the Text Retrieval Conference (TREC), 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810145"}, {"title": "Maximum rank query", "authors": ["Kyriakos Mouratidis\n,", "Jilian Zhang\n,", "HweeHwa Pang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe top-k query is a common means to shortlist a number of options from a set of alternatives, based on the user's preferences. Typically, these preferences are expressed as a vector of query weights, defined over the options' attributes. The query vector implicitly associates each alternative with a numeric score, and thus imposes a ranking among them. The top-k result includes the k options with the highest scores. In this context, we define the maximum rank query (MaxRank). Given a focal option in a set of alternatives, the MaxRank problem is to compute the highest rank this option may achieve under any possible user preference, and furthermore, to report all the regions in the query vector's domain where that rank is achieved. MaxRank finds application in market impact analysis, customer profiling, targeted advertising, etc. We propose a methodology for MaxRank processing and evaluate it with experiments on real and benchmark synthetic datasets.", "references": ["P. K. Agarwal and M. Sharir. Arrangements and their applications. In Handbook of Computational Geometry, pages 49--119. Elsevier, 1998.", "N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. The R*-tree: An efficient and robust access method for points and rectangles. In SIGMOD, pages 322--331, 1990.", "M. D. Berg, O. Cheong, M. V. Kreveld, and M. Overmars. Computational geometry: algorithms and applications. Springer, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824053"}, {"title": "Multi-layer supervised dictionary learning for visual classification", "authors": ["Qiang Guo\n,", "Chengyue Zhang\n,", "Yahong Han"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nFor the task of visual categorization, the learning model is expected to be endowed with discriminative visual feature representation and flexibilities in processing multi-layer categories structure. Many existing approaches are designed based on a flat category structure, or rely on a restricted category structure, hence may not be appreciated for dealing with complex category structure and large numbers of categories. In this paper, we propose a novel dictionary learning method by taking advantage of the hierarchical category structure. A shared discriminative dictionary and a discriminative classification model are learnt for visual categorization. An optimization framework for learning all the components of the proposed model is presented. In the process of optimization, the hierarchical semantic structure among categories is preserved in the dictionary. Experiments on Caltech256 and ImageNet object data subset demonstrate that our approach achieves promising performance on data with large numbers of classes compared with some state-of-the-art methods.", "references": ["M. Aharon, M. Elad, and A. Bruckstein. K-svd: An algorithm for designing overcomplete dictionaries for sparse representation. SIGNAL PROCESSING, 2006.", "A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2009.", "M. R. Boutell, J. Luo, X. Shen, and C. M. Brown. Learning multi-label scene classification. Pattern Recognition, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808502"}, {"title": "Integrating heterogeneous locating services for efficient development of location-based services", "authors": ["Hiroki Takatsuka\n,", "Seiki Tokunaga\n,", "Sachio Saiki\n,", "Shinsuke Matsumoto\n,", "Masahide Nakamura"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThis paper proposes a unified locating service, KULOCS, which horizontally integrates the heterogeneous locating services. Focusing on technology-independent elements [when], [where] and [who] in location queries, KULOCS integrates data and operations of the existing locating services. In the data integration, we propose a method where the time representation, the locations, the namespace are consolidated by Unix time, the location labels and the alias table, respectively. Based on possible combinations of the three elements, we then derive API for the operation integration.\nIn this paper, we also implement KULOCS as a Java Web service and integrate two locating services: GPS-based outdoor locating service and BLE-based indoor locating service. On top of the implementation, we develop application services: Umbrella Reminder Service and Stay Areas Visualization Service. Experimental evaluation shows the practical feasibility by comparing cases with or without KULOCS. Since KULOCS works as a seamless façade to the underlying locating services, the users and applications consume location information easily and efficiently, without knowing concrete services actually locating target objects.", "references": ["Aplix MyBeacon MB004 At-SR. http://www.aplix.co.jp/?page_id=10721. Accessed: 2015-09-01.", "Family Sharing. http://www.apple.com/ios/whats-new/family-sharing/. Accessed: 2015-09-01.", "Glympse. https://www.glympse.com/. Accessed: 2015-09-01."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837229"}, {"title": "Online Video Recommendation in Sharing Community", "authors": ["Xiangmin Zhou\n,", "Lei Chen\n,", "Yanchun Zhang\n,", "Longbing Cao\n,", "Guangyan Huang\n,", "Chen Wang"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nThe creation of sharing communities has resulted in the astonishing increasing of digital videos, and their wide applications in the domains such as entertainment, online news broadcasting etc. The improvement of these applications relies on effective solutions for social user access to video data. This fact has driven the recent research interest in social recommendation in shared communities. Although certain effort has been put into video recommendation in shared communities, the contextual information on social users has not been well exploited for effective recommendation. In this paper, we propose an approach based on the content and social information of videos for the recommendation in sharing communities. Specifically, we first exploit a robust video cuboid signature together with the Earth Mover's Distance to capture the content relevance of videos. Then, we propose to identify the social relevance of clips using the set of users belonging to a video. We fuse the content relevance and social relevance to identify the relevant videos for recommendation. Following that, we propose a novel scheme called sub-community-based approximation together with a hash-based optimization for improving the efficiency of our solution. Finally, we propose an algorithm for efficiently maintaining the social updates in dynamic shared communities. The extensive experiments are conducted to prove the high effectiveness and efficiency of our proposed video recommendation approach.", "references": ["https://spreadsheets.google.com/spreadsheet/pub?key =0am4ow7xs15awchn6z3hka0o4rzzzmktjskcwsfpnrgc& gid=1.", "https://www.elie.net/blog/privacy/19-of-users-use-their-browser-private-mode.", "http://www.marketingcharts.com/direct/online-viewers-prefer-socially-recommend%ed-videos-21011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2749444"}, {"title": "A Computational Approach of Data Smoothening and Prediction of Diabetes Dataset", "authors": ["Shivani Jakhmola\n,", "Tribikram Pradhan"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nData mining when applied on medical diagnosis can help doctors to take major decisions. Diabetes is a disease which has to be monitored by the patient so as not to cause severe damage to the body. Therefore to predict diabetes is an important task that is most important for the patient. In this study, a new data smoothening technique is proposed for noise removal from the data. It is very important for the user to have control over the smoothening of the data so that the information loss can be monitored. The proposed method allows the user to control the level of data smoothening by accepting the loss percentage on the individual data points. Allowable loss is calculated and a decision is made to smoothen the value or retain it to the level which is accurate. The proposed method will enable the user to get the output based on his requirements of preprocessing. The proposed algorithm will allow the user to interact with the data preprocessing system unlike the primitive algorithms. Different levels of smoothened output are obtained by different loss percentage. This preprocessed output produced will be of a better quality and will resemble more to the real world data. Furthermore, correlation and multiple regression is applied on the preprocessed diabetes dataset and a prediction is made on this basis.", "references": ["Han, Jiawei and Kamber, Micheline. 2006. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers Inc", "Pyle, Dorian. 1999. Data Preparation for Data Mining, Volume 1. Morgan Kaufmann Publishers Inc.", "Lin, Zhen, Michael Hewett, and Russ B. Altman. \"Using binning to maintain confidentiality of medical data.\" Proceedings of the AMIA Symposium. American Medical Informatics Association, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791572"}, {"title": "A Probabilistic Model for Information Retrieval Based on Maximum Value Distribution", "authors": ["Jiaul H. Paik"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe main goal of a retrieval model is to measure the degree of relevance of a document with respect to the given query. Probabilistic models are widely used to measure the likelihood of relevance of a document by combining within document term frequency and term specificity in a formal way. Recent research shows that tf normalization that factors in multiple aspects of term salience is an effective scheme. However, existing models do not fully utilize these tf normalization components in a principled way. Moreover, most state of the art models ignore the distribution of a term in the part of the collection that contains the term. In this article, we introduce a new probabilistic model of ranking that addresses the above issues. We argue that, since the relevance of a document increases with the frequency of the query term, this assumption can be used to measure the likelihood that the normalized frequency of a term in a particular document will be maximum with respect to its distribution in the elite set. Thus, the weight of a term in a document is proportional to the probability that the normalized frequency of that term is maximum under the hypothesis that the frequencies are generated randomly. To that end, we introduce a ranking function based on maximum value distribution that uses two aspects of tf normalization. The merit of the proposed model is demonstrated on a number of recent large web collections. Results show that the proposed model outperforms the state of the art models by significantly large margin.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 2002.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In ACM CIKM, 2009.", "C. L. A. Clarke, N. Craswell, I. Soboroff, and E. M. Voorhees. Overview of the trec 2011 web track. In TREC, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767762"}, {"title": "Mobile e-services and open data in e-government processes: transforming citizen involvement", "authors": ["Dan Johansson\n,", "Josefin Lassinantti\n,", "Mikael Wiberg"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nMobile computing is one of the most important paradigms to influence and enhance modern e-services, mainly due to its anytime and anywhere availability adding value to the delivered service. In a traditional e-government context, the service life cycle takes the form of citizens consuming services provided by public sector bodies. In this paper, we use a novel concept combining mobile e-services and open data to extend and allow possible citizen-driven continuation of the service life cycle. The concept is evaluated throughout the design process, and also becomes the subject of a focus group. Our most important conclusions are that the concept design extends the service life cycle within the public sector context, and also creates new entrances for citizens to participate in generating and acquiring open data, thus transforming citizens' involvement. The result is increased co-operation, as well as increased adoption and availability of data and e-services, enhancing citizen participation.", "references": ["N. Al-Dabbous, A. Al-Yatama, and K. Saleh. Assessment of the trustworthiness of e-service providers. In Proceedings of the 2nd Kuwait Conference on e-Services and e-Systems, KCESS '11, pages 24:1--24:7, New York, NY, USA, 2011. ACM.", "L. Bargiotti, M. De Keyzer, S. Goedertier, and N. Loutas. Value-based prioritisation of open government data investments, 2014. European Public Sector Information Platform. Topic Report No. 2014/08.", "B. Bergvall-Kåreborn, A. Broberg, J. Lassinantti, L. Davoli, S. Kuenen, L. Palmquist, P. Parnes, A. Ståhlbröst, K. Synnes, and P. Wennberg. User toolkits for citizen-centric mobile service innovation. In eChallenges e-2012 Conference Proceedings. IIMC International Information Management Corporation Ltd, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837197"}, {"title": "Large-Scale Question Answering with Joint Embedding and Proof Tree Decoding", "authors": ["Zhenghao Wang\n,", "Shengquan Yan\n,", "Huaming Wang\n,", "Xuedong Huang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuestion answering (QA) over a large-scale knowledge base (KB) such as Freebase is an important natural language processing application. There are linguistically oriented semantic parsing techniques and machine learning motivated statistical methods. Both of these approaches face a key challenge on how to handle diverse ways natural questions can be expressed about predicates and entities in the KB. This paper is to investigate how to combine these two approaches. We frame the problem from a proof-theoretic perspective, and formulate it as a proof tree search problem that seamlessly unifies semantic parsing, logic reasoning, and answer ranking. We combine our word entity joint embedding learned from web-scale data with other surface-form features to further boost accuracy improvements. Our real-time system on the Freebase QA task achieved a very high F1 score (47.2) on the standard Stanford WebQuestions benchmark test data.", "references": ["G. Andrew and J. Gao. 2010. Scalable training of L1-regularized log-linear models. In Proceedings of the 24th International Conference on Machine Learning, pages 33--40.", "J. Bao, N. Duan, M. Zhou, T. Zhao. 2014. Knowledge-Based Question Answering as Machine Translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 967--976.", "J. Berant, A. Chou, R. Frostig, and P. Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533--1544."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806616"}, {"title": "Speed-based Load Balancer for Scheduling Reduce Tasks to Process Intermediate Data of MapReduce Applications on Cloud Computing", "authors": ["Tzu-Chi Huang\n,", "Kuo-Chih Chu\n,", "Ce-Kuen Shieh\n,", "Ming-Fong Tsai"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nMapReduce is a programming model used to develop applications on cloud computing. However, MapReduce strongly relies on the runtime system to handle issues of task managements in order to get a better performance. While most research works focus on scheduling Map tasks to improve performances, MapReduce is identified by this paper to have the potential for performance improvements through the Speed-based Load Balancer (SLB) for scheduling Reduce tasks. According to observations on experiments of Inverted Index, Radix Sort and Word Count, MapReduce can use SLB to outperform the native scheduler used by Hadoop in the runtime system.", "references": ["Narasimhan, B. and Nichols, R. 2011. State of Cloud Applications and Platforms: The Cloud Adopters' View. Computer, Vol. 44, Issue 3 (2011), 24--28.", "Vozmediano, R. M., Montero, R. S., and Llorente, I. M. 2013. Key Challenges in Cloud Computing: Enabling the Future Internet of Services. IEEE Internet Computing, Vol. 17, Issue 4 (2013), 18--25.", "Dean, J. and Ghemawat, S. 2008. MapReduce: Simplified Data Processing on Large Clusters. Communications of the ACM, Volume 51, Issue 1 (2008), 107--113."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818880"}, {"title": "Exploring the benefits of using redundant responses in crowdsourced evaluations", "authors": ["Kathryn T. Stolee\n,", "James Saylor\n,", "Trevor Lund"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nCrowdsourcing can be an efficient and cost-effective way to evaluate software engineering research, particularly when the evaluation can be broken down into small, independent tasks. In prior work, we crowdsourced evaluations for a refactoring technique for web mashups and for a source code search engine, both using Amazon's Mechanical Turk. In the refactoring study, preference information was gathered when comparing a refactored with an unrefactored pipe, in addition to a free-text justification. In the code search study, information was gathered about whether a code snippet was relevant to a programming task and why. In both studies, we used redundant metrics and gathered quantitative and qualitative data in an effort to control response quality. Our prior work only analyzed the quantitative results.\nIn this work, we explore the value of using such redundant metrics in crowdsourced evaluations. We code the free-text responses to unveil common themes among the responses and then compare those themes with the quantitative results. Our findings indicate high similarity between the quantitative and free-text responses, that the quantitative results are sometimes more positive than the free-text response, and that some of the qualitative responses point to potential inadequacies with the quantitative questions from the studies.", "references": ["K. T. Stolee and S. Elbaum, \"Refactoring pipe-like mashups for end-user programmers,\" in International Conference on Software Engineering, 2011.", "K. T. Stolee and S. Elbaum, \"Identification, impact, and refactoring of smells in pipe-like web mashups,\" IEEE Trans. Softw. Eng., vol. 39, no. 12, pp. 1654--1679, Dec. 2013. {Online}. Available: http://dx.doi.org/10.1109/TSE.2013.42", "K. T. Stolee, \"Solving the Search for Source Code,\" PhD Thesis, University of Nebraska--Lincoln, August 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820124"}, {"title": "LEMP: Fast Retrieval of Large Entries in a Matrix Product", "authors": ["Christina Teflioudi\n,", "Rainer Gemulla\n,", "Olga Mykytiuk"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nWe study the problem of efficiently retrieving large entries in the product of two given matrices, which arises in a number of data mining and information retrieval tasks. We focus on the setting where the two input matrices are tall and skinny, i.e., with millions of rows and tens to hundreds of columns. In such settings, the product matrix is large and its complete computation is generally infeasible in practice. To address this problem, we propose the LEMP algorithm, which efficiently retrieves only the large entries in the product matrix without actually computing it. LEMP maps the large-entry retrieval problem to a set of smaller cosine similarity search problems, for which existing methods can be used. We also propose novel algorithms for cosine similarity search, which are tailored to our setting. Our experimental study on large real-world datasets indicates that LEMP is up to an order of magnitude faster than state-of-the-art approaches.", "references": ["D. Skillicorn, phUnderstanding complex datasets: data mining with matrix decompositions. Taylor & Francis Ltd, 2007.", "Y. Koren, R. Bell, and C. Volinsky, \"Matrix factorization techniques for recommender systems,\" IEEE Computer, vol. 42, no. 8, pp. 30--37, 2009.", "S. Riedel, L. Yao, B. M. Marlin, and A. McCallum, \"Relation extraction with matrix factorization and universal schemas,\" in HLT-NAACL, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2747647"}, {"title": "Organizational identity, meaning, and values: analysis of social media guideline and policy documents", "authors": ["Laura A. Pasquini\n,", "Nicholas Evangelopoulos"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nWith the increasing use of social media by students, researchers, administrative staff, and faculty in post-secondary education (PSE), a number of institutions have developed guideline and policy documents to set standards for social media use. In this study we analyze social media guidelines and policies across 250 PSE institutions from 10 countries using latent semantic analysis. This initial finding produced a list of 36 universal topics. Subsequently, chi-squared tests were employed to identify distribution differences of content-related factors between American and Non-American PSE institutions. This analysis offered a high-level summary of unstructured text data on the topic of social media guidance. The results include a comprehensive list of recommendations for developing social media guidelines and policies, and a database of social media guideline and policy documents for the PSE sector and other related organizations.", "references": ["Brenner, J. and Smith, A. 2013. 72% of online adults are social networking site users. Retrieved from http://www.pewinternet.org/Reports/2013/social-networking-sites.aspx", "Barger, C. 2011. The social media strategist: Build a successful program from the inside out. New York, NY: McGraw-Hill.", "Chen, B. and Bryer, T. 2012. Investigating instructional strategies for using social media in formal and informal learning. The International Review of Research in Open and Distributed Learning 13, 1, 87--104."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789198"}, {"title": "Web searching by individuals with cognitive disabilities", "authors": ["Redhwan Nour"], "publication": "ACM SIGACCESS Accessibility and Computing", "abstract": "Abstract\nThe ability to search for information on the web can provide tremendous support to people with cognitive disabilities, but there are few research studies with this focus. An exploratory study was conducted to explore how individuals with cognitive disabilities use three searching methods (typing, voice searching with manual microphone control, and hands-free voice searching). The results support a flexible design approach, as the preferences of the participants for the conditions varied. Some preferred typing, since they experienced some voice recognition issues with the microphone, while others chose hands-free voice searching to overcome spelling difficulties. Future work will aim to relate search behaviour of users with cognitive disabilities to their functional capabilities, and to evaluate Google's Search Education lessons to improve searching skills for people with cognitive disabilities.", "references": ["Borg, J., Lantz, A., & Gulliksen, J. (2014). Accessibility to electronic communication for people with cognitive disabilities: a systematic search and review of empirical evidence. Universal Access in the Information Society, 1-16. 2. Braddock, D., Hoehl, J., Tanis, S., Ablowitz, E., & Haffer, L. (2013). The Rights of People With Cognitive Disabilities to Technology and Information Access. Inclusion, 1(2), 95-102. 3. Davies, D. K., Stock, S. E., & Wehmeyer, M. L. (2001). Enhancing independent internet access for individuals with mental retardation through use of a specialized web browser: A pilot study. Education and Training in Mental Retardation and Developmental Disabilities, 36(1), 107-113. 4. Harrysson, B., Svensk, A., & Johansson, G. I. (2004). How people with developmental disabilities navigate the Internet. British Journal of Special Education, 31(3), 138-142. 5. Johnson, R., & Hegarty, J. R. (2003). Websites as educational motivators for adults with learning disability. British Journal of Educational Technology, 34(4), 479-486. 6. Kumin, L., Lazar, J., Feng, J., Wentz, B., & Ekedebe, N. (2012). A usability evaluation of workplace-related tasks on a multi-touch tablet computer by adults with Down syndrome. Journal of Usability Studies, 7(4), 118-142."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809904.2809909"}, {"title": "Reconnecting Digital Publications to the Web using their Spatial Information", "authors": ["Ben De Meester\n,", "Tom De Nies\n,", "Ruben Verborgh\n,", "Erik Mannens\n,", "Rik Van de Walle"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nDigital publications can be packaged and viewed via the Open Web Platform using the EPUB 3 format. Meanwhile, the increased amount of mobile clients and the advent of HTML5's Geolocation have opened a whole range of possibilities for digital publications to interact with their readers. However, EPUB 3 files often remain closed silos of information, no longer linked with the rest of the Web. In this paper, we propose a solution to reconnect digital publication with the (Semantic) Web. We will also show how we can use that connection to improve contextualization for a user, specifically via spatial information. We enrich digital publications by connecting the detected concepts to their URIs on, e.g., DBpedia, and by devising an algorithm to approximate the location of any detected concept, we can provide a user with the spatial center of gravity of his reading position. The evaluation of the location approximation algorithm showed a high recall, and the high correlation between estimation error and standard deviation can provide the user with a sense of correctness (or spread) of an approximation. This means relevant locations (and their possible radius) can be shown for a user, based on the content he or she is reading, and based on his or her location. This methodology can be used to reconnect digital publications with the online world, to entice readers, and ultimately, as a novel location-based recommendation technique.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, and Z. Ives. DBpedia: A nucleus for a Web of Open Data. In 6th International Semantic Web Conference, pages 11--15, Busan, Korea, 2007. Springer.", "S. S. Banerjee and R. R. Dholakia. Mobile advertising: does location based advertising work? International Journal of Mobile Marketing, 3(2):1--23, December 2008.", "G. Conboy, M. Garrish, M. Gylling, W. McCoy, M. Makoto, and D. Weck. EPUB 3 Overview. Technical report, IDPF, June 2014. Accessed January 22nd, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741714"}, {"title": "A Time-aware Random Walk Model for Finding Important Documents in Web Archives", "authors": ["Tu Ngoc Nguyen\n,", "Nattiya Kanhabua\n,", "Claudia Niederée\n,", "Xiaofei Zhu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nDue to their first-hand, diverse and evolution-aware reflection of nearly all areas of life, web archives are emerging as gold-mines for content analytics of many sorts. However, supporting search, which goes beyond navigational search via URLs, is a very challenging task in these unique structures with huge, redundant and noisy temporal content. In this paper, we address the search needs of expert users such as journalists, economists or historians for discovering a topic in time: Given a query, the top-k returned results should give the best representative documents that cover most interesting time-periods for the topic. For this purpose, we propose a novel random walk-based model that integrates relevance, temporal authority, diversity and time in a unified framework. Our preliminary experimental results on the large-scale real-world web archival collection shows that our method significantly improves the state-of-the-art algorithms (i.e., PageRank) in ranking temporal web pages.", "references": ["K. Berberich, M. Vazirgiannis, and G. Weikum. Time-aware authority ranking. Internet Mathematics, 2(3):301--332, 2005.", "X.-Q. Cheng, P. Du, J. Guo, X. Zhu, and Y. Chen. Ranking on data manifold with sink points. Knowledge and Data Engineering, IEEE Transactions on, 25(1):177--191, 2013.", "C. L. Clarke, M. Kolla, G. V. Cormack, O. Vechtomova, A. Ashkan, S. Büttcher, and I. MacKinnon. Novelty and diversity in information retrieval evaluation. In Proceedings of SIGIR'08, pages 659--666."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767832"}, {"title": "Pyc2Sound: a Python tool to convert images into sound", "authors": ["Vincent Bragard\n,", "Thomas Pellegrini\n,", "Julien Pinquier"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis article reports ongoing work on a user interface dedicated to generate sound from pictures and hand drawings. If we imagine what sound would correspond to a given image, on what parameters of the image do we focus and what would the result sound like? In this paper, we try to answer this question by giving a model transforming images into sound based on chosen parameters extracted from the image. For this, an input image is first binarized, then its skeleton is extracted and `tracks' are identified and used to generate chirps in an additive synthesis approach.", "references": ["Audiosculpt: a visual and \"sculptural\" approach to sound manipulation. http://forumnet.ircam.fr/product/audiosculpt/.", "Photosounder. http://photosounder.com/.", "F. Aurenhammer. Voronoi diagrams: a survey of a fundamental geometric data structure. ACM Computing Surveys, 23(3), 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814912"}, {"title": "The digital reality: e-government and access to technology and internet for American Indian and Alaska Native populations", "authors": ["Nicholet Deschine Parkhurst\n,", "Traci Morris\n,", "Emery Tahy\n,", "Karen Mossberger"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nInformation and communications technologies are powerful resources and tools for tribal governments to engage with their constituents, deliver services, conduct efficient and transparent administration, interact with other governments, and carry out policies. Digital government may in many ways be even more critical for tribes than for many other governments. As sovereign nations, tribal governments are engaged in complex relationships with other governments: local, state and federal governments. They are frequently in geographically isolated locations, with often-dispersed populations. The capacity to bridge distance can convey benefits for service delivery and civic engagement, and can connect communities with resources for health, economic development, and education. In this paper, we review research on Native American technology use and the limitations of available data. Because of the contrast between residents of urban areas and tribal lands, we examine differences in cell phone, computer and Internet use for metropolitan and nonmetropolitan Native populations, by education and income. We propose a research agenda utilizing this data, to support action to remedy disparities and to harness the potential of technology for tribal governments.", "references": ["Ayasia, H. (2013). Tribal colleges and universities: Rebuilding culture and education through distance education. Distance Learning, 10(4), 45--51.", "Azure, B. L. (2012, March 1). Digital storytelling is a new way to inform the public. Char-Koosta News. Retrieved from http://www.charkoosta.com/2012/2012_03_01/Digital_storyingtelling_is_a_new_way_to_inform_public.html", "Bennally, K. (2006). The Snowbowl Effect: When Recreation and Culture Collide {Motion picture}. United States: Indigenous Action Media. As cited in Mahoney, M. (2011). This land is your land, this land is my land: An historical narrative of an intergenerational controversy over public use management of the San Francisco Peaks {Thesis}. Arizona State University. Retrieved from http://repository.asu.edu/attachments/56997/content/mahoney_asu_0010n_10960.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757424"}, {"title": "Real-time targeted influence maximization for online advertisements", "authors": ["Yuchen Li\n,", "Dongxiang Zhang\n,", "Kian-Lee Tan"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nAdvertising in social network has become a multi-billion-dollar industry. A main challenge is to identify key influencers who can effectively contribute to the dissemination of information. Although the influence maximization problem, which finds a seed set of k most influential users based on certain propagation models, has been well studied, it is not target-aware and cannot be directly applied to online advertising. In this paper, we propose a new problem, named Keyword-Based Targeted Influence Maximization (KB-TIM), to find a seed set that maximizes the expected influence over users who are relevant to a given advertisement. To solve the problem, we propose a sampling technique based on weighted reverse influence set and achieve an approximation ratio of (1 − 1/e − ε). To meet the instant-speed requirement, we propose two disk-based solutions that improve the query processing time by two orders of magnitude over the state-of-the-art solutions, while keeping the theoretical bound. Experiments conducted on two real social networks confirm our theoretical findings as well as the efficiency. Given an advertisement with 5 keywords, it takes only 2 seconds to find the most influential users in a social network with billions of edges.", "references": ["N. Barbieri, F. Bonchi, and G. Manco. Topic-aware social influence propagation models. In ICDM, pages 81--90, 2012.", "C. Borgs, M. Brautbar, J. T. Chayes, and B. Lucier. Influence maximization in social networks: Towards an optimal algorithmic solution. CoRR, abs/1212.0884, 2012.", "S. Chen, J. Fan, G. Li, J. Feng, K.-l. Tan, and J. Tang. Online topic-aware influence maximization. Proc. VLDB Endow., 8(6):666--677, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794376"}, {"title": "Synonym Discovery for Structured Entities on Heterogeneous Graphs", "authors": ["Xiang Ren\n,", "Tao Cheng"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the increasing use of entities in serving people's daily information needs, recognizing synonyms---different ways people refer to the same entity---has become a crucial task for many entity-leveraging applications. Previous works often take a \"literal\" view of the entity, i.e., its string name. In this work, we propose adopting a \"structured\" view of each entity by considering not only its string name, but also other important structured attributes. Unlike existing query log-based methods, we delve deeper to explore sub-queries, and exploit tailed synonyms and tailed web pages for harvesting more synonyms. A general, heterogeneous graph-based data model which encodes our problem insights is designed by capturing three key concepts (synonym candidate, web page and keyword) and different types of interactions between them. We cast the synonym discovery problem into a graph-based ranking problem and demonstrate the existence of a closed-form optimal solution for outputting entity synonym scores. Experiments on several real-life domains demonstrate the effectiveness of our proposed method.", "references": ["L. M. Aiello, D. Donato, U. Ozertem, and F. Menczer. Behavior-driven clustering of queries into topics. In CIKM, 2011.", "M. Baroni and S. Bisi. Using cooccurrence statistics and the web to discover synonyms in a technical language. In LERC, 2004.", "M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In WSDM, pages 443--452, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2745396"}, {"title": "A Survey on Assessment and Ranking Methodologies for User-Generated Content on the Web", "authors": ["Elaheh Momeni\n,", "Claire Cardie\n,", "Nicholas Diakopoulos"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nUser-generated content (UGC) on the Web, especially on social media platforms, facilitates the association of additional information with digital resources; thus, it can provide valuable supplementary content. However, UGC varies in quality and, consequently, raises the challenge of how to maximize its utility for a variety of end-users. This study aims to provide researchers and Web data curators with comprehensive answers to the following questions: What are the existing approaches and methods for assessing and ranking UGC? What features and metrics have been used successfully to assess and predict UGC value across a range of application domains? What methods can be effectively employed to maximize that value? This survey is composed of a systematic review of approaches for assessing and ranking UGC: results are obtained by identifying and comparing methodologies within the context of short text-based UGC on the Web. Existing assessment and ranking approaches adopt one of four framework types: the community-based framework takes into consideration the value assigned to content by a crowd of humans, the end-user--based framework adapts and personalizes the assessment and ranking process with respect to a single end-user, the designer-based framework encodes the software designer’s values in the assessment and ranking method, and the hybrid framework employs methods from more than one of these types. This survey suggests a need for further experimentation and encourages the development of new approaches for the assessment and ranking of UGC.", "references": ["Fabian Abel, Ilknur Celik, Geert-Jan Houben, and Patrick Siehndel. 2011. Leveraging the semantics of tweets for adaptive faceted search on Twitter. In Proceedings of the 10th International Conference on The Semantic Web, Volume Part I (ISWC’11).", "Eugene Agichtein, Carlos Castillo, Debora Donato, Aristides Gionis, Gilad Mishne, Eugene Agichtein, Carlos Castillo, Debora Donato, Aristides Gionis, and Gilad Mishne. 2008. Finding high-quality content in social media with an application to community-based question answering. In Proceedings of the International Conference on Web Search and Data Mining (WSDM’08).", "Omar Alonso, Catherine C. Marshall, and Marc Najork. 2013. Are some tweets more interesting than others? #Hardquestion. In Proceedings of the Symposium on Human-Computer Interaction and Information Retrieval (HCIR’13). ACM, New York, NY."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811282"}, {"title": "#vote4me: the impact of Twitter on municipal campaign success", "authors": ["Douglas Hagar"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nThis study analyzes the impact of Twitter use on electoral performance in the 2014 Ontario municipal elections. An analysis of the extent of Twitter use, as well as the type of election-related tweets is also presented. It was found that the content of election-related tweets contained minimal discussion of electoral issues, consisting primarily of candidate campaign updates and messages of support from voters. Hashtag discussions follow a similar trend. Despite the shallow depth of discussion, this research suggests that the use of Twitter can have a positive impact on electoral performance for municipal candidates.", "references": ["Bhuiyan, S. 2011. Social media and its effectiveness in the political reform movement in Egypt. Middle East Media Educator 1, 1, 17", "Callamard, A. 2010. MENA journalists & cyber activists: in the line of fire. Global Voices Advocacy. Available at: http://advocacy.globalvoicesonline.org/2011/04/27/mena-journalists-cyber-activists-in-the-line-of-fire/(accessed April 27 2011)", "Ceron, A., Curini, L., and Iacus, S. 2015. Using sentiment analysis to monitor election campaigns: method matters---evidence from the United States and Italy. Social Science Computer Review 33, 1, 3--20."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789190"}, {"title": "How to quantify the impact of lossy transformations on change detection", "authors": ["Pavel Efros\n,", "Erik Buchmann\n,", "Adrian Englhardt\n,", "Klemens Böhm"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nTo ease the proliferation of big data, it frequently is transformed, be it by compression, be it by anonymization. Such transformations however modify characteristics of the data, such as changes in the case of time series. Changes however are important for subsequent analyses. The impact of those modifications depends on the application scenario, and quantifying it is far from trivial. This is because a transformation can shift or modify existing changes or introduce new ones. In this paper, we propose MILTON, a flexible and robust Measure for quantifying the Impact of Lossy Transformations on subsequent change detectiON. MILTON is applicable to any lossy transformation technique on time-series data and to any general-purpose change-detection approach. We have evaluated it with three real-world use cases. Our evaluation shows that MILTON allows to quantify the impact of lossy transformations and to choose the best one from a class of transformation techniques for a given application scenario.", "references": ["G. Acs and C. Castelluccia. I have a dream!(differentially private smart metering). In Information Hiding, 2011.", "S. Barker, A. Mishra, D. Irwin, E. Cecchet, P. Shenoy, and J. Albrecht. Smart*: An open data set and tools for enabling research in sustainable homes. SustKDD Workshop on Data Mining Applications in Sustainability, 2012.", "D. J. Berndt and J. Clifford. Using dynamic time warping to find patterns in time series. In KDD workshop, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791371"}, {"title": "Isn't it time to change the way we think about time?", "authors": ["Larissa Pschetz"], "publication": "Interactions", "abstract": "Abstract\nWe live in a world where everyday objects, digital services, and human beings are increasingly interconnected. This forum aims to offer and promote a rich discussion on the challenges of designing for a broader ecology of materials, artifacts, and practices. --- Elisa Giaccardi, Editor", "references": ["Bastian, M. Fatally confused: Telling time in the midst of ecological crises. Environmental Philosophy 9, 1 (2012).", "Sharma, S. In the Meantime: Temporality and Cultural Politics. Duke Univ. Press, 2014.", "Leshed, G. and Sengers, P. I lie to myself that I have freedom in my own schedule. Proc. of CHI'11. ACM, New York, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809502"}, {"title": "Retrieval from Noisy E-Discovery Corpus in the Absence of Training Data", "authors": ["Anirban Chakraborty\n,", "Kripabandhu Ghosh\n,", "Swapan Kumar Parui"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOCR errors hurt retrieval performance to a great extent. Research has been done on modelling and correction of OCR errors. However, most of the existing systems use language dependent resources or training texts for studying the nature of errors. Not much research has been reported on improving retrieval performance from erroneous text when no training data is available. We propose a novel algorithm for detecting OCR errors and improving retrieval performance on an E-Discovery corpus. Our contribution is two-fold : (1) identifying erroneous variants of query terms for improvement in retrieval performance, and (2) presenting a scope for a possible error-modelling in the erroneous corpus where clean ground truth text is not available for comparison. Our algorithm does not use any training data or any language specific resources like thesaurus. It also does not use any knowledge about the language except that the word delimiter is blank space. The proposed approach obtained statistically significant improvements in recall over state-of-the-art baselines.", "references": ["A. Chakraborty, K. Ghosh, and U. Roy. A word association based approach for improving retrieval performance from noisy ocred text. KDIR '14, pages 450--456, Rome, Italy, Oct. 2014. SCITEPRESS.", "K. Ghosh and A. Chakraborty. Improving ir performance from ocred text using cooccurrence. FIRE RISOT track 2012 working notes, Dec. 2012.", "P. Majumder, M. Mitra, S. K. Parui, G. Kole, P. Mitra, and K. Datta. Yass: Yet another suffix stripper. ACM Trans. on Information Systems, 25(4):18:1--18:20, Oct. 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767828"}, {"title": "Supporting Web Content Development using Web Index", "authors": ["Tomoya Sakusa\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nContent Management Systems (CMS) have been used recently to facilitate dynamic website creation and enable division of labor in web authoring. However, even with the use of CMS, the hyperlinks in websites must be created for every page in the website by author's handwriting. Furthermore, in changing URL, you have to manually change all corresponded hyperlinks one by one. In this study, we develop a CMS plugin using the Web Index System, which allows automate creation of hyperlinks, to collectively manage hyperlinks of invariant words. As a result, the workload involved in the management of hyperlinks in a webpage is considerably reduced and ease of website maintenance is improved.", "references": ["Shu Kin \"Cross-Browser and Cross-Standard Web Data Generation\". A doctoral thesis in Waseda University. 2012.", "Masahiro Hayashi, Motomichi Toyama \"Keio WIX System (1) User Interface (Japanese)\". DEIM '11 The 3rd Forum on Data Engineering and Information Management. 2011.", "Ryosuke Mori, Motomichi Toyama \"Keio WIX System (2) Server Side Implementation (Japanese)\". DEIM '11 The 3rd Forum on Data Engineering and Information Management. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790794"}, {"title": "Enriching data imputation with extensive similarity neighbors", "authors": ["Shaoxu Song\n,", "Aoqian Zhang\n,", "Lei Chen\n,", "Jianmin Wang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIncomplete information often occur along with many database applications, e.g., in data integration, data cleaning or data exchange. The idea of data imputation is to fill the missing data with the values of its neighbors who share the same information. Such neighbors could either be identified certainly by editing rules or statistically by relational dependency networks. Unfortunately, owing to data sparsity, the number of neighbors (identified w.r.t. value equality) is rather limited, especially in the presence of data values with variances. In this paper, we argue to extensively enrich similarity neighbors by similarity rules with tolerance to small variations. More fillings can thus be acquired that the aforesaid equality neighbors fail to reveal. To fill the missing values more, we study the problem of maximizing the missing data imputation. Our major contributions include (1) the np-hardness analysis on solving and approximating the problem, (2) exact algorithms for tackling the problem, and (3) efficient approximation with performance guarantees. Experiments on real and synthetic data sets demonstrate that the filling accuracy can be improved.", "references": ["Full version. http://ise.thss.tsinghua.edu.cn/sxsong/doc/incomplete.pdf.", "P. Bohannon, M. Flaster, W. Fan, and R. Rastogi. A cost-based model and effective heuristic for repairing constraints by value modification. In SIGMOD Conference, pages 143--154, 2005.", "F. Chiang and R. J. Miller. A unified model for data and constraint repair. In ICDE, pages 446--457, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809989"}, {"title": "StoryPivot: Comparing and Contrasting Story Evolution", "authors": ["Anja Gruenheid\n,", "Donald Kossmann\n,", "Theodoros Rekatsinas\n,", "Divesh Srivastava"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nAs the world evolves around us, so does the digital coverage of it. Events of diverse types, associated with different actors and various locations, are continuously captured by multiple information sources such as news articles, blogs, social media etc. day by day. In the digital world, these events are represented through information snippets that contain information on the involved entities, a description of the event, when the event occurred, etc. In our work, we observe that events (and their corresponding digital representations) are often inter-connected, i.e., they form stories which represent evolving relationships between events over time. Take as an example the plane crash in Ukraine in July 2014 which involved multiple entities such as \"Ukraine\", \"Malaysia\", and \"Russia\" and multiple events ranging from the actual crash to the incident investigation and the presentation of the investigator's findings. In this demonstration we present StoryPivot, a framework that helps its users to detect evolving stories in event datasets over time. To resolve stories, we differentiate between story identification, the problem of connecting events over time within a source, and story alignment, the problem of integrating stories across sources. The goal of this demonstration is to present an interactive exploration of both these problems and how events can be dynamically interpreted and put into context in real-world datasets.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line New Event Detection and Tracking. SIGIR, pages 37--45, 1998.", "A. Angel, N. Sarkas, N. Koudas, and D. Srivastava. Dense Subgraph Maintenance Under Streaming Edge Weight Updates for Real-time Story Identification. PVLDB, 5(6):574--585, 2012.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. G. Ives. DBpedia: A Nucleus for a Web of Open Data. ISWC, pages 722--735, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735356"}, {"title": "NeuroIR 2015: Neuro-Physiological Methods in IR Research", "authors": ["Jacek Gwizdka\n,", "Joemon Jose\n,", "Javed Mostafa\n,", "Max Wilson"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis Tutorial+Workshop will discuss opportunities and challenges involved in using neuro-physiological tools/techniques (such as fMRI, fNIRS, EEG, eye-tracking, GSR, HR, and facial expressions) and theories in information retrieval. The hybrid format will engage researchers and students at different levels of expertise, from those who are active in this area to those who are interested and want to learn more. The workshop will combine presentations, discussions and tutorial elements and consist of four segments (tutorial, completed research, work-in-progress, closing panel).", "references": ["Camerer, C.F., Loewenstein, G., and Prelec, D. Neuroeconomics: Why Economics Needs Brains. Scandinavian Journal of Economics 106, 3 (2004), 555--579.", "Cole, M.J., Gwizdka, J., Liu, C., Belkin, N.J., and Zhang, X. Inferring user knowledge level from eye movement patterns. Information Processing & Management 49, 5 (2013), 1075--109", "Dimoka, A., Pavlou, P.A., and Davis, F. NeuroIS: The Potential of Cognitive Neuroscience for Information Systems Research. INFORMATION SYSTEMS RESEARCH, (2010), isre.1100.0284."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767856"}, {"title": "Crowdsourcing ground truth for Question Answering using CrowdTruth", "authors": ["Benjamin Timmermans\n,", "Lora Aroyo\n,", "Chris Welty"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nGathering training and evaluation data for open domain tasks, such as general question answering, is a challenging task. Typically, ground truth data is provided by human expert annotators, however, in an open domain experts are difficult to define. Moreover, the overall process for annotating examples can be lengthy and expensive. Naturally, crowdsourcing has become a mainstream approach for filling this gap, i.e. gathering human interpretation data. However, similar to the traditional expert annotation tasks, most of those methods use majority voting to measure the quality of the annotations and thus aim at identifying a single right answer for each example, despite the fact that many annotation tasks can have multiple interpretations, which results in multiple correct answers to the same question. We present a crowdsourcing-based approach for efficiently gathering ground truth data called CrowdTruth, where disagreement-based metrics are used to harness the multitude of human interpretation and measure the quality of the resulting ground truth. We exemplify our approach in two semantic interpretation use cases for answering questions.", "references": ["Omar Alonso, Daniel E Rose, and Benjamin Stewart. Crowdsourcing for relevance evaluation. In ACM SigIR Forum, volume 42, pages 9--15. ACM, 2008.", "Lora Aroyo and Chris Welty. The Three Sides of CrowdTruth. Journal of Human Computation, 2014.", "Lora Aroyo and Chris Welty. Truth is a lie: Crowd truth and the seven myths of human annotation. AI Magazine, 36(1):15--24, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786492"}, {"title": "Integrated System of Municipal Costs: a Tool to Support Decision Making for Public Manager", "authors": ["Anderson P. Avila-Santos\n,", "Daniel S. Kaster\n,", "Evandro Baccarin\n,", "Leticia F. Negreiros\n,", "Saulo F. Amancio Vieira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper aims at demonstrating the effectiveness of a support tool for the social control of public management, the so-called SICM-Educacao (Integrated System of Municipal Costs and Education), which has been developed at the University of Londrina in a joint effort of the Department of Computing and the Department of Administration. The purpose of such a tool is to allow visualizing and comparing costs of schools, e.g. within a city. The paper shows a case study using the proposed tool over data obtained from one of the conducted surveys, regarding the city of Assai/PR. It is also shown how the tool can be used to visualize the collected data and how it can be used to aid decision-making in public power, which enforces transparency and citizens control over the public administration.", "references": ["F. L. Abrucio. Trajetória recente da gestão pública brasileira: um balanço crítico ea renovação da agenda de reformas. Revista de Administração Pública, 41(spe):67-86, 2007.", "M. Alonso. Custo no serviço público. Texto para Discussão, (31), 2008.", "E. M. ALVES FILHO and A. L. MARTINEZ. Gestão de custos numa secretaria municipal de educação. In CONGRESSO BRASILEIRO DE CUSTOS, XIII, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814162"}, {"title": "Visually Fingerprinting Humans without Face Recognition", "authors": ["He Wang\n,", "Xuan Bao\n,", "Romit Roy Choudhury\n,", "Srihari Nelakuditi"], "publication": "MobiSys '15: Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services", "abstract": "ABSTRACT\nThis paper develops techniques using which humans can be visually recognized. While face recognition would be one approach to this problem, we believe that it may not be always possible to see a person?s face. Our technique is complementary to face recognition, and exploits the intuition that human motion patterns and clothing colors can together encode several bits of information. Treating this information as a \"temporary fingerprint\", it may be feasible to recognize an individual with reasonable consistency, while allowing her to turn off the fingerprint at will.\nOne application of visual fingerprints relates to augmented reality, in which an individual looks at other people through her camera-enabled glass (e.g., Google Glass) and views information about them. Another application is in privacy-preserving pictures ? Alice should be able to broadcast her \"temporary fingerprint\" to all cameras in the vicinity along with a privacy preference, saying \"remove me\". If a stranger?s video happens to include Alice, the device can recognize her fingerprint in the video and erase her completely. This paper develops the core visual fingerprinting engine ? InSight ? on the platform of Android smartphones and a backend server running MATLAB and OpenCV. Results from real world experiments show that 12 individuals can be discriminated with 90% accuracy using 6 seconds of video/motion observations. Video based emulation confirms scalability up to 40 users.", "references": ["Qualcomm Vuforia. https://www.qualcomm.com/products/vuforia.", "Videoguide, Antoni Gaudi Modernist Museum in Barcelona. http://www.casabatllo.es/en/visit/videoguide.", "A. Ashok, M. Gruteser, N. Mandayam, J. Silva, M. Varga, and K. Dana. Challenge: mobile optical networks through visual MIMO. In ACM MobiCom, pages 105--112, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742647.2742671"}, {"title": "Predicting Personality Traits with Instagram Pictures", "authors": ["Bruce Ferwerda\n,", "Markus Schedl\n,", "Marko Tkalcic"], "publication": "EMPIRE '15: Proceedings of the 3rd Workshop on Emotions and Personality in Personalized Systems 2015", "abstract": "ABSTRACT\nInstagram is a popular social networking application, which allows photo-sharing and applying different photo filters to adjust the appearance of a picture. By applying photo filters, users are able to create a style that they want to express to their audience. In this study we tried to infer personality traits from the way users take pictures and apply filters to them. To investigate this relationship, we conducted an online survey where we asked participants to fill in a personality questionnaire, and grant us access to their Instagram account through the Instagram API. Among 113 participants and 22,398 extracted Instagram pictures, we found distinct picture features (e.g., hue, brightness, saturation) that are related to personality traits. Our findings suggest a relationship between personality traits and the way users want to make their pictures look. This allow for new ways to extract personality traits from social media trails, and new ways to facilitate personalized systems.", "references": ["M. D. Back, J. M. Stopfer, S. Vazire, S. Gaddis, S. C. Schmukle, B. Egloff, and S. D. Gosling. Facebook profiles reflect actual personality, not self-idealization. Psychological science, 2010.", "B. Ferwerda and M. Schedl. Enhancing music recommender systems with personality information and emotional states: A proposal. In Proceedings of the 2nd EMPIRE Workshop, pages 1613--0073, 2014.", "B. Ferwerda, M. Schedl, and M. Tkalcic. Personality & emotional states: Understanding users' music listening needs. UMAP 2015 Extended Proceedings, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809643.2809644"}, {"title": "The practice of selfies", "authors": ["Angelica Svelander\n,", "Mikael Wiberg"], "publication": "Interactions", "abstract": "", "references": ["http://www.oxforddictionaries.com/definition/english/selfie", "Buffardi, L.E. and Campbell, W.K. Narcissism and social networking web sites. Personality and Social Psychology Bulletin 34, 10 (2008), 1303--1314.", "Bergman, S.M., Fearrington, M.E., Davenport, S.W., and Bergman, J.Z. Millenials, narcissism, and social networking: What narcissists do on social networking sites and why. Personality and Individual Differences 50, 5 (2011), 706--711."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2770886"}, {"title": "A Reference Architecture for a Crowdsensing Platform in Smart Cities", "authors": ["Herbertt B. M. Diniz\n,", "Emanoel C. G. F. Silva\n,", "Kiev Santos da Gama"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nDue to the problems caused by population growth in large cities, there is a need for solutions that point to the initiative of Smart Cities, that is, using the technology to offer resources that can help solve or minimize urban problems. This solutions seeks the integration of several sources of Information Technology(ICTs), however, those source of Information Technology form complex structures and generate a large volume of data, that represents big challenges and opportunities, impeding the possibility of to make available, systems that integrate informations of sensors and capture data from the physical space, getting samples of what is going on in the city in real time. With the intention of offer a reference architecture, to compare issues related with those challenges and opportunities, this paper presents an approach that employs components off-the-shelves for the construction of a crowdsensing platform for solution in Smart Cities. We performed an experiment to determine the performance and stability of the system. Thus, this proposal opens the way for to broaden the integration of data sources of various types of sensors and devices.", "references": ["Bikepe. http://www.bikepe.com/. Acessado em 1 Fev de 2015.", "Espertech. http://www.espertech.com. Acessado em 1 Jan de 2015.", "Rabbitmq, clustering guide. http://www.rabbitmq.com/clustering.html. Acessado em 1 Jan de 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814074"}, {"title": "On the Trade-Offs among Performance, Energy, and Endurance in a Versatile Hybrid Drive", "authors": ["Zhichao Li\n,", "Ming Chen\n,", "Amanpreet Mukker\n,", "Erez Zadok"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nThere are trade-offs among performance, energy, and device endurance for storage systems. Designs optimized for one dimension or workload often suffer in another. Therefore, it is important to study the trade-offs to enable adaptation to workloads and dimensions. As Flash SSD has emerged, hybrid drives have been studied more closely. However, hybrids are mainly designed for high throughput, efficient energy consumption, or improving endurance—leaving quantitative study on the trade-offs unexplored. Past endurance studies also lack a concrete model to help study the trade-offs. Last, previous designs are often based on inflexible policies that cannot adapt easily to changing conditions.\nWe designed and developed GreenDM, a versatile hybrid drive that combines Flash-based SSDs with traditional HDDs. The SSD can be used as cache or as primary storage for hot data. We present our endurance model together with GreenDM to study these trade-offs. GreenDM presents a block interface and requires no modifications to existing software. GreenDM offers tunable parameters to enable the system to adapt to many workloads. We have designed, developed, and carefully evaluated GreenDM with a variety of workloads using commodity SSD and HDD drives. We demonstrate the importance of versatility to enable adaptation to various workloads and dimensions.", "references": ["D. G. Andersen, J. Franklin, M. Kaminsky, A. Phanishayee, L. Tan, and V. Vasudevan. 2009. FAWN: A fast array of wimpy nodes. In Proceedings of the 22nd ACM Symposium on Operating Systems Principles (SOSP’2009). ACM SIGOPS, New York, NY, 1--14.", "L. A. Barroso and U. Hölzle. 2009. The datacenter as a computer: An introduction to the design of warehouse-scale machines. Synthesis Lectures on Computer Architecture 4, 1, 1--108.", "bcache 2015. Bcache. Retrieved July 5, 2015 from http://bcache.evilpiepirate.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700312"}, {"title": "Verification of POI and Location Pairs via Weakly Labeled Web Data", "authors": ["Hsiu-Min Chuang\n,", "Chia-Hui Chang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the increased popularity of mobile devices and smart phones, location-based services (LBS) have become a common need in our daily life. Therefore, maintaining the correctness of POI (Points of Interest) data has become an important issue for many location-based services such as Google Maps and Garmin navigation systems. The simplest form of POI contains a location (e.g., represented by an address) and an identifier (e.g., an organization name) that describes the location. As time goes by, the POI relationship of a location and organization pair may change due to the opening, moving, or closing of a business. Thus, effectively identifying outdated or emerging POI relations is an important issue for improving the quality of POI data. In this paper, we examine the possibility of using location-related pages on the Web to verify existing POI relations via weakly labeled data, e.g., the co-occurrence of an organization and an address in Web pages, the published date of such pages, and the pairing diversity of an address or an organization, etc. The preliminary result shows a promising direction for discovering emerging POI and mandates more research for outdated POI.", "references": ["Ahlers, D. and Boll, S.: Location-based Web Search. In: The Geospatial Web, 55--66, Springer, 2007.", "Ahlers D.: Business Entity Retrieval and Data Provision for Yellow Pages by Local Search. In: ECIR, 2013.", "Ahlers D.: Lo mejor de dos idiomas - Cross-Lingual Linkage of Geotagged Wikipedia Articles. In: ECIR, 668--671, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741715"}, {"title": "Data Mining Citation Databases: A New Index Measure that Predicts Nobel Prizewinners", "authors": ["Peter Z. Revesz"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nA new citations index measure that combines total citations and h-index values is proposed. Based on the new citation index, a new algorithm that identifies emerging scientific leaders is also proposed. Experimental results show that the new method can predict Physics Nobel prizewinners from among other highly cited physics researchers many years ahead of their winning of a Nobel Prize. Hence while neither total citations nor h-index alone were good indicators, their combinations can be significant predictors of excellence in science.", "references": ["Acuna, D. E., Allesina, S., and Kording. K. P. 2012. Future impact: Predicting scientific success. Nature, 489, 7415 (September 2012), 201--202", "Aitkenhead D. 2013. Peter Higgs: I wouldn't be productive enough for today's academic system, The Guardian, 6 December 2013.", "Brenner S. 2014. Retrospective: Frederick Sanger (1918-2013), Science, volume 343, page 262, 17 January 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790763"}, {"title": "Optimizing application downtime through intelligent VM placement and migration in cloud data centers", "authors": ["Venkatesh Nandakumar\n,", "Alan Wen Jun Lu\n,", "Madalin Mihailescu\n,", "Zartab Jamil\n,", "Cristiana Amza\n,", "Harsh V. P. Singh"], "publication": "CASCON '15: Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nAs cloud data centres grow in size and complexity, hosted applications become increasingly vulnerable to dynamically occurring infrastructure downtime periods caused by partial infrastructure failures. Downtimes within cloud data centres can be diverse, ranging from unplanned server/rack unit failures to compulsory server power-offs when addressing arbitrary environment conditions, e.g., thermal issues. For instance, in these environments, server racks are often a unit of failure due to either faulty rack switches or rack power units.\nWe observe that the degree of application disruption depends on i) the application's fault tolerance, reconfiguration capabilities, and redundancy of VM components affected by the respective emergency shutdowns and ii) the support for VM migration of vulnerable application components within the constrained time window of impending shutdown of a failure unit.\nIn this context, in this paper, we develop and evaluate techniques which aim to optimize the downtime of hosted applications during emergency shutdowns due to partial failures through two orthogonal approaches: i) designing VM placement techniques that are aware of application fail-over semantics and ii) prototyping intelligent schemes for live VM migration prioritization based on prediction models for both VM migration times and expected downtimes for applications.", "references": ["http://aws.amazon.com/ec2.", "http://www.xen.org.", "http://www.vmware.com."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2886444.2886450"}, {"title": "Hyper Video Browser: Search and Hyperlinking in Broadcast Media", "authors": ["Maria Eskevich\n,", "Huynh Nguyen\n,", "Mathilde Sahuguet\n,", "Benoit Huet"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nMassive amounts of digital media is being produced and consumed daily on the Internet. Efficient access to relevant information is of key importance in contemporary society. The Hyper Video Browser provides multiple navigation means within the content of a media repository. Our system utilizes the state of the art multimodal content analysis and indexing techniques, at multiple temporal granularity, in order to satisfy the user need by suggesting relevant material. We integrate two intuitive interfaces: for search and browsing through the video archive, and for further hyperlinking to the related content while enjoying some video content. The novelty of this work includes a multi-faceted search and browsing interface for navigating in video collections and the dynamic suggestion of hyperlinks related to a media fragment content, rather than the entire video, being viewed. The approach was evaluated on the MediaEval Search and Hyperlinking task, demonstrating its effectiveness at locating accurately relevant content in a big media archive.", "references": ["E. Apostolidis, V. Mezaris, M. Sahuguet, B. Huet, B. Cervenková, D. Stein, S. Eickeler, J. L. Redondo Garcia, R. Troncy, and L. Pikora. Automatic fine-grained hyperlinking of videos within a closed collection using scene segmentation. In ACMMM 2014, 22nd ACM International Conference on Multimedia, Orlando, Florida, USA, 11 2014.", "M. Eskevich, R. Aly, D. N. Racca, R. Ordelman, S. Chen, and G. J. Jones. The Search and Hyperlinking Task at MediaEval 2014. In Proceedings of MediaEval 2014 Workshop, Barcelona, Catalunya, Spain, 2014.", "H. Le, Q. Bui, B. Huet, B. Cervenková, J. Bouchner, E. E. Apostolidis, F. Markatopoulou, A. Pournaras, V. Mezaris, D. Stein, S. Eickeler, and M. Stadtschnitzer. LinkedTV at MediaEval 2014 Search and Hyperlinking Task. In Proceedings of MediaEval 2014 Workshop, Barcelona, Catalunya, Spain, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2812618"}, {"title": "Study about users' engagement of a governmental social media", "authors": ["Camila Mariane C. Silva\n,", "Edmir Parada Vasques Prado"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe social media use has been diffusing since they are enabling information sharing and the creation of virtual communities and interaction mechanisms. Due to its characteristics, public agencies have used social media for mobilizing, inform and call their public to take part of social participation. However, if this kind of tool is capable to promote engagement in the public, is still a matter to be worried of. Thus, this study aims to analyze how a governmental social media's functionalities influence the engagement of users. Then a netnography study was accomplished. In this study we observed and analyzed interactions from a community in a social media platform that was released by the Brazilian federal government. Finally, we verified that some of its resources were not well explored by users. Even if they got through the process of engagement, their use experience was not so satisfactory to make them keep their access frequency.", "references": ["Mergel, I. 2012. The social media innovation challenge in the public sector. Information Policy, 17, 3-4, 281-292.", "Zhang, W., Johnson, T. J., Seltzer, T. e Bichard, S. L. 2010. The revolution will be networked: the influence of social networking sites on political attitudes and behavior. Social Science Computer Review, 28, 1, 75-92.", "Attfield, S., Kazai, G., Lalmas, M. e Piwowarski, B. 2011. Towards a science of user engagement. In Proceedings of the 4th ACM International Conference on Web Search and Data Mining [Position paper] (Fev. 2011)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814157"}, {"title": "GENERATE eHTML: Embedding SuperSQL Queries in HTML", "authors": ["Masato Kiya\n,", "Kento Goto\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nSuperSQL is a database publishing/presentation extension of SQL that can generate various kinds of structured documents that contain values stored in RDBs. Thanks to a useful tools, it is becomes easily to creating web application. However, users need a lot of knowledge about various programing languages such as HTML, CSS, PHP, JavaScript, and so on to create Web applications.\nIn this article, we propose a method to directly embed SuperSQL queries in a HTML file to facilitate the development of web applications.", "references": ["W3Techs. \"Usage Statistics and Market Share of PHP for Websites,\" http://w3techs.com.", "S. Artzi, A. Kiezun, J. Dolby, F. Tip, D. Dig, A. M. Paradkar, and M. D. Ernst, \"Finding Bugs in Web Applications Using Dynamic Test Generation and Explicit-State Model Checking\" IEEE TSE, . vol. 36, no. 4, pp. 474-494, 2010.", "Motomichi Toyama, \"SuperSQL: An Extended SQL for Database Publishing and Presentation\" Proceedings of ACM SIGMOD '98 International Conference on Management of Data, pp. 584-586, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790788"}, {"title": "Aggregation and multidimensional analysis of big data for large-scale scientific applications: models, issues, analytics, and beyond", "authors": ["Alfredo Cuzzocrea"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nAggregation and multidimensional analysis are well-known powerful tools for extracting useful knowledge, shaped in a summarized manner, which are being successfully applied to the annoying problem of managing and mining big data produced by large-scale scientific applications. Indeed, in the context of big data analytics, aggregation approaches allow us to provide meaningful descriptions of these data, otherwise impossible for alternative data-intensive analysis tools. On the other hand, multidimensional analysis methodologies introduce fortunate metaphors that significantly empathize the knowledge discovery phase from such huge amounts of data. Following this main trend, several big data aggregation and multidimensional analysis approaches have been proposed recently. The goal of this paper is to (i) provide a comprehensive overview of state-of-the-art techniques and (ii) depict open research challenges and future directions adhering to the reference scientific field.", "references": ["ADIOS, http://www.olcf.ornl.gov/center-projects/adios/", "D. Al-Hajjar, N. Jaafar, M. Al-Jadaan, R. Alnutaifi, \"Framework for Social Media Big Data Quality Analysis\", ADBIS 2014, 2014", "X. Amatriain, \"Mining Large Streams of User Data for Personalized Recommendations\", SIGKDD Explorations 14(2), 2012"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791377"}, {"title": "Toward Analyzing Privacy and Utility of Mobile User Data", "authors": ["Shyue-Liang Wang\n,", "Min-Jye Hsiu\n,", "I-Hsien Ting\n,", "Tzung-Pei Hong"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nMobile user data are collected around the clock and through agile service providers which can offer great services for health cares, business activities, and other personal or social services, etc. However, data could be misused and privacy could potentially be breached which might lead to harmful consequences. A few privacy-preserving techniques have been proposed to anonymize sensitive mobile context before releasing data to service providers. Nevertheless, it also reduces the utility of data that supposed to provide helpful services. As such, we propose a unified approach to define privacy gain and utility loss due to anonymizing sensitive context on mobile user data. Evaluation on various anonymization techniques, comparisons of their performances and trade-offs between privacy and utility are presented and analyzed.", "references": ["Agarwal, Y., and Hall, M. 2013. ProtectMyPrivacy: detecting and mitigating privacy leaks on iOS devices using crowdsourcing. Proceeding of the 11th annual international conference on Mobile systems, applications, and services. ACM.pp. 97--110.", "Brickell, J., and Shmatikov, V. 2008. The cost of privacy: destruction of data-mining utility in anonymized data publishing. Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM.pp. 70--78.", "Chakraborty, S., Raghavan, K. R., Johnson, M. P., and Srivastava, M. B. 2013. A framework for context-aware privacy of sensor data on mobile systems. Proceedings of the 14th Workshop on Mobile Computing Systems and Applications. ACM. Article No. 11."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818909"}, {"title": "WEMAREC: Accurate and Scalable Recommendation through Weighted and Ensemble Matrix Approximation", "authors": ["Chao Chen\n,", "Dongsheng Li\n,", "Yingying Zhao\n,", "Qin Lv\n,", "Li Shang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMatrix approximation is one of the most effective methods for collaborative filtering-based recommender systems. However, the high computation complexity of matrix factorization on large datasets limits its scalability. Prior solutions have adopted co-clustering methods to partition a large matrix into a set of smaller submatrices, which can then be processed in parallel to improve scalability. The drawback is that the recommendation accuracy is lower as the submatrices only contain subsets of the user-item rating information. This paper presents WEMAREC, a weighted and ensemble matrix approximation method for accurate and scalable recommendation. It builds upon the intuition that (sub)matrices containing more frequent samples of certain user/item/rating tend to make more reliable rating predictions for these specific user/item/rating. WEMAREC consists of two important components: (1) a weighting strategy that is computed based on the rating distribution in each submatrix and applied to approximate a single matrix containing those submatrices; and (2) an ensemble strategy that leverages user-specific and item-specific rating distributions to combine the approximation matrices of multiple sets of co-clustering results. Evaluations using real-world datasets demonstrate that WEMAREC outperforms state-of-the-art matrix approximation methods in recommendation accuracy (0.5?11.9% on the MovieLens dataset and 2.2--13.1% on the Netflix dataset) with 3--10X improvement on scalability.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engeering, 17(6):734--749, 2005.", "A. Banerjee, I. Dhillon, J. Ghosh, S. Merugu, and D. S. Modha. A generalized maximum entropy approach to bregman co-clustering and matrix approximation. The Journal of Machine Learning Research, 8:1919--1986, 2007.", "R. Bell, Y. Koren, and C. Volinsky. Modeling relationships at multiple scales to improve accuracy of large recommender systems. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 95--104. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767718"}, {"title": "Embedding sound localization and spatial audio interaction through coincident microphones arrays", "authors": ["N. Vryzas\n,", "C. A. Dimoulas\n,", "G. V. Papanikolaou"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis paper discusses a methodology for embedding sound localization techniques for spatial audio interaction, aiming at matching the low computing capabilities of mobile and embedded systems. The main goal is to implement a sound localization system, using a microphone array that combines increased accuracy with compromised computational load and applicable layout size. In particular, four cardioid microphones are placed in a cross-shape arrangement, thus forming a planar coincident microphones array for horizontal direction of arrival estimation. The incorporation of two additional microphones at the perpendicular plane is also considered for 3D audio localization. The implemented system is evaluated through simulation experiments and real-world field measurements in comparison to B-Format based localization. Joint time frequency analysis is considered for improving the localization accuracy in pure SNR conditions. The utilization of multiple arrays is also discussed for 2D and 3D position estimations, as well as signal enhancement by means of time-delay compensation.", "references": ["Bamford, J. S. 1995. An Analysis of Ambisonic Sound Systems of First and Second Order. Master of Science in Physics Thesis. Waterloo Ontario Canada.", "Benjamin, E., Chen, T. 2005. The Native B-format Microphone: Part I. Audio Engineering Society. New York.", "Benjamin, E., Chen, T. 2005. The Native B-format Microphone: Part II. Audio Engineering Society. New York."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814917"}, {"title": "Result List Actions in Fiction Search", "authors": ["Pertti Vakkari\n,", "Janna Pöntinen"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIt is studied how users browse search results to find interesting novels for four search scenarios. It is evaluated in particular whether there are differences in search result page (SERP) browsing patterns and effectiveness between an enriched catalog for finding fiction compared to a traditional public library catalog. The data was collected from 30 participants by eye-tracking and questionnaires. The results indicate that the enriched catalog supported users to identify sooner and more effectively potentially clickable items on the results list compared to a traditional public library catalog. This is likely due to the more informative metadata in the enriched catalog like snippets of content description on the result list items. The discussion includes a theoretical and empirical comparison of findings in studies on fiction and non-fiction searching.", "references": ["Adkins, D. & Bossaller, J. E. 2007. Fiction access points across computer-mediated book information sources: a comparison of online bookstores, reader advisory databases, and public library catalogs. Libr Inform Sci Res, 29, 354--368. DOI = http://dx.doi.org/10.1016/j.lisr.2007.03.004.", "Cutrell, E., & Guan, Z. 2007. What are you looking for? An eye-tracking study of information usage in web search. In Proceedings of the ACM HCI 2007 Conference on Human factors in computing systems. ACM, New York, NY, 407--415.", "Goodall, D. 1989. Browsing in the public libraries. LISU Occasional paper No 1. Library and Information Statistics Unit, Loughborough."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756911"}, {"title": "The case law of the Italian constitutional court, its power laws, and the web of scholarly opinions", "authors": ["Tommaso Agnoloni\n,", "Ugo Pagallo"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nThe paper examines the citation network of the via incidentale rulings of the Italian Constitutional Court (\"ICC\"), vis-à-vis the web of scholarly opinions, comments, and annotations, devoted to such cases. The aim is to deepen the notion of legal relevance. On the one hand, a remarkable number of cases that are considerably discussed by experts, are neither hubs nor authorities in the ICC citation network. On the other hand, cases that are relevant in the ICC citation network are scarcely debated, or even ignored, by scholars. This twofold outcome suggests that we should combine research on the citation network of the courts with the web of scholarly opinions, to obtain a more detailed picture of which decisions and verdicts have to be reckoned as relevant in a given legal system.", "references": ["Agnoloni, T. and U. Pagallo 2014. The Case Law of the Italian Constitutional Court between Network Theory and Philosophy of Information, NAIL Workshop at Jurix, Krakow (Poland), December.", "Fowler, J. H., and S. Jeon 2008. The Authority of Supreme Court Precedent, Social Networks, 30: 16--30.", "Malmgren, S. 2011. Towards a Theory of Jurisprudential Relevance Ranking: Using Link Analysis on EU Case Law. Master of Laws degree at Stockholm University."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746108"}, {"title": "Towards Searching Amongst Tables", "authors": ["Paul Thomas\n,", "Rollin Omari\n,", "Tom Rowlands"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nAn increasing number of data sets are being published online, in institutional or government repositories as well as by individual researchers, journalists, and others. These data are often represented as tables of various kinds: however, repositories have poor search over and inside tables. It is difficult for a user to tell from a repository's portal whether a useful dataset is available, and this problem is only likely to get worse.\nWe describe this problem, and demonstrate that the naïve approach of full-text search is not appropriate. We describe an alternative, based on inferring types of data and indexing columns as a unit, and demonstrate some improvements in early success especially when long captions are not available.", "references": ["Marco D Adelfio and Hanan Samet. Schema extraction for tabular data on the web. Proc. VLDB Endowment, 6(6):421--432, 2013.", "David W Embley, Matthew Hurst, Daniel Lopresti, and George Nagy. Table-processing paradigms: a research survey. Int. J of Document Analysis and Recognition, 8(2--3):66--86, 2006.", "Ying Liu, Kun Bai, Prasenjit Mitra, and C. Lee Giles. TableSeer: Automatic table metadata extraction and searching in digital libraries. In Proc. JCDL, pages 91--100, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838941"}, {"title": "Efficient Rebuilding of Large Java Heaps from Event Traces", "authors": ["Verena Bitto\n,", "Philipp Lengauer\n,", "Hanspeter Mössenböck"], "publication": "PPPJ '15: Proceedings of the Principles and Practices of Programming on The Java Platform", "abstract": "ABSTRACT\nUnderstanding and tracking down memory-related performance problems, such as long garbage collection times and memory leaks, is a tedious task in large and complex applications. Memory profilers can support developers in this task by recording detailed traces of the application's memory behavior which can then be analyzed offline. Unfortunately, these traces can become huge, and processing them is a real challenge. If the goal is to rebuild the heap from a trace in order to analyze it, most state-of-the-art tools perform badly, because they are either too slow or provide only a coarse-grained view of the monitored application.\nIn this paper we present novel techniques and data structures for efficiently processing large event traces and for reconstructing the heap with only a fraction of the monitored application's memory. The reconstructed heap contains vital information about all objects, such as their addresses, their types, their allocation sites, and their allocating threads.\nWe also provide a detailed evaluation of our approach on 33 benchmarks, showing that we can rebuild the heap from a trace efficiently using only about 18% of the memory that was used in the monitored application.", "references": ["S. M. Blackburn, R. Garner, C. Hoffmann, A. M. Khang, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanović, T. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo Benchmarks: Java Benchmarking Development and Analysis. In Proc. of the Annual ACM SIGPLAN Conf. on Object-oriented Programming Systems, Languages, and Applications, pages 169--190, 2006.", "Y. Bu, V. Borkar, G. Xu, and M. J. Carey. A bloat-aware design for big data applications. In Proc. of the 2013 Int'l. Symp. on Memory Management, pages 119--130, 2013.", "M. Hertz, S. M. Blackburn, J. E. B. Moss, K. S. McKinley, and D. Stefanović. Error-free garbage collection traces: How to cheat and not get caught. In Proc. of the 2002 ACM SIGMETRICS Int'l Conf. on Measurement and Modeling of Computer Systems, pages 140--151, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807426.2807433"}, {"title": "Multi-view Semi-supervised Learning for Web Image Annotation", "authors": ["Mengqiu Hu\n,", "Yang Yang\n,", "Hanwang Zhang\n,", "Fumin Shen\n,", "Jie Shao\n,", "Fuhao Zou"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the explosive increasing of web image data, image annotation has become a critical research issue for image semantic index and search. In this work, we propose a novel model, termed as multi-view semi-supervised learning (MVSSL), for robust image annotation task. Specifically, we exploit both labeled images and unlabeled images to uncover the intrinsic data structural information. Meanwhile, to comprehensively describe an individual datum, we take advantage of the correlated and complemental information derived from multiple facets of image data (i.e., multiple views or features). We devise a robust pair-wise constraint on outcomes of different views to achieve annotation consistency. Furthermore, we integrate a robust classifier learning component via l2,1 loss, which can provide effective noise identification power during the learning process. Finally, we devise an efficient iterative algorithm to solve the optimization problem in MVSSL. We conduct extensive experiments on the NUS-WIDE dataset, and the results illustrate that our proposed approach is promising for large scale web image annotation task.", "references": ["T. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. NUS-WIDE: a real-world web image database from national university of singapore. In CIVR, pages 48:1--48:9, 2009.", "J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. Shawe-Taylor, and S. Szedmák. Two view learning: Svm-2k, theory and practice. In NIPS, pages 355--362, 2005.", "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. B. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In ACM Multimedia, pages 675--678, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806371"}, {"title": "Improving Dynamic Index Pruning via Linear Programming", "authors": ["Simon Jonassen"], "publication": "LSDS-IR '15: Proceedings of the 2015 Workshop on Large-Scale and Distributed System for Information Retrieval", "abstract": "ABSTRACT\nDynamic index pruning techniques are commonly used to speed up query processing in Web search engines. In this work, we propose a linear programming technique which can further improve the performance of the state-of-the-art dynamic index pruning techniques. The experiments we conducted demonstrate that the proposed technique achieves reduction in terms of the disk access, index decompression, and scoring costs compared to the well-known Max-Score technique.", "references": ["A. Broder, D. Carmel, M. Herscovici, A. Soffer, and J. Zien. Efficient query evaluation using a two-level retrieval process. In Proceedings of the 12th International Conference on Information and Knowledge Management (CIKM), pages 426--434, 2003.", "B. B. Cambazoglu, E. Varol, E. Kayaaslan, C. Aykanat, and R. Baeza-Yates. Query forwarding in geographically distributed search engines. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 90--97, 2010.", "K. Chakrabarti, S. Chaudhuri, and V. Ganti. Interval-based pruning for top-k processing over compressed lists. In Proceedings of the 2011 IEEE 27th International Conference on Data Engineering (ICDE), pages 709--720, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809948.2809951"}, {"title": "Score Propagation Based on Similarity Shot Graph for Improving Visual Object Retrieval", "authors": ["Juan Manuel Barrios\n,", "Jose Manuel Saavedra"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nThe Visual Object Retrieval problem consists in locating the occurrences of a specific entity in an image/video dataset. In this work, we focus on discovering new occurrences of an entity by propagating the detection scores of already computed candidates to other video segments. The score propagation follows the edges of a pre-computed Similarity Shot Graph (SSG). The SSG connects video segments that are similar according to some criterion. Four methods for creating the SSG are presented: two based on computing and comparing low-level visual features, one based on comparing text transcriptions, and other based on computing and comparing high-level concepts.\nThe score propagation is evaluated on the INS 2014 dataset. The results show that the detection performance can be slightly improved by the proposed algorithm. However, the performance is variable and depends on the properties of the SSG and the target entity. It is part of the future work to automatically decide the kind of SSG that will be used to propagate scores given a set of detection candidates.", "references": ["Feature Detectors and Descriptors: The State Of The Art and Beyond. Feature Detection Code., 2010. http://kahlan.eps.surrey.ac.uk/featurespace/web/.", "R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In Proc. of CVPR, pages 2911--2918. IEEE, 2012.", "J. M. Barrios, J. M. Saavedra, F. Ramirez, and D. Contreras. Orand at trecvid 2014: Instance search and multimedia event detection. In Proc. of TRECVID. NIST, USA, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814644"}, {"title": "What can be Found on the Web and How: A Characterization of Web Browsing Patterns", "authors": ["Alexey Tikhonov\n,", "Liudmila Ostroumova Prokhorenkova\n,", "Arseniy Chelnokov\n,", "Ivan Bogatyy\n,", "Gleb Gusev"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nIn this paper, we suggest a novel approach to studying user browsing behavior, i.e., the ways users get to different pages on the Web. Namely, we classified all user browsing paths leading to web pages into several types or browsing patterns. In order to define browsing patterns, we consider several important points of the browsing path: its origin, the last page before the user gets to the domain of the target page, and the target page referrer. Each point can be of several types, which leads to 56 possible patterns. The distribution of the browsing paths over these patterns forms the navigational profile of a web page.\nWe conducted a comprehensive large-scale study of navigational profiles of different web pages. First, we demonstrated that the navigational profile of a web page carry crucial information about the properties of this page (e.g., its popularity and age). Second, we found that the Web consists of several typical non-overlapping clusters formed by pages of similar ranges of incoming traffic. These clusters can be characterized by the functionality of their pages.", "references": ["R. Baeza-Yates, A. P. Jr, and N. Ziviani. The evolution of web content and search engines. In Proceedings of the 8th ACM Workshop on Web Mining and Web Usage Analysis, 2008.", "P. Bailey, R. W. White, H. Liu, and G. Kumaran. Mining historic query trails to label long and rare search engine queries. In ACM Transactions on the Web, volume 4 (4), 2010.", "M. Bilenko and R. W. White. Mining the search trails of surfing crowds: identifying relevant websites from user activity. In Proceedings of the 17th international conference on World Wide Web, pages 51--60, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786468"}, {"title": "PDFMEF: A Multi-Entity Knowledge Extraction Framework for Scholarly Documents and Semantic Search", "authors": ["Jian Wu\n,", "Jason Killian\n,", "Huaiyu Yang\n,", "Kyle Williams\n,", "Sagnik Ray Choudhury\n,", "Suppawong Tuarob\n,", "Cornelia Caragea\n,", "C. Lee Giles"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nWe introduce PDFMEF, a multi-entity knowledge extraction framework for scholarly documents in the PDF format. It is implemented with a framework that encapsulates open-source extraction tools. Currently, it leverages PDFBox and TET for full text extraction, the scholarly document filter described in [5] for document classification, GROBID for header extraction, ParsCit for citation extraction, PDFFigures for figure and table extraction, and algorithm extraction [27]. While it can be run as a whole, the extraction tool in each module is highly customizable. Users can substitute default extractors with other extraction tools they prefer by writing a thin wrapper to implement the abstracts. The framework is designed to be scalable and is capable of running in parallel using a multi-processing technique in Python. Experiments indicate that the system with default setups is CPU bounded, and leaves a small footprint in the memory, which makes it best to run on a multi-core machine. The best performance using a dedicated server of 16 cores takes 1.3 seconds on average to process one PDF document. It is used to index extracted information and help users to quickly locate relevant results in published scholarly documents and to efficiently construct a large knowledge base in order to build a semantic scholarly search engine. Part of it is running on CiteSeerX digital library search engine.", "references": ["Pdflib tet. http://www.pdflib.com/products/tet/. Accessed: 2015-05-12.", "Poppler. http://poppler.freedesktop.org. Accessed: 2015-05-12.", "Tabula. http://tabula.technology. Accessed: 2015-05-13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815834"}, {"title": "Summarization Search: A New Search Abstraction for Mobile Devices", "authors": ["Sunandan Chakraborty\n,", "Zohaib Jabbar\n,", "Lakshminarayanan Subramanian"], "publication": "DEV '15: Proceedings of the 2015 Annual Symposium on Computing for Development", "abstract": "ABSTRACT\nMobile networks in developing regions have been plagued by three basic problems: low bandwidth, high latency and high costs. Due to these factors, mobile web users in these regions are known to have a highly intermittent and relatively non-interactive user experience. In this paper, we consider the case of mobile search and propose Summarization search, a new search paradigm for mobile users where the basic goal is to provide a single summarized and relatively complete search response for every user search query. Summarization search is specifically designed as a relatively non-interactive, one-time quick shot search experience for mobile users where a mobile user can issue focused queries for specific information search needs. Our summarization search engine is designed as a meta-search service on top of conventional search services to generate a single summarized and condensed search response based on extracting the \"most useful\" information from the underlying search result pages. Our system yielded a high accuracy (82-92%) for three classes of focused queries: task oriented queries, category specific queries and focused issue focused queries for specific information search needs. queries sampled from the AOL log. We also performed a user study with 400 queries and 30 users. The user study results show that in a scale of 1 (best) to 5(worst), 45% of the cases, users rated the result as '1' and 40% of the cases were rated as '2', with an average rating of 2.09 across all users for all queries. Another task in the user study revealed that for around 55% of queries, users found their information in the summarized result. This demonstrates the effectiveness of the summarization search interface, where users' information requirement is fulfilled with just one operation of submitting the search query.", "references": ["Chen, J. and Subramanian, L. and Li, J. RuralCafe: web search in the rural developing world. WWW. 2009", "Teevan, J. and Ramage, D. and Morris, M. Ringel.# TwitterSearch: a comparison of microblog search and web search. WSDM. 2011", "Radev, D. R., Hovy, E., and McKeown, K. (2002). Introduction to the special issue on summarization. Computational Linguistics., 28(4)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830629.2835217"}, {"title": "Proposal Sentiment Analysis Use in Developing a new Sustainability Metrics", "authors": ["Nataly Bruna Aires\n,", "Pietra Sales\n,", "Lucas Vieira Lopes\n,", "Marcos van Vessen\n,", "Eduardo F. Machado\n,", "Cassiana F. da Silva"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nSustainability metrics are measures and indicators that are intended to serve as management tools, both at the macro level, to public policy, for example, as in the micro, in the efficient management of a company. With its use one can measure the impacts of sustainable practices, through the correlation, for example, from increased revenue and market share, with practices such as reducing energy costs, reducing expenses with waste reduction costs of materials and water. Or even the correlation between an environment where Sustainability is promoted and the increased employee productivity and reduced spending on hiring. Arguably a growing alignment is needed between the discourse and practice of sustainability values. In this context, this article aims to use the Analysis of Feelings in the development of a new metric. In the present stage was done a survey, to know about the opinion that the Superior Educational Institute FAMEC - PR's workers have about organizational sustentability. The answers passed by an analysis, done with the tool RapidMiner, where the workers feelings were qualified as positive, negative or neutral.", "references": ["Bellen, H. M. Van. Indicadores de Sustentabilidade: uma análise comparativa. Ed. 2. Rio de Janeiro: Editora FGV, 2006.", "Callado, A. L C. Modelo de mensuração de sustentabilidade empresarial: uma aplicação em vinícolas localizadas na Serra Gaúcha. Porto Alegre. Tese de Doutorado. Universidade Federal do Rio Grande do Sul. 2010.", "Comissão Mundial Sobre o Meio Ambiente e Desenvolvimento. Nosso Futuro Comum. Ed. 1. Rio de Janeiro: Editora da Fundação Getúlio Vargas, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814131"}, {"title": "Topic-centric Classification of Twitter User's Political Orientation", "authors": ["Anjie Fang\n,", "Iadh Ounis\n,", "Philip Habel\n,", "Craig Macdonald\n,", "Nut Limsopatham"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn the recent Scottish Independence Referendum (hereafter, IndyRef), Twitter offered a broad platform for people to express their opinions, with millions of IndyRef tweets posted over the campaign period. In this paper, we aim to classify people's voting intentions by the content of their tweets---their short messages communicated on Twitter. By observing tweets related to the IndyRef, we find that people not only discussed the vote, but raised topics related to an independent Scotland including oil reserves, currency, nuclear weapons, and national debt. We show that the views communicated on these topics can inform us of the individuals' voting intentions (\"Yes\"--in favour of Independence vs. \"No\"--Opposed). In particular, we argue that an accurate classifier can be designed by leveraging the differences in the features' usage across different topics related to voting intentions. We demonstrate improvements upon a Naive Bayesian classifier using the topics enrichment method. Our new classifier identifies the closest topic for each unseen tweet, based on those topics identified in the training data. Our experiments show that our Topics-Based Naive Bayesian classifier improves accuracy by 7.8% over the classical Naive Bayesian baseline.", "references": ["F. Al Zamal, W. Liu, and D. Ruths. Homophily and latent attribute inference: Inferring latent attributes of Twitter users from neighbors. In ICWSM, 2012.", "P. Barberá. Birds of the same feather tweet together: Bayesian ideal point estimation using Twitter data. Political Analysis, 23(1), 2015.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767833"}, {"title": "Reducing the search space in ontology alignment using clustering techniques and topic identification", "authors": ["Agnese Chiatti\n,", "Zlatan Dragisic\n,", "Tania Cerquitelli\n,", "Patrick Lambrix"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nOne of the current challenges in ontology alignment is scalability and one technique to deal with this issue is to reduce the search space for the generation of mapping suggestions. In this paper we develop a method to prune that search space by using clustering techniques and topic identification. Further, we provide experiments showing that we are able to generate partitions that allow for high quality alignments with a highly reduced effort for computation and validation of mapping suggestions for the parts of the ontologies in the partition. Other techniques will still be needed for finding mappings that are not in the partition.", "references": ["A. Chiatti et al. Reducing the search space in ontology alignment using clustering techniques and topic identification. Technical report. http://www.ida.liu.se/~patla00/publications/KCAP15-extended.pdf.", "H.-H. Do and E. Rahm. Matching large schemas: approaches and evaluation. Information Systems, 32:857--885, 2007.", "Z. Dragisic et al. Results of the ontology alignment evaluation initiative 2014. In International Workshop on Ontology Matching, pages 61--104, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2816959"}, {"title": "Mobile search through dynamic mashups", "authors": ["Diego Fabian Gomez-Pardo\n,", "Franklin E. Navia-Urbano\n,", "Juan Carlos Corrales\n,", "Luis Javier Suarez-Meza"], "publication": "MOBILESoft '15: Proceedings of the Second ACM International Conference on Mobile Software Engineering and Systems", "abstract": "ABSTRACT\nNowadays, mobile devices are the first choice for seeking information and content consumption on the Web. However, the overwhelming amount of available web resources, significantly affects the quality of the results returned by search systems. Traditionally, the web resource's retrieval is performed by using syntactic and/or semantic matches between the user query and content of the resources, leaving aside aspects such as: Goals and intentions that an end-user has when performing a query. This paper introduces a novel approach that allows to improve the mobile search user experience, delivering results according to his goals and intentions. This proposal is based on three main processes: i) To infer goals and intentions of end-users from their search query through a probabilistic generative model called LDA (Latent Dirichlet Allocation). ii) to discover resources based on inferred goals and intentions. And iii) to generate a dynamic mashup with the retrieved resources. We argue that the concept of mashup can contribute to improve the user experience in mobile search. Experiments show promising results in the user search experience in contrast to traditional approaches.", "references": ["D. Florian, F. Casati, B. Benatallah, and M.-C. Shan, \"Hosted universal composition: Models, languages and infrastructure in mashart,\" in Proceedings of the 28th International Conference on Conceptual Modeling, ER '09, (Berlin, Heidelberg), pp. 428--443, Springer-Verlag, 2009.", "X. Liu, Q. Zhao, G. Huang, H. Mei, and T. Teng, \"Composing data-driven service mashups with tag-based semantic annotations,\" in Proceedings of the 2011 IEEE International Conference on Web Services, ICWS '11, (Washington, DC, USA), pp. 243--250, IEEE Computer Society, 2011.", "S. Aghaee, C. Pautasso, and A. De Angeli, \"Natural end-user development of web mashups,\" in Visual Languages and Human-Centric Computing (VL/HCC), 2013 IEEE Symposium on, pp. 111--118, Sept 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2825041.2825053"}, {"title": "A Distributed Test System Architecture for Open-source IoT Software", "authors": ["Philipp Rosenkranz\n,", "Matthias Wählisch\n,", "Emmanuel Baccelli\n,", "Ludwig Ortmann"], "publication": "IoT-Sys '15: Proceedings of the 2015 Workshop on IoT challenges in Mobile and Industrial Systems", "abstract": "ABSTRACT\nIn this paper, we discuss challenges that are specific to testing of open IoT software systems. The analysis reveals gaps compared to wireless sensor networks as well as embedded software. We propose a testing framework which (a) supports continuous integration techniques, (b) allows for the integration of project contributors to volunteer hardware and software resources to the test system, and (c) can function as a permanent distributed plugtest for network interoperability testing. The focus of this paper lies in open-source IoT development but many aspects are also applicable to closed-source projects.", "references": ["Baccelli, E., Hahm, O., Günes, M., Wählisch, M., and Schmidt, T. C. RIOT OS: Towards an OS for the Internet of Things. In Proc. of the 32nd IEEE INFOCOM. Poster (Piscataway, NJ, USA, 2013), IEEE Press.", "Bloessl, B., Leitner, C., Dressler, F., and Sommer, C. A GNU Radio-based IEEE 802.15.4 Testbed. In 12. GI/ITG KuVS Fachgespräch Drahtlose Sensornetze (FGSN 2013) (Cottbus, Germany, September 2013), pp. 37--40.", "Bluetooth Special Interest Group. The Bluetooth SIG Interoperability Program White Paper, June 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2753476.2753481"}, {"title": "The rise and fall of an online project: is bureaucracy killing efficiency in open knowledge production?", "authors": ["Nicolas Jullien\n,", "Kevin Crowston\n,", "Felipe Ortega"], "publication": "OpenSym '15: Proceedings of the 11th International Symposium on Open Collaboration", "abstract": "ABSTRACT\nWe evaluate the efficiency of an online knowledge production project and identify factors that affect efficiency. To assess efficiency, we used the Data Envelopment Analysis (DEA) modelling methodology. We apply DEA to data from more than 30 Wikipedia language projects over three years. We show that the main Wikipedia projects were indeed less efficient that smaller ones, an effect that can be attributed in part to decreasing returns to scale.", "references": ["M. Akrich, M. Callon, and B. Latour. Sociologie de la traduction: textes fondateurs. Les presses des Mines de Paris, Paris, 2006.", "R. D. Banker, A. Charnes, and W. W. Cooper. Some Models for Estimating Technical and Scale Inefficiencies in Data Envelopment Analysis. Management Science, 30(9):1078--1092, 1984.", "J. E. Blumenstock. Size matters: Word count as a measure of quality on wikipedia. In Proceeding of the 17th International Conference on World Wide Web 2008, WWW'08, pages 1095--1096, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788993.2789844"}, {"title": "PRISM: concept-preserving summarization of top-k social image search results", "authors": ["Boon Siew Seah\n,", "Sourav S. Bhowmick\n,", "Aixin Sun"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMost existing tag-based social image search engines present search results as a ranked list of images, which cannot be consumed by users in a natural and intuitive manner. In this demonstration, we present a novel concept-preserving image search results summarization system called prism. prism exploits both visual features and tags of the search results to generate high quality summary, which not only breaks the results into visually and semantically coherent clusters but it also maximizes the coverage of the original top-k search results. It first constructs a visual similarity graph where the nodes are images in the top-k search results and the edges represent visual similarities between pairs of images. This graph is optimally decomposed and compressed into a set of concept-preserving subgraphs based on a set of summarization criteria. One or more exemplar images from each subgraph is selected to form the exemplar summary of the result set. We demonstrate various innovative features of prism and the promise of superior quality summary construction of social image search results.", "references": ["T-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, Y. Zheng. NUS-WIDE: a real-world web image database from National University of Singapore. In ACM CIVR, 2009.", "V. Chvatal. A Greedy Heuristic for the Set-Covering Problem. Mathematics of Operations Research, 4(3):233--235, 1979.", "Y. Jia, J. Wang, C. Zhang, X.-S. Hua. Finding image exemplars using fast sparse affinity propagation. In ACM MM, 639--642, 2008.", "X. Li, C. G. M. Snoek, M. Worring. Learning Social Tag Relevance by Neighbor Voting, IEEE Trans. Multimedia, 11(7), 1310--1322, 2009.", "P.-A. Möellic, J. Haugeard, G. Pitel. Image clustering based on a shared nearest neighbors approach for tagged collections. In ACM CIVR, 269--278, 2008.", "M. Rege, M. Dong, J. Hua. Graph theoretical framework for simultaneously integrating visual and textual features for efficient web image clustering. In ACM WWW, 317--326, 2008.", "B. S. Seah, S. S. Bhowmick, A. Sun. PRISM: Concept-preserving social image search results summarization. In ACM SIGIR, 737--746, 2014.", "A. Sun, S. S. Bhowmick, K. T. N. Nguyen, G. Bai. Tag-based social image retrieval: An empirical evaluation, JASIST, 62(12), 2364--2381, 2011.", "H. Xu, J. Wang, X.-S. Hua, S. Li. Hybrid image summarization. In ACM MM, 1217--1220, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824088"}, {"title": "Enquiring Minds: Early Detection of Rumors in Social Media from Enquiry Posts", "authors": ["Zhe Zhao\n,", "Paul Resnick\n,", "Qiaozhu Mei"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMany previous techniques identify trending topics in social media, even topics that are not pre-defined. We present a technique to identify trending rumors, which we define as topics that include disputed factual claims. Putting aside any attempt to assess whether the rumors are true or false, it is valuable to identify trending rumors as early as possible. It is extremely difficult to accurately classify whether every individual post is or is not making a disputed factual claim. We are able to identify trending rumors by recasting the problem as finding entire clusters of posts whose topic is a disputed factual claim.\nThe key insight is that when there is a rumor, even though most posts do not raise questions about it, there may be a few that do. If we can find signature text phrases that are used by a few people to express skepticism about factual claims and are rarely used to express anything else, we can use those as detectors for rumor clusters. Indeed, we have found a few phrases that seem to be used exactly that way, including: \"Is this true?\", \"Really?\", and \"What?\". Relatively few posts related to any particular rumor use any of these enquiry phrases, but lots of rumor diffusion processes have some posts that do and have them quite early in the diffusion.\nWe have developed a technique based on searching for the enquiry phrases, clustering similar posts together, and then collecting related posts that do not contain these simple phrases. We then rank the clusters by their likelihood of really containing a disputed factual claim. The detector, which searches for the very rare but very informative phrases, combined with clustering and a classifier on the clusters, yields surprisingly good performance. On a typical day of Twitter, about a third of the top 50 clusters were judged to be rumors, a high enough precision that human analysts might be willing to sift through them.", "references": ["L. Breiman, J. Friedman, C. J. Stone, and R. A. Olshen. Classification and regression trees. CRC press, 1984.", "A. Z. Broder. On the resemblance and containment of documents. In Compression and Complexity of Sequences 1997. Proceedings, pages 21--29. IEEE, 1997.", "R. Caruana and A. Niculescu-Mizil. An empirical comparison of supervised learning algorithms. In Proceedings of the 23rd international conference on Machine learning, pages 161--168. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741637"}, {"title": "A percussion learning system by rhythm internalization using haptic indication", "authors": ["Hiroyuki Kanke\n,", "Tsutomu Terada\n,", "Masahiko Tsukamoto"], "publication": "ACE '15: Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nMastering the correct stroking order and accent technique when playing percussion is important. Percussion learning systems using haptic and visual indications have been developed. Thus, it is efficient for the learner to internalize performance information when learning how to play percussion. In this paper, we describe this process of rhythm internalization. We consider that rhythm internalization enables learners to perceive what is correct playing and to improve their performance. Additionally, because learners using previous learning method are stimulated by the indications of percussion performance information while stroking, perceiving these indications is not easy. We propose a learning method that presents the two phases separately. One of them is a phase where the learners receive the indications of performance information, and the other is a phase where they actually practice stroking. Learners first internalize rhythm through the indications of performance information. This separated learning method enables learners to learn the percussion more efficiently. This paper describes a percussion learning system using rhythm internalization with haptic, visual, and auditory indications and the design of the prototype system. We also present our evaluation of the prototype system's effectiveness.", "references": ["Rock Band: http://www.harmonixmusic.com/games/rock-band/.", "Guitar Hero: https://www.guitarhero.com/.", "YAMAHA Song Beats: http://jp.yamaha.com/products/apps/song_beats/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832932.2832971"}, {"title": "Verboseness Fission for BM25 Document Length Normalization", "authors": ["Aldo Lipani\n,", "Mihai Lupu\n,", "Allan Hanbury\n,", "Akiko Aizawa"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nBM25 is probably the most well known term weighting model in Information Retrieval. It has, depending on the formula variant at hand, 2 or 3 parameters (k1, b, and k3). This paper addresses b - the document length normalization parameter. Based on the observation that the two cases previously discussed for length normalization (multi-topicality and verboseness) are actually three: multi-topicality, verboseness with word repetition (repetitiveness) and verboseness with synonyms, we propose and test a new length normalization method that removes the need for a b parameter in BM25. Testing the new method on a set of purposefully varied test collections, we observe that we can obtain results statistically indistinguishable from the optimal results, therefore removing the need for ground-truth based optimization.", "references": ["G. Amati and J. C. C. Van Rijsbergen. Probabilistic models for information retrieval based on divergence from randomness. TOIS, 20(4), 2002.", "A. Chowdhury, M. C. McCabe, D. Grossman, and O. Frieder. Document Normalization Revisited. In Proc. of SIGIR, 2002.", "D. Harman. Overview of the Fourth Text REtrieval Conference (TREC-4). In Proc. of TREC 4, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809486"}, {"title": "Efficient Computation of Co-occurrence Based Word Relatedness", "authors": ["Jie Mei\n,", "Xinxin Kou\n,", "Zhimin Yao\n,", "Andrew Rau-Chaplin\n,", "Aminul Islam\n,", "Abidalrahman Moh'd\n,", "Evangelos E. Milios"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nMeasuring document relatedness using unsupervised co-occurrence based word relatedness methods is a processing-time and memory consuming task. This paper introduces the application of compact data structures for efficient computation of word relatedness based on corpus statistics. The data structure is used to efficiently lookup: (1) the corpus statistics for the Common Word Relatedness Approach, (2) the pairwise word relatedness for the Algorithm Specific Word Relatedness Approach. These two approaches significantly accelerate the processing time of word relatedness methods and reduce the space cost of storing co-occurrence statistics in memory, making text mining tasks like classification and clustering based on word relatedness practical.", "references": ["D. Bollegala, Y. Matsuo, and M. Ishizuka. A web search engine-based approach to measure semantic similarity between words. Knowledge and Data Engineering, IEEE Trans. on, 23(7):977--990, 2011.", "T. Brants and A. Franz. Web 1T 5-gram corpus version 1.1. Technical report, Google Research, 2006.", "K. W. Church and P. Hanks. Word association norms, mutual information, and lexicography. Comput. Linguist., 16(1):22--29, Mar. 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797088"}, {"title": "Automated News Suggestions for Populating Wikipedia Entity Pages", "authors": ["Besnik Fetahu\n,", "Katja Markert\n,", "Avishek Anand"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWikipedia entity pages are a valuable source of information for direct consumption and for knowledge-base construction, update and maintenance. Facts in these entity pages are typically supported by references. Recent studies show that as much as 20% of the references are from online news sources. However, many entity pages are incomplete even if relevant information is already available in existing news articles. Even for the already present references, there is often a delay between the news article publication time and the reference time. In this work, we therefore look at Wikipedia through the lens of news and propose a novel news-article suggestion task to improve news coverage in Wikipedia, and reduce the lag of newsworthy references. Our work finds direct application, as a precursor, to Wikipedia page generation and knowledge-base acceleration tasks that rely on relevant and high quality input sources.\nWe propose a two-stage supervised approach for suggesting news articles to entity pages for a given state of Wikipedia. First, we suggest news articles to Wikipedia entities (article-entity placement) relying on a rich set of features which take into account the salience and relative authority of entities, and the novelty of news articles to entity pages. Second, we determine the exact section in the entity page for the input article (article-section placement) guided by class-based section templates. We perform an extensive evaluation of our approach based on ground-truth data that is extracted from external references in Wikipedia. We achieve a high precision value of up to 93% in the article-entity suggestion stage and upto 84% for the article-section placement. Finally, we compare our approach against competitive baselines and show significant improvements.", "references": ["K. Balog and H. Ramampiaro. Cumulative citation recommendation: classification vs. ranking. In 36th ACM SIGIR, Dublin, Ireland, 2013, pages 941--944.", "K. Balog, H. Ramampiaro, N. Takhirov, and K. Nørvåg. Multi-step classification approaches to cumulative citation recommendation. In OAIR, Lisbon, Portugal, 2013, pages 121--128.", "Y. Bernstein and J. Zobel. Redundant documents and search effectiveness. In 14th ACM CIKM, pages 736--743, New York, USA, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806531"}, {"title": "Contribution, social networking, and the request for adminship process in Wikipedia", "authors": ["Romain Picot-Clémente\n,", "Cécile Bothorel\n,", "Nicolas Jullien"], "publication": "OpenSym '15: Proceedings of the 11th International Symposium on Open Collaboration", "abstract": "ABSTRACT\nEpistemic communities are said to be project-oriented communities of experts, evaluated on their contribution in terms of knowledge, where the main criterion for promotion is knowledge production [3]. However, [5], for Wikipedia, [7], for open source, have argued that taking responsibility is an additional step from being a regular contributor, and social interactions with peers may be an additional requirement for being promoted [6].", "references": ["L. Breiman. Random forests. Machine learning, 45(1): 5--32, 2001.", "M. Burke and R. Kraut. Mopping up: Modeling wikipedia promotion decisions. In Proceedings of CSCW 2008, pages 27--36. ACM, 2008.", "P. Cohendet, F. Créplet, and O. Dupouet. Interactions between epistemic communities and communities of practice as a mechanism of creation and diffusion of knowledge. In J.-B. Zimmermann and A. Kirman, editors, Interaction and Market Structure. Springer, Londres, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788993.2806211"}, {"title": "Constant Delay Enumeration for Conjunctive Queries", "authors": ["Luc Segoufin"], "publication": "ACM SIGMOD Record", "abstract": "Abstract\nWe survey some of the recent results about enumerating the answers to queries over a database. We focus on the case where the enumeration is performed with a constant delay between any two consecutive solutions, after a linear time preprocessing.\nThis cannot be always achieved. It requires restricting either the class of queries or the class of databases.\nWe consider conjunctive queries and describe several scenarios when this is possible.", "references": ["A. V. Aho, J. E. Hopcroft, and J. D. Ullman. The Design and Analysis of Computer Algorithms. Addison-Wesley, 1974.", "G. Bagan. MSO Queries on Tree Decomposable Structures Are Computable with Linear Delay. In Conf. on Computer Science Logic (CSL), pages 167--181, 2006.", "G. Bagan. Algorithmes et complexité des problèmes d'énumération pour l'évaluation de requêtes logiques. PhD thesis, Université de Caen, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783888.2783894"}, {"title": "Is That Twitter Hashtag Worth Reading", "authors": ["A. Anusha\n,", "Sanjay Singh"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nOnline social media such as Twitter, Facebook, Wikis and Linkedin have made a great impact on the way we consume information in our day to day life. Now it has become increasingly important that we come across appropriate content from the social media to avoid information explosion. In case of Twitter, popular information can be tracked using hashtags. Studying the characteristics of tweets containing hashtags becomes important for a number of tasks, such as breaking news detection, personalized message recommendation, friends recommendation, and sentiment analysis among others. In this paper, we have analyzed Twitter data based on trending hashtags, which is widely used nowadays. We have used event based hashtags to know users' thoughts on those events and to decide whether the rest of the users might find it interesting or not. We have used topic modeling, which reveals the hidden thematic structure of the documents (tweets in this case) in addition to sentiment analysis in exploring and summarizing the content of the documents. A technique to find the interestingness of event based twitter hashtag and the associated sentiment has been proposed. The proposed technique helps twitter follower to read, relevant and interesting hashtag.", "references": ["O. Alonso, C. Carson, D. Gerster, X. Ji, and S. U. Nabar. Detecting uninteresting content in text streams. In Proceedings of SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation (CSE 2010), pages 39--42, Geneva, Switzerland, July 2010.", "M. G. Armentano, D. Godoy, and A. A. Amandi. Followee recommendation based on text analysis of micro-blogging activity. Inf. Syst., 38(8):1116--1127, Nov 2013.", "BBC. Deadly tsunami strkes in pacific. news.bbc.co.uk/2/hi/asia-pacific/8281616.stm, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791526"}, {"title": "BUTE: bursty users tagging method estimated by time series data", "authors": ["Shuhei Yamamoto\n,", "Kei Wakabayashi\n,", "Noriko Kando\n,", "Tetsuji Satoh"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nMany Twitter users post tweets that are related to their particular interests. Users can also collect information by following other users. One approach clarifies user interests by tagging labels based on the users. A user tagging method is important to discover candidate users with similar interests. Typical approaches estimate user interests with terms in tweets and by applying graph theory such as following networks. In contrast, we propose a new user tagging method using the posting time series data of the number of tweets and developed the following hypothesis: Since users have interests, they will post more tweets at the time occurring the events compared with general times. Based on this hypothesis, we extract interests as burst levels from the user and hashtag time series data with Kleinberg's burst enumerating algorithm. We manage the burst levels of users as the term frequency in documents and calculate the hashtag scores for each user by three typical score calculation methods: cosine similarity, Naive Bayes, and TF-IDF. Thus, the proposed method needs no linguistic analysis which requires heavy computational resources. With our sophisticated experimental evaluations with actually active users, we demonstrate the high efficiency of our tagging methods, evaluate them using such information retrieval system evaluation metrics as expected reciprocal rank (ERR) and Q-measure, and clarify the strengths and limitations of each one. Naive Bayes and cosine similarity are especially suitable for user tagging and tag score calculation tasks.", "references": ["Solar eclipse of may 20, 2012. https://en.wikipedia.org/wiki/Solar_eclipse_of_May_20,_2012.", "Twitter. https://twitter.com.", "Twitter search api. https://dev.twitter.com/docs/api/1/get/search."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837198"}, {"title": "A Novel Statistical Approach for Image and Video Retrieval and Its Adaption for Active Learning", "authors": ["Moitreya Chatterjee\n,", "Anton Leuski"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe ever expanding multimedia content (such as images and videos), especially on the web, necessitates effective text query-based search (or retrieval) systems. Popular approaches for addressing this issue, use the query-likelihood model which fails to capture the user's information needs. In this work therefore, we explore a new ranking approach in the context of image and video retrieval from text queries. Our approach assumes two separate underlying distributions for query and the document respectively. We then, determine the extent of similarity between these two statistical distributions for the task of ranking. Furthermore we extend our approach, using Active Learning techniques, to address the question of obtaining a good performance without requiring a fully labeled training dataset. This is done by taking Sample Uncertainty, Density and Diversity into account. Our experiments on the popular TRECVID corpus and the open, relatively small-sized USC SmartBody corpus show that we are almost at-par or sometimes better than multiple state-of-the-art baselines.", "references": ["TRECVID 2007: TREC Video Retrieval Evaluation. link: http://www-nlpir.nist.gov/projects/tv2007/tv2007.html.", "M. Chatterjee and A. Leuski. Crmactive: An active learning based approach for effective video annotation and retrieval. In Proceedings of the 5th ACM ICMR, 2015.", "V. Lavrenko. A generative theory of relevance. Springer Science & Business Media, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806368"}, {"title": "LSDS-IR'15: 2015 Workshop on Large-Scale and Distributed Systems for Information Retrieval", "authors": ["Ismail Sengor Altingovde\n,", "B. Barla Cambazoglu\n,", "Nicola Tonellotto"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe growth of the Web and other Big Data sources lead to important performance problems for large-scale and distributed information retrieval systems. The scalability and efficiency of such information retrieval systems have an impact on their effectiveness, eventually affecting the experience of their users and monetization as well. The LSDS-IR'15 workshop will provide space for researchers to discuss the existing performance problems in the context of large-scale and distributed information retrieval systems and define new research directions in the modern Big Data era. The workshop expects to bring together information retrieval practitioners from the industry, as well as academic researchers concerned with any aspect of large-scale and distributed information retrieval systems.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806877"}, {"title": "Concept Hierarchy Extraction from Textbooks", "authors": ["Shuting Wang\n,", "Chen Liang\n,", "Zhaohui Wu\n,", "Kyle Williams\n,", "Bart Pursel\n,", "Benjamin Brautigam\n,", "Sherwyn Saul\n,", "Hannah Williams\n,"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nConcept hierarchies have been useful tools for presenting and organizing knowledge. With the rapid growth in the number of online knowledge resources, automatic concept hierarchy extraction is increasingly attractive. Here, we focus on concept extraction from textbooks based on the knowledge in Wikipedia. Given a book, we extract important concepts in each book chapter using Wikipedia as a resource and from this construct a concept hierarchy for that book. We define local and global features that capture both the local relatedness and global coherence embedded in that textbook. In order to evaluate the proposed features and extracted concept hierarchies, we manually construct concept hierarchies for three well used textbooks by labeling important concepts for each book chapter. Experiments show that our proposed local and global features achieve better performance than using only keyphrases to construct the concept hierarchies. Moreover, we observe that incorporating global features can improve the concept ranking precision and reaffirms the global coherence in the book.", "references": ["R. Agrawal, S. Gollapudi, A. Kannan, and K. Kenthapadi. Data mining for improving textbooks. ACM SIGKDD Explorations Newsletter, 13(2):7--19, 2012.", "H. Alani, S. Kim, D. E. Millard, M. J. Weal, W. Hall, P. H. Lewis, and N. R. Shadbolt. Automatic ontology-based knowledge extraction from web documents. Intelligent Systems, IEEE , 18(1):14--21, 2003.", "R. C. Bunescu and M. Pasca. Using encyclopedic knowledge for named entity disambiguation. In EACL, pages 9--16, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797062"}, {"title": "Ontology Extraction from Stories: an exploratory study in storytelling", "authors": ["Valdemar T. F. Confort\n,", "Kate Cerqueira Revoredo\n,", "Fernanda Araujo Baiao\n,", "Flavia Maria Santoro"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nBusiness and IT systems are facing increasingly complex environments characterized by collaboration, change and variety of customers, suppliers and products. Group storytelling technique can contribute to the business knowledge management. The stories count brings benefits from capture to securing information, through communication and understanding of the concepts. American Companies (3M and Apple), Japanese (Sony and Toshiba) and European (ClubMed and Oce) already use this approach in practice. Ontology Engineering can contribute towards improving the quality of information and offer a solution to address knowledge management systematically. However, the specification and manually made of ontology management can be expensive, tedious, biased and prone to error. Automatic learning ontology is an approach that extracts ontology from the data, both structured and unstructured (text). This work presents, at the exploratory stage, a proposal able to specify, automatically, elements of an ontology, from the tacit knowledge of those involved in the field. An exploratory study was able to get the concepts of an ontology, automatically, from stories told by a group storytelling tool on the business process of one department of the University.", "references": ["P. Johannesson, \"The role of business models in enterprise modelling,\" in Conceptual modelling in information systems engineering, Berlin Heidelberg, Springer, 2007, pp. 123-140.", "R. Perret, M. R. Borges and F. M. SANTORO, \"Applying group storytelling in knowledge management,\" in Groupware: Design, Implementation, and Use, Springer Berlin Heidelberg, 2004, pp. 34-41.", "J. Recker, Evaluations of Process Modeling Grammars, Berlin-Heidelberg: Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814098"}, {"title": "Data Mining Techniques Assessment for Shutdowns Prediction of Electric Power Systems", "authors": ["Anderson Trindade Maia\n,", "Jefferson Magalhaes de Morais\n,", "Yomara Pinheiro Pires\n,", "Aldebaro Barreto da Rocha Klautau\n,", "Daniel Martins"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe volume of historical information related to the behavior of electric power systems, has significantly increased the size of the energy companies databases, but without contributing to the improvement in the aspects of operation, maintenance and quality of service, except for any queries historical behavior of variables. Several studies in the literature have been proposed to investigate various aspects this problem. Some of these works address the problem of disconnections of occurrence prediction in power systems using mining techniques. However, due to the large volume of data, the search for the preparation of methodologies and data selection becomes important. In this work, a methodology using data mining techniques applied the synchronized phasor measurement time series to aid the prevention of shutdowns due to voltage deviations in electrical power systems is presented. Are tested some mining techniques on data obtained in a 230 kV transmission line linking the substations of Tucurui, Altamira, Ruropolis, constituting the electrical system Tramo western Para.", "references": ["Morais, J. M. (2011). Avaliação de Desempenho de Classificadores de Faltas em Sistemas Elétricos de Potência. Tese de Doutorado apresentada ao Programa de Pós-Graduação em Engenharia Elétrica. Universidade Federal doPará.", "Bollen, M., (2009). Bridging the gap between signal and power. IEEE Signal Processing Magazine, 26:12, July.", "Ree, J. D. L., Centeno, V., Thorp, J. S., and Phadke, A. G. (2010). Synchronized phasor measurement applications in power systems. IEEE Trans. Smart Grid, 1(1):20-27."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814085"}, {"title": "Category-Driven Approach for Local Related Business Recommendations", "authors": ["Yonathan Perez\n,", "Michael Schueppert\n,", "Matthew Lawlor\n,", "Shaunak Kishore"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhen users search online for a business, the search engine may present them with a list of related business recommendations. We address the problem of constructing a useful and diverse list of such recommendations that would include an optimal combination of substitutes and complements. Substitutes are similar potential alternatives to the searched business, whereas complements are local businesses that can offer a more comprehensive and better rounded experience for a user visiting the searched locality. In our problem setting, each business belongs to a category in an ontology of business categories. Two businesses are defined as substitutes of one another if they belong to the same category, and as complements if they are otherwise relevant to each other.\nWe empirically demonstrate that the related business recommendation lists generated by Google's search engine are too homogeneous, and overemphasize substitutes. We then use various data sources such as crowdsourcing, mobile maps directions queries, and the existing Google's related business graph to mine association rules to determine to which extent do categories complement each other, and establish relevance between businesses, using both category-level and individual business-level information. We provide an algorithmic approach that incorporates these signals to produce a list of recommended businesses that balances pairwise business relevance with overall diversity of the list. Finally, we use human raters to evaluate our system, and show that it significantly improves on the current Google system in usefulness of the generated recommendation lists.", "references": ["Google Consumer Surveys. http://www.google.com/insights/consumersurveys/home.", "Supplementary Materials. https://www.dropbox.com/sh/wau25zqwusnv8mc/AADJta6Ybc6RzyJiJRRCCk_ea?dl=0.", "R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806495"}, {"title": "Navigation Leads Selection Considering Navigational Value of Keywords", "authors": ["Robert Moro\n,", "Maria Bielikova"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSearching a vast information space such as the Web presents a challenging task and even more so, if the domain is unknown and the character of the task is thus exploratory in its nature. We have proposed a method of exploratory navigation based on navigation leads, i.e. terms that help users to filter the information space of a digital library. In this paper, we focus on the selection of the leads considering their navigational value. We employ clustering based on topic modeling using LDA (Latent Dirichlet Allocation). We present results of a preliminary evaluation on the Annota dataset containing more than 50,000 research papers.", "references": ["Blei, D.M., Ng, A.Y., Jordan, M.I. 2003. Latent Dirichlet Allocation. J. of Machine Learn. Research. 3, 4--5, 993--1022.", "Ginns, P. 2006. Integrating information: A meta-analysis of the spatial contiguity and temporal contiguity effects. Learning and Instruction. 16, 6, 511--525.", "Helic, D., Trattner, C., Strohmaier, M., Andrews, K. 2011. Are tag clouds useful for navigation? A network-theoretic analysis. Int. J. of Social Computing and Cyber-Physical Systems. 1, 33--55."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742764"}, {"title": "Unsupervised Distance Learning by Rank Correlation Measures for Image Retrieval", "authors": ["César Yugo Okada\n,", "Daniel Carlos Guimarães Pedronette\n,", "Ricardo da S. Torres"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nRanking accurately collection images is the main objective of Content-based Image Retrieval (CBIR) systems. In fact, the set of images ranked at the first positions generally defines the effectiveness of provided search services, i.e., they are used for assessing automatically the quality of search systems as this set usually contains the collection images that are of interest. Recently, the use of ranking information (e.g., rank correlation) has been used in different research initiatives with the objective of improving the effectiveness of image retrieval tasks. This paper presents a broad rank correlation analysis for unsupervised distance learning on image retrieval tasks. Various well-known rank correlation measures are considered and two new measures are proposed. Several experiments were conducted considering various image datasets involving shape, color, and texture descriptors. Experimental results demonstrate that ranking information can be exploited for distance learning tasks successfully. Evaluated approaches yield better results in terms of effectiveness than various state-of-the-art algorithms.", "references": ["N. Arica and F. T. Y. Vural. BAS: a perceptual shape descriptor based on the beam angle statistics. Pattern Recognition Letters, 24(9-10):1627--1639, 2003.", "X. Bai, B. Wang, X. Wang, W. Liu, and Z. Tu. Co-transduction for shape retrieval. In ECCV, volume 3, pages 328--341, 2010.", "S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. PAMI, 24(4):509--522, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749335"}, {"title": "WISE Blogs: A Special Blog Search Engine", "authors": ["João Simões\n,", "Frederico Azeiteiro\n,", "Jorge Bernardino"], "publication": "C3S2E '15: Proceedings of the Eighth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nIn this paper, we present models and blog search engines that currently exist and also propose a model to search blogs -- WISE Blogs. This model uses several keyword search techniques, also based on several API's that picks up the latest posts on blogging platforms, as well as the reading of RSS feeds and still uses a web crawler in strategic websites where blog contents are updated. The purpose of this model is to create a solution that is capable to catch a high number of blogs and to store its content.", "references": ["WIKIPEDIA. Interface de Programação de Aplicações. &lt;http://en.wikipedia.org/wiki/Interface_de_programação_de_aplicações&gt;. Retrieved on: 5 May 2015.", "JAVA, Akshay. Mining Social Media Communities and Content. 2008. 164 f. Dissertation (Doctorate) - Philosophy, University Of Maryland, Maryland, 2008.", "THELWALL, Mike; HASLER, Laura. Blog search engines. Wolverhampton: University Of Wolverhampton, 2006"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790798.2790824"}, {"title": "Strawman: A Batch In Situ Visualization and Analysis Infrastructure for Multi-Physics Simulation Codes", "authors": ["Matthew Larsen\n,", "Eric Brugger\n,", "Hank Childs\n,", "Jim Eliot\n,", "Kevin Griffin\n,", "Cyrus Harrison"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nWe present Strawman, a system designed to explore the in situ visualization and analysis needs of simulation code teams planning for multi-physics calculations on exascale architectures. Strawman's design derives from key requirements from a diverse set of simulation code teams, including lightweight usage of shared resources, batch processing, ability to leverage modern architectures, and ease-of-use both for software integration and for usage during simulation runs. We describe the Strawman system, the key technologies it depends on, and our experiences integrating Strawman into three proxy simulations. Our findings show that Strawman's design meets our target requirements, and that some of its concepts may be worthy of integration into our community in situ implementations.", "references": ["Apache thrift. https://thrift.apache.org/. {Accessed 12-Aug-2015}.", "Bson specification. http://bsonspec.org/. {Accessed 12-Aug-2015}.", "Civetweb project. https://github.com/civetweb/civetweb. {Accessed 16-Aug-2015}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828625"}, {"title": "How Organizational Culture influences BPM Evolution", "authors": ["Iveruska Jatoba\n,", "Carina Alves"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nBusiness Process Management (BPM) has become a powerful tool to increase the efficiency and effectiveness of services provided in public and private organizations. However, there is growing awareness that BPM requires a holistic view of the organization where the organizational culture is a critical success factor for the implementation of a BPM initiative. This article presents a case study that explores the values and cultural aspects of an organization that contribute as facilitators and barriers to the development of a BPM initiative.", "references": ["CBOK. 2013. Guia para o Gerenciamento de Processos de Negócio: Corpo Comum de Conhecimento. Versão 3.0, 1a. Ed. ABPMP. Brasil.", "Easterbrook, S., Singer, S., Storey, M. and Damian, D. 2008. Selecting Empirical Methods for Software Engineering Research. In: Guide to Advanced Empirical Software Engineering, eds. Springer London.", "Grau, C., Mörmann, J. 2014. Investigating the Relationship between Process Management and Organizational Culture: Literature Review and Research Agenda. Sciedu Press, v.1, n.2."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814173"}, {"title": "WADaR: joint wrapper and data repair", "authors": ["Stefano Ortona\n,", "Giorgio Orsi\n,", "Marcello Buoncristiano\n,", "Tim Furche"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWeb scraping (or wrapping) is a popular means for acquiring data from the web. Recent advancements have made scalable wrapper-generation possible and enabled data acquisition processes involving thousands of sources. This makes wrapper analysis and maintenance both needed and challenging as no scalable tools exists that support these tasks.\nWe demonstrate WADaR, a scalable and highly automated tool for joint wrapper and data repair. WADaR uses off-the-shelf entity recognisers to locate target entities in wrapper-generated data. Markov chains are used to determine structural repairs, that are then encoded into suitable repairs for both the data and corresponding wrappers.\nWe show that WADaR is able to increase the quality of wrapper-generated relations between 15% and 60%, and to fully repair the corresponding wrapper without any knowledge of the original website in more than 50% of the cases.", "references": ["M. Bronzi, V. Crescenzi, P. Merialdo, and P. Papotti. Extraction and integration of partially overlapping web sources. PVLDB, 6(10):805--816, 2013.", "L. Chen, S. Ortona, G. Orsi, and M. Benedikt. Aggregating semantic annotators. PVLDB, 6(13):1486--1497, 2013.", "X. Chu, Y. He, K. Chakrabarti, and K. Ganjam. Tegra: Table extraction by global record alignment. In SIGMOD, pages 1713--1728. ACM, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824120"}, {"title": "Multithreaded Processing in Dynamic Inverted Indexes for Web Search Engines", "authors": ["Carolina Bonacic\n,", "Danilo Bustos\n,", "Veronica Gil-Costa\n,", "Mauricio Marin\n,", "Victor Sepulveda"], "publication": "LSDS-IR '15: Proceedings of the 2015 Workshop on Large-Scale and Distributed System for Information Retrieval", "abstract": "ABSTRACT\nProcessing queries in Web search engines demands the efficient use of hardware resources to cope with the scale and dynamics of user traffic. This paper focuses on the multithreaded processing of queries that requires (1) accessing a large inverted index data structure to obtain a set of documents, (2) rank them by executing the WAND operator in order to obtain the top K most pertinent documents for the query, and (3) resolve the insertion of new documents on the inverted index concurrently with the execution of queries. We propose an efficient strategy to assign threads to queries and index update operations which is suitable to support updates on the index concurrently with query processing. The core of our proposal is a simple classification technique devised to quickly assign threads to query operations.", "references": ["V. N. Anh and A. Moffat. Inverted index compression using word-aligned binary codes. Inf. Retr., 8(1):151--166, 2005.", "D. Arroyuelo, S. González, M. Oyarzún, and V. Sepulveda. Document identifier reassignment and run-length-compressed inverted indexes for improved search performance. In SIGIR, pages 173--182, 2013.", "R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology behind Search (ACM Press Books). Addison-Wesley Professional, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809948.2809952"}, {"title": "Automated Computational Cognitive-Modeling: Goal-Specific Analysis for Large Websites", "authors": ["Paul Van Schaik\n,", "Raza Habib Muzahir\n,", "Mike Lockyer"], "publication": "ACM Transactions on Computer-Human Interaction", "abstract": "Abstract\nThe information architecture of websites is the most important remaining source of usability problems. Therefore, this research explores automated cognitive computational analysis of the information architecture of large websites as a basis for improvement. To support goal-specific analysis, an enhanced model of web navigation was implemented with a novel database-oriented approach. Web navigation was simulated on the information architecture of two large sites. With the improved labeling system of the information architecture, simulation results showed a significant reduction in navigation problems. The results of two experiments demonstrate that sites with improved information architecture result in better outcomes of user information retrieval. Our database-oriented approach is extensible, allowing non-goal-specific analysis, modeling of nontext media content, and analysis of the organization- and navigation systems of information architectures.", "references": ["Rafal Ablamowicz and Bertfried Fauser. 2007. CLIFFORD: A Maple 11 Package for Clifford Algebra Computations, version 11. (2007). Retrieved February 28, 2008 from http://math.tntech.edu/rafal/cliff11/index.html.", "I. Ahmed and J. Blustein. 2006. Influence of spatial ability in navigation: using look-ahead Breadcrumbs on the web. International Journal of Web Based Communities 2, 183--196.", "J. S. Ahuja and J. Webster. 2001. Perceived disorientation: An examination of a new measure to assess web design effectiveness. Interacting with Computers 14, 15--29."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746234"}, {"title": "Balancing Novelty and Salience: Adaptive Learning to Rank Entities for Timeline Summarization of High-impact Events", "authors": ["Tuan A. Tran\n,", "Claudia Niederee\n,", "Nattiya Kanhabua\n,", "Ujwal Gadiraju\n,", "Avishek Anand"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLong-running, high-impact events such as the Boston Marathon bombing often develop through many stages and involve a large number of entities in their unfolding. Timeline summarization of an event by key sentences eases story digestion, but does not distinguish between what a user remembers and what she might want to re-check. In this work, we present a novel approach for timeline summarization of high-impact events, which uses entities instead of sentences for summarizing the event at each individual point in time. Such entity summaries can serve as both (1) important memory cues in a retrospective event consideration and (2) pointers for personalized event exploration. In order to automatically create such summaries, it is crucial to identify the \"right\" entities for inclusion. We propose to learn a ranking function for entities, with a dynamically adapted trade-off between the in-document salience of entities and the informativeness of entities across documents, i.e., the level of new information associated with an entity for a time point under consideration. Furthermore, for capturing collective attention for an entity we use an innovative soft labeling approach based on Wikipedia. Our experiments on a real large news datasets confirm the effectiveness of the proposed methods.", "references": ["P. André, J. Teevan, and S. T. Dumais. From x-rays to silly putty via uranus: serendipity and its role in web search. In CHI, 2009.", "D. Berntsen. Involuntary autobiographical memories: An introduction to the unbidden past. Cambridge University Press, 2009.", "J. Bian, X. Li, F. Li, Z. Zheng, and H. Zha. Ranking specialization for web search: a divide-and-conquer approach by using topical ranksvm. In WWW, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806486"}, {"title": "Recommending Users and Communities in Social Media", "authors": ["Lei Li\n,", "Wei Peng\n,", "Saurabh Kataria\n,", "Tong Sun\n,", "Tao Li"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nSocial media has become increasingly prevalent in the last few years, not only enabling people to connect with each other by social links, but also providing platforms for people to share information and interact over diverse topics. Rich user-generated information, for example, users’ relationships and daily posts, are often available in most social media service websites. Given such information, a challenging problem is to provide reasonable user and community recommendation for a target user, and consequently, help the target user engage in the daily discussions and activities with his/her friends or like-minded people. In this article, we propose a unified framework of recommending users and communities that utilizes the information in social media. Given a user’s profile or a set of keywords as input, our framework is capable of recommending influential users and topic-cohesive interactive communities that are most relevant to the given user or keywords. With the proposed framework, users can find other individuals or communities sharing similar interests, and then have more interaction with these users or within the communities. We present a generative topic model to discover user-oriented and community-oriented topics simultaneously, which enables us to capture the exact topical interests of users, as well as the focuses of communities. Extensive experimental evaluation and case studies on a dataset collected from Twitter demonstrate the effectiveness of our proposed framework compared with other probabilistic-topic-model-based recommendation methods.", "references": ["Mohammad Al Hasan, Vineet Chaoji, Saeed Salem, and Mohammed Zaki. 2006. Link prediction using supervised learning. In SDM06: Workshop on Link Analysis, Counter-Terrorism and Security. 1--10.", "Arthur Asuncion, Max Welling, Padhraic Smyth, and Yee Whye Teh. 2009. On smoothing and inference for topic models. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence. AUAI Press, 27--34.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res. 3, 993--1022."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757282"}, {"title": "A hybrid approach for Arabic named entity disambiguation", "authors": ["Mohammad Al-Smadi\n,", "Bashar Talafha\n,", "Omar Qawasmeh\n,", "Mohammed N. Alandoli\n,", "Wegdan A. Hussien\n,", "Christian Guetl"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nThis research aims at tackling the problem of Arabic Named Entity Disambiguation (NED) through an enhanced approach of information extraction from DBpedia and Arabic Wikipedia using query label expansion and text similarity techniques.", "references": ["F. Alotaibi and M. Lee. Mapping Arabic Wikipedia into the Named Entities Taxonomy\", In Proceedings of the 24th International Conference on Computational Linguistics (COLING), p43--52, IIT, Mumbai, India, December 8-15. 2012.", "J. Lehmann, et al. DBpedia - a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web Journal, 2014.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. In The Semantic Web SE - 52, volume 4825 of Lecture Notes in Computer Science, pages 722--735. Springer Berlin Heidelberg, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809589"}, {"title": "An analysis Instruments for Assessing Adherence to level 2 TMMi in Small Enterprises", "authors": ["Daniella de Oliveira Costa\n,", "Plinio de Sa Leitao\n,", "Fabio Nogueira de Lucena"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nContext. The assessment of maturity of the testing process, although it is consensual in organizations and universities also requires affordable tools for informal assessment in small businesses according to a maturity model, as TMMi. Purpose. Identify and evaluate instruments to measure adherence to Level 2 of maturity, according to the TMMi, the testing process in small businesses. Methodology. It is an applied qualitative exploratory study which includes conducting a case study in small businesses. Involves: identifying assessment tools, featuring companies, application and analysis of the instruments and their results. Results. Two instruments, were applied in the processes of two enterprises. The instruments have different level of detail, and the results obtained differ at various areas of the process. Conclusions. The creation of an instrument with details on the practices and work products of the testing process, are not sufficient for understanding the practice, it requires more support for the domain of features. There is still need for preparing the company's evaluators to better assessment of the practicals.", "references": ["Araújo, A. F. Arcabouço para Avaliação do Nível de Maturidade em Teste de Software em Micro e Pequenas Empresas. Dissertação de mestrado. Universidade Federal de Goiás. 2013.", "APOEMA. Processo de Teste de Software para Pequenas e Micro Empresas. Disponível em: http://www.apoema.inf.ufg.br/pts-mpe/index.php/downloads", "Höhn, E. N. KiTest: Um arcabouço de conhecimento e melhoria de processo de teste. Tese de Doutorado. Universidade de São Paulo. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814125"}, {"title": "Learning to Reweight Terms with Distributed Representations", "authors": ["Guoqing Zheng\n,", "Jamie Callan"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTerm weighting is a fundamental problem in IR research and numerous weighting models have been proposed. Proper term weighting can greatly improve retrieval accuracies, which essentially involves two types of query understanding: interpreting the query and judging the relative contribution of the terms to the query. These two steps are often dealt with separately, and complicated yet not so effective weighting strategies are proposed. In this paper, we propose to address query interpretation and term weighting in a unified framework built upon distributed representations of words from recent advances in neural network language modeling. Specifically, we represent term and query as vectors in the same latent space, construct features for terms using their word vectors and learn a model to map the features onto the defined target term weights. The proposed method is simple yet effective. Experiments using four collections and two retrieval models demonstrates significantly higher retrieval accuracies than baseline models.", "references": ["M. Bendersky, D. Metzler, and W. B. Croft. Learning concept importance using a weighted dependence model. In Proceedings of the third ACM international conference on Web search and data mining, pages 31--40. ACM, 2010.", "M. Bendersky, D. Metzler, and W. B. Croft. Parameterized concept weighting in verbose queries. In SIGIR, pages 605--614, 2011.", "Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137--1155, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767700"}, {"title": "Session details: Sampling & filtering", "authors": ["Jaroslav Krivanek"], "publication": "ACM Transactions on Graphics", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3263275"}, {"title": "Harvesting Multiple Sources for User Profile Learning: a Big Data Study", "authors": ["Aleksandr Farseev\n,", "Liqiang Nie\n,", "Mohammad Akbari\n,", "Tat-Seng Chua"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nUser profile learning, such as mobility and demographic profile learning, is of great importance to various applications. Meanwhile, the rapid growth of multiple social platforms makes it possible to perform a comprehensive user profile learning from different views. However, the research efforts on user profile learning from multiple data sources are still relatively sparse, and there is no large-scale dataset released towards user profile learning. In our study, we contribute such benchmark and perform an initial study on user mobility and demographic profile learning. First, we constructed and released a large-scale multi-source multi-modal dataset from three geographical areas. We then applied our proposed ensemble model on this dataset to learn user profile. Based on our experimental results, we observed that multiple data sources mutually complement each other and their appropriate fusion boosts the user profiling performance.", "references": ["E. Amigó, J. Carrillo-de Albornoz, I. Chugur, A. Corujo, J. Gonzalo, E. Meij, M. de Rijke, and D. Spina. Overview of replab 2014: author profiling and reputation dimensions for online reputation management. In Information Access Evaluation. Multilinguality, and Interaction. 2014.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 2003.", "N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. Smote: synthetic minority over-sampling technique. Journal of artificial intelligence research, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749381"}, {"title": "Don't trust the cloud, verify: integrity and consistency for cloud object stores", "authors": ["Marcus Brandenburger\n,", "Christian Cachin\n,", "Nikola Knežević"], "publication": "SYSTOR '15: Proceedings of the 8th ACM International Systems and Storage Conference", "abstract": "ABSTRACT\nCloud services have turned remote computation into a commodity and enable convenient online collaboration. However, they require that clients fully trust the service provider in terms of confidentiality, integrity, and availability. Towards reducing this dependency, this paper introduces a protocol for verification of integrity and consistency for cloud object storage (VICOS), which enables a group of mutually trusting clients to detect data-integrity and consistency violations for cloud storage. It aims at services where multiple clients cooperate on data stored remotely on a potentially misbehaving service. VICOS enforces the consistency notion of fork-linearizability, supports wait-free client semantics for most operations, and reduces the computation and communication overhead compared to previous protocols. VICOS is based in a generic way on any authenticated data structure. A prototype of VICOS that works with the key-value store interface of commodity cloud storage has been implemented, and an evaluation demonstrates its advantage compared to existing systems.", "references": ["A. Adya, W. J. Bolosky, M. Castro, G. Cermak, R. Chaiken, J. R. Douceur, J. Howell, J. R. Lorch, M. Theimer, and R. P. Wattenhofer. FARSITE: Federated, available, and reliable storage for an incompletely trusted environment. In Proc. 5th Symp. Operating Systems Design and Implementation (OSDI), 2002.", "H. Attiya and J. Welch. Distributed Computing: Fundamentals, Simulations and Advanced Topics. Wiley, second edition, 2004.", "M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor. Checking the correctness of memories. In Algorithmica, volume 12, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757667.2757681"}, {"title": "2014 symposium on search-based software engineering: event report", "authors": ["Nadia Alshahwan"], "publication": "ACM SIGEVOlution", "abstract": "Abstract\nThe city of Fortaleza, Brazil hosted the sixth edition of the Symposium on Search-Based Software Engineering (SBSE) between the 26th and 29th of August. Brazil was chosen to host the symposium because of its strong and growing SBSE community.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815474.2815479"}, {"title": "Ontology-based recommender system for information support in knowledge-intensive processes", "authors": ["Yordan Terziev\n,", "Marian Benner-Wickner\n,", "Tobias Brückmann\n,", "Volker Gruhn"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nKnowledge-intensive processes are difficult to support because of their complexity, high variability and unpredictable information requirements. Therefore such process types are handled manually by knowledge workers with expertise in the domain. Yet to make informed decisions, knowledge workers require a multitude of domain specific, case-related information. This often leads to a time-consuming search for information and knowledge required to address the issues occurring in the case. To reduce the time spent searching for information, we propose an ontology-based recommender system that provides case-related information based on documents gathered in accumulated similar cases. The recommender system builds models of domain specific concepts for past cases as well as for the current case, which are used for case similarity calculation. To evaluate the performance of parts of our approach we used the OHSUMED document collection and compared the cosine similarity measure of ontological case model against textual case model.", "references": ["Aamodt, A. and Plaza, E. 1994. Case-based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. AI Commun 7, 1, 39--59.", "Abecker, A., Bernardi, A., Maus, H., and Wenzel, C. 2000. Information support for knowledge-intensive business processes-combining workflows with document analysis and information retrieval. Bringing Knowledge to Business Processes, 53--60.", "Benner, M., Book, M., Brückmann, T., and Gruhn, V. Execution Support for Agenda-Driven Case Management."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809600"}, {"title": "Poster: Krowd: A Key-Value Store for Crowded Venues", "authors": ["Utsav Drolia\n,", "Nathan Mickulicz\n,", "Rajeev Gandhi\n,", "Priya Narasimhan"], "publication": "S3 '15: Proceedings of the 2015 Workshop on Wireless of the Students, by the Students, & for the Students", "abstract": "ABSTRACT\nAttendees of live events want to capture and share rich content using their mobile devices, during the events. However, the infrastructure at venues that host live events provide poor, low-bandwidth connectivity. Instead of relying on infrastructure provided by the venue, we propose to stand up a temporary \"infrastructure\" using the very devices that need it, to enable content-sharing with nearby devices. To this end, we developed Krowd, a novel system that provides a key-value store abstraction to applications that share content among local, nearby users. We evaluated Krowd using over 200 hours of real-world traces from sold-out NBA and NHL playoffs and show that it is 50% faster and consumes 50% less bandwidth than alternative systems. We believe that Krowd is the only decentralized and distributed system to provide a key-value store made for neighboring mobile devices and of neighboring mobile devices.", "references": ["Dano, M. Super Bowl traffic stats. http://goo.gl/uzMD2B.", "Kapustka, P., and Stoffel, C. State of the Stadium Technology Survey. Tech. rep., 2014.", "Steinbach, P. Wi-Fi Service Increasingly Seen As a Must-Have Stadium Amenity. http://goo.gl/LCGCDv, July 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801694.2802145"}, {"title": "A Similarity Measure for Weaving Patterns in Textiles", "authors": ["Sven Helmer\n,", "Vuong Minh Ngo"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe propose a novel approach for measuring the similarity between weaving patterns that can provide similarity-based search functionality for textile archives. We represent textile structures using hypergraphs and extract multisets of $k$-neighborhoods from these graphs. The resulting multisets are then compared using Jaccard coefficients, Hamming distances, and cosine measures. We evaluate the different variants of our similarity measure experimentally, showing that it can be implemented efficiently and illustrating its quality using it to cluster and query a data set containing more than a thousand textile samples.", "references": ["D. Arnold and P. Dransart, editors. Textiles, Technical Practice and Power in the Andes. Archetype Books, London, 2014.", "L. Babai and P. Codenotti. Isomorphism of hypergraphs of low rank in moderately exponential time. In FOCS'08, pages 667--676, 2008.", "I. Bloch, A. Bretto, and A. Leborgne. Similarity between hypergraphs based on mathematical morphology. In Mathematical Morphology and Its Applications to Signal and Image Processing, volume 7883 of LNCS, pages 1--12. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767735"}, {"title": "Enriching Arabic Tweets Representation based on Web Search Engine and the Rough Set Theory", "authors": ["Mohammed Bekkali\n,", "Issam Sahmoudi\n,", "Abdelmonaime Lachkar"], "publication": "ASONAM '15: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015", "abstract": "ABSTRACT\nTwitter is a popular micro-blogging service where users search for timely and social information. Users post short text messages called Tweets, which are limited in length. These Tweets are different from traditional documents in its shortness and sparseness. As a result, short text tends to be ambiguous without enough contextual information. To address these issues, we propose an efficient method to enrich the tweet's representation for the Arabic language using web search engine as a large and open corpus and the Rough Set Theory which is a mathematical tool to deal with vagueness and uncertainty. To assess the performance of the proposed system, a series of experiments has been conducted. The effectiveness of our system has been evaluated and compared in terms of the F1-measure using the Naïve Bayesian (NB) and the Support Vector Machine (SVM) classifiers in our Arabic Tweets Categorization System. The obtained results show that enriching the tweet's representation increases significantly the F1-measure of the Arabic tweets categorization system.", "references": ["Go, A. Bhayani, R. & Huang, L. Twitter Sentiment Classification using Distant Supervision. Processing. 1-6. (2009)", "B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu. Short Text Classification in Twitter to Improve Information Filtering, SIGIR'10, July 19--23, 2010, Geneva, Switzerland.ACM 978-1 60558-896-4/10/07. (2010)", "Jiliang TANG, Xufei WANG, Huiji GAO, Xia HU and Huan LIU.Enriching short text representation in microblog for clustering Front. Comput. Sci., 6(1) DOI 10.1007/s11704-009-0000-0. (2012)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808797.2809339"}, {"title": "Real Time Recommendations from Connoisseurs", "authors": ["Noriaki Kawamae"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThe information overload problem remains serious for both consumers and service/content providers, leading to heightened demands for personalized recommendations. For recommender systems, updating user models is one of the most important tasks to keep up with their changing preferences and trends. Especially since new consumers and items emerge every day, which are promptly rated or reviewed, updating lists of items and rankings is crucial. In this paper, we set the goal of real time recommendation, to present these items instantly. Unlike standard collaborative filtering algorithms, our offline approach focuses only innovative consumers for these predictions, and then uses as few consumers as possible while keeping the same precision. Since innovators exist in many communities, and their opinions will spread and then stimulate their followers to adopt the same behavior, our approach is based on the hypothesis that a set of innova- tive consumers is sufficient to represent the most representative opinions in each community. Following this hypothesis, we derive a scalable method to detect both communities and innovative consumers in each community from a web- scale data from a behavior log. Our evaluation shows that our proposed weighting method can accurately sample given logs, and be compatible only with previous algorithms for real time recommendations.", "references": ["D. Aldous. Exchangeability and related topics, volume 1117 of Lecture Notes in Math. Springer, Berlin, 1985.", "J. K. B. Sarwa, G. Karypis and J. Riedl. Item-based collaborative filtering recommendation algorithms. In WWW, pages 285--295, 2001.", "S. Bhagat, A. Goyal, and L. V. Lakshmanan. Maximizing product adoption in social networks. In WSDM, pages 603--612, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783260"}, {"title": "Where to Go on Your Next Trip?: Optimizing Travel Destinations Based on User Preferences", "authors": ["Julia Kiseleva\n,", "Melanie J.I. Mueller\n,", "Lucas Bernardi\n,", "Chad Davis\n,", "Ivan Kovacek\n,", "Mats Stafseng Einarsen\n,", "Jaap Kamps\n,", "Alexander Tuzhilin\n,"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecommendation based on user preferences is a common task for e-commerce websites. New recommendation algorithms are often evaluated by offline comparison to baseline algorithms such as recommending random or the most popular items. Here, we investigate how these algorithms themselves perform and compare to the operational production system in large scale online experiments in a real-world application. Specifically, we focus on recommending travel destinations at Booking.com, a major online travel site, to users searching for their preferred vacation activities. To build ranking models we use multi-criteria rating data provided by previous users after their stay at a destination. We implement three methods and compare them to the current baseline in Booking.com: random, most popular, and Naive Bayes. Our general conclusion is that, in an online A/B test with live users, our Naive-Bayes based ranker increased user engagement significantly over the current online system.", "references": ["G. Adomavicius and Y. Kwon. New recommendation techniques for multicriteria rating systems. IEEE Intelligent Systems (EXPERT), 22 (3): 48--55, 2007.", "G. Adomavicius, N. Manouselis, and Y. Kwon. Multi-Criteria Recommender Systems, volume 768--803. Recommender Systems Handbook, Springer, 2011.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceeding of KDD, pages 19--28, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776777"}, {"title": "Semantic Web service Discovery Based on Fuzzy Dominated Scores", "authors": ["Hadjila Fethallah\n,", "Merzoug Mohammed\n,", "Belabed Amine"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nIn this paper, we focus on the web service discovery problem. Roughly speaking, this issue consists in selecting a set of services that are suitable to a given request. This searching process will be more complicated, when we aim to exploit several matching algorithms, as well as several matching criteria (such as inputs, outputs...). In this work we present a novel hybrid matching approach, that simultaneously uses five matching algorithms. The results (ie. ranked services) given by these components are aggregated into a final list. This later should have a high precision and recall rates, in comparison with the input lists. To get this aim, we adopt a fuzzy aggregating function that sums for each service, the margin separating the current service and those that dominate it. The conducted experiments show that the proposed approach is more effective than the individual matching algorithms.", "references": ["F. Curbera, F. Duftler, R. Khalaf, W. Nagy, N. Mukhi, and S. Weerawarana. Unraveling the Web Services Web: An Introduction to SOAP, WSDL, and UDDI. IEEE Internet Computing, 6(2). (2002).", "OASIS. Web services business process execution language, April 2007. http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.pdf.", "M. Klusch, B. Fries and K. Sycara. Automated Semantic Web Service Discovery with OWLS-MX. Proceedings of 5th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), Hakodate, Japan, ACM Press. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816881"}, {"title": "Tagging Personal Photos with Transfer Deep Learning", "authors": ["Jianlong Fu\n,", "Tao Mei\n,", "Kuiyuan Yang\n,", "Hanqing Lu\n,", "Yong Rui"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe advent of mobile devices and media cloud services has led to the unprecedented growing of personal photo collections. One of the fundamental problems in managing the increasing number of photos is automatic image tagging. Existing research has predominantly focused on tagging general Web images with a well-labelled image database, e.g., ImageNet. However, they can only achieve limited success on personal photos due to the domain gaps between personal photos and Web images. These gaps originate from the differences in semantic distribution and visual appearance. To deal with these challenges, in this paper, we present a novel transfer deep learning approach to tag personal photos. Specifically, to solve the semantic distribution gap, we have designed an ontology consisting of a hierarchical vocabulary tailored for personal photos. This ontology is mined from $10,000$ active users in Flickr with 20 million photos and 2.7 million unique tags. To deal with the visual appearance gap, we discover the intermediate image representations and ontology priors by deep learning with bottom-up and top-down transfers across two domains, where Web images are the source domain and personal photos are the target. Moreover, we present two modes (single and batch-modes) in tagging and find that the batch-mode is highly effective to tag photo collections. We conducted personal photo tagging on 7,000 real personal photos and personal photo search on the MIT-Adobe FiveK photo dataset. The proposed tagging approach is able to achieve a performance gain of $12.8\\%$ and $4.5\\%$ in terms of NDCG@5, against the state-of-the-art hand-crafted feature-based and deep learning-based methods, respectively.", "references": ["Y. Bengio. Learning deep architectures for AI. Found. Trends Mach. Learn., 2(1):1--127, Jan. 2009.", "V. Bychkovsky, S. Paris, E. Chan, and F. Durand. Learning photographic global tonal adjustment with a database of input / output image pairs. In CVPR, pages 97--104, 2011.", "L. Cao, J. Luo, H. A. Kautz, and T. S. Huang. Annotating collections of photos using hierarchical event and scene models. In CVPR, pages 1--8, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741112"}, {"title": "The Application of Recommender Systems in a Multi Site, Multi Domain Environment", "authors": ["Steven Bourke"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender systems have cemented themselves in the daily experiences of most online users. In this work we will elaborate on the different challenges faced when creating recommendations in the following domains - Online marketplaces: Two sided marketplaces where buyers and sellers can interact and sell items with each other. - Online News: Online news sites where users consume the latest news articles related to current affairs. - Generic Recommendations: Sites which create generic recommendations based on generalised algorithms.\nWe will review how we address these different challenges in Schibsted. Schibsted is an international media company with over 200 million unique users a month, split across 39 countries across the world.\nConcretely we will review, and compare the primary challenges between the different domains mentioned as well as the commonalities and general lessons we have learnt. For example in a two sided marketplace, it is important that both actors in the interaction are considered when creating recommendations. Constraints such as price sensitivity and geographical location become important when identifying good quality recommendations for our users.\nAlternatively, in online news we need to consider issues such as freshness and topical relevance when creating recommendations for users, while also striving to ensure we have editorial satisfaction. Finally we can look to generic recommendation solutions where we provide simple recommendation API end points. In this case it is important to ensure good quality recommendations while ensuring a generic enough solution that it can be used in many different scenarios.\nWhat makes these challenges particularly interesting is that we approach these different challenges with a holistic view of for improving the overall user experience for our users in Schibsted.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799495"}, {"title": "Swap Retrieval: Retrieving Images of Cats When the Query Shows a Dog", "authors": ["Amir Ghodrati\n,", "Xu Jia\n,", "Marco Pedersoli\n,", "Tinne Tuytelaars"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nQuery-by-example remains popular in image retrieval because it can exploit contextual information encoded in the image, that is difficult to express in a traditional textual query. Textual queries, on the other hand, give more flexibility in that it's easy to reformulate and refine a text query based on initial results.\nIn this work we make a first step towards getting the best of both worlds: we use an image to specify the context, but let the user specify a related category as main search criterion. For instance, starting from an image of a dog in a certain situation/context, the goal is to find images of cats with a similar situation/context.\nWe present an evaluation scheme for this new and challenging task, which we call swap retrieval, and use it to compare various methods. Results show that standard query-by-example techniques do not adapt well to the new task. Instead, techniques based on semantic knowledge extracted from textual descriptions available at training time perform reasonably well, although they are still far from the performance needed for practical use.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, 2008.", "T. L. Berg, A. C. Berg, and J. Shih. Automatic attribute discovery and characterization from noisy web data. In ECCV, 2010.", "R. Datta, D. Joshi, J. Li, and J. Z. Wang. Image retrieval: Ideas, influences, and trends of the new age. ACM Comput. Surv., 40(2), 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749373"}, {"title": "What are Popular: Exploring Twitter Features for Event Detection, Tracking and Visualization", "authors": ["Hongyun Cai\n,", "Yang Yang\n,", "Xuefei Li\n,", "Zi Huang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nAs one of the most representative social media platforms, Twitter provides various real-life information on social events in real time. Despite that social event detection has been actively studied, tweet images, which appear in around 36 percent of the total tweets, have not been well utilized for this research problem. Most existing event detection methods tend to represent an image as a bag-of-visual-words and then process these visual words in the same way as textual words. This may not fully exploit the visual properties of images. State-of-the-art visual features like convolutional neural network (CNN) features have shown significant performance gains over the traditional bag-of-visual-words in unveiling the image's semantics. Unfortunately, they have not been employed in detecting events from social websites. Hence, how to make the most of tweet images to improve the performance of social event detection and visualization remains open. In this paper, we thoroughly study the impact of tweet images on social event detection for different event categories using various visual features. A novel topic model which jointly models five Twitter features (text, image, location, timestamp and hashtag) is designed to discover events from the sheer amount of tweets. Moreover, the evolutions of events are tracked by linking the events detected on adjacent days and each event is visualized by representative images selected on three predefined criteria. Extensive experiments have been conducted on a real-life tweet dataset to verify the effectiveness of our method.", "references": ["J. Bian, Y. Yang, and T.-S. Chua. Multimedia summarization for trending topics in microblogs. In CIKM, pages 1807--1812, 2013.", "J. Bian, Y. Yang, and T.-S. Chua. Predicting trending messages and diffusion participants in microblogging network. In SIGIR, pages 537--546, 2014.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806236"}, {"title": "Structural Constraints for Multipartite Entity Resolution with Markov Logic Network", "authors": ["Tengyuan Ye\n,", "Hady W. Lauw"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMultipartite entity resolution seeks to match entity mentions across several collections. An entity mention is presumed unique within a collection, and thus could match at most one entity mention in each of the other collections. In addition to domain-specific features considered in entity resolution, there are a number of domain-invariant structural contraints that apply in this scenario, including one-to-one assignment as well as cross-collection transitivity. We propose a principled solution to the multipartite entity resolution problem, building on the foundation of Markov Logic Network (MLN) that combines probabilistic graphical model and first-order logic. We describe how the domain-invariant structural constraints could be expressed appropriately in terms of Markov logic, flexibly allowing joint modeling with domain-specific features. Experiments on two real-life datasets, each spanning four collections, show the utility of this approach and validate the contributions of various MLN components.", "references": ["Y. Crama, A. G. Oerlemans, and F. C. Spieksma. Approximation algorithms for three-dimensional assignment problems with triangle inequalities. Springer, 1996.", "A. K. Elmagarmid, P. G. Ipeirotis, and V. S. Verykios. Duplicate record detection: A survey. TKDE, 2007.", "I. P. Fellegi and A. B. Sunter. A theory for record linkage. JASA, 1969."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806590"}, {"title": "Automatic Filling of Hidden Web Forms: A Survey", "authors": ["Gustavo Zanini Kantorski\n,", "Viviane Pereira Moreira\n,", "Carlos Alberto Heuser"], "publication": "ACM SIGMOD Record", "abstract": "Abstract\nA significant part of the information available on the Web is stored in online databases which compose what is known as Hidden Web or Deep Web. In order to access information from the Hidden Web, one must fill an HTML form that is submitted as a query to the underlying database. In recent years, many works have focused on how to automate the process of form filling by creating methods for choosing values to fill the fields in the forms. This is a challenging task since forms may contain fields for which there are no predefined values to choose from. This article presents a survey of methods for Web Form Filling, analyzing the existing solutions with respect to the type of forms that they handle and the filling strategy adopted. We provide a comparative analysis of 15 key works in this area and discuss directions for future research.", "references": ["M. Álvarez, J. Raposo, A. Pan, F. Cacheda, F. Bellas, and V. Carneiro. Crawling the content hidden behind web forms. ICCSA, pages 322--333, 2007.", "L. Barbosa and J. Freire. Siphoning hidden-web data through keyword-based interfaces. In Brazilian Symposium on Databases, pages 309--321, 2004.", "L. Barbosa and J. Freire. An adaptive crawler for locating hidden-web entry points. In WWW, pages 441--450, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783888.2783898"}, {"title": "Revisiting Optimal Rank Aggregation: A Dynamic Programming Approach", "authors": ["Shayan A. Tabrizi\n,", "Javid Dadashkarimi\n,", "Mostafa Dehghani\n,", "Hassan Nasr Esfahani\n,", "Azadeh Shakery"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nRank aggregation, that is merging multiple ranked lists, is a pivotal challenge in many information retrieval (IR) systems, especially in distributed IR and multilingual IR. From the evaluation point of view, being able to calculate the upper-bound of performance of the final aggregated list lays the ground for evaluating different aggregation strategies, independently. In this paper, we propose an algorithm based on dynamic programming which, using relevancy information, obtains the aggregated list with the maximum performance that could be possibly achieved by any aggregation strategy. We also provide a detailed proof for the optimality of the result of the algorithm. Furthermore, we demonstrate that the previous proposed algorithm fails to reach the optimal result in many circumstances, due to its greedy essence.", "references": ["M. Braschler. Combination approaches for multilingual text retrieval. Information Retrieval, 7 (1--2): 183--204, 2004.", "M. Braschler, A. Göhring, and P. Schäuble. Eurospider at clef 2002. In CLEF, pages 164--174, 2003.", "J. Callan. Distributed Information Retrieval, volume 7. 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809490"}, {"title": "Gauging Correct Relative Rankings For Similarity Search", "authors": ["Weiren Yu\n,", "Julie McCann"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nOne of the important tasks in link analysis is to quantify the similarity between two objects based on hyperlink structure. SimRank is an attractive similarity measure of this type. Existing work mainly focuses on absolute SimRank scores, and often harnesses an iterative paradigm to compute them. While these iterative scores converge to exact ones with the increasing number of iterations, it is still notoriously difficult to determine how well the relative orders of these iterative scores can be preserved for a given iteration. In this paper, we propose efficient ranking criteria that can secure correct relative orders of node-pairs with respect to SimRank scores when they are computed in an iterative fashion. Moreover, we show the superiority of our criteria in harvesting top-K SimRank scores and bucket orders from a full ranking list. Finally, viable empirical studies verify the usefulness of our techniques for SimRank top-K ranking and bucket ordering.", "references": ["G. Jeh and J. Widom, \"SimRank: a measure of structural-context similarity,\" in KDD, 2002.", "M. Kusumoto, T. Maehara, and K. Kawarabayashi, \"Scalable similarity search for SimRank,\" in SIGMOD, 2014.", "W. Zheng, L. Zou, Y. Feng, L. Chen, and D. Zhao, \"Efficient SimRank-based similarity join over large graphs,\" PVLDB, vol. 6, no. 7, pp. 493--504, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806610"}, {"title": "Gamified Courses in Information Systems Program", "authors": ["Karen da Silva Figueiredo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe use of game design elements in contexts unrelated to games is increasing in industrial and educational scenarios. The gamification applied to teach Information Systems can be seen as a relevant and powerful contemporary strategy to attract students' attention. The present work proposes the use of gamification in the bachelor of Information Systems program in order to engage and motivate students. Also, this work presents the initial game design for the Algorithms III and System Analysis and Design I courses.", "references": ["Deterding, S., Dixon, D., Khaled, R., and Nacke, L. 2011. From game design elements to gamefulness: defining gamification. In Proceedings of the 15th International Academic MindTrek Conference: Envisioning Future Media Environments. ACM, 9-15.", "Borges, S., et al. 2013. Gamificação Aplicada à Educação: Um Mapeamento Sistemático. In XXIV Simpósio Brasileiro de Informática na Educação (SBIE 2013).", "Kapp, K. 2012. The gamification of learning and instruction: game-based methods and strategies for training and education. John Wiley & Sons."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814154"}, {"title": "The RoadRunner framework for efficient and scalable processing of big data", "authors": ["Christos Doulkeridis\n,", "Akrivi Vlachou\n,", "Panagiotis Nikitopoulos\n,", "Panagiotis Tampakis\n,", "Mei Saouk"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this paper, we present the overall architecture of RoadRunner, a Hadoop-based framework that enhances the efficiency of rank-aware query processing by introducing various optimizations to Hadoop, without changing its internal operation. RoadRunner focuses on a specific class of queries that involve ranking, such as top-k queries and top-k joins, as well as on preference-aware queries, such as skyline queries, which are tightly related. For this class of queries, we identify improvements on various stages of MapReduce processing, which result in improved performance without sacrificing scalability. We describe the RoadRunner framework, along with individual modules and their roles, and we demonstrate the merits of the proposed framework by means of showcase query examples.", "references": ["A. Abouzeid, K. Bajda-Pawlikowski, D. J. Abadi, A. Rasin, and A. Silberschatz. HadoopDB: an architectural hybrid of MapReduce and DBMS technologies for analytical workloads. Proceedings of the VLDB Endowment (PVDLB), 2(1):922--933, 2009.", "K. Alsabti, S. Ranka, and V. Singh. A one-pass algorithm for accurately estimating quantiles for disk-resident data. In Proceedings of Very Large Databases (VLDB), pages 346--355, 1997.", "K. S. Candan, J. W. Kim, P. Nagarkar, M. Nagendra, and R. Yu. RanKloud: scalable multimedia data processing in server clusters. IEEE MultiMedia, 18(1):64--77, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801963"}, {"title": "Diffusion-on-Manifold Aggregation of Local Features for Shape-based 3D Model Retrieval", "authors": ["Takahiko Furuya\n,", "Ryutarou Ohbuchi"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAggregating a set of local features has become one of the most common approaches for representing a multi-media data such as 2D image and 3D model. The success of Bag-of-Features (BF) aggregation [2] prompted several extensions to BF, that are, VLAD [12], Fisher Vector (FV) coding [22] and Super Vector (SV) coding [34]. They all learn small number of codewords, or representative local features, by clustering a set of large number of local features. The set of local features extracted from a media data (e.g., an image) is encoded by considering distribution of features around the codewords; BF uses frequency, VLAD and FV uses displacement vector, and SV uses a combination of both. In doing so, these encoding algorithms assume linearity of feature space about a codeword. Consequently, even if the set of features form a non-linear manifold, its non-linearity would be ignored, potentially degrading quality of aggregated features. In this paper, we propose a novel feature aggregation algorithm called Diffusion-on-Manifold (DM) that tries to take into account, via diffusion distance, structure of non-linear manifold formed by the set of local features. In view of 3D shape retrieval, we also propose a local 3D shape feature defined for oriented point set. Experiments using shape-based 3D model retrieval scenario show that the DM aggregation results in better retrieval accuracy than the existing aggregation algorithms we've compared against, that are, VLAD, FV, and SV, etc..", "references": ["Chatfield, K., Lempitsky, V., Vedaldi, A., Zisserman, A. 2011. The devil is in the details: an evaluation of recent feature encoding methods, British Machine Vision Conference (BMVC) 2011.", "Csurka, G., Dance, C. R., Fan, L., Willamowski, J., Bray, C. 2004. Visual Categorization with Bags of Keypoints, Proc. ECCV 2004 workshop on Statistical Learning in Computer Vision, 59--74.", "Donoser, M., Bischof, H. 2013. Diffusion Processes for Retrieval Revisited, Proc. CVPR 2013, 1320--1327."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749380"}, {"title": "Image Tag Assignment, Refinement and Retrieval", "authors": ["Xirong Li\n,", "Tiberio Uricchio\n,", "Lamberto Ballan\n,", "Marco Bertini\n,", "Cees G.M. Snoek\n,", "Alberto Del Bimbo"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis tutorial focuses on challenges and solutions for content-based image annotation and retrieval in the context of online image sharing and tagging. We present a unified review on three closely linked problems, i.e., tag assignment, tag refinement, and tag-based image retrieval. We introduce a taxonomy to structure the growing literature, understand the ingredients of the main works, clarify their connections and difference, and recognize their merits and limitations. Moreover, we present an open-source testbed, with training sets of varying sizes and three test datasets, to evaluate methods of varied learning complexity. A selected set of eleven representative works have been implemented and evaluated. During the tutorial we provide a practice session for hands on experience with the methods, software and datasets. For repeatable experiments all data and code are online at http://www.micc.unifi.it/tagsurvey", "references": ["L. Chen, D. Xu, I. Tsang, and J. Luo. Tag-based image retrieval improved by augmented features and group-based refinement. IEEE Transactions on Multimedia, 14(4):1057--1067, 2012.", "M. Guillaumin, T. Mensink, J. Verbeek, and C. Schmid. TagProp: Discriminative metric learning in nearest neighbor models for image auto-annotation. In Proc. of ICCV, 2009.", "X. Li and C. Snoek. Classifying tag relevance with relevant positive and negative examples. In Proc. of ACM Multimedia, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807419"}, {"title": "Towards Events Tweet Contextualization Using Social Influence Model and Users Conversations", "authors": ["Rami Belkaroui\n,", "Rim Faiz"], "publication": "WIMS '15: Proceedings of the 5th International Conference on Web Intelligence, Mining and Semantics", "abstract": "ABSTRACT\nNowadays, microblogging sites have completely changed the manner in which people communicate and share information. They are among the most relevant source of knowledge where information is created, exchanged and transformed, as witnessed by the important number of their users and their activities during events or campaigns like the terror attack in Paris in 2015. On Twitter, users post messages (called tweets) in real time about events, natural disasters, news, etc. Tweets are short messages that do not exceed 140 characters. Due to this limitation, an individual tweet it's rarely self-content. However, user cannot effectively understand or consume information.\nIn order, to make tweet understandable to a reader, it is therefore necessary to know their context. In fact, on Twitter, context can be derived from users interactions, content streams and friendship. Given that there are rich user interactions on Twitter. In this paper, we propose an approach for tweet contextualization task which combines different types of signals from social users interactions to provide automatically information that explains the tweet. In addition, our approach aims to help users to satisfy any contextual information need. To evaluate our approach, we construct a reference summary by asking assessors to manually select the most informative tweets as a summary. Our experimental results based on this editorial data set offers interesting results and help ensure that context summaries contain adequate correlating information with the given tweet.", "references": ["K. H. Ansary, A. T. Tran, and N. K. Tran. A pipeline tweet contextualization system at INEX 2013. In Working Notes for CLEF 2013 Conference, Valencia, Spain, September 23-26, 2013.", "A. Bandyopadhyay, M. Mitra, and P. Majumder. Query expansion for microblog retrieval. In Proceedings of The Twentieth Text REtrieval Conference, TREC 2011, Gaithersburg, Maryland, November 15-18, 2011.", "A. Bandyopadhyay, S. Pal, M. Mitra, P. Majumder, and K. Ghosh. Passage retrieval for tweet contextualization at INEX 2012. In CLEF 2012 Evaluation Labs and Workshop, Online Working Notes, Rome, Italy, September 17-20, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797115.2797134"}, {"title": "Location in Search", "authors": ["Vanessa Murdock"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAs users turn increasingly to handheld devices to find information, the research community has focused on real-time location signals (GPS signals) to improve search engine effectiveness. Location signals have been investigated for predicting businesses the user will frequent[3], assigning geographic coordinates to media files[1], and to improve mobile search ranking[2]. While the increased focus on real-time user location has produced excellent research, there remains a gap between the capabilities being developed in the research community, and the capabilities being developed by commercial search engines. The core of this discrepancy between the advances in research and advances in industry is understanding the user's location. The vast majority of research on user location assumes that the user's location is known, because the user has provided a GPS signal. For many systems, there is no GPS signal available. The user may choose not enable it, or the system chooses not to prompt the user for the location because doing so degrades the user experience. For these interactions, the system relies on the user's IP address for location information. Further, much of the current research uses public geocoded data such as Foursquare (http://www.foursquare.com visited June 2015), and Twitter (http://www.twitter.com visited June 2015). These data are an incomplete picture of places a user may visit, and are potentially biased in their representation of actual users. The information contained in these data is not the same type of information typically available to a commercial search engine.\nIn this talk we discuss gaps between current research on location, and industry advances in using location signals to improve search results. We focus on user location as one example of a gap between research and development.", "references": ["Larson, M., Soleymani, M., Serdyukov, P., Rudinac, S., Wartena, C., Murdock, V., Friedland, G., Ordelman, R., and Jones, G. Automatic tagging and geotagging in video collections and communities. In Proceedings of the 1st ACM International Conference on Multimedia Retrieval (ICMR). 2011.", "Lv, Y., Lymberopoulos, D., and Wu, Q. An exploration of ranking heuristics in mobile local search. In Proceedings of SIGIR. Portland, 2012.", "Shaw, B., Shea, J., Sinha, S., and Hogue, A. Learning to rank for spatiotemporal search. In Proceedings of WSDM. Rome, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776783"}, {"title": "At the forge: parts of a slow web application", "authors": ["Reuven M. Lerner"], "publication": "Linux Journal", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2846068.2846071"}, {"title": "Cloud Based Dynamical Digital Game Learning Scenario Corresponding to Individual Learner Big Data", "authors": ["Ming-Shen Jian\n,", "Jun-Lin Chen\n,", "Yi-Chi Fang\n,", "Siang-Jyun Li"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn this paper, we propose a Cloud Based Dynamical Digital Game Learning Scenario Corresponding to Individual Learner Big Data according to the proposed dynamic assigning algorithm to separate individual learner into different levels. In dynamic assigning algorithm, student's answering times and answering correct rate for each education scenario in cloud based digital game learning system is considered. Suitable teaching scenario will be provided for individual user corresponding to personal learning ability. Each designed modular teaching materials can be embedded into the game platform on the virtual machine in cloud. The information about users in the individual game learning system can be stored in the cloud database. In addition, the whole learning system is established as a virtual machine. System maintainer can configure the learning system easily and quickly. Based on cloud, different remote devices can connect to server for learning.", "references": ["Bowmaw, R. F. 1982. A Pac-Man Theory of Motivation: Tactical Implications for Classroom Instruction. Educational Technology. Vol. 22, No. 9, pp. 14--17, 1982.", "Braccy, G. W. 1992. The Bright Facture of Integrated Learning System. Educational Technology. Vol. 32, No. 9, pp. 60--62, 1992.", "Randel, J. M., Morris, B. A., Wetzel. C. D. and Whitehill, B. V. 1992. The Effectiveness of Games for Educational Purposes: A Review of Recent Research. Simulation & Gaming. Vol. 23, No. 3, pp. 261--276, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818871"}, {"title": "Cognitive Activity during Web Search", "authors": ["Md. Hedayetul Islam Shovon\n,", "D (Nanda) Nandagopal\n,", "Jia Tina Du\n,", "Ramasamy Vijayalakshmi\n,", "Bernadine Cocks"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearching on the Web or Net-surfing is a part of everyday life for many people, but little is known about the brain activity during Web searching. Such knowledge is essential for better understanding of the cognitive demands imposed by the search system and search tasks. The current study contributes to this understanding by constructing brain networks from EEG data using normalized transfer entropy (NTE) during three Web search task stages: query formulation, viewing of a search result list and reading each individual content page. This study further contributes to the connectivity analysis of the constructed brain networks, since it is an advanced quantitative technique which enables the exploration of brain function by distinct and varied brain areas. By using this approach, we identified that the cognitive activities during the three stages of Web searching are different, with various brain areas becoming more active during the three Web search task stages. Of note, query formulation generated higher interaction between cortical regions than viewing a result list or reading a content page. These findings will have implications for the improvement of Web search engines and search interfaces.", "references": ["Du, J.T.: Cognitive coordinating behaviors in multitasking web search. Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pp. 1117--1118. ACM (2011)", "Du, J.T., Spink, A.: Toward a web search model: Integrating multitasking, cognitive coordination, and cognitive shifts. Journal of the American Society for Information Science and Technology 62, 1446--1472 (2011)", "Scholer, F., Kelly, D., Wu, W.-C., Lee, H.S., Webber, W.: The effect of threshold priming and need for cognition on relevance calibration and assessment. Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, pp. 623--632. ACM (2013)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767784"}, {"title": "From \"Selena Gomez\" to \"Marlon Brando\": Understanding Explorative Entity Search", "authors": ["Iris Miliaraki\n,", "Roi Blanco\n,", "Mounia Lalmas"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nConsider a user who submits a search query \"Shakira\" having a specific search goal in mind (such as her age) but at the same time willing to explore information for other entities related to her, such as comparable singers. In previous work, a system called Spark, was developed to provide such search experience. Given a query submitted to the Yahoo search engine, Spark provides related entity suggestions for the query, exploiting, among else, public knowledge bases from the Semantic Web. We refer to this search scenario as explorative entity search. The effectiveness and efficiency of the approach has been demonstrated in previous work. The way users interact with these related entity suggestions and whether this interaction can be predicted have however not been studied. In this paper, we perform a large-scale analysis into how users interact with the entity results returned by Spark. We characterize the users, queries and sessions that appear to promote an explorative behavior. Based on this analysis, we develop a set of query and user-based features that reflect the click behavior of users and explore their effectiveness in the context of a prediction task.", "references": ["R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval - the concepts and technology behind search, Second edition. Pearson Education Ltd., Harlow, England, 2011.", "T. Berners-Lee, J. Hendler, O. Lassila, et al. The semantic web. Scientific american, 284(5):28--37, 2001.", "R. Blanco, B. B. Cambazoglu, P. Mika, and N. Torzec. Entity Recommendations in Web Search. In The Semantic Web--ISWC 2013, pages 33--48. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741284"}, {"title": "Using social microvolunteering to answer visual questions from blind users", "authors": ["Erin Brady"], "publication": "ACM SIGACCESS Accessibility and Computing", "abstract": "Abstract\nAdvances in technology have proven uniquely useful for blind people, but some visual questions they encounter still require human assistance to answer. We developed VizWiz, a smartphone application that connects blind people with visual questions to sighted workers who can provide answers. In order to make this app more sustainable and scalable, and keep costs from being passed directly to the users, we propose social microvolunteering, which allows people to donate their own time as answerers, but also access to a larger pool of answerers through their friends on social networking sites.", "references": ["Abascal, J. Mobile communication for older people: new opportunities for autonomous life. Workshop on Universal Accessibility of Ubiquitous Computing: Providing for the Elderly, (2001), 1-10.", "Azenkot, S., Prasain, S., Borning, A., Fortuna, E., Ladner, R.E., and Wobbrock, J.O. Enhancing independence and safety for blind and deaf-blind public transit riders. Proceedings of the 29th ACM SIGCHI Conference on Human Factors in Computing System (CHI), (2011), 3247.", "Bigham, J.P., Jayant, C., Ji, H., et al. VizWiz: Nearly Real-time Answers to Visual Questions. Proceedings of the ACM Symposium on User Interface Software and Technology (UIST), (2010)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809904.2809910"}, {"title": "Are Real-World Place Recommender Algorithms Useful in Virtual World Environments?", "authors": ["Leandro Balby Marinho\n,", "Christoph Trattner\n,", "Denis Parra"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nLarge scale virtual worlds such as massive multiplayer online games or 3D worlds gained tremendous popularity over the past few years. With the large and ever increasing amount of content available, virtual world users face the information overload problem. To tackle this issue, game-designers usually deploy recommendation services with the aim of making the virtual world a more joyful environment to be connected at. In this context, we present in this paper the results of a project that aims at understanding the mobility patterns of virtual world users in order to derive place recommenders for helping them to explore content more efficiently. Our study focus on the virtual world SecondLife, one of the largest and most prominent in recent years. Since SecondLife is comparable to real-world Location-based Social Networks (LBSNs), i.e., users can both check-in and share visited virtual places, a natural approach is to assume that place recommenders that are known to work well on real-world LBSNs will also work well on SecondLife. We have put this assumption to the test and found out that (i) while collaborative filtering algorithms have compatible performances in both environments, (ii) existing place recommenders based on geographic metadata are not useful in SecondLife.", "references": ["M. Ahmad, C. Shen, J. Srivastava, and N. Contractor. Predicting Real World Behaviors from Virtual World Data. Springer Proceedings in Complexity. Springer International Publishing, 2014.", "J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proc. of the 20th International Conf. on Advances in Geographic Information Systems, 2012.", "C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. In Proc. AAAI'12, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799674"}, {"title": "An enhanced graph-based infrastructure for software search engines", "authors": ["Marcus Schumacher\n,", "Colin Atkinson"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nThe first generation of software search engines such as Merobase, Sourcerer etc. showed that it is possible to support reasonably sophisticated searches over large bodies of software components using indices based on full-text search engines (most commonly Lucene). However, the tricks these engines use to map code structure to flat text are not only inflexible, they do not scale well to components composed of multiple program modules (e.g. interfaces, classes etc.) As a result, beyond plain string matching, they are only able to support a limited and a priori fixed set of query types, and are rarely, if ever able, to find components composed of more than one code module. In this paper we present an index representation approach which is able to support the key information bound up in source code in a more accurate, flexible way, and thus efficiently support a much wider range of searches on components composed of multiple program modules.", "references": ["A. Deshpande, D. Riehle, The total growth of open source, Fourth Conference on Open Source Systems, Springer Verlag (2008)", "Mili, A., Mili, R., Mittermeir, R.: A Survey of Software Reuse Libraries. Annals of Software Engineering 5 (1998)", "Hatcher, E., Gospodnetic, O., McCandless, M.: Lucene in Action (2nd edition). Manning (2010)"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820568"}, {"title": "HSpam14: A Collection of 14 Million Tweets for Hashtag-Oriented Spam Research", "authors": ["Surendra Sedhai\n,", "Aixin Sun"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nHashtag facilitates information diffusion in Twitter by creating dynamic and virtual communities for information aggregation from all Twitter users. Because hashtags serve as additional channels for one's tweets to be potentially accessed by other users than her own followers, hashtags are targeted for spamming purposes (e.g., hashtag hijacking), particularly the popular and trending hashtags. Although much effort has been devoted to fighting against email/web spam, limited studies are on hashtag-oriented spam in tweets. In this paper, we collected 14 million tweets that matched some trending hashtags in two months' time and then conducted systematic annotation of the tweets being spam and ham (i.e., non-spam). We name the annotated dataset HSpam14. Our annotation process includes four major steps: (i) heuristic-based selection to search for tweets that are more likely to be spam, (ii) near-duplicate cluster based annotation to firstly group similar tweets into clusters and then label the clusters, (iii) reliable ham tweets detection to label tweets that are non-spam, and (iv) Expectation-Maximization (EM)-based label prediction to predict the labels of remaining unlabeled tweets. One major contribution of this work is the creation of HSpam14 dataset, which can be used for hashtag-oriented spam research in tweets. Another contribution is the observations made from the preliminary analysis of the HSpam14 dataset.", "references": ["F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detecting spammers on twitter. In CEAS, 2010.", "F. Benevenuto, T. Rodrigues, V. Almeida, J. Almeida, and M. Gonçalves. Detecting spammers and content promoters in online video social networks. In SIGIR, pages 620--627, 2009.", "A. Broder. On the resemblance and containment of documents. In Proc. Compression and Complexity of Sequences, pages 21--29, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767701"}, {"title": "Non-volatile Storage", "authors": ["Mihir Nanavati\n,", "Malte Schwarzkopf\n,", "Jake Wires\n,", "Andrew Warfield"], "publication": "Queue", "abstract": "Abstract\nImplications of the Datacenter's Shifting Center", "references": ["Belay, A., Prekas, G., Klimovic, A., Grossman, S., Kozyrakis, C., Bugnion, E. 2014. IX: A protected dataplane operating system for high throughput and low latency. In Proceedings of the 11th USENIX Symposium", "Bjørling, M., Axboe, J., Nellans, D., Bonnet, P. 2013, Linux block IO: introducing multi-queue SSD access on multi-core systems. In Proceedings of the 6th International Systems and Storage Conference (SYSTOR).", "Bryant R. E., O'Hallaron, D. R. 2003. Computer systems: a programmer's perspective, volume 2. Prentice Hall, Englewood Cliffs, NJ"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857274.2874238"}, {"title": "Bringing Order to the Job Market: Efficient Job Offer Categorization in E-Recruitment", "authors": ["Emmanuel Malherbe\n,", "Mario Cataldi\n,", "Andrea Ballatore"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nE-recruitment uses a range of web-based technologies to find, evaluate, and hire new personnel for organizations. A crucial challenge in this arena lies in the categorization of job offers: candidates and operators often explore and analyze large numbers of offers and profiles through a set of job categories. To date, recruitment organizations define job categories top-down, relying on standardized vocabularies that often fail to capture new skills and requirements that emerge from dynamic labor markets. In order to support e-recruitment, this paper presents a dynamic, bottom-up method to automatically enrich and revise job categories. The method detects novel, highly characterizing terms in a corpus of job offers, leading to a more effective categorization, and is evaluated on real-world data by Multiposting (http://www.multiposting.fr/en), a large French e-recruitment firm.", "references": ["R. Boselli, M. Cesarini, F. Mercorio, and M. Mezzanzanica. How the Social Media Contributes to the Recruitment Process? In A. Rospigliosi and S. Greener, editors, Proceedings of European Conference on Social Media (ECSM), pages 10--11, Brighton, UK, 2014.", "E. T. Cornelius, T. J. Carron, and M. N. Collins. Job analysis models and job classification. Personnel Psychology, 32 (4): 693--708, 1979.", "E. C. Dierdorff, J. J. Norton, C. M. Gregory, D. Rivkin, and P. M. Lewis. O*NET's National Perspective on the Greening of the World of Work. In A. H. Huffman and S. R. Klein, editors, Driving Change with I-O Psychology, pages 348--378. Routledge, New York, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776779"}, {"title": "Semantic-aware Hashing for Social Image Retrieval", "authors": ["Jinhui Tang\n,", "Zechao Li\n,", "Liyan Zhang\n,", "Qingming Huang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWith the proliferation of large-scale social images, recent years have witnessed the increasing amount of images with user-provided tags, which leads to considerable effort made on hashing based approximate nearest neighbor (ANN) search in huge databases. In this work, we propose a novel Semantic-aware Hashing method (SaH) by discovering knowledge from these social media resources to implement approximate similarity search. Different from the previous work, the proposed method learns semantic hashing codes by exploiting heterogeneous information from the textual and visual domains. The semantic structure in the textual domain is well preserved to learn the binary codes. To handle the noisy, incomplete, or subjective user-provided tags, the visual structure is also leveraged. On the other hand, an information theoretic regularization is exploited by using maximum entropy principle and a row-wise sparse model with l2,p (0 < p ≤ 1) mixed norm is introduced to filter certain noisy or redundant visual features. Experiments are conducted on a widely-used social image dataset and the comparison results demonstrate the outperforming performance of the proposed SaH method over state-of-the-art hashing techniques.", "references": ["A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In Proc. VLDB, 1999.", "Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Proc. NIPS, 2008.", "J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for large scale search. IEEE TPAMI, 34(12):2393--2406, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749307"}, {"title": "A study of query reformulation for patent prior art search with partial patent applications", "authors": ["Mohamed Reda Bouadjenek\n,", "Scott Sanner\n,", "Gabriela Ferraro"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nPatents are used by legal entities to legally protect their inventions and represent a multi-billion dollar industry of licensing and litigation. In 2014, 326,033 patent applications were approved in the US alone -- a number that has doubled in the past 15 years and which makes prior art search a daunting, but necessary task in the patent application process. In this work, we seek to investigate the efficacy of prior art search strategies from the perspective of the inventor who wishes to assess the patentability of their ideas prior to writing a full application. While much of the literature inspired by the evaluation framework of the CLEF-IP competition has aimed to assist patent examiners in assessing prior art for complete patent applications, less of this work has focused on patent search with queries representing partial applications. In the (partial) patent search setting, a query is often much longer than in other standard IR tasks, e.g., the description section may contain hundreds or even thousands of words. While the length of such queries may suggest query reduction strategies to remove irrelevant terms, intentional obfuscation and general language used in patents suggests that it may help to expand queries with additionally relevant terms. To assess the trade-offs among all of these pre-application prior art search strategies, we comparatively evaluate a variety of partial application search and query reformulation methods. Among numerous findings, querying with a full description, perhaps in conjunction with generic (non-patent specific) query reduction methods, is recommended for best performance. However, we also find that querying with an abstract represents the best trade-off in terms of writing effort vs. retrieval efficacy (i.e., querying with the description sections only lead to marginal improvements) and that for such relatively short queries, generic query expansion methods help.", "references": ["R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., 2 edition, 2010.", "S. Bashir and A. Rauber. Improving retrievability of patents in prior-art search. In ECIR, pages 457--470. Springer Berlin Heidelberg, 2010.", "J. Carbonell and J. Goldstein. The Use of MMR, Diversity-based Reranking for Reordering Documents and Producing Summaries. In SIGIR, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746092"}, {"title": "Expert-Guided Contrastive Opinion Summarization for Controversial Issues", "authors": ["Jinlong Guo\n,", "Yujie Lu\n,", "Tatsunori Mori\n,", "Catherine Blake"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper presents a new model for the task of contrastive opinion summarization (COS) particularly for controversial issues. Traditional COS methods, which mainly rely on sentence similarity measures are not sufficient for a complex controversial issue. We therefore propose an Expert-Guided Contrastive Opinion Summarization (ECOS) model. Compared to previous methods, our model can (1) integrate expert opinions with ordinary opinions from social media and (2) better align the contrastive arguments under the guidance of expert prior opinion. We create a new data set about a complex social issue with \"sufficient\" controversy and experimental results on this data show that the proposed model are effective for (1) producing better arguments summary in understanding a controversial issue and (2) generating contrastive sentence pairs.", "references": ["Fang, Y., Si, L., Somasundaram, N., & Yu, Z. (2012, February). Mining contrastive opinions on political texts using cross-perspective topic model. In Proceedings of the fifth ACM international conference on Web search and data mining (pp. 63--72). ACM.", "Gao, H., Mahmud, J., Chen, J., Nichols, J., & Zhou, M. (2014). Modeling User Attitude toward Controversial Topics in Online Social Media. In the Eighth International AAAI Conference on Weblogs and Social Media (ICWSM 2014).", "Ganesan, K., Zhai, C., & Viegas, E. (2012, April). Micropinion generation: an unsupervised approach to generating ultra-concise summaries of opinions. In Proceedings of the 21st international conference on World Wide Web (pp.869--878). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743038"}, {"title": "Evolution Model of Adolescent Friendship Networks and BMI", "authors": ["Hsieh-Hua Yang\n,", "Chyi-In Wu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe objective is constructing a longitudinal network model of adolescent friendship networks and BMI. The participants were from 3 classes. There were 49 boys in class I, 47 girls in class II, and 15 boys and 31 girls in class III. Panel data was collected during 2 semesters from Sep. 2008 to Jul. 2009. Sociometric data were collected 7 times by having each student nominate up to 16 intimate classmates. BMI was calculated from self-reported height and weight. The program SIENA was applied to estimate the models. The result showed that the evolution of friendship networks was different between the same-gender and mixed-gender classes and BMI had effect on the evolution of friendship networks. Implication is discussed.", "references": ["Christakis, N. A., and Fowler, J. H. 2007. The Spread of obesity in a large social network over 32 Years. N. Engl. J. Med. 357, 370--379. DOI=http://www.nejm.org/doi/full/10.1056/NEJMsa066082.", "Cohen-Cole, E., and Fletcher, J. M. 2008. Is obesity contagious? Social networks vs. environmental factors in the obesity epidemic. J. Health Econ. 27, 1382--1387. DOI=10.1016/j.jhealeco.2008.04.005.", "Loh, C.-P. A., and Li, Q. 2013. Peer effects in adolescent bodyweight: Evidence from rural China. Soc. Sci. Med. 86, 35--44. DOI= 10.1016/j.socscimed.2013.02.042."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818917"}, {"title": "A novel approach for approximate aggregations over arrays", "authors": ["Yi Wang\n,", "Yu Su\n,", "Gagan Agrawal"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nApproximate aggregation has been a popular approach for interactive data analysis and decision making, especially on large-scale datasets. While there is clearly a need to apply this approach for scientific datasets comprising massive arrays, existing algorithms have largely been developed for relational data, and cannot handle both dimension-based and value-based predicates efficiently while maintaining accuracy. In this paper, we present a novel approach for approximate aggregations over array data, using bitmap indices or bitvectors as the summary structure, as they preserve both spatial and value distribution of the data. We develop approximate aggregation algorithms using only the bitvectors and certain additional pre-aggregation statistics (equivalent to a 1-dimensional histogram) that we require. Another key development is choosing a binning strategy that can improve aggregation accuracy -- we introduce a v-optimized binning strategy and its weighted extension, and present a bitmap construction algorithm with such binning. We compare our method with other existing methods including sampling and multi-dimensional histograms, as well as the use of other binning strategies with bitmaps. We demonstrate both high accuracy and efficiency of our approach. Specifically, we show that in most cases, our method is more accurate than other methods by at least one order of magnitude. Despite achieving much higher accuracy, our method can require significantly less storage than multi-dimensional histograms.", "references": ["ACOS. http://mirador.gsfc.nasa.gov/cgibin/mirador/presentNavigation.pl?tree=project&project=ACOS.", "G. Antoshenkov. Byte-aligned bitmap compression. In DCC, page 476. IEEE, 1995.", "B. Babcock, S. Chaudhuri, and G. Das. Dynamic sample selection for approximate query processing. In SIGMOD, pages 539--550. ACM, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791349"}, {"title": "Using Key Concepts in a Translation Model for Retrieval", "authors": ["Jae Hyun Park\n,", "W. Bruce Croft"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany queries, especially those in the form of longer questions, contain a subset of terms representing key concepts that describe the most important part of the user's information need. Detecting the key concepts in a query can be used as the basis for more effective weighting of query terms, but in this paper, we focus on a method of using the key concepts in a translation model for query expansion and retrieval. Translation models have been used previously in community-based question answering (CQA) systems in order to bridge the semantic gap between questions and the corresponding answer documents. Our method uses the key concepts of a question as the translation context and selectively applies the translation model to the secondary (non-key) parts of the question. We evaluate the proposed method using a CQA collection and show that selectively translating key and secondary concepts can significantly improve the retrieval performance compared to a baseline that applies the translation model without considering key concepts.", "references": ["M. Bendersky and W. B. Croft. Discovering key concepts in verbose queries. In Proceedings of the ACM SIGIR conference, pages 491--498. ACM, 2008.", "A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. Bridging the lexical chasm: statistical approaches to answer-finding. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 192--199. ACM, 2000.", "M. Ciaramita and Y. Altun. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In Proceedings of EMNLP, pages 594--602, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767768"}, {"title": "SuperMalloc: a super fast multithreaded malloc for 64-bit machines", "authors": ["Bradley C. Kuszmaul"], "publication": "ISMM '15: Proceedings of the 2015 International Symposium on Memory Management", "abstract": "ABSTRACT\nSuperMalloc is an implementation of malloc(3) originally designed for X86 Hardware Transactional Memory (HTM)@. It turns out that the same design decisions also make it fast even without HTM@. For the malloc-test benchmark, which is one of the most difficult workloads for an allocator, with one thread SuperMalloc is about 2.1 times faster than the best of DLmalloc, JEmalloc, Hoard, and TBBmalloc; with 8 threads and HTM, SuperMalloc is 2.75 times faster; and on 32 threads without HTM SuperMalloc is 3.4 times faster. SuperMalloc generally compares favorably with the other allocators on speed, scalability, speed variance, memory footprint, and code size. SuperMalloc achieves these performance advantages using less than half as much code as the alternatives. SuperMalloc exploits the fact that although physical memory is always precious, virtual address space on a 64-bit machine is relatively cheap. It allocates 2 chunks which contain objects all the same size. To translate chunk numbers to chunk metadata, SuperMalloc uses a simple array (most of which is uncommitted to physical memory). SuperMalloc takes care to avoid associativity conflicts in the cache: most of the size classes are a prime number of cache lines, and nonaligned huge accesses are randomly aligned within a page. Objects are allocated from the fullest non-full page in the appropriate size class. For each size class, SuperMalloc employs a 10-object per-thread cache, a per-CPU cache that holds about a level-2-cache worth of objects per size class, and a global cache that is organized to allow the movement of many objects between a per-CPU cache and the global cache using $O(1)$ instructions. SuperMalloc prefetches everything it can before starting a critical section, which makes the critical sections run fast, and for HTM improves the odds that the transaction will commit.", "references": ["Y. Afek, D. Dice, and A. Morrison. Cache index-aware memory allocation. In Proceedings International Symposium on Memory Managment (ISMM), pages 55–64, San Jose, California, June 2011. doi:10.1145/2076022.1993486.", "A. Alexandrescu and E. Berger. Policy-based memory allocation. Dr. Dobb’s, Dec. 1 2005. http://www.drdobbs.com/184402039. Viewed Apr. 27, 2015.", "K. Aziz. Pre-emption control for userspace, Mar. 3 2014. http://lkml.iu.edu/hypermail/linux/ kernel/1403.0/00780.html. Viewed Apr. 27, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2754169.2754178"}, {"title": "Total recall: holistic metrics for broad systems performance and user experience visibility in a data-intensive computing environment", "authors": ["Erich Birngruber\n,", "Petar Forai\n,", "Aaron Zauner"], "publication": "HUST '15: Proceedings of the Second International Workshop on HPC User Support Tools", "abstract": "ABSTRACT\nUser support personnel, systems engineers, and administrators of HPC installations need to be aware of log and telemetry information from different systems in order to perform routine tasks ranging from systems management to user inquiries. We present an integrated, distributed HPC tailored monitoring system, based on a current generation software stack from the DevOps community, with integration into the work load management system. The goal of this system is to provide a quicker turnaround time for user inquiries in response to errors. Dashboards provide an overlay of system and node level events on top of correlated metrics data. This information is directly available for querying, manipulation, and filtering, allowing statistical analysis and aggregation of collected data. Furthermore, additional dashboards offer in-sight into how users are interacting with available resources and pin-point fluctuations in utilization. The system can integrate sources of information from other monitoring solutions and event-based sources.", "references": ["S. Bagnasco, D. Berzano, A. Guarise, S. Lusso, M. Masera, and S. Vallero. Monitoring of iaas and scientific applications on the cloud using the elasticsearch ecosystem. In Journal of Physics: Conference Series, volume 608, page 012016. IOP Publishing, 2015.", "E. G. Boman, K. Madduri, S. Rajamanickam, and M. M. Wolf. High-performance computing for extreme-scale data analytics.", "J. Brandt, F. Chen, A. Gentile, J. Mayo, P. Pebay, D. Roe, N. Taerat, D. Thompson, M. Wong, et al. Framework for enabling system understanding. In Euro-Par 2011: Parallel Processing Workshops, pages 231--240. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834996.2835001"}, {"title": "Performance Evaluation MySQL InnoDB and Microsoft SQL Server 2012 for Decision Support Environments", "authors": ["Rafael Almeida\n,", "Pedro Furtado\n,", "Jorge Bernardino"], "publication": "C3S2E '15: Proceedings of the Eighth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nTraditional data analysis systems are driving radical changes to perform any kind of analysis on large volumes of data. The decision support systems are increasingly used in management of industrial enterprises, public sector and scientific community. In this paper we study the performance and suitability of two relational database engines for Decision Support Systems environments. The two engines are MySQL InnoDB and Microsoft SQL Server 2012. In the experiments we use Star Schema Benchmark (SSB), with a variety of datasets sizes. Microsoft SQL Server 2012 shows a quite acceptable behaviour while MySQL InnoDB achieves results below the expected for large datasets. These experiments allow us to assess the performance and suitability, of the studied engines, for small and medium size Decision Support environments.", "references": ["Actian VectorWise, http://www.actian.com/products/vectorwise, accessed 13 May 2014.", "Adam Jorgensen et al., Microsoft SQL Server 2012 bible, John Wiley, 2012.", "ExaSolution, http://www.exasol.com, accessed 13 May 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790798.2790808"}, {"title": "Report on the First Workshop on Supporting Complex Search Tasks", "authors": ["Maria Gäde\n,", "Mark M. Hall\n,", "Hugo Huurdeman\n,", "Jaap Kamps\n,", "Marijn Koolen\n,", "Mette Skove\n,", "Elaine Toms\n,", "David Walsh"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nThere is broad consensus in the field of IR that search is complex in many use cases and applications, both on theWeb and in domain specific collections, and both in our professional and in our daily life. Yet our understanding of complex search tasks, in comparison to simple look up tasks, is fragmented at best. The workshop addressed many open research questions: What are the obvious use cases and applications of complex search? What are essential features of work tasks and search tasks to take into account? And how do these evolve over time? With a multitude of information, varying from introductory to specialized, and from authoritative to speculative or opinionated, when to show what sources of information? How does the information seeking process evolve and what are relevant differences between different stages? With complex task and search process management, blending searching, browsing, and recommendations, and supporting exploratory search to sensemaking and analytics, UI and UX design pose an overconstrained challenge. How do we know that our approach is any good? Supporting complex search tasks requires new collaborations across the whole field of IR, and the proposed workshop brought together a diverse group of researchers to work together on one of the greatest challenges of our field.\nThe workshop featured three main elements. First, a keynote on an emerging theory of task difficulty by Diane Kelly. Second, a lively boaster and poster session in which seven contributed papers were presented. Third, three breakout groups on: 1) user interfaces and user experience, 2) tasks and users, and 3) information needs on controversial topics. There was an general feeling that the discussion made progress, and built new connections between related strands of research in IR.", "references": ["K. Balog. Task-completion Engines: A Vision with a Plan. In Gäde et al. {4}. URL http://ceur-ws.org/Vol-1338.", "A. Dean-Hall, C. Clarke, J. Kamps, and J. Kiseleva. Online evaluation of point-of-interest recommendation systems. In Gäde et al. {4}. URL http://ceur-ws.org/Vol-1338.", "S. Dori-Hacohen, E. Yom-Tov, and J. Allan. Navigating Controversy as a Complex Search Task. In Gäde et al. {4}. URL http://ceur-ws.org/Vol-1338."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795415"}, {"title": "The general model of secure computation system", "authors": ["Ludmila Babenko\n,", "Philipp Burtyka\n,", "Oleg Makarevich\n,", "Alina Trepacheva"], "publication": "SIN '15: Proceedings of the 8th International Conference on Security of Information and Networks", "abstract": "ABSTRACT\nThe paper considers the problem of organization the computations over encrypted data. This problem has become increasingly important due to the expansion of the cloud computing and the need for suitable measures to protect it. Different primitives were proposed to solve the problem in a limited context, such as garbled circuits, fully homomorphic encryption, functional encryption, secure multiparty computations and so on. However, the development of real secure computing system requires some general theory for organization of secure computing, using a systemic approach. We propose to divide all the functionality that the secure computing system must support into the several layers; the interaction between them would be done through the interfaces. Presented six-layer analytical model under the title \"Secure computing interface stack\" (\"SCIS\") is intended to standardize and facilitate the work of researchers and developers in the field of cryptographically secure computing, i.e. such systems in which the untrusted parties process the sensitive data in encrypted form without decrypting at the any stage of processing.\nFor each layer we outline the problems researchers deal with, reveal a range of issues that must be addressed, and provide a brief overview of the relative works. We survey and compare known secure computation systems analyzing them within our model and derive some new ideas for improvements of existing CSCS.", "references": ["G. Abozaid, A. El-Mahdy, and Y. Wada. A scalable multiplier for arbitrary large numbers supporting homomorphic encryption. In Digital System Design (DSD), 2013 Euromicro Conference on, pages 969--975. IEEE, 2013.", "J. R. Allen, K. Kennedy, C. Porterfield, and J. Warren. Conversion of control dependence to data dependence. In Proceedings of the 10th ACM SIGACT-SIGPLAN symposium on Principles of programming languages, pages 177--189. ACM, 1983.", "U. Banerjee. Dependence analysis, volume 3. Springer Science & Business Media, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2799979.2800006"}, {"title": "Listwise Collaborative Filtering", "authors": ["Shanshan Huang\n,", "Shuaiqiang Wang\n,", "Tie-Yan Liu\n,", "Jun Ma\n,", "Zhumin Chen\n,", "Jari Veijalainen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecently, ranking-oriented collaborative filtering (CF) algorithms have achieved great success in recommender systems. They obtained state-of-the-art performances by estimating a preference ranking of items for each user rather than estimating the absolute ratings on unrated items (as conventional rating-oriented CF algorithms do). In this paper, we propose a new ranking-oriented CF algorithm, called ListCF. Following the memory-based CF framework, ListCF directly predicts a total order of items for each user based on similar users' probability distributions over permutations of the items, and thus differs from previous ranking-oriented memory-based CF algorithms that focus on predicting the pairwise preferences between items. One important advantage of ListCF lies in its ability of reducing the computational complexity of the training and prediction procedures while achieving the same or better ranking performances as compared to previous ranking-oriented memory-based CF algorithms. Extensive experiments on three benchmark datasets against several state-of-the-art baselines demonstrate the effectiveness of our proposal.", "references": ["J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In UAI, pages 43--52, 1998.", "R. Burke. Hybrid recommender systems: Survey and experiments. User Model. User-Adap. Inter., 12:331--370, 2002.", "Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: From pairwise approach to listwise approach. In ICML, pages 129--136, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767693"}, {"title": "Predicting Pinterest: Organising the World's Images with Human-machine Collaboration", "authors": ["Nishanth Sastry"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe user generated content revolution has created a glut of multimedia content online -- from Flickr to Facebook, new images are being made available for public consumption everyday. In this talk, we will first explore how, on sites such as Pinterest, users are bringing order to this burgeoning collection by manually curating collections of images in ways that are highly personalised and relevant to their own use. We will then discuss the phenomenon of social bootstrapping, whereby existing mature social networks such as Facebook are helping bootstrap engaged communities of content curators on external sites such as Pinterest. Finally, we will demonstrate how the manual effort involved in curation can be amplified using a unique human-machine collaboration: By treating the curation efforts of a subset of users on Pinterest as a distributed human computation over a low-dimensional approximation of the content corpus, we derive simple yet powerful signals, which, when combined with image-related features drawn from state-of-the-art deep learning techniques, allow us to automatically and accurately populate the personalised curated collections of all other users.", "references": ["Cappelletti, R., and Sastry, N. IARank: Ranking users on Twitter in near real-time, based on their information amplification potential. In Proceedings of The 2012 ASE International Conference on Social Informatics (Washington D.C., USA., 2012).", "Sastry, N. How to tell head from tail in user-generated content corpora. In Proceedings of The 6th International AAAI Conference on Weblogs and Social Media (ICWSM) (Dublin, Ireland, June 2012).", "Sastry, N. Crowdsourcing and social networks. In Encyclopedia of Social Network Analysis and Mining. Springer-Verlag, 2014, pp. 316--318."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744719"}, {"title": "Insider Threats: Identifying Anomalous Human Behaviour in Heterogeneous Systems Using Beneficial Intelligent Software (Ben-ware)", "authors": ["Andrew Stephen McGough\n,", "David Wall\n,", "John Brennan\n,", "Georgios Theodoropoulos\n,", "Ed Ruck-Keene\n,", "Budi Arief\n,", "Carl Gamble\n,", "John Fitzgerald\n,"], "publication": "MIST '15: Proceedings of the 7th ACM CCS International Workshop on Managing Insider Security Threats", "abstract": "ABSTRACT\nIn this paper, we present the concept of \"Ben-ware\" as a beneficial software system capable of identifying anomalous human behaviour within a 'closed' organisation's IT infrastructure. We note that this behaviour may be malicious (for example, an employee is seeking to act against the best interest of the organisation by stealing confidential information) or benign (for example, an employee is applying some workaround to complete their job). To help distinguish between users who are intentionally malicious and those who are benign, we use human behaviour modelling along with Artificial Intelligence. Ben-ware has been developed as a distributed system comprising of probes for data collection, intermediate nodes for data routing and higher nodes for data analysis. This allows for real-time analysis with low impact on the overall infrastructure, which may contain legacy and low-power resources. We present an analysis of the appropriateness of the Ben-ware system for deployment within a large closed organisation, comprising of both new and legacy hardware, to protect its essential information. This analysis is performed in terms of the memory footprint, disk footprint and processing requirements of the different parts of the system.", "references": ["B. Aleman-Meza, P. Burns, M. Eavenson, D. Palaniswami, and A. Sheth. An ontological approach to the document access problem of insider threat. In P. Kantor, G. Muresan, F. Roberts, D. Zeng, F.-Y. Wang, H. Chen, and R. Merkle, editors, Intelligence and Security Informatics, volume 3495 of LNCS, pages 486--491. 2005.", "M. Bishop and C. Gates. Defining the insider threat. In Proceedings of the 4th Annual Workshop on Cyber Security and Information Intelligence Research: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead, CSIIRW '08, pages 15:1--15:3, New York, NY, USA, 2008.", "B. Bowen, M. Ben Salem, S. Hershkop, A. Keromytis, and S. Stolfo. Designing host and network sensors to mitigate the insider threat. Security Privacy, IEEE, 7(6):22--29, Nov 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808783.2808785"}, {"title": "On Predicting Deletions of Microblog Posts", "authors": ["Mossaab Bagdouri\n,", "Douglas W. Oard"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAmong the many classification tasks on Twitter content, predicting whether a tweet will be deleted has to date received relatively little attention. Deletions occur for a variety of reasons, which can make the classification task challenging. Moreover, deletion prediction might serve different goals, the characteristics of which should be reflected in the evaluation design. This paper addresses the problem of deletion prediction by analyzing the distribution of deleted tweets, presenting a new evaluation framework, exploring tweet-based and user-based features, and reporting prediction scores.", "references": ["D. Bamman et al. Censorship and deletion practices in Chinese social media. First Monday, 17(3), 2012.", "J. Bollen et al. Twitter mood predicts the stock market. J. of Comp. Science, 2(1):1--8, 2011.", "I. Guyon, J. Weston, S. Barnhill, and V. Vapnik. Gene selection for cancer classification using support vector machines. Machine Learning, 46(1--3):389--422, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806600"}, {"title": "Big picture of big data software engineering: with example research challenges", "authors": ["Nazim H. Madhavji\n,", "Andriy Miranskyy\n,", "Kostas Kontogiannis"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nIn the rapidly growing field of Big Data, we note that a disproportionately larger amount of effort is being invested in infrastructure development and data analytics in comparison to applications software development -- approximately a 80:20 ratio. This prompted us to create a context model of Big Data Software Engineering (BDSE) containing various elements --- such as development practice, Big Data systems, corporate decision-making, and research --- and their relationships. The model puts into perspective where various types of stakeholders fit in. From the research perspective, we describe example challenges in BDSE, specifically requirements, architectures, and testing and maintenance.", "references": ["D. Vesset, et al., \"Worldwide Big Data Technology and Services 2013--2017 Forecast,\" IDC Market Analysis, 244979, Dec. 2013.", "\"Apache Mahout\", https://mahout.apache.org/.", "\"0xdata, H2O\", http://0xdata.com."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819294"}, {"title": "People News Search via Name-Face Association Analysis", "authors": ["Yong Cheng\n,", "Zhixin Liu\n,", "Yun Zhao\n,", "Cheng Jin\n,", "Yuejie Zhang\n,", "Tao Zhang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nBy integrating multimodal information in multimodal news, a novel scheme is developed in this paper for facilitating more effective people news search via name-face association analysis. It is treated as a problem of bi-media multimodal semantic mapping on multimodal news, and modeled as an inter-related correlation distribution over multimodal semantic representations of name-face associations. Very positive results have been obtained in our experiments using a large quantity of public multimodal news data.", "references": ["Liu, C., Jiang, S., and Huang, Q. 2008. Naming Faces in Broadcast News Video by Image Google. In Proceedings of MM 2008, 717--720.", "Fan, J. P., He, X. F., Zhou, N., Peng, J. Y., and Jain, R. 2012. Quantitative Characterization of Semantic Gaps for Learning Complexity Estimation and Inference Model Selection. IEEE Transactions on Multimedia, 14(5):1414--1428.", "McCreadie, R., Macdonald, C., and Ounis, I. 2013. News Vertical Search: When and What to Display to Users. In Proceedings of SIGIR 2013, 253--262."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749301"}, {"title": "Diagnoses, Decisions, and Outcomes: Web Search as Decision Support for Cancer", "authors": ["Michael J. Paul\n,", "Ryen W. White\n,", "Eric Horvitz"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nPeople diagnosed with a serious illness often turn to the Web for their rising information needs, especially when decisions are required. We analyze the search and browsing behavior of searchers who show a surge of interest in prostate cancer. Prostate cancer is the most common serious cancer in men and is a leading cause of cancer-related death. Diagnoses of prostate cancer typically involve reflection and decision making about treatment based on assessments of preferences and outcomes. We annotated timelines of treatment-related queries from nearly 300 searchers with tags indicating different phases of treatment, including decision making, preparation, and recovery. Using this corpus, we present a variety of analyses toward the goal of understanding search and decision making about treatments. We characterize search queries and the content of accessed pages for different treatment phases, model search behavior during the decision-making phase, and create an aggregate alignment of treatment timelines illustrated with a variety of visualizations. The experiments provide insights about how people who are engaged in intensive searches about prostate cancer over an extended period of time pursue and access information from the Web.", "references": ["S. L. Ayers and J. J. Kronenfeld. Chronic illness and health-seeking information on the internet. Health, 11(3), 2007.", "J. Bader and M. Theofanos. Searching for cancer information on the internet: Analyzing natural language search queries. JMIR, 5(4), 2003.", "E. V. Bernstam, J. R. Herskovic, and W. R. Hersh. Query log analysis in biomedicine. 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741662"}, {"title": "Using the crowd to boost video annotation processes: a game based approach", "authors": ["José Pedro Pinto\n,", "Paula Viana"], "publication": "CVMP '15: Proceedings of the 12th European Conference on Visual Media Production", "abstract": "ABSTRACT\nThis short paper presents a game for collecting metadata to describe video content. Tags, introduced by registered players on a given timecode of the video, are collected and validated based on a collaborative scoring mechanism that excludes erratic annotations. The system follows a gamification approach for motivating users and includes processes for semantically relating concepts.", "references": ["Pinto, J. P. and Viana, P. 2013. TAG4VD: a game for collaborative video annotation. In Proceedings of the 21st ACM International Conference on Multimedia, 25--28. http://doi.acm.org/10.1145/2512142.251"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2824840.2824853"}, {"title": "An Unsupervised Method for Ontology Population from Textual Sources on the Web", "authors": ["Fabio Lima\n,", "Hilario Oliveira\n,", "Lais Salvador"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe increasing in the production and availability of unstructured information on the Web grows daily. This abundance of unstructured information is a great challenge for acquisition of structured knowledge. Many approaches have been proposed for extracting information from texts written in natural language. However, only a few studies have investigated the extraction of information from texts written in Portuguese. Thus, this work aims to propose and evaluate an unsupervised method for ontology population using the Web as a big source of information in the context of the Portuguese language. The results of the experiments are encouraging and demonstrated that the proposed approach reached a precision rate of 67% in the instances of ontological classes extraction.", "references": ["C. G. d. F. Alves. Um Processo Independente de Domínio para o Povoamento Automático de Ontologias a partir de Fontes Textuais. 2013.", "T. L. Baségio. Uma Abordagem Semi-automática para Identificação de Estruturas Ontológicas a partir de Textos na Língua Portuguesa do Brasil. pages 1-124, 2007.", "A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. Hruschka, and T. M. Mitchell. Toward an architecture for never-ending language learning. In In AAAI, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814121"}, {"title": "Accelerating Large-scale Image Retrieval on Heterogeneous Architectures with Spark", "authors": ["Hanli Wang\n,", "Bo Xiao\n,", "Lei Wang\n,", "Jun Wu"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nApache Spark is a general-purpose cluster computing system for big data processing and has drawn much attention recently from several fields, such as pattern recognition, machine learning and so on. Unlike MapReduce, Spark is especially suitable for iterative and interactive computations. With the computing power of Spark, a utility library, referred to as IRlib, is proposed in this work to accelerate large-scale image retrieval applications by jointly harnessing the power of GPU. Similar to the built-in machine learning library of Spark, namely MLlib, IRlib fits into the Spark APIs and benefits from the powerful functionalities of Spark. The main contributions of IRlib lie in two-folds. First, IRlib provides a uniform set of APIs for the programming of image retrieval applications. Second, the computational performance of Spark equipped with multiple GPUs is dramatically boosted by developing high performance modules for common image retrieval related algorithms. Comparative experiments concerning large-scale image retrieval are carried out to demonstrate the significant performance improvement achieved by IRlib as compared with single CPU thread implementation as well as Spark without GPUs employed.", "references": ["J. Sivic and A. Zisserman. Video google: A text retrieval approach to object matching in videos. ICCV'03, pages 1470--1477, Oct. 2003.", "J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. Comm. of the ACM - 50th anniversary issue: 1958--2008, 51(1):107--113, Jan. 2008.", "B. White, T. Yeh, J. Lin, and L. Davis. Web-scale computer vision using MapReduce for multimedia data mining. In MDMKDD'10, pages 1--10, Jul. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806392"}, {"title": "Automatic Generation of Templates using Ontology", "authors": ["S. Thenmalar\n,", "T. V. Geetha"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nGenerally, Information Extraction (IE) methods use predefined templates to determine the slot fillers to obtain relevant information. The slots define the important information necessary for the particular template. However, effective of the information is decided by the predefined template. In this paper, we mine the templates from a domain corpus to act as the predefined templates for IE. We automatically generate the templates using domain ontology for identifying the slots of the template. The performance of the proposed work is compared with the existing automatic template generation system and evaluated based on the precision metric. The automatic generation of templates using ontology produces the precision of 0.82.", "references": ["Lei Shi, Shuming Shi, Chin-Yew Lin, Yi-Dong Shen and Yong Rui, 2014, \"Unsupervised Template Mining for Semantic Category Understanding\", In Proceedings of the EMNLP 2014, Doha, Qatar, October 26--28.", "Roman Yangarber. 2003. Counter-training in discovery of semantic patterns. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 343--350.", "Satoshi Kamegai, Kenji Satou and Akihiko Konagaya, 2004, \"Automated Template Discovery for Information Extraction from Biomedical Literature\", International Conference on Cybernetics and Information Technologies, Systems and Applications"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791562"}, {"title": "Similarity search in fuzzy object databases", "authors": ["Diana Uskat\n,", "Tobias Emrich\n,", "Andreas Züfle\n,", "Klaus Arthur Schmid\n,", "Thomas Bernecker\n,", "Matthias Renz"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nFuzzy object databases are becoming more and more important in the context of image analysis. Examples include satellite images where blurred trees, houses or lakes can still be organized and searched in a meaningful manner and biomedical images which can be utilized to find similar disease patterns and monitor disease progress. One problem of the underlying data is that it contains blurred image content, i.e., fuzzy data. Therefore, an image-based similarity search, which can process huge amounts of fuzzy data in an efficient and effective way, is desirable. The aim of this work is to develop efficient and effective methods for similarity search in fuzzy object databases. First, a suitable similarity measure based on a shape similarity is proposed. Based on this, two novel k-nearest neighbor algorithms for efficient similarity search are presented. The first approach gains efficiency at the cost of incurring only approximate results, while the second approach uses a filter-refinement approach to prune computation. Our experimental evaluation shows the efficiency of the proposed algorithms.", "references": ["Altman, D.: Fuzzy set theoretic approaches for handling imprecision in spatial analysis. International Journal of Geographical Information Science 8(3), 271--289 (1994)", "Ankerst, M., Kastenmüller, G., Kriegel, H., Seidl, T.: 3d shape histograms for similarity search and classification in spatial databases. Advances in Spatial Databases 1651, 207--226 (1999)", "Bernecker, T., Emrich, T., Kriegel, H., Renz, M., Züfle, A.: Probabilistic ranking in fuzzy object databases. CIKM (2012)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791386"}, {"title": "Poster: User Location Fingerprinting at Scale", "authors": ["Puneet Jain\n,", "Justin Manweiler\n,", "Romit Roy Choudhury"], "publication": "MobiCom '15: Proceedings of the 21st Annual International Conference on Mobile Computing and Networking", "abstract": "ABSTRACT\nMany emerging mobile computing applications are continuous vision based. The primary challenge these applications face is computation partitioning between the phone and cloud. The indoor location information is one metadata that can help these applications in making this decision. In this extended-abstract, we propose a vision based scheme to uniquely fingerprint an environment which can in turn be used to identify user's location from the uploaded visual features. Our approach takes into account that the opportunity to identify location is fleeting and the phones are resource constrained -- therefore minimal yet sufficient computation needs to be performed to make the offloading decision. Our work aims to achieve near real-time performance while scaling to buildings of arbitrary sizes. The current work is in preliminary stages but holds promise for the future -- may apply to many applications in this area.", "references": ["Project tango. https://www.google.com/atap/projecttango/, 2014.", "R. Escriva, B. Wong, and E. G. Sirer. Hyperdex: A distributed, searchable key-value store. ACM SIGCOMM Computer Communication Review, 42(4):25--36, 2012.", "P. Jain, J. Manweiler, A. Acharya, and K. Beaty. Focus: clustering crowdsourced videos by line-of-sight. In SenSys, page 8. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789168.2795175"}, {"title": "A Link Prediction System in Social Networks", "authors": ["Luciano Antonio Digiampietri\n,", "William Takahiro Maruyama\n,", "Caio Rafael do Nascimento Santiago\n,", "Jamison Jose da Silva Lima"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe prediction of new relationships in a social network is a complex and extremely useful task to enhance or maximize collaborations by indicating what the most promising partnerships are. In academic social networks, prediction of relationships is typically used to try to identify potential partners in the development of a project and/or co-authors for publishing papers. This paper presents a system that combines artificial intelligence techniques with the state-of-the-art metrics for link prediction. The resulting system was tested using real data from Computer Science researchers and achieved a precision above 99.5% in the co-authorship prediction.", "references": ["I. Altintas, C. Berkley, E. Jaeger, M. Jones, B. Ludascher, and S. Mock. Kepler: An extensible system for design and execution of scientific workflows. In Proceedings of the 16th International Conference on Scientific and Statistical Database Management, pages 423-424, Washington, DC, USA, 2004.", "S. P. Callahan, J. Freire, E. Santos, C. E. Scheidegger, C. T. Silva, and H. T. Vo. Managing the evolution of dataflows with VisTrails. In Proceedings of the 22nd International Conference on Data Engineering Workshops, page 71, 2006.", "W. Cukierski, B. Hamner, and B. Yang. Graph-based features for supervised link prediction. In Neural Networks (IJCNN), The 2011 International Joint Conference on, pages 1237-1244, July 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814082"}, {"title": "CrowdSurf: Empowering Transparency in the Web", "authors": ["Hassan Metwalley\n,", "Stefano Traverso\n,", "Marco Mellia\n,", "Stanislav Miskovic\n,", "Mario Baldi"], "publication": "ACM SIGCOMM Computer Communication Review", "abstract": "Abstract\nIndividuals lack proper means to supervise the services they contact and the information they exchange when surfing the web. This security task has become challenging due to the complexity of the modern web, of the data delivering technology, and even to the adoption of encryption, which, while improving privacy, makes in-network services ineffective. The implications are serious, from a person contacting undesired services or unwillingly exposing private information, to a company being unable to control the flow of its information to the outside world. To empower transparency and the capability of taking informed choices in the web, we propose CROWDSURF, a system for comprehensive and collaborative auditing of data exchanged with Internet services. Similarly to crowdsourced efforts, we enable users to contribute in building awareness, supported by the semi-automatic analysis of data offered by a cloud-based system. The result is the creation of \"suggestions\" that individuals can transform in enforceable \"rules\" to customize their web browsing policy. CROWDSURF provides the core infrastructure to let individuals and enterprises regain visibility and control on their web activity. Preliminary results obtained executing a prototype implementation demonstrate the feasibility and potential of CROWDSURF.", "references": ["D. Naylor, A. Finamore, I. Leontiadis, Y. Grunenberger, M. Mellia, K. Papagiannaki, and P. Steenkiste, \"The Cost of the \"S\" in HTTPS,\" in ACM CoNEXT, 2014.", "G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, and C. Diaz, \"The Web Never Forgets: Persistent Tracking Mechanisms in the Wild,\" in ACM SIGSAC, 2014.", "B. Krishnamurthy, K. Naryshkin, and C. E. Wills, \"Privacy leakage vs. Protection measures: the growing disconnect,\" in W2SP, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2831347.2831349"}, {"title": "An evaluation of SimRank and Personalized PageRank to build a recommender system for the Web of Data", "authors": ["Phuong Nguyen\n,", "Paolo Tomeo\n,", "Tommaso Di Noia\n,", "Eugenio Di Sciascio"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe Web of Data is the natural evolution of the World Wide Web from a set of interlinked documents to a set of interlinked entities. It is a graph of information resources interconnected by semantic relations, thereby yielding the name Linked Data. The proliferation of Linked Data is for sure an opportunity to create a new family of data-intensive applications such as recommender systems. In particular, since content-based recommender systems base on the notion of similarity between items, the selection of the right graph-based similarity metric is of paramount importance to build an effective recommendation engine. In this paper, we review two existing metrics, SimRank and PageRank, and investigate their suitability and performance for computing similarity between resources in RDF graphs and investigate their usage to feed a content-based recommender system. Finally, we conduct experimental evaluations on a dataset for musical artists and bands recommendations thus comparing our results with two other content-based baselines measuring their performance with precision and recall, catalog coverage, items distribution and novelty metrics.", "references": ["G. Adomavicius and Y. Kwon. Improving aggregate recommendation diversity using ranking-based techniques. IEEE Trans. on Knowl. and Data Eng., 24(5):896--911, 2012.", "E. Agirre, M. Cuadros, G. Rigau, and A. Soroa. Exploring knowledge bases for similarity. In Proceedings of LREC'10, 2010.", "E. Agirre and A. Soroa. Personalizing pagerank for word sense disambiguation. In Proceedings of EACL '09, pages 33--41, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742141"}, {"title": "Language-independent Query Representation for IR Model Parameter Estimation on Unlabeled Collections", "authors": ["Parantapa Goswami\n,", "Massih-Reza Amini\n,", "Eric Gaussier"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nWe study here the problem of estimating the parameters of standard IR models (as BM25 or language models) on new collections without any relevance judgments, by using collections with already available relevance judgements. We propose different query representations that allow mapping queries (with and without relevance judgments, from different collections, potentially in different languages) into a common space. We then introduce a kernel regression approach to learn the parameters of standard IR models individually for each query in the new, unlabeled collection. Our experiments, conducted on standard English and Indian IR collections, show that our approach can be used to efficiently tune, query by query, standard IR models to new collections, potentially written in different languages. In particular, the versions of the standard IR models we obtain not only outperform the versions with default parameters, but can also outperform the versions in which the parameter values have been optimized globally over a set of queries with target relevance judgements.", "references": ["L. Bottou. Stochastic gradient tricks. In G. Montavon, G. B. Orr, and K.-R. Müller, editors, Neural Networks, Tricks of the Trade, Reloaded, Lecture Notes in Computer Science (LNCS 7700). Springer, 2012.", "P. Cai, W. Gao, A. Zhou, and K. Wong. Query weighting for ranking model adaptation. In Proceedings of the $49^th$ Annual Meeting of the Association for Computational Linguistics (ACL), New York, USA, 2011. ACM.", "B. Carterette. Robust test collections for retrieval evaluation. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809451"}, {"title": "Twitter democracy: policy versus identity politics in three emerging African democracies", "authors": ["Michael L. Best\n,", "Amanda Meng"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nSocial media offers new ways for citizens to discuss and debate politics and engage in the democratic process. These online systems could be places for rich policy relevant debate, which is favored by scholars of deliberative democracy. Alternatively, social media might be a platform for an identity driven form of political discourse that is routinely scorned by scholars of democracy. To examine these two possibilities, we analyzed tweets sent during three national elections, the defining participatory process of democracy. Our dataset includes over 760,000 tweets gathered during national elections in Nigeria, Ghana and Kenya from 2011 to 2013. In order to analyze the degree to which Twitter was being used for policy relevant discussion we developed policy term sets through a text analysis of the major political party platforms. To examine the amount of discourse focused on identity issues we created identity term sets based upon national religious, tribal, and regional differences. In Nigeria, where divisive identity politics feed violence and electoral misconduct, discussion of tribe, region, and religion dominate mentions of platform policies. In contrast Ghanaians, who enjoy the most robust democracy of the three countries, were seven times more likely to discuss policy issues rather than identity. Kenyan democracy is still undergoing consolidation, and tweets again reflect this, with almost as many tweets devoted to tribal identity as campaign policy. These findings suggest that social media discussions may echo the state of democratic deepening found in a country during its national elections.", "references": ["Abdulkadir, Alkasim. Twitter Post. March 16, 2011, 7:23 a.m. http://Twitter.com/alkayy", "Africa Practice. \"Nigeria: All eyes on 2015.\" February 20, 2014. http://www.africapractice.com/snap-shots/nigeria-election-watch-all-eyes-on-2015/", "Aldrich, JH. Why Parties? The Origin and Transformation of Political Parties in America. Chicago: The University of Chicago Press, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2738017"}, {"title": "A Fourier theory of the light field with the resolution of the sampling camera", "authors": ["Hong Zhang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn this paper, we study the problem of the light field sampling in image-based rendering (IBR). Using the spectral analysis of light field signal (LFS), the spectrum expression of the LFS with the resolution of the sampling camera is derived. In particular, the influence of the resolution of the sampling camera on the spectrum of the LFS is analyzed. In addition, we derive the relationship between the spectrum of the LFS and the resolution of the sampling camera. Based on the spectral analysis, we mathematically derive an analytical function to analyze the minimum resolution of the sampling camera. It can be applied in obtaining the best balance between the resolution setting of the sampling camera and the quality of the images reconstructed from the LFS.", "references": ["C. Zhang, and T. Chen. A survey on image-based rendering-representation, sampling and compression. EURASIP Signal Process., Image Commun., 19(1): 1--28, 2004.", "H.-Y. Shum, S. Kang, and S.-C. Chan. Survey of image-based representations and compression techniques. IEEE Trans. Circ. and Syst. for Video Tech., 13: 1020--1037, Nov. 2003.", "H.-Y. Shum, S. C. Chan, and S. B. Kang. Image-Based rendering. New York, NY, USA: Springer-Verlag, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808493"}, {"title": "A Unified Posterior Regularized Topic Model with Maximum Margin for Learning-to-Rank", "authors": ["Shoaib Jameel\n,", "Wai Lam\n,", "Steven Schockaert\n,", "Lidong Bing"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhile most methods for learning-to-rank documents only consider relevance scores as features, better results can often be obtained by taking into account the latent topic structure of the document collection. Existing approaches that consider latent topics follow a two-stage approach, in which topics are discovered in an unsupervised way, as usual, and then used as features for the learning-to-rank task. In contrast, we propose a learning-to-rank framework which integrates the supervised learning of a maximum margin classifier with the discovery of a suitable probabilistic topic model. In this way, the labelled data that is available for the learning-to-rank task can be exploited to identify the most appropriate topics. To this end, we use a unified constrained optimization framework, which can dynamically compute the latent topic similarity score between the query and the document. Our experimental results show a consistent improvement over the state-of-the-art learning-to-rank models.", "references": ["S. Agarwal and M. Collins. Maximum margin ranking algorithms for information retrieval. In ECIR, pages 332--343. 2010.", "J. Allan.uppercaseHARD track overview inuppercaseTREC 2003 high accuracy retrieval from documents. Technical report, DTIC Document, 2005.", "N. Asadi and J. Lin. Effectiveness/efficiency tradeoffs for candidate generation in multi-stage retrieval architectures. In SIGIR, pages 997--1000, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806482"}, {"title": "Convenient Discovery of Archived Video Using Audiovisual Hyperlinking", "authors": ["Roeland Ordelman\n,", "Robin Aly\n,", "Maria Eskevich\n,", "Benoit Huet\n,", "Gareth J.F. Jones"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nThis paper overviews ongoing work that aims to support end-users in conveniently exploring and exploiting large audiovisual archives by deploying multiple multimodal linking approaches. We present ongoing work on multimodal video hyperlinking, from a perspective of unconstrained link anchor identification and based on the identification of named entities, and recent attempts to implement and validate the concept of outside-in linking that relates current events to archive content. Although these concepts are not new, current work is revealing novel insights, more mature technology, development of benchmark evaluations and emergence of dedicated workshops which are opening many interesting research questions on various levels that require closer collaboration between research communities.", "references": ["R. Aly, K. McGuinness, M. Kleppe, R. Ordelman, N. E. O'Connor, and F. de Jong. Link anchors in images: Is there truth? In Proceedings of the 12th Dutch Belgian Information Retrieval Workshop (DIR 2012), pages 1--4, Ghent, 2012. University Ghent.", "R. Aly, R. Ordelman, M. Eskevich, G. J. F. Jones, and S. Chen. Linking inside a video collection - what and how to measure? In Proceedings of the 22nd International Conference on World Wide Web Companion, IW3C2 2013, Rio de Janeiro, Brazil, pages 457--460, Brazil, May 2013. ACM.", "E. Apostolidis, V. Mezaris, M. Sahuguet, B. Huet, B. Cervenková, D. Stein, S. Eickeler, J. L. Redondo Garcia, R. Troncy, and L. Pikora. Automatic fine-grained hyperlinking of videos within a closed collection using scene segmentation. In ACMMM 2014, 22nd ACM International Conference on Multimedia, Orlando, USA, 11 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814652"}, {"title": "Context-driven Dimensionality Reduction for Clustering Text Documents", "authors": ["Debasis Ganguly\n,", "Johannes Leveling\n,", "Gareth J. F. Jones"], "publication": "FIRE '15: Proceedings of the 7th Forum for Information Retrieval Evaluation", "abstract": "ABSTRACT\nWe investigate clustering documents based on automatically annotated potentially sensitive information extracted from a large collection of organizational data. The process of clustering in this particular use case is helpful to visualize and navigate through groups of documents with related content. However, the effectiveness and efficiency of document clustering is limited mainly due to the large dimensionality of the document vectors. To alleviate this problem we propose a dimensionality reduction approach which involves selecting terms with high tf-idf scores from the context of the automatically annotated sensitive regions of a document. Due to the unavailability of real organizational data for research purposes, we evaluate our approach on the standard 20 news-groups dataset. For evaluation purposes, the only sensitive information that we use from the documents of this dataset are the named entities, e.g. the names of persons and organizations. Experimental results show that our approach is able to achieve an almost perfect clustering with a purity value of 0.998 improving by 22.60% with respect to the purity value of 0.814 obtained without document dimensionality reduction.", "references": ["R. A. Baeza-Yates, C. A. Hurtado, M. Mendoza, and G. Dupret. Modeling user search behavior. In Third Latin American Web Congress (LA-Web 2005), 1 October - 2 November 2005, Buenos Aires, Argentina, pages 242--251, 2005.", "M. N. K. Boulos. The use of interactive graphical maps for browsing medical/health internet information resources. Int J Health Geogrphics, 2(1):1, 2003.", "A. Cardoso-Cachopo. Improving Methods for Single-label Text Categorization. PhD Thesis, Instituto Superior Tecnico, Universidade Tecnica de Lisboa, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838706.2838708"}, {"title": "The Probability Ranking Principle is Not Optimal in Adversarial Retrieval Settings", "authors": ["Ran Ben Basat\n,", "Moshe Tennenholtz\n,", "Oren Kurland"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe probability ranking principle (PRP) - ranking documents in response to a query by their relevance probabilities - is the theoretical foundation of most ad hoc document retrieval methods. A key observation that motivates our work is that the PRP does not account for potential post-ranking effects, specifically, changes to documents that result from a given ranking. Yet, in adversarial retrieval settings such as the Web, authors may consistently try to promote their documents in rankings by changing them. We prove that, indeed, the PRP can be sub-optimal in adversarial retrieval settings. We do so by presenting a novel game theoretic analysis of the adversarial setting. The analysis is performed for different types of documents (single topic and multi topic) and is based on different assumptions about the writing qualities of documents' authors. We show that in some cases, introducing randomization into the document ranking function yields overall user utility that transcends that of applying the PRP.", "references": ["AIRWeb - International Workshop on Adversarial Information Retrieval on the Web, 2005--2009.", "WICOW/AIRWeb Workshop on Web Quality (WebQuality), 2012.", "G. Amati and C. J. van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Transactions on Information Systems, 20(4):357--389, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809456"}, {"title": "Adoption of open source software: A study on the information technology sector in Minas Gerais", "authors": ["Luciana Guimaraes Carvalho\n,", "Orlando Abreu Gomes\n,", "Fernando Silva Parreiras"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nAlthough the use of open-source software (OSS) is a reality for information-technology companies, there has been little academic research on the factors impacting the process by which OSS is adopted, the way OSS is adopted, and the business models as employed. The TOE (Technology, Organization and Environment) framework has been used to study the influence of technological, organizational, and environmental factors considered by companies when adopting OSS. In this work, we collected data through online surveys answered by workers in IT companies in the state of Minas Gerais, Brazil. The proposed model for determining the impact of each factor on the adoption of OSS and on the business model practiced by IT companies was evaluated by using structural equations. The results show that three groups of factors impact the way of OSS adoption. Organizational and technological factors are the most relevant, whereas for business models only environmental factors are relevant. The most relevant technological factor identified is \"reduced hardware and software costs\"; the most relevant organizational factor is \"flexibility of IT structure\"; and the most relevant environmental factor is \"reports of successful use of OSS\". We verified that IT companies in Minas Gerais use OSS in software development, either by incorporating OSS components into their software products or by employing OSS tools for software development.", "references": ["S. A. Ajila and D. Wu. Empirical study of the effects of open source adoption on software development economics. Journal of Systems and Software, 80(9):1517-1529, 2007.", "C. Ayala, D. S. Cruzes, O. y. Hauge, and R. Conradi. Five Facts on the Adoption of Open Source Software. Software, 28(2):95-99, 2011.", "E. W. Bernroider and P. Schmöllerl. A technological, organisational, and environmental analysis of decision making methodologies and satisfaction in the context of IT induced business transformations. European Journal of Operational Research, 224(1):141-153, Jan. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814118"}, {"title": "Making Topic Models more Usable", "authors": ["Wray Buntine"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nThe output of topic models has always been seductive but not quite satisfying ever since the early work of Hofmann (PLSI) and Lee and Seung (NMF). An important approach to cleaning up the semantics does output analysis using coherence, and indeed other document summarization methods could also be used. However, this talk argues that topic models themselves need attention. New ways of modelling document semantics are being explored in the field of deep neural networks. Similarly, non-parametric versions of topic models allow modelling such effects as document structure, word sparsity, word burstiness, background words, multi-word terms, and network effects from author or follower networks, and semantic word hierarchies. These are usually done in the spirit of deep neural networks using hierarchical models, but earlier algorithms were often too slow to be realistic.\nThis talk will start with a brief tour of some of the variants, which can only be superficial given the huge number. This will be followed by a brief tour of some non-parametric methods known to be moderately efficient and suiting multi-core implementation. Note that the most important effect, modelling coherence, is currently poorly developed. The talk will then present experimental results on various versions of topic models to see how they can mitigate some of the unwanted artifacts of simple LDA.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809947"}, {"title": "BF-Classifier: Background/Foreground Classification and Segmentation of Soundscape Recordings", "authors": ["Miles Thorogood\n,", "Jianyu Fan\n,", "Philippe Pasquier"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nSegmentation and classification is an important but time consuming part of the process of using soundscape recordings in sound design and research. Background and foreground are general classes referring to a signal's perceptual attributes, and used as a criteria by sound designers when segmenting sound files. We establish the background / foreground classification task within a musicological and production-related context, and present a method for automatic segmentation of soundscape recordings based on this task. We created a soundscape corpus with ground truth data obtained from a human perception study. An analysis of the corpus showed an average agreement of each class - background 92.5%, foreground 80.8%, and background with foreground 75.3%. We then used the corpus to train a machine learning technique using a Support Vector Machines classifier. An analysis of the classifier demonstrated similar results to the average human performance (background 96.7%, foreground 80%, and background with foreground 86.7%). We then report an experiment evaluating the classifier with different analysis windows sizes, which demonstrates how smaller window sizes result in a diminishing performance of the classifier.", "references": ["E. Akdemir and T. Ciloglu. Bimodal automatic speech segmentation based on audio and visual information fusion. Speech Communication, 53(6):889--902, 2011.", "J.-J. Aucouturier and B. Defreville. Sounds like a park: A computational technique to recognize soundscapes holistically, without source identification. 19th International Congress on Acoustics, 2007.", "J. Augoyard and H. Torgue. Sonic Experience: A Guide to Everyday Sounds. McGill-Queen's University Press, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814926"}, {"title": "Session details: RDSM 2015", "authors": ["Kalina Bontcheva\n,", "Maria Liakata\n,", "Rob Procter\n,", "Arno Scharl"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3261068"}, {"title": "Terms, Topics & Tasks: Enhanced User Modelling for Better Personalization", "authors": ["Rishabh Mehrotra\n,", "Emine Yilmaz"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nGiven the distinct preferences of different users while using search engines, search personalization has become an important problem in information retrieval. Most approaches to search personalization are based on identifying topics a user may be interested in and personalizing search results based on this information.\nWhile topical interests information of users can be highly valuable in personalizing search results and improving user experience, it ignores the fact that two different users that have similar topical interests may still be interested in achieving very different tasks with respect to this topic (e.g. the type of tasks a broker is likely to perform related to finance is likely to be very different than that of a regular investor). Hence, considering user's topical interests jointly with the type of tasks they are likely to be interested in could result in better personalised\nWe present an approach that uses search task information embedded in search logs to represent users by their actions over a task-space as well as over their topical-interest space. In particular, we describe a tensor based approach that represents each user in terms of (i) user's topical interests and (ii) user's search task behaviours in a coupled fashion and use these representations for personalization. Additionally, we also integrate user's historic search behavior in a coupled matrix-tensor factorization framework to learn user representations. Through extensive evaluation via query recommendations and user cohort analysis, we demonstrate the value of considering topic specific task information while developing user models.", "references": ["E. Abbasnejad, S. Sanner, E. V. Bonilla, and P. Poupart. Learning community-based preferences via dirichlet process mixtures of gaussian processes. In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 1213--1219. AAAI Press, 2013.", "E. Acar, D. M. Dunlavy, and T. G. Kolda. A scalable optimization approach for fitting canonical tensor decompositions. Journal of Chemometrics, 25(2):67--86, 2011.", "P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short-and long-term behavior on search personalization. In ACM SIGIR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809467"}, {"title": "Session details: Special Track - Applications and Tools", "authors": ["Sean Wolfgand Matsui Siqueira\n,", "Marcel Ferrante Silva"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252439"}, {"title": "Personalizing maps", "authors": ["Andrea Ballatore\n,", "Michela Bertolotto"], "publication": "Communications of the ACM", "abstract": "Abstract\nDigital maps can be engineered to adapt to a person's unique interests and experience in geographic space.", "references": ["Ballatore, A. and Bertolotto, M. 2011. Semantically enriching VGI in support of implicit feedback analysis. Web and Wireless Geographical Information Systems, K. Tanaka, P. Fröhlich, and K.-S. Kim, Eds. LNCS, Vol. 6574 (Kyoto, Japan, Mar. 3-4). Springer, Berlin, Germany, 78--93.", "Ballatore, A., McArdle, G., Kelly, C., and Bertolotto, M. RecoMap: An interactive and adaptive map-based recommender. In Proceedings of the 25th ACM Symposium on Applied Computing (Sierre, Switzerland, Mar. 22-26). ACM Press, New York, 2010, 887--891.", "Ballatore, A., Wilson, D., and Bertolotto, M. A survey of volunteered open geo-knowledge bases in the semantic Web. In Quality Issues in the Management of Web Information, G. Pasi, G. Bordogna, and K. Jain, Eds. Intelligent Systems Reference Library, vol. 50. Springer, Berlin, Germany, 2013, 93--120."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756546"}, {"title": "A Document Retrieval Model Based on Digital Signal Filtering", "authors": ["Alberto Costa\n,", "Emanuele Di Buccio\n,", "Massimo Melucci"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nInformation retrieval (IR) systems are designed, in general, to satisfy the information need of a user who expresses it by means of a query, by providing him with a subset of documents selected from a collection and ordered by decreasing relevance to the query. Such systems are based on IR models, which define how to represent the documents and the query, as well as how to determine the relevance of a document for a query. In this article, we present a new IR model based on concepts taken from both IR and digital signal processing (like Fourier analysis of signals and filtering). This allows the whole IR process to be seen as a physical phenomenon, where the query corresponds to a signal, the documents correspond to filters, and the determination of the relevant documents to the query is done by filtering that signal. Tests showed that the quality of the results provided by this IR model is comparable with the state-of-the-art.", "references": ["G. Amati and C. J. van Rijsbergen. 2002. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Transactions on Information Systems 20, 4, 357--389.", "L. Atzori, A. Iera, and G. Morabito. 2010. The Internet of Things: A survey. Computer Networks 54, 15, 2787--2805.", "K. Blekas and I. E. Lagaris. 2007. Newtonian clustering: An approach based on molecular dynamics and global optimization. Pattern Recognition 40, 6, 1734--1744."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809787"}, {"title": "Repeat Consumption Recommendation Based on Users Preference Dynamics and Side Information", "authors": ["Dimitrios Rafailidis\n,", "Alexandros Nanopoulos"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe present a Coupled Tensor Factorization model to recommend items with repeat consumption over time. We introduce a measure that captures the rate with which the preferences of each user shift over time. Repeat consumption recommendations are generated based on factorizing the coupled tensor, by weighting the importance of past user preferences according to the captured rate. We also propose a variant, where the diversity of the side information is taken into account, by higher weighting users that have more rare side information. Our experiments with real-world datasets from last.fm and MovieLens demonstrate that the proposed models outperform several baselines.", "references": ["E. Acar, T. G. Kolda, and D. M. Dunlavy. All-at-once optimization for coupled matrix and tensor factorizations. CoRR, abs/1105.3422, 2011.", "A. Anderson, R. Kumar, A. Tomkins, and S. Vassilvitskii. The dynamics of repeat consumption. In WWW, pages 419--430, 2014.", "D. M. Dunlavy, T. G. Kolda, and E. Acar. Temporal link prediction using matrix and tensor factorizations. TKDD, 5(2):10, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742732"}, {"title": "Clustering-based Approach for Categorizing Pregnant Women in Obstetrics and Maternity Care", "authors": ["Sónia Pereira\n,", "Filipe Portela\n,", "Manuel F. Santos\n,", "José Machado\n,", "António Abelha"], "publication": "C3S2E '15: Proceedings of the Eighth International C* Conference on Computer Science & Software Engineering", "abstract": "ABSTRACT\nWhen a pregnant woman is guided to a hospital for obstetrics purposes, many outcomes are possible, depending on her current conditions. An improved understanding of these conditions could provide a more direct medical approach by categorizing the different types of patients, enabling a faster response to risk situations, and therefore increasing the quality of services. In this case study, the characteristics of the patients admitted in the maternity care unit of Centro Hospitalar of Porto are acknowledged, allowing categorizing the patient women through clustering techniques. The main goal is to predict the patients' route through the maternity care, adapting the services according to their conditions, providing the best clinical decisions and a cost-effective treatment to patients. The models developed presented very interesting results, being the best clustering evaluation index: 0.65. The evaluation of the clustering algorithms proved the viability of using clustering based data mining models to characterize pregnant patients, identifying which conditions can be used as an alert to prevent the occurrence of medical complications.", "references": ["C. V., Carter, M. C., Corry, M., Delbanco, S., Foster, T. C. S., Friedland, R., and Simpson, K. R.: 2020 vision for a high-quality, high-value maternity care system. Women's health issues, 20(1), S7--S17. (2010)", "Sokol, R. J., Woolf, R. B., Rosen, M. G., and Weingarden, K.: Risk, antepartum care, and outcome: impact of a maternity and infant care project. Obstetrics & Gynecology, 56(2), 150--156.", "Z. Chenhui, D. Huilong, and L. Xudong, \"An integration approach of healthcare information system,\" 2008, pp. 606--609 (1980)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790798.2790814"}, {"title": "Digital Ecosystems to Support the Open and Collaborative Government Systems", "authors": ["Andrea Magalhaes Magdaleno\n,", "Renata Mendes de Araujo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis article discusses the open and collaborative government systems such as digital ecosystems, building a conceptual framework to define, specify and develop computational solutions aimed at supporting the operating dynamics and expand relations of access to information, participation, knowledge management, innovation, and education in citizen-government relations.", "references": ["De Araujo, R.M. et al. 2013. Evolving Government-Citizen Ties in Public Service Design and Delivery. EGOV/ePart Ongoing Research (2013), 19-26.", "Araujo, R.M. de and Taher, Y. 2014. Refining IT Requirements for Government-Citizen Co-participation Support in Public Service Design and Delivery. (2014), 61-72.", "Boley, H. and Chang, E. 2007. Digital Ecosystems: Principles and Semantics. (Feb. 2007), 398^4-03."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814161"}, {"title": "Using Paired Distances of Signal Peaks in Stereo Channels as Fingerprints for Copy Identification", "authors": ["Shingchern D. You\n,", "Yi-Han Pu"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nThis article proposes to use the relative distances between adjacent envelope peaks detected in stereo audio as fingerprints for copy identification. The matching algorithm used is the rough longest common subsequence (RLCS) algorithm. The experimental results show that the proposed approach has better identification accuracy than an MPEG-7 based scheme for distorted and noisy audio. When compared with other schemes, the proposed scheme uses fewer bits with comparable performance. The proposed fingerprints can also be used in conjunction with the MPEG-7 based scheme for lower computational burden.", "references": ["3GPP TS 26.404. 2012. 3rd generation partnership project; technical specification group services and system aspects; general audio codec audio process functions; Enhanced aacPlus general audio codec; enhanced aacPlus encoder SBR part, 3GPP TS 26 404, v 11.0.0 (Sept. 2012).", "Shumeet Baluja and Michele Covell. 2007. Audio fingerprinting: combining computer vision and data stream processing. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, II-213--II-216.", "Carlo Bellettini and Gianluca Mazzini. 2007. On audio recognition performance via robust hashing. In Proceedings of the International Symposium on Intelligent Signal Processing and Communication Systems. 20--23."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742059"}, {"title": "Assessing the Impact of Syntactic and Semantic Structures for Answer Passages Reranking", "authors": ["Kateryna Tymoshenko\n,", "Alessandro Moschitti"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we extensively study the use of syntactic and semantic structures obtained with shallow and deeper syntactic parsers in the answer passage reranking task. We propose several dependency-based structures enriched with Linked Open Data (LD) knowledge for representing pairs of questions and answer passages. We use such tree structures in learning to rank (L2R) algorithms based on tree kernel. The latter can represent questions and passages in a tree fragment space, where each substructure represents a powerful syntactic/semantic feature. Additionally since we define links between structures, tree kernels also generate relational features spanning question and passage structures. We derive very important findings, which can be useful to build state-of-the-art systems: (i) full syntactic dependencies can outperform shallow models also using external knowledge and (ii) the semantic information should be derived by effective and high-coverage resources, e.g., LD, and incorporated in syntactic structures to be effective. We demonstrate our findings by carrying out an extensive comparative experimentation on two different TREC QA corpora and one community question answer dataset, namely Answerbag. Our comparative analysis on well-defined answer selection benchmarks consistently demonstrates that our structural semantic models largely outperform the state of the art in passage reranking.", "references": ["E. Aktolga, J. Allan, and D. A. Smith. Passage reranking for question answering using syntactic structures and answer types. In ECIR, 2011.", "M. W. Bilotti, J. L. Elsas, J. Carbonell, and E. Nyberg. Rank learning for factoid question answering with linguistic and semantic constraints. In CIKM, 2010.", "M. W. Bilotti and E. Nyberg. Improving text retrieval precision and answer accuracy in question answering systems. In (IR4QA) Workshop at COLING, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806490"}, {"title": "Spatial partitioning techniques in SpatialHadoop", "authors": ["Ahmed Eldawy\n,", "Louai Alarabi\n,", "Mohamed F. Mokbel"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nSpatialHadoop is an extended MapReduce framework that supports global indexing that spatial partitions the data across machines providing orders of magnitude speedup, compared to traditional Hadoop. In this paper, we describe seven alternative partitioning techniques and experimentally study their effect on the quality of the generated index and the performance of range and spatial join queries. We found that using a 1% sample is enough to produce high quality partitions. Also, we found that the total area of partitions is a reasonable measure of the quality of indexes when running spatial join. This study will assist researchers in choosing a good spatial partitioning technique in distributed environments.", "references": ["J. L. Bentley. Multidimensional Binary Search Trees Used for Associative Searching. Commun. ACM, 18(9):509--517, 1975.", "A. Eldawy and M. F. Mokbel. A Demonstration of SpatialHadoop: An Efficient MapReduce Framework for Spatial Data. In VLDB, 2013.", "A. Eldawy and M. F. Mokbel. SpatialHadoop: A MapReduce Framework for Spatial Data. In ICDE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824057"}, {"title": "Combining Acoustic and Multilevel Visual Features for Music Genre Classification", "authors": ["Ming-Ju Wu\n,", "Jyh-Shing R. Jang"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nMost music genre classification approaches extract acoustic features from frames to capture timbre information, leading to the common framework of bag-of-frames analysis. However, time-frequency analysis is also vital for modeling music genres. This article proposes multilevel visual features for extracting spectrogram textures and their temporal variations. A confidence-based late fusion is proposed for combining the acoustic and visual features. The experimental results indicated that the proposed method achieved an accuracy improvement of approximately 14% and 2% in the world's largest benchmark dataset (MASD) and Unique dataset, respectively. In particular, the proposed approach won the Music Information Retrieval Evaluation eXchange (MIREX) music genre classification contests from 2011 to 2013, demonstrating the feasibility and necessity of combining acoustic and visual features for classifying music genres.", "references": ["Jeremy F. Alm and James S. Walker. 2002. Time-frequency analysis of musical instruments. SIAM Review 44, 3, 457--476.", "James Bergstra, Michael I. Mandel, and Douglas Eck. 2010. Scalable genre and tag prediction with spectral covariance. In Proceedings of the 11th International Society for Music Information Retrieval Conference (ISMIR). J. Stephen Downie and Remco C. Veltkamp (Eds.), International Society for Music Information Retrieval, 507--512. http://dblp.uni-trier.de/db/conf/ismir/ismir2010.html#BergstraME10.", "Thierry Bertin-Mahieux, Daniel P. W. Ellis, Brian Whitman, and Paul Lamere. 2011. The million song dataset. In Proceedings of the International Conference on Music Information Retrieval. 591--596."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801127"}, {"title": "ExcUseMe: Asking Users to Help in Item Cold-Start Recommendations", "authors": ["Michal Aharon\n,", "Oren Anava\n,", "Noa Avigdor-Elgrabli\n,", "Dana Drachsler-Cohen\n,", "Shahar Golan\n,", "Oren Somekh"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe item cold-start problem is of a great importance in collaborative filtering (CF) recommendation systems. It arises when new items are added to the inventory and the system cannot model them properly since it relies solely on historical users' interactions (e.g., ratings). Much work has been devoted to mitigate this problem mostly by employing hybrid approaches that combine content-based recommendation techniques or by devoting a portion of the user traffic for exploration to gather interactions from random users. We focus on pure CF recommender systems (i.e., without content or context information) in a realistic online setting, where random exploration is inefficient and smart exploration that carefully selects users is crucial due to the huge flux of new items with short lifespan. We further assume that users arrive randomly one after the other and that the system has to immediately decide whether the arriving user will participate in the exploration of the new items.\nFor this setting we present ExcUseMe, a smart exploration algorithm that selects a predefined number of users for exploring new items. ExcUseMe gradually excavates the users that are more likely to be interested in the new items and models the new items based on the users' interactions. We evaluated ExcUseMe on several datasets and scenarios and compared it to state-of-the-art algorithms. Experimental results indicate that ExcUseMe is an efficient algorithm that outperforms all other algorithms in all tested scenarios.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In KDD '09.", "M. Aharon, A. Kagian, Y. Koren, and R. Lempel. Dynamic personalized recommendation of comment-eliciting stories. In RecSys '12.", "N. Aizenberg, Y. Koren, and O. Somekh. Build your own music recommender by modeling internet radio streams. In WWW '12."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800183"}, {"title": "A Stationary Bike in Augmented Audio Reality", "authors": ["Justyna Maculewicz\n,", "Stefania Serafin"], "publication": "REHAB '15: Proceedings of the 3rd 2015 Workshop on ICTs for improving Patients Rehabilitation Research Techniques", "abstract": "ABSTRACT\nIn this paper, we describe a system for rhythmic rehabilitation based on a stationary bike augmented in an audio reality. Specific sensors are used to monitor users pace and heart rate while exercising and manipulate audio feedback and cues. Simple technology solutions will allow for the system to be used by the wide range of users. The innovation is to use as a feedback and cues ecological sounds, which has power to manipulate pace and give a more natural experience.", "references": ["Ambrosini, E., Ferrante, S., Pedrocchi, A., Ferrigno, G., and Molteni, F. (2011). Cycling induced by electrical stimulation improves motor recovery in postacute hemiparetic patients a randomized controlled trial. Stroke, 42(4):1068--1073", "Beier, M., Bombardier, C. H., Hartoonian, N., Motl, R. W., and Kraft, G. H. (2014). Improved physical fitness correlates with improved cognition in multiple sclerosis. Archives of physical medicine and rehabilitation.", "Chuchnowska, I. and Sekala, A. (2011). An innovative system for interactive rehabilitation of children at the age of three. Archives of Materials Science and Engineering, 50(1):36--42."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838944.2838984"}, {"title": "Major Issues in Business Process Management: Key Concerns presented in Academy from a Brazilian Perspective", "authors": ["Valdemar T. F. Confort\n,", "Flavia Maria Santoro"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper is part of a major research in Business Process Management (BPM). There are international publications that identify the evolution of this area and practical challenges in several perspectives. This paper contributes with a comprehensive survey that identifies, from a Brazilian perspective, the evolution of the academic interest and the practical challenges of the national organizations. The expected results are, first, that this work can provide evidences to answer our research question: What are the issues BPM in Brazil? In addition, we expect to contribute with an approach and instruments that can be applied in the future in a new evaluation, following the same process of this research. This first part presents the results of a key concerns classification of all the papers presented in a Brazilian's Conference: the Workshop of Business Process Management. With this first part, we aim to contribute by showing and discussing what are the academy keys concern and compare it with the BPM International Conference.", "references": ["M. Dumas, M. La Rosa, J. Mendling and H. A. Reijers, Fundamentals of Business Process Management, Berlin: Springer, 2013.", "W. Aalst, A. Hotsfede and M. Weske, \"Business Process Management: a survey,\" in BPM 2003, Berlin Heidelberg, 2003.", "W. Aalst, \"Business Process Management Demystified: A tutorial on models, systems and standrds for workflow management,\" in Lecture Notes in Computer Science, Berlin, Germany, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814172"}, {"title": "An Urban Data Profiler", "authors": ["Daniel Castellani Ribeiro\n,", "Huy T. Vo\n,", "Juliana Freire\n,", "Cláudio T. Silva"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLarge volumes of urban data are being made available through a variety of open portals. Besides promoting transparency, these data can bring benefits to government, science, citizens and industry. It is no longer a fantasy to ask \"if you could know anything about a city, what do you want to know\" and to ponder what could be done with that information. However, the great number and variety of datasets creates a new challenge: how to find relevant datasets. While existing portals provide search interfaces, these are often limited to keyword searches over the limited metadata associated each dataset, for example, attribute names and textual description. In this paper, we present a new tool, UrbanProfiler, that automatically extracts detailed information from datasets. This information includes attribute types, value distributions, and geographical information, which can be used to support complex search queries as well as visualizations that help users explore and obtain insight into the contents of a data collection. Besides describing the tool and its implementation, we present case studies that illustrate how the tool was used to explore a large open urban data repository.", "references": ["L. Barbosa, K. Pham, C. Silva, M. Vieira, and J. Freire. Structured open urban data: Understanding the landscape. Big Data, 2(3), 2014.", "CKAN. http://ckan.org. {Online; accessed 28-May-2014}.", "I. Ellen, J. Lacoe, and C. Sharygin. Do foreclosures cause crime? Journal of Urban Economics, 74:59--70, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742135"}, {"title": "Building a Context Image-Based Search Engine Using Multi Clustering Technique", "authors": ["Hasan Rashaideh\n,", "Habes Alkhraisat\n,", "Alaa Ghazo"], "publication": "ICEMIS '15: Proceedings of the The International Conference on Engineering & MIS 2015", "abstract": "ABSTRACT\nContent-Based Image Retrieval (CBIR) is a challenging task which retrieves the similar images from the large database. Most of the CBIR system uses the low-level features such as color, texture and shape which has not much detailed information about the images, in case of looking for images that contain the same object or same scene with different viewpoints to extract the features from the images. Allowing users to find images on the web similar to a particular query image is a crucial component of modern search engines. In this paper the Speeded Up Robust Feature is combined with the color feature to improve the retrieval accuracy of the search engine. In this paper, k-means clustering algorithm is used for clustering image features. However, it is computationally expensive and the quality of the resulting clusters heavily depends on the dimension of the data. This paper proposed a new approach to improve the accuracy of the cluster results from using a new novel algorithm called NCD to reduce the dimension of the image features in the dataset. Experiment results show that the proposed color feature is more accurate and efficient in retrieving images with user-interested color and image objects compared with the current algorithms. Speeded Up Robust Features (SURF) show its advantages in rotation, scale changes, image blur, affine transformations and illumination changes.", "references": ["Jain.R, Workshop report: NSF workshop on visual information management systems (1993).", "Lowe, D. G. (2004). Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60(2), 91--110.", "Peter.W, Paul.F, P. Smeaton, Alan.F.C, Cathal.G, (2005). Text based approaches for content-based image retrieval on large image collections, Integration of Knowledge, Semantics and Digital Media Technology, 2005. EWIMT 2005. The 2nd European Workshop on the (Ref. No. 2005/11099), 281--288, London."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832987.2833006"}, {"title": "Topic Hypergraph Hashing for Mobile Image Retrieval", "authors": ["Lei Zhu\n,", "Jialie Shen\n,", "Liang Xie"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHashing is one of the promising solutions to support efficient Mobile Image Retrieval (MIR). However, most of existing hashing strategies simply rely on low-level features, which inevitably makes the generated hashing codes less semantic. Moreover, many of them fail to exploit complex and high-order semantic correlations of images. Motivated by these observations, we propose a novel unsupervised hashing scheme, \\emph{Topic Hypergraph Hashing} (THH), to address the limitations. A unified topic hypergraph, where images and topics are represented with independent vertices and hyperedges respectively, is first constructed to model latent semantics of images and their correlations. With topic hypergraph model, hashing codes and functions are then learned by simultaneously preserving similarity consistence and semantic correlation. Experiments on standard datasets demonstrate that THH can achieve superior performance compared with several state-of-the-art techniques, and it is more suitable for MIR.", "references": ["F. R. Bach and M. I. Jordan. Learning spectral clustering. In NIPS, pages 305--312, 2003.", "Z. Cheng, J. Shen, and H. Miao. The effects of multiple query evidences on social image retrieval. MMSJ, pages 1--15, 2014.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: A real-world web image database from national university of singapore. In CIVR, pages 48:1--48:9, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806345"}, {"title": "In-Situ Bitmaps Generation and Efficient Data Analysis based on Bitmaps", "authors": ["Yu Su\n,", "Yi Wang\n,", "Gagan Agrawal"], "publication": "HPDC '15: Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing", "abstract": "ABSTRACT\nNeither the memory capacity, memory access speeds, nor disk bandwidths are increasing at the same rate as the computing power in current and upcoming parallel machines. This has led to considerable recent research on in-situ data analytics. However, many open questions remain on how to perform such analytics, especially in memory constrained systems. Building on our earlier work that demonstrated bitmap indices (bitmaps) can be a suitable summary structure for key (offline) analytics tasks, this paper develops an in-situ analysis approach that performs data reduction (such as time-steps selection) using just bitmaps, and subsequently, stores only the selected bitmaps for post-analysis. We construct compressed bitmaps on the fly, show that many kinds of in-situ analyses can be supported by bitmaps without requiring the original data (and thus reducing memory requirements for in-situ analysis), and instead of writing the original simulation output, we only write the selected bitmaps to the disks (reducing the I/O requirements). We also demonstrate that we are able to use bitmaps for key offline analysis steps. We extensively evaluate our method with different simulations and applications, and demonstrate the effectiveness of our approach.", "references": ["Heat3d simulation. http://http://dournac.org/info/parallel_heat3d.", "Sameh Abdulah, Yu Su, and Gagan Agrawal. Accelerating data mining on incomplete datasets by bitmaps-based missing value imputation. In Proceedings of the 7th International Conference on Advances in Databases, Knowledge, and Data Applications, 2015.", "James Ahrens, Sébastien Jourdain, Patrick O'Leary, John Patchett, D Rogers, and M Peterson. An imagebased approach to extreme scale in situ visualization and analysis. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE Press, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2749246.2749268"}, {"title": "An Instrument for Merging of Bibliographic Databases", "authors": ["Anna A. Knyazeva\n,", "Oleg S. Kolobov\n,", "Fjodor E. Tatarsky\n,", "Igor Yu. Turchanovsky"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe process of merging two or more library catalogues is considered in this paper. It's necessary to solve the problem of duplicate detection and merging into one database instead of simple union of different resources. The toolbox Cflib for duplicate detection and merging has been developed by us. It's based on standard principles of record linkage and has quite simple architecture.", "references": ["M. F. Loesch. VIAF (the virtual international authority file)textendash http://viaf.org. Technical Services Quarterly, 28(2):255--256, feb 2011.", "A. Hopkinson, editor. UNIMARC Manual. Walter de Gruytertextendash K. G. Saur, jan 2008.", "A. Knyazeva, I. Turchanovsky, O. Kolobov, and O. Zhizhimov. Experience of person identification for cris-systems. In Selected Papers of XVI All-Russian Scientific Conference \"Digital libraries: Advanced Methods and Technologies, Digital Collections\", oct 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756973"}, {"title": "Overlapping Community Regularization for Rating Prediction in Social Recommender Systems", "authors": ["Hui Li\n,", "Dingming Wu\n,", "Wenbin Tang\n,", "Nikos Mamoulis"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender systems have become de facto tools for suggesting items that are of potential interest to users. Predicting a user's rating on an item is the fundamental recommendation task. Traditional methods that generate predictions by analyzing the user-item rating matrix perform poorly when the matrix is sparse. Recent approaches use data from social networks to improve accuracy. However, most of the social-network based recommender systems only consider direct friendships and they are less effective when the targeted user has few social connections. In this paper, we propose two alternative models that incorporate the overlapping community regularization into the matrix factorization framework. Our empirical study on four real datasets shows that our approaches outperform the state-of-the-art algorithms in both traditional and social-network based recommender systems regarding both cold-start users and normal users.", "references": ["E. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels. In NIPS, pages 33--40, 2008.", "D. J. Crandall, D. Cosley, D. P. Huttenlocher, J. M. Kleinberg, and S. Suri. Feedback effects between similarity and social influence in online communities. In KDD, pages 160--168, 2008.", "M. Deshpande and G. Karypis. Item-based top-phN recommendation algorithms. ACM Trans. Inf. Syst., 22(1):143--177, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800171"}, {"title": "A Novel Wharf-based Genetic Algorithm for Berth Allocation Planning", "authors": ["An-Hsiou Tsai\n,", "Chung-Nan Lee\n,", "Jain-Shing Wu\n,", "Fu-Sheng Chang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nFor a commercial port, efficiently scheduling the vessels to the public berths is an important issue. In order to save communication and awaiting time of vessels, a wharf-based genetic algorithm is proposed to schedule the public berths. In the initialization process, the schedules are encoded as the chromosomes based on wharf characteristics to avoid assigning vessels to inappropriate wharves. After selection, crossover, mutation processes, the proposed wharf-based genetic algorithm adjusts the usage of wharves to increase the convergence speed. Experimental results show that the proposed algorithm can assign vessels to proper berths as soon as vessels arrive. Compared to the other algorithms, the proposed algorithm obtains 9 times faster than the best one of competing methods. Our wharf-based genetic algorithm obtains the best performance in convergence speed and quality of the solutions than all competing methods.", "references": ["Lim, A. 1998. The berth planning problem. Operations Research Letters, Vol. 22, 105--110.", "Boile, M., Golias, M., and Theofanis, S. 2009. Scheduling of berthing resources at a marine container terminal via the use of genetic algorithms: Current and Future Research. Evolutionary Computation. Wellington Pinheiro dos Santos (Ed.), I-Tech, 61--76.", "Go, K. S., and Lim, A. 2000. Combining various algorithms to solve the ship berthing problem. Proceedings of 12th IEEE International Conference on Tools with Artificial Intelligence, 370--375."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818874"}, {"title": "Learning Socially Embedded Visual Representation from Scratch", "authors": ["Shaowei Liu\n,", "Peng Cui\n,", "Wenwu Zhu\n,", "Shiqiang Yang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nLearning image representation by deep model has recently made remarkable achievements for semantic-oriented applications, such as image classification. However, for user-centric tasks, such as image search and recommendation, simply employing the representation learnt from semantic-oriented tasks may fail to capture user intentions. In this paper, we propose a novel Socially Embedded VIsual Representation Learning (SEVIR) approach, where an Asymmetric Multi-task CNN (amtCNN) model is proposed to embed user intention learning task into semantic learning task. Specifically, to address the sparsity and unreliability problems in social behavioral data, we propose to use user clustering, reliability evaluation, random dropout in output layer in our amtCNN. With its the partially shared network architecture, the learnt representation can capture both semantics and user intentions. Comprehensive experiments are conducted to investigate the effectiveness of our approach in applications of user favoring prediction, personalized image recommendation, and image reranking. Compared to the state-of-the-art image representation techniques, our approach achieves significant improvement in performance.", "references": ["A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. In ECCV, pages 584--599.Springer, 2014.", "J. S. Breese, D. Heckerman, and C. Kadie. Empiricalanalysis of predictive algorithms for collaborative filtering. In Uncertainty in artificial intelligence, pages 43--52.Morgan Kaufmann Publishers Inc., 1998.", "P. Cui, S.-W. Liu, W.-W. Zhu, H.-B. Luan, T.-S. Chua,and S.-Q. Yang. Social-sensed image search. ACM TOIS,32(2):8, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806247"}, {"title": "The evolution of knowledge in communities of practice", "authors": ["Vinay Avasthi\n,", "Shubhamoy Dey\n,", "Kamal Kishore Jain\n,", "Rajhans Mishra"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nOrganizations and groups rely on the effective capture and sharing of knowledge for their survival. They spend a significant amount of effort and time to codify and manage the body of knowledge that their constituents collectively possess. Despite these efforts, tacit knowledge tends to solely reside within those who use it for their day to day work. It is widely believed that tacit knowledge disappears when the individual possessing it leaves an organization or group. More and more organizations are fostering communities of practice as a mechanism to influence knowledge creation and dissemination. Hence, it becomes imperative for us to understand how best to capture the knowledge that now resides within these communities, which could extend across multiple organizations. In this research article, we establish that the knowledge contained within communities of practice evolves over a period of time. We examine the evolution of this knowledge, and its impact on the community as well as the invidividuals concerned.", "references": ["Alias-i. LingPipe 4.1.0, 2008.", "A. Ardichvili, V. Page, and T. Wentling. Motivation and barriers to participation in virtual knowledge-sharing communities of practice. Journal of knowledge management, 7(1):64--77, 2003.", "V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811528"}, {"title": "Learning Deep Features For MSR-bing Information Retrieval Challenge", "authors": ["Qiang Song\n,", "Sixie Yu\n,", "Cong Leng\n,", "JiaXiang Wu\n,", "Qinghao Hu\n,", "Jian Cheng"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nTwo tasks have been put forward in the MSR-bing Grand Challenge 2015. To address the information retrieval task, we raise and integrate a series of methods with visual features obtained by convolution neural network (CNN) models. In our experiments, we discover that the ranking strategies of Hierarchical clustering and PageRank methods are mutually complementary. Another task is fine-grained classification. In contrast to basic-level recognition, fine-grained classification aims to distinguish between different breeds or species or product models, and often requires distinctions that must be conditioned on the object pose for reliable identification. Current state-of-the-art techniques rely heavily upon the use of part annotations, while the bing datasets suffer both abundance of part annotations and dirty background. In this paper, we propose a CNN-based feature representation for visual recognition only using image-level information. Our CNN model is pre-trained on a collection of clean datasets and fine-tuned on the bing datasets. Furthermore, a multi-scale training strategy is adopted by simply resizing the input images into different scales and then merging the soft-max posteriors. We then implement our method into a unified visual recognition system on Microsoft cloud service. Finally, our solution achieved top performance in both tasks of the contest", "references": ["E. Dataset. Novel datasets for fine-grained image categorization. In First Workshop on Fine Grained Visual Categorization, CVPR. Citeseer, 2011.", "R. Farrell, O. Oza, N. Zhang, V. Morariu, T. Darrell, L. S. Davis, et al. Birdlets: Subordinate categorization using volumetric primitives and pose-normalized appearance. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 161--168. IEEE, 2011.", "X.-S. Hua. Looking into msr-bing image retrieval challenge. Technical report, Microsoft Research Technical Report MSR-TR-2013-76, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2809928"}, {"title": "E2C2: efficient and effective camera calibration in indoor environments", "authors": ["Huan Li\n,", "Pai Peng\n,", "Hua Lu\n,", "Lidan Shou\n,", "Ke Chen\n,", "Gang Chen"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nCamera calibration helps users better interact with the surrounding environments. In this work, we aim at accelerating camera calibration in an indoor setting, by selecting a small but sufficient set of keypoints. Our framework consists of two phases: In the offline phase, we cluster photos labeled with Wi-Fi and gyro sensor data according to a learned distance metric. Photos in each cluster form a \"co-scene\". We further select a few frequently appearing keypoints in each co-scene as \"useful keypoints\" (UKPs). In the online phase, when a query is issued, only UKPs from the nearest co-scene are selected, and subsequently we infer extrinsic camera parameters with multiple view geometry (MVG) technique. Experimental results show that our framework is effective and efficient to support calibration.", "references": ["Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S. Dhillon. 2007. Information-theoretic metric learning. In ICML. ACM, 209--216.", "Mohammed E. Fathy, Ashraf S. Hussein, and Mohammed F. Tolba. 2011. Fundamental matrix estimation: A study of error criteria. Pattern Recognition Letters (2011), 383--391.", "Richard Hartley and Andrew Zisserman. 2003. Multiple view geometry in computer vision. Cambridge university press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2800841"}, {"title": "ASEM: Mining Aspects and Sentiment of Events from Microblog", "authors": ["Ruhui Wang\n,", "Weijing Huang\n,", "Wei Chen\n,", "Tengjiao Wang\n,", "Kai Lei"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMicroblogs contain the most up-to-date and abundant opinion information on current events. Aspect-based opinion mining is a good way to get a comprehensive summarization of events. The most popular aspect based opinion mining models are used in the field of product and service. However, existing models are not suitable for event mining. In this paper we propose a novel probabilistic generative model (ASEM) to simultaneously discover aspects and the specified opinions. ASEM incorporate a sequence labeling model(CRF) into a generative topic model. Additionally, we adopt a set of features for separating aspects and sentiments. Moreover, we novelly present a continuously learning model. It can utilize the knowledge of one event to learn another, and get a better performance. We use five real world events to do experiment. The experimental results show that ASEM extracts aspects and sentiments well, and ASEM outperforms other state-of-art models and the intuitive two-step method.", "references": ["S. Blair-Goldensohn, K. Hannan, R. McDonald, T. Neylon, G. A. Reis, and J. Reynar. Building a sentiment summarizer for local service reviews. In WWW Workshop on NLP in the Information Explosion Era, volume 14, 2008.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "S. Brody and N. Elhadad. An unsupervised aspect-sentiment model for online reviews. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 804--812. Association for Computational Linguistics, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806622"}, {"title": "IdeaPanel: A Large Scale Interactive Sketch-based Image Search System", "authors": ["Changcheng Xiao\n,", "Changhu Wang\n,", "Liqing Zhang\n,", "Lei Zhang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this work, we introduce the IdeaPanel system, an interactive sketch-based image search engine with millions of images. IdeaPanel enables users to sketch the target image in their minds and also supports tagging to describe their intentions. After a search is triggered, similar images will be returned in real time, based on which users can interactively refine their query sketches until ideal images are returned. Different from existing work, most of which requires a huge amount of memory for indexing and matching, IdeaPanel can achieve very competitive performance but requires much less memory storage. IdeaPanel needs only about 240MB memory to index 1.3M images (less than 3% of previous MindFinder system). Due to its high accuracy and low memory cost, IdealPanel can scale up to much larger database and thus has larger potential to return the most desired images for users.", "references": ["G. Borgefors. Hierarchical chamfer matching: A parametric edge matching algorithm. IEEE PAMI, 1988.", "Y. Cao, H. Wang, C. Wang, Z. Li, L. Zhang, and L. Zhang. Mindfinder: Interactive sketch-based image search on millions of images. ACM MM, 2010.", "R. Datta, D. Joshi, J. Li, and J. Z. Wang. Image retrieval: Ideas, influences, and trends of the new age. ACM Comput. Surv., 40:5:1--5:60, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749410"}, {"title": "Droplets: geo-located audio as a social media platform", "authors": ["John Shearer\n,", "Sue Swinburne\n,", "Patrick Dickinson"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nLocation-based audio has previously attracted some attention from the HCI community. This has mainly revolved around knowledge-sharing and creation of curated experiences as artistic expression. In this paper we present initial work in which we look at located audio through the lenses of social media, and present initial work on a social media app -- Droplets -- which seeks to create new geo-located social media experiences.", "references": ["Calvium, AppFurnace (2015). {Online}. Available: http://appfurnace.com/ {Accessed: 28 May 2015}.", "Giles, T., Marianek, M., and Freidel, S. (2008) URBAN ENCOUNTER: Location-Based Collective Storytelling, In Proc. OZCHI 2008, ACM Press, pp. 122--129.", "Guardian, Streetstories, (2012). {Online} Available: http://theguardian.com/mobile/streetstories {Accessed: 28 Dec 2014}"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783617"}, {"title": "Ads Keyword Rewriting Using Search Engine Results", "authors": ["Javad Azimi\n,", "Adnan Alam\n,", "Ruofei Zhang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nPaid Search (PS) ads are one of the main revenue sources of online advertising companies where the goal is returning a set of relevant ads for a searched query in search engine websites such as Bing. Typical PS algorithms, return the ads which their Bided Keywords (BKs) are a subset of searched queries or relevant to them. However, there is a huge gap between BKs and searched queries as a considerable amount of BKs are rarely searched by the users. This is mostly due to the rare BKs provided by advertisers. In this paper, we propose an approach to rewrite the rare BKs to more commonly searched keywords, without compromising the original BKs intent, which increases the coverage and depth of PS ads and thus it delivers higher monetization power. In general, we first find the relevant web documents pertaining to the BKs and then extract common keywords using the web doc title and its summary snippets. Experimental results show the effectiveness of proposed algorithm in rewriting rare BKs and consequently providing us with a significant improvement in recall and thereby revenue.", "references": ["A. Broder, P. Ciccolo, E. Gabrilovich, V. Josifovski, D. Metzler, L. Riedel, and J. Yuan. Online expansion of rare queries for sponsored search. In WWW, 2009.", "K. S. Dave and V. Varma. Pattern based keyword extraction for contextual advertising. In CIKM, 2010.", "P.-S. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck. Learning deep structured semantic models for web search using clickthrough data. CIKM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742739"}, {"title": "BMExpert: Mining MEDLINE for Finding Experts in Biomedical Domains Based on Language Model", "authors": ["Beichen Wang\n,", "Xiaodong Chen\n,", "Hiroshi Mamitsuka\n,", "Shanfeng Zhu"], "publication": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "abstract": "Abstract\nWith the rapid development of biomedical sciences, a great number of documents have been published to report new scientific findings and advance the process of knowledge discovery. By the end of 2013, the largest biomedical literature database, MEDLINE, has indexed over 23 million abstracts. It is thus not easy for scientific professionals to find experts on a certain topic in the biomedical domain. In contrast to the existing services that use some ad hoc approaches, we developed a novel solution to biomedical expert finding, BMExpert, based on the language model. For finding biomedical experts, who are the most relevant to a specific topic query, BMExpert mines MEDLINE documents by considering three important factors: relevance of documents to the query topic, importance of documents, and associations between documents and experts. The performance of BMExpert was evaluated on a benchmark dataset, which was built by collecting the program committee members of ISMB in the past three years (2012-2014) on 14 different topics. Experimental results show that BMExpert outperformed three existing biomedical expert finding services: JANE, GoPubMed, and eTBLAST, with respect to both MAP (mean average precision) and P@50 (Precision). BMExpert is freely accessed at http://datamining-iip.fudan.edu.cn/service/BMExpert/.", "references": ["E. Sayers, T. Barrett, D. Benson, E. Bolton, S. Bryant, K. Canese, V. Chetvernin, D. Church, M. DiCuccio, S. Federhen, M. Feolo, L. Y. Geer, W. Helmberg, Yuri Kapustin, D. Landsman, D. J. Lipman, T. L. Madden, D. R. Maglott, V. Miller, I. Karsch-Mizrachi, J. Ostell, K. D. Pruitt, G. D. Schuler, E. Sequeira, S. T. Sherry, M. Shumway, K. Sirotkin, A. Souvorov, G. Starchenko, T. Tatusova, L. Wagner, E. Yaschenko, and J. Ye, \"Database resources of the national center for biotechnology information,\" Nucleic Acids Res., vol. 39, pp. D38-D51, 2011.", "A. Eaton, \"HubMed: A web-based biomedical literature search interface,\" Nucleic Acids Res., vol. 34, pp. W745-W747, 2006.", "A. Doms and M. Schroeder, \"GoPubMed: Exploring PubMed with the gene ontology,\" Nucleic Acids Res., vol. 33, pp. W783-W786, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TCBB.2015.2430338"}, {"title": "The Quest for Visual Interest", "authors": ["Mohammad Soleymani"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we report on identifying the underlying factors that contribute to the visual interest in digital photos. A set of 1005 digital photos covering different topics and of different qualities was collected from Flickr. Images were annotated by a pool of diverse participants on a crowdsourcing platform. 12 bipolar ratings were collected for each photo on 7-point semantic differential scale, including dimensions related to interest, emotions and image quality. Every image received 20 annotations from unique participants. The most important appraisals and visual attributes for visual interest in photos was identified. We found that intrinsic pleasantness, arousal, visual quality and coping potential are the most important factors contributing to visual interest in digital photos. We developed a system that automatically detects the important visual attributes from low level visual features and demonstrated their significance in predicting interest at individual level.", "references": ["S. L. Chu et al. The effect of familiarity on perceived interestingness of images. In IS&T/SPIE EI, 2013.", "L. R. Goldberg et al. The international personality item pool and the future of public-domain personality measures. J. Res. Per., 40(1):84--96, 2006.", "H. Grabner et al. Visual interestingness in image sequences. In ACM MM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806364"}, {"title": "Real-time Social Media Analytics through Semantic Annotation and Linked Open Data", "authors": ["Diana Maynard\n,", "Mark A. Greenwood\n,", "Ian Roberts\n,", "George Windsor\n,", "Kalina Bontcheva"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nThis paper describes an open source framework for analysing large volume social media content, which comprises semantic annotation, Linked Open Data, semantic search, dynamic result aggregation, and information visualisation. In particular, exploratory search and sense-making are supported through information visualisation interfaces, such as co-occurrence matrices, term clouds, treemaps, and choropleths. There is also an interactive semantic search interface (Prospector), where users can save, refine, and analyse the results of semantic search queries over time. These functionalities are presented in more detail in the context of analysing tweets from UK politicians and party candidates in the run up to the 2015 UK general election.", "references": ["C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. DBpedia -- a crystallization point for the web of data. Journal of Web Semantics: Science, Services and Agents on the World Wide Web, 7:154--165, 2009.", "K. Bontcheva, L. Derczynski, A. Funk, M. A. Greenwood, D. Maynard, and N. Aswani. TwitIE: An Open-Source Information Extraction Pipeline for Microblog Text. In Proceedings of the International Conference on Recent Advances in Natural Language Processing. Association for Computational Linguistics, 2013.", "H. Cunningham, V. Tablan, A. Roberts, and K. Bontcheva. Getting more out of biomedical documents with GATE's full lifecycle open source text analytics. PLoS Computational Biology, 9(2):e1002854, 02 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786500"}, {"title": "Patriot: delivering instant heart observation with a miniature wearable ECG and cloud platform", "authors": ["Athanasios Antoniou\n,", "Emil Stoyanov Valchinov\n,", "Ioannis Chatzigiannakis\n,", "Athanasios P. Kalogeras\n,", "Christos Alexakos\n,"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nHealthcare is expected to undergo a transformation in the near future thanks to wearable health monitoring that makes it possible to offer such services as ubiquitous monitoring of patients' physiological parameters and health condition. The continuous monitoring of vital patient signals has been primarily motivated by the need to put a barrier in ever increasing healthcare costs. Recent technological advances in miniaturized healthcare sensing devices, wireless communications, microelectronics and embedded systems have contributed towards this end. The PATRIOT system comprises a miniature, wearable, non-invasive, real time electrocardiography system alongside a relevant Cloud platform for the support of proactive personal health management of cardiology patients.", "references": ["Lubitz J., Cai L., Kramarow E., Lentzner H. 2003. Health, Life Expectancy, and Health Care Spending among the Elderly, N Engl J Med 349 (Sept. 2003) 1048--1055. DOI= http://dx.doi.org/10.1056/NEJMsa020614", "Pantelopoulos A., Bourbakis N.G. 2010. A Survey on Wearable Sensor-Based Systems for Health Monitoring and Prognosis, IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews. 40, 1 (Jan. 2010), 1--12. DOI= http://dx.doi.org/10.1109/TSMCC.2009.2032660", "Nademanee K., Intarachot V., Singh P. N., Josephson M. A., Singh B. N. 1986. Characteristics and clinical significance of silent myocardial ischemia in unstable angina, The American Journal of Cardiology. 58, 4 (Aug. 1986), B26-B33."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801992"}, {"title": "3d.graz.at: efficient online city model", "authors": ["Xiaoming Xu"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nWe show the procedure used in city of Graz, which converts the normal photogrammetric measurements and other data layers into 3d city model automatically. We use ArcGIS© online to organize the model into projects and publish with CityEngineViewer© to present the city model online with extendable functions, all for free! One practical way from 3d model building to online presentation is shown.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2778295"}, {"title": "Maturity Level Assessment in Software Testing in Small and Medium-Sized Enterprises of the State of Goias", "authors": ["Adailton F. Araujo\n,", "Cassio L. Rodrigues\n,", "Auri M.R. Vincenzi\n,", "Celso G. Camilo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nSoftware testing is an important component that leads to quality software production. This paper presents the results of a framework for assessing the level of maturity in Software Testing application in the context of Small and Medium-Sized Enterprises (SMEs) based on TMMi model. Our framework includes an evaluation questionnaire based on TMMi sub-practices, support tools with examples of artifacts required to ensure that the questionnaire is thoroughly completed, as well as an automated tool support for its application, enabling SMEs to carry out self-assessment. The framework was applied in ten companies and before the results presented, it can be concluded that the companies maturity in software testing is low and that the companies positively assessed the adequacy of the framework developed for the context of SMEs.", "references": ["M. Q. A. A., S. Ramachandram, and A. M. A. An evolutionary software product development process for small and medium enterprises (SMEs). pages 298-303. IEEE, Oct. 2008.", "A. F. Araujo, C. L. Rodrigues, A. M. R. Vincenzi, C. G. Camilo-Junior, and A. F. Silva. A Framework for Maturity Assessment in Software Testing for Small and Medium-Sized Enterprises. pages 225-230, 2013.", "J. Brodman and D. Johnson. What small businesses and small organizations say about the CMM. pages 331-340. IEEE Comput. Soc. Press, Aug. 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814127"}, {"title": "Generating Desktop and Mobile Web Pages from a Single SuperSQL Query", "authors": ["Kento Goto\n,", "Ryosuke Koshijima\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nRecently, a demand for a mobile-friendly web page is rising, but creating and maintaining separate sites for mobile and desktop is costly for web developers. At our laboratory, we have been designing and developing SuperSQL, an extension of SQL that can generate HTML files that contain values stored in RDBs. In this paper, we propose an approach to generate both mobile and desktop versions of a web page with just one SuperSQL query. We believe our approach can facilitate the laborious work of creating and maintaining separate sites for mobile and desktop environments.", "references": ["Motomichi Toyama. SuperSQL: An Extended SQL for Database Publishing and Presentation. Proceedings of ACM SIGMOD '98 International Conference on Management of Data. pp. 584-586, 1998.", "SuperSQL http://ssql.db.ics.keio.ac.jp", "Toshiyuki Seto, Takuhiro Nagafuji and Motomichi Toyama. Generating HTML Sources with TFE Enhanced SQL. ACM Symposium on Applied Computing. pp.96-100, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790789"}, {"title": "The Importance of Being Expert: Efficient Max-Finding in Crowdsourcing", "authors": ["Aris Anagnostopoulos\n,", "Luca Becchetti\n,", "Adriano Fazzone\n,", "Ida Mele\n,", "Matteo Riondato"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nCrowdsourcing is a computational paradigm whose distinctive feature is the involvement of human workers in key steps of the computation. It is used successfully to address problems that would be hard or impossible to solve for machines. As we highlight in this work, the exclusive use of nonexpert individuals may prove ineffective in some cases, especially when the task at hand or the need for accurate solutions demand some degree of specialization to avoid excessive uncertainty and inconsistency in the answers. We address this limitation by proposing an approach that combines the wisdom of the crowd with the educated opinion of experts. We present a computational model for crowdsourcing that envisions two classes of workers with different expertise levels. One of its distinctive features is the adoption of the threshold error model, whose roots are in psychometrics and which we extend from previous theoretical work. Our computational model allows to evaluate the performance of crowdsourcing algorithms with respect to accuracy and cost. We use our model to develop and analyze an algorithm for approximating the best, in a broad sense, of a set of elements. The algorithm uses naïve and expert workers to find an element that is a constant-factor approximation to the best. We prove upper and lower bounds on the number of comparisons needed to solve this problem, showing that our algorithm uses expert and naïve workers optimally up to a constant factor. Finally, we evaluate our algorithm on real and synthetic datasets using the CrowdFlower crowdsourcing platform, showing that our approach is also effective in practice.", "references": ["M. Aigner. Finding the maximum and minimum. Discrete Applied Mathematics, 74 (1): 1--12, 1997. http://www.sciencedirect.com/science/article/pii/S0166218X96000121.", "M. Ajtai, V. Feldman, A. Hassidim, and J. Nelson. Sorting and selection with imprecise comparisons. In Automata, Languages and Programming, volume 5555 of Lecture Notes in Computer Science, pages 37--48, 2009.", "S. Assaf and E. Upfal. Fault tolerant sorting networks. SIAM Journal on Discrete Mathematics, 4 (4): 472--480, 1991. 10.1137/0404042. URL http://epubs.siam.org/doi/abs/10.1137/0404042."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2723722"}, {"title": "Capturing News Stories Once, Retelling a Thousand Ways", "authors": ["José Luis Redondo García\n,", "Giuseppe Rizzo\n,", "Raphaël Troncy"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nWe live in a constantly evolving world where news stories and relevant facts are happening every moment. For each of those stories, numerous news articles, posts, and social media reactions are created, offering a multitude of viewpoints about what is happening around us. Many applications have tried to deal with this complexity from very different angles, targeting particular needs, reconstructing certain parts of the story, and exploiting certain visualization paradigms. In this paper, we identify those challenges and study how an adequate news story representation can effectively support the different phases of the news consumption process. We propose an innovative model called News Semantic Snapshot (NSS) that is designed to capture the entire context of a news item. This model can feed very different applications assisting the users before, during, and after the news story consumption. It formalizes a duality in the news annotations that distinguishes between representative entities and relevant entities, and considers different relevancy dimensions that are incorporated into the model in the form of concentric layers. Finally, we analyze the impact of this NSS on existing prototypes and how it can support future ones.", "references": ["E. Apostolidis, V. Mezaris, M. Sahuguet, and et. al. Automatic fine-grained hyperlinking of videos within a closed collection using scene seg mentation. In 22nd ACM International Conference on Multimedia, Orlando, USA, 2014.", "J. L. R. García, G. Rizzo, and R. Troncy. The Concentric Nature of News Semantic Snapshots. In 8th international Conference on Knowledge Capture (KCAP), 2015.", "V. Milicic, J. García, G. Rizzo, and R. Troncy. Tracking and Analyzing the 2013 Italian Election. In 10th Extended Semantic Web Conference (ESWC), Demo Track, pages 258--262, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2816951"}, {"title": "Sketching distributed sliding-window data streams", "authors": ["Odysseas Papapetrou\n,", "Minos Garofalakis\n,", "Antonios Deligiannakis"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWhile traditional data management systems focus on evaluating single, ad hoc queries over static data sets in a centralized setting, several emerging applications require (possibly, continuous) answers to queries on dynamic data that is widely distributed and constantly updated. Furthermore, such query answers often need to discount data that is \"stale\" and operate solely on a sliding window of recent data arrivals (e.g., data updates occurring over the last 24 h). Such distributed data streaming applications mandate novel algorithmic solutions that are both time and space efficient (to manage high-speed data streams) and also communication efficient (to deal with physical data distribution). In this paper, we consider the problem of complex query answering over distributed, high-dimensional data streams in the sliding-window model. We introduce a novel sketching technique (termed ECM-sketch) that allows effective summarization of streaming data over both time-based and count-based sliding windows with probabilistic accuracy guarantees. Our sketch structure enables point, as well as inner product, queries and can be employed to address a broad range of problems, such as maintaining frequency statistics, finding heavy hitters, and computing quantiles in the sliding-window model. Focusing on distributed environments, we demonstrate how ECM-sketches of individual, local streams can be composed to generate a (low-error) ECM-sketch summary of the order-preserving merging of all streams; furthermore, we show how ECM-sketches can be exploited for continuous monitoring of sliding-window queries over distributed streams. Our extensive experimental study with two real-life data sets validates our theoretical claims and verifies the effectiveness of our techniques. To the best of our knowledge, ours is the first work to address efficient, guaranteed-error complex query answering over distributed data streams in the sliding-window model.", "references": ["Alon, N., Matias, Y., Szegedy, M.: The space complexity of approximating the frequency moments. J. Comput. Syst. Sci. 58(1), 137---147 (1999)", "Arlitt, M., Jin, T.: A workload characterization study of the 1998 world cup web site. Network 14(3), 30---37 (2000)", "Busch, C., Tirthapura, S.: A deterministic algorithm for summarizing asynchronous streams over a sliding window. In: STACS, pp. 465---476 (2007)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0380-7"}, {"title": "Study of Heuristic IR Constraints Under Function Discovery Framework", "authors": ["Parantapa Goswami\n,", "Massih-Reza Amini\n,", "Eric Gaussier"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn this paper we investigate the effect of the heuristic IR constraints on IR term-document scoring functions within the recently proposed function discovery framework. In the earlier study the constraints were empirically validated as a whole. Moreover, only the group of form constraints was utilized and the other prominent group, the adjustment constraints, was not considered. In this work we will investigate all the constraints individually and study them with two different term frequency normalization, namely normalization scheme used in DFR models and relative term count normalization used in language models.", "references": ["G. Amati and C. van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Transactions on Information Systems (TOIS), 20(4):357--389, 2002.", "S. Clinchant and E. Gaussier. Information-based models for ad hoc IR. In Proceedings of the 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 234--241. ACM, 2010.", "S. Clinchant and E. Gaussier. Retrieval constraints and word frequency distributions a log-logistic model for IR. Information Retrieval, 14(1):5--25, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809479"}, {"title": "Collaborative Filtering Based on Semantic Distance Among Items", "authors": ["Salmo M.S. Júnior\n,", "Marcelo G. Manzato"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThis paper proposes a new method to compute the semantic distance among items in collaborative filtering based on k-nearest neighbors. This approach predicts the rating that a user u would give to an item i calculating the similarity between i and other items rated by u. This items' similarity is obtained using a semantic distance metric proposed in this paper. The technique exploits ontologies available on the Web through the Linked Open Data. This is possible because they have semantic descriptions, structured by links, that define a knowledge domain. The equation to calculate the semantic distance is an extension of a related work. We propose to assign weight to links to show the specificity of item's categories. Our proposal was evaluated with a movies dataset and it was shown that significant improvements can be achieved when compared to the baseline without weighted links.", "references": ["G. Antoniou and F. van Harmelen. A Semantic Web Primer. The MIT Press, 2004.", "C. Desrosiers and G. Karypis. A comprehensive survey of neighborhood-based recommendation methods. In F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors, Recommender Systems Handbook, pages 107--144. Springer US, 2011.", "T. Di Noia, R. Mirizzi, V. C. Ostuni, D. Romito, and M. Zanker. Linked open data to support content-based recommender systems. In I-SEMANTICS '12 Proceedings of the 8th International Conference on Semantic Systems, pages 1--8, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820466"}, {"title": "Accessing and reasoning with data from disparate data sources using modular ontologies and OBDA", "authors": ["Georgios Santipantakis\n,", "Konstantinos I. Kotis\n,", "George A. Vouros"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nThis paper proposes a distributed framework for accessing, integrating and reasoning with data from heterogeneous, disparate data sources. The proposed solution combines the E -- SHIQ modular ontology representation framework with the Ontop ontology-based data access (OBDA) technology. Distribution of knowledge allows the treatment of data from disparate sources in an autonomous manner, parallelization of operations, while it allows more efficient reasoning with the data.", "references": ["OWL 2 Web Ontology Language Profiles (2nd Ed.). http://www.w3.org/TR/owl2-profiles/#OWL_2_QL. Accessed: 2015-06-04.", "T. Bagosi, D. Calvanese, J. Hardi, S. Komla-Ebri, D. Lanti, M. Rezk, M. Rodriguez-Muro, M. Slusnys, and G. Xiao. The Ontop Framework for Ontology Based Data Access. In 8th CSWS, pages 67--77, 2014.", "C. Bizer. D2RQ - treating non-RDF databases as virtual RDF graphs. In 3rd ISWC, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814874"}, {"title": "DUMPLING: A Novel Dynamic Search Engine", "authors": ["Andrew Jie Zhou\n,", "Jiyun Luo\n,", "Hui Yang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this demo paper, we introduce a new search engine that supports Information Retrieval (IR) in a dynamic setting. A dynamic search engine distinguishes itself by handling rich interactions and temporal dependency among the queries in a session or for a task. The proposed search engine is called Dumpling, named after the development team's favorite food. It implements state-of-the-art dynamic search algorithms and provides: (i) a dynamic search toolkit by integrating the Query Change Retrieval Model (QCM) and the Win-win search algorithm; (ii) a user-friendly interface supporting side-by-side comparison of search results given by a state-of-the-art static search algorithm and the proposed dynamic search algorithms; (iii) and APIs for developers to apply the dynamic search algorithms to index and search over custom datasets. Dumpling is developed under the umbrella of a bigger project in the DARPA Memex program to crawl and search the dark web to support law enforcement and national security.", "references": ["D. Guan, S. Zhang, and H. Yang. Utilizing query change for session search. In SIGIR'13.", "E. Kanoulas, M. M. Hall, P. Clough, B. Carterette, and M. Sanderson. Overview of the trec 2011 session track. In TREC'11.", "J. Luo, S. Zhang, and H. Yang. Win-win search: Dual-agent stochastic game in session search. In SIGIR'14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767873"}, {"title": "Image Retrieval by Cross-Media Relevance Fusion", "authors": ["Jianfeng Dong\n,", "Xirong Li\n,", "Shuai Liao\n,", "Jieping Xu\n,", "Duanqing Xu\n,", "Xiaoyong Du"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHow to estimate cross-media relevance between a given query and an unlabeled image is a key question in the MSR-Bing Image Retrieval Challenge. We answer the question by proposing cross-media relevance fusion, a conceptually simple framework that exploits the power of individual methods for cross-media relevance estimation. Four base cross-media relevance functions are investigated, and later combined by weights optimized on the development set. With DCG25 of 0.5200 on the test dataset, the proposed image retrieval system secures the first place in the evaluation.", "references": ["Y. Bai, W. Yu, T. Xiao, C. Xu, K. Yang, W.-Y. Ma, and T. Zhao. Bag-of-words based deep neural network for image retrieval. In ACM MM, 2014.", "Q. Fang, H. Xu, R. Wang, S. Qian, T. Wang, J. Sang, and C. Xu. Towards msr-bing challenge: Ensemble of diverse models for image retrieval. In MSR-Bing IRC 2013 Workshop, 2013.", "R. Goulden, P. Nation, and J. Read. How large can a receptive vocabulary be? Applied Linguistics, 11(4):341--363, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2809929"}, {"title": "Cross-Platform Question Routing for Better Question Answering", "authors": ["Mossaab Bagdouri"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe last two decades have seen an increasing interest in the task of question answering (QA). Earlier approaches focused on automated retrieval and extraction models. Recent developments have more focus on community driven QA. This work addresses this task through cross-platform question routing. We study question types as well as the answers that can be gathered from different platforms. After developing new evaluation measures, we optimize for various constraints of the user needs. We consider models that work for the general public, before adapting them to some special demographics (Arab journalists).", "references": ["M. Bagdouri, D. W. Oard, and V. Castelli. CLIR for informal content in Arabic forum posts. CIKM, 2014.", "M. Hasanain, T. Elsayed, and W. Magdy. Identification of answer-seeking questions in Arabic microblogs. CIKM, 2014.", "A. Oeldorf-Hirsch, B. Hecht, M. R. Morris, J. Teevan, and D. Gergle. To search or to ask: The routing of information needs between traditional search engines and social networks. CSCW, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767849"}, {"title": "Dynamic Sorted Neighborhood Indexing for Real-Time Entity Resolution", "authors": ["Banda Ramadan\n,", "Peter Christen\n,", "Huizhi Liang\n,", "Ross W. Gayler"], "publication": "Journal of Data and Information Quality", "abstract": "Abstract\nReal-time Entity Resolution (ER) is the process of matching query records in subsecond time with records in a database that represent the same real-world entity. Indexing techniques are generally used to efficiently extract a set of candidate records from the database that are similar to a query record, and that are to be compared with the query record in more detail. The sorted neighborhood indexing method, which sorts a database and compares records within a sliding window, has been successfully used for ER of large static databases. However, because it is based on static sorted arrays and is designed for batch ER that resolves all records in a database rather than resolving those relating to a single query record, this technique is not suitable for real-time ER on dynamic databases that are constantly updated. We propose a tree-based technique that facilitates dynamic indexing based on the sorted neighborhood method, which can be used for real-time ER, and investigate both static and adaptive window approaches. We propose an approach to reduce query matching times by precalculating the similarities between attribute values stored in neighboring tree nodes. We also propose a multitree solution where different sorting keys are used to reduce the effects of errors and variations in attribute values on matching quality by building several distinct index trees. We experimentally evaluate our proposed techniques on large real datasets, as well as on synthetic data with different data quality characteristics. Our results show that as the index grows, no appreciable increase occurs in both record insertion and query times, and that using multiple trees gives noticeable improvements on matching quality with only a small increase in query time. Compared to earlier indexing techniques for real-time ER, our approach achieves significantly reduced indexing and query matching times while maintaining high matching accuracy.", "references": ["Georgy Maximovic Adelson-Velskii and Evgenii Mikhailovich Landis. 1962. An information organization algorithm. In Doklady Akademia Nauk SSSR, Vol. 146. 263--266.", "Akiko Aizawa and Keizo Oyama. 2005. A fast linkage detection scheme for multi-source information integration. In Proceedings of the International Workshop on Challenges in Web Information Retrieval and Integration (WIRI). IEEE, 30--39.", "Rohan Baxter, Peter Christen, and Tim Churches. 2003. A comparison of fast blocking methods for record linkage. In SIGKDD Workshops. ACM, 25--27."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816821"}, {"title": "Context-aware Point-of-Interest Recommendation Using Tensor Factorization with Social Regularization", "authors": ["Lina Yao\n,", "Quan Z. Sheng\n,", "Yongrui Qin\n,", "Xianzhi Wang\n,", "Ali Shemshadi\n,", "Qi He"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPoint-of-Interest (POI) recommendation is a new type of recommendation task that comes along with the prevalence of location-based social networks in recent years. Compared with traditional tasks, it focuses more on personalized, context-aware recommendation results to provide better user experience. To address this new challenge, we propose a Collaborative Filtering method based on Non-negative Tensor Factorization, a generalization of the Matrix Factorization approach that exploits a high-order tensor instead of traditional User-Location matrix to model multi-dimensional contextual information. The factorization of this tensor leads to a compact model of the data which is specially suitable for context-aware POI recommendations. In addition, we fuse users' social relations as regularization terms of the factorization to improve the recommendation accuracy. Experimental results on real-world datasets demonstrate the effectiveness of our approach.", "references": ["C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. In Twenty-Sixth AAAI Conference on Artificial Intelligence, 2012.", "C. Cheng, H. Yang, M. R. Lyu, and I. King. Where you like to go next: Successive point-of-interest recommendation. In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 2605-2611. AAAI Press, 2013.", "E. Cho, S. A. Myers, and J. Leskovec. Friendship and mobility: user movement in location-based social networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1082-1090. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767794"}, {"title": "Got Many Labels?: Deriving Topic Labels from Multiple Sources for Social Media Posts using Crowdsourcing and Ensemble Learning", "authors": ["Shuo Chang\n,", "Peng Dai\n,", "Jilin Chen\n,", "Ed H. Chi"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline search and item recommendation systems are often based on being able to correctly label items with topical keywords. Typically, topical labelers analyze the main text associated with the item, but social media posts are often multimedia in nature and contain contents beyond the main text. Topic labeling for social media posts is therefore an important open problem for supporting effective social media search and recommendation. In this work, we present a novel solution to this problem for Google+ posts, in which we integrated a number of different entity extractors and annotators, each responsible for a part of the post (e.g. text body, embedded picture, video, or web link). To account for the varying quality of different annotator outputs, we first utilized crowdsourcing to measure the accuracy of individual entity annotators, and then used supervised machine learning to combine different entity annotators based on their relative accuracy. Evaluating using a ground truth data set, we found that our approach substantially outperforms topic labels obtained from the main text, as well as naive combinations of the individual annotators. By accurately applying topic labels according to their relevance to social media posts, the results enables better search and item recommendation.", "references": ["O. Alonso, C. C. Marshall, and M. Najork. Are Some Tweets More Interesting Than Others?#HardQuestion. In Proceedings of the Symposium on Human-Computer Interaction and Information Retrieval - HCIR '13, pages 1--10, New York, New York, USA, Oct. 2013. ACM Press.", "H. Aradhye, G. Toderici, and J. Yagnik. Video2text: Learning to annotate video content. In Proceedings of the 2009 IEEE International Conference on Data Mining Workshops, ICDMW '09, pages 144--151, Washington, DC, USA, 2009. IEEE Computer Society.", "K. Bontcheva and D. Rout. Making sense of social media streams through semantics: a survey. Semantic Web."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2745401"}, {"title": "Semantic enrichment for adaptive expert search", "authors": ["Marco Pavan\n,", "Thebin Lee\n,", "Ernesto William De Luca"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nExpert finding and the identification of similar professionals are important tasks for many services provided by companies and institutions. Most of research works focus on a limited set of users, characterized by the same kind of main activities, e.g., researchers, or exploit external knowledge, such as predefined ontologies. An heterogeneous environment, with possible lack of information, and not well structured data, puts forward new challenges, to address the problem of adapting user profiling and consequently expert search. In this paper, we present a first attempt to create an expert search system to support users (such as researchers, students, authors) in finding experts to get in contact or to start a cooperation with in the field of textbook research. Hereby we semantically enrich user profiles building a Community Knowledge Graph (CKG) which defines relationships among users and related items. Furthermore, we present first experimental results that base on real users.", "references": ["F. Abel, Q. Gao, G. j. Houben, and K. Tao. Semantic enrichment of twitter posts for user profile construction on the social web. ESWC, June 2011.", "A. Al-Kouz, E. W. De Luca, and S. Albayrak. Latent semantic social graph model for expert discovery in facebook. IICS, June 2011.", "F. Cena, S. Likavec, and F. Osborne. Propagating user interests in ontology-based user model. In Artificial Intelligence Around Man and Beyond, volume 6934 of Lecture Notes in Computer Science, pages 299--311. September 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809621"}, {"title": "Prediction System of Bus Arrival Time Based on Historical Data Using Regression Models", "authors": ["Kassio R. Coquita\n,", "Arley R. R. Ristar\n,", "Adriano L. I. Oliveira\n,", "Patricia C. A. R. Tedesco"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIntelligent Transportation Systems are applications of information and communication technologies aimed at improving the transportation area. Providing information about bus arrival time on the bus stop is very important and useful to passengers and transit managers. This paper presents a proposed bus arrival time prediction system at the bus stop where user is located. For this, an experimental study on bus route named Campina do Barreto No. 722 in Recife-PE, was performed by comparing the regression model for Support Vector Machine (SVR) and the neural network Extreme Learning Machine (ELM) to estimate the time it takes to go through adjacent bus stops. The experiments were performed using the bus GPS log data in the metropolitan region of Recife, and the results showed that for this application the SVR significantly outperforms ELM.", "references": ["An, S.-H., Lee, B.-H., Shin, D-R. 2011. A Survey of Intelligent Transportation Systems. Communication Systems and Networks (CICSyN), 2011 Third International Conference, pp.332-337.", "Huang, G., Wang, D. H., Lan, Y. 2011. Extreme learning machines: a survey, em: International Journal of Machine Learning and Cybernetics, vol. 2, issue 1, p. 107-122.", "Pan, J., Dai, X., Xu, X., Li, Y. 2012. A Self-Learning Algorithm for Predicting Bus Arrival Time Based on Historical Data Model. Cloud Computing and Intelligent Systems (CCIS), IEEE 2nd International Conference, vol. 3, Hangzhou, p. 1112-1116."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814079"}, {"title": "Exploiting Matrix Dependency for Efficient Distributed Matrix Computation", "authors": ["Lele Yu\n,", "Yingxia Shao\n,", "Bin Cui"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nDistributed matrix computation is a popular approach for many large-scale data analysis and machine learning tasks. However existing distributed matrix computation systems generally incur heavy communication cost during the runtime, which degrades the overall performance. In this paper, we propose a novel matrix computation system, named DMac, which exploits the matrix dependencies in matrix programs for efficient matrix computation in the distributed environment. We decompose each matrix program into a sequence of operations, and reveal the matrix dependencies between operations in the program. We next design a dependency-oriented cost model to select an optimal execution strategy for each operation, and generate a communication efficient execution plan for the matrix computation program. To facilitate the matrix computation in distributed systems, we further divide the execution plan into multiple un-interleaved stages which can run in a distributed cluster with efficient local execution strategy on each worker. The DMac system has been implemented on a popular general-purpose data processing framework, Spark. The experimental results demonstrate that our techniques can significantly improve the performance of a wide range of matrix programs.", "references": ["BLAS. http://www.netlib.org/blas/.", "Hadoop. http://hadoop.apache.org/.", "LAPACK. http://www.netlib.org/lapack/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2723712"}, {"title": "Searching for Twitter Posts by Location", "authors": ["Ariana S. Minot\n,", "Andrew Heier\n,", "Davis King\n,", "Olga Simek\n,", "Nicholas Stanisha"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe microblogging service Twitter is an increasingly popular platform for sharing information worldwide. This motivates the potential to mine information from Twitter, which can serve as a valuable resource for applications such as event localization and location-specific recommendation systems. Geolocation of Twitter messages is integral to such applications. However, only a a small percentage of Twitter posts are accompanied by a GPS location. Recent works have begun exploring ways to estimate the unknown location of Twitter users based on the content of their posts and various available metadata. This presents interesting challenges for natural language processing and multi-objective optimization. We propose a new method for estimating the home location of users based on both the content of their posts and their social connections on Twitter. Our method achieves an accuracy of 77% within 10 km in exchange for a reduction in coverage of 76% with respect to techniques which only use social connections.", "references": ["Z. Cheng, J. Caverlee, and K. Lee. You Are Where You Tweet: A Content-Based Approach to Geo-Locating Twitter Users. In CIKM, pages 759--768, 2010.", "R. Compton, D. Jurgens, and D. Allen. Geotagging One Hundred Million Twitter Accounts with Total Variation Minimization. CoRR, abs/1404.7152, 2014.", "C. Fink, J. Kopecky, N. Bos, and M. Thomas. Mapping the Twitterverse in the Developing World: An Analysis of Social Media Use in Nigeria. volume 7227 of Lecture Notes in Computer Science, pages 164--171, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809480"}, {"title": "Sequential Testing for Early Stopping of Online Experiments", "authors": ["Eugene Kharitonov\n,", "Aleksandr Vorobev\n,", "Craig Macdonald\n,", "Pavel Serdyukov\n,", "Iadh Ounis"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline evaluation methods, such as A/B and interleaving experiments, are widely used for search engine evaluation. Since they rely on noisy implicit user feedback, running each experiment takes a considerable time. Recently, the problem of reducing the duration of online experiments has received substantial attention from the research community. However, the possibility of using sequential statistical testing procedures for reducing the time required for the evaluation experiments remains less studied. Such sequential testing procedures allow an experiment to stop early, once the data collected is sufficient to make a conclusion. In this work, we study the usefulness of sequential testing procedures for both interleaving and A/B testing. We propose modified versions of the O'Brien & Fleming and MaxSPRT sequential tests that are applicable for testing in the interleaving scenario. Similarly, for A/B experiments, we assess the usefulness of the O'Brien & Fleming test, as well as that of our proposed MaxSPRT-based sequential testing procedure. In our experiments on datasets containing 115 interleaving and 41 A/B testing experiments, we observe that considerable reductions in the average experiment duration can be achieved by using our proposed tests. In particular, for A/B experiments, the average experiment durations can be reduced by up to 66% in comparison with a single step test procedure, and by up to 44% in comparison with the O'Brien & Fleming test. Similarly, a marked relative reduction of 63% in the duration of the interleaving experiments can be achieved.", "references": ["K. Balog, L. Kelly, and A. Schuth. Head first: Living labs for ad-hoc search evaluation. In CIKM 2014.", "J. Bartroff, T. L. Lai, and M.-C. Shih. Sequential Experimentation in Clinical Trials: Design and Analysis, volume 298. Springer, 2012.", "O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):6, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767729"}, {"title": "Surpassing the Limit: Keyword Clustering to Improve Twitter Sample Coverage", "authors": ["Justin Sampson\n,", "Fred Morstatter\n,", "Ross Maciejewski\n,", "Huan Liu"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nSocial media services have become a prominent source of research data for both academia and corporate applications. Data from social media services is easy to obtain, highly structured, and comprises opinions from a large number of extremely diverse groups. The microblogging site, Twitter, has garnered a particularly large following from researchers by offering a high volume of data streamed in real time. Unfortunately, the methods in which Twitter selects data to disseminate through the stream are either vague or unpublished. Since Twitter maintains sole control of the sampling process, it leaves us with no knowledge of how the data that we collect for research is selected. Additionally, past research has shown that there are sources of bias present in Twitters dissemination process. Such bias introduces noise into the data that can reduce the accuracy of learning models and lead to bad inferences. In this work, we take an initial look at the efficiency of Twitter limit track as a sample population estimator. After that, we provide methods to mitigate bias by improving sample population coverage using clustering techniques.", "references": ["H. Achrekar, A. Gandhe, R. Lazarus, S.-H. Yu, and B. Liu. Predicting Flu Trends using Twitter Data. In INFOCOM, pages 702--707. IEEE, 2011.", "S. Asur and B. A. Huberman. Predicting the Future with Social Media. In WI-IAT, volume 1, pages 492--499. IEEE, 2010.", "I. Borg and P. J. Groenen. Modern Multidimensional Scaling: Theory and Applications. Springer Science & Business Media, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791030"}, {"title": "Learning user-defined, domain-specific relations: a situated case study and evaluation in plant science", "authors": ["Ana Lucic\n,", "Catherine Blake"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nAlthough methods exist to identify well-defined relations, such as is_a or part_of, existing tools rarely support a user who wants to define new, domain-specific relations. We conducted a situated case study in plant science and introduce four new domain-specific relations that are of interest to domain scientists but have not been explored in information science. Results show that precision varies between relations and ranges from 0.73 to 0.91 for the manufacturer location category, 0.89 and 0.93 for the seed donor-bank relation, 0.29 and 0.67 for the seed origin location, and 0.32 and 0.77 for the field experiment location. The manufacturer location category recall varies from 0.91 to 0.94, the seed bank-donor location recall ranges between 0.93 and 1, the seed origin relation from 0.33 to 0.82 while the field experiment location from 0.67 to 0.83 depending on the classifier and using a combination of lexical and syntactic features in the background.", "references": ["Systems that do allow relation and argument search, include MEDIE (http://www.nactem.ac.uk/medie/) and text runner (https://code.google.com/p/newsterp/wiki/TextRunner), but such systems do not provide support for user defined relations.", "Arighi, C. N., Roberts, P. M., Agarwal, S., Bhattacharya, S., Cesareni, G., Chatr-aryamontri, A., ... Wu, C. H. (2011). BioCreative III interactive task: an overview. BMC Bioinformatics, 12(Suppl 8), S4. doi:10.1186/1471-2105-12-S8-S4.", "Bloom, Benjamin S. (1956). Taxonomy of educational objectives; the classification of educational goals (1st ed.). New York,: Longmans, Green."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857103"}, {"title": "Proposal for Simplified Security Model for Small and Medium Business", "authors": ["Goncalo M. da Silva\n,", "Gliner Dias Alencar\n,", "Anderson Apolonio L. Queiroz"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe adoption of information security model, implementation of policies and fitness for any information security standard is rare for Small and Medium Enterprises (SMEs) because, often, the complexity of the rules. As these organizations contribute to much of the national economy, being the largest employers in Brazil, it was necessary to research ways to try to fill the gap. For this purpose the present study analyzed with real sample of 48 SMEs, through a questionnaire, which the vision of information security for SMEs and proposed a model simplifying controls 133 of ISO / IEC 27002 for just 22. This simplified model was , later also validated via questionnaire with ICT professionals in SMEs.", "references": ["Alencar, G. D.; Queiroz, A. A. L.; De Queiroz, R. J. G. B. (2013). Insiders: Um Fator Ativo na Segurança da Informação. In: IX Simpósio Brasileiro de Sistemas de Informação (SBSI'13), p. 61-72.", "Trendlabs. (2014) \"2Q 2012 Security Roundup\", http://www.trendmicro.com.br/cloud-content/us/pdfs/security-intelligence/reports/rpt-its-big-business-and-its-getting-personal.pdf. Acesso: 28 de Agosto de 2014.", "ABNT. (2005a) NBR ISO/IEC 17799: Tecnologia da informação: técnicas de segurança: código de prática para a gestão da segurança da informação."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814107"}, {"title": "TESE - An Information System for Management of Experimental Software Engineering Projects", "authors": ["Isaque Elcio de Souza\n,", "Paulo Henrique Lima Oliveira\n,", "Esdras Lins Bispo\n,", "Ana Carolina Gondim Inocencio\n,", "Paulo Afonso Parreira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe Experimental Software Engineering is one of the sub-areas of Software Engineering (SE) and the aim is to improve methods, techniques and tools ES, from experimental methods. An experimental project involves several steps and activities that must be carried out by the researcher and participant, generating large amounts documents. This paper deals with experimentation in software engineering, presenting a tool for management of experimental projects, called TESE (Tool for Experimental Software Engineering), the main difference is the provision of aid to its members in relation to the concepts of Experimental Software Engineering. Evaluation one tool with students and former students of Bachelor of Computer Science at the Federal University of Goias (Regional Jatai) was performed. For this, we used a questionnaire built on the model TAM (Technology Acceptance Model), in order to find out what the reviewers think about the usefulness and ease of use of TESE tool. The result was considered positive, as on average 80% of the evaluators agreed that the tool has good utility and ease of use.", "references": ["TRAVASSOS, G. G.; GUROV, D.; AMARAL, E. A. G. G. Introdução à Engenharia de Soft. Exp. UFRJ, 2002. Disponível em: ¿http://www2. ufpa.br/cdesouza/teaching/topes/4-ES-Experimental.pdf¿. Acesso em: Abril/2015.", "TRAVASSOS, G. H, SANTOS. P. S. M., MIAN, P. G., DIAS NETO A. C, BIOLCHINI, J. \"A Environment to Support Large Scale Experimentation in Software Engineering\", 13th IEEE International Conference on Engineering of Complex Computer Systems, 2008.", "CMMI. Capability maturity model integration. Software Engineering Institute, Carnegie Mellon University, Pittsburg, PA, Tech. Rep. SEI-2002-TR-012, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814147"}, {"title": "Asymmetric Minwise Hashing for Indexing Binary Inner Products and Set Containment", "authors": ["Anshumali Shrivastava\n,", "Ping Li"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMinwise hashing (Minhash) is a widely popular indexing scheme in practice. Minhash is designed for estimating set resemblance and is known to be suboptimal in many applications where the desired measure is set overlap (i.e., inner product between binary vectors) or set containment. Minhash has inherent bias towards smaller sets, which adversely affects its performance in applications where such a penalization is not desirable. In this paper, we propose asymmetric minwise hashing ({\\em MH-ALSH}), to provide a solution to this well-known problem. The new scheme utilizes asymmetric transformations to cancel the bias of traditional minhash towards smaller sets, making the final ``collision probability'' monotonic in the inner product. Our theoretical comparisons show that, for the task of retrieving with binary inner products, asymmetric minhash is provably better than traditional minhash and other recently proposed hashing algorithms for general inner products. Thus, we obtain an algorithmic improvement over existing approaches in the literature. Experimental evaluations on four publicly available high-dimensional datasets validate our claims. The proposed scheme outperforms, often significantly, other hashing algorithms on the task of near neighbor retrieval with set containment. Our proposal is simple and easy to implement in practice.", "references": ["P. Agrawal, A. Arasu, and R. Kaushik. On indexing error-tolerant set containment. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of data, pages 927--938. ACM, 2010.", "A. Andoni and P. Indyk. E2lsh: Exact euclidean locality sensitive hashing. Technical report, 2004.", "Y. Bachrach, Y. Finkelstein, R. Gilad-Bachrach, L. Katzir, N. Koenigstein, N. Nice, and U. Paquet. Speeding up the xbox recommender system using a euclidean transformation for inner-product spaces. In RecSys, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741285"}, {"title": "Understanding usage states on mobile devices", "authors": ["Chakajkla Jesdabodi\n,", "Walid Maalej"], "publication": "UbiComp '15: Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nNowadays, mobile apps are used for nearly every situation: for planning the day, communicating with colleagues, ordering goods, or entertaining and socializing. To understand users expectations in each situation and to provide context-aware services, researchers and app vendors started to capture users' interaction with the smartphone and to model user's behavior. This paper reports on a behavioral study based on app usage data logged over one year and the corresponding apps descriptions from the app store. Using Topic Modeling and clustering techniques, we segmented the usage data into meaningful clusters that correspond to different \"states\", in which users normally use their smartphone, e.g. socializing or consuming media. Researchers and app-vendors can use the insights from our work to improve their contextual recommendation techniques and the overall usage experience.", "references": ["Rakesh Agrawal and Ramakrishnan Srikant. 1994. Fast Algorithms for Mining Association Rules in Large Databases. In Proceedings of 20th International Conference on Very Large Data Bases (VLDB'94). 487--499.", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research 3 (2003), 993--1022. http://www.jmlr.org/papers/v3/blei03a.html", "Matthias Böhmer, Brent Hecht, Johannes Schöning, Antonio Krüger, and Gernot Bauer. 2011. Falling asleep with Angry Birds, Facebook and Kindle: a large scale study on mobile application usage. In Proceedings of the 13th Conference on Human-Computer Interaction with Mobile Devices and Services. 47--56."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750858.2805837"}, {"title": "Selective K-means Tree Search", "authors": ["Tuan Anh Nguyen\n,", "Yusuke Matsui\n,", "Toshihiko Yamasaki\n,", "Kiyoharu Aizawa"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn object recognition and image retrieval, an inverted indexing method is used to solve the approximate nearest neighbor search problem. In these tasks, inverted indexing provides a nonexhaustive solution to large-scale search. However, a problem of previous inverted indexing methods is that a large-scale inverted index is required to achieve a high search recall rate. In this study, we address the problem of reducing the time required to build an inverted index without degrading the search accuracy and speed. Thus, we propose a selective k-means tree search method that combines the power of both hierarchical k-means tree and selective nonexhaustive search. Experiments based on approximate nearest neighbor search using a large dataset comprising one billion SIFT features showed that the hierarchical inverted file based on the selective k-means tree method could be built six times faster, while obtaining almost the same recall and search speed as the state-of-the-art inverted indexing methods.", "references": ["A. Babenko and V. Lempitsky. The inverted multi-index. IEEE Trans. Pattern Anal. Mach. Intell., PP(99):1--1, 2014.", "M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In Proc. SCG, pages 253--262. ACM, 2004.", "G. Hamerly. Making k-means even faster. In SDM, pages 130--140, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806353"}, {"title": "Bundling Centre for Landmark Image Discovery", "authors": ["Qian Zhang\n,", "Guoping Qiu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper introduces a novel method to efficiently discover/cluster landmark images in large image collection. We consider each cluster as a combination of several sub-clusters, which is composed of images taken from different view points of the identical landmark. For each sub-cluster, we find its local centre represented by a group of similar images, and define it as the bundling centre (BC). We therefore start the image discovery/clustering by identifying the BCs and accomplish the task by efficiently growing and merging those sub-clusters represented by different BCs. In our proposed method, we use min-hash based method to build a sparse graph so as to avoid the time-consuming full-scale exhaustive pairwise image matching. Based on the information provided by the sparse graph, BCs are identified as local dense neighbors sharing high intra-similarity. We have also proposed a weighted voting method to efficiently grow these BCs with high accuracy. More importantly, the fixed local centres can ensure each sub-cluster contains identical landmark and generate result with high precision. In addition, compared to a single representative (iconic) image, the group of similar images obtained by each BC can provide more comprehensive cluster information and, thus, overcome the problem of low recall caused by information lost during visual word quantization. We present experimental results on two landmark datasets and show that, without query expansion, our method can boost landmark image discovery/clustering performances of state of the art techniques.", "references": ["Y. Cao, C. Wang, Z. Li, L. Zhang, and L. Zhang. Spatial-bag-of-features. 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 3352--3359, June 2010.", "O. Chum and J. Matas. Large-scale discovery of spatially related images. IEEE transactions on pattern analysis and machine intelligence, 32(2):371--7, Feb. 2010.", "O. Chum, J. Matas, and J. Kittler. Locally optimized RANSAC. Pattern Recognition, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749295"}, {"title": "An Efficient and Scalable MetaFeature-based Document Classification Approach based on Massively Parallel Computing", "authors": ["Sérgio Canuto\n,", "Marcos Gonçalves\n,", "Wisllay Santos\n,", "Thierson Rosa\n,", "Wellington Martins"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe unprecedented growth of available data nowadays has stimulated the development of new methods for organizing and extracting useful knowledge from this immense amount of data. Automatic Document Classification (ADC) is one of such methods, that uses machine learning techniques to build models capable of automatically associating documents to well-defined semantic classes. ADC is the basis of many important applications such as language identification, sentiment analysis, recommender systems, spam filtering, among others. Recently, the use of meta-features has been shown to substantially improve the effectiveness of ADC algorithms. In particular, the use of meta-features that make a combined use of local information (through kNN-based features) and global information (through category centroids) has produced promising results. However, the generation of these meta-features is very costly in terms of both, memory consumption and runtime since there is the need to constantly call the kNN algorithm. We take advantage of the current manycore GPU architecture and present a massively parallel version of the kNN algorithm for highly dimensional and sparse datasets (which is the case for ADC). Our experimental results show that we can obtain speedup gains of up to 15x while reducing memory consumption in more than 5000x when compared to a state-of-the-art parallel baseline. This opens up the possibility of applying meta-features based classification in large collections of documents, that would otherwise take too much time or require the use of an expensive computational platform.", "references": ["Y.-S. Chang, R.-K. Sheu, S.-M. Yuan, and J.-J. Hsu. Scaling database performance on gpus. Information Systems Frontiers, 14(4):909--924, 2012.", "H. Chen and T. K. Ho. Evaluation of decision forests on text categorization. In Proc. SPIE Conf. Document Recognition and Retrieval, pages 191--199, 2000.", "S. Dzeroski and B. Zenko. Is combining classifiers with stacking better than selecting the best one? Machine Learning, 54(3):255--273, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767743"}, {"title": "EFQ: why-not answer polynomials in action", "authors": ["Nicole Bidoit\n,", "Melanie Herschel\n,", "Katerina Tzompanaki"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nOne important issue in modern database applications is supporting the user with efficient tools to debug and fix queries because such tasks are both time and skill demanding. One particular problem is known as Why-Not question and focusses on the reasons for missing tuples from query results. The EFQ platform demonstrated here has been designed in this context to efficiently leverage Why-Not Answers polynomials, a novel approach that provides the user with complete explanations to Why-Not questions and allows for automatic, relevant query refinements.", "references": ["A. Baid, W. Wu, C. Sun, A. Doan, and J. F. Naughton. On debugging Non-Answers in keyword search systems. In EDBT, 2015.", "N. Bidoit, M. Herschel, and K. Tzompanaki. Immutably answering Why-Not questions for equivalent conjunctive queries. In TAPP, 2014.", "N. Bidoit, M. Herschel, and K. Tzompanaki. Query-based Why-Not provenance with Nedexplain. In EDBT, pages 145--156, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824116"}, {"title": "The RAMCloud Storage System", "authors": ["John Ousterhout\n,", "Arjun Gopalan\n,", "Ashish Gupta\n,", "Ankita Kejriwal\n,", "Collin Lee\n,", "Behnam Montazeri\n,", "Diego Ongaro\n,", "Seo Jin Park\n,", "Henry Qin\n,"], "publication": "ACM Transactions on Computer Systems", "abstract": "Abstract\nRAMCloud is a storage system that provides low-latency access to large-scale datasets. To achieve low latency, RAMCloud stores all data in DRAM at all times. To support large capacities (1PB or more), it aggregates the memories of thousands of servers into a single coherent key-value store. RAMCloud ensures the durability of DRAM-based data by keeping backup copies on secondary storage. It uses a uniform log-structured mechanism to manage both DRAM and secondary storage, which results in high performance and efficient memory usage. RAMCloud uses a polling-based approach to communication, bypassing the kernel to communicate directly with NICs; with this approach, client applications can read small objects from any RAMCloud storage server in less than 5μs, durable writes of small objects take about 13.5μs. RAMCloud does not keep multiple copies of data online; instead, it provides high availability by recovering from crashes very quickly (1 to 2 seconds). RAMCloud’s crash recovery mechanism harnesses the resources of the entire cluster working concurrently so that recovery performance scales with cluster size.", "references": ["Ars Technica. 2013. Memory That Never Forgets: Non-Volatile DIMMs Hit the Market. Retrieved July 2015, from http://arstechnica.com/information-technology/2013/04/memory-that-never-forgets-non-volatile-dimms-hit-the-market/.", "Berk Atikoglu, Yuehai Xu, Eitan Frachtenberg, Song Jiang, and Mike Paleczny. 2012. Workload analysis of a large-scale key-value store. In Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS’12). ACM, New York, NY, 53--64. DOI:http://dx.doi.org/10.1145/2254756.2254766", "Yossi Azar, Andrei Z. Broder, Anna R. Karlin, and Eli Upfal. 1994. Balanced allocations (extended abstract). In Proceedings of the 26th ACM Symposium on Theory of Computing (STOC’94). ACM, New York, NY, 593--602. DOI:http://dx.doi.org/10.1145/195058.195412"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806887"}, {"title": "Semantic Tagging of Mathematical Expressions", "authors": ["Pao-Yu Chien\n,", "Pu-Jen Cheng"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSemantic tagging of mathematical expressions (STME) gives semantic meanings to tokens in mathematical expressions. In this work, we propose a novel STME approach that relies on neither text along with expressions, nor labelled training data. Instead, our method only requires a mathematical grammar set. We point out that, besides the grammar of mathematics, the special property of variables and user habits of writing expressions help us understand the implicit intents of the user. We build a system that considers both restrictions from the grammar and variable properties, and then apply an unsupervised method to our probabilistic model to learn the user habits. To evaluate our system, we build large-scale training and test datasets automatically from a public math forum. The results demonstrate the significant improvement of our method, compared to the maximum-frequency baseline. We also create statistics to reveal the properties of mathematics language.", "references": ["M. Adeel, H. S. Cheung, and S. H. Khiyal. Math go! prototype of a content based mathematical formula search engine. Journal of Theoretical & Applied Information Technology, 4(10):1002--1012, 2008.", "J. K. Baker. Trainable grammars for speech recognition. The Journal of the Acoustical Society of America, 1979.", "J. Cocke and J. T. Schwartz. Programming languages and their compilers: Preliminary notes. Courant Institute of Mathematical Sciences, New York University, 1970."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741108"}, {"title": "Extracting news text from web pages: an application for the visually impaired", "authors": ["Erik Lundgren\n,", "Panagiotis Papapetrou\n,", "Lars Asker"], "publication": "PETRA '15: Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nApart from the actual content, web pages contain several other components (referred to as boilerplate text) that describes how, and in what context the content should be displayed. We show how content bearing text can be efficiently separated from boilerplate text using a random forest classifier. We compare the performance with another state-of-the-art method for boilerplate detection that uses a decision tree classifier and shallow features extracted from the text. The result is a general improvement using the random forest classifier for both classifying problems analyzed, significantly so for the more complex problem. We also show that a small increase in feature set range can lead to even further improved accuracy. The conclusion is that random forest classification can achieve significantly higher accuracy rates than at least one of the current state-of-the-art methods for content extraction. The results can improve content extraction methods for a variety of applications, including search engine optimization and making the web more accessible for the blind or visually impaired.", "references": ["J. Ali, R. Khan, N. Ahmad, and I. Maqsood. Random forests and decision trees. International Journal of Computer Science Issues (IJCSI), 9(5), 2012.", "Z. Bar-Yossef and S. Rajagopalan. Template detection via data mining and its applications. In Proceedings of the 11th international conference on World Wide Web, pages 580--591. ACM, 2002.", "L. Breiman. Random forests. Machine learning, 45(1):5--32, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2769493.2769573"}, {"title": "Question Classification by Approximating Semantics", "authors": ["Guangyu Feng\n,", "Kun Xiong\n,", "Yang Tang\n,", "Anqi Cui\n,", "Jing Bai\n,", "Hang Li\n,", "Qiang Yang\n,", "Ming Li"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nA central task of computational linguistics is to decide if two pieces of texts have similar meanings. Ideally, this depends on an intuitive notion of semantic distance. While this semantic distance is most likely undefinable and uncomputable, in practice it is approximated heuristically, consciously or unconsciously. In this paper, we present a theory, and its implementation, to approximate the elusive semantic distance by the well-defined information distance. It is mathematically proven that any computable approximation of the intuitive concept of semantic distance is \"covered\" by our theory. We have implemented our theory to question answering (QA) and performed experiments based on data extracted from over 35 million question-answer pairs. Experiments demonstrate that our initial implementation of the theory produces convincingly fewer errors in classification compared to other academic models and commercial systems.", "references": ["C. H. Bennett, P. G acs, M. Li, P. M. Vit anyi, and W. H. Zurek. Information distance. IEEE Transactions on Information Theory, 44(4):1407--1423, 1998.", "F. Bu, X. Zhu, Y. Hao, and X. Zhu. Function-based question classification for general QA. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1119--1128, 2010.", "F. Bu, X.-Y. Zhu, and M. Li. A new multiword expression metric and its applications. Journal of Computer Science and Technology, 26(1):3--13, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2745403"}, {"title": "Q-OPT: Self-tuning Quorum System for Strongly Consistent Software Defined Storage", "authors": ["Maria Couceiro\n,", "Gayana Chandrasekara\n,", "Manuel Bravo\n,", "Matti Hiltunen\n,", "Paolo Romano\n,", "Luís Rodrigues"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nThis paper presents Q-OPT, a system for automatically tuning the configuration of quorum systems in strongly consistent Software Defined Storage (SDS) systems. Q-OPT is able to assign different quorum systems to different items and can be used in a large variety of settings, including systems supporting multiple tenants with different profiles, single tenant systems running applications with different requirements, or systems running a single application that exhibits non-uniform access patterns to data. Q-OPT supports automatic and dynamic reconfiguration, using a combination of complementary techniques, including top-k analysis to prioritise quorum adaptation, machine learning to determine the best quorum configuration, and a non-blocking quorum reconfiguration protocol that preserves consistency during reconfiguration. Q-OPT has been implemented as an extension to one of the most popular open-source SDS, namely Openstack's Swift.", "references": ["M. Aguilera, I. Keidar, D. Malkhi, and A. Shraer. Dynamic atomic storage without consensus. In Proc. PODC 2009, pages 17--25. ACM, 2009.", "R. Bahati, M. Bauer, and E. Vieira. Policy-driven autonomic management of multi-component systems. In Proc. CASCON '07, pages 137--151. IBM Corp., 2007.", "P. Bailis, S. Venkataraman, M. J. Franklin, J. M. Hellerstein, and I. Stoica. Probabilistically bounded staleness for practical partial quorums. Proc. VLDB Endow., 5(8):776--787, Apr. 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814809"}, {"title": "Multi-View Visual Recognition of Imperfect Testing Data", "authors": ["Qilin Zhang\n,", "Gang Hua"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nA practical yet under-explored problem often encountered by multimedia researchers is the recognition of imperfect testing data, where multiple sensing channels are deployed but interference or transmission distortion corrupts some of them. Typical cases of imperfect testing data include missing features and feature misalignments. To address these challenges, we choose the latent space model and introduce a new similarity learning canonical-correlation analysis (SLCCA) method to capture the semantic consensus between views. The consensus information is preserved by projection matrices learned with modified canonical-correlation analysis (CCA) optimization terms with new, explicit class-similarity constraints. To make it computationally tractable, we propose to combine a practical relaxation and an alternating scheme to solve the optimization problem. Experiments on four challenging multi-view visual recognition datasets demonstrate the efficacy of the proposed method.", "references": ["A. Argyriou, T. Evgeniou, M. Pontil, A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. In Machine Learning. press, 2007.", "A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh annual conference on Computational learning theory, pages 92--100. ACM, 1998.", "L. Bo, X. Ren, and D. Fox. Unsupervised feature learning for rgb-d based object recognition. In Experimental Robotics, pages 387--402. Springer, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806224"}, {"title": "Sameness: an experiment in code search", "authors": ["Lee Martie\n,", "André van der Hoek"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nTo date, most dedicated code search engines use ranking algorithms that focus only on the relevancy between the query and the results. In practice, this means that a developer may receive search results that are all drawn from the same project, all implement the same algorithm using the same external library, or all exhibit the same complexity or size, among other possibilities that are less than ideal. In this paper, we propose that code search engines should also locate both diverse and concise (brief but complete) sets of code results. We present four novel algorithms that use relevance, diversity, and conciseness in ranking code search results. To evaluate these algorithms and the value of diversity and conciseness in code search, twenty-one professional programmers were asked to compare pairs of top ten results produced by competing algorithms. We found that two of our new algorithms produce top ten results that are strongly preferred by the programmers.", "references": ["\"About WordNet - WordNet - About WordNet.\" {Online}. Available: http://wordnet.princeton.edu/wordnet/. {Accessed: 14-Feb-2015}.", "\"Apache Lucene - Apache Solr.\" {Online}. Available: http://lucene.apache.org/solr/. {Accessed: 14-Feb-2015}.", "\"Code Search · GitHub.\" {Online}. Available: https://github.com/search. {Accessed: 14-Feb-2015}."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820530"}, {"title": "Session details: WSREST 2015", "authors": ["Ruben Verborgh\n,", "Thomas Steiner\n,", "Carlos Pedrinaci"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3261080"}, {"title": "Architecting a Persistent and Reliable Configuration Management System", "authors": ["Dmitry Duplyakin\n,", "Matthew Haney\n,", "Henry Tufo"], "publication": "ScienceCloud '15: Proceedings of the 6th Workshop on Scientific Cloud Computing", "abstract": "ABSTRACT\nStreamlined configuration management plays a significant role in modern, complex distributed systems. Via mechanisms that promote consistency, repeatability, and transparency, configuration management systems (CMSes) address complexity and aim to increase the efficiency of administrative procedures, including deployment and failure recovery scenarios. Considering the importance of minimizing disruptions in these systems, we design an architecture that increases persistency and reliability of infrastructure management. We present our architecture in the context of hybrid, cluster-cloud environments and describe our highly available implementation that builds upon the open source CMS called Chef and infrastructure-as-a-service cloud resources from Amazon Web Services. We demonstrate how we enabled a smooth transition from the pre-existing single-server configuration to the proposed highly available management system. We summarize our experience with managing a 20-node Linux cluster using this implementation. Our analysis of utilization and cost of necessary cloud resources indicates that the designed system is a low-cost alternative to acquiring additional physical hardware for hardening cluster management. We also highlight the prototype's security and manageability features that are suitable for larger, production-ready deployments.", "references": ["B. Schroeder and G. Gibson, 'A Large-Scale Study of Failures in High-Performance Computing Systems', IEEE Transactions on Dependable and Secure Computing, vol. 7, no. 4, pp. 337--350, Jan. 2010.", "K. Yamamoto, A. Uno, H. Murai, T. Tsukamoto, F. Shoji, S. Matsui, R. Sekizawa, F. Sueyasu, H. Uchiyama, M. Okamoto, N. Ohgushi, K. Takashina, D. Wakabayashi, Y. Taguchi, and M. Yokokawa, 'The K computer Operations: Experiences and Statistics', Procedia Computer Science, vol. 29, pp. 576--585, Jan. 2014.", "P. Marshall, H. Tufo, K. Keahey, D. LaBissoniere, and M. Woitaszek, 'A Large-Scale Elastic Environment for Scientific Computing',Communications in Computer and Information Science, pp. 112--126, Jan. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2755644.2755647"}, {"title": "DISYS: an intelligent system for personalized nutritional recommendations in restaurants", "authors": ["Dimitris Ntalaperas\n,", "Efthimios Bothos\n,", "Konstantinos Perakis\n,", "Babis Magoutas\n,", "Gregoris Mentzas"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn modern urban lifestyles the consumption of prepared food in restaurants and fast foods is increasing constantly and is becoming a habit among citizens. One side effect of this way of life concerns the increase of the Body Mass Index because citizens tend to choose more foods with high amounts of energy, fats and saturated fats and less healthy foods such as vegetables and fruits. In this paper we describe an intelligent application called DISYS that aims to offer personalized information to consumers when visiting a restaurant in order to support them to select a dish or a meal that is within their preferences but at the same time is healthy for them and in line with their dietary targets and their health conditions. DISYS is operated by restaurant managers who configure the meals and dishes their establishment offers, as well as the nutritional characteristics of each meal. Moreover, dieticians can support their customers by analysing their actions and interactions with the DISYS application with respect to food consumption habits.", "references": ["Kant, Ashima K., and Barry I. Graubard. 2004. Eating out in America, 1987--2000: trends and nutritional correlates. Preventive medicine, 38, 2, 243--249.", "National Restaurant Association. 2013. On the menu: Restaurant Nutrition Initiatives. Nutrition Report. Retrieved May 22, 2015 from https://www.restaurant.org/getattachment/Industry-Impact/Food-Healthy-Living/Nutrition-Report_Final_low.pdf", "Wagner, Juergen, Gijs Geleijnse, and Aart van Halteren. 2011. Guidance and support for healthy food preparation in an augmented kitchen. In Proceedings of the 2011 Workshop on Context-awareness in Retrieval and Recommendation, ACM, 47--50."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801997"}, {"title": "Session details: Main Track - Management, Governance, and Government", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252433"}, {"title": "Brands in NewsStand: spatio-temporal browsing of business news", "authors": ["Ahmed Abdelkader\n,", "Emily Hand\n,", "Hanan Samet"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nThe NewsStand system enables the use of a map query interface to retrieve news articles associated with the principal locations that they mention collected as a result of monitoring the output of over 10,000 RSS news feeds, made available within minutes of publication. NewsStand has been enhanced to allow using the map query interface to access other information associated with the articles such as photos and videos, as well as names of people and diseases mentioned in these articles. Here we report on our efforts to enhance NewsStand to display the names of brands and to the articles mentioning them. The challenges in identifying interesting brand mentions are discussed.", "references": ["S. Bird. Nltk: the natural language toolkit. In Proc. COLING/ACL on Interactive Presentation Sessions, pages 69--72, Jul. 2006.", "C. Esperança and H. Samet. Experience with SAND/Tcl: a scripting tool for spatial databases. JVLC, 13(2):229--255, Apr. 2002.", "J. R. Finkel, T. Grenager, and C. Manning. Incorporating non-local information into information extraction systems by gibbs sampling. In Proc 43rd Annual Meeting on Association for Computational Linguistics, pages 363--370, Jun. 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820795"}, {"title": "QOCO: a query oriented data cleaning system with oracles", "authors": ["Moria Bergman\n,", "Tova Milo\n,", "Slava Novgorodov\n,", "Wang-Chiew Tan"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nAs key decisions are often made based on information contained in a database, it is important for the database to be as complete and correct as possible. For this reason, many data cleaning tools have been developed to automatically resolve inconsistencies in databases. However, data cleaning tools provide only best-effort results and usually cannot eradicate all errors that may exist in a database. Even more importantly, existing data cleaning tools do not typically address the problem of determining what information is missing from a database.\nTo tackle these problems, we present QOCO, a novel query oriented cleaning system that leverages materialized views that are defined by user queries as a trigger for identifying the remaining incorrect/missing information. Given a user query, QOCO interacts with domain experts (which we model as oracle crowds) to identify potentially wrong or missing answers in the result of the user query, as well as determine and correct the wrong data that is the cause for the error(s). We will demonstrate QOCO over a World Cup Games database, and illustrate the interaction between QOCO and the oracles. Our demo audience will play the role of oracles, and we show how QOCO's underlying operations and optimization mechanisms can effectively prune the search space and minimize the number of questions that need to be posed to accelerate the cleaning process.", "references": ["M. Bergman, T. Milo, S. Novgorodov, and W. Tan. Query-oriented data cleaning with oracles. In ACM SIGMOD, 2015.", "M. Bilenko and R. J. Mooney. Adaptive duplicate detection using learnable string similarity measures. KDD, pages 39--48, 2003.", "P. Buneman, J. Cheney, W. C. Tan, and S. Vansummeren. Curated databases. In ACM PODS, pages 1--12, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824096"}, {"title": "Multi-Aspect Collaborative Filtering based on Linked Data for Personalized Recommendation", "authors": ["Han-Gyu Ko\n,", "Joo-Sik Son\n,", "In-Young Ko"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSince users often consider more than one aspect when they choose an item, relevant researches introduced multi-criteria recommender systems and showed that multi-criteria ratings add values to the existing CF-based recommender systems to provide more accurate recommendation results to users. However, all the previous works require multi-criteria ratings given by users explicitly while most of the existing datasets such as Netflix and MovieLens are a single criterion. Therefore, to take advantage of multi-criteria recommendation, there must be a way to extract necessary aspects and analyze users' preferences on those aspects from the given single-criterion type of dataset. In this paper, we propose an approach of utilizing semantic information of items to extract essential aspects to perform multi-aspect collaborative filtering to recommend users with items in a personalized manner.", "references": ["Adomavicius, Gediminas, and YoungOk Kwon. \"New recommendation techniques for multicriteria rating systems.\" IEEE Intelligent Systems 22.3 (2007). 48--55.", "Manouselis, Nikos, and Constantina Costopoulou. \"Experimental analysis of design choices in multiattribute utility collaborative filtering.\" International Journal of Pattern Recognition and Artificial Intelligence 21.02 (2007): 311--331.", "Adomavicius, Gediminas, Nikos Manouselis, and YoungOk Kwon. \"Multi-criteria recommender systems.\" Recommender systems handbook. Springer US, 2011. 769--803."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742780"}, {"title": "Counterfactual Estimation and Optimization of Click Metrics in Search Engines: A Case Study", "authors": ["Lihong Li\n,", "Shunbao Chen\n,", "Jim Kleban\n,", "Ankur Gupta"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOptimizing an interactive system against a predefined online metric is particularly challenging, especially when the metric is computed from user feedback such as clicks and payments. The key challenge is the counterfactual nature: in the case of Web search, any change to a component of the search engine may result in a different search result page for the same query, but we normally cannot infer reliably from search log how users would react to the new result page. Consequently, it appears impossible to accurately estimate online metrics that depend on user feedback, unless the new engine is actually run to serve live users and compared with a baseline in a controlled experiment. This approach, while valid and successful, is unfortunately expensive and time-consuming. In this paper, we propose to address this problem using causal inference techniques, under the contextual-bandit framework. This approach effectively allows one to run potentially many online experiments offline from search log, making it possible to estimate and optimize online metrics quickly and inexpensively. Focusing on an important component in a commercial search engine, we show how these ideas can be instantiated and applied, and obtain very promising results that suggest the wide applicability of these techniques.", "references": ["Ricardo Baeza-Yates and Berthier Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology behind Search. Addison-Wesley Professional, 2nd edition, 2011.", "Nicholas J. Belkin. Some(what) grand challenges for information retrieval. SIGIR Forum, 42(1):47--54, 2008.", "Alina Beygelzimer and John Langford. The offset tree for learning with partial labels. In KDD, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742562"}, {"title": "A fuzzy Bayesian approach to integrate user and item based collaborating filtering for enhanced recommendations", "authors": ["Vibhor Kant\n,", "Pragya Dwivedi"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nMemory-based collaborative filtering (CF) techniques have been widely implemented for predicting ratings to unseen items by aggregating ratings of similar users or items in recommender systems (RS). Usually, sufficient ratings from similar users or similar items are not available in the rating matrix, due to the data sparsity problem. Further, these techniques suffer from correlation based problems inherent in used similarity measures. Consequently, higher prediction accuracy cannot be achieved. In this paper, we propose the use of fuzzy Naïve Bayesian (FNB) classifier for user based CF and item based CF for implicitly computing similarity between users as well as items on the basis of conditional probabilities and develop fuzzy Naïve Bayesian classifier to user based CF (FNB-UB-CF) and item based CF (FNB-IB-CF). We further develop a hybrid RS (FNB-UB-IB-CF) by combining the proposed FNB-UB-CF and FNB-IB-CF. Their combinations would be helpful in alleviating the sparsity because both user ratings and item ratings are employed. Experimental results demonstrate that the proposed methods are indeed more robust against data sparsity and give better recommendation quality using a popular MovieLens dataset.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of the-art and possible extensions. IEEE Trans Knowl Data Eng, 17(6):734--749, 2005.", "M. Vozalis and K. G. Margaritis. On the combination of user-based and item-based collaborative filtering. Int. J Comp. Math, 81(9): 1077--1096, 2004.", "V. Kant and K. K. Bharadwaj. A User-Oriented content based recommender system based on reclusive methods and interactive genetic algorithm. In Proc. of BIC-TA 2012, AISC 201, pp. 543--554, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837209"}, {"title": "Multimodal Sentiment Analysis for Automatic Estimation of Polarity Tension of TV News in TV Newscasts Videos", "authors": ["Moisés Pereira\n,", "Flávio Luis Cardeal Pádua\n,", "Adriano Cesar Machado Pereira\n,", "Giani David Silva\n,", "Fabrício Benevenuto de Souza"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThis paper presents a multimodal approach to perform content-based sentiment analysis in TV newscasts videos in order to assist in the automatic estimation of polarity tension of TV news. The proposed approach aims to contribute to the semiodiscoursive study relative to the construction of ethos of those TV shows. In order to achieve this goal, it is proposed the application of computational methods of state-of-the-art that, through the processing of newscasts' videos of interest, perform the automatic emotion recognition in facial expressions. Moreover, they extract modulations in the participants' speech (e.g., news anchors, reporters, among others) and apply sentiment analysis techniques in their text obtained from closed caption, therefore making possible to estimate the emotional tension level in the enunciation of the TV news. In order to evaluate the accuracy and the applicability of the system, we use an actual dataset composed by 358 videos from three Brazilian newscasts. The experimental results are promising, which indicate the potential of the approach to support the analysis of TV newscasts discourse.", "references": ["Begoña, G. S. M.; Fidalgo, M. R. and Santos, M. C. G.. 2010. Analysing the Development of TV News Programmes: from Information to Dramatization. Revista Latina de Comunicación Social, 65, p. 126--145.", "Goffman, E. 1981. The Lecture. Forms of Talk. Pennsylvania: University of Pennsylvania Press, p. 162--195.", "Pereira, M. H. R.; Pádua, F. L. C.; David-Silva, G. 2015. Multimodal Approach for Automatic Emotion Recognition Applied to the Tension Levels Study in TV Newscasts. Brazilian Journalism Research, v. 11, n. 1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820461"}, {"title": "Collaborative Fashion Recommendation: A Functional Tensor Factorization Approach", "authors": ["Yang Hu\n,", "Xi Yi\n,", "Larry S. Davis"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the rapid expansion of online shopping for fashion products, effective fashion recommendation has become an increasingly important problem. In this work, we study the problem of personalized outfit recommendation, i.e. automatically suggesting outfits to users that fit their personal fashion preferences. Unlike existing recommendation systems that usually recommend individual items, we suggest sets of items, which interact with each other, to users. We propose a functional tensor factorization method to model the interactions between user and fashion items. To effectively utilize the multi-modal features of the fashion items, we use a gradient boosting based method to learn nonlinear functions to map the feature vectors from the feature space into some low dimensional latent space. The effectiveness of the proposed algorithm is validated through extensive experiments on real world user data from a popular fashion-focused social network.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In KDD, 2009.", "D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "A. Bosch, A. Zisserman, and X. Munoz. Representing shape with a spatial pyramid kernel. In CIVR, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806239"}, {"title": "CS/IT OER: Availability, Discoverability and Use", "authors": ["Darina Dicheva\n,", "Christo Dichev"], "publication": "SIGITE '15: Proceedings of the 16th Annual Conference on Information Technology Education", "abstract": "ABSTRACT\nThis paper presents a study on two aspects of Computer Science and Information Technology Open Educational Resources (CS/IT OER) conducted in the CS OER Portal, a reference repository of CS/IT open educational resources. The first aspect focuses on the scope, scale and progress of CS/IT OER development. Here we present a statistical characterization of OER aimed at adding to our understanding of their potential for Computer Science and IT teaching and learning and of the impact of the observed trends. The second aspect focuses on obtaining empirical evidence on how people use search and browsing when presented with interfaces providing several alternatives for exploring content.", "references": ["Dichev, C., Dicheva, D. 2012. Open Educational Resources in Computer Science Teaching, SIGSE 2012, 619--624.", "Dichev, C., Dicheva, D. 2012. Is It Time to Change the OER Repositories Role? JCDL 2012, Washington, DC, 31--34.", "Marchionini, G. 2006. Exploratory Search: From Fnding to Understanding. In: Comm. of the ACM 9(4), 41--46."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808006.2808019"}, {"title": "Corrigendum to the Special Issue Editorial in JDIQ Volume 5, Issue 3", "authors": ["Paolo Missier"], "publication": "Journal of Data and Information Quality", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2821019"}, {"title": "Sens-Us: imagining a citizen-led, dynamic, and localized census", "authors": ["Connie Golsteijn\n,", "Sarah Gallacher\n,", "Licia Capra\n,", "Yvonne Rogers"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nSens-Us is an interactive installation that aims to rethink the UK census and explore how collecting census data can be more dynamic and localized. It explores how the census can become more integrated in our everyday lives and more citizen-lead, and it starts to imagine how this can change the relationship between citizens and the state.\nSens-Us consists of a set of five interactive physical input stations, which ask questions in five different themes that are relevant to civic lives: demographics, health, belonging, place, and trust. For each theme we explore what data people are willing to disclose and with whom, and what information they feel should be available to them. We also aim to give people insight into how sharing their data can be beneficial for the common good, and explore how this changes their views on data sharing.\nParticipants are first given a smart card which they insert in each station to register their answers to a specific card ID and subsequently answer questions using physical sliders and buttons. There is further a visualization station in which people can insert their card to view how their data compares to an aggregate of the collected data from all participants.\nSens-Us was created in partnership with the Civic Workshop and the British Council and has been deployed in Somerset House in London throughout January and February 2015 as part of a Civic Bureau exhibition. We feel this installation fits very well in the HCI 2015 conference theme as it explores how interactive technology can mediate our civic lives.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783633"}, {"title": "Building a Self-Contained Search Engine in the Browser", "authors": ["Jimmy Lin"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nJavaScript engines inside modern web browsers are capable of running sophisticated multi-player games, rendering impressive 3D scenes, and supporting complex, interactive visualizations. Can this processing power be harnessed for information retrieval? This paper explores the feasibility of building a JavaScript search engine that runs completely self-contained on the client side within the browser - this includes building the inverted index, gathering terms statistics for scoring, and performing query evaluation. The design takes advantage of the IndexDB API, which is implemented by the LevelDB key{value store inside Google's Chrome browser. Experiments show that although the performance of the JavaScript prototype falls far short of the open-source Lucene search engine, it is sufficiently responsive for interactive applications. This feasibility demonstration opens the door to interesting applications and architectures.", "references": ["N. Asadi and J. Lin. Fast candidate generation for real-time tweet search with Bloom filter chains. ACM TOIS, 31, 2013.", "F. Chang, J. Dean, S. Ghemawat, W. Hsieh, D. Wallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber. Bigtable: A distributed storage system for structured data. OSDI, 2006.", "B. Chen and Z. Xu. A framework for browser-based multiplayer online games using WebGL and WebSocket. ICMT, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809478"}, {"title": "Visualization Oriented Spatiotemporal Urban Data Management and Retrieval", "authors": ["Jonathan Liono\n,", "Flora Dilys Salim\n,", "Irwan Fario Subastian"], "publication": "UCUI '15: Proceedings of the ACM First International Workshop on Understanding the City with Urban Informatics", "abstract": "ABSTRACT\nUrban planners and policy makers often rely on data visualization and spatial data mapping tools to perceive the overall urban trends. The accumulation of historical and real-time urban data from many government and private organizations provides the opportunity for an integrated visual analytic platform. Data management and retrieval for geospatial visualization, correlations, and analysis of multiple data dimensions over a map constitute some of the main challenges when dealing with the heterogeneity of urban data from a variety of sources. In this paper, spatiotemporal aggregation strategies and approaches to accelerate the retrieval of spatial data are presented. The methods are tested on visualizing multivariate urban datasets from two cities in Australia that are aggregated from heterogeneous federated urban data providers. The aggregated spatial or temporal features can be visualized as a choropleth heatmap or extrusion on map. Dynamic spatial window query in our visual analytics tool allows extraction of flat geometry objects optimized through materialized views from a database. Given the robust and scalable orchestration of geometries retrieval, this enables urban planners to perform interactive and dynamic multidimensional visual exploration over a map.", "references": ["Main Structure and Greater Capital City Statistical Areas. http://www.abs.gov.au/ausstats/abs@.nsf/0/4EC4FBD5E83B1221CA257801000C64A2?opendocument, Aug. 2015.", "Service Interface for Real Time Information CEN/TS 15531 (prCEN/TS-oo278181). http://user47094.vs.easily.co.uk/siri/, Jan. 2015.", "What is gtfs? https://developers.google.com/transit/gtfs/, Jan. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811271.2811273"}, {"title": "On Top-k Range Reporting in 2D Space", "authors": ["Saladi Rahul\n,", "Yufei Tao"], "publication": "PODS '15: Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems", "abstract": "ABSTRACT\nOrthogonal range reporting (ORR) is a classic problem in computational geometry and databases, where the objective is to preprocess a set P of points in R2 such that, given an axis-parallel rectangle q, all the points in P ∩ Q can be reported efficiently. This paper studies a natural variant of the problem called top-k ORR, where each point p ∈ P carries a weight w(p) ∈R;. Besides q, a query also specifies an integer k ∈ [1, |P|], and needs to report the k points in q ∩ P with the largest weights. We present optimal or near-optimal structures for solving the top-k ORR problem in the pointer machine and external memory models. As a side product, our structures give new space-query tradeoff for the orthogonal range max problem, which is a special case of top-k ORR with k = 1.", "references": ["Peyman Afshani. On dominance reporting in 3D. In Proceedings of European Symposium on Algorithms (ESA), pages 41--51, 2008.", "Peyman Afshani, Lars Arge, and Kasper Dalgaard Larsen. Orthogonal range reporting in three and higher dimensions. In Proceedings of Annual IEEE Symposium on Foundations of Computer Science (FOCS), pages 149--158, 2009.", "Peyman Afshani, Lars Arge, and Kasper Dalgaard Larsen. Orthogonal range reporting: query lower bounds, optimal structures in 3-d, and higher-dimensional improvements. In Proceedings of Symposium on Computational Geometry (SoCG), pages 240--246, 2010.", "Peyman Afshani, Gerth Stolting Brodal, and Norbert Zeh. Ordered and unordered top-k range reporting in large data sets. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 390--400, 2011.", "Pankaj K. Agarwal, Lars Arge, Jun Yang, and Ke Yi. I/O-efficient structures for orthogonal range-max and stabbing-max queries. In Proceedings of European Symposium on Algorithms (ESA), pages 7--18, 2003.", "Alok Aggarwal and Jeffrey Scott Vitter. The input/output complexity of sorting and related problems. Communications of the ACM (CACM), 31(9):1116--1127, 1988.", "Stephen Alstrup, Gerth Stølting Brodal, and Theis Rauhe. Optimal static range reporting in one dimension. In Proceedings of ACM Symposium on Theory of Computing (STOC), pages 476--482, 2001.", "Gerth Stolting Brodal, Rolf Fagerberg, Mark Greve, and Alejandro Lopez-Ortiz. Online sorted range reporting. In International Symposium on Algorithms and Computation (ISAAC), pages 173--182, 2009.", "Bernard Chazelle. A functional approach to data structures and its use in multidimensional searching. SIAM Journal of Computing, 17(3):427--462, 1988.", "Bernard Chazelle. Lower bounds for orthogonal range searching: I. the reporting case. Journal of the ACM (JACM), 37(2):200--212, 1990.", "Greg N. Frederickson. An optimal algorithm for selection in a min-heap. Information and Computation, 104(2):197--214, 1993.", "Kothuri Venkata Ravi Kanth and Ambuj K. Singh. Optimal dynamic range searching in non-replicating index structures. In Proceedings of International Conference on Database Theory (ICDT), pages 257--276, 1999.", "Marek Karpinski and Yakov Nekrich. Top-k color queries for document retrieval. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 401--411, 2011.", "Edward M. McCreight. Priority search trees. SIAM Journal of Computing, 14(2):257--276, 1985.", "Gonzalo Navarro and Yakov Nekrich. Top-k document retrieval in optimal time and linear space. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 1066--1077, 2012.", "Yakov Nekrich. I/O-efficient point location in a set of rectangles. In Latin American Symposium on Theoretical Informatics (LATIN), pages 687--698, 2008.", ""], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745754.2745777"}, {"title": "The Vision of BigBench 2.0", "authors": ["Tilmann Rabl\n,", "Michael Frank\n,", "Manuel Danisch\n,", "Hans-Arno Jacobsen\n,", "Bhaskar Gowda"], "publication": "DanaC'15: Proceedings of the Fourth Workshop on Data analytics in the Cloud", "abstract": "ABSTRACT\nData is one of the most important resources for modern enterprises. Better analytics allow for a better understanding of customer requirements and market dynamics. The more data is collected, the more information can be extracted. However, information value extraction is limited by data processing speeds. Due to fast technological advances in big data management there is an abundance of big data systems. This leaves users in the dilemma of choosing a system that features good end-to-end performance for the use case. To get a good understanding of the actual performance of a system, realistic application level workloads are required.\nTo this end, we have developed BigBench, an application level benchmark focused only on big data analytics. In this paper, we present the vision of BigBench 2.0, a suite of benchmarks for all major aspects of big data processing in common business use cases. Unlike other efforts, BigBench 2.0 will have completely consistent and integrated model and workload, which will allow realistic end-to-end benchmarking of big data systems.", "references": ["A. Arasu, M. Cherniack, E. Galvez, D. Maier, A. Maskey, E. Ryvkina, M. Stonebraker, and R. Tibbetts. Linear Road: A Stream Data Management Benchmark. In VLDB, 2004.", "C. Baru, M. Bhandarkar, C. Curino, M. Danisch, M. Frank, B. Gowda, H.-A. Jacobsen, H. Jie, D. Kumar, R. Nambiar, M. Poess, F. Raab, T. Rabl, N. Ravi, K. Sachs, S. Sen, L. Yi, and C. Youn. Discussion of BigBench: A Proposed Industry Standard Performance Benchmark for Big Data. In TPCTC, pages 44--63, 2014.", "C. Baru, M. Bhandarkar, R. Nambiar, M. Poess, , and T. Rabl. Benchmarking Big Data Systems and the BigData Top100 List. Big Data, 1(1):60--64, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2799562.2799642"}, {"title": "Text-Based Ephemeral Clustering for Web Image Retrieval on Mobile Devices", "authors": ["Jose G. Moreno"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nText-Based Ephemeral Clustering for Web Image Retrieval on Mobile Devices.\nOur specific contributions in this dissertation are: two algorithms, two datasets and an evaluation tool. The Dual C-means algorithm is the main product of these. Dual C-means can be seen as a generalization of our previous proposal the AGK-means. Both algorithms are based on word-word similarity metrics and on the classical K-means algorithm. A new dataset for a complete evaluation of search results clustering (SRC) algorithms is developed and presented. Similarly, a new Web image dataset is developed and used together with a new metric to measure the users' effort when a set of Web images is explored. Finally, we developed an evaluation tool for the SRC problem, in which we have implemented several classical and recent SRC metrics.\nIn order to validate our hypothesis, we performed a great deal of different experiments with the datasets mentioned above. Three valuable characteristics are evaluated in the proposed algorithms. First, clustering quality, in which classical and recent evaluation metrics are considered. Secondly, the labelling quality of each cluster is evaluated to make sure that all possible query intents are covered. Thirdly and finally, we evaluate the user's effort in exploring the clustered results presented as horizontal image strips. For these three, we use several datasets- some of which are built to evaluate individual or combinations of these characteristics.\nWe have made our conclusions on the numerous factors discussed in this dissertation. In essence, the proposed Dual C-means algorithm, is capable of obtaining proper clustering partitions and simultaneously ensuring high quality labels. When images are displayed on a mobile device's interface, our results indicate that the users' effort to explore the Web image results is reduced.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795419"}, {"title": "Temporal Reconciliation for Dating Photographs Using Entity Information", "authors": ["Paul Martin\n,", "Marc Spaniol\n,", "Antoine Doucet"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nTemporal classification of Web contents requires a \"notion\" about them. This is particularly relevant when contents contain several dates and a human \"interpretation\" is required in order to chose the appropriate time point. The dating challenge becomes even more complex, when images have to be dated based on the content describing them. In this paper, we present a novel time-stamping approach based on semantics derived from the document. To this end, we will first introduce our experimental dataset and then explain our temporal reconciliation pipeline. In particular, we will explain the process of temporal reconciliation by incorporating information derived from named entities.", "references": ["Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, and Zachary Ives. Dbpedia: A nucleus for a web of open data. In In 6th International Semantic Web Conference, Busan, Korea, pages 11--15. Springer, 2007.", "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD '08, pages 1247--1250, New York, NY, USA, 2008. ACM.", "Gaël Dias, José G. Moreno, Adam Jatowt, and Ricardo Campos. Temporal web image retrieval. In 19th International Conference on String Processing and Information Retrieval, SPIRE'12, pages 199--204, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810142"}, {"title": "Using Health-Consumer-Contributed Data to Detect Adverse Drug Reactions by Association Mining with Temporal Analysis", "authors": ["Haodong Yang\n,", "Christopher C. Yang"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nSince adverse drug reactions (ADRs) represent a significant health problem all over the world, ADR detection has become an important research topic in drug safety surveillance. As many potential ADRs cannot be detected though premarketing review, drug safety currently depends heavily on postmarketing surveillance. Particularly, current postmarketing surveillance in the United States primarily relies on the FDA Adverse Event Reporting System (FAERS). However, the effectiveness of such spontaneous reporting systems for ADR detection is not as good as expected because of the extremely high underreporting ratio of ADRs. Moreover, it often takes the FDA years to complete the whole process of collecting reports, investigating cases, and releasing alerts. Given the prosperity of social media, many online health communities are publicly available for health consumers to share and discuss any healthcare experience such as ADRs they are suffering. Such health-consumer-contributed content is timely and informative, but this data source still remains untapped for postmarketing drug safety surveillance. In this study, we propose to use (1) association mining to identify the relations between a drug and an ADR and (2) temporal analysis to detect drug safety signals at the early stage. We collect data from MedHelp and use the FDA's alerts and information of drug labeling revision as the gold standard to evaluate the effectiveness of our approach. The experiment results show that health-related social media is a promising source for ADR detection, and our proposed techniques are effective to identify early ADR signals.", "references": ["R. Agrawal, T. Imieliński, and A. Swami. 1993. Mining association rules between sets of items in large databases. In Proceedings of the ACM SIGMOD Record. ACM, 207--216.", "J. M. Ale and G. H. Rossi. 2000. An approach to discovering temporal association rules. In Proceedings of the 2000 ACM Symposium on Applied Computing-Volume 1. ACM, 294--300.", "W.-H. Au and K. C. C. Chan. 2005. Mining changes in association rules: A fuzzy approach. Fuzzy Sets and Systems 149, 1 (2005), 87--104. doi:10.1016/j.fss.2004.07.018"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700482"}, {"title": "Context-driven Concept Search across Web Ontologies using Keyword Queries", "authors": ["Chetana Gavankar\n,", "Yuan-Fang Li\n,", "Ganesh Ramakrishnan"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nConcepts in ontologies can be used in many scenarios, including annotation of online resources, automatic ontology population, and document classification to improve web search results. Collectively, tens of millions of concepts have been defined in a large number of ontologies that cover many overlapping domains. The scale, duplication and ambiguity makes concept search a challenging problem. We present a novel concept search approach that exploits structures present in ontologies and constructs contexts to effectively filter the noise in concept search results. The three key components of our approach are (1) a context for each concept extracted from relevant properties and axioms, (2) query interpretation based on the extracted context and (3) result ranking using learning to rank algorithms. We evaluate our approach on a large dataset from BioPortal. Our comprehensive evaluation is performed on 2,062,080 concepts and more than 2,000 queries, using two widely-employed performance metrics: normalized discounted cumulative gain (NDCG) and mean reciprocal rank (MRR). Our approach outperforms BioPortal significantly for multitoken queries that make up a large percentage of total queries.", "references": ["H. Alani, C. Brewster, and N. Shadbolt. Ranking ontologies with aktiverank. In In Proc. of the International Semantic Web Conference, ISWC, pages 5--9. Springer-Verlag, 2006.", "G. A. Atemezing and R. Troncy. Information content based ranking metric for linked open vocabularies. In Proceedings of the 10th International Conference on Semantic Systems, SEMANTICS 2014, Leipzig, Germany, September 4-5, 2014, pages 53--56, 2014.", "A. S. Butt, A. Haller, and L. Xie. Ontology search: An empirical evaluation. In The Semantic Web-ISWC 2014, pages 130--147. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2816958"}, {"title": "Analytic Quality: Evaluation of Performance and Insight in Multimedia Collection Analysis", "authors": ["Jan Zahálka\n,", "Stevan Rudinac\n,", "Marcel Worring"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we present analytic quality (AQ), a novel paradigm for the design and evaluation of multimedia analysis methods. AQ complements the existing evaluation methods based on either machine-driven benchmarks or user studies. AQ includes the notion of user insight gain and the time needed to acquire it, both critical aspects of large-scale multimedia collections analysis. To incorporate insight, AQ introduces a novel user model. In this model, each simulated user, or artificial actor, builds its insight over time, at any time operating with multiple categories of relevance. The methods are evaluated in timed sessions. The artificial actors interact with each method and steer the course by indicating relevant items throughout the session. AQ measures not only precision and recall, but also throughput, diversity of the results, and the accuracy of estimating the percentage of relevant items in the collection. AQ is shown to provide a wide picture of analytic capabilities of the evaluated methods and enumerate how their strengths differ for different purposes. The AQ time plots provide design suggestions for improving the evaluated methods. AQ is demonstrated to be more insightful than the classic benchmark evaluation paradigm both in terms of method comparison and suggestions for further design.", "references": ["D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In ACM MM, pages 223--232, 2013.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In ACM CIKM, pages 621--630, 2009.", "T. Demeester, D. Trieschnigg, D. Nguyen, K. Zhou, and D. Hiemstra. Overview of the TREC 2014 federated Web search track. In TREC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806279"}, {"title": "\"Clustering of Dancelets\": Towards Video Recommendation Based on Dance Styles", "authors": ["Tingting Han\n,", "Hongxun Yao\n,", "Xiaoshuai Sun\n,", "Yanhao Zhang\n,", "Sicheng Zhao\n,", "Xiusheng Lu\n,", "Yinghao Huang\n,", "Wenlong Xie"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nDance is a special and important type of action, composed of abundant and various action elements. However, the recommendation of dance videos on the web are still not well studied. It is hard to realize it in the way of traditional methods using associated texts or static features of video content. In this paper, we study the problem focusing on extraction and representation of action information in dances. We propose to recommend dance videos based on the automatically discovered ``Dance Styles'', which play a significant role in characterizing different types of dances. To bridge the semantic gap of video content and mid-level concept, style, we take advantage of a mid-level action representation method, and extract representative patches as ``Dancelets'', a sort of intermediation between videos and the concepts. Furthermore, we propose to employ Motion Boundaries as saliency priors and sparsely extract patches containing more representative information to generate a set of dancelet candidates. Dancelets are then discovered by Normalized-cut method, which is superior in grouping visually similar patterns into the same clusters. For the fast and effective recommendation, a random forest-based index is built, and the ranking results are derived according to the matching results in all the leaf notes. Extensive experiments validated on the web dance videos demonstrate the effectiveness of the proposed methods for dance style discovery and video recommendation based on styles.", "references": ["H. B and S. B. Determining optical flow. Artificial Intelligence, 17:185--203, 1981.", "P. Cui, Z. Wang, and Z. Su. What videos are similar with you? learning a common attributed representation for video recommendation. In MM, 2014.", "N. Dalal, B. Triggs, and C. Schmid. Human detection using oriented histograms of flowand appearance. In ECCV, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806363"}, {"title": "Person-Name Parsing for Linking User Web Profiles", "authors": ["G. Sujatha Das\n,", "Xiang Li\n,", "Ang Sun\n,", "Hakan Kardes\n,", "Xin Wang"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nA person-name parser involves the identification of constituent parts of a person's name. Due to multiple writing styles (\"John Smith\" versus \"Smith, John\"), extra information (\"John Smith, PhD\", \"Rev. John Smith\"), and country-specific last-name prefixes (\"Jean van de Velde\"), parsing fullname strings from user profiles on Web 2.0 applications is not straightforward. To the best of our knowledge, we are the first to address this problem systematically by proposing machine learning approaches for parsing noisy fullname strings.\nIn this paper, we propose several types of features based on token statistics, surface-patterns, and specialized dictionaries and apply them within a sequence modeling framework to learn a fullname parser. In particular, we propose the use of \"bucket\" features based on (name-token, label) distributions in lieu of \"term\" features frequently used in various Natural Language Processing applications to prevent the growth of learning parameters as a function of the training data size. We experimentally illustrate the generalizability, effectiveness, and efficiency aspects of our proposed features for noisy fullname parsing on fullname strings from the popular, professional networking website LinkedIn and commonly-used person names in the United States. On these datasets, our fullname parser significantly outperforms both the parser trained using classification approaches and a commercially-available name parsing solution.", "references": ["MUC6 '95: Proceedings of the 6th Conference on Message Understanding. Association for Computational Linguistics, 1995.", "F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user modeling on twitter for personalized news recommendations. In UMAP, 2011.", "G. H. Bakir, T. Hofmann, B. Schölkopf, A. J. Smola, B. Taskar, and S. V. N. Vishwanathan, editors. Predicting Structured Data. MIT Press, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767117"}, {"title": "A method for analyzing health behavior in online forums", "authors": ["Rose Yesha\n,", "Aryya Gangopadhyay"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nThe prevalence of online social networks has enabled users to communicate, connect, and share content. Many of these networks serve as the de-facto Internet portal for millions of users. Due to the enormous popularity of these sites, the data about the users and their communications offer an enormous opportunity to analyze human behaviors on a large scale. It is important to analyze patterns within these records in order to more effectively treat individuals. In this paper, a method is presented for identifying these themes and patterns within forum data. This methodology includes automatic extraction of the main themes or patterns in the data, quantify the similarities and differences in the contents of different online forums, and finding similar documents based on user queries. We used data sets from four different forums. In this paper we describe a method that automatically differentiates between online discussion groups related to different behavioral health challenges and identifies the most appropriate discussion forum for a given input. Finally, we evaluated the efficacy of our method by using cross-validation.", "references": ["Amayas Abboute, Yasser Boudjeriou, Gilles Entringer, Jérôme Azé, Sandra Bringay, and Pascal Poncelet. Mining twitter for suicide prevention. In Natural Language Processing and Information Systems - 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014, Montpellier, France, June 18--20, 2014. Proceedings, pages 250--253, 2014.", "Charu C. Aggarwal and ChengXiang Zhai, editors. Mining Text Data. Springer, 2012.", "R. Albert and A.-L. Barbassi. The Structure and Dynamics of Networks. Princeton University Press, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2812592"}, {"title": "A new approach to geocoding: BingGC", "authors": ["Pavel Berkhin\n,", "Michael R. Evans\n,", "Florin Teodorescu\n,", "Wei Wu\n,", "Dragomir Yankov"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nReal-time geocoders help users find precise locations in online mapping systems. Geocoding unstructured queries can be difficult, as users may describe map locations by referencing several spatially co-located entities (e.g., a business near a street intersection). Serving these queries is important as it provides new capabilities and allows for expanding in markets with less structured postal systems. Traditionally, this problem poses significant difficulties for online systems where latency constraints prevent exhaustive join-based algorithms. Previous work in this area involved natural language processing to segment queries based on known rules, or purely spatial approaches that are difficult to maintain and may have high latency. In this paper, we present a new approach to geocoding - BingGC - that makes fulfillment of extremely diverse geocoding queries possible via a combination of traditional web search technologies and a novel algorithm that uses textual search and spatial joins to quickly find results. It allows resolution of up to s spatially co-located entities in a single query with no pre-computation or rule-based matching. We provide experimental analysis of our system compared against leading online geocoders.", "references": ["Bing Maps Tile System, 06/19/2015. https://msdn.microsoft.com/en-us/library/bb259689.aspx.", "C. M. Bishop. Pattern recognition and machine learning. Springer, 2006.", "O. Chapelle and Y. Chang. Yahoo! learning to rank challenge overview. Journal of Machine Learning Research - Proceedings Track, pages 1--24, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820827"}, {"title": "Towards in situ visualization of extreme-scale, agent-based, worldwide disease-spreading simulations", "authors": ["Andrey Krekhov\n,", "Jürgen Grüninger\n,", "Rainer Schlönvoigt\n,", "Jens Krüger"], "publication": "SA '15: SIGGRAPH Asia 2015 Visualization in High Performance Computing", "abstract": "ABSTRACT\nExascale computing is regarded as a major milestone for a number of application fields. However, utilizing the massively parallel power of such architectures requires a significant paradigm shift in the software structure of both simulation and visualization systems. A suboptimal workload distribution, communication bottlenecks between processes, as well as global memory accesses are often the limiting part in current approaches when it comes to the execution of such software in an exascale environment.\nRecent cases of malaria and Ebola in Africa have shown that there is a need for disease-spreading simulations to help healthcare workers better predict unexpected scenarios and take the necessary precautions. Reaction time plays an important role when it comes to containing a disease. Therefore, converting these kinds of demanding simulations to highly parallel computing systems as well as interactively visualizing the results is key.\nThis paper demonstrates an approach towards a worldwide simulation of disease-spreading and an integrated---in situ---visualization. Instead of applying large-scale stochastic models, our agent-based method simulates the complete population of the world, accounting for daily tasks and routines of each subject. We focus on massive parallelization and efficient scaling to benefit from existing petascale to upcoming exascale setups. In particular, workload distribution is performed based on space partitioning and not on the population count, which is nonetheless included as an initial optimization. The resulting simulation is combined with a query-driven in situ visualization client that directly utilizes the spatial partitioning and the employed hierarchy. Our preliminary benchmarks underline the scalability of our approach in terms of rising computing power and encourage further research in the direction of worldwide, agent-based simulations and the corresponding in situ visualizations.", "references": ["Ahrens, J., Jourdain, S., O'Leary, P., Patchett, J., Rogers, D. H., and Petersen, M. 2014. An image-based approach to extreme scale in situ visualization and analysis. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE Press, Piscataway, NJ, USA, SC '14, 424--434.", "Barrett, C. L., Bisset, K. R., Eubank, S. G., Feng, X., and Marathe, M. V. 2008. Episimdemics: An efficient algorithm for simulating the spread of infectious disease over large realistic social networks. In Proceedings of the 2008 ACM/IEEE Conference on Supercomputing, IEEE Press, Piscataway, NJ, USA, SC '08, 37:1--37:12.", "Broeck, W., Gioannini, C., Gonçalves, B., Quaggiotto, M., Colizza, V., and Vespignani, A. 2011. The gleamviz computational tool, a publicly available software to explore realistic epidemic spreading scenarios at the global scale. In BMC Infectious Diseases, vol. 11."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818517.2818543"}, {"title": "Describing Images with Hierarchical Concepts and Object Class Localization", "authors": ["Yahong Han\n,", "Guang Li"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nCurrent research into automatic generation of semantic descriptions centers mainly on improving the annotation accuracy for individual tag or attributes. In this paper, we focus on the generation of more informative descriptions for images. We proposes to generate layered, semantically meaningful descriptions and create summaries of key aspects of the data from the component detectors. In particular, the output descriptions include superclass, class, attributes, and the location of the area of the object which may interest users. We propose to integrate ROI (Region of Interest) identification and hierarchical semantic elements detection into a joint framework. The joint optimization of the ROI localizer and the hierarchical concept detection make them mutually beneficial and reciprocal. In this way, we create a discriminative image description generation framework based on a tightly coupled multi-layer optimization. The output descriptions contain richer information of the image content with layered contextual information, thereby enabling better management and usage of image data. Experiments on two public open benchmark datasets demonstrate that the proposed method obtains state of the art performance.", "references": ["U. Brefeld, T. Gärtner, T. Scheffer, and S. Wrobel. Efficient co-regularised least squares regression. In NIPS, pages 137--144, 2006.", "X. Cai, F. Nie, H. Huang, and C. H. Ding. Multi-class ℓ2,1-norm support vector machine. In IEEE International Conference on Data Mining, pages 91--100, 2011.", "K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine Learning Research, 2:265--292, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749290"}, {"title": "Text segmentation and Chinese site search", "authors": ["Liyuan Zhou\n,", "David Hawking\n,", "Paul Thomas"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nAutomatic segmentation and overlapping bigrams are the most common methods for overcoming the lack of explicit word boundaries in Chinese text. Past studies have compared their effectiveness, but findings have been equivocal and site search has been little studied. We compare representatives of the two approaches using a 465,000 page crawl and test queries applicable to the university context. 503 pairs of result sets were judged by 56 Chinese students.\nAlthough there are differences on certain queries, we find no overall advantage to either method. To understand the merits of each approach, we analyze cases where they performed differently. Our analysis enumerates situations which favour segmentation, and those which favour bigrams. We observe that further improvements in segmentation accuracy will not improve retrieval effectiveness.", "references": ["A. Broder. A taxonomy of web search. SIGIR Forum, 36(2):3--10, 2002.", "G. Cao, P. He, G. Wu, and S. Nie. 中文分词对中文信息检索系统性能的影响 (Impact of Chinese Segmentation to Chinese Information Retrieval). Computer Engineering and Applications, 19:78--79, 2003.", "S. Foo and H. Li. Chinese word segmentation and its effect on information retrieval. Inf. Proc. & Management, 40(1):161--190, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838940"}, {"title": "The Wikipedia location network: overcoming borders and oceans", "authors": ["Johanna Geiß\n,", "Andreas Spitz\n,", "Jannik Strötgen\n,", "Michael Gertz"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nIn social network analysis and information retrieval, research has recently been devoted to the extraction of implicit relationships between persons from unstructured textual sources. In this paper, we adapt such a person-centric approach to the extraction of locations and build the Wikipedia Location Network based on co-occurrences of place names in the English Wikipedia. We summarize the network's characteristics and demonstrate its value for future location relationship analysis tasks.", "references": ["J. Geiß, A. Spitz, and M. Gertz. Beyond Friendships and Followers: The Wikipedia Social Network. In ASONAM'15, 2015.", "Y. Liu, F. Wang, C. Kang, Y. Gao, and Y. Lu. Analyzing Relatedness by Toponym Co-Occurrences on Web Pages. T. GIS, 18(1), 2014.", "G. Quercini and H. Samet. Uncovering the Spatial Relatedness in Wikipedia. In SIGSPATIAL '14, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837694"}, {"title": "A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems", "authors": ["Ali Mamdouh Elkahky\n,", "Yang Song\n,", "Xiaodong He"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecent online services rely heavily on automatic personalization to recommend relevant content to a large number of users. This requires systems to scale promptly to accommodate the stream of new users visiting the online services for the first time. In this work, we propose a content-based recommendation system to address both the recommendation quality and the system scalability. We propose to use a rich feature set to represent users, according to their web browsing history and search queries. We use a Deep Learning approach to map users and items to a latent space where the similarity between users and their preferred items is maximized. We extend the model to jointly learn from features of items from different domains and user features by introducing a multi-view Deep Learning model. We show how to make this rich-feature based user representation scalable by reducing the dimension of the inputs and the amount of training data. The rich user feature representation allows the model to learn relevant user behavior patterns and give useful recommendations for users who do not have any interaction with the service, given that they have adequate search and browsing history. The combination of different domains into a single model for learning helps improve the recommendation quality across all the domains, as well as having a more compact and a semantically richer user latent feature vector. We experiment with our approach on three real-world recommendation systems acquired from different sources of Microsoft products: Windows Apps recommendation, News recommendation, and Movie/TV recommendation. Results indicate that our approach is significantly better than the state-of-the-art algorithms (up to 49% enhancement on existing users and 115% enhancement on new users). In addition, experiments on a publicly open data set also indicate the superiority of our method in comparison with transitional generative topic models, for modeling cross-domain recommender systems. Scalability analysis show that our multi-view DNN model can easily scale to encompass millions of users and billions of item entries. Experimental results also confirm that combining features from all domains produces much better performance than building separate models for each domain.", "references": ["Fabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao. Twitter-based user modeling for news recommendations. In IJCAI'13, pages 2962--2966.", "Amr Ahmed, Abhimanyu Das, and Alexander J Smola. Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising. In WSDM'14, pages 153--162.", "Robert M Bell and Yehuda Koren. Improved neighborhood-based collaborative filtering. In KDD'13 CUP, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741667"}, {"title": "Efficient Memory Management for Lock-Free Data Structures with Optimistic Access", "authors": ["Nachshon Cohen\n,", "Erez Petrank"], "publication": "SPAA '15: Proceedings of the 27th ACM symposium on Parallelism in Algorithms and Architectures", "abstract": "ABSTRACT\nLock-free data structures achieve high responsiveness, aid scalability, and avoid deadlocks and livelocks. But providing memory management support for such data structures without foiling their progress guarantees is difficult. Often, designers employ the hazard pointers technique, which may impose a high performance overhead.\nIn this work we propose a novel memory management scheme for lock-free data structures called optimistic access. This scheme provides efficient support for lock-free data structures that can be presented in a normalized form. Our novel memory manager breaks the traditional memory management invariant which never lets a program touch reclaimed memory. In other words, it allows the memory manager to reclaim objects that may still be accessed later by concurrently running threads. This broken invariant provides an opportunity to obtain high parallelism with excellent performance, but it also requires a careful design. The optimistic access memory management scheme is easy to employ and we implemented it for a linked list, a hash table, and a skip list. Measurements show that it dramatically outperforms known memory reclamation methods.", "references": ["D. Alistarh, P. Eugster, M. Herlihy, A. Matveev, and N. Shavit. Stacktrack: An automated transactional approach to concurrent memory reclamation. In EuroSys. ACM, 2014.", "J. Auerbach, D. F. Bacon, P. Cheng, D. Grove, B. Biron, C. Gracie, B. McCloskey, A. Micic, and R. Sciampacone. Tax-and-spend: Democratic scheduling for real-time garbage collection. In EMSOFT, pages 245--254, 2008.", "A. Braginsky, A. Kogan, and E. Petrank. Drop the anchor: lightweight memory management for non-blocking data structures. In SPAA, pages 33--42. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2755573.2755579"}, {"title": "Learning Difficulties in Computing Courses: Cognitive Processes Assessment Methods Research and Application", "authors": ["Vinicius Vieira Pessoni\n,", "Fernando Marques Federson\n,", "Auri Marcelo Rizzo Vincenzi"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nLearning difficulties in computing courses is a situation perceived in diverse universities from different countries, cultures and backgrounds. These difficulties directly affect achievement rates and increase course evasion. We believe in the existence of a foundation of cognitive processes, that without it, even the most motivated student would have trouble to transform the received information into knowledge. This work has focused mainly on the research of candidate methods for cognitive processes assessment with a strong background theory. With this kind of information would be possible to devise cognitive interventions, in order to evolve students cognitive level, and consequently, raise their success rates. A systematic review was conducted and among the many researched methods we selected Lawson Classroom Test of Scientific Reasoning - LCTSR. Authorized by its author, we conducted the first translation of LCTSR to Brazilian Portuguese and administered to students of three undergraduate computing courses: Information Systems, Computer Science and Software Engineering. We also present results of its administration that we consider important to reinforce the above suggested strategy.", "references": ["Arlin, P. K. 1982. A multitrait-multimethod validity study of a test of formal Reasoning. Educational and Psychological Measurement. 42 (1982), 1077-1088.", "Ates, S. Cataloglu, E. 2007. The effects of students' reasoning abilities on conceptual understandings and problem-solving skills in introductory mechanics. Eur. J. Phys. 28 (2007), 1161-1171.", "Barrows, H. S. Problem-based learning in medicine and beyond: A brief overview. New directions for teaching and learning. 68 (1996), 3-12."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814064"}, {"title": "Session details: Session 6 -- Big Data Analytics and Crowdsourcing for Public Health 2", "authors": ["Carlos Castillo"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3246861"}, {"title": "Kickstarting the Commons: The YFCC100M and the YLI Corpora", "authors": ["Julia Bernd\n,", "Damian Borth\n,", "Carmen Carrano\n,", "Jaeyoung Choi\n,", "Benjamin Elizalde\n,", "Gerald Friedland\n,", "Luke Gottlieb\n,", "Karl Ni\n,", "Roger Pearce\n,"], "publication": "MMCommons '15: Proceedings of the 2015 Workshop on Community-Organized Multimodal Mining: Opportunities for Novel Solutions", "abstract": "ABSTRACT\nThe publication of the Yahoo Flickr Creative Commons 100 Million dataset (YFCC100M)--to date the largest open-access collection of photos and videos--has provided a unique opportunity to stimulate new research in multimedia analysis and retrieval. To make the YFCC100M even more valuable, we have started working towards supplementing it with a comprehensive set of precomputed features and high-quality ground truth annotations. As part of our efforts, we are releasing the YLI feature corpus, as well as the YLI-GEO and YLI-MED annotation subsets. Under the Multimedia Commons Project (MMCP), we are currently laying the groundwork for a common platform and framework around the YFCC100M that (i) facilitates researchers in contributing additional features and annotations, (ii) supports experimentation on the dataset, and (iii) enables sharing of obtained results. This paper describes the YLI features and annotations released thus far, and sketches our vision for the MMCP.", "references": ["K. Ashraf, B. Elizalde, F. Iandola, M. Moskewicz, G. Friedland, K. Keutzer, and J. Bernd. Audio-based multimedia event detection with DNNs and sparse sampling. In Proceedings of the 5th ACM International Conference on Multimedia Retrieval (ICMR '15), 2015.", "J. Bernd, D. Borth, B. Elizalde, G. Friedland, H. Gallagher, L. Gottlieb, A. Janin, S. Karabashlieva, J. Takahashi, and J. Won. The YLI-MED corpus: Characteristics, procedures, and plans (ICSI Technical Report TR-15-001). arXiv:1503.04250, 2015.", "J. Choi, B. Thomee, G. Friedland, L. Cao, K. Ni, D. Borth, B. Elizalde, L. Gottlieb, C. Carrano, R. Pearce, and D. Poland. The Placing Task: A large-scale geo-estimation challenge for social-media videos and images. In Proceedings of the ACM Multimedia 2014 Workshop on Geotagging and Its Applications in Multimedia (GeoMM '14), Orlando, FL, November 2014. Association for Computing Machinery."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814815.2816986"}, {"title": "Web Question Answering: Beyond Factoids: SIGIR 2015 Workshop", "authors": ["Eugene Agichtein\n,", "David Carmel\n,", "Charles L.A. Clarke\n,", "Praveen Paritosh\n,", "Dan Pelleg\n,", "Idan Szpektor"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767861"}, {"title": "DPT: differentially private trajectory synthesis using hierarchical reference systems", "authors": ["Xi He\n,", "Graham Cormode\n,", "Ashwin Machanavajjhala\n,", "Cecilia M. Procopiuc\n,", "Divesh Srivastava"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nGPS-enabled devices are now ubiquitous, from airplanes and cars to smartphones and wearable technology. This has resulted in a wealth of data about the movements of individuals and populations, which can be analyzed for useful information to aid in city and traffic planning, disaster preparedness and so on. However, the places that people go can disclose extremely sensitive information about them, and thus their use needs to be filtered through privacy preserving mechanisms. This turns out to be a highly challenging task: raw trajectories are highly detailed, and typically no pair is alike. Previous attempts fail either to provide adequate privacy protection, or to remain sufficiently faithful to the original behavior.\nThis paper presents DPT, a system to synthesize mobility data based on raw GPS trajectories of individuals while ensuring strong privacy protection in the form of ε-differential privacy. DPT makes a number of novel modeling and algorithmic contributions including (i) discretization of raw trajectories using hierarchical reference systems (at multiple resolutions) to capture individual movements at differing speeds, (ii) adaptive mechanisms to select a small set of reference systems and construct prefix tree counts privately, and (iii) use of direction-weighted sampling for improved utility. While there have been prior attempts to solve the subproblems required to generate synthetic trajectories, to the best of our knowledge, ours is the first system that provides an end-to-end solution. We show the efficacy of our synthetic trajectory generation system using an extensive empirical evaluation.", "references": ["Taxi trajectory open dataset, Tsinghua university, China. http://sensor.ee.tsinghua.edu.cn, 2009.", "O. Abul, F. Bonchi, and M. Nanni. Never walk alone: Uncertainty for anonymity in moving objects databases. In ICDE, pages 376--385, 2008.", "R. A. Becker, R. Cáceres, K. Hanson, S. Isaacman, J. M. Loh, M. Martonosi, J. Rowland, S. Urbanek, A. Varshavsky, and C. Volinsky. Human mobility characterization from cellular network data. Commun. ACM, 56(1):74--82, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809978"}, {"title": "Scalable Multimodal Search with Distributed Indexing by Sparse Hashing", "authors": ["André Mourão\n,", "João Magalhães"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nMultimedia search systems must deal with an increasingly large and heterogeneous amount of data. Several challenges exist when deploying real-world search engines for such data. Existing literature does not properly tackle the many efficiency issues that such task requires. In this paper, we address several of the key efficiency aspects required to deploy a distributed search engine, capable of handling several millions of multimedia documents. The search engine builds on a framework designed to: first, ease the distribution of documents and queries across cluster-nodes, second, index media efficiently for fast similarity search and third aggregate ranked results from several heterogeneous sources. Moreover, the proposed framework is flexible enough to support several state-of-the-art indexing and aggregation techniques.\nAt the heart of the indexing architecture lies an inverse index structure optimized for sparse hashes, that speeds up the retrieval of similar descriptors. To leverage the distributed nature of the search framework, the proposed aggregation technique offers a low temporal complexity overhead and it is agnostic to the index type (a key aspect to support simultaneous modalities). A comprehensive evaluation with both general IR metrics and efficiency metrics, provides a unique assessment of the several efficiency bottlenecks faced by a search engine. In addition, we test the scalability of the search framework to multiple index sizes, i.e., up to 5 million documents per cluster-node.", "references": ["M. Abedini, L. Cao, N. Codella, J. H. Connell, A. Garnavi, Rahiland Geva, M. Merler, Q.-B. Nguyen, J. U. Pankanti, Sharathchandraand R. Smith, and A. Sun, Xingzhiand Tzadok. Ibm research at imageclef 2013 medical tasks. In WN of CLEF'13, 2013.", "M. Aharon, M. Elad, and A. Bruckstein. K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation. IEEE Trans. on Signal Processing, 54(11):4311--4322, 2006.", "R. Aly, D. Hiemstra, and T. Demeester. Taily: Shard selection using the tail of score distributions. In SIGIR'13, pages 673--682, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749310"}, {"title": "What Users Ask a Search Engine: Analyzing One Billion Russian Question Queries", "authors": ["Michael Völske\n,", "Pavel Braslavski\n,", "Matthias Hagen\n,", "Galina Lezina\n,", "Benno Stein"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe analyze the question queries submitted to a large commercial web search engine to get insights about what people ask, and to better tailor the search results to the users' needs. Based on a dataset of about one billion question queries submitted during the year 2012, we investigate askers' querying behavior with the support of automatic query categorization. While the importance of question queries is likely to increase, at present they only make up 3-4% of the total search traffic.\nSince questions are such a small part of the query stream, and are more likely to be unique than shorter queries, click-through information is typically rather sparse. Thus, query categorization methods based on the categories of clicked web documents do not work well for questions. As an alternative, we propose a robust question query classification method that uses the labeled questions from a large community question answering platform (CQA) as a training set. The resulting classifier is then transferred to the web search questions. Even though questions on CQA platforms tend to be different to web search questions, our categorization method proves competitive with strong baselines with respect to classification accuracy.\nTo show the scalability of our proposed method we apply the classifiers to about one billion question queries and discuss the trade-offs between performance and accuracy that different classification models offer.", "references": ["Anne Aula, Rehan M. Khan, and Zhiwei Guan. How does search behavior change as search becomes more difficult? In Proceedings of CHI 2010, pages 35--44.", "Peter Bailey, Ryen W. White, Han Liu, and Giridhar Kumaran. Mining historic query trails to label long and rare search engine queries. ACM Transactions on the Web, 4 (4): 15, 2010.", "Judit Bar-Ilan, Zheng Zhu, and Mark Levene. Topic-specific analysis of search queries. In Proceedings of the WSCD 2009 Workshop, pages 35--42."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806457"}, {"title": "Audio Information for Hyperlinking of TV Content", "authors": ["Petra Galuščáková\n,", "Pavel Pecina"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nIn this paper, we explore the use of audio information in the retrieval of multimedia content. Specifically, we focus on linking similar segments in a collection consisting of 4,000 hours of BBC TV programmes. We provide a description of our system submitted to the Hyperlinking Sub-task of the Search and Hyperlinking Task in the MediaEval 2014 Benchmark, in which it scored best. We explore three automatic transcripts and compare them to available subtitles. We confirm the relationship between retrieval performance and transcript quality. The performance of the retrieval is further improved by extending transcripts by metadata and context, by combining different transcripts, using the highest confident words of the transcripts, and by utilizing acoustic similarity.", "references": ["R. Aly, M. Eskevich, R. Ordelman, and G. J. F. Jones. Adapting Binary Information Retrieval Evaluation Metrics for Segment-based Retrieval Tasks. CoRR, abs/1312.1913, 2013.", "C. A. Bhatt, N. Pappas, M. Habibi, and A. Popescu-Belis. Multimodal Reranking of Content-based Recommendations for Hyperlinking Video Snippets. In Proc. of ICMR, pages 225--232, 2014.", "J. Davidson, B. Liebald, J. Liu, P. Nandy, T. Van Vleet, U. Gargi, S. Gupta, Y. He, M. Lambert, B. Livingston, and D. Sampath. The YouTube Video Recommendation System. In Proc. of RecSys, pages 293--296, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814643"}, {"title": "Dexter: large-scale discovery and extraction of product specifications on the web", "authors": ["Disheng Qiu\n,", "Luciano Barbosa\n,", "Xin Luna Dong\n,", "Yanyan Shen\n,", "Divesh Srivastava"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe web is a rich resource of structured data. There has been an increasing interest in using web structured data for many applications such as data integration, web search and question answering. In this paper, we present Dexter, a system to find product sites on the web, and detect and extract product specifications from them. Since product specifications exist in multiple product sites, our focused crawler relies on search queries and backlinks to discover product sites. To perform the detection, and handle the high diversity of specifications in terms of content, size and format, our system uses supervised learning to classify HTML fragments (e.g., tables and lists) present in web pages as specifications or not. To perform large-scale extraction of the attribute-value pairs from the HTML fragments identified by the specification detector, Dexter adopts two lightweight strategies: a domain-independent and unsupervised wrapper method, which relies on the observation that these HTML fragments have very similar structure; and a combination of this strategy with a previous approach, which infers extraction patterns by annotations generated by automatic but noisy annotators. The results show that our crawler strategy to locate product specification pages is effective: (1) it discovered 1:46AM product specification pages from 3; 005 sites and 9 different categories; (2) the specification detector obtains high values of F-measure (close to 0:9) over a heterogeneous set of product specifications; and (3) our efficient wrapper methods for attribute-value extraction get very high values of precision (0.92) and recall (0.95) and obtain better results than a state-of-the-art, supervised rule-based wrapper.", "references": ["L. Barbosa, S. Bangalore, and V. K. R. Sridhar. Crawling back and forth: Using back and out links to locate bilingual sites. In IJCNLP, pages 429--437, 2011.", "L. Blanco, V. Crescenzi, P. Merialdo, and P. Papotti. Supporting the automatic construction of entity aware search engines. In WIDM, pages 149--156, 2008.", "M. Bronzi, V. Crescenzi, P. Merialdo, and P. Papotti. Extraction and integration of partially overlapping web sources. PVLDB, 6(10):805--816, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2831360.2831372"}, {"title": "Adapted B-CUBED Metrics to Unbalanced Datasets", "authors": ["Jose G. Moreno\n,", "Gaël Dias"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nB-CUBED metrics have recently been adopted in the evaluation of clustering results as well as in many other related tasks. However, this family of metrics is not well adapted when datasets are unbalanced. This issue is extremely frequent in Web results, where classes are distributed following a strong unbalanced pattern. In this paper, we present a modified version of B-CUBED metrics to overcome this situation. Results in toy and real datasets indicate that the proposed adaptation correctly considers the particularities of unbalanced cases.", "references": ["E. Amigó, J. Gonzalo, J. Artiles, and F. Verdejo. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Information Retrieval, 12(4):461--486, 2009.", "A. Bagga and B. Baldwin. Entity-based cross-document coreferencing using the vector space model. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics - Volume 1, ACL '98, pages 79--85, 1998.", "C. Carpineto and G. Romano. Optimal meta search results clustering. In 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 170--177, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767836"}, {"title": "POI Recommendation: Towards Fused Matrix Factorization with Geographical and Temporal Influences", "authors": ["Jean-Benoit Griesner\n,", "Talel Abdessalem\n,", "Hubert Naacke"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nProviding personalized point-of-interest (POI) recommendation has become a major issue with the rapid emergence of location-based social networks (LBSNs). Unlike traditional recommendation approaches, the LBSNs application domain comes with significant geographical and temporal dimensions. Moreover most of traditional recommendation algorithms fail to cope with the specific challenges implied by these two dimensions. Fusing geographical and temporal influences for better recommendation accuracy in LBSNs remains unexplored, as far as we know. We depict how matrix factorization can serve POI recommendation, and propose a novel attempt to integrate both geographical and temporal influences into matrix factorization. Specifically we present GeoMF-TD, an extension of geographical matrix factorization with temporal dependencies. Our experiments on a real dataset shows up to 20\\% benefit on recommendation precision.", "references": ["B. Berjani and T. Strufe. A recommendation system for spots in location-based online social networks. SNS '11, 2011.", "C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. AAAI, 2012.", "E. Cho, S. A. Myers, and J. Leskovec. Friendship and mobility: User movement in location-based social networks. KDD '11, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799679"}, {"title": "GeoSoCa: Exploiting Geographical, Social and Categorical Correlations for Point-of-Interest Recommendations", "authors": ["Jia-Dong Zhang\n,", "Chi-Yin Chow"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecommending users with their preferred points-of-interest (POIs), e.g., museums and restaurants, has become an important feature for location-based social networks (LBSNs), which benefits people to explore new places and businesses to discover potential customers. However, because users only check in a few POIs in an LBSN, the user-POI check-in interaction is highly sparse, which renders a big challenge for POI recommendations. To tackle this challenge, in this study we propose a new POI recommendation approach called GeoSoCa through exploiting geographical correlations, social correlations and categorical correlations among users and POIs. The geographical, social and categorical correlations can be learned from the historical check-in data of users on POIs and utilized to predict the relevance score of a user to an unvisited POI so as to make recommendations for users. First, in GeoSoCa we propose a kernel estimation method with an adaptive bandwidth to determine a personalized check-in distribution of POIs for each user that naturally models the geographical correlations between POIs. Then, GeoSoCa aggregates the check-in frequency or rating of a user's friends on a POI and models the social check-in frequency or rating as a power-law distribution to employ the social correlations between users. Further, GeoSoCa applies the bias of a user on a POI category to weigh the popularity of a POI in the corresponding category and models the weighed popularity as a power-law distribution to leverage the categorical correlations between POIs. Finally, we conduct a comprehensive performance evaluation for GeoSoCa using two large-scale real-world check-in data sets collected from Foursquare and Yelp. Experimental results show that GeoSoCa achieves significantly superior recommendation quality compared to other state-of-the-art POI recommendation techniques.", "references": ["J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In ACM SIGSPATIAL, 2012.", "C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. In AAAI, 2012.", "C. Cheng, H. Yang, M. R. Lyu, and I. King. Where you like to go next: Successive point-of-interest recommendation. In IJCAI, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767711"}, {"title": "Documents topic classification model in social networks using classifiers voting system", "authors": ["Hyeoncheol Lee\n,", "Beomseok Hong\n,", "Kwangmi Ko Kim"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nTopic model uncovers abstract topics within texts documents, which is an essential task in text analysis in social networks. However, identifying topics in text documents in social networks is challenging since the texts are short, unlabeled, and unstructured. For this reason, we propose a topic classification system regarding the features of text documents in social networks. The proposed system is based on several machine-learning algorithms and voting system. The accuracy of the system has been tested using text documents that were classified into three topics. The experiment results show that the proposed system guarantees high accuracy rates in documents topic classification.", "references": ["I. King, J. Li, and K. T. Chan, \"A brief survey of computational approaches in social computing\". In IJCNN'09: Proceedings of the 2009 international joint conference on Neural Networks, pp. 2699--2706, Piscataway, NJ, USA, 2009. IEEE Press. ISBN:978-1-4244-3549-4", "C. Byun, H. Lee, J. You and Y. Kim, \"Dynamic Seed Analysis in a Social Network for Maximizing Efficiency of Data Collection\", Proceedings of the Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD), 2013 14th ACIS International Conference, July 2013, pp. 132--136", "X. Yan, J. Guo, Y, Lan and X. Cheng, \"A biterm topic model for short texts\", Proceedings of the 22nd international conference on World Wide Web, May 2013, pp.1445--1456, ISBN:978-1-4503-2035-1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811480"}, {"title": "Ranking Deep Web Text Collections for Scalable Information Extraction", "authors": ["Pablo Barrio\n,", "Luis Gravano\n,", "Chris Develder"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nInformation extraction (IE) systems discover structured information from natural language text, to enable much richer querying and data mining than possible directly over the unstructured text. Unfortunately, IE is generally a computationally expensive process, and hence improving its efficiency, so that it scales over large volumes of text, is of critical importance. State-of-the-art approaches for scaling the IE process focus on one text collection at a time. These approaches prioritize the extraction effort by learning keyword queries to identify the \"useful\" documents for the IE task at hand, namely, those that lead to the extraction of structured \"tuples.\" These approaches, however, do not attempt to predict which text collections are useful for the IE task---and hence merit further processing---and which ones will not contribute any useful output---and hence should be ignored altogether, for efficiency. In this paper, we focus on an especially valuable family of text sources, the so-called deep web collections, whose (remote) contents are only accessible via querying. Specifically, we introduce and study techniques for ranking deep web collections for an IE task, to prioritize the extraction effort by focusing on collections with substantial numbers of useful documents for the task. We study both (adaptations of) state-of-the-art resource selection strategies for distributed information retrieval, and IE-specific approaches. Our extensive experimental evaluation over realistic deep web collections, and for several different IE tasks, shows the merits and limitations of the alternative families of approaches, and provides a roadmap for addressing this critically important building block for efficient, scalable information extraction.", "references": ["E. Agichtein and S. Cucerzan. Predicting accuracy of extracting information from unstructured text collections. In CIKM, 2005.", "E. Agichtein and L. Gravano. Querying text databases for efficient information extraction. In ICDE, 2003.", "M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction from the web. In IJCAI, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806581"}, {"title": "Multiple Social Network Learning and Its Application in Volunteerism Tendency Prediction", "authors": ["Xuemeng Song\n,", "Liqiang Nie\n,", "Luming Zhang\n,", "Mohammad Akbari\n,", "Tat-Seng Chua"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe are living in the era of social networks, where people throughout the world are connected and organized by multiple social networks. The views revealed by different social networks may vary according to the different services they offer. They are complimentary to each other and comprehensively characterize a specific user from different perspectives. As compared to the scare knowledge conveyed by a single source, appropriate aggregation of multiple social networks offers us a better opportunity for deep user understanding. The challenges, however, co-exist with opportunities. The first challenge lies in the existence of block-wise missing data, caused by the fact that some users may be very active in certain social networks while inactive in others. The second challenge is how to collaboratively integrate multiple social networks. Towards this end, we first proposed a novel model for data missing completion by seamlessly exploring the knowledge from multiple sources. We then developed a robust multiple social network learning model, and applied it to the application of volunteerism tendency prediction. Extensive experiments on real world dataset verify the effectiveness of our scheme. The proposed scheme is applicable to many other domains, such as demographic inference and interest prediction.", "references": ["F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause. Cross-system user modeling and personalization on the social web. UMUAI, 2013.", "B. Bazelli, A. Hindle, and E. Stroulia. On the personality traits of stack overflow users. In ICSM, 2013.", "F. Benevenuto, T. Rodrigues, V. Almeida, J. Almeida, and M. Gonçalves. Detecting spammers and content promoters in online video social networks. In SIGIR, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767726"}, {"title": "Time-travel Translator: Automatically Contextualizing News Articles", "authors": ["Nam Khanh Tran\n,", "Andrea Ceroni\n,", "Nattiya Kanhabua\n,", "Claudia Niederée"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nFully understanding an older news article requires context knowledge from the time of article creation. Finding information about such context is a tedious and time-consuming task, which distracts the reader. Simple contextualization via Wikification is not sufficient here. The retrieved context information has to be time-aware, concise (not full Wikipages) and focused on the coherence of the article topic. In this paper, we present Contextualizer, a web-based system that acquires additional information for supporting interpretations of a news article of interest that requires a mapping, in this case, a kind of time-travel translation between present context knowledge and context knowledge at time of text creation. For a given article, the system provides a GUI that allows users to highlight their interested keywords which are then used to construct appropriate queries for retrieving contextualization candidates. Contextualizer exploits different kinds of information such as temporal similarity and textual complementarity to re-rank the candidates and presents to users in a friendly and interactive web-based interface.", "references": ["D. Ceccarelli, C. Lucchese, S. Orlando, R. Perego, and S. Trani. Dexter: An open source framework for entity linking. In ESAIR '13, 2013.", "P. Ferragina and U. Scaiella. Tagme: On-the-fly annotation of short text fragments (by wikipedia entities). In CIKM '10, 2010.", "A. Fuxman, P. Pantel, Y. Lv, A. Chandra, P. Chilakamarri, M. Gamon, D. Hamilton, B. Kohlmeier, D. Narayanan, E. Papalexakis, and B. Zhao. Contextual insights. In WWW '14, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742841"}, {"title": "RDF stream processing with CQELS framework for real-time analysis", "authors": ["Danh Le Phuoc\n,", "Minh Dao-Tran\n,", "Anh Le Tuan\n,", "Manh Nguyen Duc\n,", "Manfred Hauswirth"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nThis paper presents a solution to the Grand Challenge using CQELS (Continuous Query Evaluation over Linked Stream), a general execution framework to build RDF Stream Processing engines to answer continuous analytical queries. It provides an efficient execution architecture whereby incremental computing algorithms can be implemented to boost the performance.\nOur experimental results show strong effects of the implemented approach as CQELS outperforms a base-line implementation which recomputes on every incoming input.", "references": ["L. Aders, R. Buffat, Z. Chothia, M. Wetter, C. Balkesen, P. M. Fischer, and N. Tatbu. DEBS'11 Grand Challenge: Streams, Rules, or a Custom Solution? Technical report, ETH, Department of Computer Science, 2011.", "D. Anicic, P. Fodor, S. Rudolph, and N. Stojanovic. EP-SPARQL: a unified language for event processing and stream reasoning. In WWW, pages 635--644, 2011.", "A. Arasu, S. Babu, and J. Widom. The CQL continuous query language: semantic foundations and query execution. VLDB J., 15(2):121--142, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2772586"}, {"title": "Multi-modal & Multi-view & Interactive Benchmark Dataset for Human Action Recognition", "authors": ["Ning Xu\n,", "Anan Liu\n,", "Weizhi Nie\n,", "Yongkang Wong\n,", "Fuwu Li\n,", "Yuting Su"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHuman action recognition is one of the most active research areas in both computer vision and machine learning communities. Several methods for human action recognition have been proposed in the literature and promising results have been achieved on the popular datasets. However, the comparison of existing methods is often limited given the different datasets, experimental settings, feature representations, and so on. In particularly, there are no human action dataset that allow concurrent analysis on three popular scenarios, namely single view, cross view, and cross domain. In this paper, we introduce a Multi-modal & Multi-view & Interactive (M2I) dataset, which is designed for the evaluation of the performances of human action recognition under multi-view scenario. This dataset consists of 1760 action samples, including 9 person-person interaction actions and 13 person-object interaction actions. Moreover, we respectively evaluate three representative methods for the single-view, cross-view, and cross domain human action recognition on this dataset with the proposed evaluation protocol. It is experimentally demonstrated that this dataset is extremely challenging due to large intraclass variation, multiple similar actions, significant view difference. This benchmark can provide solid basis for the evaluation of this task and will benefit advancing related computer vision and machine learning research topics.", "references": ["J. K. Aggarwal and M. S. Ryoo. Human activity analysis: A review. ACM Comput. Surv., 43(3):16, 2011.", "X. Chang, W. Zheng, and J. Zhang. Learning person-person interaction in collective activity recognition. IEEE Transactions on Image Processing, 24(6):1905--1918, 2015.", "W. Choi and S. Savarese. Understanding collective activities of people from videos. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(6):1242--1257, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806315"}, {"title": "Query Expansion with Freebase", "authors": ["Chenyan Xiong\n,", "Jamie Callan"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nLarge knowledge bases are being developed to describe entities, their attributes, and their relationships to other entities. Prior research mostly focuses on the construction of knowledge bases, while how to use them in information retrieval is still an open problem. This paper presents a simple and effective method of using one such knowledge base, Freebase, to improve query expansion, a classic and widely studied information retrieval task. It investigates two methods of identifying the entities associated with a query, and two methods of using those entities to perform query expansion. A supervised model combines information derived from Freebase descriptions and categories to select terms that are effective for query expansion. Experiments on the ClueWeb09 dataset with TREC Web Track queries demonstrate that these methods are almost 30% more effective than strong, state-of-the-art query expansion algorithms. In addition to improving average performance, some of these methods have better win/loss ratios than baseline algorithms, with 50% fewer queries damaged.", "references": ["FACC1 Annotation on ClueWeb09. http://lemurproject.org/clueweb09/FACC1/. Accessed: 2014-06-26.", "M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction for the web. In Processing of the Internaltional Joint Conference on Artifical Intelligence, IJCAI(2007), volume 7, pages 2670--2676. IJCAI, 2007.", "M. Bendersky, D. Fisher, and W. B. Croft. Umass at Trec 2010 Web Track: Term dependence, spam filtering and quality bias. In Proceedings of The 19th Text REtrieval Conference, (TREC 2010). NIST, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809446"}, {"title": "Data layout for power efficient archival storage systems", "authors": ["Ramana Reddy\n,", "Atish Kathpal\n,", "Jayanta Basak\n,", "Randy Katz"], "publication": "HotPower '15: Proceedings of the Workshop on Power-Aware Computing and Systems", "abstract": "ABSTRACT\nLegacy archival workloads have a typical write-once-read-never pattern, which fits well for tape based archival systems. With the emergence of newer applications like Facebook, Yahoo! Flickr, Apple iTunes, demand for a new class of archives has risen, where archived data continues to get accessed, albeit at lesser frequency and relaxed latency requirements. We call these types of archival storage systems as active archives. However, keeping archived data on always spinning storage media to fulfill occasional read requests is not practical due to significant power costs. Using spin-down disks, having better latency characteristics as compared to tapes, for active archives can save significant power. In this paper, we present a two-tier architecture for active archives comprising of online and offline disks, and provide an access-aware intelligent data layout mechanism to bring power efficiency. We validate the proposed mechanism with real-world archival traces. Our results indicate that the proposed clustering and optimized data layout algorithms save upto 78% power over random placement.", "references": ["T. Achterberg. Scip: solving constraint integer programs. Mathematical Programming Computation, 1(1):1--41, 2009.", "S. Balakrishnan, R. Black, A. Donnelly, P. England, A. Glass, D. Harper, S. Legtchenko, A. Ogus, E. Peterson, and A. Rowstron. Pelican: A building block for exascale cold data storage. In Proceedings of the 11th USENIX conference on Operating Systems Design and Implementation, pages 351--365. USENIX Association, 2014.", "D. Beaver, S. Kumar, H. C. Li, J. Sobel, P. Vajgel, et al. Finding a needle in haystack: Facebook's photo storage. In OSDI, volume 10, pages 1--8, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818613.2818742"}, {"title": "Faster Text-to-Speeches: Enhancing Blind People's Information Scanning with Faster Concurrent Speech", "authors": ["João Guerreiro\n,", "Daniel Gonçalves"], "publication": "ASSETS '15: Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility", "abstract": "ABSTRACT\nBlind people rely mostly on the auditory feedback of screen readers to consume digital information. Still, how fast can information be processed remains a major problem. The use of faster speech rates is one of the main techniques to speed-up the consumption of digital information. Moreover, recent experiments have suggested the use of concurrent speech as a valid alternative when scanning for relevant information. In this paper, we present an experiment with 30 visually impaired participants, where we compare the use of faster speech rates against the use of concurrent speech. Moreover, we combine these two approaches by gradually increasing the speech rate with one, two and three voices. Results show that concurrent voices with speech rates slightly faster than the default rate, enable a significantly faster scanning for relevant content, while maintaining its comprehension. In contrast, to keep-up with concurrent speech timings, One-Voice requires larger speech rate increments, which cause a considerable loss in performance. Overall, results suggest that the best compromise between efficiency and the ability to understand each sentence is the use of Two-Voices with a rate of 1.75*default-rate (approximately 278 WPM).", "references": ["Ahmed, F., Borodin, Y., Puzis, Y., and Ramakrishnan, I. V. 2012. Why Read if You Can Skim: Towards Enabling Faster Screen Reading. In Proceedings of the International Cross-Disciplinary Conference on Web Accessibility (W4A).", "Arons, B. 1997 SpeechSkimmer: A System for Interactively Skimming Recorded Speech. ACM Transactions on Computer-Human Interaction (TOCHI) - Special issue on speech as data 4, 1, 3--38.", "Asakawa, C., Takagi, H., Ino, S., and Ifukube, T. 2003 Maximum listening speeds for the blind. In Proceedings of the International Community for Auditory Display (ICAD), pp. 276--279."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700648.2809840"}, {"title": "Towards Personalized Smart City Guide Services in Future Internet Environments", "authors": ["Robert Seeliger\n,", "Christopher Krauss\n,", "Annette Wilson\n,", "Miggi Zwicklbauer\n,", "Stefan Arbanowski"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe FI-CONTENT project aims at establishing the foundation of a European infrastructure for developing and testing novel smart city services. The Smart City Services Platform will develop enabling technology for SMEs and developer to create services offering residents and visitors to cities smart services that enhance their city visit or daily life. We have made use of generic, specific and common enablers to develop a reference implementation, the Smart City Guide web app. The basic information is provided by the Open City Database, an open source specific enabler that can be used for any city in Europe. Recommendation as a Service is an enabler that can be applied to lots use cases, here we describe how we integrated it into the Smart City Guide. The uses cases will be iteratively improved and upgraded during regular iterative cycles based on feedback gained in lab and field trials at the experimentation sites. As the app is transferable to any city, it will be tested at a number of experimentation sites.", "references": ["Call, F. I. P. P. P. \"Future Internet PPP Call 3 in a nutshell.\" Broadband (2013): 201317. https://www.fi-ppp.eu/", "Future media Internet for large-scale CONTent experimentation 2 (FI-CONTENT 2) http://mediafi.org/", "Smart City Services Platform Brun, A.; Bille-Bize Masson, C.; Seeliger, R.; Krause, D.: Scenarios, functional and technical specifications. Public Report D3.1 on the Smart City Services Platform"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743905"}, {"title": "Dismantling the Barriers to Entry", "authors": ["Rich Harris"], "publication": "Queue", "abstract": "Abstract\nWe have to choose to build a web that is accessible to everyone.", "references": ["http://backbonejs.org", "Bloomberg, M. 2012. https://twitter.com/mikebloomberg/status/154999795159805952", "Bostock, M. 2013. For example. http://bost.ocks.org/mike/example/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2773212.2790378"}, {"title": "DeepIndex for Accurate and Efficient Image Retrieval", "authors": ["Yu Liu\n,", "Yanming Guo\n,", "Song Wu\n,", "Michael S. Lew"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn the well-known Bag-of-Words model, local features, such as the SIFT descriptor, are extracted and quantized into visual words. Then, an index is created to reduce computational burden. However, local clues serve as low-level representations that can not represent high-level semantic concepts. Recently, the success of deep features extracted from convolutional neural networks(CNN) has shown promising results toward bridging the semantic gap. Inspired by this, we attempt to introduce deep features into inverted index based image retrieval and thus propose the DeepIndex framework. Moreover, considering the compensation of different deep features, we incorporate multiple deep features from different fully connected layers, resulting in the multiple DeepIndex. We find the optimal integration of one midlevel deep feature and one high-level deep feature, from two different CNN architectures separately. This can be treated as an attempt to further reduce the semantic gap. Extensive experiments on three benchmark datasets demonstrate that, the proposed DeepIndex method is competitive with the state-of-the-art on Holidays(85:65% mAP), Paris(81:24% mAP), and UKB(3:76 score). In addition, our method is efficient in terms of both memory and time cost.", "references": ["P. Agrawal, R. Girshick, and J. Malik. Analyzing the performance of multilayer neural networks for object recognition. In ECCV, 2014.", "R. Arandjelović and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012.", "A. Babenko and V. S. Lempitsky. The inverted multi-index. In CVPR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749300"}, {"title": "Initial field trial of a coach-supported web-based depression treatment", "authors": ["Stephen M. Schueller\n,", "David C. Mohr"], "publication": "PervasiveHealth '15: Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare", "abstract": "ABSTRACT\nEarly web-based depression treatments were often self-guided and included few interactive elements, instead focusing mostly on delivering informational content online. Newer programs include many more types of features. As such, trials should analyze the ways in which people use these sites in order to inform the design of subsequent sites and models of support. The current study describes of a field trial consisting of 9 patients with major depressive disorder who completed a 12-week program including weekly coach calls. Patients usage varied widely, however, patients who formed regular patterns tended to persist with the program for the longest. Future sites might be able to facilitate user engagement by designing features to support regular use and to use coaches to help establish patterns to increase long-term use and benefit.", "references": ["R. C. Kessler, P. Berglund, O. Demler, R. Jin, D. Koretz, K. R. Merikangas, A. J. Rush, E. E. Walters, and P. S. Wang. The epidemiology of major depressive disorder: Results from the National Comorbidity Survey Replication (NCS-R). Journal of the American Medical Association, 289, 23 (2003), 3095--105.", "T. B. Üstün, J. L. Ayuso-Mateos, S. Chatterji, C. Mathers, and C. J. L. Murray. Global burden of depressive disorders in the year 2000. The British Journal of Psychiatry, 184, 5 (2004), 386--92.", "R. C. Kessler, W. T. Chiu, O. Demler, K. R. Merikangas, and E. E. Walters. Prevalence, severity, and comorbidity of 12-month DSM-IV disorders in the National Comobidity Survey replication. Archives of General Psychiatry, 62, 6 (2005), 617--27."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2826165.2826169"}, {"title": "Learning to Reinforce Search Effectiveness", "authors": ["Jiyun Luo\n,", "Xuchu Dong\n,", "Hui Yang"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nSession search is an Information Retrieval (IR) task which handles a series of queries issued for a search task. In this paper, we propose a novel reinforcement learning style information retrieval framework and develop a new feedback learning algorithm to model user feedback, including clicks and query reformulations, as reinforcement signals and to generate rewards in the RL framework. From a new perspective, we view session search as a cooperative game played between two agents, the user and the search engine. We study the communications between the two agents; they always exchange opinions on \"whether the current stage of search is relevant\" and \"whether we should explore now.\" The algorithm infers user feedback models by an EM algorithm from the query logs. We compare to several state-of-the-art session search algorithms and evaluate our algorithm on the most recent TREC 2012 to 2014 Session Tracks. The experimental results demonstrates that our approach is highly effective for improving session search accuracy.", "references": ["Y. Artzi and L. Zettlemoyer. Bootstrapping semantic parsers from conversations. In EMNLP '11.", "D. P. Bertsekas. Dynamic Programming: Deterministic and Stochastic Models. Prentice-Hall, 1987.", "S. R. K. Branavan, H. Chen, L. S. Zettlemoyer, and R. Barzilay. Reinforcement learning for mapping instructions to actions. In ACL '09."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809468"}, {"title": "Smart booking without looking: providing hotel recommendations in the TripRebel portal", "authors": ["Matthias Traub\n,", "Dominik Kowald\n,", "Emanuel Lacic\n,", "Pepijn Schoen\n,", "Gernot Supp\n,", "Elisabeth Lex"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nIn this paper, we present a scalable hotel recommender system for TripRebel, a new online booking portal. On the basis of the open-source enterprise search platform Apache Solr, we developed a system architecture with Web-based services to interact with indexed data at large scale as well as to provide hotel recommendations using various state-of-the-art recommender algorithms. We demonstrate the efficiency of our system directly using the live TripRebel portal where, in its current state, hotel alternatives for a given hotel are calculated based on data gathered from the Expedia Affiliate Network (EAN).", "references": ["M. Balabanović and Y. Shoham. Fab: content-based, collaborative recommendation. Communication of ACM, 40(3):66--72, Mar. 1997.", "S. Bostandjiev, J. O'Donovan, and T. Höllerer. Tasteweights: A visual interactive hybrid recommender system. In Proc. of RecSys '12.", "R. Burke. Hybrid recommender systems: Survey and experiments. User modeling and user-adapted interaction, 12(4):331--370, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809616"}, {"title": "Using Term Location Information to Enhance Probabilistic Information Retrieval", "authors": ["Baiyan Liu\n,", "Xiangdong An\n,", "Jimmy Xiangji Huang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNouns are more important than other parts of speech in information retrieval and are more often found near the beginning or the end of sentences. In this paper, we investigate the effects of rewarding terms based on their location in sentences on information retrieval. Particularly, we propose a novel Term Location (TEL) retrieval model based on BM25 to enhance probabilistic information retrieval, where a kernel-based method is used to capture term placement patterns. Experiments on five TREC datasets of varied size and content indicate the proposed model significantly outperforms the optimized BM25 and DirichletLM in MAP over all datasets with all kernel functions, and excels the optimized BM25 and DirichletLM over most of the datasets in P@5 and P@20 with different kernel functions.", "references": ["H. Ann. The Essentials of English -- a writer's handbook. New York, Pearson Education, 2003.", "C. Dickens. Hard Times. Bradbury & Evans, 1854.", "D. A. Evans and C. Zhai. Noun-phrase analysis in unrestricted text for information retrieval. In ACL 1996, pages 17--24."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767827"}, {"title": "Identifying cover songs using information-theoretic measures of similarity", "authors": ["Peter Foster\n,", "Simon Dixon\n,", "Anssi Klapuri"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nThis paper investigates methods for quantifying similarity between audio signals, specifically for the task of cover song detection. We consider an information-theoretic approach, where we compute pairwise measures of predictability between time series. We compare discrete-valued approaches operating on quantized audio features, to continuous-valued approaches. In the discrete case, we propose a method for computing the normalized compression distance, where we account for correlation between time series. In the continuous case, we propose to compute information-based measures of similarity as statistics of the prediction error between time series. We evaluate our methods on two cover song identification tasks using a data set comprised of 300 Jazz standards and using the Million Song Dataset. For both datasets, we observe that continuous-valued approaches outperform discrete-valued approaches. We consider approaches to estimating the normalized compression distance (NCD) based on string compression and prediction, where we observe that our proposed normalized compression distance with alignment (NCDA) improves average performance over NCD, for sequential compression algorithms. Finally, we demonstrate that continuous-valued distances may be combined to improve performance with respect to baseline approaches. Using a large-scale filter-and-refine approach, we demonstrate state-of-the-art performance for cover song identification using the Million Song Dataset.", "references": ["M. A. Casey, R. Veltkamp, M. Goto, M. Leman, C. Rhodes, and M. Slaney, \"Content-based music information retrieval: Current directions and future challenges,\" Proc. IEEE, vol. 96, no. 4, pp. 668-696, Apr. 2008.", "P. Cano, E. Batlle, T. Kalker, and J. Haitsma, \"A review of audio fingerprinting,\" J. VLSI Signal Process., vol. 41, no. 3, pp. 271-284, 2005.", "J. Serrà, \"Identification of versions of the same musical composition by processing audio descriptions,\" Ph.D. dissertation, Univ. Pompeu Fabra, Barcelona, Spain, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2015.2416655"}, {"title": "Query-Adaptive Logo Search using Shape-Aware Descriptors", "authors": ["Sreyasee Das Bhattacharjee\n,", "Junsong Yuan\n,", "Yap-Peng Tan\n,", "Lingyu Duan"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe propose a graph-based optimization framework to leverage category independent object proposals (candidate object regions) for logo search in a large scale image database. The proposed contour-based feature descriptor EdgeBoW is robust to view-angle changes, varying illumination conditions and can implicitly capture the significant object shape information. Having been equipped with a local descriptor, it can handle a fair amount of occlusion and deformation frequently present in a real-life scenario. Given a small set of initially retrieved candidate object proposals, a fast graph-based short-listing scheme is designed to exploit the mutual similarities among these proposals for eliminating outliers. In contrast to a coarse image-level pairwise similarity measure, this search focussed on a few specific image regions provides a more accurate method for matching. The proposed query expansion strategy aims to assess each of the remaining better matched proposals against all its neighbors within the same image for a precise localization. Combined with an efficient feature descriptor EdgeBoW, a set of more insightful edge-weights and node-utility measures can yield promising results, specially for object categories primarily defined by its shape. Extensive set of experiments performed on a number of benchmark datasets demonstrates its effectiveness and superior generalization ability in both clutter intensive real-life images and poor quality binary document images.", "references": ["R. Tao, E. Gavves, C. Snoek, and A. Smeulders, \"Locality in generic instance search from one example\", in Proceedings of the Computer Vision and Pattern Recognition, 2014.", "Y. Zhang, Z. Jia, and T. Chen, \"Image retrieval with geometry-preserving visual phrases\", in Proceedings of the Computer Vision and Pattern Recognition, 2011.", "J. Meng, J. Yuan, Y. Jiang, N. Narasimhan, V. Vasudevan, and Y. Wu, \"Interactive visual object search through mutual information maximization\", in Proceedings of the ACM international conference on Multimedia, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806305"}, {"title": "A demonstration of TripleProv: tracking and querying provenance over web data", "authors": ["Marcin Wylot\n,", "Philippe Cudré-Mauroux\n,", "Paul Groth"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe proliferation of heterogeneous Linked Data on the Web poses new challenges to database systems. In particular, the capacity to store, track, and query provenance data is becoming a pivotal feature of modern triple stores. In this demonstration, we present TripleProv: a new system extending a native RDF store to efficiently handle the storage, tracking and querying of provenance in RDF data. In the following, we give an overview of our approach providing a reliable and understandable specification of the way results were derived from the data and how particular pieces of data were combined to answer the query. Subsequently, we present techniques enabling to tailor queries with provenance data. Finally, we describe our demonstration and how the attendees will be able to interact with our system during the conference.", "references": ["F. Geerts, G. Karvounarakis, V. Christophides, and I. Fundulaki. Algebraic structures for capturing the provenance of sparql queries. In Proceedings of the 16th International Conference on Database Theory, ICDT '13, pages 153--164, New York, NY, USA, 2013. ACM.", "T. J. Green, G. Karvounarakis, and V. Tannen. Provenance semirings. In Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pages 31--40. ACM, 2007.", "P. Groth and L. Moreau (eds.). PROV-Overview. An Overview of the PROV Family of Documents. W3C Working Group Note NOTE-prov-overview-20130430, World Wide Web Consortium, Apr. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824119"}, {"title": "Interactive Video Search", "authors": ["Klaus Schoeffmann\n,", "Frank Hopfgartner"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith an increasing amount of video data in our daily life, the need for content-based search in videos increases as well. Though a lot of research has been spent on video retrieval tools and methods which allow for automatic search in videos through content-based queries, still the performance of automatic video retrieval is far from optimal. In this tutorial we discussed (i) proposed solutions for improved video content navigation, (ii) typical interaction of content-based querying features, and (iii) advanced video content visualization methods. Moreover, we discussed interactive video search systems and ways to evaluate their performance.", "references": ["B. Adams, S. Greenhill, and S. Venkatesh. Towards a video browser for the digital native. In ICMEW'12, pages 127--132, July 2012.", "M. Christel, C. Huang, N. Moraveji, and N. Papernick. Exploiting multiple modalities for interactive video retrieval. In ICASSP'04, volume 3, pages iii--1032, May 2004.", "M. G. Christel and R. Yan. Merging storyboard strategies and automatic retrieval for improving interactive video search. In CIVR'07, pages 486--493, New York, NY, USA, 2007. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807417"}, {"title": "Microblog Entity Linking with Social Temporal Context", "authors": ["Wen Hua\n,", "Kai Zheng\n,", "Xiaofang Zhou"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nNowadays microblogging sites, such as Twitter and Chinese Sina Weibo, have established themselves as an invaluable information source, which provides a huge collection of manually-generated tweets with broad range of topics from daily life to breaking news. Entity linking is indispensable for understanding and maintaining such information, which in turn facilitates many real-world applications such as tweet clustering and classification, personalized microblog search, and so forth. However, tweets are short, informal and error-prone, rendering traditional approaches for entity linking in documents largely inapplicable. Recent work addresses this problem by utilising information from other tweets and linking entities in a batch manner. Nevertheless, the high computational complexity makes this approach infeasible for real-time applications given the high arrival rate of tweets. In this paper, we propose an efficient solution to link entities in tweets by analyzing their social and temporal context. Our proposed framework takes into consideration three features, namely entity popularity, entity recency, and user interest information embedded in social interactions to assist the entity linking task. Effective indexing structures along with incremental algorithms have also been developed to reduce the computation and maintenance costs of our approach. Experimental results based on real tweet datasets verify the effectiveness and efficiency of our proposals.", "references": ["J. Teevan, D. Ramage, and M. R. Morris.#twittersearch: A comparison of microblog search and web search. In WSDM, pages 35--44, 2011.", "W. Shen, J. Wang, P. Luo, and M. Wang. Linking named entities in tweets with knowledge base via user interest modeling. In KDD, pages 68--76, 2013.", "R. Mihalcea and A. Csomai. Wikify!: Linking documents to encyclopedic knowledge. In CIKM, pages 233--242, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2751522"}, {"title": "Integrating crowd intelligence into software", "authors": ["Rick Salay\n,", "Fabiano Dalpiaz\n,", "Marsha Chechik"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nThe knowledge resources available on the Internet are increasingly being used to support software both at development time and at execution time. These take the form of conventional services as well as human knowledge work both through crowd sourcing and information stored directly on the World Wide Web. But while these resources are vast and rich, they are also unreliable. In this paper, we propose a novel software development pattern called contributional implementation (CI) inspired by the way humans mitigate this unreliability: sources are treated as opinion providers with varying amounts of trust and aggregating multiple opinions from different sources helps improve the quality of the answers. We sketch some detailed examples of how a CI could be coded, discuss issues related to the realization of CI's in practice and outline plans for an evaluation of the approach.", "references": ["K.-J. Stol and B. Fitzgerald, \"Two's company, three's a crowd: A case study of crowdsourcing software development,\" in Proceedings of ICSE. New York, NY, USA: ACM, 2014, pp. 187--198. {Online}. Available: http://doi.acm.org/10.1145/2568225.2568249", "T. D. LaToza, M. Chen, L. Jiang, M. Zhao, and A. van der Hoek, \"Borrowing from the crowd: A study of recombination in software design competitions,\" in In Proceedings of ICSE (to appear), 2015.", "S. L. Lim, D. Quercia, and A. Finkelstein, \"Stakesource: harnessing the power of crowdsourcing and social networks in stakeholder analysis,\" in Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering-Volume 2. ACM, 2010, pp. 239--242."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820117"}, {"title": "An improved approach of lung image segmentation based on watershed algorithm", "authors": ["Xiaodan Chen\n,", "Shouting Feng\n,", "Daru Pan"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nAs a preprocessing step of chest Computed Tomography (CT) images, lung segmentation is significant for the diagnosis of lung disease. The traditional watershed algorithm is sensitive to the noise and has the drawback of over-segmentation problem. This paper presents a novel image segmentation method to improve Watershed segmentation algorithm with the maximum between-class variance algorithm (OTSU). We adopt the OTSU method and mathematical morphology method in the period of the initial image segmentation and then compute a segmentation function. Finally, we compute the watershed transform of the segmentation function. The experimental results point out that this method is an effective segmentation method of lung parenchyma, which lessens the problem of the over-segmentation in the lung image effectively and runs faster.", "references": ["Nishikawa R. Current status and future directions of computer-aided diagnosis in mammography {J}. Computerized Medical Imaging and Graphics, 2007:10(1):224--235.", "L. Tseng, L. Huang, An adaptive thresholding method for automatic lung segmentation in ct images, in: IEEE AFRICON, 2009, pp. 1--5.", "A. Karthikeyan, M. Vallianmmai, Lungs segmentation using multi-level225 thresholding in ct images, International Journal of Electroics and Computer Science Engineering 1 (3) (2012) 1509--1513."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808531"}, {"title": "EsdRank: Connecting Query and Documents through External Semi-Structured Data", "authors": ["Chenyan Xiong\n,", "Jamie Callan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper presents EsdRank, a new technique for improving ranking using external semi-structured data such as controlled vocabularies and knowledge bases. EsdRank treats vocabularies, terms and entities from external data, as objects connecting query and documents. Evidence used to link query to objects, and to rank documents are incorporated as features between query-object and object-document correspondingly. A latent listwise learning to rank algorithm, Latent-ListMLE, models the objects as latent space between query and documents, and learns how to handle all evidence in a unified procedure from document relevance judgments. EsdRank is tested in two scenarios: Using a knowledge base for web search, and using a controlled vocabulary for medical search. Experiments on TREC Web Track and OHSUMED data show significant improvements over state-of-the-art baselines.", "references": ["M. Bendersky, D. Metzler, and W. B. Croft. Effective query formulation with multiple information sources. In Proceedings of the fifth ACM International Conference on Web Search and Data Mining, pages 443--452. ACM, 2012.", "A. Berger and J. Lafferty. Information retrieval as statistical translation. In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 222--229. ACM, 1999.", "K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, pages 1247--1250. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806456"}, {"title": "A Bi-Dimensional User Profile to Discover Unpopular Web Sources", "authors": ["Romain Noël\n,", "Nicolas Malandain\n,", "Alexandre Pauchet\n,", "Laurent Vercouter\n,", "Bruno Grilheres\n,", "Stephan Brunessaux"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe discovery of new sources of information on a given topic is a prominent problem for Experts in Intelligence Analysis (EIA) who cope with the search of pages on specific and sensitive topics. Their information needs are difficult to express with queries and pages with sensitive content are difficult to find with traditional search engines as they are usually poorly indexed. We propose a double vector to model EIA's information needs, composed of DBpedia resources and keywords, both extracted from Web pages provided by the user. We also introduce a new similarity measure that is used in a Web source discovery system called DOWSER. DOWSER aims at providing users with new sources of information related to their needs without considering the popularity of a page. A series of experiments provides an empirical evaluation of the whole system.", "references": ["D. Bergmark, C. Lagoze, and A. Sbityakov. Research and Advanced Technology for Digital Libraries, pages 49--70.", "C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. Dbpedia-a crystallization point for the web of data. Web Semantics: Science, Services and Agents on the World Wide Web, 7(3):154--165, 2009.", "S. Chakrabarti, M. Van den Berg, and B. Dom. Focused crawling: a new approach to topic-specific web resource discovery. Computer Networks, 31(11--16):1623--1640, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742139"}, {"title": "Clustered Semi-Supervised Relevance Feedback", "authors": ["Kripabandhu Ghosh\n,", "Swapan Kumar Parui"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn relevance feedback, first-round search results are used to boost second-round search results. Two forms have been traditionally considered: exhaustively labelled feedback, where all first-round results to depth k are annotated for relevance by the user; and blind feedback, where the top-k results are all assumed to be relevant. In this paper, we consider an intermediate, semi-supervised scheme, in which only a subset of results is selected for annotation, and then their labels are propagated to their nearest neighbours. Specifically, we use clustering to determine the nearest-neighbour groups, and seed selection to choose documents for annotation. We find that the effectiveness of this method is indistinguishable from the exhaustive relevance feedback, and is significantly higher than both blind feedback and the use of the annotated subset alone. We show that this approach works well in environments in which some but limited amounts of human feedback are available, such as early case assessment in e-discovery.", "references": ["J. Baron, D. Lewis, and D. Oard. Trec-2006 legal track overview. 2006.", "G. V. Cormack, M. R. Grossman, B. Hedin, and D. W. Oard. Overview of the trec 2010 legal track. 2010.", "K. Ghosh, S. K. Parui, P. Majumder, A. Bandyopadhyay, and S. J. J. R. Singh. Indian statistical institute, kolkata at trec 2010: Legal interactive. TREC 2010, Nov. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806596"}, {"title": "An optimization approach for load balancing in parallel link discovery", "authors": ["Mohamed Ahmed Sherif\n,", "Axel-Cyrille Ngonga Ngomo"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nMany of the available RDF datasets describe millions of resources by using billions of triples. Consequently, millions of links can potentially exist among such datasets. While parallel implementations of link discovery approaches have been developed in the past, load balancing approaches for local implementations of link discovery algorithms have been paid little attention to. In this paper, we thus present a novel load balancing technique for link discovery on parallel hardware based on particle-swarm optimization. We combine this approach with the Orchid algorithm for geo-spatial linking and evaluate it on real and artificial datasets. Our evaluation suggests that while naïve approaches can be super-linear on small data sets, our deterministic particle swarm optimization outperforms both naïve and classical load balancing approaches such as greedy load balancing on large datasets.", "references": ["Selim G Akl. Superlinear performance in real-time parallel computation. The Journal of Supercomputing, 29(1):89--111, 2004.", "Enrique Alba. Parallel evolutionary algorithms can achieve super-linear performance. Information Processing Letters, 82(1):7--13, 2002.", "Liaquat Ali, Thomas Janson, and Christian Schindelhauer. Towards load balancing and parallelizing of rdf query processing in p2p based distributed rdf data stores. In Parallel, Distributed and Network-Based Processing (PDP), 2014 22nd Euromicro International Conference on, pages 307--311. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814872"}, {"title": "WOSP2015: 4th International Workshop on Mining Scientific Publications", "authors": ["Petr Knoth\n,", "Kris Jack\n,", "Lucas Anastasiou\n,", "Nuno Freire\n,", "Nancy Pontika\n,", "Drahomira Herrmannova"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756932"}, {"title": "Collaborative Ranking with a Push at the Top", "authors": ["Konstantina Christakopoulou\n,", "Arindam Banerjee"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe goal of collaborative filtering is to get accurate recommendations at the top of the list for a set of users. From such a perspective, collaborative ranking based formulations with suitable ranking loss functions are natural. While recent literature has explored the idea based on objective functions such as NDCG or Average Precision, such objectives are difficult to optimize directly. In this paper, building on recent advances from the learning to rank literature, we introduce a novel family of collaborative ranking algorithms which focus on accuracy at the top of the list for each user while learning the ranking functions collaboratively. We consider three specific formulations, based on collaborative p-norm push, infinite push, and reverse-height push, and propose efficient optimization methods for learning these models. Experimental results illustrate the value of collaborative ranking, and show that the proposed methods are competitive, usually better than existing popular approaches to personalized recommendation.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In KDD, 19--28, 2009.", "D. Agarwal, B.-C. Chen, P. Elango and R. Ramakrishnan. Content recommendation on web portals. In Communications of the ACM, 56(6): 92--101, 2013.", "S. Agarwal. The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list. In SDM, 839--850, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741678"}, {"title": "Assessement of features influencing the voting for opinions' helpfulness about services in Portuguese", "authors": ["Augusto C. S. Martins\n,", "Cesar A. Tacla"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents the application of a methodology for evaluation of usefulness of opinions with the aim of identifying which characteristics have more influence on the amount of votes: basic utility (e.g. ratings about the product and/or service, date of publication), textual (e.g. size of words, paragraphs) and semantics (e.g., the meaning of the words of the text). The evaluation was performed in a database extracted from TripAdvisor with opinions about hotels written in Portuguese. Results show that users give more attention to recent opinions with higher scores for value and location of the hotel and with lowest scores for cleanliness and quality of rooms. Texts with small values for intelligibility (more difficult) receive more votes than texts with large values of intelligibility.", "references": ["H. Akaike. A new look at the statistical model identification. Automatic Control, IEEE Transactions on, 19(6):716-723, Dec 1974.", "J. A. Anderson. Regression and ordered categorical variables. Journal of the Royal Statistical Society. Series B (Methodological), pages 1-30, 1984.", "Apache. Opennlp, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814083"}, {"title": "Influences of Organizational Culture in the Adoption of Agile Methodologies in Information Systems Development: A Systematic Mapping", "authors": ["Gerson Correia da Silva\n,", "Joao Paulo Amaral\n,", "Patricia Gomes Fernandes Matsubara\n,", "Valdemar Vicente Graciano"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nInformation Systems (IS) industry has been pressured to deliver software products under reduced time-to-market and restrict budget. Agile Methodologies (AM) have been adopted to meet those aforementioned needs by the adoption of self-managing teams, iterative development cycles, fast delivery, and focus on functional software. Adoption of AM requires a suitable organizational environment, with significant changes in the employees' behavior and in the working processes, impacting, and suffering the impact of Organizational Culture (OC). In this direction, methods, actions, and policies must be thought to align the company's OC to the use of AM, in such a way that both can benefit each other. However, there is a lack of proposals that systematically investigate how to align both OC and AM. In this sense, a systematic mapping study (SMS) was conducted to identify studies that associate OC in initiatives of AM adoption. This paper presents the state-of-the-art about the influence of OC in the adoption of AM. The main contribution of this paper is bringing up an overview of the area, indicating perspectives of research, and exposing (i) a list of actions which have been reported to align OC and AM; (ii) OC factors recognized as essential to the successful adoption of AM; and (iii) the perceptions on a lack of awareness about the influence of OC in IT organizations.", "references": ["Agile manifesto. www.agilemanifesto.org, 2001. Acessado em 10 de janeiro de 2015.", "Adoption of agile methods. http://www.methodsandtools.com/dynpoll/oldpoll.php?Agile2, 2008. Acessado em 5 de fevereiro de 2015.", "M. S. Ali, M. A. Babar, L. Chen, and K.-J. Stol. A systematic review of comparative evidence of aspect-oriented programming. IST, 52(9):871-887, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814096"}, {"title": "Local Filtering: Improving the Performance of Approximate Queries on String Collections", "authors": ["Xiaochun Yang\n,", "Yaoshu Wang\n,", "Bin Wang\n,", "Wei Wang"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nWe study efficient query processing for approximate string queries, which find strings within a string collection whose edit distances to the query strings are within the given thresholds. Existing methods typically hinge on the property that globally similar strings must share at least certain number of identical substrings or subsequences. They become ineffective when there are burst errors or when the number of errors is large. In this paper, we explore the opposite paradigm focusing on finding out the differences of database strings to the query string. We propose a new filtering method, called local filtering, based on the idea that two strings exhibiting substantial local dissimilarities must be globally dissimilar. We propose the concept of (positional) local distance to quantify the minimum amount of errors a query fragment contributes to the edit distance between the query and a data string. It also leads to effective pruning rules and can speed up verification via early termination. We devise a family of indexing methods based on the idea of precomputing (positional) local distances for all possible combinations of query fragments and edit distance thresholds. Based on careful analyses of subtle relationships among local distances, novel techniques are proposed to drastically reduce the amount of enumeration with no or little impact on the pruning power. Efficient query processing methods exploiting the new index and bit-parallelism are also proposed. Experimental results on real datasets show that our local filtering-based methods can achieve substantial speedup compared with state-of-the-art methods, and they are robust against factors such as dataset characteristics and large edit distance thresholds.", "references": ["A. Arasu, V. Ganti, and R. Kaushik. Efficient exact set-similarity joins. In VLDB, 2006.", "R. J. Bayardo, Y. Ma, and R. Srikant. Scaling up all-pairs similarity search. In WWW, 2007.", "B. Bustos and T. Skopal. Non-metric similarity search problems in very large collections. In ICDE, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2749445"}, {"title": "Who With Whom And How?: Extracting Large Social Networks Using Search Engines", "authors": ["Stefan Siersdorfer\n,", "Philipp Kemkes\n,", "Hanno Ackermann\n,", "Sergej Zerr"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSocial network analysis is leveraged in a variety of applications such as identifying influential entities, detecting communities with special interests, and determining the flow of information and innovations. However, existing approaches for extracting social networks from unstructured Web content do not scale well and are only feasible for small graphs. In this paper, we introduce novel methodologies for query-based search engine mining, enabling efficient extraction of social networks from large amounts of Web data. To this end, we use patterns in phrase queries for retrieving entity connections, and employ a bootstrapping approach for iteratively expanding the pattern set. Our experimental evaluation in different domains demonstrates that our algorithms provide high quality results and allow for scalable and efficient construction of social graphs.", "references": ["A. Anagnostopoulos, R. Kumar, and M. Mahdian. Influence and correlation in social networks. KDD '08, pages 7--15. ACM, 2008.", "N. Bach and S. Badaskar. A Review of Relation Extraction. 2007.", "C. Bird, A. Gourley, P. Devanbu, M. Gertz, and A. Swaminathan. Mining email social networks. In Proceedings of the 2006 International Workshop on Mining Software Repositories, MSR '06, pages 137--143. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806582"}, {"title": "Text Classification Kernels for Quality Prediction over the C3 Data Set", "authors": ["Balint Daroczy\n,", "David Siklois\n,", "Robert Palovics\n,", "Andras A. Benczur"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe compare machine learning methods to predict quality aspects of the C3 dataset collected as a part of the Reconcile project. We give methods for automatically assessing the credibility, presentation, knowledge, intention and completeness by extending the attributes in the C3 dataset by the page textual content. We use Gradient Boosted Trees and recommender methods over the evaluator, site, evaluation triplets and their metadata and combine with text classifiers. In our experiments best results can be reached by the theoretically justified normalized SVM kernel. The normalization can be derived by using the Fisher information matrix of the text content. As the main contribution, we describe the theory of the Fisher matrix and show that SVM may be particularly suitable for difficult text classification tasks.", "references": ["J. Abernethy, O. Chapelle, and C. Castillo. WITCH: A New Approach to Web Spam Detection. In Proc. 4th AIRWeb, 2008.", "R. M. Bell and Y. Koren. Lessons from the netflix prize challenge. ACM SIGKDD Explorations Newsletter, 9(2):75--79, 2007.%", "A. Ben-Hur and W. S. Noble.% Kernel methods for predicting protein--protein interactions. Bioinformatics, 21(suppl 1):i38--i46, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2778847"}, {"title": "Interlinking English and Chinese RDF Data Using BabelNet", "authors": ["Tatiana Lesnikova\n,", "Jérôme David\n,", "Jérôme Euzenat"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nLinked data technologies make it possible to publish and link structured data on the Web. Although RDF is not about text, many RDF data providers publish their data in their own language. Cross-lingual interlinking aims at discovering links between identical resources across knowledge bases in different languages. In this paper, we present a method for interlinking RDF resources described in English and Chinese using the BabelNet multilingual lexicon. Resources are represented as vectors of identifiers and then similarity between these resources is computed. The method achieves an F-measure of 88%. The results are also compared to a translation-based method.", "references": ["B. Fu, R. Brennan, and D. O'Sullivan. A Configurable Translation-Based Cross-Lingual Ontology Mapping System to adjust Mapping Outcome. Journal of Web Semantics: Science, Services and Agents on the World Wide Web, 15(3):15--36, 2012.", "J. Garcia, E. Montiel-Ponsoda, P. Cimiano, A. Gómez-Pérez, P. Buitelaar, and J. McCrae. Challenges for the Multilingual Web of Data. Journal of Web Semantics, 11:63--71, 2012.", "T. Lesnikova, J. David, and J. Euzenat. Interlinking English and Chinese RDF Data Sets Using Machine Translation. In Proceedings of the 3rd Workshop on Knowledge Discovery and Data Mining Meets Linked Open Data (Know@LOD 2014), volume 1243. CEUR-WS, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797089"}, {"title": "Rapid Clothing Retrieval via Deep Learning of Binary Codes and Hierarchical Search", "authors": ["Kevin Lin\n,", "Huei-Fang Yang\n,", "Kuan-Hsien Liu\n,", "Jen-Hao Hsiao\n,", "Chu-Song Chen"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper deals with the problem of clothing retrieval in a recommendation system. We develop a hierarchical deep search framework to tackle this problem. We use a pre-trained network model that has learned rich mid-level visual representations in module 1. Then, in module 2, we add a latent layer to the network and have neurons in this layer to learn hashes-like representations while fine-tuning it on the clothing dataset. Finally, module 3 achieves fast clothing retrieval using the learned hash codes and representations via a coarse-to-fine strategy. We use a large clothing dataset where 161,234 clothes images are collected and labeled. Experiments demonstrate the potential of our proposed framework for clothing retrieval in a large corpus.", "references": ["T. Ahonen, A. Hadid, and M. Pietikainen. Face description with local binary patterns: Application to face recognition. IEEE Trans. PAMI, 28(12):2037--2041, 2006.", "H. Chen, A. Gallagher, and B. Girod. Describing clothing by semantic attributes. In Proc. ECCV, 2012.", "D. C. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Proc. CVPR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749318"}, {"title": "Human-Centric Images and Videos Analysis", "authors": ["Si Liu\n,", "BingBing Ni\n,", "Liang Lin"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis article summarizes the corresponding half-day tutorial at ACM Multimedia 2015. This tutorial reviews recent progresses in human-centric images and videos analysis: 1) fashion analysis: parsing, attribute prediction and retrieval; 2) action analysis: discriminative feature selection, pooling and fusion; 3) person verification: cross-domain person verification via learning a generalized similarity measure, and bit-scalable deep hashing with regularized similarity learning.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807422"}, {"title": "Is consumer perception of foreign online stores affected by the image of the country? An experimental study among Japanese consumers", "authors": ["Vanessa Bracamonte\n,", "Hitoshi Okada"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nAn experimental study was conducted in Japan to investigate the influence of the perception of country-of-origin image in the evaluation of a foreign online store. The effects of country-of-origin image on consumer behavior have been investigated for products and services, but they have seldom been considered for electronic commerce. In this study, we propose that cognitive and affective dimensions of the country-of-origin image will have a positive influence on visual appeal, trust and intention of use of a foreign online store. A survey was conducted which measured the responses of Japanese respondents towards mockup online stores from Thailand and Singapore. The data was analyzed using structural equation modeling. The results show that country-of-origin image has a positive influence on the evaluation of the foreign online store, but that this influence is not equal for all countries. In general, the image of Thailand as a country has a wider influence on the Thai online store, than the Singapore image has on the Singaporean online store. We discuss these results and their implications for cross-border electronic commerce.", "references": ["Consumer Affairs Agency of Japan. Ekkyou torihiki ni kansuru chousa no gaiyou ni tsuite. 2011.", "P. W. Verlegh and J.-B. E. Steenkamp. A review and meta-analysis of country-of-origin research. Journal of Economic Psychology, 20(5):521--546, Oct. 1999.", "K. J. Dinnie. Country-of-origin 1965-2004: a literature review. Journal of Customer Behaviour, 3(2):165--213, July 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818923"}, {"title": "AutoCSP: automatically retrofitting CSP to web applications", "authors": ["Mattia Fazzini\n,", "Prateek Saxena\n,", "Alessandro Orso"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 1", "abstract": "ABSTRACT\nWeb applications often handle sensitive user data, which makes them attractive targets for attacks such as cross-site scripting (XSS). Content security policy (CSP) is a content-restriction mechanism, now supported by all major browsers, that offers thorough protection against XSS. Unfortunately, simply enabling CSP for a web application would affect the application's behavior and likely disrupt its functionality. To address this issue, we propose AutoCSP, an automated technique for retrofitting CSP to web applications. AutoCSP (1) leverages dynamic taint analysis to identify which content should be allowed to load on the dynamically-generated HTML pages of a web application and (2) automatically modifies the server-side code to generate such pages with the right permissions. Our evaluation, performed on a set of real-world web applications, shows that AutoCSP can retrofit CSP effectively and efficiently.", "references": ["\"Can I use... Support tables for HTML5, CSS3, etc,\" http://www.caniuse.com/contentsecuritypolicy, 2014.", "A. Barth, J. Caballero, and D. Song, \"Secure Content Sniffing for Web Browsers, or How to Stop Papers from Reviewing Themselves,\" in Proceedings of the IEEE Symposium on Security and Privacy (S&P), 2009.", "S. Stamm, B. Sterne, and G. Markham, \"Reining in the Web with Content Security Policy,\" in Proceedings of the International World Wide Web Conference (WWW), 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2818754.2818797"}, {"title": "Ann2RDF: moving annotations to semantic web", "authors": ["Pedro Sernadela\n,", "Sérgio Matos\n,", "José Luís Oliveira"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThe annotation of concepts and susceptible interactions has been assuming a key role in the extraction of relevant information from published documents. However, distinct annotation tools generate also different formats, creating a barrier to efficiently combine and exchange this information. The migration of curated information into semantic web format and services provides an additional value to share that knowledge, but data transformation represents here an additional challenge. In this manuscript, we present a unified layer between text-mining tools and semantic web services to reduce the effort of combining different formats. The Ann2RDF is focused on reusing existing curated data from external text-mining tools to improve their availability through an open representation model. This result in a more suitable transition process, in which desired annotations are enriched with the possibility to be shared, compared and reused across semantic Knowledge Bases.", "references": ["L. Hunter and K. B. Cohen, \"Biomedical language processing: what's beyond PubMed?,\" Mol. Cell, vol. 21, no. 5, pp. 589--94, Mar. 2006.", "P. Stenetorp, S. Pyysalo, and G. Topić, \"BRAT: a web-based tool for NLP-assisted text annotation,\" Proc. Demonstr. 13th Conf. Eur. Chapter Assoc. Comput. Linguist., pp. 102--107, 2012.", "D. Campos, J. Lourenco, S. Matos, and J. L. Oliveira, \"Egas: a collaborative and interactive document curation platform,\" Database, vol. 2014, Jun. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837253"}, {"title": "Analysis and Evaluation of Social Contagion of Physical Activity in a Group of Young Adults", "authors": ["Eric F. M. Araújo\n,", "Anita V. T. T. Tran\n,", "Julia S. Mollee\n,", "Michel C. A. Klein"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIt is known that opinions, attitudes and emotions spread through social networks. Several of these cognitions influence behavioral choices. Therefore, it is assumed that the level of physical activity of a person is influenced by the activity levels of the people in its social network. We have performed an experiment with 20 participants between 19 and 28 years old, measuring their physical activity levels for 30 days, in order to observe if there is a contagion effect due to the relationships in the social network. Using our social contagion model, we investigated if people will become more or less active according to the contacts with their peers within the network. Our model correctly predicts the direction of the change (increasing or decreasing) in 80% up to 87% of the cases investigated.", "references": ["Allender, S., Cowburn, G., and Foster, C. Understanding participation in sport and physical activity among children and adults: a review of qualitative studies. Health Education Research 21, 6 (2006), 826--835.", "Aral, S., and Walker, D. Identifying influential and susceptible individuals in social networks: Evidence from a randomized experiment. Proceedings of WISC (2010), 1--7.", "Bosse, T., Duell, R., Memon, Z. A., Treur, J., and Van Der Wal, C. N. A multi-agent model for emotion contagion spirals integrated within a supporting ambient agent model. In Principles of Practice in Multi-Agent Systems. Springer, 2009, pp. 48--67."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818922"}, {"title": "Mining minds: an innovative framework for personalized health and wellness support", "authors": ["Oresti Banos\n,", "Muhammad Bilal Amin\n,", "Wajahat Ali Khan\n,", "Taqdir Ali\n,", "Muhammad Afzal\n,", "Byeong Ho Kang\n,", "Sungyoung Lee"], "publication": "PervasiveHealth '15: Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare", "abstract": "ABSTRACT\nThe world is witnessing a spectacular shift in the delivery of health and wellness care. The key ingredient of this transformation consists in the use of revolutionary digital technologies to empower people in their self-management as well as to enhance traditional care procedures. While substantial domain-specific contributions have been provided to that end in the recent years, there is a clear lack of platforms that may orchestrate, and intelligently leverage, all the data, information and knowledge generated through these technologies. This work presents Mining Minds, an innovative framework that builds on the core ideas of the digital health and wellness paradigms to enable the provision of personalized healthcare and wellness support. Mining Minds embraces some of the currently most prominent digital technologies, ranging from Big Data and Cloud Computing to Wearables and Internet of Things, and state-of-the-art concepts and methods, such as Context-Awareness, Knowledge Bases or Analytics, among others. This paper aims at thoroughly describing the efficient and rational combination and interoperation of these modern technologies and methods through Mining Minds, while meeting the essential requirements posed by a framework for personalized health and wellness support.", "references": ["S. R. Frank, \"Digital health care-the convergence of health care and the internet,\" Journal of Ambulatory Care Management, vol. 23, no. 2, pp. 8--17, 2000.", "O. Banos et al., \"An Innovative Platform for Person-Centric Health and Wellness Support,\" in International Work-Conference on Bioinformatics and Biomedical Engineering, 2015.", "A. C. Powell et al., \"In search of a few good apps,\" The Journal of the American Medical Association, vol. 311, no. 18, pp. 1851--1852, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2826165.2826166"}, {"title": "Workshop on the application of security and testing to rich internet applications", "authors": ["Guy-Vincent Jourdan\n,", "Gregor Bochmann\n,", "Ettore Merlo\n,", "James Miller\n,", "Vio Onut\n,", "Lin Tan"], "publication": "CASCON '15: Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nWeb applications and service-oriented architectures represent an increasing part of modern software, and use more advanced techniques such as Ajax and HTML5, CCS3, JavaScript, AJAX, websockets and Client-side data. These new applications, sometimes called \"Rich Internet Applications\" (RIAs), are now being used routinely, either directly or deployed as cloud services. In addition, more and more of these applications and services are accessed from mobile devices; meanwhile, wireless connected devices rapidly grow in number to connect to the \"Internet-of-things\".", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2886444.2886511"}, {"title": "Transparent Sharing Architecture of Content Between Mobile Devices in Opportunistic Networks", "authors": ["Charles Tim Batista Garrocho\n,", "Mauricio Jose Silva\n,", "Ricardo Augusto Rabelo R. Oliveira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nOpportunistic networks are one of the most interesting developments of MANETs, which allow various applications, such as downloading the mobile traffic, communications in emergency situations and contour censorship. The increasing number of mobile devices should, in theory, promote opportunistic networks. However, in practice, current technologies for opportunistic networks, such as Wi-Fi ad-hoc, Bluetooth and Wi-Fi Direct, or are not available in current devices, or unwanted require user interaction to establish connectivity. To overcome these shortcomings, we propose an architecture that uses the Wi-Fi infrastructure mode in order to promote communication between devices, allowing the transparent exchange without user interaction content. Two applications that employ the use of this architecture are presented. The first, from personal devices, proved to be scalable in tests with up to nine devices. The second, vehicles, proved to be feasible when applied in scenarios with low speed, generating a low packet loss and high transmission rates.", "references": ["N.D. Lane, E. Miluzzo, Hong Lu, T. Choudhury, e A. T. Campbell (2010). A survey of mobile phone sensing. In Communications Magazine IEEE, 48, 140-150.", "R. K. Ganti, Fan Ye, e Hui Lei. (2011). Mobile crowdsensing: current state and future challenges, fn Communications Magazine IEEE, 49, 32-39.", "L. Pelusi, A. Passarelia, M. Conti. (2006). Opportunistic networking: data forwarding in disconnected mobile ad hoc networks. Em Communications Magazine, IEEE, 44, 134-141."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814117"}, {"title": "Mobile Audio Intelligence: From Real Time Segmentation to Crowd Sourced Semantics", "authors": ["Lazaros Vrysis\n,", "Nikolaos Tsipas\n,", "Charalampos Dimoulas\n,", "George Papanikolaou"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThe task of general audio detection and segmentation based in means of machine learning is very popular and high-demanding procedure nowadays. Most relevant works in the last decade aim at modelling audio in order to conduct a semantics analysis and a high--level categorization. A generic strategy that would detect audio events as means of transitions from one audio state to another is considered interesting and would support whole classification workflow. This work investigates the possibilities in designing a robust bimodal segmentation algorithm for audio that would perform well in different conditions without relying on complicated machine learning schemes by minimizing prior knowledge for detection model, and thus, delivering consistent performance for any input signal and computing environment. Additionally, a modern user-generated content approach for populating and updating ground truth databases is presented. Both techniques are implemented and embedded as upgrades, in a mobile software environment for smartphones.", "references": ["Atrey, P. K., Maddage, N. C., & Kankanhalli, M. S. Audio based event detection for multimedia surveillance, in IEEE Acoustics, Speech and Signal Processing, 2006, IEEE.", "Avdelidis, K., Dimoulas, C., Kalliris, G., Papanikolaou, G. Adaptive phoneme alignment based on rough set theory, in Rough Sets and Current Trends in Computing, 2010, Springer Berlin Heidelberg, 100--109.", "Bullock, J. Libxtract: A lightweight library for audio feature extraction, in International Computer Music Conference, 43, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814906"}, {"title": "Combining Topic Models for Corpus Exploration: Applying LDA for Complex Corpus Research Tasks in a Digital Humanities Project", "authors": ["Carsten Schnober\n,", "Iryna Gurevych"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nWe investigate new ways of applying LDA topic models: rather than optimizing a single model for a specific use case, we train multiple models based on different parameters and vocabularies which are combined on-the-fly to comply with varying information retrieval tasks. We also show a semi-automatic method which helps users to identify relevant topics across multiple models.\nOur methods are demonstrated and evaluated on a real-world use case: a large-scale corpus-based digital humanities project called Welt der Kinder (\"Children and their World\"). We illustrate our approach in that context and show that it can be generalized to other scenarios.\nWe evaluate this work using empirical methods from information retrieval, but also show visualizations and use cases as actually applied in the project.", "references": ["D. M. Blei and J. D. Lafferty. Dynamic Topic Models. In Proceedings of the 23rd International Conference on Machine Learning, ICML '06, pages 113--120, New York, NY, USA, 2006. ACM.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993--1022, Mar. 2003.", "J. Chang, S. Gerrish, C. Wang, J. L. Boyd-Graber, and D. M. Blei. Reading Tea Leaves: How Humans Interpret Topic Models. In Advances in Neural Information Processing Systems 22, pages 288--296, Vancouver, British Columbia, Canada, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809939"}, {"title": "Learning Maximal Marginal Relevance Model via Directly Optimizing Diversity Evaluation Measures", "authors": ["Long Xia\n,", "Jun Xu\n,", "Yanyan Lan\n,", "Jiafeng Guo\n,", "Xueqi Cheng"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we address the issue of learning a ranking model for search result diversification. In the task, a model concerns with both query-document relevance and document diversity is automatically created with training data. Ideally a diverse ranking model would be designed to meet the criterion of maximal marginal relevance, for selecting documents that have the least similarity to previously selected documents. Also, an ideal learning algorithm for diverse ranking would train a ranking model that could directly optimize the diversity evaluation measures with respect to the training data. Existing methods, however, either fail to model the marginal relevance, or train ranking models by minimizing loss functions that loosely related to the evaluation measures. To deal with the problem, we propose a novel learning algorithm under the framework of Perceptron, which adopts the ranking model that \\emph{maximizes marginal relevance at ranking and can optimize any diversity evaluation measure in training}. The algorithm, referred to as PAMM (Perceptron Algorithm using Measures as Margins), first constructs positive and negative diverse rankings for each training query, and then repeatedly adjusts the model parameters so that the margins between the positive and negative rankings are maximized. Experimental results on three benchmark datasets show that PAMM significantly outperforms the state-of-the-art baseline methods.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of the 2th ACM WSDM, pages 5--14, 2009.", "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st ACM SIGIR, pages 335--336, 1998.", "B. Carterette and P. Chandar. Probabilistic models of ranking novel documents for faceted topic retrieval. In Proceedings of the 18th ACM CIKM, pages 1287--1296, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767710"}, {"title": "Efficient Incremental High Utility Itemset Mining", "authors": ["Philippe Fournier-Viger\n,", "Jerry Chun-Wei Lin\n,", "Ted Gueniche\n,", "Prashant Barhate"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nHigh-utility itemset mining (HUIM) in transaction databases is an important data mining task with wide applications. However, most HUIM algorithms assume the unrealistic assumption that databases are static. To address this issue, algorithms have been designed to maintain high-utility itemsets in dynamic databases. However, these incremental algorithms still remain very costly in terms of execution time. In this paper, we address this problem by proposing an algorithm named EIHI (Efficient Incremental High-utility Itemset miner), which introduces several ideas to more efficiently maintain high-utility itemsets in dynamic databases. An experimental study on four datasets shows that EIHI is up to two orders of magnitude faster than the state-of-the-art HUI-LIST-INS algorithm.", "references": ["R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. Intern. Conf. Very Large Databases, pages 487--499. 1994.", "C. F. Ahmed, S. K. Tanbeer, B.-S. Jeong and Y.-K. Lee. Efficient tree structures for high-utility pattern mining in incremental databases. IEEE Trans. Knowl. Data Eng, 21(12):1708--1721, 2009.", "P. Fournier-Viger, C.-W. Wu, S. Zida and V. S. Tseng. FHM: Faster high-utility itemset mining using estimated utility co-occurrence pruning. In Proc. 21st Intern. Symp. on Methodologies for Intell. Syst., pages 83--9. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818887"}, {"title": "Geographical address classification without using geolocation coordinates", "authors": ["T. Ravindra Babu\n,", "Abhranil Chatterjee\n,", "Shivram Khandeparker\n,", "A. Vamsi Subhash\n,", "Sawan Gupta"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nOnline retail focuses on optimal delivery system of ordered shipments. In the Last Mile context of a Supply Chain, automatic categorization of addresses is an important problem. An automated solution to this problem reduces manual effort significantly from physical reading of shipment addresses to automatic identification of the corresponding route. In general, addresses help to relate to a geolocation. In the absence of geolocation information in terms of latitude and longitude of individual houses and a definitive structure in the addresses, classifying a given address as belonging to a particular locality is a challenging task. In the current work we devised an accurate method to classify the addresses belonging to a region as belonging to predefined subregions in the background of the above challenges. The activity involves text processing, address preprocessing, clustering, classification using ensemble of classifiers, efficient ways to deal with large dataset with high dimensionality and increasing labeled dataset using semi-supervised classification. We discuss each of these stages that culminates in classification of addresses into sub-localities with a high classification accuracy. The solution is demonstrated in an operational setting in a major e-commerce organization. The solution is applicable to developing countries where geolocation information is not completely available.", "references": ["C. Aggarwal and C. Zhai. Mining text data. Springer Science & Business Media, 2012.", "D. Ahlers. Applying geographic information retrieval - an experience report on developing local search for a developing country, 2014.", "T. R. Babu and M. N. Murty. Comparison of genetic algorithm based prototype selection schemes. Pattern Recognition, 34:523--525, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837696"}, {"title": "SemaGrow: optimizing federated SPARQL queries", "authors": ["Angelos Charalambidis\n,", "Antonis Troumpoukis\n,", "Stasinos Konstantopoulos"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nProcessing SPARQL queries involves the construction of an efficient query plan to guide query execution. Alternative plans can vary in the resources and the amount of time that they need by orders of magnitude, making planning crucial for efficiency. On the other hand, the construction of optimal plans can become computationally intensive and it also operates upon detailed, difficult to obtain, metadata. In this paper we present Semagrow, a federated SPARQL querying system that uses metadata about the federated data sources in order to optimize query execution. We balance between a query optimizer that introduces little overhead, has appropriate fall backs in the absence of metadata, but at the same time produces optimal plans in as many situations as possible. Semagrow also exploits non-blocking and asynchronous stream processing technologies to achieve query execution efficiency and robustness. We also present and analyse empirical results using the FedBench benchmark to compare Semagrow against FedX and SPLENDID. Semagrow clearly outperforms SPLENDID and it is either on a par or much faster than FedX.", "references": ["K. Alexander, R. Cyganiak, M. Hausenblas, and J. Zhao. Describing linked datasets with the VoID vocabulary. W3C Interest Group Note, 3 March 2011.", "C. Buil-Aranda, A. Hogan, J. Umbrich, and P.-Y. Vandenbussche. SPARQL web-querying infrastructure: Ready for action? In Proc. 12th Intl Semantic Web Conference (ISWC 2013), Sydney, Australia, October 21-25, 2013, Part II, LNCS 8219. Springer, 2013.", "A. Charalambidis, S. Konstantopoulos, and V. Karkaletsis. Dataset descriptions for optimizing federated querying. In 24th Intl World Wide Web Conference Companion Proceedings (WWW 2015), Poster Session, Florence, Italy, 18-22 May 2015, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814886"}, {"title": "Visual Event Summarization on Social Media using Topic Modelling and Graph-based Ranking Algorithms", "authors": ["Manos Schinas\n,", "Symeon Papadopoulos\n,", "Yiannis Kompatsiaris\n,", "Pericles A. Mitkas"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nDue to the increasing popularity of microblogging platforms, the amount of messages (posts) related to public events, especially posts encompassing multimedia content, is steadily increasing. The inclusion of images can convey much more information about the event, compared to their text, which is typically very short (e.g., tweets). Although such messages can be quite informative regarding different aspects of the event, there is a lot of spam and redundancy making it challenging to extract pertinent insights. In this work, we describe a summarization framework that, given a set of social media messages about an event, aims to select a subset of images derived from them, that, at the same time, maximizes the relevance of the selected images and minimizes their redundancy. To this end, we propose a topic modeling technique to capture the relevance of messages to event topics and a graph-based algorithm to produce a diverse ranking of the selected high-relevance images. A user-centered evaluation on a large Twitter dataset around several real-world events demonstrates that the proposed method considerably outperforms a number of state-of-the-art summarization algorithms in terms of result relevance, while at the same time it is also highly competitive in terms of diversity. Namely, we get an improvement of 25% in terms of precision compared to the second best result, and 7% in terms of diversity.", "references": ["Celebrating#SB48 on Twitter. https://blog.twitter.com/2014/celebrating-sb48-on-twitter, 2014. {Online; accessed 27-Feb-2014}.", "O. Alonso and K. Shiells. Timelines as summaries of popular scheduled events. In Proceedings of the 22nd International Conference on World Wide Web (WWW) companion, pages 1037--1044. International World Wide Web Conferences Steering Committee, 2013.", "J. Bian, Y. Yang, and T.-S. Chua. Multimedia summarization for trending topics in microblogs. In Proceedings of the 22nd ACM International Conference on Information and Knowledge Management, CIKM '13, pages 1807--1812, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749407"}, {"title": "Semantic annotation of geodata based on linked-open data", "authors": ["Fabio Gomes de Andrade\n,", "Cláudio de Souza Baptista\n,", "Hamon Barros Henriques"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nThere are several research works using web semantic to improve integration and retrieval of geospatial data provided by spatial data infrastructures (SDI) and geoportals. However, an important open issue that deserves more research efforts is how to implement the process of semantic annotation, in which geospatial data are associated to concepts formally defined in application ontologies. Since the volume of the data provided by a SDI is usually very large, it is necessary to provide mechanisms that are able to perform semantic annotation automatically (or semi-automatically). Aiming to solve this limitation, this article proposes a method that uses the open data provided by DBpedia, as well ideas proposed in the classic information retrieval, to provide automatic semantic annotation of feature types provided by SDIs. We used geospatial data gathered from the catalog service of a real SDI in order to evaluate our proposed method. The results obtained from initial experiments showed that our approach is viable, since it can generate semantic annotations to many feature types with an acceptable precision rate.", "references": ["Nebert, D. 2004. Developing Spatial Data Infrastrcutures: The SDI Cookbook. Global Spatial Data Infrastructure.", "Berners-lee, T., Hendler, J. and Lassila, O. 2001. The Semantic Web. Scientific American. 284, 5, 34--43. DOI= https://dx.doi.org/10.1038%2Fscientificamerican0501-34.", "Egenhofer, M. J. 2002. Toward the Semantic Geospatial Web. In Proceedings of the Tenth ACM International Symposium on Advances in Geographic Information Systems. GIS '02, ACM, New York, NY, 1--4. DOI= http://dx.doi.org/10.1145/585147.585148."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857220"}, {"title": "Relationship between Willingness to Share Photos and Preferred Level of Photo Blurring for Privacy Protection", "authors": ["Yasuhiro Tanaka\n,", "Akihisa Kodate\n,", "Yu Ichifuji\n,", "Noboru Sonehara"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nWhile expectations of personal information and life-log accumulation and utilization have been rapidly growing for more personalized services, negative issues have been increasingly recognized due to leakage of privacy information. This study aims to investigate the relationship between willingness to sharing photo and preferred level of photo blurring for privacy protection. We conducted an online questionnaire survey and analyzed it to clarify the relationship between willingness to share photos and preferred level of photo blurring by PSM (Price Sensitivity Measurement). As a result, the PSM approached enabled us to find the acceptable threshold level of photo retouching to blur identifiable people that is acceptable to users.", "references": ["W. Tan, B. M. Blake, I. Saleh and S. D. Dustdar, \"Social-Network-Sourced Big Data Analytics,\" IEEE Internet Computing, vol. 17, no. 5, pp. 62--69, 2013.", "\"Face Recognition Study FAQ,\": http://www.heinz.cmu.edu/acquisti/face-recognition-study-FAQ/. {Accessed on Aug. 24, 2015}.", "T. Yamada, S. Gohshi and I. Echizen, \"Privacy Visor: Method for Preventing Face Image Detection by Using Differences in Human and Device Sensitivity,\" Communications and Multimedia Security, Springer Lecture Notes in Computer Science, vol. 8099, pp. 152--161, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818931"}, {"title": "RosyRecommends: Collaborative Filter Analysis of Listening Behavior Using User Similarity Metrics Based on Timbral Clusters", "authors": ["Adarsh Jois\n,", "Jasmine Hsu"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nThe objective of this paper is to propose a novel way of analyzing user behavior through collaborative filtering techniques. We have have chosen to work with the Million Song Dataset (item-based data) and the EchoNest Taste Profile Dataset (user-based data). The item-based dataset was aggregated by applying k-means clustering on audio MFCCs. Upon grouping the items into a set of k clusters, a user to cluster mapping was generated. We then used collaborative filtering to examine if users have a predilection towards songs that belong to the same cluster. The experiments were performed on a range of number of clusters. Computing cluster-based similarity between users was performed by thresholding neighborhood size and various parameters for common similarity metrics. Our experiments show that users do have a predilection to songs that occur within a cluster. This serves as the experimental basis of our proposed method in augmenting a recommendation engine.", "references": ["M. L. Adam Lund. Pearson product-moment correlation, 2013.", "F. Aiolli. A preliminary study on a recommender system for the million songs dataset challenge. In In Proceedings of the ECAI Workshop on Preference Learning: Problems and Application in AI, 2012.", "T. Bertin-Mahieux, D. P. Ellis, B. Whitman, and P. Lamere. The million song dataset. In Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR 2011), 2011.", "J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, UAI'98, pages 43--52, San Francisco, CA, USA, 1998. Morgan Kaufmann Publishers Inc.", "B. Dolhansky. Musical ensemble classification using universal background model adaptation and the million song dataset. June 2012.", "QnaList. Understanding loglikelihood similarity, 2014.", "D. Lane. Hyperstat online statistics textbook, 2013.", "Adomavicius, Gediminas and Tuzhilin, Alexander. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions Knowledge and Data Engineering, IEEE Transactions on", "M. Sahidullah and G. Saha. Design, analysis and experimental evaluation of block based transformation in mfcc computation for speaker recognition. Speech Commun., 54(4):543--565, may 2012.", "G. Tzanetakis and P. Cook. Musical genre classification of audio signals. Speech and Audio Processing, IEEE Transactions on, 10(5):293--302, Jul 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791406"}, {"title": "Write Fast, Read in the Past: Causal Consistency for Client-Side Applications", "authors": ["Marek Zawirski\n,", "Nuno Preguiça\n,", "Sérgio Duarte\n,", "Annette Bieniusa\n,", "Valter Balegas\n,", "Marc Shapiro"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nClient-side apps (e.g., mobile or in-browser) need cloud data to be available in a local cache, for both reads and updates. For optimal user experience and developer support, the cache should be consistent and fault-tolerant. In order to scale to high numbers of unreliable and resource-poor clients, and large database, the system needs to use resources sparingly. The SwiftCloud distributed object database is the first to provide fast reads and writes via a causally-consistent client-side local cache backed by the cloud. It is thrifty in resources and scales well, thanks to consistent versioning provided by the cloud, using small and bounded metadata. It remains available during faults, switching to a different data centre when the current one is not responsive, while maintaining its consistency guarantees. This paper presents the SwiftCloud algorithms, design, and experimental evaluation. It shows that client-side apps enjoy the high performance and availability, under the same guarantees as a remote cloud data store, at a small cost.", "references": ["Introducing Riak 2.0: Data types, strong consistency, full-text search, and much more, Oct. 2013. URL http://basho.com/introducing-riak-2-0/.", "M. Ahamad, G. Neiger, J. E. Burns, P. Kohli, and P. W. Hutto. Causal memory: definitions, implementation, and programming. Distributed Computing, 9(1):37--49, Mar. 1995.", "S. Almeida, J. Leitão, and L. Rodrigues. ChainReaction: a causal+ consistent datastore based on Chain Replication. In Euro. Conf. on Comp. Sys. (EuroSys), Apr. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814733"}, {"title": "Personal warning service for pest management using a crop calendar and BUS model", "authors": ["Asanee Kawtrakul\n,", "Phatchariya Tippayarak\n,", "Frederic Andres\n,", "Suchada Ujjin"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nIn this paper, we present a personal warning system model as one of the main functions of a RICE WATCH system in order to support farmers in rice pest management. The model embodies the concept of time-based notification activated by using a crop calendar, and situation-based notification using a BUS model. The system also includes \"What to Do Next,\" a knowledge integration module, in order to provide advice on how to prevent or treat pests appropriately. The warning or notification service is provided to farmers through multi-channels of communication such as SMS, e-mail, internet browser and mobile application. The recommendations or advice will be generated by using an inference engine to deduce disease preventive tasks and/or disease treatment. Based on estimates by Pest Forecasting and Early Warning Group, appropriate management of risk from pests could be reduced by 80%, as well as costs for pest management being reduced by 50%.", "references": ["Aree Wiboonpongse, Songsak sriboonjit, Phrek Gypmantasiri and Prathanthip kramol. 2001. The impact of the blast Carwg and productivity Khao Dawk Mali 105. Research to increase agricultural productivity. Faculty of Agriculture, Chiang Mai University.", "Asanee Kawtrakul, Mongkol Raksapatcharawong Hutchatai Chanlekha, Vasuthep Khunthong, Mukda Suktarachan, Anan Pusittigul, Attaya Pinchongskuldit, Suchada Ujjin. 2014. Development of a Rice Watch System for Strategic Planning in Rice Markets and Services. 2014 Annual SRI, 261--265. Doi= 10.1109/SRII.2014.46.", "Asanee Kawtrakul, Vasuthep Khunthong, Mukda Suktarachan, Udomsak Lertsuchatavanich, Anan Pusittigul, Sasin Tiendee, Suchada Ujjin. 2014. Development of an Information Integration and Knowledge Fusion Platform for Spatial and Time Based Advisory Services: Precision Farming as a Case Study. 2014 Annual SRI, 241--248. Doi= 10.1109/SRII.2014.42."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857271"}, {"title": "SparkBench: a comprehensive benchmarking suite for in memory data analytic platform Spark", "authors": ["Min Li\n,", "Jian Tan\n,", "Yandong Wang\n,", "Li Zhang\n,", "Valentina Salapura"], "publication": "CF '15: Proceedings of the 12th ACM International Conference on Computing Frontiers", "abstract": "ABSTRACT\nSpark has been increasingly adopted by industries in recent years for big data analysis by providing a fault tolerant, scalable and easy-to-use in memory abstraction. Moreover, the community has been actively developing a rich ecosystem around Spark, making it even more attractive. However, there is not yet a Spark specify benchmark existing in the literature to guide the development and cluster deployment of Spark to better fit resource demands of user applications. In this paper, we present SparkBench, a Spark specific benchmarking suite, which includes a comprehensive set of applications. SparkBench covers four main categories of applications, including machine learning, graph computation, SQL query and streaming applications. We also characterize the resource consumption, data flow and timing information of each application and evaluate the performance impact of a key configuration parameter to guide the design and optimization of Spark data analytic platform.", "references": ["TPC-DS. http://www.tpc.org/tpcds/, 2014.", "TPC-H. http://www.tpc.org/tpch/, 2014.", "AMPLab. Big Data Benchmark. https://amplab.cs.berkeley.edu/benchmark/, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742854.2747283"}, {"title": "Towards an Automatic Top-down Role Engineering Approach Using Natural Language Processing Techniques", "authors": ["Masoud Narouei\n,", "Hassan Takabi"], "publication": "SACMAT '15: Proceedings of the 20th ACM Symposium on Access Control Models and Technologies", "abstract": "ABSTRACT\nRole Based Access Control (RBAC) is the most widely used model for access control due to the ease of administration as well as economic benefits it provides. In order to deploy an RBAC system, one requires to first identify a complete set of roles. This process, known as role engineering, has been identified as one of the costliest tasks in migrating to RBAC. In this paper, we propose a top-down role engineering approach and take the first steps towards using natural language processing techniques to extract policies from unrestricted natural language documents. Most organizations have high-level requirement specifications that include a set of access control policies which describes allowable operations for the system. However, it is very time consuming, labor-intensive, and error-prone to manually sift through these natural language documents to identify and extract access control policies. Our goal is to automate this process to reduce manual efforts and human errors. We apply natural language processing techniques, more specifically semantic role labeling to automatically extract access control policies from unrestricted natural language documents, define roles, and build an RBAC model. Our preliminary results are promising and by applying semantic role labeling to automatically identify predicate-argument structure, and a set of predefined rules on the extracted arguments, we were able correctly identify access control policies with a precision of 75%, recall of 88%, and F1 score of 80%.", "references": ["Collobert, R., Weston. J., Bottou, L., Karlen, M., Kavukcuoglu. K., and Kuksa P. 2011. Natural Language Processing (Almost) from Scratch, Journal of Machine Learning Research (JMLR), 2011.", "Federal information security management act of 2002, 2002. Title III of the E-Government Act of 2002.", "Meneely, A., Smith, B., Williams, L., 2011. iTrust Electronic Health Care System: A Case Study. Software System Traceability."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2752952.2752958"}, {"title": "Research opportunities for the big data era of software engineering", "authors": ["Robert DeLine"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nBig Data Analysis is becoming a widespread practice on many software development projects, and statisticians and data analysts are working alongside developers, testers and program managers. Because data science is still an emerging discipline in software projects, there are many opportunities where software engineering researchers can help improve practice. In terms of productivity, data scientists need support for exploratory analysis of large datasets, relief from clerical tasks like data cleaning, and easier paths for live deployment of new analyses. In terms of correctness, data scientists need help in preserving data meaning and provenance, and non-experts need help avoiding analysis errors. In terms of communication and coordination, teams need more approachable ways to discuss uncertainty and risk, and support for data-driven decision making needs to become available to all roles. This position paper describes these open problems and points to ongoing research beginning to tackle them.", "references": ["K. Glerum, K. Kinshumann, S. Greenberg, G. Aul, V. Orgovan, G. Nichols, D. Grant, G. Loihle, and G. Hunt, \"Debugging in the (very) large: ten years of implementation and experience,\" in Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles. ACM, 2009, pp. 103--116.", "S. Kandel, A. Paepcke, J. M. Hellerstein, and J. Heer, \"Enterprise data analysis and visualization: An interview study,\" IEEE Transactions on Visualization and Computer Graphics, vol. 18, no. 12, pp. 2917--2926, 2012.", "D. Fisher, R. DeLine, M. Czerwinski, and S. Drucker, \"Interactions with big data analytics,\" ACM interactions, vol. 19, no. 3, pp. 50--59, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819298"}, {"title": "#FoodPorn: Obesity Patterns in Culinary Interactions", "authors": ["Yelena Mejova\n,", "Hamed Haddadi\n,", "Anastasios Noulas\n,", "Ingmar Weber"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nWe present a large-scale analysis of Instagram pictures taken at 164,753 restaurants by millions of users. Motivated by the obesity epidemic in the United States, our aim is three-fold: (i) to assess the relationship between fast food and chain restaurants and obesity, (ii) to better understand people's thoughts on and perceptions of their daily dining experiences, and (iii) to reveal the nature of social reinforcement and approval in the context of dietary health on social media. When we correlate the prominence of fast food restaurants in US counties with obesity, we find the Foursquare data to show a greater correlation at 0.424 than official survey data from the County Health Rankings would show. Our analysis further reveals a relationship between small businesses and local foods with better dietary health, with such restaurants getting more attention in areas of lower obesity. However, even in such areas, social approval favors the unhealthy foods high in sugar, with donut shops producing the most liked photos. Thus, the dietary landscape our study reveals is a complex ecosystem, with fast food playing a role alongside social interactions and personal perceptions, which often may be at odds.", "references": ["S. Abbar, Y. Mejova, and I. Weber. You tweet what you eat: Studying food consumption through twitter. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '15, 2015.", "D. H. Bodicoat, P. Carter, A. Comber, C. Edwardson, L. J. Gray, S. Hill, D. Webb, T. Yates, M. J. Davies, and K. Khunti. Is the number of fast-food outlets in the neighbourhood related to screen-detected type 2 diabetes mellitus and associated risk factors' Public health nutrition, pages 1--8, 2014.", "A. Culotta. Estimating county health statistics with twitter. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '14, pages 1335--1344, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750511.2750524"}, {"title": "Large-Scale Real-Time Data Management for Engagement and Monetization", "authors": ["Simon Jonassen"], "publication": "LSDS-IR '15: Proceedings of the 2015 Workshop on Large-Scale and Distributed System for Information Retrieval", "abstract": "ABSTRACT\nCxense helps companies understand their audience and build great online experiences. Cxense Insight and DMP let customers annotate, filter, segment and target their users based on the consumed content and performed actions in real-time. With more than 5000 active websites, Insight alone tracks more than a billion unique users with more than 15 billions page views per month. To leverage the huge amounts of data in real-time, we have built a large distributed system relying on techniques familiar from databases, information retrieval and data mining. In this talk, we outline our solutions and give some insight into the technology we use and the challenges we face. This introduction should be interesting to undergraduate and PhD students as well as experienced researchers and engineers.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809948.2809953"}, {"title": "The Influence of Pre-processing on the Estimation of Readability of Web Documents", "authors": ["João Rafael de Moura Palotti\n,", "Guido Zuccon\n,", "Allan Hanbury"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper investigates the effect that text pre-processing approaches have on the estimation of the readability of web pages. Readability has been highlighted as an important aspect of web search result personalisation in previous work. The most widely used text readability measures rely on surface level characteristics of text, such as the length of words and sentences. We demonstrate that different tools for extracting text from web pages lead to very different estimations of readability. This has an important implication for search engines because search result personalisation strategies that consider users reading ability may fail if incorrect text readability estimations are computed.", "references": ["M. Baroni, F. Chantree, A. Kilgarriff, and S. Sharoff. Cleaneval: a competition for cleaning web pages. In LREC, 2008.", "M. Coleman and T. L. Liau. A Computer Readability Formula Designed for Machine Scoring. JAP, 1975.", "K. Collins-Thompson, P. N. Bennett, R. W. White, S. de la Chica, and D. Sontag. Personalizing Web Search Results by Reading Level. In CIKM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806613"}, {"title": "BlueDBM: an appliance for big data analytics", "authors": ["Sang-Woo Jun\n,", "Ming Liu\n,", "Sungjin Lee\n,", "Jamey Hicks\n,", "John Ankcorn\n,", "Myron King\n,", "Shuotao Xu\n,", "Arvind"], "publication": "ISCA '15: Proceedings of the 42nd Annual International Symposium on Computer Architecture", "abstract": "ABSTRACT\nComplex data queries, because of their need for random accesses, have proven to be slow unless all the data can be accommodated in DRAM. There are many domains, such as genomics, geological data and daily twitter feeds where the datasets of interest are 5TB to 20 TB. For such a dataset, one would need a cluster with 100 servers, each with 128GB to 256GBs of DRAM, to accommodate all the data in DRAM. On the other hand, such datasets could be stored easily in the flash memory of a rack-sized cluster. Flash storage has much better random access performance than hard disks, which makes it desirable for analytics workloads. In this paper we present BlueDBM, a new system architecture which has flash-based storage with in-store processing capability and a low-latency high-throughput inter-controller network. We show that BlueDBM outperforms a flash-based system without these features by a factor of 10 for some important applications. While the performance of a ram-cloud system falls sharply even if only 5%~10% of the references are to the secondary storage, this sharp performance degradation is not an issue in BlueDBM. BlueDBM presents an attractive point in the cost-performance trade-off for Big Data analytics.", "references": ["N. Agrawal, V. Prabhakaran, T. Wobber, J. D. Davis, M. Manasse, and R. Panigrahy, \"Design tradeoffs for ssd performance,\" in USENIX 2008 Annual Technical Conference on Annual Technical Conference, ser. ATC'08. Berkeley, CA, USA: USENIX Association, 2008, pp. 57--70. Available: http://dl.acm.org/citation.cfm?id=1404014.1404019", "I. T. Association, Infiniband, 2014 (Accessed November 18, 2014). Available: http://www.infinibandta.org", "J. Banerjee, D. Hsiao, and K. Kannan, \"Dbc: A database computer for very large databases,\" Computers, IEEE Transactions on, vol. C-28, no. 6, pp. 414--429, June 1979."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2749469.2750412"}, {"title": "Generalized Team Draft Interleaving", "authors": ["Eugene Kharitonov\n,", "Craig Macdonald\n,", "Pavel Serdyukov\n,", "Iadh Ounis"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nInterleaving is an online evaluation method that compares two ranking functions by mixing their results and interpreting the users' click feedback. An important property of an interleaving method is its sensitivity, i.e. the ability to obtain reliable comparison outcomes with few user interactions. Several methods have been proposed so far to improve interleaving sensitivity, which can be roughly divided into two areas: (a) methods that optimize the credit assignment function (how the click feedback is interpreted), and (b) methods that achieve higher sensitivity by controlling the interleaving policy (how often a particular interleaved result page is shown).\nIn this paper, we propose an interleaving framework that generalizes the previously studied interleaving methods in two aspects. First, it achieves a higher sensitivity by performing a joint data-driven optimization of the credit assignment function and the interleaving policy. Second, we formulate the framework to be general w.r.t. the search domain where the interleaving experiment is deployed, so that it can be applied in domains with grid-based presentation, such as image search. In order to simplify the optimization, we additionally introduce a stratified estimate of the experiment outcome. This stratification is also useful on its own, as it reduces the variance of the outcome and thus increases the interleaving sensitivity.\nWe perform an extensive experimental study using large-scale document and image search datasets obtained from a commercial search engine. The experiments show that our proposed framework achieves marked improvements in sensitivity over effective baselines on both datasets.", "references": ["S. Asmussen and P. W. Glynn. Stochastic simulation: Algorithms and analysis, volume 57. Springer Science & Business Media, 2007.", "O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):6, 2012.", "A. Chuklin, A. Schuth, K. Hofmann, P. Serdyukov, and M. de Rijke. Evaluating aggregated search using interleaving. In CIKM 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806477"}, {"title": "Results Presentation Methods for a Spoken Conversational Search System", "authors": ["Johanne R. Trippas\n,", "Damiano Spina\n,", "Mark Sanderson\n,", "Lawrence Cavedon"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nWe propose research to investigate a new paradigm for Interactive Information Retrieval (IIR) where all input and output is mediated via speech. Our aim is to develop a new framework for effective and efficient IIR over a speech-only channel: a Spoken Conversational Search System (SCSS). This SCSS will provide an interactive conversational approach to determine user information needs, presenting results and enabling search reformulations. We have thus far investigated the format of results summaries for both audio and text, features such as summary length and summaries documents (noisy document or clean document) generated from (noisy) speech-recognition output from spoken document. In this paper we discuss future directions regarding a novel spoken interface targeted at search result presentation, query intent detection, and interaction patterns for audio search.", "references": ["L. Azzopardi and M. de Rijke. Automatic construction of known-item finding test beds. In Proc. of SIGIR'06, pages 603--604, 2006.", "C. Baber, B. Mellor, R. Graham, J. M. Noyes, and C. Tunley. Workload and the use of automatic speech recognition: The effects of time and resource demands. Speech Communication, 20 (1): 37--53, 1996.", "E. Chang, F. Seide, H. M. Meng, C. Zhuoran, S. Yu, and L. Yuk-Chi. A system for spoken query information retrieval on mobile devices. Speech and Audio Processing, IEEE Trans. on, 10 (8): 531--541, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810356"}, {"title": "Modeling Parameter Interactions in Ranking SVM", "authors": ["Yaogong Zhang\n,", "Jun Xu\n,", "Yanyan Lan\n,", "Jiafeng Guo\n,", "Maoqiang Xie\n,", "Yalou Huang\n,", "Xueqi Cheng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRanking SVM, which formalizes the problem of learning a ranking model as that of learning a binary SVM on preference pairs of documents, is a state-of-the-art ranking model in information retrieval. The dual form solution of Ranking SVM model can be written as a linear combination of the preference pairs, i.e., w = ∑(i,j) αij (xi - xj), where αij denotes the Lagrange parameters associated with each pair (i,j). It is obvious that there exist significant interactions over the document pairs because two preference pairs could share a same document as their items. Thus it is natural to ask if there also exist interactions over the model parameters αij, which we may leverage to propose better ranking model. This paper aims to answer the question. Firstly, we found that there exists a low-rank structure over the Ranking SVM model parameters αij, which indicates that the interactions do exist. Then, based on the discovery, we made a modification on the original Ranking SVM model by explicitly applying a low-rank constraint to the parameters. Specifically, each parameter αij is decomposed as a product of two low-dimensional vectors, i.e., αij = vi, vj, where vectors vi and vj correspond to document i and j, respectively. The learning process, thus, becomes to optimize the modified dual form objective function with respect to the low-dimensional vectors. Experimental results on three LETOR datasets show that our method, referred to as Factorized Ranking SVM, can outperform state-of-the-art baselines including the conventional Ranking SVM.", "references": ["Bernhard E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. In Computational Learning Theory, pages 144--152, 1992.", "Chris Burges, Tal Shaked, and et.al. Learning to rank using gradient descent. In ICML, pages 89--96, 2005.", "Yunbo Cao, Jun Xu, Tie yan Liu, Hang Li, Yalou Huang, and Hsiao wuen Hon. Adapting ranking SVM to document retrieval. In SIGIR, pages 186--193, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806595"}, {"title": "Ranking Optimization for Person Re-identification via Similarity and Dissimilarity", "authors": ["Mang Ye\n,", "Chao Liang\n,", "Zheng Wang\n,", "Qingming Leng\n,", "Jun Chen"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nPerson re-identification is a key technique to match different persons observed in non-overlapping camera views.Many researchers treat it as a special object retrieval problem, where ranking optimization plays an important role. Existing ranking optimization methods utilize the similarity relationship between the probe and gallery images to optimize the original ranking list in which dissimilarity relationship is seldomly investigated. In this paper, we propose to use both similarity and dissimilarity cues in a ranking optimization framework for person re-identification. Its core idea is based on the phenomenon that the true match should not only be similar to the strong similar samples of the probe but also dissimilar to the strong dissimilar samples. Extensive experiments have shown the great superiority of the proposed ranking optimization method.", "references": ["R. Cucchiara. Multimedia surveillance systems. In Proceedings of the third ACM international workshop on Video surveillance & sensor networks. ACM, 2005.", "M. Farenzena, L. Bazzani, A. Perina, V. Murino, and M. Cristani. Person re-identification by symmetry-driven accumulation of local features. In CVPR, 2010.", "D. Gray, S. Brennan, and H. Tao. Evaluating appearance models for recognition, reacquisition, and tracking. In PETS workshop, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806326"}, {"title": "Towards Less Biased Web Search", "authors": ["Xitong Liu\n,", "Hui Fang\n,", "Deng Cai"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nWeb search engines now serve as essential assistant to help users make decisions in different aspects. Delivering correct and impartial information is a crucial functionality for search engines as any false information may lead to unwise decision and thus undesirable consequences. Unfortunately, a recent study revealed that Web search engines tend to provide biased information with most results supporting users' beliefs conveyed in queries regardless of the truth.\nIn this paper we propose to alleviate bias in Web search through predicting the topical polarity of documents, which is the overall tendency of one document regarding whether it supports or disapproves the belief in query. By applying the prediction to balance search results, users would receive less biased information and therefore make wiser decision. To achieve this goal, we propose a novel textual segment extraction method to distill and generate document feature representation, and leverage convolution neural network, an effective deep learning approach, to predict topical polarity of documents. We conduct extensive experiments on a set of queries with medical indents and demonstrate that our model performs empirically well on identifying topical polarity with satisfying accuracy. To our best knowledge, our work is the first on investigating the mitigation of bias in Web search and could provide directions on future research.", "references": ["B. He, C. Macdonald, J. He, and I. Ounis. An Effective Statistical Approach to Blog Post Opinion Retrieval. In CIKM, pages 1063--1072, 2008.", "B. He, C. Macdonald, and I. Ounis. Ranking Opinionated Blog Posts using OpinionFinder. In SIGIR, pages 727--728, 2008.", "S. Ieong, N. Mishra, E. Sadikov, and L. Zhang. Domain Bias in Web Search. In WSDM, pages 413--422, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809476"}, {"title": "REGULA: Utilizing the Regularity of Human Mobility for Location Recommendation", "authors": ["Steven Mudda\n,", "Silvia Giordano"], "publication": "IWGS '15: Proceedings of the 6th ACM SIGSPATIAL International Workshop on GeoStreaming", "abstract": "ABSTRACT\nIn this paper, we address the problem of recommending new locations to the users of a Location Based Social Network (LBSN). LBSNs are social and physical information-rich networks that incorporate mobility patterns and social ties of humans. Most of the existing recommender systems are build on variants of graph-based techniques that utilize complete knowledge of location history and social ties of all users. Therefore, these recommender systems are computationally expensive for large scale LBSNs. Further, these systems do not take into account the mobility habits of humans. Recent studies on human mobility patterns have highlighted that people frequently visit a set of locations and go to places closer to them. In this paper, we validate the existence of these human mobility aspects in LBSN through the analysis of user check-in behavior and derive a set of observations. Further, we propose REGULA-- A location recommendation algorithm that exploits three behavior patterns of humans: 1) People regularly (or habitually) visit a set of locations 2) People go to places close to these regularly visited locations and 3) People are more likely to visit places that were recently visited by others like friends. Using these behavior patterns, REGULA minimizes the computational complexity by reducing the set of candidate locations to recommend. We evaluate the performance of REGULA by employing two large scale LBSN datasets: Gowalla and Brightkite. Based on our results, we show that REGULA outperforms existing state of the art recommendation algorithms for LBSNs while reducing the complexity.", "references": ["J. Bao, Y. Zheng, D. Wilkie, and M. F. Mokbel. A survey on recommendations in location-based social networks. ACM Transaction on Intelligent Systems and Technology, 2013.", "E. Cho, S. A. Myers, and J. Leskovec. Friendship and mobility: User movement in location-based social networks. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '11, pages 1082--1090, New York, NY, USA, 2011. ACM.", "G. Ference, M. Ye, and W.-C. Lee. Location recommendation for out-of-town users in location-based social networks. In Proceedings of the 22Nd ACM International Conference on Conference on Information & Knowledge Management, CIKM '13, pages 721--726, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833165.2833172"}, {"title": "Insight in Image Collections by Multimedia Pivot Tables", "authors": ["Marcel Worring\n,", "Dennis C. Koelma"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWe propose a multimedia analytics solution for getting insight in image collections by extending the powerful method of pivot tables, found in the ubiquitous spreadsheets, to multimedia. Our proposed solution is designed by considering the characteristics of multimedia data as well as insight and provides integral access to visual content through concept detection results, tags, geolocation, and other metadata. We present a set of scenarios of using the pivot tables for a collection of images, tags, and metadata from Flickr. User experiments have been instrumental in realizing the final design presented in this paper. The accompanying video shows the solution in action.", "references": ["R. Burtner, S. Bohn, and D. Payne. Interactive visual comparison of multimedia data through type-specific views. In SPIE, Visualization and data analysis, 2013.", "E. Chi, J. Riedl, P. Barry, and J. Konstan. Principles for information visualization spreadsheets. Computer Graphics and Applications, July/August 1998.", "N. Chinchor, J. Thomas, P. C. Wong, M. Christel, and W. Ribarsky. Multimedia analysis + visual analytics = multimedia analytics. Computer Graphics and Applications, IEEE, 30(5):52--60, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749312"}, {"title": "Forensics-aware web services composition and ranking", "authors": ["Aymen Akremi\n,", "Hassen Sallay\n,", "Mohsen Rouached\n,", "Rafik Bouaziz\n,", "Mohamed Abid"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nWeb service composition has been extensively studied in recent years. Although a lot of new models and mechanisms have been proposed, many issues in service composition still remain unsolved. Among them, forensics examination is one of the major concerns. As opposed to traditional forensics implementations, applying forensics to Web service infrastructures introduces novel problems such as the need for neutrality, comprehensiveness, and reliability. Existing approaches fail to recognize that even optimized strategies for service selection and composition involve the exchange of large amounts of potentially sensitive data, causing potentially serious forensics leaks. Consequently, forensics is still among the key challenges that keep hampering service composition-based solutions.\nIn this context, this paper proposes a built in forensics-aware framework for Web services (Fi4SOA). Fi4SOA uses Sherwood Applied Business Security (SABSA) methodology to merge forensics properties with business requirements at service design phase. It uses reasoning machine over a new proposed ontology to define forensics properties and monitor forensics events at run time phase.", "references": ["A. Akremi, H. Sallay, and M. Rouached. An efficient intrusion alerts miner for forensics readiness in high speed networks. IJISP, 8(1):62--78, 2014.", "A. R. Amran, R. C.-W. Phan, and D. J. Parish. Metrics for network forensics conviction evidence. In ICITST, pages 1--8. IEEE, 2009.", "G. Baryannis, O. Danylevych, D. Karastoyanova, K. Kritikos, P. Leitner, F. Rosenberg, and B. Wetzstein. Service composition. In Service Research Challenges and Solutions for the Future Internet - S-Cube - Towards Engineering, Managing and Adapting Service-Based Systems, pages 55--84, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837226"}, {"title": "An Unsupervised Method for Ontology Population from Textual Sources on the Web", "authors": ["Fabio Lima\n,", "Hilario Oliveira\n,", "Lais Salvador"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe increasing in the production and availability of unstructured information on the Web grows daily. This abundance of unstructured information is a great challenge for acquisition of structured knowledge. Many approaches have been proposed for extracting information from texts written in natural language. However, only a few studies have investigated the extraction of information from texts written in Portuguese. Thus, this work aims to propose and evaluate an unsupervised method for ontology population using the Web as a big source of information in the context of the Portuguese language. The results of the experiments are encouraging and demonstrated that the proposed approach reached a precision rate of 67% in the instances of ontological classes extraction.", "references": ["C. G. d. F. Alves. Um Processo Independente de Domínio para o Povoamento Automático de Ontologias a partir de Fontes Textuais. 2013.", "T. L. Baségio. Uma Abordagem Semi-automática para Identificação de Estruturas Ontológicas a partir de Textos na Língua Portuguesa do Brasil. pages 1-124, 2007.", "A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. Hruschka, and T. M. Mitchell. Toward an architecture for never-ending language learning. In In AAAI, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814086"}, {"title": "Exploiting Multiple Web Resources towards Collecting Positive Training Samples for Visual Concept Learning", "authors": ["Olga Papadopoulou\n,", "Vasileios Mezaris"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe number of images uploaded to the web is enormous and is rapidly increasing. The purpose of our work is to use these for acquiring positive training data for visual concept learning. Manually creating training data for visual concept classifiers is an expensive and time consuming task. We propose an approach which automatically collects positive training samples from the Web by constructing a multitude of text queries and retaining for each query only very few top-ranked images returned by each one of the different web image search engines (Google, Flickr and Bing). In this way, we sift the burden of false positive rejection to the Web search engines and directly assemble a rich set of high-quality positive training samples. Experiments on forty concepts, evaluated on the ImageNet dataset, show the merit of the proposed approach.", "references": ["P. Over, G. Awad, et al., \"Trecvid 2014 - an overview of the goals, tasks, data, evaluation mechanisms and metrics,\" in Proc. TRECVID 2014. NIST, USA, 2014.", "X. Li, C. G. Snoek, et al., \"Harvesting social images for bi-concept search,\" IEEE Trans. on Multimedia, vol. 14, no. 4, pp. 1091--1104, 2012.", "X. Li, C. G. Snoek, and M. Worring, \"Unsupervised multi-feature tag relevance learning for social image retrieval,\" in Proc. Int. Conf. on Image and Video Retrieval. ACM, 2010, pp. 10--17."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749338"}, {"title": "A Bayesian Perspective on Locality Sensitive Hashing with Extensions for Kernel Methods", "authors": ["Aniket Chakrabarti\n,", "Venu Satuluri\n,", "Atreya Srivathsan\n,", "Srinivasan Parthasarathy"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nGiven a collection of objects and an associated similarity measure, the all-pairs similarity search problem asks us to find all pairs of objects with similarity greater than a certain user-specified threshold. In order to reduce the number of candidates to search, locality-sensitive hashing (LSH) based indexing methods are very effective. However, most such methods only use LSH for the first phase of similarity search—that is, efficient indexing for candidate generation. In this article, we present BayesLSH, a principled Bayesian algorithm for the subsequent phase of similarity search—performing candidate pruning and similarity estimation using LSH. A simpler variant, BayesLSH-Lite, which calculates similarities exactly, is also presented. Our algorithms are able to quickly prune away a large majority of the false positive candidate pairs, leading to significant speedups over baseline approaches. For BayesLSH, we also provide probabilistic guarantees on the quality of the output, both in terms of accuracy and recall. Finally, the quality of BayesLSH’s output can be easily tuned and does not require any manual setting of the number of hashes to use for similarity estimation, unlike standard approaches. For two state-of-the-art candidate generation algorithms, AllPairs and LSH, BayesLSH enables significant speedups, typically in the range 2 × --20 × for a wide variety of datasets.\nWe also extend the BayesLSH algorithm for kernel methods—in which the similarity between two data objects is defined by a kernel function. Since the embedding of data points in the transformed kernel space is unknown, algorithms such as AllPairs which rely on building inverted index structure for fast similarity search do not work with kernel functions. Exhaustive search across all possible pairs is also not an option since the dataset can be huge and computing the kernel values for each pair can be prohibitive. We propose K-BayesLSH an all-pairs similarity search problem for kernel functions. K-BayesLSH leverages a recently proposed idea—kernelized locality sensitive hashing (KLSH)—for hash bit computation and candidate generation, and uses the aforementioned BayesLSH idea for candidate pruning and similarity estimation. We ran a broad spectrum of experiments on a variety of datasets drawn from different domains and with distinct kernels and find a speedup of 2 × --7 × over vanilla KLSH.", "references": ["Sameer Agarwal, Yasutaka Furukawa, Noah Snavely, Ian Simon, Brian Curless, Steven M. Seitz, and Richard Szeliski. 2011. Building rome in a day. Commun. ACM 54, 10 (Oct. 2011), 105--112. DOI:http://dx.doi.org/10.1145/2001269.2001293", "Alexandr Andoni and Piotr Indyk. 2008. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM 51 (2008), 117--122.", "Roberto J. Bayardo, Yiming Ma, and Ramakrishnan Srikant. 2007. Scaling up all pairs similarity search. In Proceedings of the 16th International Conference on World Wide Web (WWW'07). ACM, Banff, Alberta, Canada, 131--140. DOI:http://dx.doi.org/10.1145/1242572.1242591"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2778990"}, {"title": "Does Dialectal Variation Matter in Term-Based Feature Selection of Sentiment Analysis?: An Investigation into Multi-dialectal Chinese Microblogs", "authors": ["Kwun Cheung Chan\n,", "King Wa Fu\n,", "Chung Hong Chan"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nThis paper examines the feature selection procedures of sentiment analysis on a multi-dialectal language. We analyzed a dataset with over 6 million microblogs in China, a multi-dialectal country, deployed sentiment classifier to examine the positive/negative emotion carried by the microblogs, and explored the regional variations in the optimal feature vectors. The results support a localized feature vectors in some China's regions can maximize the classification accuracy and show that geographical distance between provinces and common dialect used contribute to explaining the provincial difference in the feature vectors. This research can be applied to other multicultural countries for feature vector optimization in sentiment analysis.", "references": ["Asur, S. and Huberman, B. A. Predicting the future with social media. IEEE, City, 2010.", "Bollen, J., Mao, H. and Zeng, X. Twitter mood predicts the stock market. Journal of Computational Science, 2, 1 2011), 1--8.", "Kurpaska, M. Chinese language (s): a look through the prism of The great dictionary of modern Chinese dialects. Walter de Gruyter, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786924"}, {"title": "Geosocial Search: Finding Places based on Geotagged Social-Media Posts", "authors": ["Barak Pat\n,", "Yaron Kanza\n,", "Mor Naaman"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nGeographic search -- where the user provides keywords and receives relevant locations depicted on a map -- is a popular web application. Typically, such search is based on static geographic data. However, the abundant geotagged posts in microblogs such as Twitter and in social networks like Instagram, provide contemporary information that can be used to support geosocial search---geographic search based on user activities in social media. Such search can point out where people talk (or tweet) about different topics. For example, the search results may show where people refer to ``jogging'', to indicate popular jogging places. The difficulty in implementing such search is that there is no natural partition of the space into ``documents'' as in ordinary web search. Thus, it is not always clear how to present results and how to rank and filter results effectively. In this paper, we demonstrate a two-step process of first, quickly finding the relevant areas by using an arbitrary indexed partition of the space, and secondly, applying clustering on discovered areas, to present more accurate results. We introduce a system that utilizes geotagged posts in geographic search and illustrate how different ranking methods can be used, based on the proposed two-step search process. The system demonstrates the effectiveness and usefulness of the approach.", "references": ["S. Ahern, M. Naaman, R. Nair, and J. H.-I. Yang. World explorer: Visualizing aggregate data from unstructured text in geo-referenced collections. In Proc. of JCDL, 2007.", "M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. Optics: Ordering points to identify the clustering structure. ACM Sigmod Record, 28(2), 1999.", "J. Cranshaw, R. Schwartz, J. I. Hong, and N. M. Sadeh. The livehoods project: Utilizing social media to understand the dynamics of a city. In ICWSM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742847"}, {"title": "Discriminative voting for activity prediction", "authors": ["Zhen Xu\n,", "Laiyun Qing\n,", "Jun Miao"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nHuman activity prediction is a quite challenging problem, for activity prediction systems have to make decisions based on partially observed videos. However, activity prediction methodologies have many practical applications in real-world scenarios, such as human-robot interaction, security surveillance, etc. In this paper, we formulate the activity prediction problem into a discriminative weighted voting framework by unifying two different discriminative weights: 1) detector weights (DW): Mid-level features detected by distinct detectors are supposed to have different weights. 2) temporal weights (TW): Human activities are composed of sequential frames, so features in different phases should have different voting weights. We evaluate our voting model on two datasets. The experimental results clearly show that our method with discriminative weights enables better prediction of human activities.", "references": ["J. K. Aggarwal and M. S. Ryoo. Human activity analysis: A review. ACM Computing Surveys (CSUR), 2011.", "Y. Cao, D. Barrett, A. Barbuand, S. Narayanaswamy, H. Yu, A. Michaux, Y. Lin, S. Dickinson, J. M. Siskind, and S. Wang. Recognize human activities from partially observed videos. In CVPR, 2013.", "M. Grant, S. Boyd, and Y. Ye. CVX: Matlab software for disciplined convex programming, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808494"}, {"title": "EMIF: Towards a Scalable and Effective Indexing Framework for Large Scale Music Retrieval", "authors": ["Jialie Shen\n,", "Tao Mei\n,", "Dacheng Tao\n,", "Xuelong Li\n,", "Yong Rui"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this article, we present a novel indexing technique called EMIF (Effective Music Indexing Framework) to facilitate scalable and accurate content based music retrieval. It is designed based on a \"classification-and-indexing\" principle and consists of two main functionality layers: 1) a novel semantic-sensitive classification to identify input music's category and 2) multiple indexing structures - one local indexing structure corresponds to one semantic category. EMIF's layered architecture not only enables superior search accuracy but also reduces query response time significantly. To evaluate the system, a set of comprehensive experimental studies have been carried out using large test collection and EMIF demonstrates promising performance over state-of-the-art approaches.", "references": ["N. L. A. Dempster and D. Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society, Series B, 39(1), 1977.", "C. M. Bishop. Neural Network for Pattern Recognition. Oxford University Press, 2000.", "C. Böhm, S. Berchtold, and D. A. Keim. Searching in high-dimensional spaces: Index structures for improving the performance of multimedia databases. ACM Computing Surveys, 33(3), 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749346"}, {"title": "Restrictions on use of the Factory Floor Information in Maintenance Management", "authors": ["Rolando Jacyr Kurscheidt\n,", "Eduardo Santos\n,", "Eduardo Rocha Loures"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe maintenance management aims to estimate the equipment conditions over time or to make predictions or diagnosis of failures. With the growing of Information Systems, like as Factory Information Systems, Process Mining technics could be used to support maintenance decisions making. To ensure the quality and reliability of the information obtained, improvements must be made in events acquisitions. This paper proposes recommendations for structuring the records of Factory Information Systems events, aiming to facilitate the application of Process Mining algorithms. We use as case study of a parts manufacturing process for the automotive sector, using a CNC machine. It is concluded that the main cause for the reduction of quality of information is due to lack of delimiters events and incorrect input events by the operator. With the application of the proposed improvements, we try to extract information to optimize costs, increase equipment availability and guide the implementation of improvements in production processes.", "references": ["Sand, K., Aupied, J., Spruyt, F. 2010. Application of Bayesian Networks for Maintenance and Risk Modelling. IEEE.", "Weber, P., Medina-Oliva, G., Simon, C, lung, B. 2012. \"Overview on bayesian networks applications for dependability, risk analysis and maintenance areas,\" Engineering Applications of Artificial Intelligence, 25(4), pp. 671-682.", "Ahmad, R. Kamaruddin, S. 2012. An overview of time-based and condition-based maintenance in industrial application. Computers & Industrial Engineering 63, pp. 35-149."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814130"}, {"title": "Knowledge-Driven Video Information Retrieval with LOD: From Semi-Structured to Structured Video Metadata", "authors": ["Leslie F. Sikos\n,", "David M.W. Powers"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nIn parallel with the tremendously increasing number of video contents on the Web, many technical specifications and standards have been introduced to store technical details and describe the content of, and add subtitles to, online videos. Some of these specifications are based on unstructured data with limited machine-processability, data reuse, and interoperability, while others are XML-based, representing semi-structured data. While low-level video features can be derived automatically, high-level features are mainly related to a particular knowledge domain and heavily rely on human experience, judgment, and background. One of the approaches to solve this problem is to map standard, often semi-structured, vocabularies, such as that of MPEG-7, to machine-interpretable ontologies. Another approach is to introduce new multimedia ontologies. While video contents can be annotated efficiently with terms defined by structured LOD datasets, such as DBpedia, ontology standardization would be desired in the video production and distribution domains. This paper compares the state-of-the-art video annotations in terms of descriptor level and machine-readability, highlights the limitations of the different approaches, and makes suggestions towards standard video annotations.", "references": ["Blöhdorn, S., Petridis, K., Saathoff, C., Simou, N., Tzouvaras, V., Avrithis, Y., Handschuh, S., Kompatsiaris, Y., Staab, S., and Strintzis, M. Semantic Annotation of Images and Videos for Multimedia Analysis. Lect Notes Comput Sc, 3532. 592--607. DOI= http://dx.doi.org/10.1007/11431053_40.", "Boll, S., Klas, W., Sheth, A. Overview on using metadata to manage multimedia data. In: Sheth, A., Klas, W. (eds.) Multimedia data management: Using metadata to integrate and apply digital media. McGraw-Hill, New York, 1998, 3.", "Choudhury, S., Breslin, J. G., and Passant, A. Enrichment and Ranking of the YouTube Tag Space and Integration with the Linked Data Cloud. Lect Notes Comput Sc, 5823. 747--762. DOI= http://dx.doi.org/10.1007/978-3-642-04930-9_47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810141"}, {"title": "Assessor Differences and User Preferences in Tweet Timeline Generation", "authors": ["Yulu Wang\n,", "Garrick Sherman\n,", "Jimmy Lin\n,", "Miles Efron"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn information retrieval evaluation, when presented with an effectiveness difference between two systems, there are three relevant questions one might ask. First, are the differences statistically significant? Second, is the comparison stable with respect to assessor differences? Finally, is the difference actually meaningful to a user? This paper tackles the last two questions about assessor differences and user preferences in the context of the newly-introduced tweet timeline generation task in the TREC 2014 Microblog track, where the system's goal is to construct an informative summary of non-redundant tweets that addresses the user's information need. Central to the evaluation methodology is human-generated semantic clusters of tweets that contain substantively similar information. We show that the evaluation is stable with respect to assessor differences in clustering and that user preferences generally correlate with effectiveness metrics even though users are not explicitly aware of the semantic clustering being performed by the systems. Although our analyses are limited to this particular task, we believe that lessons learned could generalize to other evaluations based on establishing semantic equivalence between information units, such as nugget-based evaluations in question answering and temporal summarization.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. WSDM, 2009.", "A. Al-Maskari, M. Sanderson, P. Clough, and E. Airio. The good and the bad system: Does the test collection predict users' effectiveness? SIGIR, 2008.", "J. Allan. Topic Detection and Tracking: Event-Based Information Organization. Kluwer, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767699"}, {"title": "A comparative study of feature level fusion strategies for Multimodal Biometric Systems based on Face and Iris", "authors": ["Daniel M. M. da Costa\n,", "Henrique Passos\n,", "Sarajane Marques Peres\n,", "Clodoaldo A. M. de Lima"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nWith the technology advances, new approaches for automatic recognition of a person's identity have been proposed and such a fact has encouraged the use of Biometrics Systems. This approach uses physical or behavioural characteristics of the user in order to recognize or authenticate their identity. The Biometric Systems can be classified as Unimodal or Multimodal. The Unimodal Systems use a single biometric modality to perform the recognition, while the Multimodal ones use two or more modalities. A Multimodal Biometric System can be constructed in different ways, according to its architecture, fusion level and fusion strategies. The main of this work is to investigate and compare different feature level fusion strategies, in order to design a Multimodal Biometric System with high performance. In this paper, we used the discrete wavelet transform to extract the feature sets from iris and face images. Experimental results show that Multimodal Biometric Systems outperform Unimodal Biometric Systems according to recognition rate computed over the outputs produced by the induced Support Vector Machine classifier.", "references": ["A. Batool and A. Tariq. Computerized system for fingerprint identification for biometric security. In Multitopic Conference (INMIC), 2011 IEEE 14th International, pages 102-106. IEEE, 2011.", "C. S. C. S. Burrus, R. A. Gopinath, and H. Guo. Introduction to wavelets and wavelet transforms : a primer. Upper Saddle River, N.J. Prentice Hall, 1998.", "T. Camus and R. Wildes. Reliable and fast eye finding in close-up images. In Pattern Recognition, 2002. Proceedings. 16th International Conference on, volume 1, pages 389-394 vol.1, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814095"}, {"title": "An Investigation About the Absence of Validation on Security Quantification Methods", "authors": ["Rodrigo Sanches Miani\n,", "Bruno Bogaz Zarpelao\n,", "Leonardo de Souza Mendes"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nTo understand the actions that lead to successful attacks and also how they can be mitigated, researchers should identify and measure the factors that influence both attackers and victims. Quantifying security is particularly important to construct relevant metrics that support the decisions that need to be made to protect systems and networks. In this work, we aimed at investigating the lack of validation in security quantification methods. Different approaches to security quantification were examined and 57 papers are classified. The results show that most of papers seek to measure generic and complex targets like measuring network security or the security of an entire organization, however, the incidence of validation attempts is higher in works that propose the quantification of specific targets.", "references": ["O. Balci. Verification, validation, and accreditation. In Proceedings of the 30th conference on Winter simulation, 1998.", "S. Bhatt, W. Horne, and P. Rao. On Computing Enterprise IT Risk Metrics. pages 271-280, 2011.", "W. Boyer and M. McQueen. Ideal based cyber security technical metrics for control systems. In Critical Information Infrastructures Security, pages 246-260, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814109"}, {"title": "IR Evaluation: Modeling User Behavior for Measuring Effectiveness", "authors": ["Charles L.A. Clarke\n,", "Mark D. Smucker\n,", "Emine Yilmaz"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis half-day tutorial on IR evaluation combines an introduction to classical IR evaluation methods with material on more recent user-oriented approaches. We primarily focus on off-line evaluation, but some material on on-line evaluation is also covered. The broad goal of the tutorial is to equip researchers with an understanding of modern approaches to IR evaluation, facilitating new research on this topic and improving evaluation methodology for emerging areas.", "references": ["Azzah Al-Maskari, Mark Sanderson, and Paul Clough. The relationship between IR effectiveness measures and user satisfaction. In 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 773--774, 2007.", "Javed A. Aslam, Virgil Pavlu, and Emine Yilmaz. A statistical method for system evaluation using incomplete judgments. In 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541--548, 2006.", "Javed A. Aslam, Emine Yilmaz, and Virgiliu Pavlu. The maximum entropy method for analyzing retrieval measures. In 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 27--34, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767876"}, {"title": "Predicting Search Satisfaction Metrics with Interleaved Comparisons", "authors": ["Anne Schuth\n,", "Katja Hofmann\n,", "Filip Radlinski"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe gold standard for online retrieval evaluation is AB testing. Rooted in the idea of a controlled experiment, AB tests compare the performance of an experimental system (treatment) on one sample of the user population, to that of a baseline system (control) on another sample. Given an online evaluation metric that accurately reflects user satisfaction, these tests enjoy high validity. However, due to the high variance across users, these comparisons often have low sensitivity, requiring millions of queries to detect statistically significant differences between systems. Interleaving is an alternative online evaluation approach, where each user is presented with a combination of results from both the control and treatment systems. Compared to AB tests, interleaving has been shown to be substantially more sensitive. However, interleaving methods have so far focused on user clicks only, and lack support for more sophisticated user satisfaction metrics as used in AB testing. In this paper we present the first method for integrating user satisfaction metrics with interleaving. We show how interleaving can be extended to (1) directly match user signals and parameters of AB metrics, and (2) how parameterized interleaving credit functions can be automatically calibrated to predict AB outcomes. We also develop a new method for estimating the relative sensitivity of interleaving and AB metrics, and show that our interleaving credit functions improve agreement with AB metrics without sacrificing sensitivity. Our results, using 38 large-scale online experiments en- compassing over 3 billion clicks in a web search setting, demonstrate up to a 22% improvement in agreement with AB metrics (constituting over a 50% error reduction), while maintaining sensitivity of one to two orders of magnitude above the AB tests. This paves the way towards more sensitive and accurate online evaluation.", "references": ["O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. phACM TOIS, 30 (1): 1--41, Feb. 2012.", "F. Diaz, R. White, G. Buscher, and D. Liebling. Robust models of mouse movement on dynamic web search results pages. In phCIKM, pages 1451--1460. ACM Press, Oct. 2013.", "G. Dupret and M. Lalmas. Absence time and user engagement: Evaluating ranking functions. In phWSDM, pages 173--182, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767695"}, {"title": "When Relevance Judgement is Happening?: An EEG-based Study", "authors": ["Marco Allegretti\n,", "Yashar Moshfeghi\n,", "Maria Hadjigeorgieva\n,", "Frank E. Pollick\n,", "Joemon M. Jose\n,", "Gabriella Pasi"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRelevance is a central notion in Information Retrieval, but it is considered to be a difficult concept to define. We analyse brain signals for the first 800 milliseconds (ms) of a relevance assessment process to answer the question \"when relevance is happening in the brain?\" with the belief that it will lead to better operational definitions of relevance. For this purpose, we devised a user study in which we captured the brain response of 20 participants. Using a 64-channel EEG device, we measured the electrophysiological activity of the brain while the subjects were in the phase of giving an explicit judgement about the relevance of presented images according to a given topic. Analyses were then performed over different time windows of the recorded EEG signals using repeated measures ANOVA. Data reveal significant variation between relevance and non-relevance within the EEG signals from the presentation of the image to 800 milliseconds afterwards. At an early stage these differences were located at frontal and posterior electrode sites. However, at later stages these differences were located in central, centro-parietal and centro-frontal areas.Our findings are an important step towards (i) a better understanding of the concept of relevance and (ii) a more effective implicit feedback systems.", "references": ["I. Arapakis, K. Athanasakos, and J. M. Jose. A comparison of general vs personalised affective models for the prediction of topical relevance. In SIGIR, pages 371--378, 2010.", "I. Arapakis, Y. Moshfeghi, H. Joho, R. Ren, D. Hannah, and J. M. Jose. Enriching user profiling with affective features for the improvement of a multimodal recommender system. In CIVR, 2009.", "P. Borlund. The concept of relevance in ir. Journal of the American Society for information Science and Technology, 54:913--925, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767811"}, {"title": "VPIndexer: velocity-based partitioning for indexing moving objects", "authors": ["Xiaofeng Xu\n,", "Li Xiong\n,", "Vaidy Sunderam\n,", "Jinfei Liu\n,", "Jun Luo"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nIndexing moving objects has been extensively studied in the past decades. In most real world applications, the moving objects exhibit particular patterns on their velocities. For example, velocities of vehicles in city road networks usually show patterns on both directions and values. Velocity-based partitioning techniques have been proved effective in improving query performances of moving object indexes. This demo presents VPIndexer, a toolkit for visualizing comparison of three velocity-based partitioning algorithms: VMBR-based partitioning, DVA-based partitioning and our recently proposed speed-based partitioning techniques. VPIndexer uses the Bx-tree and the TPR*-tree as the baseline approaches.", "references": ["T. Brinkhoff. A framework for generating network-based moving objects. GeoInformatica, 6(2), 2002.", "S. Chen, C. S. Jensen, and D. Lin. A benchmark for evaluating moving object indexes. PVLDB, 1(2), 2008.", "S. Chen, B. C. Ooi, K.-L. Tan, and M. A. Nascimento. St2b-tree: a self-tunable spatio-temporal b+-tree index for moving objects. In SIGMOD, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820786"}, {"title": "Measuring and Characterizing Nutritional Information of Food and Ingestion Content in Instagram", "authors": ["Sanket S. Sharma\n,", "Munmun De Choudhury"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSocial media sites like Instagram have emerged as popular platforms for sharing ingestion and dining experiences. However research on characterizing the nutritional information embedded in such content is limited. In this paper, we develop a computational method to extract nutritional information, specifically calorific content from Instagram food posts. Next, we explore how the community reacts specifically to healthy versus non-healthy food postings. Based on a crowdsourced approach, our method was found to detect calorific content in posts with 89% accuracy. We further show the use of Instagram as a platform where sharing of moderately healthy food content is common, and such content also receives the most support from the community.", "references": ["Sofiane Abbar, Yelena Mejova, and Ingmar Weber. You tweet what you eat: Studying food consumption through twitter. In Proc. CHI, 2015.", "Daniel Fried, Mihai Surdeanu, Stephen Kobourov, Melanie Hingle, and Dane Bell. Analyzing the language of food on social media. In Proc. IEEE Big Data.", "Claudia Wagner, Philipp Singer, and Markus Strohmaier. Spatial and temporal patterns of online food preferences. In Proc. WWW Companion."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742754"}, {"title": "Efficient Location-Aware Web Search", "authors": ["Joel Mackenzie\n,", "Farhana M. Choudhury\n,", "J. Shane Culpepper"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nMobile search is quickly becoming the most common mode of search on the internet. This shift is driving changes in user behaviour, and search engine behaviour. Just over half of all search queries from mobile devices have local intent, making location-aware search an increasingly important problem. In this work, we compare the efficiency and effectiveness of two general types of geographical search queries, range queries and k nearest neighbor queries, for common web search tasks. We test state-of-the-art spatial-textual indexing and search algorithms for both query types on two large datasets. Finally, we present a rank-safe dynamic pruning algorithm that is simple to implement and use with current inverted indexing techniques. Our algorithm is more efficient than the tightly coupled best-in-breed hybrid indexing algorithms that are commonly used for top-k spatial textual queries, and more likely to find relevant documents than techniques derived from range queries.", "references": ["Microsoft: 53 percent of mobile searches have local intent. http://searchengineland.com/microsoft-53-percent-of-mobile-searches-have-local-intent-55556. Accessed: 2015-09-03.", "Understanding consumers' local search behavior. https://www.thinkwithgoogle.com/research-studies/how-advertisers-can-extend-their-relevance-with-search.html. Accessed: 2015-09-03.", "N. Asadi and J. Lin. Document vector representations for feature extraction in multi-stage document ranking. Information Retrieval, 16 (6):747--768, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838933"}, {"title": "A File Recommendation Model For Cloud Storage Systems", "authors": ["Ricardo Batista Rodrigues\n,", "Carlo M. R. da Silva\n,", "Frederico A. Durao\n,", "Rodrigo E. Assad\n,", "Vinicius C. Garcia\n,", "Silvio R. L. Meira"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe technological development in recent years has experienced the exponentially growth of the digital universe, part of this digital universe lies stored in cloud storage systems. With each day, more of these systems come out, offering data storage in a distributed manner with the proposal to provide high availability rate, what has driven more and more users who have migrated your data to the cloud. However, the large amount of files stored in these systems makes it difficult to filter relevant content, requiring time and labor by the user in searching for files with similar content to your preferences. Face of this scenario, this study proposes a model for recommendation of files in cloud storage systems, which aims to use cloud features associated with the technique of content-based recommendation.", "references": ["L. M. d. L. A. V. F. P. R. T. e. A. C. S. Adriano de Oliveira Tito, Arley Ramalho Rodrigues Ristar. Recroute: Uma proposta de aplicativo para recomenda de rotas de nibus utilizando informas contextuais dos usuos. Anais do X Simp Brasileiro de Sistemas de Informas, pages 218-223, 2014.", "T. B. M. d. S. Alezy Oliveira Lima, Ricardo Alexandre Afonso. Plataforma pguide: um modelo de recomenda para usuos ms. Anais do X Simp Brasileiro de Sistemas de Informa, pages 73-84, 2013.", "A. Ansari, S. Essegaier, and R. Kohli. Internet recommendation systems. JOURNAL OF MARKETING RESEARCH, 37(3):363-375, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814078"}, {"title": "Facebook's affordances, visible culture, and anti-anonymity", "authors": ["Angela M. Cirucci"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nThis paper outlines and analyzes a selection of Facebook's affordances to argue that the site compels users to become as visible as possible, thus refusing their right to be anonymous. This promoted visible culture is primarily guided by two affordance categories: the \"real you\" policy and photographs. The related interface affordances for each category are catalogued and focus groups with emerging adult users (n=45) are analyzed to better understand how users interact with the space while attempting to maintain and broadcast the self. Findings indicate that users (1) do not question the \"real you\" policy because they view Facebook, like the Census or an application, as an \"official\" space and (2) value photographs of corporeal selves to the point of ostracizing offline friends on the site when they have chosen \"non-traditional\" profile pictures.", "references": ["Goffman, E. 1959. The presentation of self in everyday life. New York, NY: Anchor Books.", "Hogan, B. 2010. The presentation of self in the age of social media: Distinguishing performances and exhibitions online. Bulletin of Science, Technology & Society 30, 6, 377--386. DOI=10.1177/0270467610385893", "Farquhar, L. 2013. Performing and interpreting identity through Facebook imagery. Convergence 19, 4, 446--471."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789202"}, {"title": "Slow Search: Improving Information Retrieval Using Human Assistance", "authors": ["Jaime Teevan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe live in a world where the pace of everything from communication to transportation is getting faster. In recent years a number of \"slow movements\" have emerged that advocate for reducing speed in exchange for increasing quality, including the slow food movement, slow parenting, slow travel, and even slow science. We propose the concept of \"slow search,\" where search engines use additional time to provide a higher quality search experience than is possible given conventional time constraints. While additional time can be used to identify relevant results within the existing search engine framework, it can also be used to create new search artifacts and enable previously unimaginable user experiences. This talk will focus on how search engines can make use of additional time to employ a resource that is inherently slow: other people. Using crowdsourcing and friendsourcing, it will highlight opportunities for search systems to support new search experiences with high quality result content that takes time to identify.", "references": ["Bernstein, M., Teevan, J., Dumais, S.T., Libeling, D. and Horvitz, E. Direct answers for search queries in the long tail. CHI 2012.", "Eickhoff, C., Teevan, J., White, R. and Dumais, S.T. Lessons from the journey: A query log analysis of within-session learning. WSDM 2014.", "Jeong, J., Morris, M., Teevan, J. and Liebling, D. A crowd powered socially embedded search engine. ICWSM 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806417"}, {"title": "Probabilistic Matrix Factorization With Semantic And Visual Neighborhoods For Image Tag Completion", "authors": ["Dimitrios Rafailidis"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWe present an image tag completion method, namely PMF-SVN, where the key idea is to exploit images' Semantically and Visually similar Neighborhoods (SVNs) in the learning process of a Probabilistic Matrix Factorization (PMF) framework. We propose a two-step SVN formation algorithm that can generate an image set with the images being both visually and semantically similar. Furthermore, we introduce an efficient way to incorporate the formed SVNs into the learning process of PMF, under the constraint that the latent features of each image are averaged by the features of the images that belong to its SVN. In our experiments with benchmark datasets, we show that the proposed PMF-SVN method outperforms competitive baselines, in terms of completion accuracy, by efficiently capturing the semantical and visual associations between images and tags in SVNs.", "references": ["J. Chen, Y. Cui, G. Ye, D. Liu, and S. Chang. Event-driven semantic concept discovery by exploiting weakly tagged internet images. In ICMR, page 1, 2014.", "Z. Feng, S. Feng, R. Jin, and A. K. Jain. Image tag completion by noisy matrix recovery. In ECCV, pages 424--438, 2014.", "Z. Lin, G. Ding, M. Hu, J. Wang, and X. Ye. Image tag completion via image-specific and tag-specific linear sparse reconstructions. In CVPR, pages 1618--1625, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749333"}, {"title": "A Real-Time Eye Tracking Based Query Expansion Approach via Latent Topic Modeling", "authors": ["Yongqiang Chen\n,", "Peng Zhang\n,", "Dawei Song\n,", "Benyou Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nFormulating and reformulating reliable textual queries have been recognized as a challenging task in Information Retrieval (IR), even for experienced users. Most existing query expansion methods, especially those based on implicit relevance feedback, utilize the user's historical interaction data, such as clicks, scrolling and viewing time on documents, to derive a refined query model. It is further expected that the user's search experience would be largely improved if we could dig out user's latent query intention, in real-time, by capturing the user's current interaction at the term level directly. In this paper, we propose a real-time eye tracking based query expansion method, which is able to: (1) automatically capture the terms that the user is viewing by utilizing eye tracking techniques; (2) derive the user's latent intent based on the eye tracking terms and by using the Latent Dirichlet Allocation (LDA) approach. A systematic user study has been carried out and the experimental results demonstrate the effectiveness of our proposed methods.", "references": ["A. Ajanki, D. R. Hardoon, S. Kaski, K. Puolamäki, and J. Shawe-Taylor. Can eyes reveal interest? Implicit queries from gaze patterns. User Modeling and User-Adapted Interaction, 19(4):307--339, 2009.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "G. Buscher, A. Dengel, and L. van Elst. Query expansion using gaze-based feedback on the subdocument level. In ACM SIGIR, pages 387--394. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806602"}, {"title": "Reasoning with patterns to effectively answer XML keyword queries", "authors": ["Cem Aksoy\n,", "Aggeliki Dimitriou\n,", "Dimitri Theodoratos"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nKeyword search is a popular technique for searching tree-structured data on the Web because it frees the user from knowing a complex query language and the structure of the data sources. However, the imprecision of the keyword queries usually results in a very large number of results of which only a few are relevant to the query. Multiple previous approaches have tried to address this problem. They exploit the structural properties of the tree data in order to filter out irrelevant results. This is not an easy task though, and in the general case, these approaches show low precision and/or recall and low quality of result ranking. In this paper, we argue that exploiting the structural relationships of the query matches locally in the data tree is not sufficient and a global analysis of the keyword matches in the data tree is necessary in order to assign meaningful semantics to keyword queries. We present an original approach for answering keyword queries which extracts structural patterns of the query matches and reasons with them in order to return meaningful results ranked with respect to their relevance to the query. Comparisons between patterns are realized based on different types of homomorphisms between patterns. As the number of patterns is typically much smaller than that of the of query matches, this global reasoning is feasible. We design an efficient stack-based algorithm for evaluating keyword queries on tree-structured data, and we also devise a heuristic extension which further improves its performance. We run comprehensive experiments on different datasets to evaluate the efficiency of the algorithms and the effectiveness of our ranking and filtering semantics. The experimental results show that our approach produces results of higher quality compared to previous ones and our algorithms are fast and scale well with respect to the input and output size.", "references": ["Aksoy, C., Dimitriou, A., Theodoratos, D., Wu, X.: XReason: a semantic approach that reasons with patterns to answer XML keyword queries. In: DASFAA, pp. 299---314 (2013)", "Baeza-Yates, R.A., Ribeiro-Neto, B.A.: Modern Information Retrieval. ACM Press/Addison-Wesley, New York (1999)", "Bao, Z., Ling, T.W., Chen, B., Lu. J.: Effective XML keyword search with relevance oriented ranking. In: ICDE, pp. 517---528 (2009)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0384-3"}, {"title": "GiveMe Views: a support tool to software evolution based on historical data analysis", "authors": ["Jacimar F. Tavares\n,", "Jose Maria N. David\n,", "Marco Antonio P. Araujo\n,", "Regina Braga\n,", "Fernanda Campos\n,", "Glauco Carneiro"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents Give Me Views tool that can indicate possible modules and components that may be impacted when a corrective maintenance, adaptive or evolutionary is performed. Provides views that allow user to obtain information about the relationships between modules and components based on statistical analyzes performed by an SAE (Statistical Analysis Engine) on historical software data. A proof of concept was performed in order to verify the feasibility of the tool in software development activities in a real context of use. The tool deployment results in a software development company are presented.", "references": ["Basili, Victor R. Caldiera, Gianluigi H. Rombach, Dieter. (1994). \"The Goal Question Metric Approach\". Chapter in Encyclopedia of Software Engineering, Wiley, 1994.", "GiveMe Views: http://givemeinfra.com.br/givemeviews. Acessado em jun de 2014.", "Haitzer, Thomas. Uwe Zdun. \"Semi-automated architectural abstraction specifications for supporting software evolution\". Science of Computer Programming, Vol. 90, Part B, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814068"}, {"title": "The Impact of Structured Event Embeddings on Scalable Stock Forecasting Models", "authors": ["Janderson B. Nascimento\n,", "Marco Cristo"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nAccording to the efficient market hypothesis, financial prices are unpredictable. However, meaningful advances have been achieved on anticipating market movements using machine learning techniques. In this work, we propose a novel method to represent the input for a stock price forecaster. The forecaster is able to predict stock prices from time series and additional information from web pages. Such information is extracted as structured events and represented in a compressed concept space. By using such representation with scalable forecasters, we reduced prediction error by about 10%, when compared to the traditional auto regressive models.", "references": ["Michele Banko, Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. Open information extraction for the web. In IJCAI, volume 7, pages 2670--2676, 2007.", "Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Janvin. A neural probabilistic language model. The Journal of Machine Learning Research, 3:1137--1155, 2003.", "Leo Breiman. Random forests. Machine learning, 45(1):5--32, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820467"}, {"title": "Surfing the Net for Software Engineering Notes", "authors": ["Mark Doernhoefe"], "publication": "ACM SIGSOFT Software Engineering Notes", "abstract": "", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815021.2815025"}, {"title": "Automated Support for Scrum Projects Sprint Planning", "authors": ["Hanna Tatila de Sousa\n,", "Thanner S. Silva\n,", "Paulo S. Santos\n,", "Rodrigo F. Calhau\n,", "Mateus Barcellos Costa"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn this paper an approach to support Sprint Planning in Scrum projects is discussed. This approach allows the automatic determination of the optimal set of tasks for a given sprint, as well as its execution flow, considering the a priori information concerning the current state of the project, tasks's difficulty and importance, and the relations between tasks. The proposed solution is based on the representation of the project decision space, defined by this information, as workflow models. To evaluate the approach, a prototype has been developed and is being assessed in the context of the Cornea Notification and Collecting Information System (Sincap) project. The results suggest that the use of the approach provides greater determinism for the sprint planning process, easies the viewing and evaluation of project scenarios and decreases planning time.", "references": ["D. Biasoli and L. M. Fontoura. Auxílio de redes de petri coloridas na implantação de projetos scrum. In Anais do VII Simpósio Brasileiro de Sistemas de Informação, pages 498-502. SBC, 2011.", "M. B. Costa and T. S. Silva. Uma abordagem para recomendação no apoioa modelagem de processos de negócio. In Anais do XXIX Simpósio Brasileiro de Banco de Dados, pages 177-186. SBC, 2014.", "J. A. Crowder and S. Friess. Productivity tools for the modern team. In Agile Project Management: Managing for Success, pages 43-48. Springer, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814105"}, {"title": "Ear ball for empathy: research into the simulation of sensory experiences common to developmental disorders", "authors": ["Taisuke Murakami"], "publication": "SA '15: SIGGRAPH Asia 2015 Emerging Technologies", "abstract": "ABSTRACT\nDevelopmental disorders (particularly autism spectrum disorders) are characterised by difficulties in sensory integration and a body image which differs from the normal, healthy one. In order to enable healthy people to experience and thus develop a deeper understanding of the different body image that people with developmental disorders possess the author is pursuing research into the simulation of sensory experiences common to developmental disorders. This study focuses on a particular sensory characteristic of developmental disorders where difficulty is experienced in locating the source of sound in an environment and the development of a device for simulating the sense of hearing experienced in such a disorder. Workshops for children were carried out using the developed device, with interviews indicating that the majority of participants experienced feelings of ambiguity in relation to their own senses. Such a feeling in one's sensory boundaries is a phenomenon which is common in developmental disorder research. It was concluded that the device developed in this study allowed people to vicariously experience the senses of people with developmental disorders.", "references": ["Axel Brauns. 2002. Buntschatten und Fledermause, Hoffmann und Campe Verlag.", "Naoki Higashida 2013. The Reason I Jump, SCEPTRE.", "Temple Grandin. 1995. Thinking in Pictures, Doubleday."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818466.2818479"}, {"title": "Deep Self-taught Hashing for Image Retrieval", "authors": ["Ke Zhou\n,", "Yu Liu\n,", "Jingkuan Song\n,", "Linyu Yan\n,", "Fuhao Zou\n,", "Fumin Shen"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHashing is a promising technique to tackle the problem of scalable retrieval, and it generally consists two major components, namely hash code generation and hash functions learning.The majority of existing hashing fall under the shallow model, which is intrinsically weak on mining robust visual features and learning complicated hash functions. In view of the superiority of deep structure, especially the Convolutional Neural Networks (CNNs), on extracting high level representation, we propose a deep self-taught hashing (DSTH) framework to combine deep structures with hashing to improve the retrieval performance by automatically learning robust visual features and hash functions. By employing CNNs, more robust and discriminative features of the images can be extracted to benefit the hash codes generation. Then, we apply CNNs and Multi-layer Perceptron under deep learning scheme to learn hash function in supervised process by using the generated hash codes as labels. The experimental results have shown that the DSTH is superior to several state-of-the-art algorithms.", "references": ["J. Wang, Y. Song, T. Leung, C. Rosenberg, and Y. Wu. Learning fine-grained image similarity with deep ranking. CVPR, 2014.", "Y. Yang, Y. Yang, Z. Huang, H. Shen and F. Nie. Tag Localization with Spatial Correlations and Joint Group Sparsity. CVPR, 2011.", "R. Xia, Y. Pan, H. Lai, C. Liu, S. Yan. Supervised Hashing for Image Retrieval via Image Representation Learning. AAAI, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806320"}, {"title": "Personalized Catch-up & DVR: VOD or Linear, That is the Question", "authors": ["Pancrazio Auteri\n,", "Roberto Turrin"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe expansion of TV services such as DVR and, more recently, Catch-up have removed the temporal constraint typical of the Linear \"appointment\" TV enabling users to watch content they love at any time and on-demand. However, the DVR and Catch-up TV libraries, while providing a convenient time-shifted \"on-demand\" consumption, are indeed composed by content recently aired on a linear channel, so that they have more in common with Linear TV than they have with VOD. In this talk we will present and discuss the main challenges and some possible solutions to personalize the user experience with content from DVR and Catch-up TV, such as: (i) The consumption pattern is strongly affected by the context (e.g., time and device used to access the video service). (ii) Some content is consumed serially and still follows seasonal dynamics (e.g., TV Series). (iii) The system is fed with a massive and very dynamic streams of data (e.g., new content arriving right after broadcast, signals of user interactions). (iv) The same piece of content may coexist across multiple services provided by the same operator (e.g., linear schedule, network-DVR, catch-up TV, subscription VOD, rental VOD).", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799493"}, {"title": "Exploratory Visual Analysis and Interactive Pattern Extraction from Semi-Structured Data", "authors": ["Axel J. Soto\n,", "Ryan Kiros\n,", "Vlado Kešelj\n,", "Evangelos Milios"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nSemi-structured documents are a common type of data containing free text in natural language (unstructured data) as well as additional information about the document, or meta-data, typically following a schema or controlled vocabulary (structured data). Simultaneous analysis of unstructured and structured data enables the discovery of hidden relationships that cannot be identified from either of these sources when analyzed independently of each other. In this work, we present a visual text analytics tool for semi-structured documents (ViTA-SSD), that aims to support the user in the exploration and finding of insightful patterns in a visual and interactive manner in a semi-structured collection of documents. It achieves this goal by presenting to the user a set of coordinated visualizations that allows the linking of the metadata with interactively generated clusters of documents in such a way that relevant patterns can be easily spotted. The system contains two novel approaches in its back end: a feature-learning method to learn a compact representation of the corpus and a fast-clustering approach that has been redesigned to allow user supervision. These novel contributions make it possible for the user to interact with a large and dynamic document collection and to perform several text analytical tasks more efficiently. Finally, we present two use cases that illustrate the suitability of the system for in-depth interactive exploration of semi-structured document collections, two user studies, and results of several evaluations of our text-mining components.", "references": ["Richard Arias-Hernandez, Linda T. Kaastra, Tera Marie Green, and Brian Fisher. 2011. Pair analytics: Capturing reasoning processes in collaborative visual analytics. In 2011 44th Hawaii International Conference on System Sciences (HICSS’11). IEEE, 1--10.", "Sugato Basu, Arindam Banerjee, and Raymond J. Mooney. 2002. Semi-supervised clustering by seeding. In International Conference on Machine Learning, Vol. 2. 27--34.", "Yoshua Bengio. 2009. Learning deep architectures for AI. Foundations and Trends in Machine Learning 2, 1, 1--127."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2812115"}, {"title": "Analyzing Book-Related Features to Recommend Books for Emergent Readers", "authors": ["Maria Soledad Pera\n,", "Yiu-Kai Ng"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nWe recognize that emergent literacy forms a foundation upon which children will gage their future reading. It is imperative to motivate young readers to read by offering them appealing books to read so that they can enjoy reading and gradually establish a reading habit during their formative years that can aid in promoting their good reading habits. However, with the huge volume of existing and newly-published books, it is a challenge for parents/educators (young readers, respectively) to find the right ones that match children's interests and their read-ability levels. In response to the needs, we have developed K3Rec, a recommender which applies a multi-dimensional approach to suggest books that simultaneously match the interests/preferences and reading abilities of emergent (i.e., K-3) readers. K3Rec considers the grade levels, contents, illustrations, and topics, besides using special properties, such as length and writing style, to distinguish K-3 books from other books targeting more mature readers. K3Rec is novel, since it adopts an unsupervised strategy to suggest books for K-3 readers which does not rely on the existence of personal social media data, such as personal tags and ratings, that are seldom, if ever, created by emergent readers. Further-more, unlike existing book recommenders, K3Rec explicitly analyzes book illustrations, which is of special significance for emergent readers, since illustrations assist these readers in understanding the contents of books. K3Rec focuses on a niche group of readers that has not been explicitly targeted by existing book recommenders. Empirical studies conducted using data from BiblioNasium.com and Amazon's Mechanical Turk have verified the effectiveness of K3Rec in making book recommendations for emergent readers.", "references": ["R. Allington and E. Gabriel. Every Child, Every Day. Reading: The Core Skill, 69(6):10--15, 2012.", "R. Benjamin. Reconstructing Readability: Recent Developments and Recommendations in the Analysis of Text Difficulty. Educational Psychology, 24:63--88, 2012.", "A. Budanitsky and G. Hirst. Evaluating WordNet- based Measures of Lexical Semantic Relatedness. Computational Linguistics, 32(1):13--47, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791037"}, {"title": "Exploiting Word and Visual Word Co-occurrence for Sketch-based Clipart Image Retrieval", "authors": ["Ching-Hsuan Liu\n,", "Yen-Liang Lin\n,", "Wen-Feng Cheng\n,", "Winston H. Hsu"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nAs the increasing popularity of touch-screen devices, retrieving images by hand-drawn sketch has become a trend. Human sketch can easily express some complex user intention such as the object shape. However, sketches are sometimes ambiguous due to different drawing styles and inter-class object shape ambiguity. Although adding text queries as semantic information can help removing the ambiguity of sketch, it requires a huge amount of efforts to annotate text tags to all database clipart images. We propose a method directly model the relationship between text and clipart images by the co-occurrence relationship between words and visual words, which improves traditional sketch-based image retrieval (SBIR), provides a baseline performance and obtains more relevant results in the condition that all images in database do not have any text tag. Experimental results show that our method really can help SBIR to get better retrieval result since it indeed learned semantic meaning from the ``word-visual word\" (W-VW) co-occurrence relationship.", "references": ["Y. Cao, C. Wang, L. Zhang, and L. Zhang. Edgel index for large-scale sketch-based image search. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 761--768. IEEE, 2011.", "Y. Cao, H. Wang, C. Wang, Z. Li, L. Zhang, and L. Zhang. Mindfinder: interactive sketch-based image search on millions of images. In Proceedings of the international conference on Multimedia, pages 1605--1608. ACM, 2010.", "M. Eitz, K. Hildebrand, T. Boubekeur, and M. Alexa. An evaluation of descriptors for large-scale image retrieval from sketched feature lines. Computers & Graphics, 34(5):482--498, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806351"}, {"title": "A Clustering-Based Framework to Control Block Sizes for Entity Resolution", "authors": ["Jeffrey Fisher\n,", "Peter Christen\n,", "Qing Wang\n,", "Erhard Rahm"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nEntity resolution (ER) is a common data cleaning task that involves determining which records from one or more data sets refer to the same real-world entities. Because a pairwise comparison of all records scales quadratically with the number of records in the data sets to be matched, it is common to use blocking or indexing techniques to reduce the number of comparisons required. These techniques split the data sets into blocks and only records within blocks are compared with each other. Most existing blocking techniques do not provide control over the size of the generated blocks, despite this control being important in many practical applications of ER, such as privacy-preserving record linkage and real-time ER. We propose two novel hierarchical clustering approaches which can generate blocks within a specified size range, and we present a penalty function which allows control of the trade-off between block quality and block size in the clustering process. We evaluate our techniques on three real-world data sets and compare them against three baseline approaches. The results show our proposed techniques perform well on the measures of pairs completeness and reduction ratio compared to the baseline approaches, while also satisfying the block size restrictions.", "references": ["I. Bhattacharya and L. Getoor. Collective entity resolution in relational data. ACM TKDD, 1(1), 2007.", "P. Christen. Data matching: concepts and techniques for record linkage, entity resolution, and duplicate detection. Springer, 2012.", "P. Christen. A survey of indexing techniques for scalable record linkage and deduplication. IEEE TKDE, 24(9), 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783396"}, {"title": "TweetSense: Context Recovery for Orphan Tweets by Exploiting Social Signals in Twitter", "authors": ["Manikandan Vijayakumar\n,", "Tejas Mallapura Umamaheshwar\n,", "Subbarao Kambhampati\n,", "Kartik Talamadupula"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nAs the popularity of Twitter, and the volume of tweets increased dramatically, hashtags have naturally evolved to become a de facto context providing/categorizing mechanism on Twitter. Despite their wide-spread adoption, fueled in part by hashtag recommendation systems, lay users continue to generate tweets without hashtags. When such \"orphan\" tweets show up in a (browsing) user's time-line, it is hard to make sense of their context. In this paper, we present a system called TweetSense which aims to rectify such orphan tweeets by recovering their context in terms of their missing hashtags. TweetSense enables this context recovery by using both the content and social network features of the orphan tweet. We characterize the context recovery problem, present the details of TweetSense and present a systematic evaluation of its effectiveness over a 7 million tweet corpus.", "references": ["W. Feng and J. Wang. We can learn your hashtags: Connecting tweets to explicit topics. In Data Engineering (ICDE), 2014 IEEE 30th International Conference on, pages 856--867, March 2014.", "J. She and L. Chen. Tomoha: Topic model-based hashtag recommendation on twitter. In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, WWW Companion '14, pages 371--372, Republic and Canton of Geneva, Switzerland, 2014. International World Wide Web Conferences Steering Committee.", "E. Zangerle, W. Gassler, and G. Specht. On the impact of text similarity functions on hashtag recommendations in microblogging environments. Eva 2013, 3(4):889--898, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2790157"}, {"title": "Planning sightseeing tours using crowdsensed trajectories", "authors": ["Igo Brilhante\n,", "Jose Antonio Macedo\n,", "Franco Maria Nardini\n,", "Raffaele Perego\n,", "Chiara Renso"], "publication": "SIGSPATIAL Special", "abstract": "Abstract\nWe present an application where semantically enriched trajectories obtained from crowdsensed data are used to build an advanced system for planning personalized sightseeing tours, called TripBuilder. The interesting feature of TripBuilder is that it uses Wikipedia content and trajectories of previous tourists collected by georeferenced Flickr photos in a complex spatio-temporal framework. The objective is to address, in an unsupervised way, the problem of suggesting a budgeted sightseeing tour based on the preferences of the tourist and the time available for the visit. We present few highlights of how TripBuilder works along with a research agenda where we discuss the role of semantically enriched trajectories and crowdsourced location data in planning itineraries.", "references": ["I. R. Brilhante, J. A. Macedo, F. M. Nardini, R. Perego, and C. Renso. Where shall we go today?: Planning touristic tours with tripbuilder. In Proceedings of the 22nd ACM International Conference on Conference on Information and Knowledge Management, CIKM 2013, pages 757--762, New York, NY, USA, 2013. ACM.", "I. R. Brilhante, J. A. Macedo, F. M. Nardini, R. Perego, and C. Renso. Tripbuilder: A tool for recommending sightseeing tours. In M. Rijke, T. Kenter, A. P. Vries, C. X. Zhai, F. Jong, K. Radinsky, and K. Hofmann, editors, Advances in Information Retrieval, volume 8416 of Lecture Notes in Computer Science, pages 771--774. Springer International Publishing, 2014.", "I. R. Brilhante, J. A. Macedo, F. M. Nardini, R. Perego, and C. Renso. On planning sightseeing tours with tripbuilder. Information Processing & Management, 51(2):1--15, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2782759.2782769"}, {"title": "A Novelty-Seeking based Dining Recommender System", "authors": ["Fuzheng Zhang\n,", "Kai Zheng\n,", "Nicholas Jing Yuan\n,", "Xing Xie\n,", "Enhong Chen\n,", "Xiaofang Zhou"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe rapid growth of location-based services provide the potential to understand people's mobility pattern at an unprecedented level, which can also enable food-service industry to accurately predict consumer's dining behavior. In this paper, by leveraging users' historical dining pattern, socio-demographic characteristics and restaurants' attributes, we aim at generating the top-K restaurants for a user's next dining. Compared to previous studies in location prediction which mainly focus on regular mobility patterns, we present a novelty-seeking based dining recommender system, termed NDRS, in consideration of both exploration and exploitation. First, we apply a Conditional Random Field (CRF) with additional constraints to infer users' novelty-seeking statuses by considering both spatial-temporal-historical features and users' socio-demographic characteristics. On the one hand, when a user is predicted to be novelty-seeking, by incorporating the influence of restaurants' contextual factors such as price and service quality, we propose a context-aware collaborative filtering method to recommend restaurants she has never visited before. On the other hand, when a user is predicted to be not novelty-seeking, we then present a Hidden Markov Model (HMM) considering the temporal regularity to recommend the previously visited restaurants. To evaluate the performance of each component as well as the whole system, we conduct extensive experiments, with a large dataset we have collected covering the concerned dining related check-ins, users' demographics, and restaurants' attributes. The results reveal that our system is effective for dining recommendation.", "references": ["M. Acker and P. McReynolds. The\" need for novelty\": A comparison of six instruments. The Psychological Record, 1967.", "G. Adomavicius, R. Sankaranarayanan, S. Sen, and A. Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Transactions on Information Systems (TOIS), 23(1):103--145, 2005.", "T. D. Andersson and L. Mossberg. The dining experience: do restaurants satisfy customer needs? Food Service Technology, 4(4):171--177, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741095"}, {"title": "A Deep Siamese Network for Scene Detection in Broadcast Videos", "authors": ["Lorenzo Baraldi\n,", "Costantino Grana\n,", "Rita Cucchiara"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present a model that automatically divides broadcast videos into coherent scenes by learning a distance measure between shots. Experiments are performed to demonstrate the effectiveness of our approach by comparing our algorithm against recent proposals for automatic scene segmentation. We also propose an improved performance measure that aims to reduce the gap between numerical evaluation and expected results, and propose and release a new benchmark dataset.", "references": ["E. Apostolidis and V. Mezaris. Fast Shot Segmentation Combining Global and Local Visual Descriptors. In IEEE Int. Conf. Acoustics, Speech and Signal Process., pages 6583--6587, 2014.", "V. T. Chasanis, C. Likas, and N. P. Galatsanos. Scene detection in videos using shot clustering and sequence alignment. IEEE Trans. Multimedia, 11(1):89--100, 2009.", "R. Hadsell, S. Chopra, and Y. LeCun. Dimensionality reduction by learning an invariant mapping. In IEEE Int. Conf. Comput. Vis. Pattern Recognit., volume 2, pages 1735--1742. IEEE, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806316"}, {"title": "Inside Jokes: Identifying Humorous Cartoon Captions", "authors": ["Dafna Shahaf\n,", "Eric Horvitz\n,", "Robert Mankoff"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nHumor is an integral aspect of the human experience. Motivated by the prospect of creating computational models of humor, we study the influence of the language of cartoon captions on the perceived humorousness of the cartoons. Our studies are based on a large corpus of crowdsourced cartoon captions that were submitted to a contest hosted by the New Yorker. Having access to thousands of captions submitted for the same image allows us to analyze the breadth of responses of people to the same visual stimulus.\nWe first describe how we acquire judgments about the humorousness of different captions. Then, we detail the construction of a corpus where captions deemed funnier are paired with less-funny captions for the same cartoon. We analyze the caption pairs and find significant differences between the funnier and less-funny captions. Next, we build a classifier to identify funnier captions automatically. Given two captions and a cartoon, our classifier picks the funnier one 69% of the time for captions hinging on the same joke, and 64% of the time for any pair of captions. Finally, we use the classifier to find the best captions and study how its predictions could be used to significantly reduce the load on the cartoon contest's judges.", "references": ["Tesla stock moves on april fools' joke, http://blogs.wsj.com/moneybeat/2015/04/01/tesla-stock-moves-on-april-fools-joke, 2015.", "S. Attardo. Linguistic Theories of Humor. Approaches to Semiotics. Mouton de Gruyter, 1994.", "S. Attardo. A primer for the linguistics of humor. The Primer of Humor Research, Berlin & New York: Mouton de Gruyter, pages 101--155, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783388"}, {"title": "Surveillance and falsification implications for open source intelligence investigations", "authors": ["Petra Saskia Bayerl\n,", "Babak Akhgar"], "publication": "Communications of the ACM", "abstract": "Abstract\nLegitimacy of surveillance is crucial to safeguarding validity of OSINT data as a tool for law-enforcement agencies.", "references": ["Barlett, J., Miller, C., Crump, J., and Middleton, L. Policing in an Information Age. Demos, London, U.K., Mar. 2013.", "Bell, P. and Congram, M. Intelligence-led policing (ILP) as a strategic planning resource in the fight against transnational organized crime (TOC). International Journal of Business and Commerce 2, 12 (2013), 15--28.", "Best, C. Challenges in open source intelligence. In Proceedings of the Intelligence and Security Informatics Conference (Athens, Greece, Sept. 12--14, 2011), 58--62."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2699410"}, {"title": "Optimised Scheduling of Online Experiments", "authors": ["Eugene Kharitonov\n,", "Craig Macdonald\n,", "Pavel Serdyukov\n,", "Iadh Ounis"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModern search engines increasingly rely on online evaluation methods such as A/B tests and interleaving. These online evaluation methods make use of interactions by the search engine's users to test various changes in the search engine. However, since the number of the user sessions per unit of time is limited, the number of simultaneously running on-line evaluation experiments is bounded. In an extreme case, it might be impossible to deploy all experiments since they arrive faster than are proccessed. Consequently, it is very important to efficiently use the limited resource of the user's interactions. In this paper, we formulate the novel problem of schedule optimisation for the queue of the online experiments: given a limited number of the user interactions available for experimentation, we want to re-order the queue so that the number of successful experiments is maximised. In order to build a schedule optimisation algorithm, we start by formulating a model of an online experimentation pipeline. Next, we propose to reduce the task of finding the optimal schedule to a learning-to-rank problem, where we require the most promising experiments to be ranked first in the schedule. To evaluate the proposed approach, we perform an evaluation study using two datasets containing 82 interleaving and 35 A/B test experiments, performed by a commercial search engine. We measure the quality of a schedule as the number of successful experiments executed under the limited resource of the user interactions. Our proposed schedulers obtain improvements of up to 342% compared to the un-optimised baseline schedule on the dataset of interleaving experiments and up to 43% on the dataset of A/B tests.", "references": ["O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):6, 2012.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In CIKM 2009.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In WWW 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767706"}, {"title": "A Hierarchical Distributed Fog Computing Architecture for Big Data Analysis in Smart Cities", "authors": ["Bo Tang\n,", "Zhen Chen\n,", "Gerald Hefferman\n,", "Tao Wei\n,", "Haibo He\n,", "Qing Yang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe ubiquitous deployment of various kinds of sensors in smart cities requires a new computing paradigm to support Internet of Things (IoT) services and applications, and big data analysis. Fog Computing, which extends Cloud Computing to the edge of network, fits this need. In this paper, we present a hierarchical distributed Fog Computing architecture to support the integration of massive number of infrastructure components and services in future smart cities. To secure future communities, it is necessary to build large-scale, geospatial sensing networks, perform big data analysis, identify anomalous and hazardous events, and offer optimal responses in real-time. We analyze case studies using a smart pipeline monitoring system based on fiber optic sensors and sequential learning algorithms to detect events threatening pipeline safety. A working prototype was constructed to experimentally evaluate event detection performance of the recognition of 12 distinct events. These experimental results demonstrate the feasibility of the system's city-wide implementation in the future.", "references": ["Smart Cities. http://www.ibm.com/smarterplanet/us/en/smarter_cities/overview/. Accessed: 2015-07-26.", "Smart Cities USA. http://smartamerica.org/teams/smart-cities-usa/. Accessed: 2015-07-26.", "R. Alzbutas, T. Iešmantas, M. Povilaitis, and J. Vitkutė. Risk and uncertainty analysis of gas pipeline failure and gas combustion consequence. Stochastic Environmental Research and Risk Assessment, 28(6):1431--1446, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818898"}, {"title": "Technological Management of Small Crops Through Mobile Apps and Precision Agriculture", "authors": ["Sergio Manuel Serra da Cruz\n,", "Ana Claudia de Macedo Vieira\n,", "Marden Manuel Marques"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nSmall farmers realize that the adoption of information systems and wireless communications in the field is more than a trend it becomes a necessity. Despite having access to mobile telephony, they do not usually use mobile applications to improve their operations. This work presents a novel computational approach focused on improving the quality of Brazilian tomato crops. We present a low cost and ubiquitous computing environment based on precision agriculture principles to support small farmers to inspect tomato crops and to help them to early detect late blight, one of major disease affecting tomato plants in Brazil. Our initial results have shown that the approach is capable of handling field observations, retrospective provenance descriptiors and process images with neural networks to assit small farmers in automated detection of the foliage disease.", "references": ["IBGE. 2013, Brasil em números\", http://biblioteca.ibge.gov.br/visualizacao/periodicos/2/bn_2013_v21.pdf", "CGI - Cotnitê Gestor Da Internet No Brasil. 2011. TICs domicílios e empresas 2010\". São Paulo, 2011. http://www.cetic.br/tic/2010/index.htm", "Schwartz, C. 2012. Relações de Gênero e Apropriaçõo de Tecnologias de Informaçõo e Comunicaçõo na Agricultura Familiar de Santa Maria-RS\". Tese de Doutorado - UFSM."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814120"}, {"title": "Person re-identification by the marriage of KISS metric learning and post-rank optimization: KISSPOP", "authors": ["Bingbing Zhuang\n,", "Ziping Zhu\n,", "Fangbemi Abassin Sourou\n,", "Nenghai Yu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nPerson re-identification refers to recognizing a person in different locations over non-overlapping cameras. This is an important but very challenging problem in intelligent surveillance video analysis areas. In this paper, we proposed a simple yet efficient framework KISSPOP to design a person re-identification system. In this system, we creatively combine the KISS metric (KISSME) learning with a human-in-the-loop one-shot negative sample mining process, which can also be regarded as a user feedback strategy. The purposes of feedback from user are two folds: 1. to optimize the initial result in the case KISSME does not perform well, which means the true match failed to be ranked into top n (e.g. 20); 2. to on-line update the KISSME model. Experiments on public dataset demonstrate the effectiveness of our framework.", "references": ["M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. The Journal of Machine Learning Research, 7: 2399--2434, 2006.", "M. Dikmen, E. Akbas, T. S. Huang, and N. Ahuja. Pedestrian recognition with a learned metric. In Computer Vision--ACCV 2010, pages 501--512. Springer, 2011.", "M. Farenzena, L. Bazzani, A. Perina, V. Murino, and M. Cristani. Person re-identification by symmetry-driven accumulation of local features. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 2360--2367. IEEE, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808515"}, {"title": "Document Retrieval Metrics for Program Understanding", "authors": ["Eric Harth\n,", "Philippe Dugerdil"], "publication": "FIRE '15: Proceedings of the 7th Forum for Information Retrieval Evaluation", "abstract": "ABSTRACT\nThe need for domain knowledge representation for program comprehension is now widely accepted in the program comprehension community. The so-called \"concept assignment problem\" represents the challenge to locate domain concepts in the source code of programs. The vast majority of attempts to solve it are based on static source code search for clues to domain concepts. In contrast, our approach is based on dynamic analysis using information retrieval (IR) metrics. First we explain how we modeled the domain concepts and their role in program comprehension. Next we present how some of the popular IR metrics could be adapted to the \"concept assignment problem\" and the way we implemented the search engine. Then we present our own metric and the performance of these metrics to retrieve domain concepts in source code. The contribution of the paper is to show how the IR metrics could be applied to the \"concept assignment problem\" when the \"documents\" to retrieve are domain concepts structured in an ontology.", "references": ["T. J. Biggerstaff and B. Mitbander. 1994. Program understanding and the concept assignment problem. Communications of the ACM, 37(5).", "R. Brooks. 1983. Towards a theory of the comprehension of computer programs. Intl. J. of Human-Computer Studies, 18(6).", "Dumais S.T., Furnas G.W., Landauer T.K., Deerwester S., Harshman R. 1988. Using Latent Semantic Analysis to Improve Access to Textual Information. Proc of the ACM CHI."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838706.2838710"}, {"title": "A Theoretical Analysis of Cross-lingual Semantic Relatedness in Vector Space Models", "authors": ["Lei Zhang\n,", "Thanh Tran\n,", "Achim Rettinger"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nSemantic relatedness is essential for different text processing tasks, especially in the cross-lingual setting due to the vocabulary mismatch problem. Many concept-based solutions to semantic relatedness have been proposed, which vary in the notions of concept and document representation. In our contribution, we provide a unified model that generalizes over the existing approaches to cross-lingual semantic relatedness. It shows that the main existing solutions represent different ways for constructing the concept space, which result in different document representations and implications for semantic relatedness computation. In particular, it al- lows us to provide theoretical justifications of existing solutions. Through the experimental evaluation, we show that the results support our theoretical findings.", "references": ["M. Anderka and B. Stein. The esa retrieval model revisited. In SIGIR, pages 670--671, 2009.", "D. M. Blei, A. Y. Ng, M. I. Jordan, and J. Lafferty. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "P. Cimiano, A. Schultz, S. Sizov, P. Sorg, and S. Staab. Explicit versus latent concept models for cross-language information retrieval. In IJCAI, pages 1513--1518, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809450"}, {"title": "Session details: Session 8B: Memory Management", "authors": ["Alper Buyuktosunoglu"], "publication": "ACM SIGARCH Computer Architecture News", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3261628"}, {"title": "Intelligent Information Retrieval Technique for Wireless Sensor Networks", "authors": ["Deepali Virmani\n,", "Savneet Kaur\n,", "Geetika Malhotra"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nWireless Sensor Networks play a vital role in military applications. In Military it's very important to extract the actual information from the transmitted message. Sentiment analysis is a valuable knowledge resource which analyses collective sentiments of a text and helps in decision making. This paper proposes an Intelligent Information Retrieval Technique (IIRT) based on SentiWordNet, a lexical resource which is used for aspect analysis of text messages sent among military groups. The Proposed IIRT extracts the intelligent information from the text messages transmitted in military groups in WSNs. Proposed IIRT is based on sentiment analysis, where first the aggregated message is filtered then segregated with the help of lemmatization and then opinion words are gathered by grammatical tagging. At last aspect analysis of these opinion words is done with the help of SentiWordNet. IIRT gathers the intelligent information from the original message by calculating the polarity values of the opinion words. The proposed IIRT is executed on the time stamping data messages sent among military groups in wireless sensor networks and the results prove the correctness and accuracy of our IIRT.", "references": ["Bhaskar, J., K., S. and Nedungadi, P. 2014. Enhanced Sentiment Analysis of Informal Textual Communication in Social Media by Considering Objective Words and Intensifiers. IEEE International Conference on Recent Advances and Innovations in Engineering (Jaipur, India, May 09-14 2014). ICRAIE'14, 1--6.", "Chinsha, T.C., Joseph, S. 2015. A Syntactic Approach for Aspect Based Opinion Mining. In Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (Anaheim, California, Feb 7-9 2015). ICSC'15, 24--31.", "Singh, V.K., Piryani, R., Uddin, A. and Walia, P. 2013. Sentiment Analysis of Movie Reviews and Blog Posts. 3rd IEEE International Advance Computing Conference (Ghaziabad, India Feb 22-23 2013). IACCF'13, 893--898."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791475"}, {"title": "Open Domain Question Answering via Semantic Enrichment", "authors": ["Huan Sun\n,", "Hao Ma\n,", "Wen-tau Yih\n,", "Chen-Tse Tsai\n,", "Jingjing Liu\n,", "Ming-Wei Chang"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMost recent question answering (QA) systems query large-scale knowledge bases (KBs) to answer a question, after parsing and transforming natural language questions to KBs-executable forms (e.g., logical forms). As a well-known fact, KBs are far from complete, so that information required to answer questions may not always exist in KBs. In this paper, we develop a new QA system that mines answers directly from the Web, and meanwhile employs KBs as a significant auxiliary to further boost the QA performance. Specifically, to the best of our knowledge, we make the first attempt to link answer candidates to entities in Freebase, during answer candidate generation. Several remarkable advantages follow: (1) Redundancy among answer candidates is automatically reduced. (2) The types of an answer candidate can be effortlessly determined by those of its corresponding entity in Freebase. (3) Capitalizing on the rich information about entities in Freebase, we can develop semantic features for each answer candidate after linking them to Freebase. Particularly, we construct answer-type related features with two novel probabilistic models, which directly evaluate the appropriateness of an answer candidate's types under a given question. Overall, such semantic features turn out to play significant roles in determining the true answers from the large answer candidate pool. The experimental results show that across two testing datasets, our QA system achieves an 18%~54% improvement under F_1 metric, compared with various existing QA systems.", "references": ["K. Balog and R. Neumayer. Hierarchical target type identification for entity-oriented queries. In CIKM, pages 2391--2394. ACM, 2012.", "J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on Freebase from question-answer pairs. In EMNLP, pages 1533--1544, 2013.", "J. Berant and P. Liang. Semantic parsing via paraphrasing. In ACL, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741651"}, {"title": "Words and Pictures: Crowdsource Discovery beyond Image Semantics", "authors": ["Shih-Fu Chang"], "publication": "CrowdMM '15: Proceedings of the Fourth International Workshop on Crowdsourcing for Multimedia", "abstract": "ABSTRACT\nLarge annotated images from the Web and crowdsource, together with powerful machine learning tools, play a crucial role in rapid progress in semantic recognition of image data in recent years. However, as inferred in the saying \"A Picture is Worth More Than 1,000 Words,\" there is much richer information than just semantic labels associated with images from the Web resources and Crowdsource Fora. Such additional information covers the rich unexploited aspects, such as visual aesthetics, emotions, sentiments, user intention, and knowledge structure. Discovering such novel dimensions of image descriptions beyond semantics will have huge impact for exciting emerging applications such as personalized search and content recommendation. But it requires rigorous research in concept definition, task formulation, data crawling, and evaluation mechanisms. In this talk, I will address these issues by sharing our experiences [1-4] in discovering beyond-semantic visual descriptions related to visual sentiment, video upload intent classification, cultural influence on visual sentiment, and finally a wiki-style video event ontology.", "references": ["Borth, Damian, Rongrong Ji, Tao Chen, Thomas Breuel, and Shih-Fu Chang. \"Large-scale visual sentiment ontology and detectors using adjective noun pairs.\" In Proceedings of the 21st ACM international conference on Multimedia, pp. 223--232. ACM, 2013.", "Christoph Kofler, Subhabrata Bhattacharya, Martha Larson, Tao Chen, Alan Hanjalic, Shi-Fu Chang. Uploader Intent for Online Video: Typology, Inference and Applications. Multimedia, IEEE Transactions on, 17, 2015.", "Brendan Jou, Tao Chen, Nikolaos Pappas, Miriam Redi, Mercan Topkara, Shih-Fu Chang. Visual Affect Around the World: A Large-scale Multilingual Visual Sentiment Ontology. In Proceedings of the 23st ACM international conference on Multimedia, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810188.2810197"}, {"title": "Visual Coding in a Semantic Hierarchy", "authors": ["Yang Yang\n,", "Hanwang Zhang\n,", "Mingxing Zhang\n,", "Fumin Shen\n,", "Xuelong Li"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn recent years, tremendous research endeavours have been dedicated to seeking effective visual representations for facilitating various multimedia applications, such as visual annotation and retrieval. Nonetheless, existing approaches can hardly achieve satisfactory performance due to the scarcity of fully exploring semantic properties of visual codes. In this paper, we present a novel visual coding approach, termed as hierarchical semantic visual coding (HSVC), to effectively encode visual objects (e.g., image and video) in a semantic hierarchy. Specifically, we first construct a semantic-enriched dictionary hierarchy, which is comprised of dictionaries corresponding to all concepts in a semantic hierarchy as well as their hierarchical semantic correlation. Moreover, we devise an on-line semantic coding model, which simultaneously 1) exploits the rich hierarchical semantic prior knowledge in the learned dictionary, 2) reflects semantic sparse property of visual codes, and 3) explores semantic relationships among concepts in the semantic hierarchy. To this end, we propose to integrate concept-level group sparsity constraint and semantic correlation matrix into a unified regularization term. We design an effective algorithm to optimize the proposed model, and a rigorous mathematical analysis has been provided to guarantee that the algorithm converges to a global optima. Extensive experiments on various multimedia datasets have been conducted to illustrate the superiority of our proposed approach as compared to state-of-the-art methods.", "references": ["S. Bengio, F. Pereira, Y. Singer, and D. Strelow. Group sparse coding. In NIPS, pages 82--89, 2009.", "A. Bergamo, L. Torresani, and A. W. Fitzgibbon. Picodes: Learning a compact code for novel-category recognition. In NIPS, pages 2088--2096, 2011.", "A. Binder, K.-R. Müller, and M. Kawanabe. On taxonomies for multi-class image categorization. IJCV, 99(3):281--301, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806244"}, {"title": "Component segmentation of sketches used in 3D model retrieval", "authors": ["Yang Kang\n,", "Chi Xu\n,", "Shujin Lin\n,", "Songhua Xu\n,", "Xiaonan Luo\n,", "Qiang Chen"], "publication": "SIGGRAPH '15: ACM SIGGRAPH 2015 Posters", "abstract": "ABSTRACT\nSketching is a natural human practice. With the popularity of multi-touch tablets and styluses, sketching has become a more popular means of human-computer interaction. However, accurately recognizing sketches is rather challenging, especially when they are drawn by non-professionals. Therefore, automatic sketch understanding has attracted much research attention. To tackle the problem, we propose to segment sketch drawings before analyzing the semantic meanings of sketches for the purpose of developing a sketch-based 3D model retrieval system.", "references": ["Kalogerakis, E., Hertzmann, A., and Singh, K. 2010. Learning 3d mesh segmentation and labeling. In ACM Transactions on Graphics (TOG), vol. 29, ACM, 102."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2787626.2792655"}, {"title": "Disassortative Degree Mixing and Information Diffusion for Overlapping Community Detection in Social Networks (DMID)", "authors": ["Mohsen Shahriari\n,", "Sebastian Krott\n,", "Ralf Klamma"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper we propose a new two-phase algorithm for overlapping community detection (OCD) in social networks. In the first phase, called disassortative degree mixing, we identify nodes with high degrees through a random walk process on the row-normalized disassortative matrix representation of the network. In the second phase, we calculate how closely each node of the network is bound to the leaders via a cascading process called network coordination game. We implemented the algorithm and four additional ones as a Web service on a federated peer-to-peer infrastructure. Comparative test results for small and big real world networks demonstrated the correct identification of leaders, high precision and good time complexity. The Web service is available as open source software.", "references": ["Hamsterster full network dataset - konect, August, 2014.", "D. Chen, Y. Fu, and M. Shang. An efficient algorithm for overlapping community detection in complex networks. In Intelligent Systems, 2009. GCIS '09. WRI Global Congress on, volume 1, pages 244--247, May 2009.", "L. Danon, J. Duch, A. Diaz-Guilera, and A. Arenas. Comparing community structure identification. Journal of Statistical Mechanics: Theory and Experiment, P09008, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741696"}, {"title": "Events and Controversies: Influences of a Shocking News Event on Information Seeking", "authors": ["Danai Koutra\n,", "Paul N. Bennett\n,", "Eric Horvitz"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIt has been suggested that online search and retrieval contributes to the intellectual isolation of users within their preexisting ideologies, where people's prior views are strengthened and alternative viewpoints are infrequently encountered. This so-called \"filter bubble\" phenomenon has been called out as especially detrimental when it comes to dialog among people on controversial, emotionally charged topics, such as the labeling of genetically modified food, the right to bear arms, the death penalty, and online privacy. We seek to identify and study information-seeking behavior and access to alternative versus reinforcing viewpoints following shocking, emotional, and large-scale news events. We choose for a case study to analyze search and browsing on gun control/rights, a strongly polarizing topic for both citizens and leaders of the United States. We study the period of time preceding and following a mass shooting to understand how its occurrence, follow-on discussions, and debate may have been linked to changes in the patterns of searching and browsing. We employ information-theoretic measures to quantify the diversity of Web domains of interest to users and understand the browsing patterns of users. We use these measures to characterize the influence of news events on these web search and browsing patterns.", "references": ["Sandy Hook elementary school shooting. http://en.wikipedia.org/wiki/Sandy_Hook_ Elementary_School_shooting. Retrieved 6/10/14.", "Gun Ownership and Use in America. http://www.gallup.com/poll/20098/gun-ownership-use-america.aspx, 2005. Retrieved 7/10/14.", "Firefox vs. Internet Explorer. http://www.comscore.com/Insights/Blog/Firefox-vs.-Internet-Explorer,Firefox-vs-Internet-Explorer-Part-2, 2007. Retrieved 11/6/14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741099"}, {"title": "Analyzing and organizing the sonic space of vocal imitations", "authors": ["D. A. Mauro\n,", "D. Rocchesso"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThe sonic space that can be spanned with the voice is vast and complex and, therefore, it is difficult to organize and explore. In order to devise tools that facilitate sound design by vocal sketching we attempt at organizing a database of short excerpts of vocal imitations. By clustering the sound samples on a space whose dimensionality has been reduced to the two principal components, it is experimentally checked how meaningful the resulting clusters are for humans. Eventually, a representative of each cluster, chosen to be close to its centroid, may serve as a landmark in the exploration of the sound space, and vocal imitations may serve as proxies for synthetic sounds.", "references": ["K. Adiloglu, C. Drioli, P. Polotti, D. Rocchesso, S. Delle Monache, et al. Physics-based spike-guided tools for sound design. In Proceedings of Conference on Digital Audio Effects, 2010.", "M. Cartwright and B. Pardo. Vocalsketch: Vocally imitating audio concepts. In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), april 2015.", "M. Changizi. Harnessed: How Language and Music Mimicked Nature and Transformed Ape to Man. Perseus Books Group, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814921"}, {"title": "Twin Feature and Similarity Maximal Matching for Image Retrieval", "authors": ["Lei Wang\n,", "Hanli Wang\n,", "Fengkuangtian Zhu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn recent years, most advanced image retrieval algorithms are built upon local features, and various up-to-date match kernels are developed to boost image retrieval performances. However, most of these image retrieval algorithms need to face up two challenging issues: (1) the locality property of local features as well as quantization noise and (2) the phenomenon of burstiness, which significantly affect image retrieval performances. In this paper, two novel techniques including Twin Feature (TF) and Similarity Maximal Matching (SMM) are proposed for image retrieval performance improvement, which can be employed with non-aggregated kernel models, for example, the Selective Match Kernel (SMK). The proposed TF employs extra information from neighboring image patches to refine visual matching. As far as SMM is concerned, it tries to control burstiness by dynamically searching the match-pair combinations to maximize the global similarity score and thus removes multiple matches. Experimental results on two benchmark image datasets including Oxford5k and Paris6k demonstrate that the new techniques SMKtf (SMK with TF) and SMKsmm (SMK with SMM) can greatly enhance image retrieval accuracy performances as compared to SMK, and their combination, i.e., SMKtf+smm, is able to achieve better image retrieval accuracies than a number of state-of-the-art approaches.", "references": ["R. Arandjelovic and A. Zisserman. All about VLAD. In Proc. CVPR'13, pages 1578--1585, Jun. 2013.", "Y. Avrithis. Quantize and conquer: A dimensionality-recursive solution to clustering, vector quantization, and image retrieval. In Proc. ICCV'13, pages 3024--3031, Dec. 2013.", "Y. Avrithis and G. Tolias. Hough pyramid matching: Speeded-up geometry re-ranking for large scale image retrieval. IJCV, 107(1):1--19, Oct. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749345"}, {"title": "Multi-Level Fusion for Person Re-identification with Incomplete Marks", "authors": ["Zheng Wang\n,", "Ruimin Hu\n,", "Yi Yu\n,", "Chao Liang\n,", "Wenxin Huang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nMost video surveillance suspect investigation systems rely on the videos taken in different camera views. Actually, besides the videos, in the investigation process, investigators also manually label some marks, which, albeit incomplete, can be quite accurate and helpful in identifying persons. This paper studies the problem of Person Re-identification with Incomplete Marks (PRIM), aiming at ranking the persons in the gallery according to both the videos and incomplete marks. This problem is solved by a multi-step fusion algorithm, which consists of three key steps: (i) The early fusing step exploits both visual features and marked attributes to predict a complete and precise attribute vector. (ii) Based on the statistical attribute d ominance and saliency phenomena, a dominance-saliency matching model is suggested for measuring the distance between attribute vectors. (iii) The gallery is ranked separately by using visual features and attribute vectors, and the overall ranking list is the result of a late fusion. Experiments conducted on VIPeR dataset have validated the effectiveness of the proposed method in all the three key steps. The results also show that through introducing marks, the retrieval accuracy is significantly improved.", "references": ["Y. Deng, P. Luo, C. C. Loy, and X. Tang. Pedestrian attribute recognition at far distance. ACM MM, 2014.", "M. Farenzena, L. Bazzani, A. Perina, V. Murino, and M. Cristani. Person re-identification by symmetry-driven accumulation of local features. CVPR, 2010.", "R. Feris, R. Bobbitt, L. Brown, and S. Pankanti. Attribute based people search: Lessons learnt from a practical surveillance system. ICMR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806400"}, {"title": "ArgumentBind - A Model for Implementing Argument Web Integrated Applications with Open and Linked Data", "authors": ["Roberto Niche\n,", "Sandro J. Rigo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nOnline communication and collaboration tools are widely employed by users in order to express their opinions on a vast amount of subjects. These tools were not designed to accurately identify topics, nor to point out relationships between topic elements related to a given discussion. As it turns out, there is a staggering amount of user-contributed information generally available, and conversely, a huge challenge related to accurately pointing out featured topics and their intertwining relationships and sources. The main purpose of Argument Web is to define a rich, full-featured annotation model capable of storing relationships between topics and their sources. Given the availability of rich, interlinked data about a number of related subjects, Argument Web can potentially increase the quality of online discussions and the analysis of its components. However, there is still a reduced number of real-world applications based on these concepts. Even in well-known projects, there's still a lack of exploration efforts related to the use of open and linked data. This paper presents an application model based on Argument Interchange Format (AIF) and state-of-the-art semantic Web technology. Its main contribution lies in the integration of external source information, linked data formats and data visualization aspects. The solution is then evaluated through a case-study related to the use of open and linked data on the field of public administration.", "references": ["Atkinson, K.; Bench-Capon, T.; Mcburney, Parmenides P.: Facilitating deliberation in democracies. Artificial Intelligence and Law, 2006. retirado do artigo Laying the foundations for a World Wide Argument Web.", "Facebook, 11 Setembro 2014. Disponivel em: ¿http://www.facebookstories.com/2013/pt-br¿. Acesso em: 11 Setembro 2014.", "Chesñevar, C. et al. Towards an Argument Interchange Format. The Knowledge Engineering Review, Vol. 00:0, p. 1-25, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814158"}, {"title": "Runtime metric meets developer: building better cloud applications using feedback", "authors": ["Jürgen Cito\n,", "Philipp Leitner\n,", "Harald C. Gall\n,", "Aryan Dadashi\n,", "Anne Keller\n,", "Andreas Roth"], "publication": "Onward! 2015: 2015 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward!)", "abstract": "ABSTRACT\nA unifying theme of many ongoing trends in software engineering is a blurring of the boundaries between building and operating software products. In this paper, we explore what we consider to be the logical next step in this succession: integrating runtime monitoring data from production deployments of the software into the tools developers utilize in their daily workflows (i.e., IDEs) to enable tighter feedback loops. We refer to this notion as feedback-driven development (FDD). This more abstract FDD concept can be instantiated in various ways, ranging from IDE plugins that implement feedback-driven refactoring and code optimization to plugins that predict performance and cost implications of code changes prior to even deploying the new version of the soft- ware. We demonstrate existing proof-of-concept realizations of these ideas and illustrate our vision of the future of FDD and cloud-based software development in general. Further, we discuss the major challenges that need to be solved be- fore FDD can achieve mainstream adoption.", "references": ["N. Ayewah, D. Hovemeyer, J. Morgenthaler, J. Penix, and W. Pugh. Using Static Analysis to Find Bugs. IEEE Software, 25(5), Sept 2008.", "A. Barker, B. Varghese, J. S. Ward, and I. Sommerville. Academic Cloud Computing Research: Five Pitfalls and Five Opportunities. In Proceedings of the 6th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 14), Philadelphia, PA, June 2014. USENIX Association.", "C.-P. Bezemer and A. Zaidman. Multi-tenant SaaS Applications: Maintenance Dream or Nightmare? In Proceedings of the Joint ERCIM Workshop on Software Evolution (EVOL) and International Workshop on Principles of Software Evolution (IWPSE), IWPSE-EVOL ’10, pages 88–92, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814228.2814232"}, {"title": "Recommendation using analysis of semantic social network in social network services", "authors": ["Sangun Park\n,", "Juyoung Kang"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nAs Social Network Services became one of the most successful Web based businesses, recommendation using the social network also became actively utilized to attract and retain customers. One of the current research trends of the recommendation is using the various relationships between customers in order to increase the possibility of enhanced recommendation. This paper suggests a semantic social network that represents the various relationships among customers and products through semantic graph, and a method that generates recommendation rules through semantic social network mining over the semantic graph..", "references": ["Berners-Lee, T., Hendler, J., and Lassila, O., 2001. The semantic web. Scientific american 284, 5, 28--37.", "Bobadilla, J., Ortega, F., Hernando, A., and Gutiérrez, A., 2013. Recommender systems survey. Knowledge-Based Systems 46, 0, 109--132.", "Cantador, I. and Castells, P., 2006. Multilayered semantic social network modeling by ontology-based user profiles clustering: Application to collaborative filtering. In Managing Knowledge in a World of Networks Springer, 334--349."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781603"}, {"title": "Overlap Between Google and Bing Web Search Results!: Twitter to the Rescue?", "authors": ["Rakesh Agrawal\n,", "Behzad Golshan\n,", "Evangelos Papalexakis"], "publication": "COSN '15: Proceedings of the 2015 ACM on Conference on Online Social Networks", "abstract": "ABSTRACT\nAccess to diverse perspectives nurtures an informed citizenry. Google and Bing have emerged as the duopoly that largely arbitrates which English language documents are seen by web searchers. We present our empirical study over the search results produced by Google and Bing that shows a large overlap. Thus, citizens may not gain different perspectives by simultaneously probing them for the same query. Fortunately, our study also shows that by mining Twitter data one can obtain search results that are quite distinct from those produced by Google and Bing. Additionally, the users found those results to be quite informative.", "references": ["R. Agrawal, B. Golshan, and E. Papalexakis. A study of distinctiveness in web results of two search engines. In 24th international conference on World Wide Web, Web Science Track. ACM, May 2015.", "R. Agrawal, B. Golshan, and E. Papalexakis. Whither social networks for web search? In 21st ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Sydney, Australia, August 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2817946.2820604"}, {"title": "New Research Directions in Knowledge Discovery and Allied Spheres", "authors": ["Anisoara Nica\n,", "Fabian M. Suchanek\n,", "Aparna S. Varde"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nThe realm of knowledge discovery extends across several allied spheres today. It encompasses database management areas such as data warehousing and schema versioning; information retrieval areas such as Web semantics and topic detection; and core data mining areas, e.g., knowledge based systems, uncertainty management, and time-series mining. This becomes particularly evident in the topics that Ph.D. students choose for their dissertation. As the grass roots of research, Ph.D. dissertations point out new avenues of research, and provide fresh viewpoints on combinations of known fields. In this article we overview some recently proposed developments in the domain of knowledge discovery and its related spheres. Our article is based on the topics presented at the doctoral workshop of the ACM Conference on Information and Knowledge Management, CIKM 2011.", "references": ["L. Abele, M. Kleinsteuber, and H. Thorbjoern. Resource monitoring in industrial production with knowledge-based models and rules. PIKM 2011, pp. 35--43.", "M. L. Ba, T. Abdessalem, and P. Senellart. Towards a version control model with uncertain data. PIKM 2011, pp. 43--50.", "D. Ganguly, J. Leveling, and G. J. Jones. Utilizing sub-topical structure of documents for information retrieval. PIKM 2011, pp. 75--78."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783702.2783708"}, {"title": "A Head-Weighted Gap-Sensitive Correlation Coefficient", "authors": ["Ning Gao\n,", "Douglas Oard"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nInformation retrieval systems rank documents, and shared-task evaluations yield results that can be used to rank information retrieval systems. Comparing rankings in ways that can yield useful insights is thus an important capability. When making such comparisons, it is often useful to give greater weight to comparisons near the head of a ranked list than to what happens further down. This is the focus of the widely used τAP measure. When scores are available, gap-sensitive measures give greater weight to larger differences than to smaller ones. This is the focus of the widely used Pearson correlation measure (ρ). This paper introduces a new measure, τGAP, which combines both features. System comparisons from the TREC 5 Ad Hoc track are used to illustrate the differences in emphasis achieved by τAP, ρ, and the proposed τGAP.", "references": ["C. Buckley and E. M. Voorhees. Evaluating evaluation measure stability. In SIGIR, pages 33--40, 2000.", "N. Gao et al. Reducing reliance on relevance judgments for system comparison by using expectation-maximization. In ECIR, pages 1--12. 2014.", "K. S. Jones. Automatic indexing. Journal of Documentation, 30(4):393--432, 1974."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767793"}, {"title": "MusicMixer: computer-aided DJ system based on an automatic song mixing", "authors": ["Tatsunori Hirai\n,", "Hironori Doi\n,", "Shigeo Morishima"], "publication": "ACE '15: Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology", "abstract": "ABSTRACT\nIn this paper, we present MusicMixer, a computer-aided DJ system that helps DJs, specifically with song mixing. MusicMixer continuously mixes and plays songs using an automatic music mixing method that employs audio similarity calculations. By calculating similarities between song sections that can be naturally mixed, MusicMixer enables seamless song transitions. Though song mixing is the most fundamental and important factor in DJ performance, it is difficult for untrained people to seamlessly connect songs. MusicMixer realizes automatic song mixing using an audio signal processing approach; therefore, users can perform DJ mixing simply by selecting a song from a list of songs suggested by the system, enabling effective DJ song mixing and lowering entry barriers for the inexperienced. We also propose personalization for song suggestions using a preference memorization function of MusicMixer.", "references": ["Jean-Julien Aucouturier and Francois Pachet. 2002. Scaling up Music Playlist Generation. In Proceedings of the IEEE International Conference on Multimedia and Expo 2002, Vol. 1. 105--108 vol. 1.", "David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. The Journal of Machine Learning Research 3 (2003), 993--1022.", "Dave Cliff. 2000. Hang the DJ: Automatic Sequencing and Seamless Mixing of Dance-Music Tracks. HP LABORATORIES TECHNICAL REPORT HPL 104 (2000)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832932.2832942"}, {"title": "Nuke 'Em Till They Go: Investigating Power User Attacks to Disparage Items in Collaborative Recommenders", "authors": ["Carlos E. Seminario\n,", "David C. Wilson"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender Systems (RSs) can be vulnerable to manipulation by malicious users who successfully bias recommendations for their own benefit or pleasure. These are known as attacks on RSs and are typically used to either promote (\"push\") or disparage (\"nuke\") targeted items contained within the recommender's user-item dataset. Our recent work with the Power User Attack (PUA) model, determined that attackers disguised as influential power users can mount successful (from the attacker's viewpoint) push attacks against user-based, item-based, and SVD-based recommenders. However, the success of push attack vectors may not be symmetric for nuke attacks, which target the opposite effect --- reducing the likelihood that target items appear in users' top-N lists. The asymmetry between push and nuke attacks is highlighted when evaluating these attacks using traditional robustness metrics such as Rank and Prediction Shift. This paper examines the PUA attack model in the context of nuke attacks, in order to investigate the differences between push and nuke attack orientations, as well as how they are evaluated. In this work we show that the PUA is able to mount successful nuke attacks against commonly-used recommender algorithms highlighting the \"nuke vs. push\" asymmetry in the results.", "references": ["R. Burke, M. P. O'Mahony, and N. J. Hurley. Robust collaborative recommendation. In F. Ricci et al., editors, Recommender Systems Handbook. Springer, 2011.", "C. Desrosiers and G. Karypis. A comprehensive survey of neighborhood-based recommendations methods. In F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors, Recommender Systems Handbook. Springer, 2011.", "J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In Proc of the ACM SIGIR Conf, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799666"}, {"title": "An Introduction to Entity Recommendation and Understanding", "authors": ["Hao Ma\n,", "Yan Ke"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nEntities and the Knowledge about the entities have become indispensable building blocks in modern search engines. This tutorial aims to present the current state of research in the emerging semantic search and recommendation field by studying how to help users effectively explore the knowledge base as well as answer their information needs. Many live applications and systems will be demonstrated throughout this tutorial. After the completion of the tutorial, the audience will have an introduction and overview of what is the emerging topics of entity recommendation and understanding. The audience will learn and be able to understand some current research work as well as industry practices using computational intelligence techniques in entity recommendation and understanding. One of the major goals of this tutorial is to help audience identify a few research directions that could have big impact in the near future.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741991"}, {"title": "Data licensing on the cloud: empirical insights and implications for linked data", "authors": ["Ivan Ermilov\n,", "Tassilo Pellegrini"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nThis paper investigates necessities and pitfalls in existing data licensing practices on the World Wide Web. The authors analyzed four open data portals with respect to the available licenses and drew conclusions about the quantity and quality of available licensing information. Additionally the authors address reasoning issues with respect to the automatic detection and potential clearance of licensing conflicts when creating derivative works from multiple data sources. The issues raised in this paper should be taken into account when designing and implementing a Linked Data licensing policy.", "references": ["ODRL Community Group. https://www.w3.org/community/odrl/. Accessed: 2015-05-29.", "H. Abelson, B. Adida, M. Linksvayer, and N. Yergler. ccREL: The Creative Commons Rights Expression Language. W3C Member Submission, 2008.", "P. Archer et al. Study on business models for Linked Open Government Data. ISA programme by PwC EU Services. European Union, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814878"}, {"title": "Understanding the Impact of the Role Factor in Collaborative Information Retrieval", "authors": ["Lynda Tamine\n,", "Laure Soulier"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nCollaborative information retrieval systems often rely on division of labor policies. Such policies allow work to be divided among collaborators with the aim of preventing redundancy and optimizing the synergic effects of collaboration. Most of the underlying methods achieve these goals by the means of explicit vs. implicit role-based mediation. In this paper, we investigate whether and how different factors, such as users' behavior, search strategies, and effectiveness, are related to role assignment within a collaborative exploratory search. Our main findings suggest that: (1) spontaneous and cohesive implicit roles might emerge during the collaborative search session implying users with no prior roles, and that these implicit roles favor the search precision, (2) role drift might occur alongside the search session performed by users with prior-assigned roles.", "references": ["E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In ACM SIGIR, pages 3--10, 2006.", "B. Amidan, T. Ferryman, and S. Cooley. Data outlier detection using the chebyshev theorem. In Aerospace Conference, 2005 IEEE, pages 3814--3819, 2005.", "A. Aula, P. Majaranta, and K.-J. Räihä. Eye-tracking reveals the personal styles for search result evaluation. In INTERACT, pages 1058--1061, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806481"}, {"title": "ConfSeer: leveraging customer support knowledge bases for automated misconfiguration detection", "authors": ["Rahul Potharaju\n,", "Joseph Chan\n,", "Luhui Hu\n,", "Cristina Nita-Rotaru\n,", "Mingshi Wang\n,", "Liyuan Zhang\n,", "Navendu Jain"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe introduce ConfSeer, an automated system that detects potential configuration issues or deviations from identified best practices by leveraging a knowledge base (KB) of technical solutions. The intuition is that these KB articles describe the configuration problems and their fixes so if the system can accurately understand them, it can automatically pinpoint both the errors and their resolution. Unfortunately, finding an accurate match is difficult because (a) the KB articles are written in natural language text, and (b) configuration files typically contain a large number of parameters with a high value range. Thus, expert-driven manual troubleshooting is not scalable.\nWhile there are several state-of-the-art techniques proposed for individual tasks such as keyword matching, concept determination and entity resolution, none offer a practical end-to-end solution to detect problems in machine configurations. In this paper, we describe our experiences building ConfSeer using a novel combinations of ideas from natural language processing, information retrieval and interactive learning. ConfSeer powers the recommendation engine behind Microsoft Operations Management Suite that proposes fixes for software configuration errors. The system has been running in production for about a year to proactively find misconfigurations on tens of thousands of servers. Our evaluation of ConfSeer against an expert-defined rule-based commercial system, an expert survey and web search engines shows that it achieves 80%-97.5% accuracy and incurs low runtime overheads.", "references": ["Apple Knowledge Base. http://kbase.info.apple.com/.", "Desk.com. http://desk.com.", "EMC Powerlink. http://powerlink.emc.com."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824079"}, {"title": "Memory Vectors for Particular Object Retrieval with Multiple Queries", "authors": ["Ronan Sicre\n,", "Hervé Jégou"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWe address the problem of retrieving all the images containing a specific object in a large image collection, where the input query is given as a set of representative images of the object. This problem is referred to as multiple queries in the literature. For images described with bag-of-visual-words (BOW), one of the best performing approach amounts to simply averaging the query descriptors.\nThis paper1 introduces an improved fusion of the object description based on the recent concept of generalized max-pooling and memory vectors, which summarizes a set of vectors by a single representative vector. They have the property of reducing the influence of frequent features. Therefore, we propose to build a memory vector for each set of queries and the membership test is performed with each image descriptor from the database, to determine its similarity with the query representative. This new strategy for multiple queries brings a significant improvement for most of the image descriptors we have considered, in particular with Convolutional Neural Networks (CNN) features.", "references": ["R. Arandjelovic and A. Zisserman. Multiple queries for large scale specific object retrieval. In BMVC, 2012.", "R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, June 2012.", "A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. ECCV, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749306"}, {"title": "Online Learning to Rank: Absolute vs. Relative", "authors": ["Yiwei Chen\n,", "Katja Hofmann"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline learning to rank holds great promise for learning personalized search result rankings. First algorithms have been proposed, namely absolute feedback approaches, based on contextual bandits learning; and relative feedback approaches, based on gradient methods and inferred preferences between complete result rankings. Both types of approaches have shown promise, but they have not previously been compared to each other. It is therefore unclear which type of approach is the most suitable for which online learning to rank problems. In this work we present the first empirical comparison of absolute and relative online learning to rank approaches.", "references": ["K. Hofmann, A. Schuth, S. Whiteson, and M. de Rijke. Reusing historical interaction data for faster online learning to rank for IR. In WSDM '13, pages 549--558, 2013.", "T. Joachims. Evaluating retrieval performance using clickthrough data. Text Mining, pages 79--96, 2003.", "J. Langford and T. Zhang. The epoch-greedy algorithm for multi-armed bandits with side information. In Advances in neural information processing systems, pages 817--824, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742718"}, {"title": "Microblogging Queries on Graph Databases: An Introspection", "authors": ["Oshini Goonetilleke\n,", "Saket Sathe\n,", "Timos Sellis\n,", "Xiuzhen Zhang"], "publication": "GRADES'15: Proceedings of the GRADES'15", "abstract": "ABSTRACT\nMicroblogging data is growing at a rapid pace. This poses new challenges to the data management systems, such as graph databases, that are typically suitable for analyzing such data. In this paper, we share our experience on executing a wide variety of micro-blogging queries on two popular graph databases: Neo4j and Sparksee. Our queries are designed to be relevant to popular applications of micro-blogging data. The queries are executed on a large real graph data set comprising of nearly 50 million nodes and 326 million edges.", "references": ["R. Angles, A. Prat-Pérez, et al. Benchmarking database systems for social network applications. In GRADES Workshop, pages 1--7, 2013.", "O. Goonetilleke, T. Sellis, et al. Twitter analytics: A big data management perspective. SIGKDD Explorations, 16(1):11--20, 2014.", "S. Jouili and V. Vansteenberghe. An empirical comparison of graph databases. In SocialCom, pages 708--715. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2764947.2764952"}, {"title": "Bridging the Ultimate Semantic Gap: A Semantic Search Engine for Internet Videos", "authors": ["Lu Jiang\n,", "Shoou-I Yu\n,", "Deyu Meng\n,", "Teruko Mitamura\n,", "Alexander G. Hauptmann"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nSemantic search in video is a novel and challenging problem in information and multimedia retrieval. Existing solutions are mainly limited to text matching, in which the query words are matched against the textual metadata generated by users. This paper presents a state-of-the-art system for event search without any textual metadata or example videos. The system relies on substantial video content understanding and allows for semantic search over a large collection of videos. The novelty and practicality is demonstrated by the evaluation in NIST TRECVID 2014, where the proposed system achieves the best performance. We share our observations and lessons in building such a state-of-the-art system, which may be instrumental in guiding the design of the future system for semantic search in video.", "references": ["S. Banerjee and T. Pedersen. An adapted lesk algorithm for word sense disambiguation using wordnet. In CICLing, 2002.", "Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, 2009.", "S. Bhattacharya, F. X. Yu, and S.-F. Chang. Minimally needed evidence for complex event recognition in unconstrained videos. In ICMR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749399"}, {"title": "EMPIRE 2015: Workshop on Emotions and Personality in Personalized Systems", "authors": ["Marco Tkalčič\n,", "Berardina De Carolis\n,", "Marco de Gemmis\n,", "Ante Odić\n,", "Andrej Košir"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe EMPIRE workshop focuses on recommender systems (and other personalized systems) that take advantage of user-centric properties, such as emotions and personality. The workshop is organized as a focused mini-conference with technical and position papers. The goal is to gather the scattered work under a common umbrella and take advantage of the discussion time to draw future research opportunities.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798716"}, {"title": "Domain specific information retrieval and text mining in medical document", "authors": ["Sanghoon Lee\n,", "Yanjun Zhao\n,", "Mohamed Eid Mahmoud Masoud\n,", "Maria Valero\n,", "Semra Kul\n,", "Saeid Belkasim"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nThis paper introduces a domain specific knowledge discovery technique that is applicable for both information retrieval and text mining, identifying word meanings characterized by domains. The meaning of words is identified by using a domain fusion algorithm that not only narrows domain concepts from different domain knowledge but also avoids the unknown domain problem so that specific domains can be found in a series of words. Domain knowledge is presented for the purpose of experiments on medical documents. Experiments performed over two different fields: query expansion in information retrieval and text classification in text mining, demonstrate the effectiveness of the proposed methodology.", "references": ["E. Agirre, O. L. de Lacalle, and A. Soroa. Random walks for knowledge-based word sense disambiguation. Computational Linguistics, 40(1):57--84, 2014.", "L. D. Baker and A. K. McCallum. Distributional clustering of words for text classification. In the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pages 96--103. ACM, 1998.", "L. Bentivogli, P. Forner, B. Magnini, and E. Pianta. Revising the wordnet domains hierarchy: semantics, coverage and balancing. In the Workshop on Multilingual Linguistic Ressources, pages 101--108. Association for Computational Linguistics, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2808726"}, {"title": "Citizen centered e-government?: the case of National Migration Institute in the Southern Mexican border", "authors": ["Luz Maria Garcia-Garcia\n,", "J. Ramon Gil-Garcia\n,", "Victor Gómez"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nThe purpose of this poster is to present the current state of this study. The objective is to know whether the Mexican National Migration Institute web portal provides the results users expect; in particular to obtain the entry permission to foreign workers, and if the process is easier, cheaper, and faster now with the implementation of information technologies than it was before. This is particularly interesting, since the main users of these processes are not citizens, but national from Central American countries. The question that leads this research project is the following, which are the organizational and institutional variables that have influenced the technological characteristics of INM's web portal and how those characteristics produced benefits and respond to the user's expectations? Are the influences similar to the ones present in citizen-oriented applications and systems? To reach this goal a mixed methodology is applied with three different techniques: interviews of coffee growers and Guatemalan workers, an assessment of the technical features of the web portal and an analysis of the official documents of National Migration Institute.", "references": ["R. S. Almazán and J. R. G. García. Construyendo un índice de funcionalidad para el gobierno electrónico: una primera evaluación de los portales estatales en méxico. Espacios Públicos, 11(21):8--18, 2008.", "J. Bertot and P. Jeager. User-centered e-government: Challenges and benefits for government web sites, government. Information Quartely, (23):163--168, 2006.", "R. Bouzas-Lorenzo and X. M. M. Lago. El estudio de la funcionalidad de los portales gubernamentales. Comité Editorial, page 259, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757457"}, {"title": "\"I like to explore sometimes\": Adapting to Dynamic User Novelty Preferences", "authors": ["Komal Kapoor\n,", "Vikas Kumar\n,", "Loren Terveen\n,", "Joseph A. Konstan\n,", "Paul Schrater"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nStudies have shown that the recommendation of unseen, novel or serendipitous items is crucial for a satisfying and engaging user experience. As a result, recent developments in recommendation research have increasingly focused towards introducing novelty in user recommendation lists. While, existing solutions aim to find the right balance between the similarity and novelty of the recommended items, they largely ignore the user needs for novelty. In this paper, we show that there are large individual and temporal differences in the users' novelty preferences. We develop a regression model to predict these dynamic novelty preferences of users using features derived from their past interactions. Finally, we describe an adaptive recommender,~\\emph{adaNov-R}, that adapts to the user needs for novel items and show that the model achieves better recommendation performance on a metric that considers both novel and familiar items.", "references": ["G. Adomavicius and Y. Kwon. Toward more diverse recommendations: Item re-ranking methods for recommender systems. In Workshop on Information Technologies and Systems, 2009.", "G. Adomavicius and Y. Kwon. Maximizing aggregate recommendation diversity: A graph-theoretic approach. In Proc. of the 1st International Workshop on Novelty and Diversity in Recommender Systems (DiveRS 2011), pages 3--10. Citeseer, 2011.", "A. Anderson, R. Kumar, A. Tomkins, and S. Vassilvitskii. The dynamics of repeat consumption. In Proceedings of the 23rd international conference on World wide web, pages 419--430. International World Wide Web Conferences Steering Committee, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800172"}, {"title": "Fine-grained population estimation", "authors": ["Hannah Bast\n,", "Sabine Storandt\n,", "Simon Weidner"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nWe show how to estimate population numbers for arbitrary user-defined regions, down to the level of individual buildings. This is important for various applications like evacuation planning, facility placement, or traffic estimation. However, census data with precise population numbers is typically only available at the level of cities, villages, or districts, if at all.\nPrevious approaches either rely on available census data for already small areas or on sophisticated input data like high resolution aerial images. Our framework uses only freely available data, in particular, OpenStreetMap data. In the OpenStreetMap project, crowd-sourced data is collected about street networks, buildings, places of interest as well as all kind of regions and natural structures world-wide. We use this data to learn three classifiers that are relevant for the population distribution inside an area: residential vs. industrial vs. commercial landuse, inhabited vs. uninhabited buildings, and single-family vs. multi-family houses. Once learned, we can use these classifiers for population estimation even in areas without any census data at all.\nOur experiments show good average accuracy (measured as the deviation from actual census data) for rural areas (25%), metropolitan areas (10%), and cities in countries other than that containing the training data (12%).", "references": ["Mohamed Bakillah, Steve Liang, Amin Mobasheri, Jamal Jokar Arsanjani, and Alexander Zipf. Fine-resolution population mapping using openstreetmap points-of-interest. International Journal of Geographical Information Science, 28(9):1940--1963, 2014.", "Hannah Bast, Jonas Sternisko, and Sabine Storandt. Forestmaps: A computational model and visualization for forest utilization. In Web and Wireless Geographical Information Systems, pages 115--133. Springer, 2014.", "Norbert Beckmann, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. The r*-tree: an efficient and robust access method for points and rectangles. In SIGMOD, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820828"}, {"title": "Heterogeneous Data Mining for Planning Active Surveillance of Malaria", "authors": ["Xiao Gu\n,", "Hechang Chen\n,", "Bo Yang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nMalaria is one of the most serious diseases in the world, which is densely distributed in poverty and remote areas. In the prevention and control of malaria, active surveillance is more efficient than passive surveillance to discover the incidences timely and accurately. However, it is always faced with the challenge of how to allocate the limited sources, such as medical staff and medicine, appropriately so as to achieve a maximum infect. In this paper, we propose a novel method to characterize the spatiotemporal patterns of infection risk for active surveillance planning. Specifically, we propose a temporal heterogeneous diffusion network model to discover high risk areas timely, and a mixture optimization method to find high risk areas accurately. The validation on existing real-world data shows that our method outperforms the existing state-of-the-art both in terms of infection risk prediction and planning of active surveillance under different thresholds.", "references": ["WHO. 2014. World malaria report 2014. available at: www.who.int/malaria/world malaria report 2014.", "Xia Z G, Yang M N, Zhou S S. Malaria Situation in the Peopleaŕs Republic of China in 2011. Chinese Journal of Parasitology and Parasitic Diseases. 2012, 30(6): 419--422.", "Kulldorff M. A spatial scan statistic. Communications in Statistics-Theory and methods, 1997, 26(6): 1481--1496."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818911"}, {"title": "L2Knng: Fast Exact K-Nearest Neighbor Graph Construction with L2-Norm Pruning", "authors": ["David C. Anastasiu\n,", "George Karypis"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe k-nearest neighbor graph is often used as a building block in information retrieval, clustering, online advertising, and recommender systems algorithms. The complexity of constructing the exact k-nearest neighbor graph is quadratic on the number of objects that are compared, and most existing methods solve the problem approximately. We present L2Knng, an efficient algorithm that finds the exact cosine similarity k-nearest neighbor graph for a set of sparse high-dimensional objects. Our algorithm quickly builds an approximate solution to the problem, identifying many of the most similar neighbors, and then uses theoretic bounds on the similarity of two vectors, based on the L2-norm of part of the vectors, to find each object's exact k-neighborhood. We perform an extensive evaluation of our algorithm, comparing against both exact and approximate baselines, and demonstrate the efficiency of our method across a variety of real-world datasets and neighborhood sizes. Our approximate and exact L2Knng variants compute the k-nearest neighbor graph up to an order of magnitude faster than their respective baselines.", "references": ["David C. Anastasiu and George Karypis. L2ap: Fast cosine similarity search with prefix l-2 norm bounds. In 30th IEEE International Conference on Data Engineering, ICDE '14, 2014.", "Alexandr Andoni and Piotr Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, January 2008.", "Amit Awekar and Nagiza F. Samatova. Fast matching for all pairs similarity search. In Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology - Volume 01, WI-IAT '09, pages 295--300, Washington, DC, USA, 2009. IEEE Computer Society."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806534"}, {"title": "Enhancing user search experience in digital libraries with rotated latent semantic indexing", "authors": ["Serhiy Polyakov"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nThis study investigates a semi-automatic method for creation of topical labels representing the topical concepts in information objects. The method is called rotated latent semantic indexing (rLSI). rLSI has found application in text mining but has not been used for topical labels generation in digital libraries (DLs). The present study proposes a theoretical model and an evaluation framework which are based on the LSA theory of meaning and investigates rLSI in a DL environment. The proposed evaluation framework for rLSI topical labels is focused on human-information search behavior and satisfaction measures. The experimental systems that utilize those topical labels were built for the purposes of evaluating user satisfaction with the search process. A new instrument was developed for this study and the experiment showed high reliability of the measurement scales and confirmed the construct validity. Data was collected through the information search tasks performed by 122 participants using two experimental systems. A quantitative method of analysis, partial least squares structural equation modeling (PLS-SEM), was used to test a set of research hypotheses and to answer research questions. The results showed a not significant, indirect effect of topical label type on both guidance and satisfaction. The conclusion of the study is that topical labels generated using rLSI provide the same levels of alignment, guidance, and satisfaction with the search process as topical labels created by the professional indexers using best practices.", "references": ["Anderson, J. D., & Pérez-Carballo, J. (2001). The nature of indexing: How humans and machines analyze messages and texts for retrieval. Part II: Machine indexing, and the allocation of human versus machine effort. Information Processing & Management, 37(2), 255--277. doi:10.1016/s0306-4573(00)00046-7", "Chen, Y.-N., & Ke, H.-R. (2014). A study on mental models of taggers and experts for article indexing based on analysis of keyword usage. Journal of the Association for Information Science and Technology, 65(8), 1675--1694. doi:10.1002/asi.23077", "Evangelopoulos, N. E., Zhang, X., & Prybutok, V. R. (2012). Latent semantic analysis: Five methodological recommendations. European Journal of Information Systems, 21(1), 70--86. doi:10.1057/ejis.2010.61"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857215"}, {"title": "Dynamic simulation of software workers and task completion", "authors": ["Razieh Lotfalian Saremi\n,", "Ye Yang"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nAs more and more companies are trying to leverage crowdsourcing to reduce cost and time-to-market of software production, it is very important to better understand the dynamics of crowdsourced software development in order to fully realize its benefits and avoid hidden pitfalls. This paper presents a systems dynamic model for crowdsourced software development platforms based on data gathered from Topcoder. The model is composed of three components: the worker submodel, the task submodel, and the interactions between the two submodels. Results of simulations are compared with empirical data gathered from Topcoder for validation. The major simulation results indicate that task uploading and software workers arrival in the platform follow typical exponential patterns; incentivizing the crowd developers to become more active will lead to more tasks completion and success; and tasks associated with higher awards generally receive few submissions.", "references": ["Klaas-Jan Stol, Brian Fitzgerald, Two's Company, Three's a Crowd: A Case Study of Crowdsourcing Software Development (2014).", "He Zhang, Barbara Kitchenham, D. Ross Jeffery: Toward trustworthy software process models: an exploratory study on transformable process modeling. Journal of Software: Evolution and Process 24(7): 741-763 (2012)", "He Zhang, D. Ross Jeffery, Dan Houston, LiGuo Huang, Liming Zhu: Impact of process simulation on software practice: an initial report. ICSE 2011: 1046-1056(2011)"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820120"}, {"title": "Augmenting Social Multimedia Semantic Interaction through Audio-Enhanced Web-TV Services", "authors": ["Nikolaos Tsipas\n,", "Panagiotis Zapartas\n,", "Lazaros Vrysis\n,", "Charalampos Dimoulas"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nMultimedia semantic analysis is a key element in managing the exponentially growing amount of produced multimedia content, available on the web and the social media. Towards this direction, a semantically enhanced Web-TV environment providing video-on-demand and simulcast streaming services, is proposed. The system offers content management and analysis automation capabilities by exploiting information derived from the semantic analysis of the user uploaded content and the social interaction of its users through the processes of annotation and tagging. A fusion based approach is employed for the categorization of content, enabling users to combine heterogeneous semantic information, thus enhancing content exploration with rich media experience. The paper focuses on the analysis of the system's architecture, the applied methodologies for incorporating user generated classification schemes and annotations, and the evaluation of machine learning algorithms to provide innovative multimedia content exploration methods.", "references": ["F. Bellard. Ffmpeg multimedia system. http:/www.ffmpeg. org, 2005.", "T. Bertin-Mahieux, D. Eck, and M. I. Mandel. Automatic tagging of audio: The state-of-the-art. Machine audition: Principles, algorithms and systems, pages 334--352, 2010.", "P. Boersma and D. Weenink. Praat, a system for doing phonetics by computer. 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814907"}, {"title": "Ushio: analyzing news media and public trends in Twitter", "authors": ["Fangzhou Yao\n,", "Kevin Chen-Chuan Chang\n,", "Roy H. Campbell"], "publication": "UCC '15: Proceedings of the 8th International Conference on Utility and Cloud Computing", "abstract": "ABSTRACT\nIn this information age, Social Networking Services contribute a significant amount of contents in creating a knowledge based society. Nowadays, there are more than 500 million tweets sent per day in Twitter. Such drastic growth of contents brings new opportunities for human beings to discover their surroundings more effectively in a timely manner. Moreover, these types of services evolve not only in a perspective of scalability, but also in the view of indicating more meaningful information regarding what happens in the world. Numerous news agencies are broadcasting breaking news via Twitter and people would like to leave comments with their own opinions as well. However, there are differences between events that news media are more willing to cover and news stories that people are more interested in. Furthermore, as people are becoming the largest sensor network, trending topics are not only led by media, but also by the public, and hence it is worth pondering how they affect each other. In this paper, we focus on studying these concerns by building a system, Ushio, analyzing Twitter streams in both the tweets updated by multiple news agencies and those appearing in the public timeline. We describe our design and implementation of this system, which extracts named entities from the Twitter streams and generates corresponding statistics with its relational model. We then show how we use these data to find trending topics and real focus from both media and the public, as well as discover their related topics along with the correlation indicating the leading role between them for assorted topics.", "references": ["F. Yao, K. C. Chang, and R. H. Campbell, Data Set for This Paper, {Online}. Available: http://goo.gl/ihNeuD", "D. Murphy, Facebook Tops 1B Monthly Active Users, {Online}. Available: http://goo.gl/8HcndP", "E. Protalinski, Twitter Passes 255m Monthly Active Users, {Online}. Available: http://goo.gl/GMu8xX"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3233397.3233479"}, {"title": "A Structured Query Model for the Deep Relational Web", "authors": ["Hasan M. Jamil\n,", "Hosagrahar V. Jagadish"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe deep web is very large and diverse and queries evaluated against the deep web can provide great value. While there have been attempts at accessing the data in the deep web, these are clever \"one-of'' systems and techniques. In this paper, we describe an ongoing research of a generic structured query model that can be used against the deep web. Using this query model, the contributions of a community of researchers can be combined freely, leading to a system that can be improved incrementally each time someone develops a specific novel technique to improve a particular operator.", "references": ["S. Blohm, P. Cimiano, and E. Stemle. Harvesting relations from the web: quantifiying the impact of filtering functions. In NCAI, pages 1316--1321, 2007.", "M. J. Cafarella, A. Y. Halevy, and N. Khoussainova. Data integration for the relational web. PVLDB, 2(1):1090--1101, 2009.", "M. J. Cafarella, A. Y. Halevy, D. Z. Wang, E. W. 0002, and Y. Zhang. Webtables: exploring the power of tables on the web. PVLDB, 1(1):538--549, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806589"}, {"title": "Sentiment analysis of greek tweets and hashtags using a sentiment lexicon", "authors": ["Georgios Kalamatianos\n,", "Dimitrios Mallis\n,", "Symeon Symeonidis\n,", "Avi Arampatzis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nThe rapid growth of social media has rendered opinion and sentiment mining an important area of research with a wide range of applications. We focus on the Greek language and the microblogging platform \"Twitter\", investigating methods for extracting sentiment of individual tweets as well population sentiment for different subjects (hashtags). The proposed methods are based on a sentiment lexicon. We compare several approaches for measuring the intensity of \"Anger\", \"Disgust\", \"Fear\", \"Happiness\", \"Sadness\", and \"Surprise\". To evaluate the effectiveness of our methods, we develop a benchmark dataset of tweets, manually rated by two humans. Our automated sentiment results seem promising and correlate to real user sentiment. Finally, we examine the variation of sentiment intensity over time for selected hashtags, and associate it with real-world events.", "references": ["Tsakalidis, A., et al. 2014. An Ensemble Model for Cross-Domain Polarity Classification on Twitter. 15th International Conference, Thessaloniki, Greece, Proceedings, Part II, (October 12-14, 2014,) 168--177. DOI: 10.1007/978-3-319-11746-1_12.", "Burnside, G., Papadopoulos, S., and Petkos, G. 2014. D2.3 Social stream mining framework. Social Sensor, Sensing User Generated Input for Improved Media Discovery and Experience. FP7-287975.", "Paltoglou, G., and Buckley. K. 2013. Subjectivity annotation of the Microblog 2011 Realtime Adhoc relevance judgments. ECIR 2013: 35th European Conference on Information Retrieval, pages 344--355."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802010"}, {"title": "An exploratory study on the use of Twitter and Facebook in tandem", "authors": ["Tasos Spiliotopoulos\n,", "Ian Oakley"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nThe diversity of available Social Network Sites (SNSs) enables people to use multiple services to fulfill their communication needs. Accordingly, this paper argues there is value in studying SNSs simultaneously -- that key insights regarding SNS use will be revealed when multiple services are examined together. To demonstrate this point, we present a study of 198 Facebook users with the goal of predicting the likelihood of each being a Twitter user based on their Facebook usage. Exploratory factor analysis on twelve activity metrics collected via the Facebook API led to the identification of five discrete usage dimensions. Of these five dimensions, only those that corresponded to functionality not available in Twitter significantly (and positively) predicted ownership of an account. This result suggests complementary use of the two SNSs based on feature differentiation.", "references": ["Junco, R. 2013. Comparing actual and self-reported measures of Facebook use. Computers in Human Behavior 29, 3 (2013), 626--631. DOI = http://dx.doi.org/10.1016/j.chb.2012.11.007.", "Lampe, C., Vitak, J., and Ellison, N. 2013. Users and Nonusers: Interactions between Levels of Facebook Adoption and Social Capital. In Proceedings of the 2013 Conference on Computer Supported Cooperative Work. CSCW '13. ACM Press, 809--820. DOI = http://dx.doi.org/10.1145/2441776.2441867.", "Papacharissi, Z. and Mendelson, A. 2011. Toward a New(er) Sociability: Uses, Gratifications and Social Capital on Facebook. In S. Papathanassopoulos, ed., Media Perspectives for the 21st Century. Routledge."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783620"}, {"title": "Implementing linearizability at large scale and low latency", "authors": ["Collin Lee\n,", "Seo Jin Park\n,", "Ankita Kejriwal\n,", "Satoshi Matsushita\n,", "John Ousterhout"], "publication": "SOSP '15: Proceedings of the 25th Symposium on Operating Systems Principles", "abstract": "ABSTRACT\nLinearizability is the strongest form of consistency for concurrent systems, but most large-scale storage systems settle for weaker forms of consistency. RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics, thereby making it easy to turn non-linearizable operations into linearizable ones. RIFL is designed for large-scale systems and is lightweight enough to be used in low-latency environments. RIFL handles data migration by associating linearizability metadata with objects in the underlying store and migrating metadata with the corresponding objects. It uses a lease mechanism to implement garbage collection for metadata. We have implemented RIFL in the RAMCloud storage system and used it to make basic operations such as writes and atomic increments linearizable; RIFL adds only 530 ns to the 13.5 μs base latency for durable writes. We also used RIFL to construct a new multi-object transaction mechanism in RAMCloud; RIFL's facilities significantly simplified the transaction implementation. The transaction mechanism can commit simple distributed transactions in about 20 μs and it outperforms the H-Store main-memory database system for the TPC-C benchmark.", "references": ["RAMCloud Git Repository. https://github.com/PlatformLab/RAMCloud.git.", "Aguilera, M. K., Merchant, A., Shah, M., Veitch, A., and Karamanolis, C. Sinfonia: A New Paradigm for Building Scalable Distributed Systems. ACM Transactions on Computer Systems 27, 3 (Nov. 2009), 5:1--5:48.", "Baker, J., Bond, C., Corbett, J. C., Furman, J., Khorlin, A., Larson, J., Leon, J.-M., Li, Y., Lloyd, A., and Yushprakh, V. Megastore: Providing Scalable, Highly Available Storage for Interactive Services. In Proceedings of the Conference on Innovative Data system Research (CIDR) (2011), pp. 223--234."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815400.2815416"}, {"title": "BUMP: bridging unmet modes of participation", "authors": ["Cody Chu\n,", "Claudia B. Rebola\n,", "James Kao"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nThis paper describes the development of a technology designed for social connectedness. The goal was to design and develop a technology that allows older adults to be more connected with family and/or close ones. Bridging Unmet Modes of Participation (BUMP) respond to the needs of designing technology products for inclusion and integration of older adults and addressing issues of isolation and social disconnected experienced with the aging population.", "references": ["Adams, K. B., Sanders S., Auth EA (2004) Loneliness and depression in independent living retirement communities: risk and resilience factors. Aging Ment Health 8(6):475--485", "Centers for Disease Control and Prevention, Injury Prevention & Control: Data & Statistics. (2011). Centers for Disease Control and Prevention, Editor 2011: Atlanta, GA.", "Cornwell, E. Y. and L. J. Waite. (2009). Social Disconnectedness, Perceived Isolation, and Health Among Older Adults. J Health Soc Behav. 50(1): p. 31--48."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783601"}, {"title": "Verbal anchor usage on fuzzy systems to help creating initial strategy maps: case study", "authors": ["Marcelo Ladeira\n,", "Fernando de Albuquerque Linhares"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nMore than 50% of the Brazilian companies do not survive to its second year due to the lack of a proper business strategy plan. The Balanced Scorecard(BSC) methodology was proposed to help companies create simple strategy plans that can be explained to all employees within all company levels. The core of this methodology is the strategy map that shows a collection of strategic objectives that a company needs to achieve to reach its mission. Small and medium companies find it difficult to create their own strategies without the help of a management consultant, which is not always affordable. We proposed the Mistral Solutions, a system that helps managers to build strategy maps according to the BSC methodology. To easy the numeric knowledge acquisition process, a manager can answer a question using a verbal anchor scale instead of a number. This system is based on fuzzy logic. Fuzzy rules are instantiated from the answers given and indicate the most adequate strategic objectives. This paper presents three study cases based on the use of the Mistral Solutions. The Regional Labor Court of the 10a Region, a company in the civil construction industry, and a Real Estate Registry Office are focused as case of study. The strategy maps proposed by Mistral Solutions were empirically validated by a BSC specialist and by managers in charge of strategic planning of these institutions. These institutions represent the public sector, the private sector, and a public concession. Mistral Solutions selected the eight more appropriate strategic objectives from a set of forty five, two for each classic BSC perspectives. In the empirical evaluation, the system performed better when applied to private sector institutions when all the eight strategic objectives were considered adequate by the manager in charge of strategic planning of this institution.", "references": ["F. de Albuquerque Linhares. Utilização de Âncoras Verbais e Raciocínio Fuzzy na Construção de Mapas Estratégicos da Metodologia Balanced Scorecard. M.Sc., Universidade de Brasília, Brasilia, Brazil, 2015.", "A. Humphrey. Swot analysis for management consulting. Stanford Research Institute (SRI International) Alumni Newsletter, pages 7-8, December 2005.", "R. S. Kaplan and D. P. Norton. The Balanced Scorecard: Translating Strategy into Action. Harvard Business Review Press, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814126"}, {"title": "A LINQ-based Conditional Pattern Collection Algorithm for Parallel Frequent Itemset Mining on a Multi-Core Computer", "authors": ["Chun-Hong Huang\n,", "Yungho Leu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nDue to the prevalence of big datasets, the existing frequent itemset mining algorithms are not adequate. In this paper, we propose a new algorithm for parallel frequent itemset mining on a multi-core computer system. We propose to use LINQ queries to divide a transaction database into a set of independent sub-datasets, called the conditional pattern collections. Subsequently, the threads of a multi-core computer system mine the conditional pattern collections concurrently by using an existing implementation of a frequent itemset mining algorithm. The experimental results showed that the proposed algorithm offered 2x speedup and 4x speedup, for a fast implementation of éclat and a fast implementation of FP-growth, respectively, on a personal computer system with a quad-core Intel i7 CPU.", "references": ["Agrawal, R., Imielinski, T., and Swami, A. 1993. Mining association rules between sets of items in large databases. Paper presented at the ACM SIGMOD.", "Liu, L., Li, E., Zhang, Y., and Tang, Z. 2007. Optimization of frequent itemset mining on multiple-core processor. Paper presented at the Very Large Data Base.", "Dong, J. and Han, M. 2007. BitTableFI: An efficient mining frequent itemsets algorithm. Knowledge-Based Systems, 20(4), 329--335"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818893"}, {"title": "Cross-Social Network Collaborative Recommendation", "authors": ["Aleksandr Farseev\n,", "Denis Kotkov\n,", "Alexander Semenov\n,", "Jari Veijalainen\n,", "Tat-Seng Chua"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nOnline social networks have become an essential part of our daily life, and an increasing number of users are using multiple online social networks simultaneously. We hypothesize that the integration of data from multiple social networks could boost the performance of recommender systems. In our study, we perform cross-social network collaborative recommendation and show that fusing multi-source data enables us to achieve higher recommendation performance as compared to various single-source baselines.", "references": ["F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause. Cross-system user modeling and personalization on the social web. User Model. User-Adap. Inter., 23(2-3):169--209, 2013.", "A. Farseev, N. Liqiang, M. Akbari, and T.-S. Chua. Harvesting multiple sources for user profile learning: a big data study. In ICMR, 2015.", "P. Winoto and T. Tang. If you like the devil wears prada the book, will you also enjoy the devil wears prada the movie? a study of cross-domain recommendations. New Generation Computing, 26(3):209--225, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786504"}, {"title": "Session details: Session 5B: Retrieval Enhancements 1", "authors": ["J. Shane Culpepper"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252304"}, {"title": "Towards An Interactive Keyword Search over Relational Databases", "authors": ["Zhong Zeng\n,", "Zhifeng Bao\n,", "Mong Li Lee\n,", "Tok Wang Ling"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nKeyword search over relational databases has been widely studied for the exploration of structured data in a user-friendly way. However, users typically have limited domain knowledge or are unable to precisely specify their search intention. Existing methods find the minimal units that contain all the query keywords, and largely ignore the interpretation of possible users' search intentions. As a result, users are often overwhelmed with a lot of irrelevant answers. Moreover, without a visually pleasing way to present the answers, users often have difficulty understanding the answers because of their complex structures. Therefore, we design an interactive yet visually pleasing search paradigm called ExpressQ. ExpressQ extends the keyword query language to include keywords that match meta-data, e.g., names of relations and attributes. These keywords are utilized to infer users' search intention. Each possible search intention is represented as a query pattern, whose meaning is described in human natural language. Through a series of user interactions, ExpressQ can determine the search intention of the user, and translate the corresponding query patterns into SQLs to retrieve answers to the query. The ExpressQ prototype is available at http://expressq.comp.nus.edu.sg.", "references": ["B. Aditya, G. Bhalotia, S. Chakrabarti, A. Hulgeri, C. Nakhe, P. Parag, and S. Sudarshan. BANKS: Browsing and keyword searching in relational databases. In VLDB, 2002.", "M. Kargar, A. An, N. Cercone, P. Godfrey, J. Szlichta, and X. Yu. MeanKS: Meaningful keyword search in relational databases with complex schema. In SIGMOD, 2014.", "F. Li and H. V. Jagadish. Usability, databases, and HCI. IEEE Data Eng. Bull., 35(3):37--45, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742830"}, {"title": "Scalable Organization of Collections of Motion Capture Data via Quantitative and Qualitative Analysis", "authors": ["Songle Chen\n,", "Zhengxing Sun\n,", "Yan Zhang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper proposes a scalable method for organizing the collection of motion capture data for overview and exploration, and it mainly addresses three core problems, including data abstraction, neighborhood construction and data visualization. To alleviate the contradiction between limited visual space and the ever-increasing size of real-word datasets, hierarchical affinity propagation (HAP) is adopt to perform data abstraction on low-level pose features to generate multi-layers of data aggregations in consistent with coarse to fine abstraction levels of human cognition. To construct a meaningful neighborhood for user choosing a browsing path and positioning themselves, quartet analysis-based phylogenetic tree is created upon high-level pose features to produce more reliable neighbors for different aggregations of the specific abstraction level. To provide a convenient interactive environment for user navigation, a phylogenetic tree-centric visualization strategy in three-dimensional space is present. Experimental results on HDM05 motion capture dataset verify the effectiveness of the proposed method.", "references": ["Carnegie Mellon University. \"Motion Capture Database,\" http://mocap.cs.cmu.edu/.", "H. d. Medien. \"HDM Motion Capture Database (HDM05),\" http://www.mpi-inf.mpg.de/resources/HDM05/.", "J. Bernard, N. Wilhelm, B. Kruger et al., \"MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation,\" Visualization and Computer Graphics, IEEE Transactions on, vol. 19, no. 12, pp. 2257--2266, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749384"}, {"title": "Non-Compositional Term Dependence for Information Retrieval", "authors": ["Christina Lioma\n,", "Jakob Grue Simonsen\n,", "Birger Larsen\n,", "Niels Dalum Hansen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModelling term dependence in IR aims to identify co-occurring terms that are too heavily dependent on each other to be treated as a bag of words, and to adapt the indexing and ranking accordingly. Dependent terms are predominantly identified using lexical frequency statistics, assuming that (a) if terms co-occur often enough in some corpus, they are semantically dependent; (b) the more often they co-occur, the more semantically dependent they are. This assumption is not always correct: the frequency of co-occurring terms can be separate from the strength of their semantic dependence. E.g. \"red tape\" might be overall less frequent than \"tape measure\" in some corpus, but this does not mean that \"red\"+\"tape\" are less dependent than \"tape\"+\"measure\". This is especially the case for non-compositional phrases, i.e. phrases whose meaning cannot be composed from the individual meanings of their terms (such as the phrase \"red tape\" meaning bureaucracy). Motivated by this lack of distinction between the frequency and strength of term dependence in IR, we present a principled approach for handling term dependence in queries, using both lexical frequency and semantic evidence. We focus on non-compositional phrases, extending a recent unsupervised model for their detection (Kiela & Clark 2013) to IR. Our approach, integrated into ranking using Markov Random Fields (Metzler & Croft 2005), yields effectiveness gains over competitive TREC baselines, showing that there is still room for improvement in the very well-studied area of term dependence in IR.", "references": ["T. Baldwin, C. Bannard, T. Tanaka, and D. Widdows. An empirical model of multiword expression decomposability. In ACL Multiword Expressions Wksh., pages 89--96. 2003.", "C. Bannard, T. Baldwin, and A. Lascarides. A statistical approach to the semantics of verb-particles. In ACL Multiword Expressions Wksh., pages 65--72, 2003.", "P. B. Baxendale. Machine-made index for technical literature. IBM Journal for R&D, 2:354--361, 1958."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767717"}, {"title": "Heterogeneous Semantic Level Features Fusion for Action Recognition", "authors": ["Junjie Cai\n,", "Michele Merler\n,", "Sharath Pankanti\n,", "Qi Tian"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nAction recognition is an important problem in computer vision and has received substantial attention in recent years. However, it remains very challenging due to the complex interaction of static and dynamic information, as well as the high computational cost of processing video data. This paper aims to apply the success of static image semantic recognition to the video domain, by leveraging both static and motion based descriptors in different stages of the semantic ladder. We examine the effects of three types of features: low-level dynamic descriptors, intermediate-level static deep architecture outputs, and static high-level semantics. In order to combine such heterogeneous sources of information, we employ a scalable method to fuse these features. Through extensive experimental evaluations, we demonstrate that the proposed framework significantly improves action classification performance. We have obtained an accuracy of 89.59% and 62.88% on the well-known UCF-101 and HMDB-51 benchmarks, respectively, which compare favorably with the state-of-the-art.", "references": ["M. Merler, B. Huang, L. Xie, G. Hua and A. Natsev. Semantic model vectors for complex video event recognition. In IEEE Transactions on Multimedia, 2013.", "Y. Jia. Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding. http://caffe.berkeleyvision.org/, 2013.", "A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar and L. Fei-Fei. Large-scale video classification with convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749320"}, {"title": "Tailoring Music Recommendations to Users by Considering Diversity, Mainstreaminess, and Novelty", "authors": ["Markus Schedl\n,", "David Hauger"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nA shortcoming of current approaches for music recommendation is that they consider user-specific characteristics only on a very simple level, typically as some kind of interaction between users and items when employing collaborative filtering. To alleviate this issue, we propose several user features that model aspects of the user's music listening behavior: diversity, mainstreaminess, and novelty of the user's music taste. To validate the proposed features, we conduct a comprehensive evaluation of a variety of music recommendation approaches (stand-alone and hybrids) on a collection of almost 200 million listening events gathered from \\propername{Last.fm}. We report first results and highlight cases where our diversity, mainstreaminess, and novelty features can be beneficially integrated into music recommender systems.", "references": ["G. Adomavicius and A. Tuzhilin. Recommender Systems Handbook, chapter Context-Aware Recommender Systems, pages 217--253. Springer, 2011.", "L. Baltrunas, M. Kaminskas, B. Ludwig, O. Moling, F. Ricci, K.-H. Lüke, and R. Schwaiger. InCarMusic: Context-Aware Music Recommendations in a Car. In Proc. EC-Web, 2011.", "O. Celma. Music Recommendation and Discovery -- The Long Tail, Long Fail, and Long Play in the Digital Music Space. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767763"}, {"title": "Top-k Reliable Edge Colors in Uncertain Graphs", "authors": ["Arijit Khan\n,", "Francesco Gullo\n,", "Thomas Wohler\n,", "Francesco Bonchi"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study the fundamental problem of finding the set of top-k edge colors that maximizes the reliability between a source node and a destination node in an uncertain and edge-colored graph. Our top-k reliable color set problem naturally arises in a variety of real-world applications including pathway finding in biological networks, topic-aware influence maximization, and team formation in social networks, among many others. In addition to the #P-completeness of the classical reliability finding problem between a source and a destination node over an uncertain graph, we prove that our problem is also NP-hard, and neither sub-modular, nor super-modular. To this end, we aim at designing effective and scalable solutions for the top-k reliable color set problem. We first introduce two baselines following the idea of repetitive inclusion of the next best edge colors, and we later develop a more efficient and effective algorithm that directly finds the highly-reliable paths while maintaining the budget on the number of edge-colors. An extensive empirical evaluation on various large-scale and real-world graph datasets illustrates that our proposed techniques are both scalable and highly accurate.", "references": ["M. O. Ball. Computational Complexity of Network Reliability Analysis: An Overview. IEEE Tran. on Reliability, 1986.", "N. Barbieri, F. Bonchi, and G. Manco. Topic-Aware Social Influence Propagation Models. In ICDM, 2012.", "M. Chen, Y. Gu, Y. Bao, and G. Yu. Label and Distance-Constraint Reachability Queries in Uncertain Graphs. In DASFAA, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806619"}, {"title": "Challenged Content Delivery Network: Eliminating the Digital Divide", "authors": ["Hua-Jun Hong\n,", "Shu-Ting Wang\n,", "Chih-Pin Tan\n,", "Tarek El-Ganainy\n,", "Khaled Harras\n,", "Cheng-Hsin Hsu\n,", "Mohamed Hefeeda"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present a complete system, called Challenged Content Delivery Network (CCDN), to efficiently deliver multimedia content to mobile users who live in developing countries, rural areas, or over-populated cities with no or weak network infrastructure. These mobile users do not have always-on Internet access. We demo our CCDN, implemented on a Linux server, Raspberry Pi proxies, and Android phones from three aspects: multimedia, networking, and machine learning tools. We propose multiple optimization algorithm modules that compute personalized distribution plans, and maximize the overall user experience. CCDN allows people living in area with challenged networks access to multimedia content, like news reports, using mobile devices, such as smartphones. This in turn will help in eliminating the digital divide, which refers to information inequality to persons with different Internet accessing abilities.", "references": ["How do we accelerate Internet access in Africa? http://tinyurl.com/q9ksjwg, 2013.", "D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "C. Burges. From ranknet to LambdaRank to LambdaMART: An overview. Technical report, Microsoft Research, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807970"}, {"title": "Web Archiving and Digital Libraries (WADL)", "authors": ["Edward A. Fox\n,", "Zhiwu Xie"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis workshop will explore integration of Web archiving and digital libraries, so the complete life cycle involved is covered: creation/authoring, uploading/publishing in the Web (2.0), (focused) crawling, indexing, exploration (searching, browsing), ..., archiving (of events). It will include particular coverage of current topics of interest:, big data, mobile web archiving, and systems (e.g., Memento, SiteStory, Uninterruptible Web Service).", "references": ["Weber, M., Lazer, D., Carpenter-Negulescu, K., and Kosterich, A. 2014. Working with Internet Archives for Research (WIRE 2014 Workshop, Cambridge, MA, June 17--18, 2014). http://wp.comminfo.rutgers.edu/nsfia/", "Fox, E.A. and Farag, M.M. 2013. Report on the Workshop on Web Archiving and Digital Libraries (WADL 2013), WADL Workshop Report, ACM SIGIR Forum, 47(2): 128--133. http://sigir.org/files/forum/2013D/p128.pdf", "Fox, E.A. 2013. Web Archiving and Digital Libraries (WADL 2013). Virginia Tech CTRnet announcement, http://www.ctrnet.net/sites/default/files/JCDL2013WorkshopWebArchiving20130603.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756934"}, {"title": "Long-term Optimization of Update Frequencies for Decaying Information", "authors": ["Simon Razniewski\n,", "Werner Nutt"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nMany kinds of information, such as addresses, crawls of webpages, or academic affiliations, are prone to becoming outdated over time. Therefore, in some applications, updates are performed periodically in order to keep the correctness and usefulness of such information high. As refreshing information usually has a cost, e.g. computation time, network bandwidth or human work time, a problem is to find the right update frequency depending on the benefit gained from the information and on the speed with which the information is expected to get outdated.\nThis is especially important since often entities exhibit a different speed of getting outdated, as, e.g., addresses of students change more frequently than addresses of pensionists, or news portals change more frequently than personal homepages. Thus, there is no uniform best update frequency for all entities.\nPrevious work [5] on data freshness has focused on the question of how to best distribute a fixed budget for updates among various entities, which is of interest in the short-term, when resources are fixed and cannot be adjusted.\nIn the long-term, many businesses are able to adjust their resources in order to optimize their gain. Then, the problem is not one of distributing a fixed number of updates but one of determining the frequency of updates that optimizes the overall gain from the information.\nIn this paper, we investigate how the optimal update frequency for decaying information can be determined. We show that the optimal update frequency is independent for each entity, and how simple iteration can be used to find the optimal update frequency. An implementation of our solution for exponential decay is available online.", "references": ["M. Baker, K. Keeton, and S. Martin. Why traditional storage systems don't help us save stuff forever. In Proc. 1st IEEE Workshop on Hot Topics in System Dependability, pages 2005--120. Citeseer, 2005.", "M. Bouzeghoub. A framework for analysis of data freshness. In Proceedings of the 2004 international workshop on Information quality in information systems, pages 59--67. ACM, 2004.", "L. Bright and L. Raschid. Using latency-recency profiles for data delivery on the web. In Proceedings of the 28th international conference on Very Large Data Bases, pages 550--561. VLDB Endowment, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767113"}, {"title": "Extracting Situational Information from Microblogs during Disaster Events: a Classification-Summarization Approach", "authors": ["Koustav Rudra\n,", "Subham Ghosh\n,", "Niloy Ganguly\n,", "Pawan Goyal\n,", "Saptarshi Ghosh"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMicroblogging sites like Twitter have become important sources of real-time information during disaster events. A significant amount of valuable situational information is available in these sites; however, this information is immersed among hundreds of thousands of tweets, mostly containing sentiments and opinion of the masses, that are posted during such events. To effectively utilize microblogging sites during disaster events, it is necessary to (i) extract the situational information from among the large amounts of sentiment and opinion, and (ii) summarize the situational information, to help decision-making processes when time is critical. In this paper, we develop a novel framework which first classifies tweets to extract situational information, and then summarizes the information. The proposed framework takes into consideration the typicalities pertaining to disaster events where (i) the same tweet often contains a mixture of situational and non-situational information, and (ii) certain numerical information, such as number of casualties, vary rapidly with time, and thus achieves superior performance compared to state-of-the-art tweet summarization approaches.", "references": ["M. A. Cameron, R. Power, B. Robinson, and J. Yin. Emergency Situation Awareness from Twitter for Crisis Management. In Proc. Conference on World Wide Web (WWW), 2012.", "D. Chakrabarti and K. Punera. Event summarization using tweets. In Proc. AAAI ICWSM, 2011.", "C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1--27:27, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806485"}, {"title": "Session details: Tutorials", "authors": ["Yoelle Maarek"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis year's conference received twelve submissions, of which eight were accepted, and one was extended to an additional half-day. The decision was based on criteria of relevance to the SIGIR community, core quality and experience of presenters. The accepted tutorials include three fullday tutorials, and two morning-afternoon sequences. It was important for us to build a diverse yet comprehensive program that would address the needs of all attendees from newcomers, eager to acquire critical knowledge, to experts curious about side or emerging areas of research in Information Retrieval.\nTo this effect we made sure to cover a wide range of topics from fundamental ones (\"Revisiting the Foundations of IR\") to timely ones such as formal models (\"Building and Using Models forInformation Seeking, Search and Retrieval\"), the handling of verbose queries (\"Information Retrieval with Verbose Queries\"), or related to leveraging Wikipedia (\"Exploiting Wikipedia for Information Retrieval Tasks\".) We also decided to allow for non-mainstream topics in order to expand the horizons of Information Retrieval practitioners and researchers with a full-day tutorial on \"Music Retrieval and Recommendation\".\nIn addition, we wanted to offer more flexibility to attendees in building their own personalized program as well as learning about timely topics. We thus included this year two morningafternoon sequence of half-day tutorials. One such sequence deals with click models, starting in the morning with \"An Introduction to Click Models for Web Search\", while the afternoon session dives deep into \"Advanced Click Models and their Applications to IR\". The other sequence covers the always-critical topic of IR evaluation, with a morning session dealing with \"Designing an Endto- End Evaluation Pipeline\", and an afternoon session tackling user behavior in \"Modeling User Behavior for Measuring Effectiveness\". Note that in order to offer more flexibility to attendees, the morning and afternoon sessions of these two tutorials are each considered as stand-alone tutorials and can be taken independently.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3255941"}, {"title": "Should conferences meet journals and where?: a proposal for 'PACM'", "authors": ["Joseph A. Konstan\n,", "Jack W. Davidson"], "publication": "Communications of the ACM", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811400"}, {"title": "Lifespan-based Partitioning of Index Structures for Time-travel Text Search", "authors": ["Animesh Nandi\n,", "Suriya Subramanian\n,", "Sriram Lakshminarasimhan\n,", "Prasad M. Deshpande\n,", "Sriram Raghavan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTime-travel text search over a temporally evolving document collection is useful in various applications. Supporting a wide range of query classes demanded by these applications require different index layouts optimized for their respective query access patterns. The problem we tackle is how to efficiently handle different query classes using the same index layout.\nOur approach is to use list intersections on single-attribute indexes of keywords and temporal attributes. Although joint predicate evaluation on single-attribute indexes is inefficient in general, we show that partitioning the index based on version lifespans coupled with exploiting the transaction-time ordering of record-identifiers, can significantly reduce the cost of list intersections.\nWe empirically evaluate different index partitioning alternatives on top of open-source Lucene, and show that our approach is the only technique that can simultaneously support a wide range of query classes efficiently, have high indexing throughput in a real-time ingestion setting, and also have negligible extra storage costs.", "references": ["Anand, A., Bedathur, S., Berberich, K., and Schenkel, R. Temporal index sharding for space-time efficiency in archive search. In SIGIR (2011).", "Anand, A., Bedathur, S., Berberich, K., and Schenkel, R. Index maintenance for time-travel text search. In SIGIR (2012).", "Barbay, J., Lopez-Ortiz, A., Lu, T., and Salinger, A. An experimental investigation of set intersection algorithms for text searching. In Journal of Experimental Algorithmics (JEA), Volume 14 (2009)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806442"}, {"title": "Mjölnir: collecting trash in a demanding new world", "authors": ["Zev Weiss\n,", "Sriram Subramanian\n,", "Swaminathan Sundararaman\n,", "Vinay Sridhar\n,", "Nisha Talagala\n,", "Andrea C. Arpaci-Dusseau\n,", "Remzi H. Arpaci-Dusseau"], "publication": "INFLOW '15: Proceedings of the 3rd Workshop on Interactions of NVM/FLASH with Operating Systems and Workloads", "abstract": "ABSTRACT\nAs flash devices become ubiquitous in data centers and cost per gigabyte drops, flash systems need to provide data services similar to those of traditional storage. We present Mjölnir, a powerful and scalable engine that addresses the core problems that make efficient flash based data services challenging: multi-reference management and garbage collection. Additionally, by providing powerful primitives for address remapping, Mjölnir enables redesign of the I/O stack for greater efficiency and performance with flash. Mjölnir uses techniques from language runtimes for reference management and garbage collection; we show via prototype and experimental evaluation that this design can deliver predictable performance even with varied user workloads across a range of capacity and reference-count scales.", "references": ["Native Flash Support for Applications. http://www.flashmemorysummit.com/.", "ioCache. http://www.fusionio.com/products/iocache, 2012.", "Agarwal, N., Prabhakaran, V., Wobber, T., Davis, J. D., Manasse, M., and Panigrahy, R. Design Trade-offs for SSD Performance. In Proceedings of the USENIX Annual Technical Conference (USENIX '08) (Boston, Massachusetts, June 2008)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2819001.2819006"}, {"title": "A Theoretical Model for Big Data Analytics using Machine Learning Algorithms", "authors": ["Ananthi Sheshasaayee\n,", "J. V. N. Lakshmi"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nBig Data processing is currently becoming increasingly important in modern era due to continuous growth of the amount of data generated in various fields. Architecture for Big Data usually ranges across multiple machines and clusters consisting of various sub systems. To potentially speed up the processing, a unified way of machine learning is applied on MapReduce frame work. A broadly applicable programming model MapReduce is applied on different learning algorithms belonging to machine learning family for all business decisions. This paper presents parallel implementation of various machine learning algorithms, includes K-Means, Logistic Regression implemented on top of MapReduce model.", "references": ["Abadi, D., and Rasin, A. HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads. InVLDB '09 by ACM.", "Alan F. Gates, Building a HighLevel Dataflow System on top of MapReduce: The Pig Experience In Proceedings of International Conference on VLDB '09 by ACM in France 2009.", "Ananthi, S., and Lakshmi J V N, An Analysis On Machine Learning Algorithms Implemented On Hadoop MapReduce. In Proceedings of International Conference on Communication, Computing and Information Technology (Chennai, India 2015). ICCCMIT '14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791549"}, {"title": "Top-k entity augmentation using consistent set covering", "authors": ["Julian Eberius\n,", "Maik Thiele\n,", "Katrin Braunschweig\n,", "Wolfgang Lehner"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nEntity augmentation is a query type in which, given a set of entities and a large corpus of possible data sources, the values of a missing attribute are to be retrieved. State of the art methods return a single result that, to cover all queried entities, is fused from a potentially large set of data sources. We argue that queries on large corpora of heterogeneous sources using information retrieval and automatic schema matching methods can not easily return a single result that the user can trust, especially if the result is composed from a large number of sources that user has to verify manually. We therefore propose to process these queries in a Top-k fashion, in which the system produces multiple minimal consistent solutions from which the user can choose to resolve the uncertainty of the data sources and methods used. In this paper, we introduce and formalize the problem of consistent, multi-solution set covering, and present algorithms based on a greedy and a genetic optimization approach. We then apply these algorithms to Web table-based entity augmentation. The publication further includes a Web table corpus with 100M tables, and a Web table retrieval and matching system in which these algorithms are implemented. Our experiments show that the consistency and minimality of the augmentation results can be improved using our set covering approach, without loss of precision or coverage and while producing multiple alternative query results.", "references": ["J. Beasley and P. Chu. A genetic algorithm for the set covering problem. European Journal of Operational Research, 94(2):392--404, 1996.", "J. Bleiholder and F. Naumann. Data fusion. ACM Comput. Surv., pages 1--41, 2009.", "M. J. Cafarella, A. Halevy, and N. Khoussainova. Data integration for the relational web. VLDB, pages 1090--1101, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791353"}, {"title": "Data structure aware garbage collector", "authors": ["Nachshon Cohen\n,", "Erez Petrank"], "publication": "ISMM '15: Proceedings of the 2015 International Symposium on Memory Management", "abstract": "ABSTRACT\nGarbage collection may benefit greatly from knowledge about program behavior, but most managed languages do not provide means for the programmer to deliver such knowledge. In this work we propose a very simple interface that requires minor programmer effort and achieves substantial performance and scalability improvements. In particular, we focus on the common use of data structures or collections for organizing data on the heap. We let the program notify the collector which classes represent nodes of data structures and also when such nodes are being removed from their data structures. The data-structure aware (DSA) garbage collector uses this information to improve performance, locality, and load balancing. Experience shows that this interface requires a minor modification of the application. Measurements show that for some significant benchmarks this interface can dramatically reduce the time spent on garbage collection and also improve the overall program performance.", "references": ["E. E. Aftandilian and S. Z. Guyer. Gc assertions: using the garbage collector to check heap properties. In PLDI, pages 235–244, 2009.", "B. Alpern, C. R. Attanasio, J. J. Barton, M. G. Burke, P. Cheng, J.-D. Choi, A. Cocchi, S. J. Fink, D. Grove, M. Hind, S. F. Hummel, D. Lieber, V. Litvinov, M. Mergen, T. Ngo, J. R. Russell, V. Sarkar, M. J. Serrano, J. Shepherd, S. Smith, V. C. Sreedhar, H. Srinivasan, and J. Whaley. The jalapeno virtual machine. IBM Systems Journal, 39(1):211– 238, 2000.", "K. Barabash and E. Petrank. Tracing garbage collection on highly parallel platforms. In ISMM, pages 1–10. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2754169.2754176"}, {"title": "Terms in Time and Times in Context: A Graph-based Term-Time Ranking Model", "authors": ["Andreas Spitz\n,", "Jannik Strötgen\n,", "Thomas Bögel\n,", "Michael Gertz"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nApproaches in support of the extraction and exploration of temporal information in documents provide an important ingredient in many of today's frameworks for text analysis. Methods range from basic techniques, primarily the extraction of temporal expressions and events from documents, to more sophisticated approaches such as ranking of documents with respect to their temporal relevance to some query term or the construction of timelines. Almost all of these approaches operate on the document level, that is, for a collection of documents a timeline is extracted or a ranked list of documents is returned for a temporal query term. In this paper, we present an approach to characterize individual dates, which can be of different granularities, and terms. Given a query date, a ranked list of terms is determined that are highly relevant for that date and best summarize the date. Analogously, for a query term, a ranked list of dates is determined that best characterize the term. Focusing on just dates and single terms as they occur in documents provides a fine-grained query and exploration method for document collections. Our approach is based on a weighted bipartite graph representing the co-occurrences of time expressions and terms in a collection of documents. We present different measures to obtain a ranked list of dates and terms for a query term and date, respectively. Our experiments and evaluation using Wikipedia as a document collection show that our approach provides an effective means in support of date and temporal term summarization.", "references": ["O. Alonso, M. Gertz, and R. A. Baeza-Yates. Clustering and Exploring Search Results using Timeline Constructions. In CIKM'09, pages 97--106, 2009.", "O. Alonso and K. Shiells. Timelines as Summaries of Popular Scheduled Events. In WWW'13, Companion Volume, pages 1037--1044, 2013.", "O. Alonso, J. Strötgen, R. Baeza-Yates, and M. Gertz. Temporal Information Retrieval: Challenges and Opportunities. In TempWeb'11, pages 1--8, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741693"}, {"title": "Dual Clustering and Data Decomposition for Nursing Care Management", "authors": ["Shusaku Tsumoto\n,", "Shoji Hirano\n,", "Haruko Iwata"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper proposes a method for construction of a clinical pathway based on dual clustering which consists of attribute and sampling clustering. The method consists of the following four steps: first, couting numbers of nursing orders of a given disease are extracted from hospital information system. Second, orders are classified into several groups by using clustering (sample clustering). Third, attributes clustering is applied to the data. Finally, original temporal data are split into several sub-tables by uisn the results of attribute clustering and the first step will be repeated in a recursive way. After the grouping results are stable, a new pathway will be constructed from all the induced results. The method was applied to a dataset of a disease extracted from a hospital information system. The results show that the proposed method constructed a clinical pathway, which was not only similar to the pathway manually acquired from medical experts but also discovered nursing orders which they forget to include.\nClustering", "references": ["I. Bichindaritz. Memoire: A framework for semantic interoperability of case-based reasoning systems in biology and medicine. Artif Intell Med, 36(2):177--192, 2006.", "B. S. Everitt, S. Landau, M. Leese, and D. Stahl. Cluster Analysis. Wiley, 5th edition, 2011.", "E. Hanada, S. Tsumoto, and S. Kobayashi. A Ahubiquitous environment&alpha;h through wireless voice/data communication and a fully computerized hospital information system in a university hospital. In H. Takeda, editor, E-Health, volume 335 of IFIP Advances in Information and Communication Technology, pages 160--168. Springer Boston, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818932"}, {"title": "Diversity and Novelty on the Web: Search, Recommendation, and Data Streaming Aspects", "authors": ["Rodrygo L.T. Santos\n,", "Pablo Castells\n,", "Ismail Sengor Altingovde\n,", "Fazli Can"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis tutorial aims to provide a unifying account of current research on diversity and novelty in different web information systems. In particular, the tutorial will cover the motivations, as well as the most established approaches for producing and evaluating diverse results in search engines, recommender systems, and data streams, all within the context of the World Wide Web. By contrasting the state-of-the-art in these multiple domains, this tutorial aims to derive a common understanding of the diversification problem and the existing solutions, their commonalities and differences, as a means to foster new research directions.", "references": ["F. Can, S. Kocberber, O. Baglioglu, S. Kardas, H. C. Ocalan, and E. Uyar. New event detection and topic tracking in Turkish. JASIST, 61(4):802--819, 2010.", "A. M. Ozdemiray and I. S. Altingovde. Explicit search result diversification using score and rank aggregation methods. JASIST. In press. http://dx.doi.org/10.1002/asi.23259", "R. L. T. Santos, C. Macdonald, and I. Ounis. Search result diversification. Foundations and Trends in Information Retrieval, 9(1):1--90, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741988"}, {"title": "BodyBeat: Eavesdropping on our Body Using a Wearable Microphone", "authors": ["Tauhidur Rahman\n,", "Alexander T. Adams\n,", "Mi Zhang\n,", "Erin Cherry\n,", "Tanzeem Choudhury"], "publication": "GetMobile: Mobile Computing and Communications", "abstract": "", "references": ["O. Amft, M. Stäger, P. Lukowicz, and G. Tröster. Analysis of chewing sounds for dietary monitoring. In UbiComp 2005, 56--72.", "K. Yatani and K. N. Truong. BodyScope: a wearable acoustic sensor for activity recognition. In UbiComp 2012, 341--350.", "S. Reichert, R. Gass, C. Brandt, and E. Andrès. Analysis of Respiratory Sounds: State of the Art. In Clinical Medicine 2008. Circulatory, Respiratory and Pulmonary Medicine, 2, 45--58."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786984.2786989"}, {"title": "On the Behavior of PRES Using Incomplete Judgment Sets", "authors": ["Ellen M. Voorhees"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nPRES, the Patent Retrieval Evaluation Score, is a family of retrieval evaluation measures that combines recall and user effort to reflect the quality of a retrieval run with respect to recall-oriented search tasks. Previous analysis of the measure was done using the test collection for the CLEF-IP 2009 track, a collection that contains a limited range of number of relevant documents, making it difficult to assess the behavior of PRES for varying recall contexts. This paper examines the effect of incomplete judgments on PRES scores using the well-studied TREC-8 ad hoc test collection, a collection with a much more varied number-of-relevants profile. Experiments with small judgment sets created through a typical collection-building process show the PRES measures are resilient to incomplete judgment sets.", "references": ["C. Buckley, D. Dimmick, I. Soboroff, and E. M. Voorhees. Bias and the limits of pooling for large collections. Information Retrieval, 10:491--508, 2007.", "W. Magdy and G. J. Jones. Examining the robustness of evaluation metrics for patent retrieval with incomplete relevance judgments. In Proceedings of CLEF 2010, LNCS 6360, pages 82--93, 2010.", "W. Magdy and G. J. Jones. PRES: A score metric for evaluating recall-oriented information retrieval applications. In Proceedings of SIGIR 2010, pages 611--618, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809484"}, {"title": "Personalized Federated Search at LinkedIn", "authors": ["Dhruv Arya\n,", "Viet Ha-Thuc\n,", "Shakti Sinha"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLinkedIn has grown to become a platform hosting diverse sources of information ranging from member profiles, jobs, professional groups, slideshows etc. Given the existence of multiple sources, when a member issues a query like \"software engineer\", the member could look for software engineer profiles, jobs or professional groups. To tackle this problem, we exploit a data-driven approach that extracts searcher intents from their profile data and recent activities at a large scale. The intents such as job seeking, hiring, content consuming are used to construct features to personalize federated search experience. We tested the approach on the LinkedIn homepage and A/B tests show significant improvements in member engagement. As of writing this paper, the approach powers all of federated search on LinkedIn homepage.", "references": ["J. Arguello, F. Diaz, and J. Callan. Learning to aggregate vertical results into web search results. In Proceedings of the 20th Conference on Information and Knowledge Management, pages 201--210, 2011.", "F. Diaz. Integration of news content into web results. In Proceedings of the Second International Conference on Web Search and Web Data Mining, pages 182--191, 2009.", "D. Lefortier, P. Serdyukov, F. Romanenko, and M. de Rijke. Blending vertical and web results - A case study using video intent. In Proceedings of the 36th European Conference on IR Research, pages 184--196, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806615"}, {"title": "Session details: Main Track - Solutions for Systems-of-Systems and Software Ecosystems", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252428"}, {"title": "Aggregate estimations over location based services", "authors": ["Weimo Liu\n,", "Md Farhadur Rahman\n,", "Saravanan Thirumuruganathan\n,", "Nan Zhang\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nLocation based services (LBS) have become very popular in recent years. They range from map services (e.g., Google Maps) that store geographic locations of points of interests, to online social networks (e.g., WeChat, Sina Weibo, FourSquare) that leverage user geographic locations to enable various recommendation functions. The public query interfaces of these services may be abstractly modeled as a kNN interface over a database of two dimensional points on a plane: given an arbitrary query point, the system returns the k points in the database that are nearest to the query point. In this paper we consider the problem of obtaining approximate estimates of SUM and COUNT aggregates by only querying such databases via their restrictive public interfaces. We distinguish between interfaces that return location information of the returned tuples (e.g., Google Maps), and interfaces that do not return location information (e.g., Sina Weibo). For both types of interfaces, we develop aggregate estimation algorithms that are based on novel techniques for precisely computing or approximately estimating the Voronoi cell of tuples. We discuss a comprehensive set of real-world experiments for testing our algorithms, including experiments on Google Maps, WeChat, and Sina Weibo.", "references": ["http://www.census.gov/2010census/data/.", "http://investor.starbucks.com/phoenix.zhtml?c=99518&p=irol-financialhighlights.", "Google Places API. https://developers.google.com/places/documentation/."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824034"}, {"title": "Cloud Computing Resource Scheduling and a Survey of Its Evolutionary Approaches", "authors": ["Zhi-Hui Zhan\n,", "Xiao-Fang Liu\n,", "Yue-Jiao Gong\n,", "Jun Zhang\n,", "Henry Shu-Hung Chung\n,", "Yun Li"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nA disruptive technology fundamentally transforming the way that computing services are delivered, cloud computing offers information and communication technology users a new dimension of convenience of resources, as services via the Internet. Because cloud provides a finite pool of virtualized on-demand resources, optimally scheduling them has become an essential and rewarding topic, where a trend of using Evolutionary Computation (EC) algorithms is emerging rapidly. Through analyzing the cloud computing architecture, this survey first presents taxonomy at two levels of scheduling cloud resources. It then paints a landscape of the scheduling problem and solutions. According to the taxonomy, a comprehensive survey of state-of-the-art approaches is presented systematically. Looking forward, challenges and potential future research directions are investigated and invited, including real-time scheduling, adaptive dynamic scheduling, large-scale scheduling, multiobjective scheduling, and distributed and parallel scheduling. At the dawn of Industry 4.0, cloud computing scheduling for cyber-physical integration with the presence of big data is also discussed. Research in this area is only in its infancy, but with the rapid fusion of information and data technology, more exciting and agenda-setting topics are likely to emerge on the horizon.", "references": ["L. Agostinho, G. Feliciano, L. Olivi, E. Cardozo, and E. Guimaraes. 2011. A bio-inspired approach to provisioning of virtual resources in federated clouds. In Proceedings of the IEEE 9th International Conference on Dependable, Autonomic and Secure Computing. 598--604.", "Y. Ajiro and A. Tanaka. 2007. Improving packing algorithms for server consolidation. In Proceedings of the International Conference for the Computer Measurement Group, 399--406.", "E. Apostol, I. Baluta, A. Gorgoi, and V. Cristea. 2011. Efficient manager for virtualized resource provisioning in cloud systems. In Proceedings of the IEEE International Conference on Intelligent Computer Communication and Processing. 511--517."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788397"}, {"title": "KSGM: Keynode-driven Scalable Graph Matching", "authors": ["Xilun Chen\n,", "K. Selçuk Candan\n,", "Maria Luisa Sapino\n,", "Paulo Shakarian"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUnderstanding how a given pair of graphs align with each other (also known as the graph matching problem) is a critical task in many search, classification, and analysis applications. Unfortunately, the problem of maximum common subgraph isomorphism between two graphs is a well known NP-hard problem, rendering it impractical to search for exact graph alignments. While there are several heuristics, most of these analyze and encode global and local structural information for every node of the graph and then rank pairs of nodes across the two graphs based on their structural similarities. Moreover, many algorithms involve a post-processing (or refinement) step which aims to improve the initial matching accuracy. In this paper we note that the expensive refinement phase of graph matching algorithms is not practical in any application where scalability is critical. It is also impractical to seek structural similarity between all pairs of nodes. We argue that a more practical and scalable solution is to seek structural keynodes of the input graphs that can be used to limit the amount of time needed to search for alignments. Naturally, these keynodes need to be selected carefully to prevent any degradations in accuracy during the alignment process. Given this motivation, in this paper, we first present a structural keynode extraction (SKE) algorithm and then use structural keynodes obtained during off-line processing for keynode-driven scalable graph matching (KSGM). Experiments show that the proposed keynode-driven scalable graph matching algorithms produce alignments that are as accurate as (or better than) the state-of-the-art algorithms, with significantly faster online executions.", "references": ["http://networkx.github.io/", "http://snap.stanford.edu/index.html", "X. Bai, H. Yu, and E. R. Hancock. Graph matching using spectrament. ICPR 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806577"}, {"title": "Query Workloads for Data Series Indexes", "authors": ["Kostas Zoumpatianos\n,", "Yin Lou\n,", "Themis Palpanas\n,", "Johannes Gehrke"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nData series are a prevalent data type that has attracted lots of interest in recent years. Most of the research has focused on how to efficiently support similarity or nearest neighbor queries over large data series collections (an important data mining task), and several data series summarization and indexing methods have been proposed in order to solve this problem. Nevertheless, up to this point very little attention has been paid to properly evaluating such index structures, with most previous work relying solely on randomly selected data series to use as queries (with/without adding noise). In this work, we show that random workloads are inherently not suitable for the task at hand and we argue that there is a need for carefully generating a query workload. We define measures that capture the characteristics of queries, and we propose a method for generating workloads with the desired properties, that is, effectively evaluating and comparing data series summarizations and indexes. In our experimental evaluation, with carefully controlled query workloads, we shed light on key factors affecting the performance of nearest neighbor search in large data series collections.", "references": ["R. Agrawal, C. Faloutsos, and A. Swami. Efficient similarity search in sequence databases. In FODO, 1993.", "I. Assent, R. Krieger, F. Afschari, and T. Seidl. The ts-tree: Efficient time series search and retrieval. In EDBT, 2008.", "S. D. Bay, D. Kibler, M. J. Pazzani, and P. Smyth. The uci kdd archive of large data sets for data mining research and experimentation. In SIGKDD Explorations, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783382"}, {"title": "Preprocessing Code Example For Searching", "authors": ["Duong Nhu\n,", "Caslon Chua"], "publication": "ASWEC ' 15 Vol. II: Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference", "abstract": "ABSTRACT\nStudents who start learning to program often find it difficult to acquire programming concepts. Among all teaching materials, code example is favoured most by both teachers and students. A number of code examples can be found in on-line resources, such as TutorialsPoint and W3School, however, there is not much work on standardising good code examples. This paper proposed a process to prepare good code example for searching. First, we will define characteristics for good code example, followed by a set of preprocessing methods for extracting and processing these characteristics for searching. To evaluate the perceived usefulness of the extracted and processed characteristics for searching, we devised a questionnaire to evaluate the perceived usefulness of the extracted and processed characteristics that will be used in the development of the code example search engine. The positive outcome of this preliminary work enabled us to start work on the code example search system to be used by novice programmers to learn programming.", "references": ["Winslow, L. E. 1996. Programming pedagogy - a psychological overview. ACM SIGCSE Bulletin. 28, 3 (1996), 17--22.", "Lahtinen, E., Ala-Mutka, K. and Järvinen, H.-M. 2005. A study of the difficulties of novice programmers. ACM SIGCSE Bulletin. 37, 3 (2005), 14.", "Sweller, J., van Merrienboer, J. J. G. and Paas, F. G. W. C. 1998. Cognitive Architecture and Instructional Design. Educational Psychology Review. 10, 3 (1998), 251--296."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811681.2811687"}, {"title": "Analysis Techniques of Food Nutrient Data", "authors": ["Chun-Hsin Wu\n,", "Chih-Hung Hung\n,", "Jung-Chin Ke"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nDietary intake is important to health. For nutritional assessment, food compositions are important reference data. Although food composition data are maintained by many countries, part of them are often incomplete or inaccurate. This paper presents practical techniques to process and normalize food nutrient data, and further propose computational methods based on vector space models to evaluate similarity of foods and assess nutrition of diets automatically. The results show that the missing data and the raw data must be normalized to obtain acceptable similarity precision, and the proposed approaches are potentially very useful tools for nutrition studies and food engineering.", "references": ["U.S. Department of Agriculture. Human nutrition national program. http://www.ars.usda.gov/research/programs/programs.htm?NP_CODE=107", "U.S. Nutrient Data Laboratory. Generation of food composition data for U.S. foods (Project Number: 1235-52000-038-08). http://www.ars.usda.gov/research/projects/projects.htm?ACCN_NO=403495", "U.S. Nutrient Data Laboratory. The USDA national nutrient databank: acquisition, evaluation and compilation of food composition data (Project Number: 1235-52000-038-00). http://www.ars.usda.gov/research/projects/projects.htm?ACCN_NO=404226"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818873"}, {"title": "Integrative data analysis of multi-platform cancer data with a multimodal deep learning approach", "authors": ["Muxuan Liang\n,", "Zhizhong Li\n,", "Ting Chen\n,", "Jianyang Zeng"], "publication": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "abstract": "Abstract\nIdentification of cancer subtypes plays an important role in revealing useful insights into disease pathogenesis and advancing personalized therapy. The recent development of high-throughput sequencing technologies has enabled the rapid collection of multi-platform genomic data (e.g., gene expression, miRNA expression, and DNA methylation) for the same set of tumor samples. Although numerous integrative clustering approaches have been developed to analyze cancer data, few of them are particularly designed to exploit both deep intrinsic statistical properties of each input modality and complex cross-modality correlations among multi-platform input data. In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data. In our integrative clustering framework, relationships among inherent features of each single modality are first encoded into multiple layers of hidden variables, and then a joint latent model is employed to fuse common features derived from multiple input modalities. A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner. Tests on two available cancer datasets show that our integrative data analysis approach can effectively extract a unified representation of latent features to capture both intra- and cross-modality correlations, and identify meaningful disease subtypes from multi-platform cancer data. In addition, our approach can identify key genes and miRNAs that may play distinct roles in the pathogenesis of different cancer subtypes. Among those key miRNAs, we found that the expression level of miR-29a is highly correlated with survival time in ovarian cancer patients. These results indicate that our multimodal DBN based data analysis approach may have practical applications in cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.", "references": ["R. Shen, A. B. Olshen, and M. Ladanyi, \"Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis,\" Bioinformatics, vol. 25, no. 22, pp. 2906--2912, 2009.", "S. Zhang, C.-C. Liu, W. Li, H. Shen, P. W. Laird, and X. J. Zhou, \"Discovery of multi-dimensional modules by integrative analysis of cancer genomic data,\" Nucleic Acids Res., vol. 40, no. 19, pp. 9379--9391, 2012.", "J. A. Hartigan and M. A. Wong, \"Algorithm as 136: A k-means clustering algorithm,\" J. Royal Statist. Soc. Ser. C (Appl. Statist.), vol. 28, no. 1, pp. 100--108, 1979."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TCBB.2014.2377729"}, {"title": "Statistically Significant Detection of Linguistic Change", "authors": ["Vivek Kulkarni\n,", "Rami Al-Rfou\n,", "Bryan Perozzi\n,", "Steven Skiena"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe propose a new computational approach for tracking and detecting statistically significant linguistic shifts in the meaning and usage of words. Such linguistic shifts are especially prevalent on the Internet, where the rapid exchange of ideas can quickly change a word's meaning. Our meta-analysis approach constructs property time series of word usage, and then uses statistically sound change point detection algorithms to identify significant linguistic shifts. We consider and analyze three approaches of increasing complexity to generate such linguistic property time series, the culmination of which uses distributional characteristics inferred from word co-occurrences. Using recently proposed deep neural language models, we first train vector representations of words for each time period. Second, we warp the vector spaces into one unified coordinate system. Finally, we construct a distance-based distributional time series for each word to track its linguistic displacement over time.\nWe demonstrate that our approach is scalable by tracking linguistic change across years of micro-blogging using Twitter, a decade of product reviews using a corpus of movie reviews from Amazon, and a century of written books using the Google Book Ngrams. Our analysis reveals interesting patterns of language usage change commensurate with each medium.", "references": ["R. P. Adams and D. J. MacKay. Bayesian online change-point detection. Cambridge, UK, 2007.", "R. Al-Rfou, B. Perozzi, and S. Skiena. Polyglot: Distributed word representations for multilingual nlp. In CoNLL, 2013.", "M. Basseville and I. V. Nikiforov. Detection of Abrupt Changes: Theory and Application. Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1993."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741627"}, {"title": "A Streaming Real-Time Web Observatory Architecture for Monitoring the Health of Social Machines", "authors": ["Ramine Tinati\n,", "Xin Wang\n,", "Ian Brown\n,", "Thanassis Tiropanis\n,", "Wendy Hall"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOver the past years, streaming Web services have become popular, with many of the top Web platforms now offering near real-time streams of user and machine activity. In light of this, Web Observatories now are faced with the challenge of being able to process and republish real-time, big data, Web streams, whilst maintaining access control and data consistency. In this paper we describe the architecture used in the Southampton Web Observatory to harvest, process, and serve real-time Web streams.", "references": ["Aniello, L., Baldoni, R., and Querzoni, L. Adaptive online scheduling in storm. In Proceedings of the 7th ACM International Conference on Distributed Event-based Systems, DEBS '13, ACM (2013), 207--218.", "Artikis, A., Etzion, O., Feldman, Z., and Fournier, F. Event processing under uncertainty. In Proceedings of the 6th ACM International Conference on Distributed Event-Based Systems, DEBS '12, ACM (2012), 32--43.", "Brown, I. C., Hall, W., and Harris, L. Towards a taxonomy for web observatories. In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, WWW Companion '14, International World Wide Web Conferences Steering Committee (Republic and Canton of Geneva, Switzerland, 2014), 1067--1072."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743977"}, {"title": "A Convolutional Click Prediction Model", "authors": ["Qiang Liu\n,", "Feng Yu\n,", "Shu Wu\n,", "Liang Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe explosion in online advertisement urges to better estimate the click prediction of ads. For click prediction on single ad impression, we have access to pairwise relevance among elements in an impression, but not to global interaction among key features of elements. Moreover, the existing method on sequential click prediction treats propagation unchangeable for different time intervals. In this work, we propose a novel model, Convolutional Click Prediction Model (CCPM), based on convolution neural network. CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression. Experiment results on two public large-scale datasets indicate that CCPM is effective on click prediction.", "references": ["O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, and G. Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In ICASSP, 2012.", "N. Kalchbrenner, E. Grefenstette, and P. Blunsom. A convolutional neural network for modelling sentences. In ACL, 2014.", "A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806603"}, {"title": "A multi-layer markup language for geospatial semantic annotations", "authors": ["Ludovic Moncla\n,", "Mauro Gaio"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nIn this paper we describe a markup language for semantically annotating raw texts. We define a formal representation of text documents written in natural language that can be applied for the task of Named Entities Recognition and Spatial Role Labeling.\nThe proposal relies on a multi-layer annotation process based on a core generic layer, which can be freely adapted into more specific layers depending on the intended goal. Our markup language is based on the TEI Guidelines1 to propose a generic and extensible markup language. This language is particularly dedicated for the text mining task and ready to use to be layered with more semantic relationships between elements of the text.\nWe show the feasibility of this proposal from a generic annotation of texts describing itineraries toward a geospatial semantic annotation.", "references": ["A. Abeillé, L. Clément, and F. Toussenel. Building a treebank for french. In A. Abeillé, editor, Treebanks, number 20 in Text, Speech and Language Technology, pages 165--187. Springer Netherlands, Jan. 2003.", "M. Egenhofer and R. Franzosa. Point-set topological spatial relations. International journal for Geographical Information Systems, 5(2):161--174, 1991.", "A. U. Frank. Qualitative spatial reasoning with cardinal directions. In Proc. of the Seventh Austrian Conference on Artificial Intelligence, pages 157--167. Springer, 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837700"}, {"title": "Visualising spatial web service growth across Europe", "authors": ["Sampo Savolainen\n,", "Ilkka Rinne"], "publication": "AcademicMindTrek '15: Proceedings of the 19th International Academic Mindtrek Conference", "abstract": "ABSTRACT\nService quality is essential for broadening the adoption and use of data via APIs and online services. The success of any software that use these services will be dependent on the quality the services it uses. Web services are provided by a myriad of different organisations and service providers with different resources and technical capabilities, which inevitably raises the question whether a developer interested in the services can trust them or not. Availability of such services is a crucial factor in service quality: it measures how reliable a service is under normal conditions. If a service is not available, the service is of no use regardless of how good quality data it may serve when functional. Therefore it can be argued that availability is the most important measure of service quality. It is however a non-trivial task to determine the level of availability.\nThis paper revolves around the availability of spatial web services in Europe. This kind of services are used by thousands of map applications and they serve as the bedrock of INSPIRE, which is a Europe-wide effort to harmonize both spatial data and how this data is accessed. Spatial web services are implemented using widely adopted standard protocols that make data sharing and interoperability between applications straightforward.\nSpatineo has released a web application that visualises the availability of spatial web services in Europe. The Service Map showcases countries and organisations in Europe that provide reliable services and highlights areas that need attention. The availability data is collected by Spatineo who specializes in quality of service and the improvement of European spatial data infrastructure.", "references": ["Commission Regulation (EC) No 976/2009 of 19 October 2009 implementing Directive 2007/2/EC of the European Parliament and of the Council as regards the Network Services."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818187.2818274"}, {"title": "Incremental Sampling of Query Logs", "authors": ["Ricardo Baeza-Yates"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe introduce a simple technique to generate incremental query log samples that mimics well the original query distribution. In this way, editorial judgments for new queries can be consistently added to previous judgments. We also review the problem of how to choose the sample size depending on the types of queries that need to be detected as well as the conditions needed to get a good sample.", "references": ["A. Agresti and B.A. Coull. Approximate is better than \"exact\" for interval estimation of binomial proportions. The American Statistician 52(2):119--126, 1998.", "R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval: the concepts and technology behind search (2nd ed.). Pearson Education, 2011.", "R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras and F. Silvestri. Design Trade-Offs for Search Engine Caching. (special issue in query log analysis). ACM Transactions on the Web, 2(4), Article 4, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776780"}, {"title": "Multi-modal video concept detection for scalable logging of pre-production broadcast content", "authors": ["C. Gray\n,", "J. Collomosse\n,", "J. Thorpe\n,", "A. Turner"], "publication": "CVMP '15: Proceedings of the 12th European Conference on Visual Media Production", "abstract": "ABSTRACT\nWe present a scalable semantic video concept detection framework, applied to automated metadata annotation (video logging) in a broadcast production environment. Video logging demands both accurate and fast concept detection. Whilst research often focuses on the former, the latter is essential in practical scenarios where days of footage may be shot per broadcast episode and production is dependent on immediate availability of metadata. We present a hierarchical classification framework that delivers benefits to both through two contributions. First, a dynamic weighting scheme for combining video features from multiple modalities enabling higher accuracy detection rates over diverse production footage. Second, a hierarchical classification strategy that exploits ontological relationships between concepts to scale sub-linearly with the number of classes, yielding a real-time solution. We demonstrate an end-to-end production system incorporating chronological and semantic browsing with our detection framework. Demo video included.", "references": ["R. Arandjelović and A. Zisserman. Three things everyone should know to improve object retrieval. In Proc. Computer Vision and Pattern Recognition (CVPR), 2012.", "R. Arandjelović and A. Zisserman. All about VLAD. In Proc. Computer Vision and Pattern Recognition (CVPR), 2013.", "A. Bangham, K. Moravec, R. Harvey, and M. Fisher. Scale-space trees and applications as filters for stereo vision and image retrieval. In Proc. British Machine Vision Conference (BMVC), 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2824840.2824841"}, {"title": "Selective Domain Information Acquisition to Improve Segmentation Quality", "authors": ["Yinghui Yang\n,", "Zijie Qi\n,", "Hongyan Liu"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nIt has been well established that adding domain information about whether certain data objects (for example customers in customer segmentation application) should belong to the same segment can improve the quality of the segments. However, it can be expensive to acquire such domain knowledge. Consequently, we need to limit the number of constrains we acquire and more importantly maximize the effectiveness of these limited number of constraints we can acquire from the experts. Many of the constrained clustering methods randomly select constraints, which have been shown in our experiments to be ineffective. In this paper, we define the problem of identifying the most informative constraints. We propose an algorithm which generates the most informative constraints by maximizing the information gain from the constraints. We conducted a set of experiments on various data sets to compare our method with two other methods according to two measurements: the accuracy rate and the Vector Quantization Error (VQE), which is the objective function k-means clustering method minimizes. We illustrated that our approach not only achieves better accuracy rates, but also maintains low VQE values. Our results suggest that businesses can enhance their segmentation quality greatly by actively acquire the right type of domain information.", "references": ["Asuncion, A., and Newman, D. 2007. UCI machine learning repository.", "Bar-Hillel, A., Hertz, N. Shental, and Weinshall, D. 2005. Learning a mahalanobis metric from equivalence constraints. Journal of Machine Learning Research, 6, 937--965.", "Basu, S., Banerjee, A., and Mooney, R. J. 2004. Active semi-supervision for pairwise constrained clustering. In SDM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781575"}, {"title": "Evaluating popularity data for relevance ranking in library information systems", "authors": ["Kim Plassmeier\n,", "Timo Borst\n,", "Christiane Behnert\n,", "Dirk Lewandowski"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nIn this poster, we present our work in progress to develop a relevance model for library information systems, which takes non-textual factors into account. Here we focus on popularity data like citation or usage data. These data contain various biases that need to be corrected so as not to degrade the performance of the relevance model. Further, the different data might be to some extent incommensurable. We make use of the Characteristic Scores and Scales method to achieve two goals: first, remove biases from the raw data, and second, establish a common scale for the different data to support weighing the data against each other.", "references": ["Antelman, K., Lynema, E., & Pace, A. K. (2006). Toward a twenty-first century library catalogue. Information Technology & Libraries, 25(3), 128--139.", "Bornmann, L., & Daniel, H.-D. (2008). What do citation counts measure? A review of studies on citing behavior. Journal of Documentation, 64(1), 45--80.", "Bornmann, L., Leydesdorff, L., & Mutz, R. (2013). The use of percentiles and percentile rank classes in the analysis of bibliometric data: Opportunities and limits. Journal of Informetrics, 7(1), 158--165."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857195"}, {"title": "Teaching Information Systems for Computer Graduation Courses: a report experience using a practical ICT approach", "authors": ["Edison Ishikawa\n,", "Celia Ghedini Ralha"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nTeaching Information Systems (IS) for computer students, with courses very related to Information and Communications Technology (ICT) requires adapting the subject with a different approach. To achieve this goal, this paper presents a methodology that exemplifies the application of IS knowledge inside ICT organizations or ICT departments. The content used and its importance were evaluated applying a questionnaire to the students. Responses showed that this method increased students' IS subject understanding and the desire to apply IS knowledge in their professional activities.", "references": ["Amazon. Amazon Web Services. Disponível em http://aws.amazon.com/, consultado em fevereiro de 2015, 2015.", "Astah. Astah - UML Modeler. Disponível em http://astah.net/editions/community, consultado em fevereiro de 2015, 2015.", "I. I. S. Audit and C. Association. COBIT - Control Objectives for Information and Related Technology. Disponível em http://www.isaca.org/cobit, consultado em fevereiro de 2015, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814150"}, {"title": "Product news summarization for competitor intelligence using topic identification and artificial bee colony optimization", "authors": ["Swapnajit Chakraborti\n,", "Shubhamoy Dey"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nWith proliferation of web content, nowadays, various information about companies have become publicly available online. These information are mostly text documents such as news, reports, which can provide useful insight into various aspects about corporations. In order to extract useful information from this huge and diverse collection of texts, appropriate state-of-the-art text mining techniques are necessary. In this paper, a novel multi-document extractive text summarization technique, based on topic identification and artificial bee colony optimization, is described which can be used by companies for extracting important facts from the product-specific news items of their competitors and subsequently use them as one of the inputs for strategic business decision making. The results presented in this paper are based on the corpus created by collecting news items for a specific consumer electronics company from authentic news sites available on the internet. The quality of summary generated using this approach is found to be better on many aspects as compared to summaries generated by a well-known benchmark summarizer called MEAD.", "references": ["Alguliev, R. M. (2011). Sentence selection for generic document summarization using an adaptive differential evolution algorithm. Swarm and Evolutionary Computations, 213--222.", "Alguliev, R. M. (2014). Multiple documents summarization based on evolutionary optimization algorithm. Expert Systems with Applications, 1675--1689.", "Baxendale, P. (1958). Machine-made index for technical literature - an experiment. IBM Journal of Research Development, 354--361."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811465"}, {"title": "Choreography in the Mapping of New Instruments", "authors": ["Alon Ilsar\n,", "Andrew Johnston"], "publication": "C&C '15: Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition", "abstract": "ABSTRACT\nThis paper discusses the use of choreography in mapping sound to movement in the field of new instrument design. Using the analogy of the drum kit player utilising all four limbs in a similar fashion to a dancer, we investigate the notion of mapping movement to prerecorded sound in that order, as opposed to sound mapped to movement. In this way the mapping process becomes a type of \"choreography\", where a particular piece of music is learnt to be played as the mapping is determined. We outline three main factors which must be balanced within the mapping process. We present findings from the development of a new gestural interface for electronic percussionists and several collaborations that this interface has been used in.", "references": ["Maes, P.-J., Leman, M., Lesaffre, M., Demey, M., and Moelants, D. From Expressive Gesture to Sound, Journal on Multimodal User Interfaces, 3, 1--2 (2010), 67--78.", "Arias, R. I Know It's Only Noise but I like It: Scattered Notes on the Pleasures of Experimental Improvised Music?, Leonardo Music Journal, 12 (2002), 31--32.", "Fels, S. Designing for Intimacy: Creating New Interfaces for Musical Expression, Proc. IEEE 2004, 92,"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757226.2764543"}, {"title": "A Probabilistic Model for Using Social Networks in Personalized Item Recommendation", "authors": ["Allison J.B. Chaney\n,", "David M. Blei\n,", "Tina Eliassi-Rad"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPreference-based recommendation systems have transformed how we consume media. By analyzing usage data, these methods uncover our latent preferences for items (such as articles or movies) and form recommendations based on the behavior of others with similar tastes. But traditional preference-based recommendations do not account for the social aspect of consumption, where a trusted friend might point us to an interesting item that does not match our typical preferences. In this work, we aim to bridge the gap between preference- and social-based recommendations. We develop social Poisson factorization (SPF), a probabilistic model that incorporates social network information into a traditional factorization method; SPF introduces the social aspect to algorithmic recommendation. We develop a scalable algorithm for analyzing data with SPF, and demonstrate that it outperforms competing methods on six real-world datasets; data sources include a social reader and Etsy.", "references": ["X. Amatriain, P. Castells, A. de Vries, and C. Posse. Workshop on recommendation utility evaluation: Beyond RMSE. In RecSys, pages 351--352, 2012.", "R. Andersen, C. Borgs, J. Chayes, U. Feige, A. Flaxman, A. Kalai, V. Mirrokni, and M. Tennenholtz. Trust-based recommendation systems: an axiomatic approach. In WWW, pages 199--208, 2008.", "B. C. Arnold, E. Castillo, and J. M. Sarabia. Conditional specification of statistical models. Springer, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800193"}, {"title": "Semi-supervised Hashing with Semantic Confidence for Large Scale Visual Search", "authors": ["Yingwei Pan\n,", "Ting Yao\n,", "Houqiang Li\n,", "Chong-Wah Ngo\n,", "Tao Mei"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSimilarity search is one of the fundamental problems for large scale multimedia applications. Hashing techniques, as one popular strategy, have been intensively investigated owing to the speed and memory efficiency. Recent research has shown that leveraging supervised information can lead to high quality hashing. However, most existing supervised methods learn hashing function by treating each training example equally while ignoring the different semantic degree related to the label, i.e. semantic confidence, of different examples. In this paper, we propose a novel semi-supervised hashing framework by leveraging semantic confidence. Specifically, a confidence factor is first assigned to each example by neighbor voting and click count in the scenarios with label and click-through data, respectively. Then, the factor is incorporated into the pairwise and triplet relationship learning for hashing. Furthermore, the two learnt relationships are seamlessly encoded into semi-supervised hashing methods with pairwise and listwise supervision respectively, which are formulated as minimizing empirical error on the labeled data while maximizing the variance of hash bits or minimizing quantization loss over both the labeled and unlabeled data. In addition, the kernelized variant of semi-supervised hashing is also presented. We have conducted experiments on both CIFAR-10 (with label) and Clickture (with click data) image benchmarks (up to one million image examples), demonstrating that our approaches outperform the state-of-the-art hashing techniques.", "references": ["C. F. Cadieu, H. Hong, D. Yamins, N. Pinto, N. J. Majaj, and J. J. DiCarlo. The neural representation benchmark and its evaluation on brain and machine. In ICLR, 2013.", "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013.", "A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In VLDB, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767725"}, {"title": "Beyond Page Objects: Testing Web Applications with State Objects", "authors": ["Arie van Deursen"], "publication": "Queue", "abstract": "Abstract\nUse states to drive your tests", "references": ["AngularJS. ngInclude directive; https://docs.angularjs.org/api/ng/directive/ngInclude.", "Antoniol, G., Briand, L.C., Di Penta, M., Labiche, Y. 2002. A case study using the round-trip strategy for state-based class testing. Proceedings of the 13th International Symposium on Software Reliability Engineering (ISSRE). IEEE, pp. 269-279.", "Binder, R. V. 1999. Testing Object-oriented Systems. Addison-Wesley."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791301.2793039"}, {"title": "Experiments with a Venue-Centric Model for Personalisedand Time-Aware Venue Suggestion", "authors": ["Romain Deveaud\n,", "M-Dyaa Albakour\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLocation-based social networks (LBSNs), such as Foursquare, fostered the emergence of new tasks such as recommending venues a user might wish to visit. In the literature, recommending venues has typically been addressed using user-centric recommendation approaches relying on collaborative filtering techniques. Such approaches not only require many users with detailed profiles to be effective, but they also cannot recommend venues to users who are not actually members of the LBSN. In contrast, in this paper, we introduce a venue-centric yet personalised probabilistic approach that suggests personalised and popular venues for users to visit in the near future. In our approach, we probabilistically incorporate two components, a popularity component for predicting the popularity of a venue at a given point in time, as estimated from the attendance of the venue in the LBSN (i.e. number of check-ins), and a personalisation component for identifying its interestingness with respect to the estimated preferences of the user. The popularity of each venue is predicted using time series forecasting models that are trained on the recent attendance trends of the venue, while the users' interests are modelled from the entity pages that they like on Facebook. Using three major cities, we conduct a user study to evaluate the effectiveness of the two components of our approach in suggesting venues for different types of users at different times of the day. Our experimental results show that an approach that combines the popularity and personalisation components is able to consistently outperform the recommendation service of the leading Foursquare LBSN. We also find that combining popularity and personalisation is effective for both new visitors and residents, while former visitors prefer popular venues.", "references": ["M.-D. Albakour, C. Macdonald, and I. Ounis. Identifying Local Events by Using Microblogs as Social Sensors. In Proc. of OAIR, 2013.", "G. Amati, E. Ambrosi, M. Bianchi, C. Gaibisso, and G. Gambosi. FUB, IASI-CNR and Univ. of Tor Vergata at TREC 2007 Blog Track. In Proc. of TREC, 2007.", "J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and Preference-aware Recommendation Using Sparse Geo-social Networking Data. In Proc. of SIGSPATIAL, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806484"}, {"title": "Early Detection of Topical Expertise in Community Question Answering", "authors": ["David van Dijk\n,", "Manos Tsagkias\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe focus on detecting potential topical experts in community question answering platforms early on in their lifecycle. We use a semi-supervised machine learning approach. We extract three types of feature: (i) textual, (ii) behavioral, and (iii) time-aware, which we use to predict whether a user will become an expert in the longterm. We compare our method to a machine learning method based on a state-of-the-art method in expertise retrieval. Results on data from Stack Overflow demonstrate the utility of adding behavioral and time-aware features to the baseline method with a net improvement in accuracy of 26% for very early detection of expertise.", "references": ["E. Agichtein, C. Castillo, D. Donato, A. Gionis, and G. Mishne. Finding high-quality content in social media, with an application to community-based question answering. In WSDM '08, pages 183--194. ACM, 2008.", "A. Anderson, D. Huttenlocher, J. Kleinberg, and J. Leskovec. Steering user behavior with badges. In WWW '13, pages 95--106. ACM, 2013.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Foundations and Trends in Information Retrieval, 6 (2--3): 127--256, August 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767840"}, {"title": "Spatiotemporal Sequential Influence Modeling for Location Recommendations: A Gravity-based Approach", "authors": ["Jia-Dong Zhang\n,", "Chi-Yin Chow"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nRecommending to users personalized locations is an important feature of Location-Based Social Networks (LBSNs), which benefits users who wish to explore new places and businesses to discover potential customers. In LBSNs, social and geographical influences have been intensively used in location recommendations. However, human movement also exhibits spatiotemporal sequential patterns, but only a few current studies consider the spatiotemporal sequential influence of locations on users’ check-in behaviors. In this article, we propose a new gravity model for location recommendations, called LORE, to exploit the spatiotemporal sequential influence on location recommendations. First, LORE extracts sequential patterns from historical check-in location sequences of all users as a Location-Location Transition Graph (L2TG), and utilizes the L2TG to predict the probability of a user visiting a new location through the developed additive Markov chain that considers the effect of all visited locations in the check-in history of the user on the new location. Furthermore, LORE applies our contrived gravity model to weigh the effect of each visited location on the new location derived from the personalized attractive force (i.e., the weight) between the visited location and the new location. The gravity model effectively integrates the spatiotemporal, social, and popularity influences by estimating a power-law distribution based on (i) the spatial distance and temporal difference between two consecutive check-in locations of the same user, (ii) the check-in frequency of social friends, and (iii) the popularity of locations from all users. Finally, we conduct a comprehensive performance evaluation for LORE using three large-scale real-world datasets collected from Foursquare, Gowalla, and Brightkite. Experimental results show that LORE achieves significantly superior location recommendations compared to other state-of-the-art location recommendation techniques.", "references": ["Jie Bao, Yu Zheng, and Mohamed F. Mokbel. 2012. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proceedings of the 20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 199--208.", "Zaiben Chen, Heng Tao Shen, and Xiaofang Zhou. 2011. Discovering popular routes from trajectories. In Proceedings of the 27th IEEE International Conference on Data Engineering. 900--911.", "An-Jung Cheng, Yan-Ying Chen, Yen-Ta Huang, Winston H. Hsu, and Hong-Yuan Mark Liao. 2011. Personalized travel recommendation by mining people attributes from community-contributed photos. In Proceedings of the 19th ACM International Conference on Multimedia. 83--92."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786761"}, {"title": "Multi-Faceted Recall of Continuous Active Learning for Technology-Assisted Review", "authors": ["Gordon V. Cormack\n,", "Maura R. Grossman"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nContinuous active learning achieves high recall for technology-assisted review, not only for an overall information need, but also for various facets of that information need, whether explicit or implicit. Through simulations using Cormack and Grossman's TAR Evaluation Toolkit (SIGIR 2014), we show that continuous active learning, applied to a multi-faceted topic, efficiently achieves high recall for each facet of the topic. Our results assuage the concern that continuous active learning may achieve high overall recall at the expense of excluding identifiable categories of relevant information.", "references": ["M. Bagdouri, D. D. Lewis, and D. W. Oard. Sequential testing in classifier evaluation yields biased estimates of effectiveness. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 933--936, 2013.", "M. Bagdouri, W. Webber, D. D. Lewis, and D. W. Oard. Towards minimizing the annotation cost of certified text classification. In Proceedings of the 22nd ACM International Conference Information and Knowledge Management, pages 989--998, 2013.", "D. C. Blair. STAIRS redux: Thoughts on the STAIRS evaluation, ten years after. Journal of the American Society for Information Science, 47(1):4--22, Jan. 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767771"}, {"title": "The Impact of Sound Design on the Interpretation of Archive Silent Films. Meteora, (1924): A case study.", "authors": ["Christos A. Goussios\n,", "Eleni Gkolfinopoulou\n,", "Dimitra Margaritidou\n,", "Ioannis Sykovaris\n,", "Konstantinos Stathis"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis work focuses on the potential and impact that sound design can have or add on the interpretation of Archive Silent Films. An endeavor to discover linkage and possibilities between sound elements and emotions is attempted. Moreover sound design is presented as an expressive means in cinema nowadays. The Greek silent film Meteora (Dorizas, 1924), was used as the canvas for different approaches and applications of sound design, highlighting the unlimited possibilities of the image/sound narrative interconnections. It was also used for the performance of a multifaceted experiment between film school students, where there were two major fields of interest: memory-imagination-creation using sound elements and persuasion-impact-potential of an existing soundtrack. The students acted in two ways: as sound designers, sharing their imagination and as audience criticizing, arguing and discussing on an already-applied sound design. These fore mentioned actions, attempts and applications were part of the educational procedure for the teaching of Film Sound & Music in the School of Film Studies, Faculty of Fine Arts, Aristotle University of Thessaloniki (AUTh), Greece on spring semester 2014--2015.", "references": ["Blacking J., How Musical is Man, Greek translation, Athens, 1981.", "Chion M., Le son au cinéma, Greek translation, Athens, 2007.", "Early Cinema in the Balkans and the Near East, Beginnings to Interwar Period, International Conference, June 5-7, 2015, Athens, Greece http://filmiconjournal.com/conference/2015"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814909"}, {"title": "Chronos Acoes: Tool to Support Decision Making for Investor of the Stock Exchange", "authors": ["Tiberio Cesar Souza do Nascimento\n,", "Leonardo Cunha de Miranda"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nInvestors in the stock market employ various techniques of graphical analysis to assist in decision making about their investments. To facilitate the use of these techniques are developed tools able to process large volumes of data in order to present consolidated information to investors. However, most of these tools is complex to use for those who are beginners in this kind of market and therefore needs help to make more informed decisions to minimize the damage and maximize profits at the same time. In this context, this work presents the Chronos Acoes, a tool developed to support investors in making decision to purchasing or sale of assets on the BM and FBOVESPA, which is the main stock exchange of Brazil.", "references": ["Portal do Investidor. Disponível em: ¿http://www.portaldoinvestidor.gov.br¿. Acesso em: 03 mar. 2015.", "Bolsa Financeira: O que são ações?. Disponível em: ¿http://www.bolsafinanceira.com¿. Acesso em: 03 mar. 2015.", "ITU: Statistics. Disponível em: ¿http://www.itu.int/en/ITU-D/Statistics/Pages/stat/default.aspx¿. Acesso em: 03 mar. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814143"}, {"title": "Analyzing social media to characterize local HIV at-risk populations", "authors": ["Narendran Thangarajan\n,", "Nella Green\n,", "Amarnath Gupta\n,", "Susan Little\n,", "Nadir Weibel"], "publication": "WH '15: Proceedings of the conference on Wireless Health", "abstract": "ABSTRACT\nThe number of new HIV infections per year in the U.S. has remained stable at 50,000 since the 1990's. To improve epidemic control, we need more public health tools that are aimed at decreasing HIV transmission. Online social networks and their real-time communication capabilities are emerging as novel platforms for conducting epidemiological studies and recent research has outlined the feasibility of using Twitter to study HIV epidemiology. We propose a new method for identifying HIV at-risk populations using publicly available data from Twitter as an indicator of HIV risk. In this paper we take existing approaches further by introducing a new infrastructure to collect, classify, query and visualize these data, and we show the feasibility of identifying and characterizing HIV at-risk populations in the San Diego area at a finer level of granularity.", "references": ["Benjamin M Althouse, Yih Yng Ng, and Derek AT Cummings. Prediction of Dengue Incidence Using Search Query Surveillance. PLoS neglected tropical diseases, 5(8):e1258, 2011.", "Eiji Aramaki, Sachiko Maskawa, and Mizuki Morita. Twitter Catches the Flu: Detecting Influenza Epidemics using Twitter. In Proceedings of the conference on empirical methods in natural language processing, pages 1568--1576. Association for Computational Linguistics, 2011.", "John W Ayers, Kurt M Ribisl, and John S Brownstein. Tracking the Rise in Popularity of Electronic Nicotine Delivery Systems (Electronic Cigarettes) Using search Query Surveillance. American journal of preventive medicine, 40(4):448--453, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811780.2811923"}, {"title": "Context-Adaptive Matrix Factorization for Multi-Context Recommendation", "authors": ["Tong Man\n,", "Huawei Shen\n,", "Junming Huang\n,", "Xueqi Cheng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nData sparsity is a long-standing challenge for recommender systems based on collaborative filtering. A promising solution for this problem is multi-context recommendation, i.e., leveraging users' explicit or implicit feedback from multiple contexts. In multi-context recommendation, various types of interactions between entities (users and items) are combined to alleviate data sparsity of a single context in a collective manner. Two issues are crucial for multi-context recommendation: (1) How to differentiate context-specific factors from entity-intrinsic factors shared across contexts? (2) How to capture the salient phenomenon that some entities are insensitive to contexts while others are remarkably context-dependent? Previous methods either do not consider context-specific factors, or assume that a context imposes equal influence on different entities, limiting their capability of combating data sparsity problem by taking full advantage of multiple contexts.\nIn this paper, we propose a context-adaptive matrix factorization method for multi-context recommendation by simultaneously modeling context-specific factors and entity-intrinsic factors in a unified model. We learn an entity-intrinsic latent factor for every entity, and a context-specific latent factor for every entity in each context. Meanwhile, using a context-entity mixture parameter matrix we explicitly model the extent to which each context imposes influence on each entity. Experiments on two real scenarios demonstrate that our method consistently outperforms previous multi-context recommendation methods on all different sparsity levels.Such a consistent performance promotion forms the unique superiority of our method, enabling it to be a reliable model for multi-context recommendation.", "references": ["Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30--37, 2009.", "Noam Koenigstein, Gideon Dror, and Yehuda Koren. Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy. In Proceedings of the fifth ACM conference on Recommender systems, pages 165--172. ACM, 2011.", "Jiahui Liu, Peter Dolan, and Elin Rønby Pedersen. Personalized news recommendation based on click behavior. In Proceedings of the 15th international conference on Intelligent user interfaces, pages 31--40. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806503"}, {"title": "Improving tweet clustering using bigrams formed from word associations", "authors": ["Khadija Ali Vakeel\n,", "Shubhamoy Dey"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nIn this work we propose an innovative clustering algorithm for twitter data. In the the context of e-commerce, we use Apiori algorithm to form 2-gram association rules and cluster tweets using self organizing maps. Since tweets are relatively small, word association becomes all the more important in mining the information. To check if 2-grams formed using word associations, help in increasing clustering tendency we use Hopkins index. Tested on two separate datasets, of 200 and 10,000 tweets each related to the key word \"Amazon\", our results of the analysis show that there is improvement in the clustering tendency in both the datasets. This improvement in clustering tendency is potentially useful because customer grouping based on the tweets can help businesses determine new trends and identify customers with different sentiments.", "references": ["Agrawal, R., & Srikant, R. 1994, September. Fast algorithms for mining association rules. In Proc. 20th int. conf. very large data bases, VLDB (Vol. 1215, pp. 487--499).", "Chakrabarti, S. 2003. Mining the Web: Discovering knowledge from hypertext data. Morgan Kaufmann.", "Cheong, M., & Lee, V. 2010, August. A study on detecting patterns in twitter intra-topic user and message clustering. In Pattern Recognition (ICPR), 2010 20th International Conference on (pp. 3125--3128). IEEE."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811535"}, {"title": "Sourcing and trust: Twitter journalism in Ireland", "authors": ["Bahareh Rahmanzadeh Heravi\n,", "Natalie Harrower"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nSocial media, in particular Twitter, have been widely adopted in newsrooms for various purposes, including sourcing news leads and content, disseminating stories, soliciting user comments and driving traffic to corporate websites. This paper investigates the ways in which journalists use social media for sourcing and verification, and their attitudes towards social media in terms of trust. The analysis is built on a survey of journalists in Ireland conducted in 2013, which revealed that journalists in Ireland are heavy adopters of Twitter in their workflows, and in particular use social media for sourcing news leads and content. However, they are highly skeptical about the level of trust in social media. While this paper focuses on journalists in Ireland, the analysis of the relationship between trust, sourcing and verification reveals broader patterns about journalistic values, and how these values and practices operate in the new media landscape.", "references": ["Broersma, M., and Graham, T. 2012. Social Media as a Beat. Journalism Practice 6, 3, 403--419. DOI: 10.1080/17512786.2012.663626", "Bruno, N. 2011. Tweet First, Verify Later: How Real-Time Information is Changing the Coverage of Worldwide Crisis Events. Reuters Institute for the Study of Journalism. Oxford: University of Oxford.", "Bruns, A., and Highfield, T. 2012. Blogs, Twitter and Breaking News: The Produ-sage of Citizen Journalism. In: Lind RA (ed) Produsing Theory in a Digital World: The Intersection of Audiences and Production in Contemporary Theory. New York: Peter Lang Publishing Inc, 15--32."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789194"}, {"title": "Performance-optimized pages' architecture, navigation and images techniques for JQuery mobile sites", "authors": ["Andreas B. Gizas\n,", "Sotiris P. Christodoulou"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nMobile clients have been on the rise and Web sites are becoming more accessible by portable devices like tablets and smartphones. Mobile sites are built on standards such as HTML5, CSS3 and other modern web technologies like JQuery Mobile, and they run on any mobile platform with a modern, standards-compliant web browser. However, the performance and usability of such sites are often insufficient. In this work we study the performance of jQuery Mobile web sites, investigate how the synergy with other technologies or techniques could be used to improve performance and conclude to a set of design patterns and coding practices, focused on jQuery Mobile framework, with emphasis on the architecture of the pages, navigation system and images loading techniques.", "references": ["Aberdeen Group (2012), First Class Mobile Application Performance management, Research brief, Aug. 2012.", "Charland A. and LeRoux B. (2011). Mobile Application Development: Web vs. Native. Queue 9, 4, Pages 20 (April 2011)", "Doyle Matt (2014). Master Mobile Web Apps with jQuery Mobile (Fourth Edition). Elated Communications."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801995"}, {"title": "The Greek Music Dataset", "authors": ["Dimos Makris\n,", "Ioannis Karydis\n,", "Spyros Sioutas"], "publication": "EANN '15: Proceedings of the 16th International Conference on Engineering Applications of Neural Networks (INNS)", "abstract": "ABSTRACT\nMusic Information Research (MIR) requires musical data in order to test methods and to compare results. Greek music presents a number of unique characteristics that make its musical pieces distinct from popular tracks existing in currently available datasets, leading thus to the MIR requirement of Greek datasets. This work presents the Greek Music Dataset (GMD), a collection of musical information pertaining to Greek musical pieces. GMD is a significant extension of the Greek Audio Dataset by addition of symbolic information, both features and raw MIDI files, inclusion of multi-label manual genre categorisation of the content as well as by extension of the included tracks and balancing of the content in terms of genre. GMD includes information for 1400 Greek tracks, while for each track, the dataset includes pre-computed audio, lyrics & symbolic features for immediate use in MIR tasks, manually annotated labels pertaining to mood & genre styles of music, generic objective metadata, a manually selected MIDI file (available for 500 of the tracks) and a manually selected link to a performance / audio content in YouTube for further research.", "references": ["Factors in automatic musical genre classification of audio signals, 2003.", "S. Argamon, M. Šarić, and S. S. Stein. Style mining of electronic messages for multiple authorship discrimination: First results. In Proceedings of International Conference on Knowledge Discovery and Data Mining, pages 475--480, 2003.", "A. Berenzweig, B. Logan, D. P. W. Ellis, and B. P. W. Whitman. A large-scale evaluation of acoustic and subjective music-similarity measures. Comput. Music J., 28(2):63--76, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797143.2797175"}, {"title": "Evaluation of Consumer Shopping Behavior in M-Commerce and E-Commerce", "authors": ["Felipe Lemos\n,", "Luis Fabricio Goes"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper intends to anlyze why e-commerce is more popular than mobile commerce among internet users, despite the growth of mobile market. Through survey research carried out among 130 users, it was possible to infer that people use mobile devices along the day and prefer using computers than mobile devices in all phases of their purchases. The possible reasons of that behavior is related to safety conditions of m-commerce and errors that occur on eletronic transactions. Mobile devices are used auxialiry tool to check available products on market and to follow the track of requests already done.", "references": ["F. ALEXANDRINI. Perfil empresarial na prática do e-commerce: comercialização eletrónica. Universidade Federal de Santa Catarina, Centro Tecnológico. Programa de Pós-Graduação em Engenharia de Produção., 2000.", "C. ANGELO and J. SILVEIRA. Varejo Competitivo. Editora Atlas, 3th edition, 1999.", "C. ANGELO and J. SILVEIRA. Varejo Competitivo. Editora Atlas, 6th edition, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814080"}, {"title": "EMV-matchmaker: Emotional Temporal Course Modeling and Matching for Automatic Music Video Generation", "authors": ["Jen-Chun Lin\n,", "Wen-Li Wei\n,", "Hsin-Min Wang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper presents a novel content-based emotion-oriented music video (MV) generation system, called EMV-matchmaker, which utilizes the emotional temporal phase sequence of the multimedia content as a bridge to connect music and video. Specifically, we adopt an emotional temporal course model (ETCM) to respectively learn the relationship between music and its emotional temporal phase sequence and the relationship between video and its emotional temporal phase sequence from an emotion-annotated MV corpus. Then, given a video clip (or a music clip), the visual (or acoustic) ETCM is applied to predict its emotional temporal phase sequence in a valence-arousal (VA) emotional space from the corresponding low-level visual (or acoustic) features. For MV generation, string matching is applied to measure the similarity between the emotional temporal phase sequences of video and music. The results of objective and subjective experiments demonstrate that EMV-matchmaker performs well and can generate appealing music videos that can enhance the viewing and listening experience.", "references": ["P. N. Juslin and D. Västfjäll. Emotional responses to music: the need to consider underlying mechanisms. Behav Brain Sci., 2008.", "D. A. Shamma et al. MusicStory: a personalized music video creator. In ACM MM, 2005.", "O. Gillet et al. On the correlation of automatic audio and visual segmentations of music videos. IEEE TCSVT, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806359"}, {"title": "Cross-layer memory management for managed language applications", "authors": ["Michael R. Jantz\n,", "Forrest J. Robinson\n,", "Prasad A. Kulkarni\n,", "Kshitij A. Doshi"], "publication": "OOPSLA 2015: Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nPerformance and energy efficiency in memory have become critically important for a wide range of computing domains. However, it is difficult to control and optimize memory power and performance because these effects depend upon activity across multiple layers of the vertical execution stack. To address this challenge, we construct a novel and collaborative framework that employs object placement, cross-layer communication, and page-level management to effectively distribute application objects in the DRAM hardware to achieve desired power/performance goals. In this work, we describe the design and implementation of our framework, which is the first to integrate automatic object profiling and analysis at the application layer with fine-grained management of memory hardware resources in the operating system. We demonstrate the utility of our framework by employing it to more effectively control memory power consumption. We design a custom memory-intensive workload to show the potential of our approach. Next, we develop sampling and profiling-based analyses and modify the code generator in the HotSpot VM to understand object usage patterns and automatically determine and control the placement of hot and cold objects in a partitioned VM heap. This information is communicated to the operating system, which uses it to map the logical application pages to the appropriate DRAM ranks according to user-defined provisioning goals. We evaluate our framework and find that it achieves our test goal of significant DRAM energy savings across a variety of workloads, without any source code modifications or recompilations.", "references": ["M. Arnold, S. Fink, D. Grove, M. Hind, and P. F. Sweeney. A survey of adaptive optimization in virtual machines. Proceedings of the IEEE, 92(2):449–466, February 2005.", "Gaurav Banga, Peter Druschel, and Jeffrey C. Mogul. Resource containers: a new facility for resource management in server systems. In Proceedings of the third symposium on Operating systems design and implementation, OSDI ’99, pages 45–58. USENIX Association, 1999.", "Adam Belay, Andrea Bittau, Ali Mashtizadeh, David Terei, David Mazières, and Christos Kozyrakis. Dune: safe user-level access to privileged cpu features. In Proceedings of the 10th USENIX conference on Operating Systems Design and Implementation, OSDI’12, pages 335–348. USENIX Association, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814270.2814322"}, {"title": "Logo Recognition for Image-based Indoor Positioning Systems on Mobile Devices", "authors": ["Shiuan-Shiang Wang\n,", "Pei-Hsuan Tsai\n,", "Wei-Shuo Li"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nImage recognition techniques have been widely used in positioning systems in recent years. By recognizing the objects targeted by users' camera, one can decide the users' location. In this paper, a mobile indoor positioning system based on the image recognition techniques is implemented for shopping malls. We recognize the stores by their logos, and then use the location of the stores to locate the users. The image recognition method includes extracting local features from the image, calculating the Bag-of-Word structure through a pre-trained hierarchical clustering tree, and using cosine similarity to make the comparison between the training images and the query images. Though SIFT and SURF are the most extensively used local feature detectors and descriptors in the field, the limitations of mobile devices make them infeasible due to their high computational complexity. Moreover, both SIFT and SURF are patent-protected and are not free modules in OpenCV4Android, which will cause additional cost. Therefore, in this paper, we attempt to adopt features that exclude SIFT and SURF. By analyzing the precision and speed of pairwise mashup of feature detectors and descriptors, we target to find the most suitable pair of algorithms to be used on mobile devices. In this paper, the Global Mall at Hsinchu, Taiwan, is used as a scenario for the actual test.", "references": ["Agrawal, M., Konolige, K., and Blas, M. R. 2008. Censure: Center surround extremas for real-time feature detection and matching. In 10th European Conference on Computer Vision (Marseille, France, Oct. 12-18, 2008), 102--115.", "Bay, H., Ess, A., Tuytelaars, T., and Van G. L. 2008. Speeded-up robust features (SURF). Computer vision and image understanding, 110,3 (June 2008), 346--359.", "Calonder, M., Lepetit, V., Strecha, C., and Fua, P. 2010. Brief: Binary robust independent elementary features. In 11th European Conference on Computer Vision (Crete, Greece, Sep 5-11, 2010), 778--792."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818930"}, {"title": "A creative process to elicit contexts for context sensitive systems", "authors": ["Carlos Batista\n,", "Carla Silva"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nRequirements engineering is concerned with the identification of services (functional requirements) and restrictions (non-functional requirements) that a system must meet to satisfy the needs of its users. Requirements, in turn, are increasingly influenced by the context in which the systems are used. In the search for systems that are adaptable to the needs of users and to changes in the operating environment, context-sensitive systems arise. There is a need for a process to systematically elicit contexts to such systems. Given this scenario, we propose a process to elicit requirements and contextual information to be used during the requirements elicitation phase. The process is based on the Storytelling Group technique and also includes mind maps, the 5W1H dimensions (who, what, when, where, why and how) and the conditional dimension that are used to structure and organize the information collected; heuristics were defined to guide the identification of contexts from the information captured in the mind map structured with 5W1H + conditional. Moreover, the contextual information is analyzed and modeled using a specific framework for contexts. To illustrate the use of the process, a Smart Home system was used. The process was also applied in the context of an information technology company for evaluation and posterior refinement. Then, the effectiveness and easiness of use of the process were evaluated in an empirical study in an academic environment. The results obtained indicate that the process is useful and easy to use, bringing benefits to the development of context sensitive systems.", "references": ["ALI, R., DALPIAZ F., GIORGINI P. \"A goal-based framework for contextual requirements modeling and analysis\", In: Req. Eng. (2010) 15:439-458.", "AMES, V. D. B.\"As possibilidades de uso do software de análise qualitativa NVivo\". Vol. 1, n.2 ago. 2013. Disponível em:http://www.sociologiasplurais.ufpr.br/v1n2_artigo12.pdf", "BASILI, V. R.; CALDIERA, G.; ROMBACH, H. D. \"The goal question metric approach.\" Encyclopedia of software eng. 2.1994 (1994): 528-532."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814111"}, {"title": "Towards a computational processing of oral dialectal data", "authors": ["Nikitas N. Karanikolas\n,", "Eleni Galiotou\n,", "Dimitris Papazachariou\n,", "Konstantinos Athanasakos\n,", "George Koronakis\n,", "Angela Ralli"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this paper, we discuss issues concerning the computational processing of oral data in a unified framework for the exploitation of oral and written dialectal corpora. We describe the analysis and design of a multimedia database and software for storing and retrieving dialectal data, focusing on the subsystem of oral resources from three Greek dialects in Asia Minor. We discuss problems concerning the archiving and exploitation of such an oral corpus and we propose solutions.", "references": ["Anderson, J., Beavan, D., Kay, C. 2007. SCOTS: Scottish Corpus of Texts and Speech, In Creating and digitalizing Language Corpora Vol. 1, Beal J. (ed.), Palgrave McMillan Publication, pp. 17--34", "Anhøj, J. (2003), \"Generic Design of Web-Based Clinical Databases\", Journal Medical Internet Research, 4. DOI=http://dx.doi.org/10.2196/jmir.5.4.e27", "Barbiers, S. et al. 2006. Dynamic Syntactic Atlas of the Dutch dialects (DynaSAND). Amsterdam, Meertens Institute. http://www.meertens.knaw.nl/sand/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2801966"}, {"title": "Indexing bi-temporal windows", "authors": ["Chang Ge\n,", "Martin Kaufmann\n,", "Lukasz Golab\n,", "Peter M. Fischer\n,", "Anil K. Goel"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nBi-temporal databases support system (transaction) and application time, enabling users to query the history as recorded today and as it was known in the past. In this paper, we study windows over both system and application time, i.e., bi-temporal windows. We propose a two-dimensional index that supports one-time and continuous queries over fixed and sliding bi-temporal windows, covering static and streaming data. We demonstrate the advantages of the proposed index compared to the state-of-the-art in terms of query performance, index update overhead and space footprint.", "references": ["M. Al-Kateb et al. Temporal Query Processing in Teradata. In EDBT, 573--578, 2013.", "C.-H. Ang and K.-P. Tan. The Interval B-Tree. Inf. Process. Lett., 53(2):85--89, 1995.", "R. S. Barga et al. Consistent Streaming Through Time: A Vision for Event Stream processing. In CIDR, 363--374, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791373"}, {"title": "Web Usage Classification and Clustering Approach for Web Search Personalization", "authors": ["K. Vijayalakshmi\n,", "Sudarson Jena"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nThe increases in the information resources on the World Wide Web in search of the necessary information, as users navigate the Web with multiple sites. When user surfing the web which is a huge and complicated often miss their required searching pages. Web personalization is based on the Web usage logs of user's makes advantage of the knowledge required for the analysis of the content and structure of web sites promising to solve this problem by supporting one of the procedures. The search engine can affect the effectiveness of existing approaches, depending on the user profile, which is building more and more on the web pages or documents. In this paper, we propose an efficient and novel web search based on the individual classification and clustering method. The proposed approach classified the cluster data using frequent pattern mining and multilevel association rules for recurring relationship and cluster the web usage using Hierarchical methods with the navigating site and user interest for personalization. This approach process in advance to support the real time personalization and minimizes the cost reduction of preparation personalization resource in real time. The proposed approach is an effective personalization to the user's interest; in experimental research it has shown high precision measures.", "references": [". J. Lai and B. Soh, \"Personalized Web search results with profile comparisons,\" 3rd International Conf. on Information Technology and Applications-2005, Vol. -1, Pages. 573--576, 2005", ". M. Eirinaki and M. Vazirgiannis, \"Web Mining for Web Personalization\", ACM TOIT, 3(1):1--27, 2003.", ". M. Kutub, R. Prachetaa and M. Bedekar, \"User Web Search Behaviour,\" 3rd International Conference on Emerging Trends in Engineering and Technology, Pages. 549--554, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818677"}, {"title": "Improving Pseudo Relevance Feedback in the Divergence from Randomness Model", "authors": ["Dipasree Pal\n,", "Mandar Mitra\n,", "Samar Bhattacharya"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn an earlier analysis of Pseudo Relevance Feedback (PRF) models by Clinchant and Gaussier (2013), five desirable properties that PRF models should satisfy were formalised. Also, modifications to two PRF models were proposed in order to improve compliance with the desirable properties. These resulted in improved retrieval effectiveness. In this study, we introduce a sixth property that we believe PRF models should satisfy. We also extend the earlier exercise to Bo1, a standard PRF model. Experimental results on the robust, wt10g and gov2 datasets show that the proposed modifications yield improvements in effectiveness.", "references": ["G. Amati. Probability Models for Information Retrieval Based on Divergence from Randomness. U. Glasgow, 2003.", "G. Amati and C. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM TOIS, 20:357--389, 2002.", "S. Clinchant and É. Gaussier. A theoretical analysis of pseudo-relevance feedback models. In ICTIR '13, pages 6--13, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809494"}, {"title": "On Gapped Set Intersection Size Estimation", "authors": ["Chen Chen\n,", "Jianbin Qin\n,", "Wei Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThere exists considerable literature on estimating the cardinality of set intersection result. In this paper, we consider a generalized problem for integer sets where, given a gap parameter δ, two elements are deemed as matches if their numeric difference equals δ or is within δ. We call this problem the gapped set intersection size estimation (GSISE/), and it can be used to model applications in database systems, data mining, and information retrieval. We first distinguish two subtypes of the estimation problem: the point gap estimation and range gap estimation. We propose optimized sketches to tackle the two problems efficiently and effectively with theoretical guarantees. We demonstrate the usage of our proposed techniques in mining top-K related keywords efficiently, by integrating with an inverted index. Finally, substantial experiments based on a large subset of the ClueWed09 dataset demonstrate the efficiency and effectiveness of the proposed methods.", "references": ["N. Alon, Y. Matias, and M. Szegedy. The space complexity of approximating the frequency moments. In STOC, 1996.", "J. Barbay, A. López-Ortiz, and T. Lu. Faster adaptive set intersections for text searching. In WEA, 2006.", "J. Barbay, A. López-Ortiz, T. Lu, and A. Salinger. An experimental investigation of set intersection algorithms for text searching. Journal of Experimental Algorithmics, 14, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806438"}, {"title": "Heterogeneous data alignment for cross-media computing", "authors": ["Shikui Wei\n,", "Yunchao Wei\n,", "Lei Zhang\n,", "Zhenfeng Zhu\n,", "Yao Zhao"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nMassive data sets are generated everyday, and knowledge spreading trends to involve diverse media types and information sources. The new situation emerges some new challenging research problems: (1) How to bridge the heterogeneity and mine the shared information among cross-view representations? (2) How to build the semantic association among heterogeneous information objects. (3) How to fully explore the complementary information underlying heterogeneous information objects to cooperatively make decision. In fact, the core of these problems is to align heterogeneous data. In this paper, we first give a short introduction about heterogeneous data alignment. And then, two ongoing works in our group about heterogeneous data alignment are discussed, i.e., consistent pattern mining and modality-dependent cross-media retrieval. Finally, we conclude this paper and discuss some potential applications of heterogeneous data alignment.", "references": ["Y. Wei, Y. Zhao, Z. Zhu, S. Wei, and F. J. Y. S. Xiao, Yanhui. Modality-dependent cross-media retrieval. ACM Transactions on Intelligent Systems and Technology, 2015.", "L. Zhang, Y. Zhao, Z. Zhu, S. Wei, and X. Wu. Mining semantically consistent patterns for cross-view data. IEEE Transactions on Knowledge and Data Engineering, 26(11):2745--2758, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808576"}, {"title": "Perspectives of Bandwidth Sharing Schemes in Communication Systems with Blocking", "authors": ["Chia-Hung Wang\n,", "Mu-En Wu\n,", "Wei-Ho Chung"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper introduces two revenue management schemes to allocate the limited bandwidth from capitalistic and socialistic perspectives, respectively. Under the budget constraint, the revenue functions with the congestion costs are studied through the mathematical properties of the blocking probability with respect to the bandwidth allocation. In addition, we derive the monotone and convex relations between the allocated bandwidth and factors affecting the revenue functions. The analysis for the proposed two management schemes contributes managerial insights for different network managers while determining bandwidth allocation on their operating network.", "references": ["T. Aktaran-Kalayci and H. Ayhan. Sensitivity of optimal prices to system parameters in a steady-state service facility. Eur. J. Oper. Res., 193:120--128, 2009.", "E. Anderson, F. P. Kelly, and R. Steinberg. A contract and balancing mechanism for sharing capacity in a communication network. Manag. Sci., 52(1):39--53, 2006.", "D. Bertsimas, V. F. Farias, and N. Trichakis. The price of fairness. Oper. Res., 59(1):17--31, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818899"}, {"title": "Randomized stress-testing of link-time optimizers", "authors": ["Vu Le\n,", "Chengnian Sun\n,", "Zhendong Su"], "publication": "ISSTA 2015: Proceedings of the 2015 International Symposium on Software Testing and Analysis", "abstract": "ABSTRACT\nLink-time optimization (LTO) is an increasingly important and adopted modern optimization technology. It is currently supported by many production compilers, including GCC, LLVM, and Microsoft Visual C/C++. Despite its complexity, but because it is more recent, LTO is relatively less tested compared to the more mature, traditional optimizations. To evaluate and help improve the quality of LTO, we present the first extensive effort to stress-test the LTO components of GCC and LLVM, the two most widely-used production C compilers. In 11 months, we have discovered and reported 37 bugs (12 in GCC; 25 in LLVM). Developers have confirmed 21 of our bugs, and fixed 11 of them. Our core technique is differential testing and realized in the tool Proteus. We leverage existing compiler testing tools (Csmith and Orion) to generate single-file test programs and address two important challenges specific for LTO testing. First, to thoroughly exercise LTO, Proteus automatically transforms a single-file program into multiple compilation units and stochastically assigns each an optimization level. Second, for effective bug reporting, we develop a practical mechanism to reduce LTO bugs involving multiple files. Our results clearly demonstrate Proteus’s utility; we plan to make ours a continuous effort in validating link-time optimizers.", "references": ["ACE. SuperTest compiler test and validation suite. http://www.ace.nl/compiler/supertest.html.", "B. Anckaert, F. Vandeputte, B. Bus, B. Sutter, and K. Bosschere. Link-time optimization of ia64 binaries. In M. Danelutto, M. Vanneschi, and D. Laforenza, editors, Euro-Par 2004 Parallel Processing, volume 3149 of Lecture Notes in Computer Science, pages 284–291. Springer Berlin Heidelberg, 2004.", "A. Balestrat. CCG: A random C code generator. https://github.com/Merkil/ccg/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2771783.2771785"}, {"title": "Scientific Information Understanding via Open Educational Resources (OER)", "authors": ["Xiaozhong Liu\n,", "Zhuoren Jiang\n,", "Liangcai Gao"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nScientific publication retrieval/recommendation has been investigated in the past decade. However, to the best of our knowledge, few efforts have been made to help junior scholars and graduate students to understand and consume the essence of those scientific readings. This paper proposes a novel learning/reading environment, OER-based Collaborative PDF Reader (OCPR), that incorporates innovative scaffolding methods that can: 1. auto-characterize student emerging information need while reading a paper; and 2. enable students to readily access open educational resources (OER) based on their information need. By using metasearch methods, we pre-indexed 1,112,718 OERs, including presentation videos, slides, algorithm source code, or Wikipedia pages, for 41,378 STEM publications. Based on the computational information need, we use text mining and heterogeneous graph mining algorithms to recommend high quality OERs to help students better understand the scientific content in the paper. Evaluation results and exit surveys for an information retrieval course show that the OCPR system alone with the recommended OERs can effectively assist graduate students better understand the complex STEM publications. For instance, 78.42% of participants believe the OCPR system and recommended OERs can provide precise and useful information they need, while 78.43% of them believe the recommended OERs are close to exactly what they need when reading the paper. From OER ranking viewpoint, MRR, MAP and NDCG results prove that learning to rank and cold start solutions can efficiently integrate different text and graph ranking features.", "references": ["Javed A Aslam and Mark Montague. Models for metasearch. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 276--284. ACM, 2001.", "Shumeet Baluja, Rohan Seth, D Sivakumar, Yushi Jing, Jay Yagnik, Shankar Kumar, Deepak Ravichandran, and Mohamed Aly. Video suggestion and discovery for youtube: taking random walks through the view graph. In Proceedings of the 17th international conference on World Wide Web, pages 895--904. ACM, 2008.", "James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. The youtube video recommendation system. In Proceedings of the fourth ACM conference on Recommender systems, pages 293--296. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767750"}, {"title": "Computationally Supported Collection-level Descriptions in Large Heterogeneous Metadata Aggregations", "authors": ["Unmil P. Karadkar\n,", "Karen Wickett\n,", "Madhura Parikh\n,", "Richard Furuta\n,", "Joshua Sheehy\n,", "Meghanath Reddy Junnutula\n,", "Jeremy Tzou"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe Computational Collection Description project is developing mechanisms for generating field-specific collection-level descriptors from item values. Using the Digital Public Library of America (DPLA) as a sample data set, we describe a flexible, extensible architecture for processing field-level values, an augmented Collection class to record the generated metadata, and our early results of enhancements for a DPLA collection.", "references": ["Bourdon, F., Catapano, T., McDonough, J., et al. EAD 2002 Schema - EAD Official Site. 2002. http://www.loc.gov/ead/eadschema.html.", "Digital Public Library of America. Metadata Application Profile, Version 3. 2014. http://dp.la/info/wp-content/uploads/2013/04/DPLA-MAP-V3.1--2.pdf.", "Dunn, H. Collection Level Description - the Museum Perspective. D-Lib Magazine 6, 2000. http://www.dlib.org/dlib/september00/dunn/09dunn.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756970"}, {"title": "DocRicher: An Automatic Annotation System for Text Documents Using Social Media", "authors": ["Qiang Hu\n,", "Qi Liu\n,", "Xiaoli Wang\n,", "Anthony K.H. Tung\n,", "Shubham Goyal\n,", "Jisong Yang"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nWe demonstrate a system, DocRicher, to enrich a text document with social media, that implicitly reference certain passages of it. The aim is to provide an automatic annotation interface to satisfy users' information need, without cumbersome queries to traditional search engines. The system consists of four components: text analysis, query construction, data assignment, and user feedback. Through text analysis, the system decomposes a text document into appropriate topical passages, of which each is represented using detected key phrases. By submitting combinations of these phrases as queries to social media systems, the relevant results are used to suggest new annotations, that are linked to the corresponding passages. We have built a user-friendly visualization tool for users to browse automatically recommended annotations on their reading documents. Users are either allowed to rate a recommended annotation by accepting it or not; or add a new annotation by manually highlighting texts and adding personal comments. Both these annotations are regarded as the ground truth to derive new queries for retrieving more relevant contents. We also apply data fusion to merge the query results from various contexts and retain most relevant ones.", "references": ["R. Agrawal, S. Gollapudi, A. Kannan, and K. Kenthapadi. Similarity search using concept graphs. In CIKM. ACM Association for Computing Machinery, November 2014.", "R. Angheluta, R. D. Busser, and M.-F. Moens. The use of topic segmentation for automatic summarization. In Workshop on Text Summarization in Conjunction with the ACL, pages 11--12, 2002.", "L. Carroll. Evaluating hierarchical discourse segmentation. ACL, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735379"}, {"title": "Multi-view Latent Hashing for Efficient Multimedia Search", "authors": ["Xiaobo Shen\n,", "Fumin Shen\n,", "Quan-Sen Sun\n,", "Yun-Hao Yuan"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHashing techniques have attracted broad research interests in recent multimedia studies. However, most of existing hashing methods focus on learning binary codes from data with only one single view, and thus cannot fully utilize the rich information from multiple views of data. In this paper, we propose a novel unsupervised hashing approach, dubbed multi-view latent hashing (MVLH), to effectively incorporate multi-view data into hash code learning. Specifically, the binary codes are learned by the latent factors shared by multiple views from an unified kernel feature space, where the weights of different views are adaptively learned according to the reconstruction error with each view. We then propose to solve the associate optimization problem with an efficient alternating algorithm. To obtain high-quality binary codes, we provide a novel scheme to directly learn the codes without resorting to continuous relaxations, where each bit is efficiently computed in a closed form. We evaluate the proposed method on several large-scale datasets and the results demonstrate the superiority of our method over several other state-of-the-art methods.", "references": ["G. Ding, Y. Guo, and J. Zhou. Collective matrix factorization hashing for multimodal data. In CVPR, pages 2083--2090, 2014.", "A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In VLDB, pages 518--529, 1999.", "Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. TPAMI, 35(12):2916--2929, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806342"}, {"title": "Recycling trash in cache", "authors": ["Jonathan Shidal\n,", "Ari J. Spilo\n,", "Paul T. Scheid\n,", "Ron K. Cytron\n,", "Krishna M. Kavi"], "publication": "ISMM '15: Proceedings of the 2015 International Symposium on Memory Management", "abstract": "ABSTRACT\nThe disparity between processing and storage speeds can be bridged in part by reducing the traffic into and out of the slower memory components. Some recent studies reduce such traffic by determining dead data in cache, showing that a significant fraction of writes can be squashed before they make the trip toward slower memory. In this paper, we examine a technique for eliminating traffic in the other direction, specifically the traffic induced by dynamic storage allocation. We consider recycling dead storage in cache to satisfy a program's storage-allocation requests. We first evaluate the potential for recycling under favorable circumstances, where the associated logic can run at full speed with no impact on the cache's normal behavior. We then consider a more practical implementation, in which the associated logic executes independently from the cache's critical path. Here, the cache's performance is unfettered by recycling, but the operations necessary to determine dead storage and recycle such storage execute as time is available. Finally, we present the design and analysis of a hardware implementation that scales well with cache size without sacrificing too much performance.", "references": ["D. F. Bacon, P. Cheng, and V. T. Rajan. A unified theory of garbage collection. In Proceedings of the 19th Annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, OOPSLA ’04, pages 50– 68, New York, NY, USA, 2004. ACM. ISBN 1-58113-831-8.. URL http://doi.acm.org/10.1145/1028976.1028982.", "H. G. Baker. Infant mortality and generational garbage collection. SIGPLAN Not., 28(4):55– 57, Apr. 1993. ISSN 0362-1340.", ". URL http://doi.acm.org/10.1145/152739.152747."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2754169.2754183"}, {"title": "Evaluating Two-Stream CNN for Video Classification", "authors": ["Hao Ye\n,", "Zuxuan Wu\n,", "Rui-Wei Zhao\n,", "Xi Wang\n,", "Yu-Gang Jiang\n,", "Xiangyang Xue"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nVideos contain very rich semantic information. Traditional hand-crafted features are known to be inadequate in analyzing complex video semantics. Inspired by the huge success of the deep learning methods in analyzing image, audio and text data, significant efforts are recently being devoted to the design of deep nets for video analytics. Among the many practical needs, classifying videos (or video clips) based on their major semantic categories (e.g.,\"skiing\") is useful in many applications. In this paper, we conduct an in-depth study to investigate important implementation options that may affect the performance of deep nets on video classification. Our evaluations are conducted on top of a recent two-stream convolutional neural network (CNN) pipeline, which uses both static frames and motion optical flows, and has demonstrated competitive performance against the state-of-the-art methods. In order to gain insights and to arrive at a practical guideline, many important options are studied, including network architectures, model fusion, learning parameters and the final prediction methods. Based on the evaluations, very competitive results are attained on two popular video classification benchmarks. We hope that the discussions and conclusions from this work can help researchers in related fields to quickly set up a good basis for further investigations along this very promising direction.", "references": ["Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE TPAMI, 2013.", "G. E. Dahl, D. Yu, L. Deng, and A. Acero. Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition. IEEE TASLP, 2012.", "J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. CoRR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749406"}, {"title": "Exploiting User and Business Attributes for Personalized Business Recommendation", "authors": ["Kai Lu\n,", "Yi Zhang\n,", "Lanbo Zhang\n,", "Shuxin Wang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nData sparsity and cold-start are two major problems in personalized recommendation. They are especially severe in business recommendation, because business transactions are usually completed offline and customers generally do not provide ratings after a transaction. Due to these two problems, matrix factorization (MF) models, which are shown to be effective in many recommendation tasks, are likely to fail on business recommendation tasks, especially for new users and new items. In this paper, we propose an Integrated Bias and Factorization Model (IBFM), which exploits user and business attributes. The user attributes include demographic information, vote information, point-of-interests; the business attributes include check-in information, locations, business names, categories, etc. To handle the cold-start problem, we employ a sampling strategy to generate the latent factor vectors for new users and new businesses based on similar users/businesses. Our methods are evaluated on the data set used in the RecSys 2013 Yelp business rating prediction challenge. Experimental results show that our proposed methods significantly outperform several existing state-of-the-art methods. In particular, the single model IBFM performs the best in this challenge on both public and private leaderboards.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. on Knowl. and Data Eng., 17(6):734--749, June 2005.", "N. Golbandi, Y. Koren, and R. Lempel. Adaptive bootstrapping of recommender systems using decision trees. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, 2011.", "A. Gunawardana and C. Meek. Tied boltzmann machines for cold start recommendations. In Proceedings of the 2008 ACM Conference on Recommender Systems, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767806"}, {"title": "Improving Summarization Quality with Topic Modeling", "authors": ["Marina Litvak\n,", "Natalia Vanetik\n,", "Chunlei Liu\n,", "Lemin Xiao\n,", "Onur Savas"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nThe problem of extractive text summarization for a collection of documents is defined as the problem of selecting a small subset of sentences so that the contents and meaning of the original document set are preserved in the best possible way. In this paper we describe different applications of topic modeling as it relates to summarization. We consider two summarization models - supervised and unsupervised - enhanced by integrating the topic knowledge into their standard lexicon-based models. Both summarizers strive to cover as much information of the input documents as possible when generating the summaries. The supervised summarizer operates in a standard rank-and-select-sentences manner of extractive summarization, where the best linear combination of multiple sentence features is learned by a genetic algorithm (GA). The unsupervised summarizer models the summarization task as an optimization problem. As is the case with most existing summarization approaches, both original models measure information coverage by lexical units and were enriched by topic knowledge, providing a new measure for the informaition coverage. The experimental results show that utilizing topic knowledge improves the summarization quality.", "references": ["A. Aker, T. Cohn, and R. Gaizauskas. Multi-document summarization using A* search and discriminative training. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, pages 482--491, 2010.", "E. Alfonseca and P. Rodriguez. Generating extracts with genetic algorithms. In Proceedings of the 2003 European Conference on Information Retrieval (ECIR'2003), pages 511--519, 2003.", "M. Berkelaar. lp-solve free software, 1999. http://lpsolve.sourceforge.net/5.5/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809944"}, {"title": "Repl electric performance: end of buffer", "authors": ["Joseph Wilk"], "publication": "FARM 2015: Proceedings of the 3rd ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design", "abstract": "ABSTRACT\nA performance with a single programmer live coding both visuals and music using OpenGL shaders, Overtone and Emacs.", "references": ["OpenGL Shader Language: http://www.opengl.org/documentation/glsl/", "Shadertone: http://github.com/overtone/shadertone", "Overtone: http://github.com/overtone/overtone"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808083.2808084"}, {"title": "Spatial grouping coding for three-dimensional multichannel audio system", "authors": ["Pingfang Hu\n,", "Li Gao"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nCurrent multichannel parameter coding methods often group channels in pairs before downmixing and spatial parameters extraction as MPEG Surround does. Properly grouping of multichannel signals will effectively exploit the interchannel correlation for the eliminate of interchannel redundancy. When there exist multiple virtual sounds in 3D scenes, the fixed grouping coding of multichannel will probably encode channels with low correlations to a downmix with extracted spatial parameters, which will bring the problem of sound aliasing. In the proposed multichannel parameter coding structure, the grouping method of channels is based on the correlation characters between channel signals to make sure the channel signals with high correlation that generate the same virtual sound will be properly grouped together. Both subjective and objective experimental results for the evaluation of sound quality and spatial orientation quality identify that the proposed dynamic grouping method for downmixing and spatial parameters extraction is superior to the fixed grouping method in MPEG Surround.", "references": ["C Faller, F Baumgarte, Binaural cue coding-part II: schemes and applications. IEEE Trans. Speech Audio Process. 11(6), 520--531 (2003)", "Herre, J., et al., MPEG surround-the ISO/MPEG standard for efficient and compatible multichannel audio coding. Journal of the Audio Engineering Society, 2008. 56(11): p. 932--955.", "Cheng, B., Spatial squeezing techniques for low bit-rate multichannel audio coding. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808533"}, {"title": "Exploring EEG for Object Detection and Retrieval", "authors": ["Eva Mohedano\n,", "Kevin McGuinness\n,", "Graham Healy\n,", "Noel E. O'Connor\n,", "Alan F. Smeaton\n,", "Amaia Salvador\n,", "Sergi Porta\n,", "Xavier Giró-i-Nieto"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper explores the potential for using Brain Computer Interfaces (BCI) as a relevance feedback mechanism in content-based image retrieval. Several experiments are performed using a rapid serial visual presentation (RSVP) of images at different rates (5Hz and 10Hz) on 8 users with different degrees of familiarization with BCI and the dataset. We compare the feedback from the BCI and mouse-based interfaces in a subset of TRECVid images, finding that, when users have limited time to annotate the images, both interfaces are comparable in performance. Comparing our best users in a retrieval task, we found that EEG-based relevance feedback can outperform mouse-based feedback.", "references": ["A. Amir, M. Berg, and H. Permuter. Mutual relevance feedback for multimodal query formulation in video retrieval. In Proceedings of the 7th ACM SIGMM International Workshop on Multimedia Information Retrieval, MIR '05, pages 17--24, 2005.", "N. Bigdely-Shamlo, A. Vankov, R. R. Ramirez, and S. Makeig. Brain activity-based image classification from rapid serial visual presentation. Neural Systems and Rehabilitation Engineering, IEEE Transactions on, 16(5):432--441, 2008.", "G. Healy and A. F. Smeaton. Optimising the number of channels in eeg-augmented image search. In Proceedings of the 25th BCS Conference on Human-Computer Interaction, pages 157--162. British Computer Society, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749368"}, {"title": "Latent Discriminative Models for Social Emotion Detection with Emotional Dependency", "authors": ["Xiaojun Quan\n,", "Qifan Wang\n,", "Ying Zhang\n,", "Luo Si\n,", "Liu Wenyin"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nSentiment analysis of such opinionated online texts as reviews and comments has received increasingly close attention, yet most of the work is intended to deal with the detection of authors’ emotion. In contrast, this article presents our study of the social emotion detection problem, the objective of which is to identify the evoked emotions of readers by online documents such as news articles. A novel Latent Discriminative Model (LDM) is proposed for this task. LDM works by introducing intermediate hidden variables to model the latent structure of input text corpora. To achieve this, it defines a joint distribution over emotions and latent variables, conditioned on the observed text documents. Moreover, we assume that social emotions are not independent but correlated with one another, and the dependency of them is capable of providing additional guidance to LDM in the training process. The inclusion of this emotional dependency into LDM gives rise to a new Emotional Dependency-based LDM (eLDM). We evaluate the proposed models through a series of empirical evaluations on two real-world corpora of news articles. Experimental results verify the effectiveness of LDM and eLDM in social emotion detection.", "references": ["C. O. Alm, D. Roth, and R. Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing. 579--586.", "T. L. Bailey and C. Elkan. 1995. Unsupervised learning of multiple motifs in biopolymers using expectation maximization. Machine Learning 21, 1 (1995), 51--80.", "S. Bao, S. Xu, L. Zhang, R. Yan, Z. Su, D. Han, and Y. Yu. 2012. Mining social emotions from affective text. IEEE Transactions on Knowledge and Data Engineering 24, 9 (2012), 1658--1670."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2749459"}, {"title": "Launching an Efficient Participatory Sensing Campaign: A Smart Mobile Device-Based Approach", "authors": ["Fei Hao\n,", "Mingjie Jiao\n,", "Geyong Min\n,", "Laurence T. Yang"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nParticipatory sensing is a promising sensing paradigm that enables collection, processing, dissemination and analysis of the phenomena of interest by ordinary citizens through their handheld sensing devices. Participatory sensing has huge potential in many applications, such as smart transportation and air quality monitoring. However, participants may submit low-quality, misleading, inaccurate, or even malicious data if a participatory sensing campaign is not launched effectively. Therefore, it has become a significant issue to establish an efficient participatory sensing campaign for improving the data quality. This article proposes a novel five-tier framework of participatory sensing and addresses several technical challenges in this proposed framework including: (1) optimized deployment of data collection points (DC-points); and (2) efficient recruitment strategy of participants. Toward this end, the deployment of DC-points is formulated as an optimization problem with maximum utilization of sensor and then a Wise-Dynamic DC-points Deployment (WD3) algorithm is designed for high-quality sensing. Furthermore, to guarantee the reliable sensing data collection and communication, a trajectory-based strategy for participant recruitment is proposed to enable campaign organizers to identify well-suited participants for data sensing based on a joint consideration of temporal availability, trust, and energy. Extensive experiments and performance analysis of the proposed framework and associated algorithms are conducted. The results demonstrate that the proposed algorithm can achieve a good sensing coverage with a smaller number of DC-points, and the participants that are termed as social sensors are easily selected, to evaluate the feasibility and extensibility of the proposed recruitment strategies.", "references": ["Hossein Ahmadi, Nam Pham, Raghu K. Ganti, Tarek F. Abdelzaher, Suman Nath, and Jiawei Han. 2010. Privacy-aware regression modeling of participatory sensing data. In Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems. ACM, New York, 99--112.", "Haleh Amintoosi and Salil S. Kanhere. 2014. A reputation framework for social participatory sensing systems. Mobile Netw. Appl. 19, 1, 88--100.", "Haleh Amintoosi and Salil S. Kanhere. 2013. A trust-based recruitment framework for multi-hop social participatory sensing. In Proceedings of the 9th IEEE International Conference on Distributed Computing in Sensor Systems. IEEE, 266--273."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808198"}, {"title": "Deriving an Emergent Relational Schema from RDF Data", "authors": ["Minh-Duc Pham\n,", "Linnea Passing\n,", "Orri Erling\n,", "Peter Boncz"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe motivate and describe techniques that allow to detect an \"emergent\" relational schema from RDF data. We show that on a wide variety of datasets, the found structure explains well over 90% of the RDF triples. Further, we also describe technical solutions to the semantic challenge to give short names that humans find logical to these emergent tables, columns and relationships between tables. Our techniques can be exploited in many ways, e.g., to improve the efficiency of SPARQL systems, or to use existing SQL-based applications on top of any RDF dataset using a RDBMS.", "references": ["R. Agrawal et al. Fast algorithms for mining association rules. In VLDB, 1994.", "M. Arenas et al. A principled approach to bridging the gap between graph data and their schemas. In VLDB, 2014.", "K. Boitmanis et al. Fast and simple approximation of the diameter and radius of a graph. In Experimental Algorithms, pages 98--108. Springer, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741121"}, {"title": "Session details: Main Track - Information Systems Tools", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252427"}, {"title": "Meta-heuristic generation of robust XPath locators for web testing", "authors": ["Maurizio Leotta\n,", "Andrea Stocco\n,", "Filippo Ricca\n,", "Paolo Tonella"], "publication": "SBST '15: Proceedings of the Eighth International Workshop on Search-Based Software Testing", "abstract": "ABSTRACT\nTest scripts used for web testing rely on DOM locators, often expressed as XPaths, to identify the active web page elements and the web page data to be used in assertions. When the web application evolves, the major cost incurred for the evolution of the test scripts is due to broken locators, which fail to locate the target element in the new version of the software. We formulate the problem of automatically generating robust XPath locators as a graph exploration problem, for which we provide an optimal, greedy algorithm. Since such an algorithm has exponential time and space complexity, we present also a genetic algorithm.", "references": ["M. Leotta, D. Clerissi, F. Ricca, and P. Tonella. Visual vs. DOM-based web locators: An empirical study. In Proceedings of 14th International Conference on Web Engineering (ICWE 2014), volume 8541 of LNCS, pages 322--340. Springer, 2014.", "M. Leotta, A. Stocco, F. Ricca, and P. Tonella. Reducing web test cases aging by means of robust XPath locators. In Proceedings of 25th International Symposium on Software Reliability Engineering Workshops, ISSREW 2014, pages 449--454. IEEE, 2014.", "M. Leotta, A. Stocco, F. Ricca, and P. Tonella. Using multi-locators to increase the robustness of web test cases. In Proceedings of 8th International Conference on Software Testing, Verification and Validation, ICST 2015. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2821339.2821351"}, {"title": "Taming subgraph isomorphism for RDF query processing", "authors": ["Jinha Kim\n,", "Hyungyu Shin\n,", "Wook-Shin Han\n,", "Sungpack Hong\n,", "Hassan Chafi"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nRDF data are used to model knowledge in various areas such as life sciences, Semantic Web, bioinformatics, and social graphs. The size of real RDF data reaches billions of triples. This calls for a framework for efficiently processing RDF data. The core function of processing RDF data is subgraph pattern matching. There have been two completely different directions for supporting efficient subgraph pattern matching. One direction is to develop specialized RDF query processing engines exploiting the properties of RDF data for the last decade, while the other direction is to develop efficient subgraph isomorphism algorithms for general, labeled graphs for over 30 years. Although both directions have a similar goal (i.e., finding subgraphs in data graphs for a given query graph), they have been independently researched without clear reason. We argue that a subgraph isomorphism algorithm can be easily modified to handle the graph homomorphism, which is the RDF pattern matching semantics, by just removing the injectivity constraint. In this paper, based on the state-of-the-art subgraph isomorphism algorithm, we propose an in-memory solution, TurboHOM++, which is tamed for the RDF processing, and we compare it with the representative RDF processing engines for several RDF benchmarks in a server machine where billions of triples can be loaded in memory. In order to speed up TurboHOM++, we also provide a simple yet effective transformation and a series of optimization techniques. Extensive experiments using several RDF benchmarks show that TurboHOM++ consistently and significantly outperforms the representative RDF engines. Specifically, TurboHOM++ outperforms its competitors by up to five orders of magnitude.", "references": ["D. J. Abadi et al. Sw-store: A vertically partitioned dbms for semantic web data management. The VLDB Journal, 385--406, 2009.", "M. Atre et al. Matrix \"bit\" loaded: A scalable lightweight join query processor for rdf data. In WWW '10, 41--50.", "C. Bizer and A. Schultz. The berlin sparql benchmark. International Journal on Semantic Web and Information Systems (IJSWIS), 1--24, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809985"}, {"title": "Grading Degradation in an Institutionally Managed Repository", "authors": ["Luis Meneses\n,", "Sampath Jayarathna\n,", "Richard Furuta\n,", "Frank Shipman"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIt is not unusual for digital collections to degrade and suffer from problems associated with unexpected change. In an analysis of the ACM conference list, we found that categorizing the degree of change affecting a digital collection over time is a difficult task. More specifically, we found that categorizing this degree of change is not a binary problem where documents are either unchanged or they have changed so dramatically that they do not fit within the scope of the collection. It is, in part, a characterization of the intent of the change. In this work, we examine and categorize the various degrees of change that digital documents endure within the boundaries of an institutionally managed repository.", "references": ["P. L. Bogen, R. Furuta, and F. Shipman, \"A quantitative evaluation of techniques for detection of abnormal change events in blogs,\" presented at the Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries, Washington, DC, USA, 2012.", "P. Dave, U. P. Karadkar, R. Furuta, L. Francisco-Revilla, F. Shipman, S. Dash, et al., \"Browsing intricately interconnected paths,\" in Proceedings of the fourteenth ACM conference on Hypertext and hypermedia - HYPERTEXT '03, Nottingham, UK, 2003, pp. 95 - 103.", "L. Page, S. Brin, R. Motwani, and T. Winograd, \"The PageRank citation ranking: Bringing order to the web,\" Stanford University1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756966"}, {"title": "Software analytics to software practice: a systematic literature review", "authors": ["Tamer Mohamed Abdellatif\n,", "Luiz Fernando Capretz\n,", "Danny Ho"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nSoftware Analytics (SA) is a new branch of big data analytics that has recently emerged (2011). What distinguishes SA from direct software analysis is that it links data mined from many different software artifacts to obtain valuable insights. These insights are useful for the decision-making process throughout the different phases of the software lifecycle. Since SA is currently a hot and promising topic, we have conducted a systematic literature review, presented in this paper, to identify gaps in knowledge and open research areas in SA. Because many researchers are still confused about the true potential of SA, we had to filter out available research papers to obtain the most SA-relevant work for our review. This filtration yielded 19 studies out of 135. We have based our systematic review on four main factors: which software practitioners SA targets, which domains are covered by SA, which artifacts are extracted by SA, and whether these artifacts are linked or not. The results of our review have shown that much of the available SA research only serves the needs of developers. Also, much of the available research uses only one artifact which, in turn, means fewer links between artifacts and fewer insights. This shows that the available SA research work is still embryonic leaving plenty of room for future research in the SA field.", "references": ["A. E. Hassan et al., \"Roundtable: what's next in software analytic,\" IEEE Software, Vol. 30, Issue 4, pp. 53--56, 2013.", "T. Menzies and T. Zimmermann, \"Software analytics: so what?,\" IEEE Software, Vol. 30, Issue 4, pp. 31--37, 2013.", "T. Menzies and T. Zimmermann, \"The many faces of software analytics,\" IEEE Software, Vol. 30, Issue 5, pp. 28--29, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819300"}, {"title": "Dive into Remote Events: Omnidirectional Video Streaming with Acoustic Immersion", "authors": ["Daisuke Ochi\n,", "Kenta Niwa\n,", "Akio Kameda\n,", "Yutaka Kunita\n,", "Akira Kojima"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe propose a system that can provide the physical presence of remote events through a head mount display (HMD) and a headphone. It can stream omnidirectional video within a limited network bandwidth at a high bitrate without sending regions that users are not viewing. It can also reproduce binaural sounds by convoluting head related transfer functions and angular region-wise separated signals. Technical demos of the system using an Oculus Rift HMD with a headphone will be performed to enable users to experience the visual and acoustic immersion it provides.", "references": ["D. Ochi, S. Iwaki, Y. Kunita, J. Hirose, K. Fujii, and A. Kojima, HMD Viewing Spherical Streaming System, Proc: ACM MM 2014, November 2014.", "D. Ochi, S. Iwaki, K. Akio, Y. Kunita, and A. Kojima, Live Streaming System for Omnidirectional Video, Proc: IEEE VR 2015 , March 2015.", "Y. Hioka, K. Furuya, K. Kobayashi, K. Niwa, and Y. Haneda, Underdetermined sound source separation using power spectrum density estimated by combination of directivity gain, IEEE trans: on Audio; Speech; and Language, Vol.21, No.6, pp.1240--1250, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807963"}, {"title": "We are searching for", "authors": ["Mimi Onuoha"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\n\"We Are Searching For\" is a print piece that consists of the aggregation and presentation of browser search terms. The site-specific work unfolds within and outside of the exhibition space, with a physical print functioning as evidence of the human and programmatic processes informing its creation. Prior to installation, the artist gathers all of the browser keywords from as many of the showing institution's public computers as possible. The terms are then assembled into the print, resulting in a work that changes with each showing.\n\"We Are Searching For\" is an inquiry into digital data ownership and an exploration of the boundaries of public and private, permanence and temporality. By transforming individual search terms into collective community artifacts, viewers are prompted to engage with the ability of the search keywords to simultaneously obfuscate, humanize, and entertain.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783635"}, {"title": "Concept-Based Relevance Models for Medical and Semantic Information Retrieval", "authors": ["Chunye Wang\n,", "Ramakrishna Akella"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nRelevance models provide an important approach for estimating probabilities of words in the relevant class. However, the associated bag-of-words assumption breaks dependencies between words, especially between those within a phrase. If such dependencies could be preserved, it would permit matching the query terms with document terms having the same dependencies. Additionally, during the estimation of relevance, relevance models are unable to distinguish relevant and non-relevant information in a feedback document, and hence take the entire document into account, which potentially hurts the accuracy of estimation. In this paper, we define the notion of \"concept\", and design a concept-based information retrieval framework. Using this framework, we transform documents and queries from term space into concept space, and propose a concept-based relevance model for improved estimation of relevance. Our approach has three advantages. First, this approach only assumes independence between concepts, so is able to keep the strong dependencies between the words of a concept. Second, it unifies synonyms or different surface forms of a concept, leading to reduced dimensionality of the space, increased sample size of a concept, and consequently more accurate and reliable estimates of the relevance. Third, when knowledge bases are available, our approach enables the semantic analysis of query concepts, and thus identifies concepts related to the query, from which a more accurate distribution of relevance can be estimated. This work is aligned with semantic search methods.\nWe apply our concept-based relevance model to information retrieval in the medical domain, where concepts are abundant and their variations are numerous. We compare with relevance models, BM25 with pseudo relevance feedback, and the state of the art conceptual language models, on several data collections. The proposed model demonstrates consistent and statistically significant improvements across collections, outperforming top benchmark conceptual language models by at least 9% and up to 20% on a number of metrics.", "references": ["K. S. Jones, S. Robertson, D. Hiemstra, and H. Zaragoza. Language modelling and relevance. In Language Modeling for Information Retrieval, pp. 57--71, 2003.", "K. S. Jones, S. Walker, and S. Robertson, A probabilistic model of information retrieval: development and comparative experiments, Part 1. Information Processing and Management, 36, no. 6, pp. 779--808, 2000.", "J. M. Ponte and W. B. Croft. A language modeling approach to information retrieval. In Proc. of SIGIR, 275--281, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806497"}, {"title": "Geographically distributed sensemaking: developing understanding in forum-based software development teams", "authors": ["Ben Shreeve\n,", "Paul Ralph\n,", "Pete Sawyer\n,", "Patrick Stacey"], "publication": "CHASE '15: Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering", "abstract": "ABSTRACT\nGlobal software development is becoming increasingly popular. Working in geographically distributed teams affords advantages to both employer and employee alike. Despite this, distributed working remains a point of contention for many organisations, with some claiming it unsuitable for complex collaborative work. Many argue that the complex act of team sensemaking (the process by which a team develops an understanding of a situation or problem) can only effectively be performed in co-located environments. To investigate this assumption, we examine the communications of a geographically distributed game development team. This global team communicates entirely via forums, yet still manages complex sensemaking tasks asynchronously. We use thematic analysis to investigate how themes develop during online conversations, and use speech act sequences to explore how understanding is developed during these asynchronous conversations. Our findings demonstrate how collective sensemaking occurs within a real-world, geographically distributed team.", "references": ["P. Hinds and C. McGrath, \"Structures that work: social structure, work structure and coordination ease in geographically distributed teams,\" in Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work. ACM, 2006, pp. 343--352.", "M. M. N. Zenun, G. Loureiro, and C. S. Araujo, \"The Effects of Teams' Co-location on Project Performance,\" Complex Systems Concurrent Engineering, pp. 717--726, 2007.", "J. M. Wilson, M. O'Leary, A. Metiu, and Q. R. Jett, \"Perceived Proximity in Virtual Work: Explaining the Paradox of Far-but-Close,\" Organization Studies, vol. 29, no. 7, pp. 979--1002, May 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819321.2819328"}, {"title": "Click-through-based Deep Visual-Semantic Embedding for Image Search", "authors": ["Yuan Liu\n,", "Zhongchao Shi\n,", "Xue Li\n,", "Gang Wang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe problem of image search is mostly considered from the perspectives of feature-based vector model and image ranker learning. A fundamental issue that underlies the success of these approaches is the similarity learning between query and image. The need of image surrounding texts in feature-based vector model, however, makes the similarity sensitive to the quality of text descriptions. On the other, the image ranker learning can suffer from robustness problem, originating from the fact that human labeled query-image pairs do not always predict user search intention precisely. We demonstrate in this paper that the above two issues can be well mitigated by jointly exploring visual-semantic embedding and the use of click-through data. Specifically, we propose a novel click-through-based deep visual-semantic embedding (C-DVSE) model for learning query and image similarity. The proposed model consists of two components: a deep convolutional neural networks followed by an image embedding layer for learning visual embedding, and a deep neural networks for generating query semantic embedding. The objective of our model is to maximize the correlation between semantic (query) and visual (clicked image) embedding. When the visual-semantic embedding is learnt, query-image similarity can be directly computed by cosine similarity on this embedding space. On a large-scale click-based image dataset with 11.7 million queries and one million images, our model is shown to be powerful for keyword-based image search with superior performance over several state-of-the-art methods.", "references": ["Y. Bai, W. Yu, T. Xiao, C. Xu, K. Yang, W.-Y. Ma, and T. Zhao. Bag-of-words based deep neural network for image retrieval. In ACM MM, 2014.", "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009.", "Y. Gong, Q. Ke, M. Isard, and S. Lazebnik. A multi-view embedding space for modeling internet images, tags, and their semantics. IJCV, (106):210--233, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806373"}, {"title": "Progressive Shape-Distribution-Encoder for 3D Shape Retrieval", "authors": ["Jin Xie\n,", "Fan Zhu\n,", "Guoxian Dai\n,", "Yi Fang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we propose a deep shape descriptor by learning the shape distributions at different diffusion time via a progressive deep shape-distribution-encoder. First, we develop a shape distribution representation with the kernel density estimator to characterize the intrinsic geometrical structure of the shape. Then, we propose to learn discriminative shape features through a progressive shape-distribution-encoder. Specially, the progressive shape-distribution-encoder aims at modeling the complex non-linear transform of the estimated shape distributions between consecutive diffusion time. Furthermore, in order to characterize the intrinsic structure of the shape more efficiently, we stack multiple proposed progressive shape-distribution-encoders to form a neural network structure. Finally, we concatenated all neurons in the hidden layers of the progressive shape-distribution-encoder network to form a discriminative shape descriptor for retrieval. The proposed method is evaluated on three benchmark 3D shape datasets %with large geometric variations, i.e., McGill, SHREC'10 ShapeGoogle and SHREC'14 Human datasets, and the experimental results demonstrate the superiority of our method to the existing approaches.", "references": ["A. M. Bronstein, M. M. Bronstein, L. J. Guibas, and M. Ovsjanikov. Shape google: Geometric words and expressions for invariant shape retrieval. ACM Transactions on Graphics, 30(1):1, 2011.", "Y. Fang, M. Sun, and K. Ramani. Temperature distribution descriptor for robust 3d shape retrieval. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, pages 9--16. IEEE, 2011.", "Y. Fang, J. Xie, G. Dai, M. Wang, F. Zhu, T. Xu, and E. Wong. 3d deep shape descriptor. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2319--2328, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806308"}, {"title": "Image Tagging via Cross-Modal Semantic Mapping", "authors": ["Zhi-Hong Deng\n,", "Hongliang Yu\n,", "Yunlun Yang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nImages without annotations are ubiquitous on the Internet, and recommending tags for them has become a challenging open task in image understanding. A common bottleneck of related work is the semantic gap between the image and text representations. In this paper, we bridge the gap by introducing a semantic layer, the space of word embeddings that represents the image tags as the word vectors. Our model first learns the optimal mapping from the visual space to the semantic space using training sources. Then we annotate test images by decoding the semantic representations of the visual features. Extensive experiments demonstrate that our model outperforms the state-of-the-art approaches in predicting the image tags.", "references": ["M. Chen, A. Zheng, and K. Weinberger. Fast image tagging. In Proceedings of The 30th International Conference on Machine Learning, pages 1274--1282, 2013.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval, page 48. ACM, 2009.", "R. Collobert and J. Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160--167. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806302"}, {"title": "Towards Solving the Bottleneck of Pitch-based Singing Voice Separation", "authors": ["Bilei Zhu\n,", "Wei Li\n,", "Linwei Li"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nSinging voice separation from accompaniment in monaural music recordings is a crucial technique in music information retrieval. A majority of existing algorithms are based on singing pitch detection, and take the detected pitch as the cue to identify and separate the harmonic structure of the singing voice. However, as a key yet undependable premise, vocal pitch detection makes the separation performance of these algorithms rather limited. To overcome the inherent weakness of pitch-based inference algorithms, two novel methods based on non-negative matrix factorization (NMF) are devised in this paper. The first one combines NMF with the distribution regularities of vocals under different time frequency resolutions, so that many vocal unrelated portions are eliminated and the singing voice is hence enhanced. In consequence, the accuracy of vocal pitch detection is significantly improved. The second method applies NMF to decompose the spectrogram into non-overlapping and indivisible segments, which can be used as another cue besides the pitch to help identify the vocal harmonic structure. The two proposed methods are integrated into the framework of pitch-based inference. Extensive testing on the MIR-1K public dataset shows that both of them are rather effective, and the overall performances outperform other state-of-the-art singing separation algorithms.", "references": ["J. L. Durrieu, G. Richard, B. David and C. Ffievotte. Source/filter model for unsupervised main melody extraction from polyphonic audio signals. IEEE Transactions on Audio, Speech, and Language Processing, 18(3): 564--575, 2010.", "H. Fujihara, M. Goto, T. Kitahara and H. G. Okuno. A modeling of singing voice robust to accompaniment sounds and its application to singer identification and vocal-timbre-similarity-based music information retrieval. IEEE Transactions on Audio, Speech, and Language Processing, 18(3): 638--648, 2010.", "A. Mesaros and T. Virtanen. Automatic recognition of lyrics in singing. EURASIP Journal on Audio, Speech, and Music Processing, 2010, Article ID 546047."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806257"}, {"title": "Data profiling with metanome", "authors": ["Thorsten Papenbrock\n,", "Tanja Bergmann\n,", "Moritz Finke\n,", "Jakob Zwiener\n,", "Felix Naumann"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nData profiling is the discipline of discovering metadata about given datasets. The metadata itself serve a variety of use cases, such as data integration, data cleansing, or query optimization. Due to the importance of data profiling in practice, many tools have emerged that support data scientists and IT professionals in this task. These tools provide good support for profiling statistics that are easy to compute, but they are usually lacking automatic and efficient discovery of complex statistics, such as inclusion dependencies, unique column combinations, or functional dependencies.\nWe present Metanome, an extensible profiling platform that incorporates many state-of-the-art profiling algorithms. While Metanome is able to calculate simple profiling statistics in relational data, its focus lies on the automatic discovery of complex metadata. Metanome's goal is to provide novel profiling algorithms from research, perform comparative evaluations, and to support developers in building and testing new algorithms. In addition, Metanome is able to rank profiling results according to various metrics and to visualize the, at times, large metadata sets.", "references": ["Z. Abedjan, P. Schulze, and F. Naumann. DFD: Efficient functional dependency discovery. In Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 949--958, 2014.", "J. Bauckmann, U. Leser, and F. Naumann. Efficiently computing inclusion dependencies for schema discovery. In ICDE Workshops, page 2, 2006.", "P. A. Flach and I. Savnik. Database dependency discovery: a machine learning approach. AI Communications, 12(3):139--160, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824086"}, {"title": "How good are query optimizers, really?", "authors": ["Viktor Leis\n,", "Andrey Gubichev\n,", "Atanas Mirchev\n,", "Peter Boncz\n,", "Alfons Kemper\n,", "Thomas Neumann"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nFinding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.", "references": ["R. Ahmed, R. Sen, M. Poess, and S. Chakkappen. Of snowstorms and bushy trees. PVLDB, 7(13):1452--1461, 2014.", "B. Babcock and S. Chaudhuri. Towards a robust query optimizer: A principled and practical approach. In SIGMOD, pages 119--130, 2005.", "S. Bellamkonda, H.-G. Li, U. Jagtap, Y. Zhu, V. Liang, and T. Cruanes. Adaptive and big data scale parallel execution in Oracle. PVLDB, 6(11):1102--1113, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2850583.2850594"}, {"title": "A Relationship between the Average Precision and the Area Under the ROC Curve", "authors": ["Wanhua Su\n,", "Yan Yuan\n,", "Mu Zhu"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nFor similar evaluation tasks, the area under the receiver operating characteristic curve (AUC) is often used by researchers in machine learning, whereas the average precision (AP) is used more often by the information retrieval community. We establish some results to explain why this is the case. Specifically, we show that, when both the AUC and the AP are rescaled to lie in [0,1], the AP is approximately the AUC times the initial precision of the system.", "references": ["A. Arampatzis and S. Robertson. Modeling score distributions in information retrieval. Information Retrieval, 14:26--46, 2011.", "J. Davis and M. Goadrich. The relationship between precision-recall and ROC curves. In Proceedings of the 23rd International Conference on Machine learning, pages 233--240. ACM, 2006.", "D. J. Hand. Measuring classifier performance: A coherent alternative to the area under the ROC curve. Machine learning, 77(1):103--123, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809481"}, {"title": "On Microblog Dimensionality and Informativeness: Exploiting Microblogs' Structure and Dimensions for Ad-Hoc Retrieval", "authors": ["Jesus Alberto Rodriguez Perez\n,", "Joemon M. Jose"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn recent years, microblog services such as Twitter have gained increasing popularity, leading to active research on how to effectively exploit its content. Microblog documents such as tweets differ in morphology with respect to more traditional documents such as web pages. Particularly, tweets are considerably shorter (140 characters) than web documents and contain contextual tags regarding the topic (hashtags), intended audience (mentions) of the document as well as links to external content(URLs).\nTraditional and state of the art retrieval models perform rather poorly in capturing the relevance of tweets, since they have been designed under very different conditions. In this work, we define a microblog document as a high-dimensional entity and study the structural differences between those documents deemed relevant and those non-relevant. Secondly we experiment with enhancing the behaviour of the best observed performing retrieval model by means of a re-ranking approach that accounts for the relative differences in these dimensions amongst tweets. Additionally we study the interactions between the different dimensions in terms of their order within the documents by modelling relevant and non-relevant tweets as state machines. These state machines are then utilised to produce scores which in turn are used for re-ranking.\nOur evaluation results show statistically significant improvements over the baseline in terms of precision at different cut-off points for both approaches. These results confirm that the relative presence of the different dimensions within a document and their ordering are connected with the relevance of microblogs.", "references": ["Y. Aboulnaga, C. L. A. Clarke, and D. R. Cheriton. Frequent itemset mining for query expansion in microblog ad-hoc search.", "G. Amati, G. Amodeo, M. Bianchi, G. Marcone, F. U. Bordoni, C. Gaibisso, G. Gambosi, A. Celi, C. Di Nicola, and M. Flammini. Fub, iasi-cnr, univaq at trec 2011 microblog track. In TREC, 2011.", "G. Amati, C. Joost, and V. Rijsbergen. Probabilistic models for information retrieval based on divergence from randomness. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809466"}, {"title": "Towards Aspects Identification in Business Process Through Process Mining", "authors": ["Bruna Christina P. Brandao\n,", "Flavia Maria Santoro\n,", "Leonardo Guerreiro Azevedo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn business process models, elements can be scattered (repeated) within different processes, making it difficult to handle changes, analyze process for improvements, or check crosscutting impacts. These scattered elements are named as Aspects. Similar to the aspect-oriented paradigm in programming languages, in BPM, aspect handling has the goal to modularize the crosscutting concerns spread across the models. This process modularization facilitates the management of the process (reuse, maintenance and understanding). The current approaches for aspect identification are made manually; thus, resulting in the problem of subjectivity and lack of systematization. This paper proposes a method to automatically identify aspects in business process from its event logs. The method is based on mining techniques and it aims to solve the problem of the subjectivity identification made by specialists. The initial results from a preliminary evaluation showed evidences that the method identified correctly the aspects present in the process model.", "references": ["Azevedo, L.G. Santoro, F. Baiao, F., Souza, J., Revoredo, K., Pereira, V., Herlain, I. 2009. \"A Method for Service Identification from Business Process Models in a SOA Approach\". In T. Halpin et al., eds. Enterprise, Business-Process and Information Systems Modeling. pp. 99-112.", "Azevedo, L. G., Baiao, F., Santoro, F. Souza, J. F. 2011. \"A Business Aware Service Identification and Analysis Approach\". In: IADIS International Conference Information Systems 2011, March, 11-13, Avila, Spain.", "Barbosa, F. S. \"Comparing Three Aspect Mining Techniques.\" 2008. Doctoral Symposium in Informatics Engineering (DSIE'08). Portugal."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814174"}, {"title": "Essential Web Pages Are Easy to Find", "authors": ["Ricardo Baeza-Yates\n,", "Paolo Boldi\n,", "Flavio Chierichetti"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper we address the problem of estimating the index size needed by web search engines to answer as many queries as possible by exploiting the marked difference between query and click frequencies. We provide a possible formal definition for the notion of essential web pages as those that cover a large fraction of distinct queries --- i.e., we look at the problem as a version of MaxCover. Although in general MaxCover is approximable to within a factor of 1-1/e ~0.632 from the optimum, we provide a condition under which the greedy algorithm does find the actual best cover (or remains at a known bounded factor from it). The extra check for optimality (or for bounding the ratio from the optimum) comes at a negligible algorithmic cost. Moreover, in most practical instances of this problem, the algorithm is able to provide solutions that are provably optimal, or close to optimal. We relate this observed phenomenon to some properties of the queries' click graph. Our experimental results confirm that a small number of web pages can respond to a large fraction of the queries (e.g., 0.4% of the pages answers 20% of the queries). Our approach can be used in several related search applications, and has in fact an even more general appeal --- as a first example, our preliminary experimental study confirms that our algorithm has extremely good performances on other (social network based) MaxCover instances.", "references": ["A. Anagnostopoulos, L. Becchetti, S. Leonardi, I. Mele, and P. Sankowski. Stochastic Query Covering. In Proc. of WSDM 2011, pages 725--734, 2011. ACM.", "R. Baeza-Yates. Information retrieval in the web: beyond current search engines. Int. J. Approx. Reasoning, 34(2--3):97--104, 2003.", "R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. Design trade-offs for search engine caching. TWEB, 2(4), 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741100"}, {"title": "A Feature Vector Based Approach for Software Component Clustering and Reuse Using K-means", "authors": ["Chintakindi Srinivas\n,", "C. V. Guru Rao"], "publication": "ICEMIS '15: Proceedings of the The International Conference on Engineering & MIS 2015", "abstract": "ABSTRACT\nSoftware component clustering is an unsupervised learning approach which is used to cluster the software components. These clusters may then be used to study, analyze, understand behavior of the software components. In this paper, we use the k-means clustering algorithm to cluster the software components. The main difference lies in the use of distance measure which is designed to find the similarity between the software components. We use the distance measure [12], to find the pair wise project distance matrix and apply the k-means algorithm on this distance matrix. The main idea is to use more than one distance measure, to explore consensus based technique, so as to cluster software components, instead of using only one measure to cluster the components. This approach may also be applied for software architecture recovery problem by using our distance measure.", "references": ["Chun Yong Chong, Sai Peck Lee, and Teck Chaw Ling. 2013. Efficient software clustering technique using an adaptive and preventive dendrogram cutting approach. Inf. Softw. echnol. 55, 11, 1994--2012", "Rashid Naseem, Onaiza Maqbool, and Siraj Muhammad. 2013. Cooperative clustering for software modularization. J. Syst. Softw. 86, 8 (August 2013), 2045--2062.", "Zubair Shah, Rashid Naseem, Mehmet A. Orgun, Abdun Mahmood, and Sara Shahzad. 2013. Software Clustering Using Automated Feature Subset Selection. In Part II of the Proceedings of the 9th International Conference on Advanced Data Mining and Applications - Volume 8347."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832987.2833080"}, {"title": "Interact: A Mixed Reality Virtual Survivor for Holocaust Testimonies", "authors": ["Minhua Ma\n,", "Sarah Coward\n,", "Chris Walker"], "publication": "OzCHI '15: Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction", "abstract": "ABSTRACT\nIn this paper we present Interact---a mixed reality virtual survivor for Holocaust education. It was created to preserve the powerful and engaging experience of listening to, and interacting with, Holocaust survivors, allowing future generations of audience access to their unique stories. Interact demonstrates how advanced filming techniques, 3D graphics and natural language processing can be integrated and applied to specially-recorded testimonies to enable users to ask questions and receive answers from that virtualised individuals. This provides a new and rich interactive narratives of remembrance to engage with primary testimony. We discuss the design and development of Interact, and argue that this new form of mixed reality is promising media to overcome the uncanny valley.", "references": ["Artstein, R., Traum, D., Alexander, O., Leuski, A., Jones, A., Georgila, K., Debevec, P., Swartout, W., Maio, H. and Smith, S. Time-offset interaction with a holocaust survivor. In Proceedings of the 19th International Conference on Intelligent User Interfaces, ACM, New York, USA (2014), 163--168.", "Brenton, H., Cillies, M., Ballin, D. and Chatting, D. The Uncanny Valley: does it exist? In the 11th International Conference on Human-Computer Interaction. Lawrence Erlbaum Associates, Las Vegas (2005).", "Byrne, W., Doermann, D., Franz, M., Gustman, S., Hajic, J., Oard, D., Picheny, M., Psutka, J., Ramabhadran, B., Soergel, D., et al. Automatic recognition of spontaneous speech for access to multilingual oral history archives. IEEE Speech and Audio Processing (2004), 12(4): 420--435."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838739.2838803"}, {"title": "Mitigating browser fingerprint tracking: multi-level reconfiguration and diversification", "authors": ["Pierre Laperdrix\n,", "Walter Rudametkin\n,", "Benoit Baudry"], "publication": "SEAMS '15: Proceedings of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems", "abstract": "ABSTRACT\nThe diversity of software components (e.g., browsers, plugins, fonts) is a wonderful opportunity for users to customize their platforms. Yet, massive customization creates a privacy issue: browsers are slightly different from one another, allowing third parties to collect unique and stable fingerprints to track users. Although software diversity appears to be the source of this privacy issue, we claim that this same diversity, combined with automatic reconfiguration, provides the essential ingredients to constantly change browsing platforms. Constant change acts as a moving target defense strategy against fingerprint tracking by breaking one essential property: stability over time.\nWe leverage virtualization and modular architectures to automatically assemble and reconfigure software components at multiple levels. We operate on operating systems, browsers, fonts and plugins. This work is the first application of software reconfiguration to build a moving target defense against browser fingerprint tracking. The main objective is to automatically modify the fingerprint a platform exhibits. We have developed a prototype called Blink to experiment the effectiveness of our approach at randomizing fingerprints. We have assembled and reconfigured thousands of platforms, and we observe that all of them exhibit different fingerprints, and that commercial fingerprinting solutions are not able to detect that the different platforms actually correspond to a single user.", "references": ["P. Eckersley, \"How unique is your web browser?\" in Proceedings of the 10th International Conference on Privacy Enhancing Technologies, ser. PETS'10. Berlin, Heidelberg: Springer-Verlag, 2010, pp. 1--18. {Online}. Available: http://dl.acm.org/citation.cfm?id=1881151.1881152", "N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel, F. Piessens, and G. Vigna, \"Cookieless monster: Exploring the ecosystem of web-based device fingerprinting,\" in Proc. of the Symp. on Security and Privacy, 2013, pp. 541--555.", "G. Acar, M. Juarez, N. Nikiforakis, C. Diaz, S. Gürses, F. Piessens, and B. Preneel, \"Fpdetective: dusting the web for fingerprinters,\" in Proc. of the Conf. on Computer & Communications Security (CCS). ACM, 2013, pp. 1129--1140."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2821357.2821378"}, {"title": "Accessible on-line graphics", "authors": ["Anuradha Madugalla"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nToday's Internet contains a huge amount of resources and most of these resources include graphics. However, blind users fail to take the maximum advantage of these resources due to limitations in technology. Their devices (screen readers, voice synthesizers etc.) can only read textual content and fail miserably where graphics are involved. Therefore a robust method to help blind users understand on-line graphics would be of great benefit to them.", "references": ["L. Bártek, R. Ošlejšek, and T. Pitner. Is accessibility an issue in the knowledge society? modern web applications in the light of accessibility. In Organizational, Business, and Technological Aspects of the Knowledge Society, pages 359--364. Springer, 2010.", "L.-P. de las Heras, S. Ahmed, M. Liwicki, E. Valveny, and G. Sánchez. Statistical segmentation and structural recognition for floor plan interpretation. International Journal on Document Analysis and Recognition (IJDAR), pages 1--17, 2013.", "Z. B. Fredj and D. A. Duce. Grassml: Accessible smart schematic diagrams for all. In Proceedings of the 2006 International Cross-disciplinary Workshop on Web Accessibility (W4A), pages 57--60, NY, USA, 2006. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2578726.2746672"}, {"title": "An energy-aware method for the joint recognition of activities and gestures using wearable sensors", "authors": ["Joseph Korpela\n,", "Kazuyuki Takase\n,", "Takahiro Hirashima\n,", "Takuya Maekawa\n,", "Julien Eberle\n,", "Dipanjan Chakraborty\n,", "Karl Aberer"], "publication": "ISWC '15: Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nThis paper presents an energy-aware method for recognizing time series acceleration data containing both activities and gestures using a wearable device coupled with a smartphone. In our method, we use a small wearable device to collect accelerometer data from a user's wrist, recognizing each data segment using a minimal feature set chosen automatically for that segment. For each collected data segment, if our model finds that recognizing the segment requires high-cost features that the wearable device cannot extract, such as dynamic time warping for gesture recognition, then the segment is transmitted to the smartphone where the high-cost features are extracted and recognition is performed. Otherwise, only the minimum required set of low-cost features are extracted from the segment on the wearable device and only the recognition result, i.e., label, is transmitted to the smartphone in place of the raw data, reducing transmission costs. Our method automatically constructs this adaptive processing pipeline solely from training data.", "references": ["Breiman, L. Random forests. Mach. Learn. 45, 1 (2001), 5--32.", "Chawla, N. V., Bowyer, K. W., Hall, L. O., and Kegelmeyer, W. P. SMOTE: synthetic minority over-sampling technique. J. Artif. Intell. Res. 16 (2002), 341--378.", "French, B., Siewiorek, D. P., Smailagic, A., and Deisher, M. Selective sampling strategies to conserve power in context aware devices. In Int. Symp. on Wearable Comput. 2007, IEEE (2007), 77--80."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802083.2808400"}, {"title": "WikiMirs 3.0: A Hybrid MIR System Based on the Context, Structure and Importance of Formulae in a Document", "authors": ["Yuehan Wang\n,", "Liangcai Gao\n,", "Simeng Wang\n,", "Zhi Tang\n,", "Xiaozhong Liu\n,", "Ke Yuan"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nNowadays, mathematical information is increasingly available in websites and repositories, such like ArXiv, Wikipedia and growing numbers of digital libraries. Mathematical formulae are highly structured and usually presented in layout presentations, such as PDF, LATEX and Presentation MathML. The differences of presentation between text and formulae challenge traditional text-based index and retrieval methods. To address the challenge, this paper proposes an upgraded Mathematical Information Retrieval (MIR) system, namely WikiMirs 3.0, based on the context, structure and importance of formulae in a document. In WikiMirs 3.0, users can easily \"cut\" formulae and contexts from PDF documents as well as type in queries. Furthermore, a novel hybrid indexing and matching model is proposed to support both exact and fuzzy matching. In the hybrid model, both context and structure information of formulae are taken into consideration. In addition, the concept of formula importance within a document is introduced into the model for more reasonable ranking. Experimental results, compared with two classical MIR systems, demonstrate that the proposed system along with the novel model provides higher accuracy and better ranking results over Wikipedia.", "references": ["A. Aizawa, M. Kohlhase, I. Ounis, and M. Schubotz. Ntcir-11 math-2 task overview. In Proceedings of NTCIR-11 Math-2 task Workshop Meeting {1}, 2014.", "L. Gao, Z. Tang, X. Lin, Y. Liu, R. Qiu, and Y. Wang. Structure extraction from pdf-based book documents. In Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries, pages 11--20. ACM, 2011.", "L. Gao, Y. Wang, L. Hao, and Z. Tang. Icst math retrieval system for ntcir-11 math-2 task. In Proceedings of the 11th NTCIR Conference on Evaluation of Information Access Technologies, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756918"}, {"title": "IR meets NLP: On the Semantic Similarity between Subject-Verb-Object Phrases", "authors": ["Dmitrijs Milajevs\n,", "Mehrnoosh Sadrzadeh\n,", "Thomas Roelleke"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nMeasuring the semantic similarity between phrases and sentences is an important task in natural language processing (NLP) and information retrieval (IR). We compare the quality of the distributional semantic NLP models against phrase-based semantic IR. The evaluation is based on the correlation between human judgements and model scores on a distributional phrase similarity task. We experiment with four NLP and two IR model variants. On the NLP side, models vary over normalization schemes and composition operators. On the IR side, models vary with respect to estimation of the probability of a term being in a document, namely P(t|d) where only term co-occurrence information is used and P(t|d, sim) which incorporates term distributional similarity. A mixture of the two methods is presented and evaluated. For both methods, word meanings are derived from large corpora of data: the BNC and ukWaC. One of the main findings is that grammatical distributional models give better scores than the IR models. This suggests that an IR model enriched with distributional linguistic information performs better in the long standing problem in IR of document retrieval where there is no direct symbolic relationship between query and document concepts.", "references": ["Hany Azzam and Thomas Roelleke. SQR: a semantic query rating scheme. In Proceedings of the third workshop on Exploiting semantic annotations in information retrieval, ESAIR '10, pages 21--22, New York, NY, USA, 2010. ACM.", "Hany Azzam, Sirvan Yahyaei, Marco Bonzanini, and Thomas Roelleke. A schema-driven approach for knowledge-oriented retrieval and query formulation. In Proceedings of the Third International Workshop on Keyword Search on Structured Data, KEYS '12, pages 39--46, New York, NY, USA, 2012. ACM.", "Marco Baroni and Roberto Zamparelli. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP '10, pages 1183--1193, Stroudsburg, PA, USA, 2010. ACL."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809448"}, {"title": "An Entity Class-Dependent Discriminative Mixture Model for Cumulative Citation Recommendation", "authors": ["Jingang Wang\n,", "Dandan Song\n,", "Qifan Wang\n,", "Zhiwei Zhang\n,", "Luo Si\n,", "Lejian Liao\n,", "Chin-Yew Lin"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis paper studies Cumulative Citation Recommendation (CCR) for Knowledge Base Acceleration (KBA). The CCR task aims to detect potential citations of a set of target entities with priorities from a volume of temporally-ordered stream corpus. Previous approaches for CCR that build an individual relevance model for each entity fail to handle unseen entities without annotation. A baseline solution is to build a global entity-unspecific model for all entities regardless of the relationship information among entities, which cannot guarantee to achieve satisfactory result for each entity. In this paper, we propose a novel entity class-dependent discriminative mixture model by introducing a latent entity class layer to model the correlations between entities and latent entity classes. The model can better adjust to different types of entities and achieve better performance when dealing with a broad range of entities. An extensive set of experiments has been conducted on TREC-KBA-2013 dataset, and the experimental results demonstrate that the proposed model can achieve the state-of-the-art performance.", "references": ["J. Allan. Introduction to topic detection and tracking. In Topic Detection and Tracking, volume 12 of The Information Retrieval Series, pages 1--16. Springer US, 2002.", "K. Balog and H. Ramampiaro. Cumulative citation recommendation: classification vs. ranking. In SIGIR, pages 941--944. ACM, 2013.", "K. Balog, H. Ramampiaro, N. Takhirov, and K. Nørvåg. Multi-step classification approaches to cumulative citation recommendation. In OAIR, pages 121--128. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767698"}, {"title": "An Aspect-driven Social Media Explorer", "authors": ["Nedim Lipka\n,", "W. Bruce Croft"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe demonstrate an exploration tool that organizes social media content under diverse aspects enabling comprehensive explorations. Unlike existing approaches that group content by trending topics, we present a holistic view of diverse and relevant content with respect to a given query.", "references": ["www.gnip.com.", "www.w3.org/TR/wai-aria-practices/#accordion.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767864"}, {"title": "A Privacy-Preserving Bipartite Graph Matching Framework for Multimedia Analysis and Retrieval", "authors": ["Wei-Ta Chu\n,", "Feng-Chi Chang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe emergence of cloud computing provides an unlimited computation/storage for users, and yields new opportunities for multimedia analysis and retrieval research. However, privacy of users, e.g., search intention, may be leaked to the server and maliciously utilized by companies or individuals with animus. This paper presents a privacy-preserving multimedia analysis framework based on a widely-adopted structure, i.e., bipartite graph, so that multimedia analysis and retrieval in the encrypted domain is enabled. This work aims to keep the server unaware of what the user wants to retrieve, and at the same time take advantage of the server's computation power. Homomorphic encryption schemes and communication protocols in the encrypted domain are integrated to facilitate bipartite graph construction and implement the Hungarian algorithm to find the best matching. Two applications, video tag suggestion and video copy detection, are developed on top of the privacy-preserving framework, and the evaluation results demonstrate that performance obtained in the encrypted domain is comparable with that obtained in the plain text domain.", "references": ["R. Diestel. Graph Theory. Heidelberg, Springer, 2005.", "P. Paillier. Public-key cryptosystems based on composite degree residuosity classes. Proceedings of the International Conference on Theory and Application of Cryptographic Techniques, pp. 223--238, 1999.", "A. Likas, N. Vlassis, N., and J. J. Verbeek, The global k-means clustering algorithm. Pattern Recognition, vol. 36, pp. 451--461, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749286"}, {"title": "Exploring Long Running News Stories using Wikipedia", "authors": ["Jaspreet Singh\n,", "Abhijit Anand\n,", "Vinay Setty\n,", "Avishek Anand"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nA significant portion of today's news articles are part of long running stories. To better understand the context of these stories journalists, social scientists and other scholars use news collections to find temporal and topical insights. However these insights are devoid of user impressions, derived from click-through data and query logs, and are only reliable if the collection is complete and consistent. In this work we introduce the notion of combining user impressions from Wikipedia with news collection based insights for long running news story exploration and outline promising new research directions. We also demonstrate our initial attempts with a prototype system called NewsEX.", "references": ["O. Alonso, K. Berberich, S. Bedathur, and G. Weikum. Neat: News exploration along time. Proc. of ECIR'2010.", "O. Alonso, M. Gertz, and R. Baeza-Yates. Clustering and exploring search results using timeline constructions. In Proc. of the 18th ACM CIKM, 2009.", "R. Jones and F. Diaz. Temporal profiles of queries. ACM Transactions on Information Systems, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786489"}, {"title": "Dissemination of anonymized streaming data", "authors": ["Yongluan Zhou\n,", "Lidan Shou\n,", "Xuan Shang\n,", "Ke Chen"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nWith the vision of the emergence of streaming data marketplaces, we study the problem of how to use a scalable dissemination infrastructure, composed by a number of brokers, to disseminate anonymized streaming data to a large number of clients. To satisfy the clients, who are trusted at different anonymity levels and have their own urgencies in requiring the data, we propose to deeply integrate the anonymization process into the dissemination infrastructure. More specifically, we extend the existing anonymization algorithms to derive the anonymity data from other anonymity data with different privacy constraints rather than only from the original microdata, in a technique which we call version derivation. With this flexibility, the anonymous data can be generated as needed, according to the available bandwidth, on the way from the data source to the end clients. Exploiting such new opportunities, we formulate the problem of dissemination planning which aims at minimizing the information loss of the disseminated data. Furthermore, we design two dissemination plan optimization strategies to solve the problem. The experimental study using both synthetic and real datasets verifies the effectiveness of our approach.", "references": ["Delay models in data networks. In http://web.mit.edu/dimitrib/www/Queueing_Data_Nets.pdf.", "J. Cao, B. Carminati, E. Ferrari, and K.-L. Tan. Castle: Continuously anonymizing data streams. IEEE Trans. Dependable Sec. Comput., 8(3):337--352, 2011.", "C.-M. Chao. Privacy-preserving classification of data streams. In SEKE, pages 603--606, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2771837"}, {"title": "Supply and demand of independent UK music artists on the web", "authors": ["Matt McVicar\n,", "Cédric Mesnage\n,", "Jefrey Lijffijt\n,", "Eirini Spyropoulou\n,", "Tijl De Bie"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nAs in any dynamic market, supply and demand of music are in a constant state of disequilibrium. Music charts have for many years documented the demand for the most popular music, but a more comprehensive understanding of this market has remained beyond reach. In this paper, we provide a proof of concept for how web resources now make it possible to study both demand and supply sides, accounting also for smaller, independent artists.", "references": ["A. Bellogín, A. P de Vries, and J. He. Artist popularity: Do web and social music services agree? In Proc. of ICWSM, pages 673--676, 2013.", "D. Hauger, M. Schedl, A. Košir, and M. Tkalčič. The million musical tweets dataset: What can we learn from microblogs. In Proc. of ISMIR, pages 189--194, 2013.", "R. Price and D. Bonett. Estimating the ratio of two poisson rates. CSDA, 34(3):345--356, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786488"}, {"title": "Effective Multi-Query Expansions: Robust Landmark Retrieval", "authors": ["Yang Wang\n,", "Xuemin Lin\n,", "Lin Wu\n,", "Wenjie Zhang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nGiven a query photo issued by a user (q-user), the landmark retrieval is to return a set of photos with their landmarks similar to those of the query, while the existing studies on the landmark retrieval focus on exploiting geometries of landmarks for similarity matches between candidate photos and a query photo. We observe that the same landmarks provided by different users may convey different geometry information depending on the viewpoints and/or angles, and may subsequently yield very different results. In fact, dealing with the landmarks with shapes caused by the photography of q-users is often nontrivial and has never been studied.\nMotivated by this, in this paper we propose a novel framework, namely multi-query expansions, to retrieve semantically robust landmarks by two steps. Firstly, we identify the top-k photos regarding the latent topics of a query landmark to construct multi-query set so as to remedy its possible shape. For this purpose, we significantly extend the techniques of Latent Dirichlet Allocation. Secondly, we propose a novel technique to generate the robust yet compact pattern set from the multi-query photos. To ensure redundancy-free and enhance the efficiency, we adopt the existing minimum-description-length-principle based pattern mining techniques to remove similar query photos from the (k+1) selected query photos. Then, a landmark retrieval rule is developed to calculate the ranking scores between mined pattern set and each photo in the database, which are ranked to serve as the final ranking list of landmark retrieval. Extensive experiments are conducted on real-world landmark datasets, validating the significantly higher accuracy of our approach.", "references": ["E. Amitay, N. Harel, R. Sivan, and A. Soffer. Web-a-where: geotagging web content. In ACM SIGIR, 2004.", "R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012.", "S. Arslan, S. Kim, M. He, and R. Zimmermann. Relevance ranking in georeferenced video search. Multimedia Systems, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806233"}, {"title": "K-strings algorithm, a new approach based on Kmeans", "authors": ["Viet-Hoang Le\n,", "Sung-Ryul Kim"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nK-means is a popular clustering algorithm which is widely used in anomaly-based intrusion detection. It tries to classify a given data set into k (a predefined number) categories. However, to apply to a high dimensional dataset, we believe that the calculated distance of the multitude of different attributes along with diverse ranges, that depend on a sole center point are not fair and limit the chance to generate good quality clusters. Aiming to cluster a high dimensional dataset more effective, we propose K-string clustering algorithm in this paper. In which, we obtain a set of center points, that play the role as the backbone of a cluster, instead of a unique centroid to generate clusters. To evaluate we use fitness function, and absolutely the output clusters shown a competition results when comparing to K-means algorithm and Genetic Algorithm [6].", "references": ["SANS Institute. Understanding Intrusion Detection Systems. http://www.sans.org/reading-room/whitepapers/detection/understanding-intrusion-detection-systems-337.", "Dorothy E. Denning. 1986. An Intrusion Detection Model. In Proceedings of the Seventh IEEE Symposium on Security and Privacy (May 1986). NJ, USA. DOI= http://dx.doi.org/10.1109/TSE.1987.232894.", "James MacQueen. 1967. Some Methods for classification and Analysis of Multivariate Observations. In Proceedings of 5th Berkeley Symposium on Mathematical Statistics and Probability. University of California Press. pp. 281--297. MR 0214227."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811472"}, {"title": "AutoTag 'n Search My Photos: Leveraging the Social Graph for Photo Tagging", "authors": ["Shobana Balakrishnan\n,", "Surajit Chaudhuri\n,", "Vivek Narasayya"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nPersonal photo collections are large and growing rapidly. Today, it is difficult to search such a photo collection for people who occur in them since it is tedious to manually associate face tags in photos. The key idea is to learn face models for friends and family of the user using tagged photos in a social graph such as Facebook as training examples. These face models are then used to automatically tag photos in the collection, thereby making it more searchable and easier to organize. To illustrate this idea we have developed a Windows app called AutoTag 'n Search My Photos. In this demo paper we describe the architecture, user interaction and controls, and our initial learnings from deploying the app.", "references": ["Picasa. http://en.wikipedia.org/wiki/Picasa, 2002.", "Microsoft Research Face SDK. http://research.microsoft.com/en-us/projects/facesdk/, 2011.", "SQLite. http://sqlite.org/about.html, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742843"}, {"title": "NWSearch 2015: International Workshop on Novel Web Search Interfaces and Systems", "authors": ["Davood Rafiei\n,", "Katsumi Tanaka"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nHeld for the first time in conjunction with the ACM International Conference on Information and Knowledge Management (CIKM), NWSearch 2015 aims to bring together researchers, developers and practitioners who are interested in pushing the search boundary on the Web and exploring more novel forms of searches, interfaces, task formulations, and result organizations and presentations. In particular, the workshop seeks to identify some of the problems and challenges facing the development of such tools and interfaces and to flourish new ideas and findings that can shape or influence future research directions and developments. The workshop organizers solicited contributions that would fall within the large spectrum of human-computer interaction in one extreme and system production and development in the other extreme.", "references": ["K. Gkirtzou, G. Papastefanatos, and T. Dalamagas. Rdf keyword search based on keywords-to-sparql translation. In Proc. of NWSearch Workshop, 2015.", "M. Liska, P. Sojka, and M. Ruzicka. Combining text and formula queries in math information retrieval: Evaluation of query results merging strategies. In Proc. of NWSearch Workshop, 2015.", "J. R. Trippas, D. Spina, M. Sanderson, and L. Cavedon. Towards a spoken conversational search system. In Proc. of NWSearch Workshop, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806882"}, {"title": "Questions vs. Queries in Informational Search Tasks", "authors": ["Ryen W. White\n,", "Matthew Richardson\n,", "Wen-tau Yih"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSearch systems traditionally require searchers to formulate information needs as keywords rather than in a more natural form, such as questions. Recent studies have found that Web search engines are observing an increase in the fraction of queries phrased as natural language. As part of building better search engines, it is important to understand the nature and prevalence of these intentions, and the impact of this increase on search engine performance. In this work, we show that while 10.3% of queries issued to a search engine have direct question intent, only 3.2% of them are formulated as natural language questions. We investigate whether search engines perform better when search intent is stated as queries or questions, and we find that they perform equally well to both", "references": ["Azzopardi, L., Kelly, D., and Brennan, K. (2013). How query cost affects search behavior. SIGIR, 23--32.", "Belkin, N.J. et al. (2003). Query length in interactive information retrieval. SIGIR, 205--212.", "Broder, A. (2002). A taxonomy of web search. SIGIR Forum, 36(2): 3--10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742769"}, {"title": "On-Device Mobile Landmark Recognition Using Binarized Descriptor with Multifeature Fusion", "authors": ["Tao Guan\n,", "Yuesong Wang\n,", "Liya Duan\n,", "Rongrong Ji"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nAlong with the exponential growth of high-performance mobile devices, on-device Mobile Landmark Recognition (MLR) has recently attracted increasing research attention. However, the latency and accuracy of automatic recognition remain as bottlenecks against its real-world usage. In this article, we introduce a novel framework that combines interactive image segmentation with multifeature fusion to achieve improved MLR with high accuracy. First, we propose an effective vector binarization method to reduce the memory usage of image descriptors extracted on-device, which maintains comparable recognition accuracy to the original descriptors. Second, we design a location-aware fusion algorithm that can fuse multiple visual features into a compact yet discriminative image descriptor to improve on-device efficiency. Third, a user-friendly interaction scheme is developed that enables interactive foreground/background segmentation to largely improve recognition accuracy. Experimental results demonstrate the effectiveness of the proposed algorithms for on-device MLR applications.", "references": ["G. Baatz, K. Koeser, D. Chen, R. Grzeszczuk, and M. Pollefeys. 2010. Handling urban location recognition as a 2D homothetic problem. In Proceedings of the 11th European Conference on Computer Vision (ECCV’10).", "H. Bay, A. Ess, T. Tuytelaars, and L. V. Gool. 2008. SURF: Speeded up robust features. Computer Vision and Image Understanding (CVIU) 110, 3, 346--359.", "C. Biancalana, F. Gasparetti, and A. Micarelli. 2013. An approach to social recommendation for context-aware mobile services. ACM Transactions on Intelligent Systems and Technology 4, 1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795234"}, {"title": "Application of Knowledge Discovery in Databases in Evapotranspiration Estimation: an Experiment in the State of Rio de Janeiro", "authors": ["Fernando Xavier\n,", "Asterio Kiyoshi Tanaka\n,", "Kate Cerqueira Revoredo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nWith the growing volume of data in various areas such as Hydrology, there is a need for using information systems to aid in handling such data. This article is a report of an experiment that used knowledge discovery techniques to estimate an important component of the hydrological cycle: evapotranspiration. The experiment reported in this article was done with weather data and showed that some algorithms, such as M5P, present good results when compared to historical data of the estimated evapotranspiration.", "references": ["Branco, P. M. (2014). Elementos que caracterizam o clima. Disponível http://www.cprm.gov.br/publique/cgi/cgilua.exe/sys/start.htm?infoid=1267&sid=129 [acessado em 28-Novembro-2014].", "Di Bello, R. C. (2005). Análise do Comportamento da Umidade do Solo no Modelo Chuva-Vazão Smap II-Versão com Suavização Hiperbólica Estudo de Caso: Região de Barreiras na Bacia do Rio Grande-BA (Dissertação de Mestrado, Universidade Federal do Rio de Janeiro).", "Eagleson, P. S. (1994). The evolution of modern hydrology (from watershed to continent in 30 years). Advances in water resources, 17(1), 3-18."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814088"}, {"title": "An Ontology-based Co-creation Enhancing System for Idea Recommendation in an Online Community", "authors": ["Donghee Yoo\n,", "Keunho Choi\n,", "Hanjun Lee\n,", "Yongmoo Suh"], "publication": "ACM SIGMIS Database: the DATABASE for Advances in Information Systems", "abstract": "Abstract\nCompanies have been collecting innovative ideas that can help them to develop new products and services through co-creation with their customers. As more customers participate in suggesting ideas, companies are likely to acquire more valuable ones. At the same time, however, some fundamental problems occur such as managing and selecting useful ideas from a large number of collected ideas. Semantic web mining techniques allow us to manage a large number of customers' ideas effectively, extract meaningful information from the ideas, and provide useful information for idea selection. In order to cope with such problems and enhance the value of co-creation, we propose an ontology-based co-creation enhancing system (OnCES) developed using semantic web mining techniques. To this end, we 1) defined a co-creation idea ontology (CCIO) that includes common concepts related to customers' ideas from MyStarbucksIdea.com, their attributes, and relationships between them; 2) transformed the customers' ideas into semantic data in RDF format according to the CCIO; 3) conducted text mining to extract new knowledge from the ideas such as keywords, the number of positive words, the number of negative words, and the sentiment score; and 4) built prediction models using keywords and other features such as those about customer and idea in order to predict the adoptability of each idea. The results of text mining and prediction analysis were also added to the semantic data. We implemented the OnCES system, which provides useful services such as idea navigation, idea recommendation, semantic information retrieval, and idea clustering, utilizing the stored semantic data while saving the time and effort required to process a huge number of customers' ideas.", "references": ["Berendt, B., Hotho, A. and Stumme, G. (2002), \"Towards Semantic Web Mining,\" In Proceedings of the first International Semantic Web, Sardinia, Italy, pp. 264--278.", "Cassiman, B. and Veugelers, R. (2006), \"In search of complementarity in innovation strategy: Internal R&D and external knowledge acquisition,\" Management science, Vol. 52, No. 1: pp. 68--82.", "Chesbrough, H. W. (2003), Open innovation: The new imperative for creating and profiting from technology. Harvard Business Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2804075.2804077"}, {"title": "An Approach for Clustering Text Data Streams Using K-means and Ternary Feature Vector Based Similarity Measure", "authors": ["M. S. B. PhridviRaj\n,", "C. V. Guru Rao"], "publication": "ICEMIS '15: Proceedings of the The International Conference on Engineering & MIS 2015", "abstract": "ABSTRACT\nClustering text data streams is an unsupervised learning process which requires handling data streams. In the current work, we find the pair wise distance between customer transactions using the transaction similarity measure and obtain corresponding pair wise distance matrix. This pair wise distance matrix is then used to cluster the data streams such as customer transactions which are generated continuously in super markets and stored in to the database. For clustering, customer transactions, we use the k-means clustering algorithm. The input to k-means algorithm is the distance matrix in contrast to conventional approach which does not use the distance matrix. Finally, we define the proposed distance measure and validate it using the case study. We compare the results obtained using this approach with the one obtained using conventional k-means.", "references": ["Jonathan A. Silva, Elaine R. Faria, Rodrigo C. Barros, Eduardo R. Hruschka, André C. P. L. F. de Carvalho, and Joao Gama. 2013. Data stream clustering: A survey. ACM Comput. Surv. 46, 1, Article 13 (July 2013), 31 pages.", "Zaher Al Aghbari, Ibrahim Kamel, and Thuraya Awad. 2012. On clustering large number of data streams. Intell. Data Anal. 16, 1 (January 2012), 69--91. DOI=10.3233/IDA-2011-0511", "Sebastian Lühr and Mihai Lazarescu. 2009. Incremental clustering of dynamic data streams using connectivity based representative points. Data Knowl. Eng. 68, 1 (January 2009), 1--27."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832987.2833081"}, {"title": "Game suspension boundary detection by reading two clocks for broadcast basketball video", "authors": ["Xinguo Yu\n,", "Wan Ding"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nThis paper presents a novel algorithm for finding suspension boundaries (starting and end time points of event) of broadcast basketball videos, which employs the superimposed features extracted from the game clock and the shot clock to infer the suspension boundary. The main challenge of suspension boundary detection in the proposed way is to read (localize and recognize) the game clock and the shot clock. The difficulties of reading the two clocks from basketball videos lie in that the two clocks are independent from each other and are paused and reset frequently. This paper proposes two new techniques against the difficulties. The first new technique is a new set of functions of instantiating the second-periodicity method to identify the pixels inside second-regions without knowing the transit frames of two clocks. The second technique is a procedure of finding the proper digit-sequence from the second place of the shot clock. This technique solves the difficulty caused by the frequent pauses and the resets of two clocks. With the information extracted from the game clock and the shot clock this paper infers the start and the end time points of suspension clips. Experimental results show that the proposed algorithm can find much more accurate boundary points of suspensions at a much lower computing cost than the existing algorithms can.", "references": ["X. Yu, and D. Farin, \"Current and emerging topics in sports video processing,\" ICME 2005, IEEE, pp. 526--529, July 2005.", "H. T. Chen et al, \"Recognizing tactic patterns in broadcast basketball video using player trajectory,\" JVCIR, ELSEVIER, pp. 932--947, 2012.", "W. Brendel et al, \"Probabilistic Event Logic for Interval-Based Event Recognition,\" CVPR 2011, IEEE, pp. 3329--3336, June, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808537"}, {"title": "Querying Web-Scale Information Networks Through Bounding Matching Scores", "authors": ["Jiahui Jin\n,", "Samamon Khemmarat\n,", "Lixin Gao\n,", "Junzhou Luo"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWeb-scale information networks containing billions of entities are common nowadays. Querying these networks can be modeled as a subgraph matching problem. Since information networks are incomplete and noisy in nature, it is important to discover answers that match exactly as well as answers that are similar to queries. Existing graph matching algorithms usually use graph indices to improve the efficiency of query processing. For web-scale information networks, it may not be feasible to build the graph indices due to the amount of work and the memory/storage required. In this paper, we propose an efficient algorithm for finding the best k answers for a given query without precomputing graph indices. The quality of an answer is measured by a matching score that is computed online. To speed up query processing, we propose a novel technique for bounding the matching scores during the computation. By using bounds, we can efficiently prune the answers that have low qualities without having to evaluate all possible answers. The bounding technique can be implemented in a distributed environment, allowing our approach to efficiently answer the queries on web-scale information networks. We demonstrate the effectiveness and the efficiency of our approach through a series of experiments on real-world information networks. The result shows that our bounding technique can reduce the running time up to two orders of magnitude comparing to an approach that does not use bounds.", "references": ["Apache Jena. http://jena.apache.org/.", "DBLP. http://www.informatik.uni-trier.de/~ley/db/.", "Hadoop Distributed File System. http://hadoop.apache.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741131"}, {"title": "On crowdsourcing information maps: cornucopia of the commons for the city", "authors": ["Seng W. Loke"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nInformation maps about urban phenomena can be constructed via crowdsourcing, creating a potential Cornucopia of the Commons, as information can be reused by many. We present a stylised model of crowdsourcing for building urban information maps, and make observations about the behaviour of contributors.", "references": ["Eleni Christopoulou, Dimitris Ringas, and John D. Garofalakis. The vision of the sociable smart city. In Distributed, Ambient, and Pervasive Interactions - Second International Conference, DAPI, pages 545--554, 2014.", "Garrett Hardin. The tragedy of the commons. Science, 162(3859):1243--1248, 1968.", "Yaron Singer. Budget feasible mechanism design. SIGecom Exch., 12(2):24--31, November 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2801628"}, {"title": "Truth Finding with Attribute Partitioning", "authors": ["M. Lamine Ba\n,", "Roxana Horincar\n,", "Pierre Senellart\n,", "Huayu Wu"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nTruth finding is the problem of determining which of the statements made by contradictory sources is correct, in the absence of prior information on the trustworthiness of the sources. A number of approaches to truth finding have been proposed, from simple majority voting to elaborate iterative algorithms that estimate the quality of sources by corroborating their statements. In this paper, we consider the case where there is an inherent structure in the statements made by sources about real-world objects, that imply different quality levels of a given source on different groups of attributes of an object. We do not assume this structuring given, but instead find it automatically, by exploring and weighting the partitions of the sets of attributes of an object, and applying a reference truth finding algorithm on each subset of the optimal partition. Our experimental results on synthetic and real-world datasets show that we obtain better precision at truth finding than baselines in cases where data has an inherent structure.", "references": ["D. Attia Waguih and L. Berti-Équille. Truth discovery algorithms: An experimental evaluation. CoRR, abs/1409.6428, 2014.", "M. L. Ba, S. Montenez, R. Tang, and T. Abdessalem. Integration of web sources under uncertainty and dependencies. In UnCrowd, 2014.", "J. Bleiholder, K. Draba, and F. Naumann. FuSem: exploring different semantics of data fusion. In VLDB, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767118"}, {"title": "Why Do Social Media Users Share Misinformation?", "authors": ["Xinran Chen\n,", "Sei-Ching Joanna Sin\n,", "Yin-Leng Theng\n,", "Chei Sian Lee"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWidespread misinformation on social media is a cause of concern. Currently, it is unclear what factors prompt regular social media users with no malicious intent to forward misinformation to their online networks. Using a questionnaire informed by the Uses and Gratifications theory and the literature on rumor research, this study asked university students in Singapore why they shared misinformation on social media. Gender differences were also tested. The study found that perceived information characteristics such as its ability to spark conversations and its catchiness were top factors. Self-expression and socializing motivations were also among the top reasons. Women reported a higher prevalence of misinformation sharing. The implications for the design of social media applications and information literacy training were discussed.", "references": ["Shah, C. 2012. Collaborative information seeking: The art and science of making the whole greater than the sum of all. Springer, Berlin.", "Anne P. Mintz ed. 2012. Web of deceit: Misinformation and manipulation in the age of social media. Information Today, Medford, NJ.", "Ratkiewicz, J., Conover, M., Meiss, M., Gonçalves, B., Patil, S., Flammini, A., and Menczer, F. 2010. Detecting and tracking the spread of astroturf memes in microblog streams. Technical Report. arXiv:1011.3768 {cs.SI}, CoRR. Retrieved 27 Janurary, 2015 from http://arxiv.org/abs/1011.3768"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756941"}, {"title": "Towards Entity Correctness, Completeness and Emergence for Entity Recognition", "authors": ["Lei Zhang\n,", "Yunpeng Dong\n,", "Achim Rettinger"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLinking words or phrases in unstructured text to entities in knowledge bases is the problem of entity recognition and disambiguation. In this paper, we focus on the task of entity recognition in Web text to address the challenges of entity correctness, completeness and emergence that existing approaches mainly suffer from. Experimental results show that our approach significantly outperforms the state-of-the-art approaches in terms of precision, F-measure, micro-accuracy and macro-accuracy, while still preserving high recall.", "references": ["J. R. Finkel, T. Grenager, and C. D. Manning. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL, 2005.", "J. Hoffart, Y. Altun, and G. Weikum. Discovering emerging entities with ambiguous names. In WWW, pages 385--396, 2014.", "J. Hoffart, M. A. Yosef, I. Bordino, H. Fürstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum. Robust disambiguation of named entities in text. In EMNLP, pages 782--792, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742766"}, {"title": "Ranking Buildings and Mining the Web for Popular Architectural Patterns", "authors": ["Ujwal Gadiraju\n,", "Stefan Dietze\n,", "Ernesto Diaz-Aviles"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nKnowledge about the reception of architectural structures is crucial for architects and urban planners. Yet obtaining such information has been a challenging and costly activity. However, with the advent of the Web, a vast amount of structured and unstructured data describing architectural structures has become available publicly. This includes information about the perception and use of buildings (for instance, through social media), and structured information about the building's features and characteristics (for instance, through public Linked Data). Hence, first mining (i) the popularity of buildings from the social Web and (ii) then correlating such rankings with certain features of buildings, can provide an efficient method to identify successful architectural patterns. In this paper we propose an approach to rank buildings through the automated mining of Flickr metadata. By further correlating such rankings with building properties described in Linked Data we are able to identify popular patterns for particular building types (airports, bridges, churches, halls, and skyscrapers). Our approach combines crowdsourcing with Web mining techniques to establish influential factors, as well as ground truth to evaluate our rankings. Our extensive experimental results depict that methods tailored to specific structure types allow an accurate measurement of their public perception.", "references": ["S. Bird. Nltk: the natural language toolkit. In Proceedings of the COLING/ACL on Interactive presentation sessions, pages 69--72. Association for Computational Linguistics, 2006.", "P. M. Bluyssen, C. Cox, N. Boschi, M. Maroni, G. Raw, C. Roulet, and F. Foradini. European project hope (health optimisation protocol for energy-efficient buildings). In Healthy Buildings, volume 1, pages 76--81, 2003.", "W. Chow. Proposed fire safety ranking system eb-fsrs for existing high-rise nonresidential buildings in hong kong. Journal of architectural engineering, 8(4):116--124, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786467"}, {"title": "Automatic memory reclamation for lock-free data structures", "authors": ["Nachshon Cohen\n,", "Erez Petrank"], "publication": "OOPSLA 2015: Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nLock-free data-structures are widely employed in practice, yet designing lock-free memory reclamation for them is notoriously difficult. In particular, all known lock-free reclamation schemes are ``manual'' in the sense that the developer has to specify when nodes have retired and may be reclaimed. Retiring nodes adequately is non-trivial and often requires the modification of the original lock-free algorithm. In this paper we present an automatic lock-free reclamation scheme for lock-free data-structures in the spirit of a mark-sweep garbage collection. The proposed algorithm works with any normalized lock-free algorithm and with no need for the programmer to retire nodes or make changes to the algorithm. Evaluation of the proposed scheme on a linked-list and a hash table shows that it performs similarly to the best manual (lock-free) memory reclamation scheme.", "references": ["D. Alistarh, P. Eugster, M. Herlihy, A. Matveev, and N. Shavit. Stacktrack: An automated transactional approach to concurrent memory reclamation. In EuroSys. ACM, 2014.", "J. Auerbach, D. F. Bacon, P. Cheng, D. Grove, B. Biron, C. Gracie, B. McCloskey, A. Micic, and R. Sciampacone. Tax-and-spend: Democratic scheduling for real-time garbage collection. In EMSOFT, pages 245–254, 2008.", "A. Braginsky, A. Kogan, and E. Petrank. Drop the anchor: lightweight memory management for non-blocking data structures. In SPAA, pages 33–42. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814270.2814298"}, {"title": "Interaction Studies with Social Robots", "authors": ["Kerstin Dautenhahn"], "publication": "ICMI '15: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nOver the past 10 years we have seen worldwide an immense growth of research and development into companion robots. Those are robots that fulfil particular tasks, but do so in a socially acceptable manner. The companionship aspect reflects the repeated and long-term nature of such interactions, and the potential of people to form relationships with such robots, e.g. as friendly assistants. A number of companion and assistant robots have been entering the market, two of the latest examples are Aldebaran's Pepper robot, or Jibo (Cynthia Breazeal). Companion robots are more and more targeting particular application areas, e.g. as home assistants or therapeutic tools. Research into companion robots needs to address many fundamental research problems concerning perception, cognition, action and learning, but regardless how sophisticated our robotic systems may be, the potential users need to be taken into account from the early stages of development. The talk will emphasize the need for a highly user-centred approach towards design, development and evaluation of companion robots. An important challenge is to evaluate robots in realistic and long-term scenarios, in order to capture as closely as possible those key aspects that will play a role when using such robots in the real world. In order to illustrate these points, my talk will give examples of interaction studies that my research team has been involved in. This includes studies into how people perceive robots' non-verbal cues, creating and evaluating realistic scenarios for home companion robots using narrative framing, and verbal and tactile interaction of children with the therapeutic and social robot Kaspar. The talk will highlight the issues we encountered when we proceeded from laboratory-based experiments and prototypes to real-world applications.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818346.2818347"}, {"title": "Visual analytics for supporting evidence-based interpretation of molecular cytogenomic findings", "authors": ["Paul Parsons\n,", "Kamran Sedig\n,", "Robert E. Mercer\n,", "Maryam Khordad\n,", "Joan Knoll\n,", "Peter Rogan"], "publication": "VAHC '15: Proceedings of the 2015 Workshop on Visual Analytics in Healthcare", "abstract": "ABSTRACT\nInterpreting molecular cytogenomic findings that cover the human genome (e.g., microarray results) is challenging, as it requires accessing and working with multiple, diverse sources of data that are often large and heterogeneous. These data need to be accessed, queried, and simultaneously integrated to achieve open-ended goals, such as interpreting findings to make diagnoses and engage in genetic counselling. Currently, typical workflows of users are laborious, as data sources are often not integrated and must be accessed separately. Furthermore, large document sets often have to be combed through to assist in interpretation. Analytics tools are needed to help users process and distill large bodies of information into manageable sizes so the most relevant portions can be focused on. Current tools typically do not offer support for interactively exploring and engaging with visual representations of important entities and relationships (e.g., chromosomes, gene-phenotype relationships, and scientific articles). We present VErdICT, a visual analytics tool that can support users in their interpretation of molecular cytogenomic findings. A participatory design approach was taken to make VErdICT human-centered. We describe its development, usability and usefulness, and outline some future research challenges.", "references": ["B. B. Bederson. Interfaces for staying in the flow. Ubiquity, 2004(September): 1--1, 2004.", "M. Brehmer, S. Ingram, J. Stray, and T. Munzner. Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists. IEEE Transactions on Visualization and Computer Graphics, 20(12): 2271--2280, 2014.", "A. Doms and M. Schroeder. GoPubMed: Exploring PubMed with the gene ontology. Nucleic Acids Research, 33(SUPPL. 2), 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2836034.2836036"}, {"title": "Breast cancer classification of mammographic masses using improved shape features", "authors": ["Sailesh Gc\n,", "Chulwoo Pack\n,", "Sung Shin\n,", "Hyung D. Choi"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nBreast cancer classification technique divides breast cancer into two categories, benign tumors and malignant tumors. The main purpose of breast cancer classification is to classify abnormalities into benign or malignant classes and thus help physicians with further analysis by minimizing the possible errors that can be done because of fatigued or inexperienced physician. In this paper, we propose three new shape features to classify mammographic images into benign and malignant class. SVM is used as a machine learning tool for training and classification purpose. In order to evaluate the improved performance of the proposed shape features, convexity, circularity and a modified global shape feature of compactness was used. The result shows that the proposed shape features can improve measure of performances such as MCC, specificity, sensitivity and accuracy and can be a promising tool to provide preliminary decision support information to physicians for further diagnosis.", "references": ["U.S. Breast Cancer Statistics. (2011). {Online}. Available: http://www.breastcancer.org/symptoms/understand_bc/statistics.jsp", "Althuis, M. D., Dozier, J. M., Anderson, W. F., Devesa, S. S., and Brinton, L. A., 2005. Global trends in breast cancer incidence and mortality 1973--1997. Int J Epidemiol 34, 2 (Apr), 405--412. DOI= http://dx.doi.org/10.1093/ije/dyh414.", "American Cancer Society, \"Breast Cancer\", American Cancer Society, Inc., Surveillance and Health Policy Research, Feb 2011"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811507"}, {"title": "Geocoding textual documents through the usage of hierarchical classifiers", "authors": ["Fernando Melo\n,", "Bruno Martins"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we evaluate automated techniques, based on a hierarchical representation for the Earth's surface and leveraging SVM classifiers, for assigning geospatial coordinates to previously unseen documents, using only the raw text as input evidence. We report on experiments with Wikipedia documents in four different languages, and with two Twitter datasets from previous studies. We obtained state-of-the-art results, showing that document geocoding can be handled effectively with appropriate bag-of-words representations and with out-of-the-box supervised learning methods.", "references": ["B. Adams and K. Janowicz. On the geo-indicativeness of non-georeferenced text. In Proceedings of the International AAAI Conference on Weblogs and Social Media, 2012.", "E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-where: geotagging Web content. In Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2004.", "I. Anastácio, B. Martins, and P. Calado. Classifying documents according to locational relevance. In Proceedings of the Portuguese Conference on Artificial Intelligence, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837690"}, {"title": "Inspection of Governmental Sites' Interaction: comparison between methods", "authors": ["Vinicius de Figueiredo Marques\n,", "Breno Augusto Ferreira\n,", "Joao Paulo Pinho\n,", "Rondinely Oliveira\n,", "Cristiano Maciel"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nGovernments make use of internet to be closer with their governed nowadays. Therefore, government sites must be able to be used by anyone who wanted to. The present paper exposes an analysis of three known usability inspection methods (Cognitive Walkthrough, Heuristics Evaluation, g-Quality) and exposes theirs differences and similarities. This paper makes a comparison between them willing to suggest a better usage of them also.", "references": ["Berntzen, L.; Olsen, M. G. 2009. Benchmarking e-government-a comparative review of three international benchmarking studies. In Digital Society, IEEE, pp. 77-82, 2009. IEEE.", "Brasil, CGU. 2013. Relatório sobre a implementação da lei no 12.527: Lei do Acesso à Informação. 2013.", "Eletrônico, GBrasil. 2015. \"Padrões de Interoperabilidade de Governo Eltetrônico - ePing.\", 2015. http://eping.governoeletronico.gov.br/, Novembro."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814160"}, {"title": "Disentangling the Lexicons of Disaster Response in Twitter", "authors": ["Nathan O. Hodas\n,", "Greg Ver Steeg\n,", "Joshua Harrison\n,", "Satish Chikkagoudar\n,", "Eric Bell\n,", "Courtney D. Corley"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nPeople around the world use social media platforms such as Twitter to express their opinion and share activities about various aspects of daily life. In the same way social media changes communication in daily life, it also is transforming the way individuals communicate during disasters and emergencies. Because emergency officials have come to rely on social media to communicate alerts and updates, they must learn how users communicate disaster related content on social media. We used a novel information-theoretic unsupervised learning tool, CorEx, to extract and characterize highly relevant content used by the public on Twitter during known emergencies, such as fires, explosions, and hurricanes. Using the resulting analysis, authorities may be able to score social media content and prioritize their attention toward those messages most likely to be related to the disaster.", "references": ["J. P. Bagrow, D. Wang, and A.-L. Barabasi. Collective response of human populations to large-scale emergencies. PloS one, 6(3):e17680, 2011.", "Booz-Allen-Hamilton. Crisis communications social media round table special report. Report, 2009.", "W. J. Burns. Risk perception: a review. Report, USC, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741728"}, {"title": "An empirical study of end-user programmers in the computer music community", "authors": ["Gregory Burlet\n,", "Abram Hindle"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nComputer musicians are a community of end-user programmers who often use visual programming languages such as Max/MSP or Pure Data to realize their musical compositions. This research study conducts a multifaceted analysis of the software development practices of computer musicians when programming in these visual music-oriented languages. A statistical analysis of project metadata harvested from software repositories hosted on GitHub reveals that in comparison to the general population of software developers, computer musicians' repositories have less commits, less frequent commits, more commits on weekends, yet similar numbers of bug reports and similar numbers of contributing authors. Analysis of source code in these repositories reveals that the vast majority of code can be reconstructed from duplicate fragments. Finally, these results are corroborated by a survey of computer musicians and interviews with individuals in this end-user community. Based on this analysis and feedback from computer musicians we find that there are many avenues where software engineering can be applied to help aid this community of end-user programmers.", "references": ["J. Chadabe, \"Remarks on computer music culture,\" Computer Music Journal, vol. 24, no. 4, pp. 9--11, 2000.", "K. T. Stolee, S. Elbaum, and A. Sarma, \"End-user programmers and their communities: An artifact-based analysis,\" in Proceedings of the International Symposium on Empirical Software Engineering and Measurement, 2011, pp. 147--156.", "A. J. Ko, R. Abraham, L. Beckwith, A. Blackwell, M. Burnett, M. Erwig, J. Lawrance, C. Scaffidi, H. Lieberman, B. A. Myers, M. B. Rosson, G. Rothermel, M. Shaw, and S. Widenbeck, \"The state of the art in end-user software engineering,\" ACM Computing Surveys, vol. 43, no. 3, pp. 1--60, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820554"}, {"title": "RateMyDay: Mobile Tool to Follow the Daily Activities", "authors": ["Joao Wagner Chaves Costa\n,", "Leonardo Cunha de Miranda"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe advance of the Internet, mobile devices and their applications are providing a new range of data and habits that can help achieve our goals everyday and still provide us a better quality of life. In this context, we present the RateMyDay, which is a tool for mobile devices. This tool aims to support people in adapting and monitoring daily routines. People will be able to record and analyze, in a simple, private and personal, their day to day and thus form and monitor your routine life. In a second step, they can analyze your progress through a historical, indexes and statistics.", "references": ["Maeda, J. As Leis da Simplicidade. MIT Press. 2007.", "Schmitz, D. e Lira, D. Angular JS na Prática. Leanpub.", "Boaglio, F. MongoDB: Construa Novas Aplicações com Novas Tecnologias. Casa do Código, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814144"}, {"title": "User Variability and IR System Evaluation", "authors": ["Peter Bailey\n,", "Alistair Moffat\n,", "Falk Scholer\n,", "Paul Thomas"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTest collection design eliminates sources of user variability to make statistical comparisons among information retrieval (IR) systems more affordable. Does this choice unnecessarily limit generalizability of the outcomes to real usage scenarios? We explore two aspects of user variability with regard to evaluating the relative performance of IR systems, assessing effectiveness in the context of a subset of topics from three TREC collections, with the embodied information needs categorized against three levels of increasing task complexity. First, we explore the impact of widely differing queries that searchers construct for the same information need description. By executing those queries, we demonstrate that query formulation is critical to query effectiveness. The results also show that the range of scores characterizing effectiveness for a single system arising from these queries is comparable or greater than the range of scores arising from variation among systems using only a single query per topic. Second, our experiments reveal that searchers display substantial individual variation in the numbers of documents and queries they anticipate needing to issue, and there are underlying significant differences in these numbers in line with increasing task complexity levels. Our conclusion is that test collection design would be improved by the use of multiple query variations per topic, and could be further improved by the use of metrics which are sensitive to the expected numbers of useful documents.", "references": ["O. Alonso, D. E. Rose, and B. Stewart. Crowdsourcing for relevance evaluation. In SIGIR Forum, volume 42, pages 9--15, 2008.", "L. W. Anderson and D. A. Krathwohl. A Taxonomy for Learning, Teaching and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives. Longman, New York, 2001.", "L. Azzopardi, D. Kelly, and K. Brennan. How query cost affects search behavior. In Proc. SIGIR, pages 23--32, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767728"}, {"title": "Fast Democratic Aggregation and Query Fusion for Image Search", "authors": ["Zhanning Gao\n,", "Jianru Xue\n,", "Wengang Zhou\n,", "Shanmin Pang\n,", "Qi Tian"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn image search using local features, to avoid indexing each feature individually, encoding methods are popularly adopted to embed and aggregate local features of an image into a compact vector. Democratic aggregation with triangulation embedding (T-embedding) exhibits significant retrieval accuracy improvement over previous works. However, it suffers high computational complexity. To address this problem and consistently improve the retrieval performance, we propose a new democratic method to accelerate aggregating step without accuracy lost. We also embed weak spatial context in the kernel construction to depress co-occurrence caused by local feature detector. Furthermore, we enhance the retrieval performance with an efficient query fusion strategy. The evaluation on public datasets shows that our democratic aggregation is an order of magnitude faster than the original democratic aggregation with comparable retrieval accuracy, and the query fusion achieves a significant accuracy improvement over previous works.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012.", "R. Arandjelovic and A. Zisserman. All about VLAD. In CVPR, 2013.", "A. Babenko and V. Lempitsky. The inverted multi-index. In CVPR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749293"}, {"title": "Privacy implications of database ranking", "authors": ["Md Farhadur Rahman\n,", "Weimo Liu\n,", "Saravanan Thirumuruganathan\n,", "Nan Zhang\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn recent years, there has been much research in the adoption of Ranked Retrieval model (in addition to the Boolean retrieval model) in structured databases, especially those in a client-server environment (e.g., web databases). With this model, a search query returns top-k tuples according to not just exact matches of selection conditions, but a suitable ranking function. While much research has gone into the design of ranking functions and the efficient processing of top-k queries, this paper studies a novel problem on the privacy implications of database ranking.\nThe motivation is a novel yet serious privacy leakage we found on real-world web databases which is caused by the ranking function design. Many such databases feature private attributes - e.g., a social network allows users to specify certain attributes as only visible to him/herself, but not to others. While these websites generally respect the privacy settings by not directly displaying private attribute values in search query answers, many of them nevertheless take into account such private attributes in the ranking function design. The conventional belief might be that tuple ranks alone are not enough to reveal the private attribute values. Our investigation, however, shows that this is not the case in reality.\nTo address the problem, we introduce a taxonomy of the problem space with two dimensions, (1) the type of query interface and (2) the capability of adversaries. For each subspace, we develop a novel technique which either guarantees the successful inference of private attributes, or does so for a significant portion of real-world tuples. We demonstrate the effectiveness and efficiency of our techniques through theoretical analysis, extensive experiments over real-world datasets, as well as successful online attacks over websites with tens to hundreds of millions of users - e.g., Amazon Goodreads and Renren.com.", "references": ["Amazon goodreads. https://www.goodreads.com/.", "Catch22dating. http://www.catch22dating.com/.", "Eharmony. http://www.eharmony.com."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794379"}, {"title": "Case-based retrieval of similar diabetic patients", "authors": ["Damien Zufferey\n,", "Stefano Bromuri\n,", "Michael Schumacher"], "publication": "PervasiveHealth '15: Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare", "abstract": "ABSTRACT\nPatients suffering from diabetes often develop several comorbidities such as hypertension and dyslipidemia. The presence of the comorbidities leads to more complex patient profiles associated with specific patient treatments. In this paper we present a novel algorithm to help physicians, given a new case, in retrieving similar past patient cases. This novel algorithm is based on the bag-of-words (BoW) model to encode as features, the occurrence of each pre-computed cluster, for each patient, according to the approach of document classification. We then evaluate the algorithm on a real de-identified dataset of 3201 diabetic patients, demonstrating the advantage of our approach.", "references": ["Y. Ko, \"A study of term weighting schemes using class information for text classification,\" in Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, ser. SIGIR '12. New York, NY, USA: ACM, 2012, pp. 1029--1030. {Online}. Available: http://doi.acm.org/10.1145/2348283.2348453", "J. Sivic and A. Zisserman, \"Efficient visual search of videos cast as text retrieval,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 31, no. 4, pp. 591--606, april 2009.", "M. Honarkhah and J. Caers, \"Stochastic simulation of patterns using distance-based pattern modeling,\" Mathematical Geosciences, vol. 42, pp. 487--517, 2010. {Online}. Available: http://dx.doi.org/10.1007/s11004-010-9276-7"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2826165.2826225"}, {"title": "Exploring Statistical Language Models for Recommender Systems", "authors": ["Daniel Valcarce"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nEven though there exist multiple approaches to build recommendation algorithms, algebraic techniques based on vector and matrix representations are predominant in the field. Notwithstanding the fact that these algebraic Collaborative Filtering methods have been demonstrated to be very effective in the rating prediction task, they do not generally provide good results in the top-N recommendation task. In this research, we return to the roots of recommender systems and we explore the relationship between Information Filtering and Information Retrieval. We think that probabilistic methods taken from the latter field such as statistical Language Models can be a more effective and formal way for generating personalised ranks of recommendations. We compare our improvements against several algebraic and probabilistic state-of-the-art algorithms and pave the way to future and promising research directions.", "references": ["R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval: The Concepts and Technology Behind Search. Addison Wesley, 2011.", "N. Barbieri and G. Manco. An Analysis of Probabilistic Methods for Top-N Recommendation in Collaborative Filtering. In ECML PKDD '11, pages 172--187, 2011.", "N. J. Belkin and W. B. Croft. Information Filtering and Information Retrieval: Two Sides of the Same Coin? Commun. ACM, 35(12):29--38, Dec. 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796547"}, {"title": "Challenges in designing an introductory course in big data programming: lightning talk", "authors": ["Roland A. DePratti"], "publication": "Journal of Computing Sciences in Colleges", "abstract": "Abstract\nWe live in a world where massive amounts of data are being generated, leading to advances in disciplines including physics, astronomy, biology, sociology, and business. This so-called Big Data cannot be stored and analyzed using traditional data storage and processing applications, yet its successful storage, mining, and analyses are critical for advances in the fields mentioned above and others. Since April 2014, four Computer Science professors from Eastern Connecticut State University have been participating in Big Data training exercises and developing an Introductory Course in Big Data Programming. However, the broad scope of Big Data and its relative newness pose key challenges to course development.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2753024.2753046"}, {"title": "Multimedia COMMONS -- Community-Organized Multimodal Mining: Opportunities for Novel Solutions (MMCommons Workshop 2015)", "authors": ["Gerald Friedland\n,", "Chong-Wah Ngo\n,", "David Ayman Shamma"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe Multimedia COMMONS workshop laid the groundwork for developing a research community around the Multimedia Genome Project (MMGP), an initiative initially focused on annotation of---and research using---the 99.2 million images and nearly 800,000 videos in the Yahoo Flickr Creative Commons 100 Million dataset (YFCC100M). Current and potential users of the YFCC100M presented new research and systems that used this unprecedentedly large, unprecedentedly open-source dataset; discussed ideas for future data challenges and new benchmarking tasks that would not previously have been possible; and suggested priorities and plans for annotation and distribution based on community needs and interests.", "references": ["J. Bernd, D. Borth, B. Elizalde, G. Friedland, H. Gallagher, L. Gottlieb, A. Janin, S. Karabashlieva, J. Takahashi, and J. Won. The YLI-MED corpus: Characteristics, procedures, and plans (ICSI Technical Report TR-15-001). arXiv:1503.04250, 2015.", "J. Choi, B. Thomee, G. Friedland, L. Cao, K. Ni, D. Borth, B. Elizalde, L. Gottlieb, C. Carrano, R. Pearce, and D. Poland. The Placing Task: A large-scale geo-estimation challenge for social-media videos and images. In Proceedings of the ACM Multimedia 2014 Workshop on Geotagging and Its Applications in Multimedia (GeoMM '14), Orlando, FL, November 2014. Association for Computing Machinery.", "B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. YFCC100M: The new data in multimedia research. Communications of the ACM, 2015. To appear."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806409"}, {"title": "Wikipedia Page View Reflects Web Search Trend", "authors": ["Mitsuo Yoshida\n,", "Yuki Arase\n,", "Takaaki Tsunoda\n,", "Mikio Yamamoto"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nThe frequency of a web search keyword generally reflects the degree of public interest in a particular subject matter. Search logs are therefore useful resources for trend analysis. However, access to search logs is typically restricted to search engine providers. In this paper, we investigate whether search frequency can be estimated from a different resource such as Wikipedia page views of open data. We found frequently searched keywords to have remarkably high correlations with Wikipedia page views. This suggests that Wikipedia page views can be an effective tool for determining popular global web search trends.", "references": ["Choi, Hyunyoung and Varian, Hal. Predicting the Present with Google Trends. Economic Record, 88, s1 (June 2012), 2--9.", "Radinsky, Kira, Davidovich, Sagie, and Markovitch, Shaul. Predicting the News of Tomorrow Using Patterns in Web Search Queries. Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (Dec. 2008), 363--367.", "Jansen, Bernard J and Spink, Amanda H. An analysis of web searching by European alltheweb.com users. Information Processing and Management, 41, 2 (Mar. 2005), 361--381."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786495"}, {"title": "What's in this paper?: Combining Rhetorical Entities with Linked Open Data for Semantic Literature Querying", "authors": ["Bahar Sateli\n,", "René Witte"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nFinding research literature pertaining to a task at hand is one of the essential tasks that scientists face on daily basis. Standard information retrieval techniques allow to quickly obtain a vast number of potentially relevant documents. Unfortunately, the search results then require significant effort for manual inspection, where we would rather select relevant publications based on more fine-grained, semantically rich queries involving a publication's contributions, methods, or application domains. We argue that a novel combination of three distinct methods can significantly advance this vision: (i) Natural Language Processing (NLP) for Rhetorical Entity (RE) detection; (ii) Named Entity (NE) recognition based on the Linked Open Data (LOD) cloud; and (iii) automatic generation of RDF triples for both NEs and REs using semantic web ontologies to interconnect them. Combined in a single workflow, these techniques allow us to automatically construct a knowledge base that facilitates numerous advanced use cases for managing scientific documents.", "references": ["C. Blake. Beyond genes, proteins, and abstracts: Identifying scientific claims from full-text biomedical articles. Journal of Biomedical Informatics, 43(2):173 -- 189, 2010.", "H. Cunningham et al. Text Processing with GATE (Version 6) ARGE X. University of Sheffield, Department of Computer Science, 2011.", "J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes. Improving Efficiency and Accuracy in Multilingual Entity Extraction. In Proc. of the 9th Intl. Conf. on Semantic Systems (I-Semantics), 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742022"}, {"title": "Sub-document Timestamping of Web Documents", "authors": ["Yue Zhao\n,", "Claudia Hauff"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nKnowledge about a (Web) document's creation time has been shown to be an important factor in various temporal information retrieval settings. Commonly, it is assumed that such documents were created at a single point in time. While this assumption may hold for news articles and similar document types, it is a clear oversimplification for general Web documents. In this paper, we investigate to what extent (i) this simplifying assumption is violated for a corpus of Web documents, and, (ii) it is possible to accurately estimate the creation time of individual Web documents' components (so-called sub-documents).", "references": ["L. Breiman. Random forests. Machine learning, 45(1):5--32, 2001.", "R. Campos, G. Dias, A. M. Jorge, and A. Jatowt. Survey of temporal information retrieval and related applications. ACM Computing Surveys (CSUR), 47(2):15, 2014.", "N. Chambers. Labeling documents with timestamps: Learning from their time expressions. In ACL '12, pages 98--106, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767803"}, {"title": "A Scheduling Method for Area-based Broadcasting Considering Loading Time", "authors": ["Yusuke Gotoh\n,", "Tomoki Yoshihisa"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nDue to the recent popularization of digital broadcasting systems, clients can have several types of watching contents. In addition, area-based broadcasting using the bandwidth that is not used in radio broadcasting has attracted great attention. In area-based network environment, the server can deliver continuous media data such as audio and video to clients in a limited area. In area-based broadcasting, since the server delivers data repeatedly, clients have to wait until their data are broadcast. To reduce the waiting time, many studies employ the division based broadcasting technique, which reduces waiting time by dividing the data into several segments and frequently broadcasting the precedent segments. When the server makes the broadcast schedule in area-based broadcasting, it needs to consider both loading times of highlight scene and main scene. In broadcasting, since playing time of the commercial contents is predetermined, the server needs to make the broadcast schedule according to the consumption rate and the number of channels by setting both loading times of the highlight scene and the main scene. In this paper, we propose a scheduling method considering loading time for area-based broadcasting. In our scheduling method, since the server makes the broadcast schedule using a different ratio of dividing data for the highlight scene and the main scene respectively, waiting time is reduced effectively.", "references": ["WHITE PAPER Information and Communications in Japan (2011). http://www.soumu.go.jp/johotsusintokei/whitepaper/eng/WP2011/2011-index.html.", "The Review Team of a New Vision for Utilizing Radio Waves (2010). http://www.soumu.go.jp/main_sosiki/joho_tsusin/eng/councilreport/pdf/100806_l.pdf.", "T. Yoshihisa, M. Tsukamoto, and S. Nishio: A Broadcasting Scheme for Continuous Media Data with Restictions in Data Division, Proc. IPSJ International Conference on Mobile Compuring and Ubiquitous Networking (ICMU'05), pp.90--95 (2005)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2837175"}, {"title": "DigInPix: Visual Named-Entities Identification in Images and Videos", "authors": ["Pierre Letessier\n,", "Nicolas Hervé\n,", "Alexis Joly\n,", "Hakim Nabi\n,", "Mathieu Derval\n,", "Olivier Buisson"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper presents an automatic system able to identify visual named-entities appearing in images and videos, among a list of 25,000 entities, aggregated from Wikipedia lists, and more specific websites. DigInPix is a generic application designed to identify different kinds of entities. In this first attempt, we only focus on logo identification (more generally on legal persons). The identification process mainly relies on an efficient CBIR system, searching in an indexed image database composed of 600,000 weak-labelled images crawled from Google Images. DigInPix proposes a responsive-design html5 interface [1] for testing purposes.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012.", "D. Carmel, M.-W. Chang, E. Gabrilovich, B.-J. P. Hsu, and K. Wang. ERD 2014: Entity recognition and disambiguation challenge. SIGIR Forum, 2014.", "P.-H. Gosselin, N. Murray, H. Jégou, and F. Perronnin. Revisiting the fisher vector for fine-grained classification. Pattern Recognition Letters, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749369"}, {"title": "RAIDShield: Characterizing, Monitoring, and Proactively Protecting Against Disk Failures", "authors": ["Ao Ma\n,", "Rachel Traylor\n,", "Fred Douglis\n,", "Mark Chamness\n,", "Guanlin Lu\n,", "Darren Sawyer\n,", "Surendar Chandra\n,", "Windsor Hsu"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nModern storage systems orchestrate a group of disks to achieve their performance and reliability goals. Even though such systems are designed to withstand the failure of individual disks, failure of multiple disks poses a unique set of challenges. We empirically investigate disk failure data from a large number of production systems, specifically focusing on the impact of disk failures on RAID storage systems. Our data covers about one million SATA disks from six disk models for periods up to 5 years. We show how observed disk failures weaken the protection provided by RAID. The count of reallocated sectors correlates strongly with impending failures.\nWith these findings we designed RAIDShield, which consists of two components. First, we have built and evaluated an active defense mechanism that monitors the health of each disk and replaces those that are predicted to fail imminently. This proactive protection has been incorporated into our product and is observed to eliminate 88% of triple disk errors, which are 80% of all RAID failures. Second, we have designed and simulated a method of using the joint failure probability to quantify and predict how likely a RAID group is to face multiple simultaneous disk failures, which can identify disks that collectively represent a risk of failure even when no individual disk is flagged in isolation. We find in simulation that RAID-level analysis can effectively identify most vulnerable RAID-6 systems, improving the coverage to 98% of triple errors.\nWe conclude with discussions of operational considerations in deploying RAIDShield more broadly and new directions in the analysis of disk errors. One interesting approach is to combine multiple metrics, allowing the values of different indicators to be used for predictions. Using newer field data that reports an additional metric, medium errors, we find that the relative efficacy of reallocated sectors and medium errors varies across disk models, offering an additional way to predict failures.", "references": ["Bruce Allen. 2004. Monitoring hard disks with S.M.A.R.T. Linux Journal 2004, 117, 9.", "A. Alvarez, Walter A. Burkhard, and Flaviu Cristian. 1997. Tolerating multiple failures in RAID architectures with optimal storage and uniform declustering. In Proceedings of the 24th International Symposium on Computer Architecture (ISCA’97). 62--72. DOI:http://dx.doi.org/10.1145/264107.264132", "Ahmed Amer, Darrell D. E. Long, and S. J. Thomas Schwarz. 2014. Reliability challenges for storing exabytes. In Proceedings of the 2014 International Conference on Computing, Networking and Communications (ICNC). IEEE, 907--913."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820615"}, {"title": "Towards maximum independent sets on massive graphs", "authors": ["Yu Liu\n,", "Jiaheng Lu\n,", "Hua Yang\n,", "Xiaokui Xiao\n,", "Zhewei Wei"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMaximum independent set (MIS) is a fundamental problem in graph theory and it has important applications in many areas such as social network analysis, graphical information systems and coding theory. The problem is NP-hard, and there has been numerous studies on its approximate solutions. While successful to a certain degree, the existing methods require memory space at least linear in the size of the input graph. This has become a serious concern in view of the massive volume of today's fast-growing graphs.\nIn this paper, we study the MIS problem under the semi-external setting, which assumes that the main memory can accommodate all vertices of the graph but not all edges. We present a greedy algorithm and a general vertex-swap framework, which swaps vertices to incrementally increase the size of independent sets. Our solutions require only few sequential scans of graphs on the disk file, thus enabling in-memory computation without costly random disk accesses. Experiments on large-scale datasets show that our solutions are able to compute a large independent set for a massive graph with 59 million vertices and 151 million edges using a commodity machine, with a memory cost of 469MB and a time cost of three minutes, while yielding an approximation ratio that is around 99% of the theoretical optimum.", "references": ["An implementation of the C++ standard template library STL for external memory computations. http://stxxl.sourceforge.net.", "J. Abello, A. L. Buchsbaum, and J. Westbrook. A functional approach to external graph algorithms. Algorithmica, 32(3):437--458, 2002.", "W. Aiello, F. R. K. Chung, and L. Lu. A random graph model for massive graphs. In Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, May 21--23, 2000, Portland, OR, USA, pages 171--180, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2831360.2831366"}, {"title": "Development and Evaluation of Search Tasks for IIR Experiments using a Cognitive Complexity Framework", "authors": ["Diane Kelly\n,", "Jaime Arguello\n,", "Ashlee Edwards\n,", "Wan-ching Wu"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nOne of the most challenging aspects of designing interactive information retrieval (IIR) experiments with users is the development of search tasks. We describe an evaluation of 20 search tasks that were designed for use in IIR experiments and developed using a cognitive complexity framework from educational theory. The search tasks represent five levels of cognitive complexity and four topical domains. The tasks were evaluated in the context of a laboratory IIR experiment with 48 participants. Behavioral and self-report data were used to characterize and understand differences among tasks. Results showed more cognitively complex tasks required significantly more search activity from participants (e.g., more queries, clicks, and time to complete). However, participants did not evaluate more cognitively complex tasks as more difficult and were equally satisfied with their performances across tasks. Our work makes four contributions: (1) it adds to what is known about the relationship among task, search behaviors and user experience; (2) it presents a framework for task creation and evaluation; (3) it provides tasks and questionnaires that can be reused by others and (4) it raises questions about findings and assumptions of many recent studies that only use behavioral signals from search logs as evidence for task difficulty and searcher satisfaction, as many of our results directly contradict these findings.", "references": ["Ageev, M., Guo, Q., Lagun, D. & Agichtein, E. (2011). Find it if you can: A game for modeling different types of web search success using interaction data. Proc. of SIGIR, 345--354.", "Allan, J., Croft, B., Moffat, A. & Sanderson, M. (Eds). (2012). Frontiers, challenges and opportunities for Information retrieval: Report from SWIRL 2012. SIGIR Forum, 46(1), 2--32.", "Anderson, L. W. & Krathwohl, D. A. (2001). A taxonomy for learning, teaching and assessing: A revision of Bloom's taxonomy of educational objectives. New York: Longman."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809465"}, {"title": "End-to-end solution for accessible chemical diagrams", "authors": ["Volker Sorge\n,", "Mark Lee\n,", "Sandy Wilkinson"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nChemical diagrams are an important means of conveying information in chemistry and biosciences to students, starting as early as secondary school. But even in electronic teaching material, diagrams are commonly given as bitmap graphics leaving them inaccessible for visually impaired learners. We present an end-to-end solution to making these diagrams Web accessible, by employing image analysis solutions to recognise and semantically analyse diagrams, and by regenerating them in a format that makes them amenable to assistive technology. We provide software tools that allow readers to interactively engage with diagrams by exploring them step-wise and on different layers, enabling aural rendering of diagrams and their individual components together with highlighting and magnification to assist readers with low vision or learning difficulties. Our technology builds on open standards, supporting a number of computing platforms, browsers, and screen readers, and is extensible to diagrams in other STEM subjects.", "references": ["A. Brown, S. Pettifer, and R. Stevens. Evaluation of a non-visual molecule browser. ACM SIGACCESS Accessibility and Computing, 77--78: 40--47, 2004.", "A. Brown, R. Stevens, and S. Pettifer. Audio representation of graphs: A quick look. In Proc. of Audit. Displays, 2006.", "L. Brown, S. Brewster, S. Ramloll, R. Burton, and B. Riedel. Design guidelines for audio presentation of graphs and tables. In Proc. on Auditory Display, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746667"}, {"title": "Understanding Complex Networks Using Graph Spectrum", "authors": ["Yanhua Li\n,", "Zhi-Li Zhang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nComplex networks are becoming indispensable parts of our lives. The Internet, wireless (cellular) networks, online social networks, and transportation networks are examples of some well-known complex networks around us. These networks generate an immense range of big data: weblogs, social media, the Internet traffic, which have increasingly drawn attentions from the computer science research community to explore and investigate the fundamental properties of, and improve the user experiences on, these complex networks. This work focuses on understanding complex networks based on the graph spectrum, namely, developing and applying spectral graph theories and models for understanding and employing versatile and oblivious network information -- asymmetrical characteristics of the wireless transmission channels, multiplex social relations, e.g., trust and distrust relations, etc -- in solving various application problems, such as estimating transmission cost in wireless networks, Internet traffic engineering, and social influence analysis in social networks.", "references": ["D. Aldous and J. A. Fill. Reversible markov chains and random walks on graphs. http://www.stat.berkeley.edu/ Aldous/RWG/book.html.", "D. Boley, G. Ranjan, and Z.-L. Zhang. Commute times for a directed graph using an asymmetric laplacian. Linear Algebra and its Applications, 435(2):224--242, 2011.", "C.-K. Chau and P. Basu. Exact analysis of latency of stateless opportunistic forwarding. In INFOCOM 2009, pages 828--836. IEEE, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744718"}, {"title": "Mining Missing Hyperlinks from Human Navigation Traces: A Case Study of Wikipedia", "authors": ["Robert West\n,", "Ashwin Paranjape\n,", "Jure Leskovec"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nHyperlinks are an essential feature of the World Wide Web. They are especially important for online encyclopedias such as Wikipedia: an article can often only be understood in the context of related articles, and hyperlinks make it easy to explore this context. But important links are often missing, and several methods have been proposed to alleviate this problem by learning a linking model based on the structure of the existing links. Here we propose a novel approach to identifying missing links in Wikipedia. We build on the fact that the ultimate purpose of Wikipedia links is to aid navigation. Rather than merely suggesting new links that are in tune with the structure of existing links, our method finds missing links that would immediately enhance Wikipedia's navigability. We leverage data sets of navigation paths collected through a Wikipedia-based human-computation game in which users must find a short path from a start to a target article by only clicking links encountered along the way. We harness human navigational traces to identify a set of candidates for missing links and then rank these candidates. Experiments show that our procedure identifies missing links of high quality.", "references": ["L. Adamic and E. Adar. Friends and neighbors on the Web. Social Networks, 25(3):211--230, 2003.", "M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: A game for modeling different types of Web search success using interaction data. In SIGIR, 2011.", "Amazon.com. Mechanical Turk. Website, 2014. http://www.mturk.com (accessed Nov.\\ 10, 2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741666"}, {"title": "A concurrent k-NN search algorithm for R-tree", "authors": ["Jagat Sesh Challa\n,", "Poonam Goyal\n,", "S. Nikhil\n,", "Sundar Balasubramaniam\n,", "Navneet Goyal"], "publication": "Compute '15: Proceedings of the 8th Annual ACM India Conference", "abstract": "ABSTRACT\nk-nearest neighbor (k-NN) search is one of the commonly used query in database systems. It has its application in various domains like data mining, decision support systems, information retrieval, multimedia and spatial databases, etc. When k-NN search is performed over large data sets, spatial data indexing structures such as R-trees are commonly used to improve query efficiency. The best-first k-NN (BF-kNN) algorithm is the fastest known k-NN over R-trees. We present CBF-kNN, a concurrent BF-kNN for R-trees, which is the first concurrent version of k-NN we know of for R-trees. CBF-kNN uses one of the most efficient concurrent priority queues known as mound. CBF-kNN overcomes the concurrency limitations of priority queues by using a tree-parallel mode of execution. CBF-kNN has an estimated speedup of O(p/k) for p threads. Experimental results on various real datasets show that the speedup in practice is close to this estimate.", "references": ["T. Cover and P. Hart. 1967. Nearest neighbor pattern classification. IEEE Trans. Inf. Theo. 13,1(Sep 1967), 21--27.", "N. Bhatia and Vandana. 2010. Survey of Nearest Neighbor Techniques. International Journal of Computer Science & Information Security (IJCSIS'10) 8, 2 (2010), 302--305.", "A. Guttman. 1984. R-trees: a dynamic index structure for spatial searching. SIGMOD Rec.14, 2 (June 1984), 47--57."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835043.2835050"}, {"title": "Community-aware ranking algorithms for expert identification in question-answer forums", "authors": ["Mohsen Shahriari\n,", "Sathvik Parekodi\n,", "Ralf Klamma"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nQuestion-Answer forums (QAF) are significant platforms for disseminating informal information and play important role in problem solving and learning. Expert identification still has some limitations and link analysis methods do not consider community dimension. In this paper an authority analysis approach for identifying experts is proposed. This approach combines overlapping community detection (OCD) algorithms with ranking methods to compute the nodes' expertise level in QAFs. Firstly, graph resulting from a specific search query is computed and an OCD algorithm is applied on it. After identifying clusters of nodes, we change updating rules of original Hyperlink-Induced Topic Search (HITS) and PageRank to take the effect of intra cluster links and extra cluster connections. People whom are intra or overlapping to a community possess higher vision about context of the community than nodes which are outside. We experimented the proposed overlapping community-aware ranking algorithms and compared them with baseline approaches on online forums. Results indicate that OCD improves expert identification accuracy and relevancy.", "references": ["M. Bouguessa, B. Dumoulin, and S. Wang. Identifying authoritative actors in question-answering forums: The case of yahoo! answers. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '08, pages 866--874, New York and NY and USA, 2008. ACM.", "A. Bozzon, M. Brambilla, S. Ceri, M. Silvestri, and G. Vesci. Choosing the right crowd: expert finding in social networks. In N. W. Paton and G. Guerrini, editors, The 16th International Conference on Extending Database Technology, pages 637--648, New York, 2013. ACM.", "L. Chen and R. Nayak. Expertise analysis in a question answer portal for author ranking. In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 01, WI-IAT '08, pages 134--140, Washington and DC and USA, 2008. IEEE Computer Society."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809592"}, {"title": "Efficient $$k$$k-closest pair queries in general metric spaces", "authors": ["Yunjun Gao\n,", "Lu Chen\n,", "Xinhan Li\n,", "Bin Yao\n,", "Gang Chen"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nGiven two object sets $$P$$P and $$Q$$Q, a k-closest pair$$(k\\hbox {CP})$$(kCP)query finds $$k$$k closest object pairs from $$P\\times Q$$P Q. This operation is common in many real-life applications such as GIS, data mining, and recommender systems. Although it has received much attention in the Euclidean space, there is little prior work on the metric space. In this paper, we study the problem of kCP query processing in general metric spaces, namely Metric kCP$$(\\hbox {M}k\\hbox {CP})$$(MkCP)search, and propose several efficient algorithms using dynamic disk-based metric indexes (e.g., M-tree), which can be applied to arbitrary type of data as long as a certain metric distance is defined and satisfies the triangle inequality. Our approaches follow depth-first and/or best-first traversal paradigm(s), employ effective pruning rules based on metric space properties and the counting information preserved in the metric index, take advantage of aggressive pruning and compensation to further boost query efficiency, and derive a node-based cost model for $$\\hbox {M}k\\hbox {CP}$$MkCP retrieval. In addition, we extend our techniques to tackle two interesting variants of $$\\hbox {M}k\\hbox {CP}$$MkCP queries. Extensive experiments with both real and synthetic data sets demonstrate the performance of our proposed algorithms, the effectiveness of our developed pruning rules, and the accuracy of our presented cost model.", "references": ["Achtert, E., Kriegel, H.P., Kroger, P., Renz, M., Zufle, A.: Reverse $$k$$k-nearest neighbor search in dynamic and general metric databases. In: EDBT, pp. 886---897 (2009)", "Alvarez, M., Pan, A., Raposo, J., Bellas, F., Cacheda, F.: Using clustering and edit distance techniques for automatic web data extraction. In: WISE, pp. 212---224 (2007)", "Angiulli, F., Pizzuti, C.: An approximate algorithm for top-$$k$$k closest pairs join query in large high dimensional data. Data Knowl. Eng. 53(3), 263---281 (2005)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0383-4"}, {"title": "Compact Snippet Caching for Flash-based Search Engines", "authors": ["Rui Zhang\n,", "Pengyu Sun\n,", "Jiancong Tong\n,", "Rebecca Jane Stones\n,", "Gang Wang\n,", "Xiaoguang Liu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn response to a user query, search engines return the top-k relevant results, each of which contains a small piece of text, called a snippet, extracted from the corresponding document. Obtaining a snippet is time consuming as it requires both document retrieval (disk access) and string matching (CPU computation), so caching of snippets is used to reduce latency. With the trend of using flash-based solid state drives (SSDs) instead of hard disk drives for search engine storage, the bottleneck of snippet generation shifts from I/O to computation. We propose a simple, but effective method for exploiting this trend, which we call fragment caching: instead of caching the whole snippet, we only cache snippet metadata which describe how to retrieve the snippet from the document. While this approach increases I/O time, the cost is insignificant on SSDs. The major benefit of fragment caching is the ability to cache the same snippets (without loss of quality) while only using a fraction of the memory the traditional method requires. In our experiments, we find around 10 times less memory is required to achieve comparable snippet generation times for dynamic memory, and we consistently achieve a vastly greater hit ratio for static caching.", "references": ["R. A. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and F. Silvestri. The impact of caching on search engines. In Proc. SIGIR, pages 183--190, 2007.", "L. A. Barroso, J. Dean, and U. Hölzle. Web search for a planet: The google cluster architecture. IEEE Micro, 23(2):22--28, 2003.", "D. Ceccarelli, C. Lucchese, S. Orlando, R. Perego, and F. Silvestri. Caching query-biased snippets for efficient retrieval. In Proc. EDBT, pages 93--104, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767764"}, {"title": "Automatic Determination of Hyperlink Destination in Web Index", "authors": ["Yosuke Aoki\n,", "Ryosuke Koshijima\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nIn general, a search engine is used to obtain information about specified keywords of interest. However, users must go through the list of web pages presented by the search engine in order to find the page that meets the purpose. In order to reduce this burden, we propose Web Index (WIX), a hyperlink generation system that achieves joining information resources on the web. The WIX system replaces keywords that appear in Web documents on browser into hyperlinks to a specific web page group of the user's choice. However, when there are multiple URLs paired up with a keyword, there is a need to choose the web page that meets the user's purpose. In this paper, we propose WIX System and an architecture that decides and presents likely candidates for hyperlink destination based on similarity of URLs and the content of each candidate.", "references": ["Masahiro Hayashi, Motomichi Toyama \"Keio WIX System (1) User Interface (Japanese)\". DEIM '11 The 3rd Forum on Data Engineering and Information Management. 2011.", "Ryosuke Mori, Motomichi Toyama \"Keio WIX System (2) The implementation in Server-side' (Japanese)'. DEIM '11 The 3rd Forum on Data Engineering and Information Management. 2011.", "Alfred V. Aho and Margaret J. Corasick. Efficient string matching: An aid to bibliographic search. Commun. ACM, Vol. 18, No. 6, pp. 333--340, June 1975."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790784"}, {"title": "Estimating a Ranked List of Human Genetic Diseases by Associating Phenotype-Gene with Gene-Disease Bipartite Graphs", "authors": ["Md Zia Ullah\n,", "Masaki Aono\n,", "Md Hanif Seddiqui"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nWith vast amounts of medical knowledge available on the Internet, it is becoming increasingly practical to help doctors in clinical diagnostics by suggesting plausible diseases predicted by applying data and text mining technologies. Recently, Genome-Wide Association Studies (GWAS) have proved useful as a method for exploring phenotypic associations with diseases. However, since genetic diseases are difficult to diagnose because of their low prevalence, large number, and broad diversity of symptoms, genetic disease patients are often misdiagnosed or experience long diagnostic delays. In this article, we propose a method for ranking genetic diseases for a set of clinical phenotypes. In this regard, we associate a phenotype-gene bipartite graph (PGBG) with a gene-disease bipartite graph (GDBG) by producing a phenotype-disease bipartite graph (PDBG), and we estimate the candidate weights of diseases. In our approach, all paths from a phenotype to a disease are explored by considering causative genes to assign a weight based on path frequency, and the phenotype is linked to the disease in a new PDBG. We introduce the Bidirectionally induced Importance Weight (BIW) prediction method to PDBG for approximating the weights of the edges of diseases with phenotypes by considering link information from both sides of the bipartite graph. The performance of our system is compared to that of other known related systems by estimating Normalized Discounted Cumulative Gain (NDCG), Mean Average Precision (MAP), and Kendall’s tau metrics. Further experiments are conducted with well-known TF · IDF, BM25, and Jenson-Shannon divergence as baselines. The result shows that our proposed method outperforms the known related tool Phenomizer in terms of NDCG@10, NDCG@20, MAP@10, and MAP@20; however, it performs worse than Phenomizer in terms of Kendall’s tau-b metric at the top-10 ranks. It also turns out that our proposed method has overall better performance than the baseline methods.", "references": ["M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. Butler, J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, J. T. Eppig, and others. 2000. Gene ontology: Tool for the unification of biology. Nature Genetics 25, 1 (2000), 25.", "S Aymé. 2003. Orphanet, an information site on rare diseases. Soins; la revue de référence infirmière 672 (2003), 46--47.", "A. Bankier and C. G. Keith. 1989. Short communication: POSSUM: The microcomputer laser-videodisk syndrome information system. Ophthalmic Genetics 10, 1 (1989), 51--52."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700487"}, {"title": "An interactive exploratory search system for on-line apparel shopping", "authors": ["Eriko Koike\n,", "Takayuki Itoh"], "publication": "VINCI '15: Proceedings of the 8th International Symposium on Visual Information Communication and Interaction", "abstract": "ABSTRACT\nMany people (especially women) tend to take relatively longer time for shopping. This paper presents a system for product retrieval inspired by psychology of women's shopping activity, and an implementation of the system for apparel products. Our study supposes products which pre-defined keywords are assigned, and prepares icons representing the combination of the keywords. The system intuitively displays various icons in a display space to demonstrate the diversity of the products. When a user selects an interested icon, the system switches the display to a set of images corresponding to the selected icon, so that the user can visually compare the similar products. The system also features user interfaces to input the preference of users, and reflects the input to the evolutionary computation which adjusts the selection of icons to their preferences. It acts real shopping behavior because we often firstly look over the shops to understand the diversity of products, and then close up the particular groups of the products. This paper introduces an experiment which demonstrates the preferable assistance of the shopping behavior of women who are interested in various products.", "references": ["J. S. Breese, D. Heckerman, C. Kadir, Empirical analysis of predictive algorithms for collaborative filtering, Uncertainty in Artificial Intelligence, 43--52, 1998.", "J.-D. Fekete, C. Plaisant, Excentric labeling; dynamic neighborhood labeling for data visualization, SIGCHI conference on Human Factors in Computer Systems, 512--519, 1999.", "T, Hiroyasu, H. Yokouchi, M. Tanaka, M. Miki, Extraction of design variables using collaborative filtering for interactive genetic algorithms, IEEE International Conference on Fuzzy Systems, 1579--1584, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801040.2801041"}, {"title": "Question Quality in Community Question Answering Forums: a survey", "authors": ["Antoaneta Baltadzhieva\n,", "Grzegorz Chrupała"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nCommunity Question Answering websites (CQA) offer a new opportunity for users to provide, search and share knowledge. Although the idea of receiving a direct, targeted response to a question sounds very attractive, the quality of the question itself can have an important effect on the likelihood of getting useful answers. High quality questions improve the CQA experience and therefore it is essential for CQA forums to better understand what characterizes questions that are more appealing for the forum community. In this survey, we review existing research on question quality in CQA websites. We discuss the possible measures of question quality and the question features that have been shown to influence question quality.", "references": ["Adamic, L. A., Zhang, J., Bakshy, E., & Ackerman, M. S. (2008). Knowledge sharing and yahoo answers: Everyone knows something. Proceedings of the 17th international conference on the World Wide Web", "Agichtein, E., Castillo, C., Donato, D., Gionis, A., & Mishne, G. (2008). Finding high-quality content in social media. Proceedings of WSDM.", "Ahn, J., Butler, B.S., Weng, C. & Webster, S. (2013). Learning to be a Better Q'er in Social Q&A Sites: Social Norms and Information Artifacts. Proceedings of the Association for Information Science & Technology, 1--10"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830544.2830547"}, {"title": "An empirical study on stack overflow using topic analysis", "authors": ["Jie Zou\n,", "Ling Xu\n,", "Weikang Guo\n,", "Meng Yan\n,", "Dan Yang\n,", "Xiaohong Zhang"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nProgramming question and answer (Q&A) websites, such as Stack Overflow, gathered knowledge and expertise of developers from all over the world, this knowledge reflects some insight into the development activities. To comprehend the actual thoughts and needs of the developers, we analyzed the nonfunctional requirements (NFRs) on Stack Overflow. In this paper, we acquired the textual content of Stack Overflow discussions, utilized the topic model, latent Dirichlet allocation (LDA), to discover the main topics of Stack Overflow discussions, and we used the wordlists to find the relationship between the discussions and NFRs. We focus on the hot and unresolved NFRs, the evolutions and trends of the NFRs in their discussions. We found that the most frequent topics the developers discuss are about usability and reliability while they concern few about maintainability and efficiency. The most unresolved problems also occurred in usability and reliability. Moreover, from the visualization of the NFR evolutions over time, we can find the trend for each NFR.", "references": ["A. Hindle, M. W. Godfrey, and R. C. Holt, \"What's hot and what's not: Windowed developer topic analysis,\" in Software Maintenance, 2009. ICSM 2009. IEEE International Conference on, 2009, pp. 339--348.", "A. Hindle, N. Ernst, M. W. Godfrey, R. C. Holt, and J. Mylopoulos, \"What's in a name? on the automated topic naming of software maintenance activities,\" submission http//softwareprocess. es/whats-in-a-name, vol. 125, pp. 150--155, 2010.", "D. M. Blei, A. Y. Ng, and M. I. Jordan, \"Latent dirichlet allocation,\" J. Mach. Learn. Res., vol. 3, pp. 993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820583"}, {"title": "Building and Using Models of Information Seeking, Search and Retrieval: Full Day Tutorial", "authors": ["Leif Azzopardi\n,", "Guido Zuccon"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUnderstanding how people interact with information systems when searching is central to the study of Interactive Information Retrieval (IIR). While much of the prior work in this area has either been conceptual, observational or empirical, recently there has been renewed interest in developing mathematical models of information seeking and search. This is because such models can provide a concise and compact representation of search behaviours and naturally generate testable hypotheses about search behaviour. This full day tutorial focuses on explaining and building formal models of Information Seeking and Retrieval. The tutorial is structured into four sessions. In the first session we will discuss the rationale of modelling and examine a number of early formal models of search (including early cost models and the Probability Ranking Principle). Then we will examine more contemporary formal models (including Information Foraging Theory, the Interactive Probability Ranking Principle, and Search Economic Theory). The focus will be on the insights and intuitions that we can glean from the math behind these models. The latter sessions will be dedicated to building models that optimise particular objectives which drive how users make decisions, along with a how-to guide on model building, where we will describe different techniques (including analytical, graphical and computational) that can be used to generate hypotheses from such models. In the final session, participants will be challenged to develop a simple model of interaction applying the techniques learnt during the day, before concluding with an overview of challenges and future directions.\nThis tutorial is aimed at participants wanting to know more about the various formal models of information seeking, search and retrieval, that have been proposed in the literature. The tutorial will be presented at an introductory level, and is designed to support participants who want to be able to understand and apply such models, as well as to build their own models.", "references": ["C. W. Axelrod. The economic evaluation of information storage and retrieval systems. Information Processing & Management, 13(2):117--124, 1977.", "L. Azzopardi. Query side evaluation: an empirical analysis of effectiveness and effort. In Proc. of SIGIR, pages 556--563. ACM, 2009.", "L. Azzopardi. The economics in interactive information retrieval. In Proc. of SIGIR, pages 15--24. ACM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767874"}, {"title": "On the Reusability of Open Test Collections", "authors": ["Seyyed Hadi Hashemi\n,", "Charles L.A. Clarke\n,", "Adriel Dean-Hall\n,", "Jaap Kamps\n,", "Julia Kiseleva"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCreating test collections for modern search tasks is increasingly more challenging due to the growing scale and dynamic nature of content, and need for richer contextualization of the statements of request. To address these issues, the TREC Contextual Suggestion Track explored an open test collection, where participants were allowed to submit any web page as a result for a personalized venue recommendation task. This prompts the question on the reusability of the resulting test collection: How does the open nature affect the pooling process? Can participants reliably evaluate variant runs with the resulting qrels? Can other teams evaluate new runs reliably? In short, does the set of pooled and judged documents effectively produce a post hoc test collection? Our main findings are the following: First, while there is a strongly significant rank correlation, the effect of pooling is notable and results in underestimation of performance, implying the evaluation of non-pooled systems should be done with great care. Second, we extensively analyze impacts of open corpus on the fraction of judged documents, explaining how low recall affects the reusability, and how the personalization and low pooling depth aggravate that problem. Third, we outline a potential solution by deriving a fixed corpus from open web submissions.", "references": ["C. Buckley, D. Dimmick, I. Soboroff, and E. Voorhees. Bias and the limits of pooling for large collections. Information retrieval, 10(6):491--508, 2007.", "B. Carterette. On rank correlation and the distance between rankings. In SIGIR, pages 436--443, 2009.", "G. V. Cormack and T. R. Lynam. Power and bias of subset pooling strategies. In SIGIR, pages 837--838, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767788"}, {"title": "Spotting familiar code snippet structures for program comprehension", "authors": ["Venkatesh Vinayakarao"], "publication": "ESEC/FSE 2015: Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering", "abstract": "ABSTRACT\nDevelopers deal with the persistent problem of understanding non-trivial code snippets. To understand the given implementation, its issues, and available choices, developers will benefit from reading relevant discussions and descriptions over the web. However, there is no easy way to know the relevant natural language terms so as to reach to such descriptions from a code snippet, especially if the documentation is inadequate and if the vocabulary used in the code is not helpful for web search. We propose an approach to solve this problem using a repository of topics and associated structurally variant snippets collected from a discussion forum. In this on-going work, we take Java methods from the code samples of three Java books, match them with the repository, and associate the topics with 76.9% precision and 66.7% recall.", "references": ["How to implement Chebyshev Type 2 LPF in Java? http://StackOverflow.com/questions/16879642/ how-to-implement-chebyshev-type-2-lpf-in-java.", "B. Ashok, J. Joy, H. Liang, S. K. Rajamani, G. Srinivasa, and V. Vangala. Debugadvisor: A recommender system for debugging. In Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering, ESEC/FSE ’09, pages 373–382, New York, NY, USA, 2009. ACM.", "S. K. Bajracharya, J. Ossher, and C. V. Lopes. Leveraging usage similarity for effective retrieval of examples in code repositories. In Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE ’10, pages 157–166, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786805.2807560"}, {"title": "Automatic Feature Generation on Heterogeneous Graph for Music Recommendation", "authors": ["Chun Guo\n,", "Xiaozhong Liu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline music streaming services (MSS) experienced exponential growth over the past decade. The giant MSS providers not only built massive music collection with metadata, they also accumulated large amount of heterogeneous data generated from users, e.g. listening history, comment, bookmark, and user generated playlist. While various kinds of user data can potentially be used to enhance the music recommendation performance, most existing studies only focused on audio content features and collaborative filtering approaches based on simple user listening history or music rating. In this paper, we propose a novel approach to solve the music recommendation problem by means of heterogeneous graph mining. Meta-path based features are automatically generated from a content-rich heterogeneous graph schema with 6 types of nodes and 16 types of relations. Meanwhile, we use learning-to-rank approach to integrate different features for music recommendation. Experiment results show that the automatically generated graphical features significantly (p<0.0001) enhance state-of-the-art collaborative filtering algorithm.", "references": ["J. Bu, S. Tan, C. Chen, C. Wang, H. Wu, L. Zhang, and X. He. Music recommendation by unified hypergraph: combining social media information and music content. In Proceedings of the international conference on Multimedia, pages 391--400. ACM, 2010.", "G. Dror, Y. Labs, N. Koenigstein, Y. Koren, and M. Weimer. The yahoo! music dataset and kddcup'11. In JMLR Workshop and Conference Proceedings: Proceedings of KDD Cup 2011 Competition, pages 3--18, 2012.", "H. Kautz, B. Selman, and M. Shah. Referral web: combining social networks and collaborative filtering. Communications of the ACM, 40(3):63--65, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767808"}, {"title": "SpeakerLDA: Discovering Topics in Transcribed Multi-Speaker Audio Contents", "authors": ["Damiano Spina\n,", "Johanne R. Trippas\n,", "Lawrence Cavedon\n,", "Mark Sanderson"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nTopic models such as Latent Dirichlet Allocation (LDA) have been extensively used for characterizing text collections according to the topics discussed in documents. Organizing documents according to topic can be applied to different information access tasks such as document clustering, content-based recommendation or summarization. Spoken documents such as podcasts typically involve more than one speaker (e.g., meetings, interviews, chat shows or news with reporters). This paper presents a work-in-progress based on a variation of LDA that includes in the model the different speakers participating in conversational audio transcripts. Intuitively, each speaker has her own background knowledge which generates different topic and word distributions. We believe that informing a topic model with speaker segmentation (e.g., using existing speaker diarization techniques) may enhance discovery of topics in multi-speaker audio content.", "references": ["L. AlSumait, D. Barbará, and C. Domeniconi. On-line lda: Adaptive topic models for mining text streams with applications to topic detection and tracking. In Proceedings of ICDM'08, pages 3--12. IEEE, 2008.", "E. Amigó, J. Gonzalo, and F. Verdejo. A general evaluation measure for document organization tasks. In Proceedings of SIGIR'13, pages 643--652, 2013.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814649"}, {"title": "Session details: Mining and Analytics", "authors": ["Heng Tao Shen"], "publication": "SIGMOD '15 PhD Symposium: Proceedings of the 2015 ACM SIGMOD on PhD Symposium", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3260950"}, {"title": "Leveraging Technology to Improve Intent to Purchase", "authors": ["Hayden Wimmer\n,", "Victoria Yoon"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nDistribution of deceptive counterfeit goods via online marketplaces such as Amazon and eBay has introduced a particularly burdensome decision making process for the consumers. The consumers need to spend additional time in the information search step, reading product and seller reviews to assist with counterfeit detection. Automated counterfeit detection could assist with this process. This paper presents the conceptual framework that employs artificial intelligence techniques, such as natural language processing and topic analysis, in order to automatically detecting counterfeit goods. Specifically, online reviews of products and sellers can be downloaded and parsed using natural language processing. Topic analysis methods can be performed against the resulting text corpus to detect the most frequent terms in the reviews and to examine the reviews for a collection of keywords related to fraudulent products. The implications of this research are to alert consumers to potentially counterfeit products thereby increasing trust and efficiency in the online marketplace.", "references": ["A. R. Hevner, S. T. March, J. Park, and S. Ram, \"Design science in information systems research,\" MIS Q., vol. 28, pp. 75--105, 2004.", "K. Peffers, T. Tuunanen, M. Rothenberger, and S. Chatterjee, \"A Design Science Research Methodology for Information Systems Research,\" Journal of Management Information Systems, vol. 24, pp. 45--77, 2007.", "N. Vulkan, The economics of e-commerce: a strategic guide to understanding and designing the online marketplace: Princeton University Press, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781601"}, {"title": "GLI-Color: Gradual Locality Integration of Color features for image retrieval", "authors": ["Salah Bougueroua\n,", "Bachir Boucheham"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nIn this paper, we propose a novel method for color features based image retrieval. The proposal exploits the advantage of local histograms using a distinguished design to delimiting the concerned regions through an elliptic form, organized in circular-concentric manner of increasing size. For each elliptic region, normalized color histograms in the RGB color space are established. Through this sophisticated design, our method will gradually integrate the locality information, thus it is called: Gradual Locality Integration of Color features (GLI-Color). The experiments are conducted on Corel-1k database, using Manhattan and d1 distance metrics. The comparisons of obtained results with global histogram and some published works have shown a significant higher performance.", "references": ["Appas, A. R., Darwish, A. M., El-Desouki, A. I., and Shaheen, S. I., 1998. Image Indexing Using Composite Regional Color Channel Features, 492--500.", "Bougueroua, S. and Boucheham, B., 2014. Ellipse Based Local Binary Pattern for Color Image Retrieval. In ISKO-Maghreb: Concepts and Tools for knowledge Management (ISKO-Maghreb), 2014 4th International Symposium, 1--8. DOI= http://dx.doi.org/10.1109/ISKO-Maghreb. 2014.7033459.", "Fierro-Radilla, A., Perez-Daniel, K., Nakanomiyatakea, M., Perez-Meana, H., and Benoispineau, J., 2014. An Effective Visual Descriptor Based on Color and Shape Features for Image Retrieval. In Human-Inspired Computing and Its Applications Springer International Publishing, 336--348. DOI= http://dx.doi.org/10.1007/978-3-319-13647-9_31."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816920"}, {"title": "Graph Query Reformulation with Diversity", "authors": ["Davide Mottin\n,", "Francesco Bonchi\n,", "Francesco Gullo"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWe study a problem of graph-query reformulation enabling explorative query-driven discovery in graph databases. Given a query issued by the user, the system, apart from returning the result patterns, also proposes a number of specializations (i.e., supergraphs) of the original query to facilitate the exploration of the results.\nWe formalize the problem of finding a set of reformulations of the input query by maximizing a linear combination of coverage (of the original query's answer set) and diversity among the specializations. We prove that our problem is hard, but also that a simple greedy algorithm achieves a (1/2)-approximation guarantee.\nThe most challenging step of the greedy algorithm is the computation of the specialization that brings the maximum increment to the objective function. To efficiently solve this step, we show how to compute the objective-function increment of a specialization linearly in the number of its results and derive an upper bound that we exploit to devise an efficient search-space visiting strategy.\nAn extensive evaluation on real and synthetic databases attests high efficiency and accuracy of our proposal.", "references": ["C. C. Aggarwal and H. Wang. Managing and Mining Graph Data. Springer, 2010.", "M. K. Anand, S. Bowers, and B. Ludäscher. Techniques for efficiently querying scientific workflow provenance graphs. In EDBT, pages 287--298, 2010.", "R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval - the concepts and technology behind search, Second edition. Pearson Education Ltd., 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783343"}, {"title": "Session details: Session 2 -- Web 2.0 and Online Communities of Practice", "authors": ["John Powell"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3246857"}, {"title": "How many results per page?: A Study of SERP Size, Search Behavior and User Experience", "authors": ["Diane Kelly\n,", "Leif Azzopardi"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe provision of \"ten blue links\" has emerged as the standard for the design of search engine result pages (SERPs). While numerous aspects of SERPs have been examined, little attention has been paid to the number of results displayed per page. This paper investigates the relationships among the number of results shown on a SERP, search behavior and user experience. We performed a laboratory experiment with 36 subjects, who were randomly assigned to use one of three search interfaces that varied according to the number of results per SERP (three, six or ten). We found subjects' click distributions differed significantly depending on SERP size. We also found those who interacted with three results per page viewed significantly more SERPs per query; interestingly, the number of SERPs they viewed per query corresponded to about 10 search results. Subjects who interacted with ten results per page viewed and saved significantly more documents. They also reported the greatest difficulty finding relevant documents, rated their skills the lowest and reported greater workload, even though these differences were not significant. This work shows that behavior changes with SERP size, such that more time is spent focused on earlier results when SERP size decreases.", "references": ["J. Arguello, W.-C. Wu, D. Kelly, and A. Edwards. Task complexity, vertical display and user interaction in aggregated search. In Proceedings of the 35th International ACM SIGIR Conference, SIGIR '12, pages 435--444, 2012.", "A. Aula, R. M. Khan, Z. Guan, P. Fontes, and P. Hong. A comparison of visual and textual page previews in judging the helpfulness of web pages. In Proceedings of the 19th International WWW Conference, pages 51--60, 2010.", "L. Azzopardi, D. Kelly, and K. Brennan. How query cost affects search behavior. In Proc. of the 36th International ACM SIGIR Conference, pages 23--32, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767732"}, {"title": "Frankenplace: Interactive Thematic Mapping for Ad Hoc Exploratory Search", "authors": ["Benjamin Adams\n,", "Grant McKenzie\n,", "Mark Gahegan"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nAd hoc keyword search engines built using modern information retrieval methods do a good job of handling fine-grained queries. However, they perform poorly at facilitating spatial and spatially-embedded thematic exploration of the results, despite the fact that many queries, e.g. \"civil war,\" refer to different documents and topics in different places. This is not for lack of data: geographic information, such as place names, events, and coordinates are common in unstructured document collections on the web. The associations between geographic and thematic contents in these documents can provide a rich groundwork to organize information for exploratory research. In this paper we describe the architecture of an interactive thematic map search engine, Frankenplace, designed to facilitate document exploration at the intersection of theme and place. The map interface enables a user to zoom the geographic context of their query in and out, and quickly explore through thousands of search results in a meaningful way. And by combining topic models with geographically contextualized search results, users can discover related topics based on geographic context. Frankenplace utilizes a novel indexing method called geoboost for boosting terms associated with cells on a discrete global grid. The resulting index factors in the geographic scale of the place or feature mentioned in related text, the relative textual scope of the place reference, and the overall importance of the containing document in the document network. The system is currently indexed with over 5 million documents from the web, including the English Wikipedia and online travel blog entries. We demonstrate that Frankenplace can support four distinct types of exploratory search tasks while being adaptive to scale and location of interest.", "references": ["B. Adams and K. Janowicz. On the geo-indicativeness of non-georeferenced text. In ICWSM, pages 375--378. The AAAI Press, 2012.", "B. Adams and G. McKenzie. Frankenplace: An application for similarity-based place search. In ICWSM, pages 616--617. The AAAI Press, 2012.", "G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Transactions on Information Systems (TOIS), 20(4):357--389, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741137"}, {"title": "SmartCluster: Using Public Data to Group Smart Cities by Domains", "authors": ["Ricardo Alexandre Afonso\n,", "Clovis Holanda do Nascimento\n,", "Vinicius Cardoso Garcia\n,", "Alexandre Alvaro"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThere are currently several domains and indicators around the world that serve to categorize Smart Cities, however, there are not enough studies on the comparison of these cities in Brazil. The public databases have data on various indicators and domains, and these data need to be standardized and clustered to allow a comparison between the smart cities. Make an analysis based on clustering similarity smart cities indicators can bring to the municipal managers a better understanding of the strategic possibilities of resource optimization.", "references": ["Brousell, Lauren. Five Things You Need to Know About Smart Cities. 2012. Disponível em: http://goo.gl/XMnAtD acessado em 06 de março de 2015.", "Hollands, R.G. (2008). Will the real smart city please stand up? City, 12(3), 303-320.", "Boulton, A., (2011). Cyberinfrastructures and \"smart\" world cities. Disponível em: http://goo.gl/t6DGDv acessado em 06 de março de 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814167"}, {"title": "Data Like This: Ranked Search of Genomic Data Vision Paper", "authors": ["V. M. Megler\n,", "David Maier\n,", "Daniel Bottomly\n,", "Libbey White\n,", "Shannon McWeeney\n,", "Beth Wilmot"], "publication": "ExploreDB '15: Proceedings of the Second International Workshop on Exploratory Search in Databases and the Web", "abstract": "ABSTRACT\nHigh-throughput genetic sequencing produces the ultimate \"big data\": a human genome sequence contains more than 3B base pairs, and more and more characteristics, or annotations, are being recorded at the base-pair level. Locating areas of interest within the genome is a challenge for researchers, limiting their investigations. We describe our vision of adapting \"big data\" ranked search to the problem of searching the genome. Our goal is to make searching for data as easy for scientists as searching the Internet.", "references": ["Agrawal, R. and Srikant, R. 2003. Searching with numbers. IEEE TKDE. 15, 4 (Aug. 2003), 855--870.", "Ahrens, J.P. et al. 2011. Data-intensive science in the US DOE. CISE. 13, 6 (Dec. 2011), 14--24.", "Altschul, S.F. et al. 1997. Gapped BLAST and PSI-BLAST. Nucleic acids res. 25, 17 (1997), 3389--3402."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795218.2795221"}, {"title": "Fog Data: Enhancing Telehealth Big Data Through Fog Computing", "authors": ["Harishchandra Dubey\n,", "Jing Yang\n,", "Nick Constant\n,", "Amir Mohammad Amiri\n,", "Qing Yang\n,", "Kunal Makodiya"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe size of multi-modal, heterogeneous data collected through various sensors is growing exponentially. It demands intelligent data reduction, data mining and analytics at edge devices. Data compression can reduce the network bandwidth and transmission power consumed by edge devices. This paper proposes, validates and evaluates Fog Data, a service-oriented architecture for Fog computing. The center piece of the proposed architecture is a low power embedded computer that carries out data mining and data analytics on raw data collected from various wearable sensors used for telehealth applications. The embedded computer collects the sensed data as time series, analyzes it, and finds similar patterns present. Patterns are stored, and unique patterns are transmited. Also, the embedded computer extracts clinically relevant information that is sent to the cloud. A working prototype of the proposed architecture was built and used to carry out case studies on telehealth big data applications. Specifically, our case studies used the data from the sensors worn by patients with either speech motor disorders or cardiovascular problems. We implemented and evaluated both generic and application specific data mining techniques to show orders of magnitude data reduction and hence transmission power savings. Quantitative evaluations were conducted for comparing various data mining techniques and standard data compression techniques. The obtained results showed substantial improvement in system efficiency using the Fog Data architecture.", "references": ["R. Bellazzi, Big Data and Biomedical Informatics: A Challenging Opportunity. Yearb Med Inform 2014:8--13.", "C. Wang, W. Lu, M. R. Narayanan, S. J. Redmond, and N. H. Lovell. \"Low-power technologies for wearable telecare and telehealth systems: A review, \"Biomedical Engineering Letters 5, no. 1 (2015): 1--9.", "N. Selvaraj, \"Long-term remote monitoring of vital signs using a wireless patch sensor.\" In Healthcare Innovation Conference (HIC), 2014 IEEE, pp. 83--86. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818889"}, {"title": "Sec-Buzzers: a Web Service for Exploring Cyber Security Emerging Topics based on Social Network Mining", "authors": ["Chih-Hung Hsieh\n,", "Kuo-Chen Lee\n,", "Ching-Hao Mao\n,", "Chia-Min Lai\n,", "Chiun-How Kao\n,", "Jyun-Han Dai"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nRecognition of information threats from social media can give advantages to incident response in very early stage. Previous related studies mostly focus on finding general hot terms instead of specific continuously-changing targets, such that usage of these methods may be limited when given specific theme as default. To our best knowledge so far, the proposed Sec-Buzzers is the first web-based service not only dedicated to finding the various emerging topics of cyber threats (i.e., nearly zero-day attacks) but also providing the possible remedy solutions. Unlike previous works, Sec-Buzzers mainly benefits from the strategy of community-oriented resource filtering and a novel modified topic association graph, such that a set of highly-contributing Twitter users was grouped, and information from that was explored then exploited. Demonstrations show that, by combining several measurements to quantify significance, Sec-Buzzers indeed uncovered emerging (or suddenly appearing) issues which are highly related to real cases about security threats.", "references": ["Turkish hacker crashes google play store twice while testing vulnerability, 2014. {Online; accessed: 9-July-2015}.", "David jevans on wikipedia, 2015. {Online; accessed: 15-July-2015}.", "Duqu 2.0: The most sophisticated malware ever seen, 2015. {Online; accessed: 16-July-2015}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818897"}, {"title": "Enhancing Mathematics Information Retrieval", "authors": ["Martin Líška"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["M. Líška, M. Ruzicka, and P. Sojka. Math Indexer and Searcher under the Hood: History and Development of a Winning Strategy. In N. Kando and K. Kishida, editors, Proceedings of the 11th NTCIR Conference on Evaluation of Information Access Technologies, pages 127--134. National Institute of Informatics, 2014.", "P. Sojka and M. Líška. Indexing and Searching Mathematics in Digital Libraries -- Architecture, Design and Scalability Issues. In J. H. Davenport, W. M. Farmer, J. Urban, and F. Rabe, editors, Intelligent Computer Mathematics. Proceedings of 18th Symposium, Calculemus 2011, and 10th International Conference, MKM 2011, volume 6824 of Lecture Notes in Artificial Intelligence, LNAI, pages 228--243, Berlin, Germany, July 2011. Springer--Verlag. http://dx.doi.org/10.1007/978--3--642--22673--1_16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767843"}, {"title": "Balancing Aspects in Retrieved Search Results", "authors": ["David Wemhoener\n,", "James Allan"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nMany queries contain explicit aspects which must be balanced in any retrieved result in order to meet a user's information need: if aspects of the query are missing or disproportionately represented in documents, the results will be of lower quality than desired. This balancing thus needs to occur both within the retrieved documents individually and across the entire set. We introduce the concept of query-aspect balance and describe a new evaluation measure, β-NDCG, that allows the evaluation of query-aspect balance on multivalued query-aspect judgments. We apply β-NDCG to a small test collection and explore its utility. We show that β-NDCG-NDCG captures problems of query aspect balance within and across documents in the ranked list.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In Proceedings of the Second ACM International Conference on Web Search and Data Mining, WSDM '09, pages 5--14, New York, NY, USA, 2009. ACM.", "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '98, pages 335--336, New York, NY, USA, 1998. ACM.", "O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM '09, pages 621--630, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809492"}, {"title": "A Probabilistic Approach for Image Retrieval Using Descriptive Textual Queries", "authors": ["Yashaswi Verma\n,", "C.V. Jawahar"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe address the problem of image retrieval using textual queries. In particular, we focus on descriptive queries that can be either in the form of simple captions (e.g., ``a brown cat sleeping on a sofa''), or even long descriptions with multiple sentences. We present a probabilistic approach that seamlessly integrates visual and textual information for the task. It relies on linguistically and syntactically motivated mid-level textual patterns (or phrases) that are automatically extracted from available descriptions. At the time of retrieval, the given query is decomposed into such phrases, and images are ranked based on their joint relevance with these phrases. Experiments on two popular datasets (UIUC Pascal Sentence and IAPR-TC12 benchmark) demonstrate that our approach effectively retrieves semantically meaningful images, and outperforms baseline methods.", "references": ["R. Arandjelović and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012.", "R. Datta, D. Joshi, J. Li, and J. Wang. Image retrieval: Ideas, influences and trends of new age. ACM Computing Surveys, 2008.", "M.-C. de Marneffe and C. D. Manning. The stanford typed dependencies representation. In COLING Workshop, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806289"}, {"title": "Poster: A Context Simulation Harness for Realistic Mobile App Testing", "authors": ["Manoj R. Rege\n,", "Vlado Handziski\n,", "Adam Wolisz"], "publication": "MobiSys '15: Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services", "abstract": "ABSTRACT\nAccurate performance testing of mobile apps require comprehensive simulation of real world context in a mobile emulator viz. location, sensor values, network conditions etc. Existing mobile emulators support such simulation, however they lack the capability for automated generation of realistic, correlated, and dependent context traces. As a result, the burden of their generation and injection is left to the developers who have to create their own traces. This is not straightforward: there are heterogenous remote databases of traces, mathematical models and trace files can be used as well, but the trace values should be correlated, and traces have to be converted to a common format. We are developing ContextMonkey - a framework that addresses these concerns by leveraging context traces from databases such as FourSquare [1], OpenSignal [2], Google Street View [3]. It acts as a harness to mobile emulators, and aims at improving the efficiency of mobile app performance tests.", "references": ["Foursquare. https://developer.foursquare.com/.", "Opensignal maps. http://opensignal.com.", "Google street view. https://www.google.com/maps/views/streetview."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742647.2745913"}, {"title": "Online template matching over a stream of digitized documents", "authors": ["Michael Stockerl\n,", "Christoph Ringlstetter\n,", "Matthias Schubert\n,", "Eirini Ntoutsi\n,", "Hans-Peter Kriegel"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nAlthough living in the information age for decades, paperwork is still a tedious part of everybody's life. Assistance systems that implement techniques of digitization and document understanding may offer considerable reductions in time and effort for the users. A large portion of paper documents like invoices, delivery receipts or admonitions are based on a fixed company specific template and therefore exhibit a high degree of similarity. In this work, we propose a template extraction method over a stream of incoming documents and a template allocation method for assigning new instances from the stream to the most suitable templates. Our method employs text augmented by layout information to represent the digital image of the paper document. Document similarity is assessed with respect to both textual and layout parts of the document; the matching terms contribute accordingly to their distance to the query terms. To be more robust against distortions on the documents due to the digitization process, the templates are not static, rather they are maintained in an online fashion based on their new assigned documents. Real data experiments show that the combination of textual and layout information and the continuous template adaptation through online update, improves the template identification quality of earlier proposed methods.", "references": ["S. Agarwal, I. Delhi, S. Godbole, D. Punjani, and S. R. How much noise is too much: A study in automatic text classification. In Data Mining, 2007. ICDM 2007, pages 3--12, 2007.", "C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for clustering evolving data streams. In Proceedings of the 29th International Conference on Very Large Data Bases (VLDB), Berlin, Germany, 2003.", "C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for projected clustering of high dimensional data streams. In Proceedings of the 30th International Conference on Very Large Data Bases (VLDB), Toronto, Canada, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791354"}, {"title": "Exploring Session Context using Distributed Representations of Queries and Reformulations", "authors": ["Bhaskar Mitra"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch logs contain examples of frequently occurring patterns of user reformulations of queries. Intuitively, the reformulation \"San Francisco\" -- \"San Francisco 49ers\" is semantically similar to \"Detroit\" -- \"Detroit Lions\". Likewise, \"London\" -- \"things to do in London\" and \"New York\" -- \"New York tourist attractions\" can also be considered similar transitions in intent. The reformulation \"movies\" -- \"new movies\" and \"york\" -- \"New York\", however, are clearly different despite the lexical similarities in the two reformulations. In this paper, we study the distributed representation of queries learnt by deep neural network models, such as the Convolutional Latent Semantic Model, and show that they can be used to represent query reformulations as vectors. These reformulation vectors exhibit favourable properties such as mapping semantically and syntactically similar query changes closer in the embedding space. Our work is motivated by the success of continuous space language models in capturing relationships between words and their meanings using offset vectors. We demonstrate a way to extend the same intuition to represent query reformulations. Furthermore, we show that the distributed representations of queries and reformulations are both useful for modelling session context for query prediction tasks, such as for query auto-completion (QAC) ranking. Our empirical study demonstrates that short-term (session) history context features based on these two representations improves the mean reciprocal rank (MRR) for the QAC ranking task by more than 10% over a supervised ranker baseline. Our results also show that by using features based on both these representations together we achieve a better performance, than either of them individually.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proc. WWW, pages 107--116, 2011.", "P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short- and long-term behavior on search personalization. In Proc. SIGIR, pages 185--194, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3: 993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767702"}, {"title": "A Hybrid Approach for Large-Scale Image Classification", "authors": ["Been-Chian Chien\n,", "Chia-Wei Ku"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nDigital photos and images increase considerably in recent years. How to manage and access large-scale images efficiently and effectively becomes an important issue in big data era. The main techniques of image retrieval are typically divides into two categories: the content-based retrieval approach and the keyword-based retrieval approach. The content-based retrieval approach searches images with a similar query image. In other hand, the keyword-based retrieval approach searches images with keywords. For retrieving images by semantic keywords and avoiding manually annotation by users, high-accurate image classification is required. In this paper, we propose a hybrid framework combining classifiers, similarity matching and association rules for large-scale multi-label image classification. The results of experiments show that the combination model provides an effective image classification.", "references": ["Agrawal, R. and Srikant, R. 1994. Fast algorithms for mining association rules in large databases. In Proceedings of the 20th International Conference on Very Large Data Bases (Santiago, Chile, Sep. 1994). 487--499.", "Bentley, J. L. 1975. Multidimensional binary search trees used for associative searching. Communications of the ACM 18, 9 (Sept. 1975), New York, USA, 851--861.", "Blei, D. M. and Jordan, M. I. 2003. Modeling annotated data. In Proceedings of the 26th annual international ACM SIGIR Conference on Research and Development in Information Retrieval (Toronto, Canada, July 2003), 127--134."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818900"}, {"title": "Analyzing Effect of Roles on Search Performance and Query Formulation in Collaborative Search", "authors": ["Takehiro Yamamoto\n,", "Mitsuo Yamamoto\n,", "Katsumi Tanaka"], "publication": "ECol '15: Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking", "abstract": "ABSTRACT\nWe investigate how explicit search roles assigned to group members affect their search performance and behavior in collaborative information seeking (CIS). Although several roles have been proposed in CIS, how these roles affect the search performances and behaviors of the members has not yet been explored. We focus on the existing Gatherer and Surveyor roles and analyze their effects on search performances and query formulation behaviors. The goal of our study is to understand the relationships between the roles and search behaviors and get insights into developing algorithms such as query suggestions or document rankings adaptive to the roles and behaviors. We conducted a user study with 20 participants in 10 pairs, where each pair of Gatherer and Surveyor were asked to perform a recall-oriented collaborative search task. We first analyzed the search performance of the two roles in terms of recall and diversity. We also analyzed how their queries were affected by their preceding queries or webpages that were visited through a questionnaire and log analysis. Finally, we discussed what algorithms would be required to support role-based CIS.", "references": ["J. Foster. Collaborative information seeking and retrieval. Annual review of information science and technology, 40(1):329--356, 2006.", "G. Golovchinsky, P. Qvarfordt, and J. Pickens. Collaborative information seeking. Computer, 42(3):47--51, 2009.", "R. González-Ibáñez and C. Shah. Coagmento: A system for supporting collaborative information seeking. In Proc. of ASIST, pages 1--4, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2812376.2812377"}, {"title": "A Parallel GPU-Based Approach to Clustering Very Fast Data Streams", "authors": ["Pengtao Huang\n,", "Xiu Li\n,", "Bo Yuan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nClustering data streams has become a hot topic in the era of big data. Driven by the ever increasing volume, velocity and variety of data, more efficient algorithms for clustering large-scale complex data streams are needed. In this paper, we present a parallel algorithm called PaStream, which is based on advanced Graphics Processing Unit (GPU) and follows the online-offline framework of CluStream. Our approach can achieve hundreds of times speedup on high-speed and high-dimensional data streams compared with CluStream. It can also discover clusters with arbitrary shapes and handle outliers properly. The efficiency and scalability of PaStream are demonstrated through comprehensive experiments on synthetic and standard benchmark datasets with various problem factors.", "references": ["Accelerate Continuum Documentation. http://docs.continuum.io/accelerate.", "C. Aggarwal, J. Han, J. Wang, and P. Yu. A framework for clustering evolving data streams. In Proceedings of the 29th International Conference on Very Large Data Bases, pages 81--92, 2003.", "C. Aggarwal, J. Han, J. Wang, and P. Yu. A framework for projected clustering of high dimensional data streams. In Proceedings of the Thirtieth International Conference on Very Large Data Bases, pages 852--863, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806545"}, {"title": "Visual-based Deep Learning for Clothing from Large Database", "authors": ["Ju-Chin Chen\n,", "Chao-Feng Liu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nHuge benefits can be obtained by mining information from Big Data. Analyzing large volumes of consumption behavior data that are limited by conventional machine learning techniques and computational analysis becomes a critical problem as Big Data is examined. Furthermore, there is a need for powerful visual-based analytics tools when pictures have become a core content component on the Internet. Hence, in this study, we explore Deep Learning with convolutional neural networks with a goal of resolving clothing style classification and retrieval tasks. To reduce training complexity, transfer learning is incorporated by fine-tuning pre-trained models on large scale datasets. Furthermore, because the parameters are vast for any given deep net, one architecture inspired from Adaboost is designed to use multiple deep nets that are trained with a sub-dataset. Thus, the training time can be accelerated if each net is computed in one client node in a distributed computing environment. Moreover, to increase system flexibility, two architectures with multiple deep nets with two outputs are proposed for binary-class classification. Therefore, when new classes are added, no additional computation is needed for all training data. Experiments are performed to compare existing systems with hand-crafted features and conventional learning models. According to the results, the proposed system can provide significant improvements on three public clothing datasets for style classifications.", "references": ["US National Security Agency 2013. The National Security Agency: Missions, Authorities. Oversight and Partnerships, 5 (August. 2013).", "Chen, X. W. and Lin, X. 2014. Big data deep learning: challenges and perspectives. IEEE Access, 514--525. DOI: http://dx.doi.org/10.1109/ACCESS.2014.2325029.", "Gantz, J. and Reinsel, D. 2011. Extracting value from chaos, EMC."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818902"}, {"title": "Robust gender classification on unconstrained face images", "authors": ["Fudong Nian\n,", "Lanying Li\n,", "Teng Li\n,", "Changsheng Xu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nRobust and automatic gender classification on a single face image is one of the fundamental artificial intelligence tasks. And it has become relevant to an increasing amount of applications alongside the rise of social media. In this paper we consider the problem of robust gender classification on unconstrained face images based on weakly calibration and deep neural network methods. While there has been a lot of significant researches on this problem, the proposed method has distinct advantages compared with other approaches. To facilitate tolerance of the pose variations of the face image caused by different shooting angles, an efficient face detection and calibration method is proposed to preprocess unconstrained face images. Furthermore, we extract deep face representations using deep convolutional neural networks (CNN) which could handle all unconstrained face images efficiently. We evaluate our method on the real-life unconstrained faces database-the Labeled Faces in the Wild (LFW) and it outperforms the previous best results reported in the literature.", "references": ["http://pan.baidu.com/s/1c0q97n6.", "http://www.faceplusplus.com.", "W.-S. Chu, C.-R. Huang, and C.-S. Chen. Gender classification from unaligned facial images using support subspaces. Information Sciences, 221: 98--109, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808570"}, {"title": "Using Part-of-Speech N-grams for Sensitive-Text Classification", "authors": ["Graham McDonald\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nFreedom of Information legislations in many western democracies, including the United Kingdom (UK) and the United States of America (USA), state that citizens have typically the right to access government documents. However, certain sensitive information is exempt from release into the public domain. For example, in the UK, FOIA Exemption 27 (International Relations) excludes the release of Information that might damage the interests of the UK abroad. Therefore, the process of reviewing government documents for sensitivity is essential to determine if a document must be redacted before it is archived, or closed until the information is no longer sensitive. With the increased volume of digital government documents in recent years, there is a need for new tools to assist the digital sensitivity review process. Therefore, in this paper we propose an automatic approach for identifying sensitive text in documents by measuring the amount of sensitivity in sequences of text. Using government documents reviewed by trained sensitivity reviewers, we focus on an aspect of FOIA Exemption 27 which can have a major impact on international relations, namely, information supplied in confidence. We show that our approach leads to markedly increased recall of sensitive text, while achieving a very high level of precision, when compared to a baseline that has been shown to be effective at identifying sensitive text in other domains.", "references": ["D. Abril, G. Navarro-Arribas, and V. Torra. On the declassification of confidential documents. In Mod. Dec. for Art. Intel. 6820:235--246, 2011.", "D. A. R. P. Agency. Darpa, new technologies to support declassification. Request for Information, DARPA-SN-10-73, 2010.", "A. Allan. Records Review. UK Government. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809496"}, {"title": "Mining Relevant Time for Query Subtopics in Web Archives", "authors": ["Tu Ngoc Nguyen\n,", "Nattiya Kanhabua\n,", "Wolfgang Nejdl\n,", "Claudia Niederée"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the reflection of nearly all types of social cultural, societal and everyday processes of our lives in the web, web archives from organizations such as the Internet Archive have the potential of becoming huge gold-mines for temporal content analytics of many kinds (e.g., on politics, social issues, economics or media). First hand evidences for such processes are of great benefit for expert users such as journalists, economists, historians, etc. However, searching in this unique longitudinal collection of huge redundancy (pages of near-identical content are crawled all over again) is completely different from searching over the web. In this work, we present our first study of mining the temporal dynamics of subtopics by leveraging the value of anchor text along the time dimension of the enormous web archives. This task is especially useful for one important ranking problem in the web archive context, the time-aware search result diversification. Due to the time uncertainty (the lagging nature and unpredicted behavior of the crawlers), identifying the trending periods for such temporal subtopics relying solely on the timestamp annotations of the web archive (i.e., crawling times) is extremely difficult. We introduce a brute-force approach to detect a time-reliable sub-collection and propose a method to leverage them for relevant time mining of subtopics. This is empirically found effective in solving the problem.", "references": ["K. Berberich and S. Bedathur. Temporal diversification of search results. In TAIA'2013.", "N. Dai and B. D. Davison. Mining anchor text trends for retrieval. In Proceedings of ECIR'2010.", "V. Dang and B. W. Croft. Query reformulation using anchor text. In Proceedings of WSDM'2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741702"}, {"title": "Fielded Sequential Dependence Model for Ad-Hoc Entity Retrieval in the Web of Data", "authors": ["Nikita Zhiltsov\n,", "Alexander Kotov\n,", "Fedor Nikolaev"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPreviously proposed approaches to ad-hoc entity retrieval in the Web of Data (ERWD) used multi-fielded representation of entities and relied on standard unigram bag-of-words retrieval models. Although retrieval models incorporating term dependencies have been shown to be significantly more effective than the unigram bag-of-words ones for ad hoc document retrieval, it is not known whether accounting for term dependencies can improve retrieval from the Web of Data. In this work, we propose a novel retrieval model that incorporates term dependencies into structured document retrieval and apply it to the task of ERWD. In the proposed model, the document field weights and the relative importance of unigrams and bigrams are optimized with respect to the target retrieval metric using a learning-to-rank method. Experiments on a publicly available benchmark indicate significant improvement of the accuracy of retrieval results by the proposed model over state-of-the-art retrieval models for ERWD.", "references": ["K. Balog, M. Bron, and M. D. Rijke. Query Modeling for Entity Search based on Terms, Categories, and Examples. ACM TOIS, 29:22, 2011.", "K. Balog and R. Neumayer. A Test Collection for Entity Search in DBpedia. In Proceedings of the 36th ACM SIGIR, pages 737--740, 2013.", "M. Bendersky, D. Metzler, and W. B. Croft. Learning Concept Importance Using a Weighted Dependence Model. In Proceedings of the 3rd ACM WSDM, pages 31--40, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767756"}, {"title": "A Novel Pattern Search Engine for Time Series Supporting Dynamic Expected Patterns within a Short Period of Time", "authors": ["Hai T. Mai\n,", "Young-chan Kim"], "publication": "BigDAS '15: Proceedings of the 2015 International Conference on Big Data Applications and Services", "abstract": "ABSTRACT\nRecently, the world gets more and more distributed, big data now not only come from websites as Google, Bing, Yahoo having now or social networking service as Facebook etc.; there are sensors everywhere reporting millions of data each second. Among all the types of big data, data from sensors which is the most widespread is referred as time-series data. There are many attempts have been taken to recognize or retrieve the pattern of time-series such as recommender system, machine learning with pattern recognition and classification but all of them are push model. Once the expected patterns change, the whole system must be trained again it is great pain and it takes a huge of time. In other words, the existing systems cannot support dynamic expected patterns for retrieving the information. This paper proposes a novel pattern search engine for time-series which allows us to use any expected pattern or the combination of them as a query for searching information in a very short period of time without being trained or indexed again.", "references": ["Douglas C.Montgomery, Introduction to Statistical Quality Control, USA: Willey, 2005.", "A. Ferreira J. Atkinson, Intelligent Search Agents Using Web-Driven Natural-Language Explanatory Dialogs, IEEE Computer, Vol. 38, No. 10, pp. 44--52, 2005.", "K. Matsumoto, A. Monden, T. Kamei, Development of a Software Search Engine for the World Wide Web, Workshop on Software Product Archiving and Retrieving System, pp. 39--44, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837060.2837064"}, {"title": "Permutation search methods are efficient, yet faster search is possible", "authors": ["Bilegsaikhan Naidan\n,", "Leonid Boytsov\n,", "Eric Nyberg"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe survey permutation-based methods for approximate k-nearest neighbor search. In these methods, every data point is represented by a ranked list of pivots sorted by the distance to this point. Such ranked lists are called permutations. The underpinning assumption is that, for both metric and non-metric spaces, the distance between permutations is a good proxy for the distance between original points. Thus, it should be possible to efficiently retrieve most true nearest neighbors by examining only a tiny subset of data points whose permutations are similar to the permutation of a query. We further test this assumption by carrying out an extensive experimental evaluation where permutation methods are pitted against state-of-the art benchmarks (the multi-probe LSH, the VP-tree, and proximity-graph based retrieval) on a variety of realistically large data set from the image and textual domain. The focus is on the high-accuracy retrieval methods for generic spaces. Additionally, we assume that both data and indices are stored in main memory. We find permutation methods to be reasonably efficient and describe a setup where these methods are most useful. To ease reproducibility, we make our software and data sets publicly available.", "references": ["A. Abdullah, J. Moeller, and S. Venkatasubramanian. Approximate bregman near neighbors in sublinear time: Beyond the triangle inequality. In Proceedings of the twenty-eighth annual symposium on Computational geometry, pages 31--40. ACM, 2012.", "G. Amato, C. Gennaro, and P. Savino. MI-file: using inverted files for scalable approximate similarity search. Multimedia tools and applications, 71(3):1333--1362, 2014.", "G. Amato and P. Savino. Approximate similarity search in metric spaces using inverted files. In Proceedings of the 3rd international conference on Scalable information systems, InfoScale '08, pages 28:1--28:10, ICST, Brussels, Belgium, Belgium, 2008. ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824059"}, {"title": "Provenance-based analysis of data-centric processes", "authors": ["Daniel Deutch\n,", "Yuval Moskovitch\n,", "Val Tannen"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWe consider in this paper static analysis of the possible executions of data-dependent applications, namely applications whose control flow is guided by a finite-state machine, as well as by the state of an underlying database. We note that previous work in this context has not addressed two important features of such analysis, namely analysis under hypothetical scenarios, such as changes to the application's state machine and/or to the underlying database, and the consideration of meta-data, such as cost or access privileges. Observing that semiring-based provenance has been proven highly effective in supporting these two features for database queries, we develop in this paper a semiring-based provenance framework for the analysis of data-dependent processes, accounting for hypothetical reasoning and meta-data. The development addresses two interacting new challenges: (1) combining provenance annotations for both information that resides in the database and information about external inputs (e.g., user choices) and (2) finitely capturing infinitely many process executions. We have implemented our framework as part of the PROPOLIS system.", "references": ["Abiteboul, S., Hull, R., Vianu, V.: Foundations of Databases. Addison-Wesley, Reading, MA (1995)", "Abiteboul, S., Vianu, V., Fordham, B., Yesha, Y.: Relational transducers for electronic commerce. In: PODS, ACM, Seattle, 1---3 June 1998", "Ailamaki, A., Ioannidis, Y. E., Livny, M.: Scientific workflow management by database management. In: SSDBM, IEEE, Capri, Italy, 1---3 July 1998"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0390-5"}, {"title": "SYNAISTHISI: an enabling platform for the current internet of things ecosystem", "authors": ["Georgios Pierris\n,", "Dimosthenis Kothris\n,", "Evaggelos Spyrou\n,", "Costas Spyropoulos"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nThe emerging interest in the Internet of Things (IoT) research is being motivated by the high expectations of market analysts and researchers suggesting that the IoT will transform the everyday lives of consumers, end--users, professionals, businesses, the public sector, and the global economy in the broader sense. SYNAISTHISI is an integrated platform that allows humans, systems, machines, and devices for the creation and management of services. It covers multiple tangential directions of the IoT research, enabling it to feature a wide spectrum of applicability to research and business areas. In this work, we present the architecture and an implementation of SYNAISTHISI platform based on the existing web--technologies and protocols that prevail in the current IoT ecosystem. Finally, a Smart Meeting Room use case is demonstrated.", "references": ["C. Akasiadis, E. Spyrou, G. Pierris, D. Sgouropoulos, G. Siantikos, A. Mavrommatis, C. Vrakopoulos, and T. Giannakopoulos. Exploiting future internet technologies: The smart room case. In \"Proc. of International Conference on PErvasive Technologies Related to Assistive Environments (PETRA), 2015\", 2015.", "J. Bradley, J. Barbier, and D. Handler. Embracing the internet of everything to capture your share of $14.4 trillion. White Paper, CISCO, 2013.", "E. Curry. Message-oriented middleware. John Wiley & Sons, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802019"}, {"title": "FlowGate: towards extensible and scalable web-based flow cytometry data analysis", "authors": ["Yu Qian\n,", "Hyunsoo Kim\n,", "Shweta Purawat\n,", "Jianwu Wang\n,", "Rick Stanton\n,", "Alexandra Lee\n,", "Weijia Xu\n,", "Ilkay Altintas\n,", "Robert Sinkovits\n,"], "publication": "XSEDE '15: Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure", "abstract": "ABSTRACT\nRecent advances in cytometry instrumentation are enabling the generation of \"big data\" at the single cell level for the identification of cell-based biomarkers, which will fundamentally change the current paradigm of diagnosis and personalized treatment of immune system disorders, cancers, and blood diseases. However, traditional flow cytometry (FCM) data analysis based on manual gating cannot effectively scale to address this new level of data generation. Computational data analysis methods have recently been developed to cope with the increasing data volume and dimensionality generated from FCM experiments. Making these computational methods easily accessible to clinicians and experimentalists is one of the biggest challenges that algorithm developers and bioinformaticians need to address. This paper describes FlowGate, a novel prototype cyberinfrastructure for web-based FCM data analysis, which integrates graphical user interfaces (GUI), workflow engines, and parallel computing resources for extensible and scalable FCM data analysis. The goal of FlowGate is to allow users to easily access state-of-the-art FCM computational methods developed using different programming languages and software on the same platform, when the implementations of these methods follow standardized I/O. By adopting existing data and information standards, FlowGate can also be integrated as the back-end data analytical platform with existing immunology and FCM databases. Experimental runs of two representative FCM data analytical methods in FlowGate on different cluster computers demonstrated that the task runtime can be reduced linearly with the number of compute cores used in the analysis.", "references": ["Aghaeepour N, Finak G, The FlowCAP Consortium, The DREAM Consortium, Hoos HH, Mosmann TR, Brinkman RR, Gottardo R, and Scheuermann RH. Critical assessment of automated flow cytometry data analysis techniques, Nature Methods, 10, 228238 (2013) doi:10.1038/nmeth.2365.", "Altintas I, Wang J, Crawl D, Li W. Challenges and approaches for distributed workflow-driven analysis of large-scale biological data, in: Proceedings of the Workshop on Data analytics in the Cloud at EDBT/ICDT 2012 Conference (DanaC2012), 2012, pp 73--78.", "Brusic V, Gottardo R, Kleinstein SH, Davis MM, Hafler DA, Quill H, Palucka AK, Poland GA, Pulendran B, Reinherz EL, Stuart KD, Togias A. Computational resources for high-dimensional immune analysis from the Human Immunology Project Consortium. Nature Biotechnology, 2014; 32:146--148."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792745.2792750"}, {"title": "Ranking tokens with class label frequencies for medical article classification", "authors": ["Kostas Fragos\n,", "Christos Skourlas"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this paper, a new method for medical article classification is proposed based on exploiting information from local and global class label frequencies in training corpus. The proposed method partially overcomes the low accuracy rate of KNN classifier. First, it uses a lexical approach to identify tokens in the medical document article and then, it uses local and global class label frequencies in a sophisticated way similar to traditional tf-idf weighting scheme to devise the weighted function in classification process. The evaluation experiments on the collection of medical documents, called Ohsumed, show that the method proposed here significantly outperforms traditional KNN classification.", "references": ["Taeho Jo. Application of table based similarity to classification of biomedical documents. IEEE International Conference on Granular Computing 2013: 162--166.", "Mohammed GH A Z, Can A B. ROLEX-SP: Rules of lexical syntactic patterns for free text categorization. Journal of Knowledge-Based Systems Elsevier 2011; 24: 58--65.", "Parvin, H., Alizadeh, H. and Minaei-Bidgoli, B. A Modification on K-Nearest Neighbor Classifier, pp 37--41, Vol. 10, Issue 14, November 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802022"}, {"title": "Building Web Personalization System with Time-Driven Web Usage Mining", "authors": ["P. T. Ramya\n,", "G. P. Sajeev"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nWeb personalization is a powerful tool used for personalizing the Websites. The personalization system aims at suggesting the Web pages to the users based on their navigational patterns. Use of attributes such as time, popularity of Web objects makes the model more efficient. This paper proposes a novel Web personalization model which utilizes time attributes, such as duration of visit, inter-visiting time, burst of visit, and the user's navigational pattern. Test results indicate that the proposed model explores the user's behaviour and their interest.", "references": ["A. Ben-Hur, D. Horn, H. T. Siegelmann, and V. Vapnik. Support vector clustering. The Journal of Machine Learning Research, 2:125--137, 2002.", "P. Danzig, J. Mogul, V. Paxson, and M. Schwartz. The internet traffic archive. Available at URL http://ita. ee. lbl. gov, 2000.", "R. O. Duda, P. E. Hart, and D. G. Stork. Pattern classification. John Wiley & Sons, 2nd edition, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791481"}, {"title": "Modeling Multi-query Retrieval Tasks Using Density Matrix Transformation", "authors": ["Qiuchi Li\n,", "Jingfei Li\n,", "Peng Zhang\n,", "Dawei Song"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe quantum probabilistic framework has recently been applied to Information Retrieval (IR). A representative is the Quantum Language Model (QLM), which is developed for the ad-hoc retrieval with single queries and has achieved significant improvements over traditional language models. In QLM, a density matrix, defined on the quantum probabilistic space, is estimated as a representation of user's search intention with respect to a specific query. However, QLM is unable to capture the dynamics of user's information need in query history. This limitation restricts its further application on the dynamic search tasks, e.g., session search. In this paper, we propose a Session-based Quantum Language Model (SQLM) that deals with multi-query session search task. In SQLM, a transformation model of density matrices is proposed to model the evolution of user's information need in response to the user's interaction with search engine, by incorporating features extracted from both positive feedback (clicked documents) and negative feedback (skipped documents). Extensive experiments conducted on TREC 2013 and 2014 session track data demonstrate the effectiveness of SQLM in comparison with the classic QLM.", "references": ["G. V. Cormack, M. D. Smucker, and C. L. A. Clarke. Efficient and effective spam filtering and re-ranking for large web datasets. Inf. Retr., 14(5):441--465, 2011.", "A. M. Gleason. Measures on the closed subspaces of a hilbert space. J. Math. Mech, 6(6):885--893, 1957.", "D. Guan, S. Zhang, and H. Yang. Utilizing query change for session search. In SIGIR, pages 453--462. ACM, 20"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767819"}, {"title": "Local Ranking Problem on the BrowseGraph", "authors": ["Michele Trevisiol\n,", "Luca Maria Aiello\n,", "Paolo Boldi\n,", "Roi Blanco"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe \"Local Ranking Problem\" (LRP) is related to the computation of a centrality-like rank on a local graph, where the scores of the nodes could significantly differ from the ones computed on the global graph. Previous work has studied LRP on the hyperlink graph but never on the BrowseGraph, namely a graph where nodes are webpages and edges are browsing transitions. Recently, this graph has received more and more attention in many different tasks such as ranking, prediction and recommendation. However, a web-server has only the browsing traffic performed on its pages (local BrowseGraph) and, as a consequence, the local computation can lead to estimation errors, which hinders the increasing number of applications in the state of the art. Also, although the divergence between the local and global ranks has been measured, the possibility of estimating such divergence using only local knowledge has been mainly overlooked. These aspects are of great interest for online service providers who want to: (i) gauge their ability to correctly assess the importance of their resources only based on their local knowledge, and (ii) take into account real user browsing fluxes that better capture the actual user interest than the static hyperlink network. We study the LRP problem on a BrowseGraph from a large news provider, considering as subgraphs the aggregations of browsing traces of users coming from different domains. We show that the distance between rankings can be accurately predicted based only on structural information of the local graph, being able to achieve an average rank correlation as high as 0.8.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, pages 19--26, New York, NY, USA, 2006. ACM.", "R. Andersen, C. Borgs, J. Chayes, J. Hopcraft, V. S. Mirrokni, and S.-H. Teng. Local computation of pagerank contributions. In WAW, pages 150--165, San Diego, CA, USA, 2007. Springer-Verlag.", "Z. Bar-Yossef and L.-T. Mashiach. Local approximation of pagerank and reverse pagerank. In CIKM, pages 279--288, Napa Valley, California, USA, 2008. ACM Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767704"}, {"title": "High-Performance Storage Support for Scientific Applications on the Cloud", "authors": ["Dongfang Zhao\n,", "Xu Yang\n,", "Iman Sadooghi\n,", "Gabriele Garzoglio\n,", "Steven Timm\n,", "Ioan Raicu"], "publication": "ScienceCloud '15: Proceedings of the 6th Workshop on Scientific Cloud Computing", "abstract": "ABSTRACT\nAlthough cloud computing has become one of the most popular paradigms for executing data-intensive applications (for example, Hadoop), the storage subsystem is not optimized for scientific applications. We believe that when executing scientific applications in the cloud, a node-local distributed storage architecture is a key approach to overcome the challenges from the conventional shared/parallel storage systems. We analyze and evaluate four representative file systems (S3FS, HDFS, Ceph, and FusionFS) on three platforms (Kodiak cluster, Amazon EC2 and FermiCloud) with a variety of benchmarks to explore how well these storage systems can handle metadata intensive, write intensive, and read intensive workloads.", "references": ["K. Shvachko, et al. The hadoop distributed file system. In MSST, 2010.", "S. Ghemawat, et al. The Google file system. In SOSP, 2003.", "P. Carns, et al. Small-file access in parallel file systems. In IPDPS, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2755644.2755648"}, {"title": "Recognition of trees using Computer Vision to prevent interruptions in the Power Distribution System", "authors": ["Heuber Gustavo Frazao de Lima\n,", "Ronaldo Martins Costa\n,", "Anderson da Silva Soares\n,", "Gustavo Teodoro Laureano"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe electrical distribution is a critical activity since many people depend of this service. Faults in the distribution system occur from several factors that can damage the system and therefore interrupt the supply of energy. Among the various factors that may cause problems this work proposes a automatic detection of trees near or even in the distribution network. In order to avoid that the trees to force or even rupture of the distribution cables, are made the pruning of the trees that have some kind of risk to the network. However, this activity is usually manual and teams must sift through all the network for problems. The main objective of this work is to propose a process, based on computer vision, which allows the automated identification of nearby trees or under the power distribution network from aerial images provided by Google Earth.", "references": ["Kagan, N., de Oliveira, C.C.C.B. & Robba, E.J., 2005. Introdução aos sistemas de distribuição de energia elétrica, Edgard Blucher.", "Projeto SCOM 02, Comitê de Distribuição, \"Manutenção de Sistemas de Distribuição\", CELG - Centrais Elétricas de Goiás, 1988.", "Projeto SCOM 08, Comitê de Distribuição, \"Critérios para a Manutenção de Rede de Distribuição\", CELG - Centrais Elétrieas de Goiás, 1988."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814081"}, {"title": "Fast Image Classification for Monument Recognition", "authors": ["Giuseppe Amato\n,", "Fabrizio Falchi\n,", "Claudio Gennaro"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nContent-based image classification is a wide research field that addresses the landmark recognition problem. Among the many classification techniques proposed, the k-nearest neighbor (kNN) is one of the most simple and widely used methods. In this article, we use kNN classification and landmark recognition techniques to address the problem of monument recognition in images. We propose two novel approaches that exploit kNN classification technique in conjunction with local visual descriptors.\nThe first approach is based on a relaxed definition of the local feature based image to image similarity and allows standard kNN classification to be efficiently executed with the support of access methods for similarity search.\nThe second approach uses kNN classification to classify local features rather than images. An image is classified evaluating the consensus among the classification of its local features. In this case, access methods for similarity search can be used to make the classification approach efficient.\nThe proposed strategies were extensively tested and compared against other state-of-the-art alternatives in a monument and cultural heritage landmark recognition setting. The results proved the superiority of our approaches.\nAn additional relevant contribution of this work is the exhaustive comparison of various types of local features and image matching solutions for recognition of monuments and cultural heritage related landmarks.", "references": ["Giuseppe Amato and Fabrizio Falchi. 2010. kNN based image classification relying on local feature similarity. In Proceedings of the 3rd International Conference on Similarity Search and Applications (SISAP’10). ACM, New York, NY, 101--108.", "Giuseppe Amato and Fabrizio Falchi. 2011. Local feature based image similarity functions for kNN classfication. In Proceedings of the 3rd International Conference on Agents and Artificial Intelligence (ICAART’11). 157--166.", "Giuseppe Amato, Fabrizio Falchi, and Claudio Gennaro. 2011. Geometric consistency checks for kNN based image classification relying on local features. In Proceedings of the 4th International Conference on Similarity Search and Applications (SISAP’11). ACM, New York, NY, 81--88. DOI:http://dx.doi.org/10.1145/1995412.1995428"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2724727"}, {"title": "SIGIR 2015 Workshop on Temporal, Social and Spatially-aware Information Access (#TAIA2015)", "authors": ["Klaus Berberich\n,", "James Caverlee\n,", "Miles Efron\n,", "Claudia Hauff\n,", "Vanessa Murdock\n,", "Milad Shokouhi\n,", "Bart Thomee"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this workshop we aim to bring together practitioners and researchers to discuss their recent breakthroughs and the challenges with addressing spatial and temporal information access, both from the algorithmic and the architectural perspectives.", "references": ["F. Diaz, S. Dumais, M. Efron, K. Radinsky, M. de Rijke, and M. Shokouhi. Sigir 2013 workshop on time aware information access (# taia2013). In Proceedings of the 36th international ACM SIGIR conference on Research &Ddevelopment in information retrieval, SIGIR '13, pages 1137--1137, 2013.", "F. Diaz, S. Dumais, K. Radinsky, M. de Rijke, and M. Shokouhi.#taia2012. SIGIR Forum, 46(2):102--106, 2012.", "F. Diaz, C. Hauff, V. Murdock, M. de Rijke, and M. Shokouhi. Sigir 2014 workshop on temporal, social and spatially-aware information access (#taia2014). In Proceedings of the 37th international ACM SIGIR conference on Research &Ddevelopment in information retrieval, SIGIR '14, pages 1298--1298, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767860"}, {"title": "A Methodology to Evaluate Important Dimensions of Information Quality in Systems", "authors": ["Ion-George Todoran\n,", "Laurent Lecornu\n,", "Ali Khenchaf\n,", "Jean-Marc Le Caillec"], "publication": "Journal of Data and Information Quality", "abstract": "Abstract\nAssessing the quality of the information proposed by an information system has become one of the major research topics in the last two decades. A quick literature survey shows that a significant number of information quality frameworks are proposed in different domains of application: management information systems, web information systems, information fusion systems, and so forth. Unfortunately, they do not provide a feasible methodology that is both simple and intuitive to be implemented in practice. In order to address this need, we present in this article a new information quality methodology. Our methodology makes use of existing frameworks and proposes a three-step process capable of tracking the quality changes through the system. In the first step and as a novelty compared to existing studies, we propose decomposing the information system into its elementary modules. Having access to each module allows us to locally define the information quality. Then, in the second step, we model each processing module by a quality transfer function, capturing the module’s influence over the information quality. In the third step, we make use of the previous two steps in order to estimate the quality of the entire information system. Thus, our methodology allows informing the end-user on both output quality and local quality. The proof of concept of our methodology has been carried out considering two applications: an automatic target recognition system and a diagnosis coding support system.", "references": ["C. Bishop. 2006. Pattern Recognition And Machine Learning. Springer-Verlag, New York, NY.", "R. Bovee, R. Srivastava, and B. Mak. 2003. A conceptual framework and belief-function approach to assessing overall information quality. International Journal of Intelligent Systems. 18, 1 (Jan. 2003), 51--74.", "I. N. Chengalur-Smith, D. P. Ballou, and H. L. Pazer. 1999. The impact of data quality information on decision making: An exploratory analysis. IEEE Transactions on Knowledge and Data Engineering 11, 6 (Dec. 1999), 853--864."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744205"}, {"title": "Assessment of Tweet Credibility with LDA Features", "authors": ["Jun Ito\n,", "Jing Song\n,", "Hiroyuki Toda\n,", "Yoshimasa Koike\n,", "Satoshi Oyama"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the fast development of Social Networking Services (SNS) such as Twitter, which enable users to exchange short messages online, people can get information not only from the traditional news media but also from the masses of SNS users. However, SNS users sometimes propagate spurious or misleading information, so an effective way to automatically assess the credibility of information is required. In this paper, we propose methods to assess information credibility on Twitter, methods that utilize the \"tweet topic\" and \"user topic\" features derived from the Latent Dirichlet Allocation (LDA) model. We collected two thousand tweets labeled by seven annotators each, and designed effective features for our classifier on the basis of data analysis results. An experiment we conducted showed a 3% improvement in Area Under Curve (AUC) scores compared with existing methods, leading us to conclude that using topical features is an effective way to assess tweet credibility.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. The Journal of Machine Learning Research, 3:993--1022, 2003.", "L. Breiman. Random Forests. Machine Learning, 45(1):5--32, 2001.", "C. Castillo, M. Mendoza, and B. Poblete. Information Credibility on Twitter. In WWW, pp. 675--684, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742569"}, {"title": "Comparing Approaches for Query Autocompletion", "authors": ["Giovanni Di Santo\n,", "Richard McCreadie\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWithin a search engine, query auto-completion aims to predict the final query the user wants to enter as they type, with the aim of reducing query entry time and potentially preparing the search results in advance of query submission. There are a large number of approaches to automatically rank candidate queries for the purposes of auto-completion. However, no study exists that compares these approaches on a single dataset. Hence, in this paper, we present a comparison study between current approaches to rank candidate query completions for the user query as it is typed. Using a query-log and document corpus from a commercial medical search engine, we study the performance of 11 candidate query ranking approaches from the literature and analyze where they are effective. We show that the most effective approaches to query auto-completion are largely dependent on the number of characters that the user has typed so far, with the most effective approach differing for short and long prefixes. Moreover, we show that if personalized information is available about the searcher, this additional information can be used to more effectively rank query candidate completions, regardless of the prefix length.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proc. of WWW, 2011.", "S. Bhatia, D. Majumdar, and P. Mitra. Query suggestions in the absence of query logs. In Proc. of SIGIR, 2011.", "C. Fellbaum. Wordnet and wordnets. Encyclopedia of Language and Linguistics, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767829"}, {"title": "Collision Resolution in Hash Tables for Vocabulary Accumulation During Parallel Indexing", "authors": ["Matt Crane\n,", "Andrew Trotman"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nDuring indexing the vocabulary of a collection needs to be built. The structure used for this needs to account for the skew distribution of terms. Parallel indexing allows for a large reduction in number of times the global vocabulary needs to be examined, however, this also raises a new set of challenges. In this paper we examine the structures used to resolve collisions in a hash table during parallel indexing, and find that the best structure is different from those suggested previously.", "references": ["S. Büttcher, C. L. A. Clarke, and G. V. Cormack. Information Retrieval: Implementing and Evaluating Search Engines. MIT Press, 2010.", "S. Heinz and J. Zobel. Performance of data structures for small sets of strings. In Proceedings of the 25th Australasian Conference on Computer Science, ACSC '02, pages 87--94, 2002.", "T. J. Rolfe. One-time binary search tree balancing: The Day/Stout/Warren (DSW) algorithm. SIGCSE Bull., 34(4):85--88, Dec. 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838942"}, {"title": "Componentizing the Web", "authors": ["Taylor Savage"], "publication": "Queue", "abstract": "Abstract\nWe may be on the cusp of a new revolution in web development.", "references": ["http://bosonic.github.io/", "http://w3c.github.io/webcomponents/spec/custom/", "http://w3c.github.io/webcomponents/spec/imports/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838344.2844732"}, {"title": "Modelling the Usefulness of Document Collections for Query Expansion in Patient Search", "authors": ["Nut Limsopatham\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDealing with the medical terminology is a challenge when searching for patients based on the relevance of their medical records towards a given query. Existing work used query expansion (QE) to extract expansion terms from different document collections to improve query representation. However, the usefulness of particular document collections for QE was not measured and taken into account during retrieval. In this work, we investigate two automatic approaches that measure and leverage the usefulness of document collections when exploiting multiple document collections to improve query representation. These two approaches are based on resource selection and learning to rank techniques, respectively. We evaluate our approaches using the TREC Medical Records track's test collection. Our results show the potential of the proposed approaches, since they can effectively exploit 14 different document collections, including both domain-specific (e.g. MEDLINE abstracts) and generic (e.g. blogs and webpages) collections, and significantly outperform existing effective baselines, including the best systems participating at the TREC Medical Records track. Our analysis shows that the different collections are not equally useful for QE, while our two approaches can automatically weight the usefulness of expansion terms extracted from different document collections effectively.", "references": ["G. Amati. Probabilistic Models for Information Retrieval based on Divergence from Randomness. PhD thesis. University of Glasgow, 2003.", "G. Amati, E. Ambrosi, M. Bianchi, C. Gaibisso and G. Gambosi. FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog Track. TREC'07.", "J. Callan. Distributed Information Retrieval. Advances in Information Retrieval, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806614"}, {"title": "A study of tweet chats for breast cancer patients", "authors": ["Kunal Singh\n,", "Ajita John"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nOne of the oldest patient communities on Twitter is characterized by the hashtag #bcsm, and it is a forum for breast cancer patients and survivors. This community has been hosting a weekly, moderated chat for the last three years. This paper describes work that analyzes the content of these chats and explores their effectiveness for the patients. The computational analysis compares the engagement, linguistic, and psychological facets of patients' tweets during the chats and out of the chats, and shows that there is a significant difference in the tweeting behavior by the patients in the two modes. The result shows the effectiveness of social media chats for cancer patients for the purposes of information exchange and support.", "references": ["Butcher, L. 2013. Profiles in oncology social media: Deanna Attai, MD,@ DrAttai. Oncology Times 35, 24, 40--42.", "Fox, S., and Duggan, M. 2013. Health online 2013. Pew Internet and American Life Project. Health.", "Elkin, N. 2008. How America searches: health and wellness. Avalable at: http://www.icrossing.com/icrossing-how-america-searches (accessed 21 February 2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789193"}, {"title": "A connective MOOC for K-12 science and mathematics teacher professional development in native American Pueblo schools", "authors": ["Josephine Kilde\n,", "Lorenzo Gonzales"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nThis paper describes considerations for the participatory design and development of an online collaborative learning and support tool intended to increase STEM proficiency among elementary and high school teachers in Native American Pueblo schools in New Mexico. This project builds upon prior work that trained K-12 teachers to use investigative teaching, which in turn had significant positive impact on the math and science proficiency of Native American and Hispanic students. The current project seeks to use Connective Massive Open Course (cMOOC) technology to build online peer learning communities for the purpose of professional development amongst rural teachers with the expectation of building shared epistemologies that would guide integration of Native American learning processes in pedagogy and practice. The overall objective is to enable Pueblo teachers to more effectively teach STEM subject matter, as measured by an increase in both teacher and student content knowledge base. If successful, the use of these technologies should facilitate rapid expansion of the program across Native American Pueblos and reservations in United States, Canada, Mexico, and elsewhere.", "references": ["R. Mussa and K. Paul, \"Poverty in Malawi-Current status and knowledge gaps,\" no. December, 2011.", "M. Sarche and P. Spicer, \"Poverty and health disparities for American Indian and Alaska Native children: current knowledge and future prospects.,\" Ann. N. Y. Acad. Sci., vol. 1136, pp. 126--36, Jan. 2008.", "\"Native Nations | FCC.gov,\" Federal Communications Commission. {Online}. Available: http://www.fcc.gov/native. {Accessed: 21-Feb-2015}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2737871"}, {"title": "Accessibility for business and pleasure", "authors": ["Sarah Horton\n,", "David Sloan"], "publication": "Interactions", "abstract": "Abstract\nThis forum is dedicated to maximizing the success of HCI practitioners within the frenetic world of product and service design. It focuses on UX strategy approaches, leadership, management techniques, and above all the challenge of bringing HCI to peer-level status with longstanding business disciplines such as marketing and engineering. --- Daniel Rosenberg, Editor", "references": ["Denning, S. Why Tim Cook doesn't care about 'the bloody ROI.' Forbes. Mar. 7, 2014; http://www.forbes.com/sites/stevedenning/2014/03/07/why-tim-cook-doesnt-care-about-the-bloody-roi/", "Brown, T. Change By Design. HarperBusiness, New York, 2009.", "National Federation for the Blind. 2012 Resolutions; https://nfb.org/images/nfb/publications/bm/bm12/bm1208/bm120814.htm"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2843590"}, {"title": "Proof Protocol for a Machine Learning Technique Making Longitudinal Predictions in Dynamic Contexts", "authors": ["Kevin B. Pratt"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWe demonstrate a protocol for proving strongly that a black-box machine learning technique robustly predicts the future in dynamic, indefinite contexts. We propose necessary components of the proof protocol and demonstrate results visualizations to support evaluation of the proof components. Components include contemporaneously verifiable discrete predictions, deterministic computability of longitudinal predictions, imposition of realistic costs and domain constraints, exposure to diverse contexts, statistically significant excess benefits relative to a priori benchmarks and Monte Carlo trials, insignificant decay of excess benefits, pathology detection and an extended real-time trial \"in the wild.\" We apply the protocol to a big data machine learning technique deployed since 2011 that finds persistent, exploitable opportunities in many of 41 segments of US financial markets, the existence of which opportunities substantially contradict the Efficient Market Hypothesis.", "references": ["Brooks, J. S. et al. 2006. Testing Hypotheses for the Success of Different Conservation Strategies. Conservation Biology, 20, 5 (Oct. 2006), 1528--1538. DOI=10.1111/j.1523--1739.2006.00506.", "Canadi, I., Barford, P. and Sommers, J. 2012. Revisiting broadband performance. In IMC '12 Proceedings of the 2012 ACM conference on Internet measurement conference. ACM New York, NY (2012), 273--286.", "Changa, R. M., Kauffman, R. J. and Kwonc, Y. 2014. Understanding the paradigm shift to computational social science in the presence of big data. Decision Support Systems, 63 (Jul. 2014), 67--80. DOI=10.1016/j.dss.2013.08.008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788592"}, {"title": "Finding Money in the Haystack: Information Retrieval at Bloomberg", "authors": ["Jonathan J. Dorando\n,", "Konstantine Arkoudas\n,", "Parth Vasa\n,", "Gary Kazantsev\n,", "Gideon Mann"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe financial markets are a rich domain for search, and it is not simple to serving the entire scope of financial professionals, who make their living on accurate, timely, and deep information. The data sources are many and disparate. This includes domains with rich structured data such as company and security attributes, textual data like research reports, and time sensitive news stories. Not only is the domain complicated, but some of the techniques that work for web search have to be adapted and reconsidered in an enterprise context with fewer eyeballs but just as complicated questions. At Bloomberg, we have been addressing these problems over the past four years in the search and discoverability group, heavily leveraging the insights from the academic and open-source communities to apply to our problems. We'll discuss about our efforts in Natural Language Question & Answer (NLQA), learning to rank, federated search, crowd sourcing, and how this all comes together to make search effective for our users.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776782"}, {"title": "Dynamic Memory Pressure Aware Ballooning", "authors": ["Jinchun Kim\n,", "Viacheslav Fedorov\n,", "Paul V. Gratz\n,", "A. L. Narasimha Reddy"], "publication": "MEMSYS '15: Proceedings of the 2015 International Symposium on Memory Systems", "abstract": "ABSTRACT\nHardware virtualization is a major component of large scale server and data center deployments due to their facilitation of server consolidation and scalability. Virtualization, however, comes at a high cost in terms of system main memory utilization. Current virtual machine (VM) memory management solutions impose a high performance penalty and are oblivious to the operating regime of the system. Therefore, there is a great need for low-impact VM memory management techniques which are aware of and reactive to current system state, to drive down the overheads of virtualization.\nWe observe that the host machine operates under different memory pressure regimes, as the memory demand from guest VMs changes dynamically at runtime. Adapting to this runtime system state is critical to reduce the performance cost of VM memory management. In this paper, we propose a novel dynamic memory management policy called Memory Pressure Aware (MPA) ballooning. MPA ballooning dynamically allocates memory resources to each VM based on the current memory pressure regime. Moreover, MPA ballooning proactively reacts and adapts to sudden changes in memory demand from guest VMs. MPA ballooning requires neither additional hardware support, nor incurs extra minor page faults in its memory pressure estimation. We show that MPA ballooning provides an 13.2% geomean speed-up versus the current ballooning techniques across a set of application mixes running in guest VMs; often yielding performance nearly identical to that of a non-memory constrained system.", "references": ["P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neugebauer, I. Pratt, and A. Warfield. Xen and the art of virtualization. In ACM SIGOPS Operating Systems Review (SOSP), volume 37, pages 164--177, 2003.", "T. W. Barr, A. L. Cox, and S. Rixner. Spectlb: a mechanism for speculative address translation. In Computer Architecture (ISCA), 2011 38th Annual International Symposium on, pages 307--317. IEEE, 2011.", "C. Bienia, S. Kumar, J. P. Singh, and K. Li. The parsec benchmark suite: characterization and architectural implications. In Proceedings of the 17th International conference on Parallel Architectures and Complication Techniques (PACT), pages 72--81, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818950.2818967"}, {"title": "Automatic Methods for Disambiguating Author Names in Bibliographic Data Repositories", "authors": ["Anderson A. Ferreira\n,", "Marcos André Gonçalves\n,", "Alberto H.F. Laender"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nName ambiguity in the context of bibliographic citation records is a hard problem that affects the quality of services and content in digital libraries and similar systems. This problem occurs when an author publishes works under distinct names or distinct authors publish works under similar names. The challenges of dealing with author name ambiguity have led to a myriad of name disambiguation methods. In this tutorial, we characterize such methods by means of a proposed taxonomy, present an overview of some of the most representative ones and discuss open challenges.", "references": ["I. Bhattacharya and L. Getoor. A Latent Dirichlet Model for Unsupervised Entity Resolution. In SDM, 2006.", "A. P. Carvalho, A. A. Ferreira, A. H. F. Laender, and M. A. Gonçalves. Incremental Unsupervised Name Disambiguation in Cleaned Digital Libraries. JIDM, 2 (3): 289--304, 2011.", "R. G. Cota, A. A. Ferreira, M. A. Gonçalves, A. H. F. Laender, and C. Nascimento. An unsupervised heuristic-based hierarchical method for name disambiguation in bibliographic citations. JASIST, 61 (9): 1853--1870, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756930"}, {"title": "Batch processing of Top-k Spatial-textual Queries", "authors": ["Farhana M. Choudhury\n,", "J. Shane Culpepper\n,", "Timos Sellis"], "publication": "GeoRich'15: Second International ACM Workshop on Managing and Mining Enriched Geo-Spatial Data", "abstract": "ABSTRACT\nTop-k spatial-textual queries have received significant attention in the research community. Several techniques to efficiently process this class of queries are now widely used in a variety of applications. However, the problem of how best to process multiple queries efficiently is not well understood. Applications relying on processing continuous streams of queries, and offline pre-processing of other queries could benefit from solutions to this problem. In this work, we study practical solutions to efficiently process a set of top-k spatial-textual queries. We propose an efficient best-first algorithm for the batch processing of top-k spatial-textual queries that promotes shared processing and reduced I/O in each query batch. By grouping similar queries and processing them simultaneously, we are able to demonstrate significant performance gains using publicly available datasets.", "references": ["Google annual search statistics. http://www.statisticbrain.com/google-searches. {Online; accessed 20-03-2015}.", "L. Chen, G. Cong, C. S. Jensen, and D. Wu. Spatial keyword query processing: an experimental evaluation. In VLDB, pages 217--228, 2013.", "G. Cong, C. S. Jensen, and D. Wu. Efficient retrieval of the top-k most relevant spatial web objects. PVLDB, 2(1):337--348, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786006.2786008"}, {"title": "An Approach to Lowering the In Situ Visualization Barrier", "authors": ["Thomas Fogal\n,", "Jens Krüger"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nCoupling visualization and analysis software with simulation code is a resource-intensive task. As the usage of simulation-based science grows, we asked ourselves: what would it take to enable in situ visualization for every simulation in existence? This paper presents an alternative view focusing on the approachability of in situ visualization. Utilizing a number of techniques from the program analysis community and taking advantage of commonalities in scientific software, we find that we can vastly reduce the time investment required to achieve visualization-enabled simulations.", "references": ["J. Ahrens, B. Geveci, and C. Law. ParaView: An end-user tool for large data visualization. The Visualization Handbook, 717:731, 2005.", "G. Antoniu and P. Hatcher. Remote Object Detection in Cluster-Based Java. Research Report RR-4101, 2001.", "D. Bruening, Q. Zhao, and S. Amarasinghe. Transparent dynamic instrumentation. In Proceedings of the 8th ACM SIGPLAN/SIGOPS Conference on Virtual Execution Environments, VEE '12, pages 133--144, New York, NY, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828618"}, {"title": "Information cartography", "authors": ["Dafna Shahaf\n,", "Carlos Guestrin\n,", "Eric Horvitz\n,", "Jure Leskovec"], "publication": "Communications of the ACM", "abstract": "Abstract\nA metro map can tell a story, as well as provide good directions.", "references": ["Ahmed, A., Ho, Q., Eisenstein, J., Xing, E., Smola, A.J., and Teo, C.H. Unified analysis of streaming news. In Proceedings of the 20th International Conference on the World Wide Web (Hyderabad, India, Mar. 28-Apr. 1). ACM Press, New York, 2011.", "Allan, J., Gupta, R., and Khandelwal, V. Temporal summaries of new topics. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (New Orleans, LA, Sept. 9-13). ACM Press, New York, 2001.", "Bloom, B.S., Engelhart, M.D., Furst, E.J., and Hill, W.H., Eds. Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain. Longman, White Plains, NY, 1956."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2735624"}, {"title": "Music Retrieval and Recommendation: A Tutorial Overview", "authors": ["Peter Knees\n,", "Markus Schedl"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this tutorial, we give an introduction to the field of and state of the art in music information retrieval (MIR). The tutorial particularly spotlights the question of music similarity, which is an essential aspect in music retrieval and recommendation. Three factors play a central role in MIR research: (1) the music content, i.e., the audio signal itself, (2) the music context, i.e., metadata in the widest sense, and (3) the listeners and their contexts, manifested in user-music interaction traces. We review approaches that extract features from all three data sources and combinations thereof and show how these features can be used for (large-scale) music indexing, music description, music similarity measurement, and recommendation. These methods are further showcased in a number of popular music applications, such as automatic playlist generation and personalized radio stationing, location-aware music recommendation, music search engines, and intelligent browsing interfaces. Additionally, related topics such as music identification, automatic music accompaniment and score following, and search and retrieval in the music production domain are discussed.", "references": ["A. Arzt and G. Widmer. Towards effective 'any-time' music tracking. In Proceedings of the Starting AI Researchers' Symposium (STAIRS), Lisbon, Portugal, 2010.", "L. Barrington, D. Turnbull, M. Yazdani, and G. Lanckriet. Combining audio content and social context for semantic music discovery. In Proceedings of the ACM SIGIR, Boston, MA, USA, 2009.", "O. Celma and P. Herrera. A new approach to evaluating novel recommendations. In Proceedings of the ACM Conference on Recommender Systems (RecSys), New York, NY, USA, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767880"}, {"title": "An Empirical Comparison of Statistical Term Association Graphs with DBpedia and ConceptNet for Query Expansion", "authors": ["Rajul Anand\n,", "Alexander Kotov"], "publication": "FIRE '15: Proceedings of the 7th Forum for Information Retrieval Evaluation", "abstract": "ABSTRACT\nTerm graphs constructed from document collections as well as external resources, such as encyclopedias (DBpedia) and knowledge bases (ConceptNet), can be used as sources of semantically related terms for query expansion. Although these resources individually have been shown to be effective for IR, it is not known how their retrieval effectiveness compares with each other. In this work, we use standard TREC collections to perform systematic evaluation and empirical comparison of retrieval effectiveness of both types of term graphs for all and difficult queries. Our results indicate that of the term association graphs constructed automatically from document collection using information theoretic measures are more effective for Web collections, while the term graphs derived from DBpedia and ConceptNet are more effective for newswire collections.", "references": ["J. Bai, D. Song, P. Bruza, J-Y. Nie and G. Cao. Query Expansion using Term Relationships in Language Models for Information Retrieval. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management (CIKM'05), pages 688--695, 2005.", "A. Bouchoucha, J. He, and J-Y. Nie. Diversified Query Expansion using ConceptNet. Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM'13), pages 1861--1864, 2013.", "C. Burgess, K. Livesay, and K. Lund. Explorations in Context Space: Words, Sentences and Discourse. Discourse Processes, 25:211--257, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838706.2838715"}, {"title": "Ontology Search: Finding the Right Ontologies on the Web", "authors": ["Anila Sahar Butt"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWith the recent growth of Linked Data on the Web, there is an increased need for knowledge engineers to find ontologies to describe their data. Only limited work exists that addresses the problem of searching and ranking ontologies based on keyword queries. In this proposal we introduce the main challenges to find appropriate ontologies, and preliminary solutions to address these challenges. Our evaluation shows that the proposed solution performs significantly better than existing solutions on a benchmark ontology collection for the majority of the sample queries defined in the benchmark.", "references": ["H. Alani, C. Brewster, and N. Shadbolt. Ranking Ontologies with AKTiveRank. In Proceedings of the International Semantic Web Conference (ISWC), pages 5--9, 2006.", "A. S. Butt, A. Haller, and L. Xie. Ontology search: An empirical evaluation. In Proceedings of the International Semantic Web Conference, pages 130--147, Riva del Gara, Italy, 2014.", "A. S. Butt, A. Haller, and L. Xie. Relationship-based top-k concept retrieval for ontology search. In Knowledge Engineering and Knowledge Management, pages 485--502. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741753"}, {"title": "Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR", "authors": ["Casper Petersen\n,", "Christina Lioma\n,", "Jakob Grue Simonsen\n,", "Birger Larsen"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nWe present two novel models of document coherence and their application to information retrieval (IR). Both models approximate document coherence using discourse entities, e.g. the subject or object of a sentence. Our first model views text as a Markov process generating sequences of discourse entities (entity n-grams); we use the entropy of these entity n-grams to approximate the rate at which new information appears in text, reasoning that as more new words appear, the topic increasingly drifts and text coherence decreases. Our second model extends the work of Guinaudeau & Strube [28] that represents text as a graph of discourse entities, linked by different relations, such as their distance or adjacency in text. We use several graph topology metrics to approximate different aspects of the discourse flow that can indicate coherence, such as the average clustering or betweenness of discourse entities in text. Experiments with several instantiations of these models show that: (i) our models perform on a par with two other well-known models of text coherence even without any parameter tuning, and (ii) reranking retrieval results according to their coherence scores gives notable performance gains, confirming a relation between document coherence and relevance. This work contributes two novel models of document coherence, the application of which to IR complements recent work in the integration of document cohesiveness or comprehensibility to ranking [5, 56].", "references": ["E. Banik. Extending a surface realizer to generate coherent discourse. In ACL/IJCNLP (Short Papers), pages 305--308. ACL, 2009.", "R. Barzilay, N. Elhadad, and K. McKeown. Inferring strategies for sentence ordering in multidocument news summarization. J. Artif. Intell. Res. (JAIR), 17:35--55, 2002.", "R. Barzilay and M. Lapata. Modeling local coherence: An entity-based approach. ACL, 34(1):1--34, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809458"}, {"title": "Session details: Main Track - Software Requirements, Architecture and Design for Information Systems", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252435"}, {"title": "An Optimization Framework for Merging Multiple Result Lists", "authors": ["Chia-Jung Lee\n,", "Qingyao Ai\n,", "W. Bruce Croft\n,", "Daniel Sheldon"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDeveloping effective methods for fusing multiple ranked lists of documents is crucial to many applications. Federated web search, for instance, has become a common practice where a query is issued to different verticals and a single ranked list of blended results is created. While federated search is regarded as collection fusion, data fusion techniques aim at improving search coverage and precision by combining multiple search runs on a single document collection. In this paper, we study in depth and extend a neural network-based approach, LambdaMerge, for merging results of ranked lists drawn from one (i.e., data fusion) or more (i.e., collection fusion) verticals. The proposed model considers the impact of the quality of documents, ranked lists and verticals for producing the final merged result in an optimization framework. We further investigate the potential of incorporating deep structures into the model with an aim of determining better combinations of different evidence. In the experiments on collection fusion and data fusion, the proposed approach significantly outperforms several standard baselines and state-of-the-art learning-based approaches.", "references": ["J. A. Aslam and M. Montague. Bayes optimal metasearch: A probabilistic model for combining the results of multiple retrieval systems (poster session). In Proceedings of SIGIR, SIGIR '00, pages 379--381, 2000.", "J. A. Aslam and M. Montague. Models for metasearch. In Proceedings of SIGIR, SIGIR '01, pages 276--284, 2001.", "S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman, O. Frieder, and N. Goharian. On fusion of effective retrieval strategies in the same information retrieval system. JASIST, 55:859--868, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806489"}, {"title": "Switching sources: a study of people's exploratory search behavior on social media and the web", "authors": ["Dongho Choi\n,", "Ziad Matni\n,", "Chirag Shah"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nSearching the Web for information via search engines is a ubiquitous phenomenon and a well-established field of study in Information Science. Social media sites also continue to evolve and by now have gained enough popularity and momentum to be used as not just vessels for communication with others, but also as important repositories of information. However, it is not clear if the information behavior of users of traditional search engines differ from those performing information searches strictly on social media sites. To address this, we examined data from two user studies on people's exploratory searching behavior: one group only used Web search engines, while the other exclusively used social media sites to search for information. Information search behaviors of both groups regarding exploratory tasks were observed and analyzed through search log and surveys. The results indicate that, while people using social media sites for exploratory search tasks find a smaller quantity and a less diverse set of documents than what they might discover when utilizing traditional Web search engines, they do perceive to end up with more relevant documents. They also report doing less work and feeling less challenged.", "references": ["Bawden, D. (1986). Information systems and the stimulation of creativity. Journal of Information Science, 12(5), 203--216.", "Bennett, W. L., & Iyengar, S. (2008). A New Era of Minimal Effects? The Changing Foundations of Political Communication. Journal of Communication, 58(4), 707--731.", "Budd, J. M. (2004). Relevance!: Language, Semantics, Philosophy."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857115"}, {"title": "Gathering Additional Feedback on Search Results by Multi-Armed Bandits with Respect to Production Ranking", "authors": ["Aleksandr Vorobev\n,", "Damien Lefortier\n,", "Gleb Gusev\n,", "Pavel Serdyukov"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nGiven a repeatedly issued query and a document with a not-yet-confirmed potential to satisfy the users' needs, a search system should place this document on a high position in order to gather user feedback and obtain a more confident estimate of the document utility. On the other hand, the main objective of the search system is to maximize expected user satisfaction over a rather long period, what requires showing more relevant documents on average. The state-of-the-art approaches to solving this exploration-exploitation dilemma rely on strongly simplified settings making these approaches infeasible in practice. We improve the most flexible and pragmatic of them to handle some actual practical issues. The first one is utilizing prior information about queries and documents, the second is combining bandit-based learning approaches with a default production ranking algorithm. We show experimentally that our framework enables to significantly improve the ranking of a leading commercial search engine.", "references": ["A. Agarwal, D. Hsu, S. Kale, J. Langford, L. Li, and R. E. Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. arXiv preprint arXiv:1402.0555, 2014.", "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2--3):235--256, 2002.", "P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz. Inferring and using location metadata to personalize web search. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '11, pages 135--144, New York, NY, USA, 2011. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741104"}, {"title": "Geo-Social Ranking: functions and query processing", "authors": ["Nikos Armenatzoglou\n,", "Ritesh Ahuja\n,", "Dimitris Papadias"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nGiven a query location q, Geo-Social Ranking (GSR) ranks the users of a Geo-Social Network based on their distance to q, the number of their friends in the vicinity of q, and possibly the connectivity of those friends. We propose a general GSR framework and four GSR functions that assign scores in different ways: (i) LC, which is a weighted linear combination of social (i.e., friendships) and spatial (i.e., distance to q) aspects, (ii) RC, which is a ratio combination of the two aspects, (iii) HGS, which considers the number of friends in coincident circles centered at q, and (iv) GST, which takes into account triangles of friends in the vicinity of q. We investigate the behavior of the functions, qualitatively assess their results, and study the effects of their parameters. Moreover, for each ranking function, we design a query processing technique that utilizes its specific characteristics to efficiently retrieve the top-k users. Finally, we experimentally evaluate the performance of the top-k algorithms with real and synthetic datasets.", "references": ["Armenatzoglou, N., Papadopoulos, S., Papadias, D.: A general framework for geo-social query processing. In: VLDB (2013)", "Aurenhammer, F., Edelsbrunner, H.: An optimal algorithm for constructing the weighted voronoi diagram in the plane. Pattern Recogn. 17(2), 251---257 (1984)", "Babenko, M., Goldberg, A., Gupta, A., Nagarajan, V.: Algorithms for hub label optimization. In: Automata, Languages, and Programming, LNCS 7965, pp. 69---80 (2013)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0400-7"}, {"title": "A Modular Approach to Promote Creativity and Inspiration in Search", "authors": ["Alice Thudt\n,", "Uta Hinrichs\n,", "Sheelagh Carpendale"], "publication": "C&C '15: Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition", "abstract": "ABSTRACT\nWhen searching through collections of books or written texts, the efficient yet limiting query paradigm is still the most dominant entry point. Previous work characterizes search processes in various contexts and describes them as integral and closely related to creative endeavours. We revisit this work from a design perspective, proposing guidelines for versatile search interfaces that are based on a modular approach to search. Inspired by aspects of search in physical environments, our recommendations address learning, creativity, inspiration, and pleasure as positive aspects of (book) search. Based on in-depth interviews with library patrons about search practises in physical and digital environments and drawing from previous work on search behaviour, we discuss search patterns as modular constructs consisting of micro-strategies. We illustrate how the structure of these patterns is highly flexible. Much like creative processes, they fluidly evolve based on learning and ideation during search, particularly in physical environments. This modular perspective provides a basis for designing interfaces that facilitate creative approaches to search in digital environments.", "references": ["Bates, M. J. Information Search Tactics. Journal of American Society for Information Sciences 30 (1979), 205--214.", "Bates, M. J. An exploratory paradigm for online information retrieval. In Proc. of Information Science (1985), 91--99.", "Bates, M. J. The design of browsing and berrypicking techniques for the online search interface. Online Information Review 13, 5 (1989), 407--431."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757226.2757253"}, {"title": "Destmaster: improved destination input system for the UR-walking application", "authors": ["Stefan Covaci\n,", "Maximilian Frick\n,", "Florian Krämer\n,", "Julian Pörsch"], "publication": "MUM '15: Proceedings of the 14th International Conference on Mobile and Ubiquitous Multimedia", "abstract": "ABSTRACT\nFast, intuitive interaction combined with high quality results are very important aspects, which need consideration, when implementing a search engine. With this in mind, the project \"improved destination input system for the UR-Walking application\" aims at optimizing the destination input for the Campus Navigation Web-Application at the University of Regensburg. Improving this type of search system involves handling ambivalent search requests. For example, keywords like the name of a professor could generate a misleading result, because the professors' name could lead either to his office or to one of his seminars. In this paper, we describe our implemented approaches to cope with a vast spectrum of different search requests concerning the campus navigation application.", "references": ["Paternò, F., Mancini, C., & Meniconi, S. (1997, January). ConcurTaskTrees: A diagrammatic notation for specifying task models. In Human-Computer Interaction INTERACT'97 (pp. 362-369). Springer US.", "Wandke, H. (2005). Assistance in human-machine interaction: a conceptual framework and a proposal for a taxonomy. Theoretical Issues in Ergonomics Science, 6(2), 129--155.", "Nielsen, J. (1995).10 usability heuristics for user interface design. Fremont: Nielsen Norman Group. {Accessed on to the 20 September 2015}. Available on the Internet."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2836041.2841203"}, {"title": "Conceptualization of a technical solution for web navigation of visually impaired people", "authors": ["Stéphanie Giraud\n,", "Pierre Thérouanne\n,", "Dirk D. Steiner"], "publication": "IHM '15: Proceedings of the 27th Conference on l'Interaction Homme-Machine", "abstract": "ABSTRACT\nDespite the autonomy gain provided by the Web for blind people, its access for this population still remains difficult. Today, web accessibility is practically restricted to the normative accessibility guaranteed by the application of design standards. Effective accessibility, which ensures that the users can reach their goal, is therefore forgotten at the expense of the interface usability. Thus, we proposed the conceptualization of a technical solution which attains effective accessibility by solving the information filtering problem encountered by blind people. The conceptualization of this solution, supported by previous experimental results, seems promising to make web interfaces easier and faster to use by blind people.", "references": ["Montagné, G. L'inclusion des personnes aveugles et malvoyantes dans le monde d'aujourd'hui. Paris: Ministère du travail, des relations sociales et de la solidarité (2007).", "World Health Organization. Global data on visual impairments 2010. Retrieved from http://www.who.int/blindness/GLOBALDATAFINALforweb.pdf", "HandiCapZero. Enquête 2005: qui êtes-vous? Retrieved from http://www.handicapzero.org/fileadmin/user_upload/contenu/Enquete/Telechargez_l_enquete_complete_en_PDF.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820619.2825004"}, {"title": "Towards Automatic Meal Plan Recommendations for Balanced Nutrition", "authors": ["David Elsweiler\n,", "Morgan Harvey"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nFood recommenders have been touted as a useful tool to help people achieve a healthy diet. Here we incorporate nutrition into the recommender problem by examining the feasibility of algorithmically creating daily meal plans for a sample of user profiles (n=100), combined with a diverse set of food preference data (n=64) collected in a natural setting. Our analyses demonstrate it is possible to recommend plans for a large percentage of users which meet the guidelines set out by international health agencies", "references": ["S. Berkovsky, J. Freyne, and G. Smith. Personalized network updates: increasing social interactions and contributions in social networks. In UMAP, pages 1--13. Springer, 2012.", "E. Brunner, D. Stallone, M. Juneja, S. Bingham, and M. Marmot. Dietary assessment in whitehall ii: comparison of 7 d diet diary and food-frequency questionnaire and validity against biomarkers. British J. of Nutrition, 86(3):405--14, 2001.", "D. Ornish et al. Can lifestyle changes reverse coronary heart disease?: The lifestyle heart trial. The Lancet, 336(8708):129 -- 133, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799665"}, {"title": "SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR)", "authors": ["Jaime Arguello\n,", "Fernando Diaz\n,", "Jimmy Lin\n,", "Andrew Trotman"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767858"}, {"title": "Popularity and Quality in Social News Aggregators: A Study of Reddit and Hacker News", "authors": ["Greg Stoddard"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nNo abstract available.", "references": ["E. Bakshy, I. Rosenn, C. Marlow, and L. Adamic. The role of social networks in information diffusion. In Proceedings of the 21st international conference on World Wide Web, pages 519--528. ACM, 2012.", "Y. Chen and T. W. Yan. Position-normalized click prediction in search advertising. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 795--803. ACM, 2012.", "G. E. Dupret and B. Piwowarski. A user browsing model to predict search engine click data from past observations. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 331--338. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742470"}, {"title": "Scalable Transportation Monitoring using the Smartphone Road Monitoring (SRoM) System", "authors": ["Sam Aleyadeh\n,", "Sharief M.A. Oteafy\n,", "Hossam S. Hassanein"], "publication": "DIVANet '15: Proceedings of the 5th ACM Symposium on Development and Analysis of Intelligent Vehicular Networks and Applications", "abstract": "ABSTRACT\nOur quest for ubiquitous Intelligent Transportation Systems (ITS) is simply infeasible over proprietary systems. In a time of abundant smart devices, it is impractical to consider developing competing proprietary monitoring systems to collect information for ITS operation. We argue for utilizing smartphones to present a driver and road monitoring system capable of scaling to the number of drivers without incurring high implementation costs, thus allowing for safer driving conditions and shorter accident response times. We propose the Smartphone Road Monitoring (SRoM) system that is capable of sensing road artifacts such as potholes and slippery roads. The information is collected through crowdsourcing and processed by base stations, giving faster and more accurate responses compared to current systems, to address road safety related events in a timely manner. It is also capable of detecting aberrant driver behavior such as speeding and drifting. SRoM uses both the driver's smartphone and vehicle as sources of information, and allows pedestrians to share media pertaining to each event. The collected data is made available to the public through an interactive map updated with the authenticated events. We implemented a prototype of the system to perform the task of safety monitoring. System evaluation of the prototype shows that the system can be easily implemented in real-life using current technologies at little cost.", "references": ["Canadian Motor Vehicle Traffic Collision Statistics (2011). Retrieved May 2015, from http://www.tc.gc.ca/media/documents/roadsafety/TrafficCollisionStatisitcs_2011.pdf", "European Automobile Manufacturers Association Average Vehicle Age Statics (2010). Retrieved May 2015, from http://www.acea.be/statistics/tag/category/average-vehicle-age.pdf", "Z. Wei, F. Yu, and A. Boukerche. 2014. Trust based security enhancements for vehicular ad hoc networks. In Proceedings of the fourth ACM international symposium on Development and analysis of intelligent vehicular networks and applications (DIVANet '14). ACM, New York, NY, USA, 103--109."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815347.2815349"}, {"title": "Visualization of Trustworthiness Graphs", "authors": ["Stephen Mayhew\n,", "Dan Roth"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nTrustworthiness is a field of research that seeks to estimate the credibility of information by using knowledge of the source of the information. The most interesting form of this problem is when different pieces of information share sources, and when there is conflicting information from different sources. This model can be naturally represented as a bipartite graph. In order to understand this data well, it is important to have several methods of exploring it. A good visualization can help to understand the problem in a way that no simple statistics can. This paper defines several desiderata for a \"good\" visualization and presents three different visualization methods for trustworthiness graphs.\nThe first visualization method is simply a naive bipartite layout, which is infeasible in nearly all cases. The second method is a physics-based graph layout that reveals some interesting and important structure of the graph. The third method is an orthogonal approach based on the adjacency matrix representation of a graph, but with many improvements that give valuable insights into the structure of the trustworthiness graph.\nWe present interactive web-based software for the third form of visualization.", "references": ["Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems, 30(1):107--117, 1998.", "Jon M Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM (JACM), 46(5):604--632, 1999.", "Jeff Pasternack and Dan Roth. Knowing what to believe (when you already know something). In Proceedings of the 23rd International Conference on Computational Linguistics, pages 877--885. Association for Computational Linguistics, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742574"}, {"title": "Understanding-oriented visual representation learning", "authors": ["Zechao Li"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nReal-world data such as images and video are often described by high-dimensional features, which are often redundant and noisy. It is necessary to uncover an appropriate latent subspace for data representation, which can increase learning accuracy and improve the performance comprehensibility. Different from the previous representation learning methods, we propose to integrate image understanding and representation learning into a joint learning framework. Image understanding and representation learning promote each other. Discriminative information for image understanding is discovered from data by the proposed nonnegative spectral clustering, which can well guide the representation learning. To find a better representation, the latent structures of data are exploited, which is benefit to image understanding. Besides, we adopt the ℓ2, 1 mixed norm to handle with the noisy or redundant original features. Based on the proposed frameworks, a suitable feature subset is selected and a suitable representation in the subspace is identified. It is noted that the proposed frameworks are general ones which can leverage several well-known algorithms as special cases and elucidate their intrinsic relationships.", "references": ["P. N. Belhumeur, J. P. Hespanha, X. Wu, and D. J. Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. IEEE Trans. Pattern Analysis and Machine Intelligence, 19(7):711--720, 1997.", "D. Cai, C. Zhang, and X. He. Unsupervised feature selection for multi-cluster data. In Proceedings of ACM SIGKDD International Conference Knowledge Discovery and Data Mining, pages 333--342, 2010.", "R. Duda, P. Hart, and D. Stork. Pattern Recognition (2nd Edition). New York, USA: John Wiley & Sons, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808572"}, {"title": "Who are the American Vegans related to Brad Pitt?: Exploring Related Entities", "authors": ["Nitish Aggarwal\n,", "Kartik Asooja\n,", "Housam Ziad\n,", "Paul Buitelaar"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this demo, we present Entity Relatedness Graph (EnRG), a focused related entities explorer, which provides the users with a dynamic set of filters and facets. It gives a ranked lists of related entities to a given entity, and clusters them using the different filters. For instance, using EnRG, one can easily find the American vegans related to Brad Pitt or Irish universities related to Semantic Web. Moreover, EnRG helps a user in discovering the provenance for implicit relations between two entities. EnRG uses distributional semantics to obtain the relatedness scores between two entities.", "references": ["N. Aggarwal, K. Asooja, P. Buitelaar, and G. Vulcu. Is brad pitt related to backstreet boys' exploring related entities. In Semantic Web Challenge ISWC, 2014.", "N. Aggarwal and P. Buitelaar. Wikipedia-based distributional semantics for entity relatedness. In 2014 AAAI Fall Symposium Series, 2014.", "R. Blanco, B. B. Cambazoglu, P. Mika, and N. Torzec. Entity recommendations in web search. In International Semantic Web Conference (2), pages 33--48, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742851"}, {"title": "ParaView Catalyst: Enabling In Situ Data Analysis and Visualization", "authors": ["Utkarsh Ayachit\n,", "Andrew Bauer\n,", "Berk Geveci\n,", "Patrick O'Leary\n,", "Kenneth Moreland\n,", "Nathan Fabian\n,", "Jeffrey Mauldin"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nComputer simulations are growing in sophistication and producing results of ever greater fidelity. This trend has been enabled by advances in numerical methods and increasing computing power. Yet these advances come with several costs including massive increases in data size, difficulties examining output data, challenges in configuring simulation runs, and difficulty debugging running codes. Interactive visualization tools, like ParaView, have been used for post-processing of simulation results. However, the increasing data sizes, and limited storage and bandwidth make high fidelity post-processing impractical. In situ analysis is recognized as one of the ways to address these challenges. In situ analysis moves some of the post-processing tasks in line with the simulation code thus short circuiting the need to communicate the data between the simulation and analysis via storage. ParaView Catalyst is a data processing and visualization library that enables in situ analysis and visualization. Built on and designed to interoperate with the standard visualization toolkit VTK and the ParaView application, Catalyst enables simulations to intelligently perform analysis, generate relevant output data, and visualize results concurrent with a running simulation. In this paper, we provide an overview of the Catalyst framework and some of the success stories.", "references": ["S. Ahern, A. Shoshani, K.-L. Ma, A. Choudhary, T. Critchlow, S. Klasky, V. Pascucci, J. Ahrens, E. Bethel, H. Childs, et al. Scientific discovery at the exascale. report from the doe ascr 2011 workshop on exascale data management. Analysis, and Visualization, 2, 2011.", "J. Ahrens, B. Geveci, and C. Law. ParaView: An End-User Tool for Large-Data Visualization. The Visualization Handbook, page 717, 2005.", "J. Ahrens, S. Jourdain, P. O'Leary, J. Patchett, D. H. Rogers, and M. Petersen. An image-based approach to extreme scale in situ visualization and analysis. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC '14, pages 424--434, Piscataway, NJ, USA, 2014. IEEE Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828624"}, {"title": "Dynamic Adjustment of Subtitles Using Audio Fingerprints", "authors": ["Lucas C. Villa Real\n,", "Rodrigo Laiola Guimarães\n,", "Priscilla Avegliano"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nAnyone who ever downloaded subtitle files from the Internet has faced problems synchronizing them with the associated media files. Even with the efforts of communities on reviewing user-contributed subtitles and with mechanisms in movie players to automate the discovery of subtitles for a given media, users still face lip synchronization issues. In this work we conduct a study on several subtitle files associated with popular movies and TV series and analyze their differences. Based on that, we propose a two-phase subtitle synchronization method that annotates subtitles with audio fingerprints, which serve as synchronization anchors to the media player. Preliminary results obtained with our prototype suggest that our technique is effective and has minimal impact on the extension of subtitle formats and on media playback performance.", "references": ["A. Brown, R. Jones, et al. Dynamic subtitles: the user experience. In Proceedings of the 2015 ACM International Conference on Interactive Experiences for TV and Online Video. ACM, 2015.", "D. C. Bulterman, A. Jansen, et al. An efficient, streamable text format for multimedia captions and subtitles. In Proceedings of the 2007 ACM symposium on Document engineering, pages 101--110. ACM, 2007.", "C. Concolato and J. Le Feuvre. Live http streaming of video and subtitles within a browser. In Proceedings of the 4th ACM Multimedia Systems Conference, pages 146--150. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806378"}, {"title": "Short Text Similarity with Word Embeddings", "authors": ["Tom Kenter\n,", "Maarten de Rijke"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nDetermining semantic similarity between texts is important in many tasks in information retrieval such as search, query suggestion, automatic summarization and image finding. Many approaches have been suggested, based on lexical matching, handcrafted patterns, syntactic parse trees, external sources of structured semantic knowledge and distributional semantics. However, lexical features, like string matching, do not capture semantic similarity beyond a trivial level. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains. Lastly, approaches depending on parse trees are restricted to syntactically well-formed texts, typically of one sentence in length.\nWe investigate whether determining short text similarity is possible using only semantic features---where by semantic we mean, pertaining to a representation of meaning---rather than relying on similarity in lexical or syntactic representations. We use word embeddings, vector representations of terms, computed from unlabelled data, that represent terms in a semantic space in which proximity of vectors can be interpreted as semantic similarity.\nWe propose to go from word-level to text-level semantics by combining insights from methods based on external sources of semantic knowledge with word embeddings. A novel feature of our approach is that an arbitrary number of word embedding sets can be incorporated. We derive multiple types of meta-features from the comparison of the word vectors for short text pairs, and from the vector means of their respective word embeddings. The features representing labelled short text pairs are used to train a supervised learning algorithm. We use the trained model at testing time to predict the semantic similarity of new, unlabelled pairs of short texts\nWe show on a publicly available evaluation set commonly used for the task of semantic similarity that our method outperforms baseline methods that work under the same conditions.", "references": ["E. Agirre, M. Diab, D. Cer, and A. Gonzalez-Agirre. Semeval-2012 task 6: A pilot on semantic textual similarity. In SemEval 2012, 2012.", "E. Agirre, D. Cer, M. Diab, A. Gonzalez-Agirre, and W. Guo. sem 2013 shared task: Semantic textual similarity, including a pilot on typed-similarity. In *SEM 2013, 2013.", "R. M. Aliguliyev. A new sentence similarity measure and sentence based extractive technique for automatic text summarization. Expert Systems with Applications, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806475"}, {"title": "Fast Distributed Correlation Discovery Over Streaming Time-Series Data", "authors": ["Tian Guo\n,", "Saket Sathe\n,", "Karl Aberer"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe dramatic rise of time-series data in a variety of contexts, such as social networks, mobile sensing, data centre monitoring, etc., has fuelled interest in obtaining real-time insights from such data using distributed stream processing systems. One such extremely valuable insight is the discovery of correlations in real-time from large-scale time-series data. A key challenge in discovering correlations is that the number of time-series pairs that have to be analyzed grows quadratically in the number of time-series, giving rise to a quadratic increase in both computation cost and communication cost between the cluster nodes in a distributed environment. To tackle the challenge, we propose a framework called AEGIS. AEGIS exploits well-established statistical properties to dramatically prune the number of time-series pairs that have to be evaluated for detecting interesting correlations. Our extensive experimental evaluations on real and synthetic datasets establish the efficacy of AEGIS over baselines.", "references": ["Tech. report -- http://infoscience.epfl.ch/record/210363.", "Storm. http://storm-project.net/.", "D. Abadi, D. Carney, U. Cetintemel, M. Cherniack, C. Convey, S. Lee, M. Stonebraker, N. Tatbul, and S. Zdonik. Aurora: A new model and architecture for data stream management. VLDB Journal, pages 120--139, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806440"}, {"title": "Fast in-memory transaction processing using RDMA and HTM", "authors": ["Xingda Wei\n,", "Jiaxin Shi\n,", "Yanzhe Chen\n,", "Rong Chen\n,", "Haibo Chen"], "publication": "SOSP '15: Proceedings of the 25th Symposium on Operating Systems Principles", "abstract": "ABSTRACT\nWe present DrTM, a fast in-memory transaction processing system that exploits advanced hardware features (i.e., RDMA and HTM) to improve latency and throughput by over one order of magnitude compared to state-of-the-art distributed transaction systems. The high performance of DrTM are enabled by mostly offloading concurrency control within a local machine into HTM and leveraging the strong consistency between RDMA and HTM to ensure serializability among concurrent transactions across machines. We further build an efficient hash table for DrTM by leveraging HTM and RDMA to simplify the design and notably improve the performance. We describe how DrTM supports common database features like read-only transactions and logging for durability. Evaluation using typical OLTP workloads including TPC-C and SmallBank show that DrTM scales well on a 6-node cluster and achieves over 5.52 and 138 million transactions per second for TPC-C and SmallBank Respectively. This number outperforms a state-of-the-art distributed transaction system (namely Calvin) by at least 17.9X for TPC-C.", "references": ["IEEE 1588 Precision Time Protocol (PTP) Version 2. http://sourceforge.net/p/ptpd/wiki/Home/.", "Aguilera, M. K., Merchant, A., Shah, M., Veitch, A., and Karamanolis, C. Sinfonia: A new paradigm for building scalable distributed systems. In Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles (2007), SOSP'07, ACM, pp. 159--174.", "Alomari, M., Cahill, M., Fekete, A., and Röhm, U. The cost of serializability on platforms that use snapshot isolation. In IEEE 24th International Conference on Data Engineering (2008), ICDE'08, IEEE, pp. 576--585."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815400.2815419"}, {"title": "Finding deep compiler bugs via guided stochastic program mutation", "authors": ["Vu Le\n,", "Chengnian Sun\n,", "Zhendong Su"], "publication": "OOPSLA 2015: Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "abstract": "ABSTRACT\nCompiler testing is important and challenging. Equivalence Modulo Inputs (EMI) is a recent promising approach for compiler validation. It is based on mutating the unexecuted statements of an existing program under some inputs to produce new equivalent test programs w.r.t. these inputs. Orion is a simple realization of EMI by only randomly deleting unexecuted statements. Despite its success in finding many bugs in production compilers, Orion’s effectiveness is still limited by its simple, blind mutation strategy. To more effectively realize EMI, this paper introduces a guided, advanced mutation strategy based on Bayesian optimization. Our goal is to generate diverse programs to more thoroughly exercise compilers. We achieve this with two techniques: (1) the support of both code deletions and insertions in the unexecuted regions, leading to a much larger test program space; and (2) the use of an objective function that promotes control-flow-diverse programs for guiding Markov Chain Monte Carlo (MCMC) optimization to explore the search space. Our technique helps discover deep bugs that require elaborate mutations. Our realization, Athena, targets C compilers. In 19 months, Athena has found 72 new bugs — many of which are deep and important bugs — in GCC and LLVM. Developers have confirmed all 72 bugs and fixed 68 of them.", "references": ["ACE. SuperTest compiler test and validation suite. URL http://www.ace.nl/compiler/supertest.html.", "C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan. An Introduction to MCMC for Machine Learning. Machine Learning, 50(1):5–43, Jan. 2003.", "A. Balestrat. CCG: A random C code generator. URL https://github.com/Merkil/ccg/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814270.2814319"}, {"title": "Towards web-based semantic enrichment of 3D insects", "authors": ["Stuart Anderson\n,", "Matt Adcock\n,", "Beth Mantle\n,", "John La Salle\n,", "Chuong Nguyen\n,", "David Lovell"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nNatural history collections are an invaluable resource housing a wealth of knowledge with a long tradition of contributing to a wide range of fields such as taxonomy, quarantine, conservation and climate change. It is recognized however [Smith and Blagoderov 2012] that such physical collections are often heavily underutilized as a result of the practical issues of accessibility. The digitization of these collections is a step towards removing these access issues, but other hurdles must be addressed before we truly unlock the potential of this knowledge.", "references": ["Jolley-Rogers, G., Yeates, D., Croft, J., et al. 2012. Ultra-small RFID p-Chips on the heads of entomological pins provide an automatic and durable means to track and label insect specimens. Zootaxa 3359, 31--42.", "Kim, M. H., Rushmeier, H., Ffrench, J., Passeri, I., and Tidmarsh, D. 2014. Hyper3D. Journal on Computing and Cultural Heritage 7, 3, 1--19.", "Mantle, B. L., La Salle, J., and Fisher, N. 2012. Whole-drawer imaging for digital management and curation of a large entomological collection. ZooKeys 209, 209, 147--63."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2778305"}, {"title": "Dynamic adaptive mesh streaming for real-time 3D teleimmersion", "authors": ["Simon Crowle\n,", "Alexandros Doumanoglou\n,", "Benjamin Poussard\n,", "Michael Boniface\n,", "Dimitrios Zarpalas\n,", "Petros Daras"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nRecent advances in full body 3D reconstruction methods have lead to the realisation of high quality, real-time, photo realistic capture of users in a range of tele-immersion (TI) contexts including gaming and mixed reality environments. The full body reconstruction (FBR) process is computationally expensive requiring comparatively high CPU, GPU and network resources in order to maintain a shared, virtual reality in which high quality 3D reproductions of users can be rendered in real-time. A significant optimisation of the delivery of FBR content has been achieved through the real-time compression and de-compression of 3D geometry and textures. Here we present a new, adaptive compression methodology that allows a TI system called 3D-LIVE to modify the quality and speed of a FBR TI pipeline based on the data carrying capability of the network. Our rule-based adaptation strategy uses network performance sampling processes and a configurable rule engine to dynamically alter the compression of FBR reconstruction on-the-fly. We demonstrate the efficacy of the approach with an experimental evaluation of system and conclude with a discussion of future directions for adaptive FBR compression.", "references": ["3D-LIVE. 3D-LIVE: 3D Living Interactions through Visual Environments. {Online} http://3dliveproject.eu/wp/.", "Alexiadis, D. S., Zarpalas, D., and Daras, P. 2013. Real-time, full 3-d reconstruction of moving foreground objects from multiple consumer depth cameras. IEEE Transactions on Multimedia 15, 2, 339--358.", "Alexiadis, D. S., Zarpalas, D., and Daras, P. 2013. Real-time, realistic full-body 3d reconstruction and texture mapping from multiple kinects. In 11th IEEE IVMSP Workshop: 3D Image/Video Technologies and Applications, Yonsei University, Seoul, Korea, 10-12 June."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2775296"}, {"title": "Who's Afraid of Itten: Using the Art Theory of Color Combination to Analyze Emotions in Abstract Paintings", "authors": ["Andreza Sartori\n,", "Dubravko Culibrk\n,", "Yan Yan\n,", "Nicu Sebe"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nColor plays an essential role in everyday life and is one of the most important visual cues in human perception. In abstract art, color is one of the essential means to convey the artist's intention and to affect the viewer emotionally. However, colors are rarely experienced in isolation, rather, they are usually presented together with other colors. In fact, the expressive properties of two-color combinations have been extensively studied by artists. It is intriguing to try to understand how color combinations in abstract paintings might affect the viewer emotionally, and to investigate if a computer algorithm can learn this mechanism.\nIn this work, we propose a novel computational approach able to analyze the color combinations in abstract paintings and use this information to infer whether a painting will evoke positive or negative emotions in an observer. We exploit art theory concepts to design our features and the learning algorithm. To make use of the color-group information, we propose inferring the emotions elicited by paintings based on the sparse group lasso approach. Our results show that a relative improvement of between 6% and 8% can be achieved in this way. Finally, as an application, we employ our method to generate Mondrian-like paintings and do a prospective user study to evaluate the ability of our method as an automatic tool for generating abstract paintings able to elicit positive and negative emotional responses in people.", "references": ["L. Dickerman, M. Affron, and M. of Modern Art. Inventing Abstraction, 1910--1925: How a Radical Idea Changed Modern Art. Museum of Modern Art (New York, N.Y.), 2012.", "G. Dorfles and A. Vettese. Arti visive. Protagonisti e movimenti. VOL.3A: Il Novecento. Atlas, 2001.", "P. F. Felzenszwalb and D. P. Huttenlocher. Efficient graph-based image segmentation. Int. J. Comput. Vision, 59(2):167--181, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806250"}, {"title": "Discussing a Recommendation System to Support Participation in the Democratic Citizen Community", "authors": ["Max Martins\n,", "Jivago Medeiros\n,", "Cristiano Maciel"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper proposes a recommendation system facing virtual communities seeking to analyze the proposal impacts presented in a dedicated virtual community for debate and discussion of matters of public interest. To conduct the evaluation, there was an experiment used the virtual community described after the implementation of the proposal. The analysis of data collected during the experiment showed relevant evidence related to implementation of the proposed.", "references": ["CGI.br (Comitê Gestor da Internet no Brasil). A evolução da internet no Brasil, 15 anos do CGI, ano 2, edição 03,2010. Disponivel em: ¿http://www.cgi.br/publicacoes/revista/edicao03/txt.htm¿. Acesso em: 16 nov. 2014, 16:55:12.", "BRAMBILLA, M. A; PRIMO, A. Software social e construção do conhecimento. In: XXVD Congresso Brasileiro de Ciências da Comunicação. 2004.", "GAMA, F. O que são as Comunidades Virtuais. Rio de Janeiro: Editora, 2012. Disponível em: ¿http://gamavirtual.ugf.br/cvn/oq_comunidade.php¿. Acesso em: 23 nov. 2014, 10:28:08."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814164"}, {"title": "Data partitioning strategies for graph workloads on heterogeneous clusters", "authors": ["Michael LeBeane\n,", "Shuang Song\n,", "Reena Panda\n,", "Jee Ho Ryoo\n,", "Lizy K. John"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nLarge scale graph analytics are an important class of problem in the modern data center. However, while data centers are trending towards a large number of heterogeneous processing nodes, graph analytics frameworks still operate under the assumption of uniform compute resources. In this paper, we develop heterogeneity-aware data ingress strategies for graph analytics workloads using the popular PowerGraph framework. We illustrate how simple estimates of relative node computational throughput can guide heterogeneity-aware data partitioning algorithms to provide balanced graph cutting decisions. Our work enhances five online data ingress strategies from a variety of sources to optimize application execution for throughput differences in heterogeneous data centers. The proposed partitioning algorithms improve the runtime of several popular machine learning and data mining applications by as much as a 65% and on average by 32% as compared to the default, balanced partitioning approaches.", "references": ["Amazon EC2. http://aws.amazon.com/ec2. Accessed: 04-16-2015.", "Apache hadoop. https://hadoop.apache.org/. Accessed: 08-11-2015.", "Ec2 network estimations. http://www.aerospike.com/blog/boosting-amazon-ec2-network-for-high-throughput. Accessed: 04-16-2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807632"}, {"title": "Big Data Text Summarization for Events: A Problem Based Learning Course", "authors": ["Tarek Kanan\n,", "Xuan Zhang\n,", "Mohamed Magdy\n,", "Edward Fox"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nProblem/project Based Learning (PBL) is a highly effective student-centered teaching method, where student teams learn by solving problems. This paper describes an instance of PBL applied to digital library education. We show the design, implementation, results, and partial evaluation of a Computational Linguistics course that provides students an opportunity to engage in active learning about adding value to digital libraries with large collections of text, i.e., one aspect of \"big data.\" Students are engaging in PBL with the semester long challenge of generating good English summaries of an event, given a large collection from our webpage archives. Six teams, each working with a different type of event, and applying three different summarization methods, learned how to generate good summaries; these have fair precision relative to the Wikipedia page that describes their event.", "references": ["Buck Institute for Education. Why Project Based Learning (PBL)? Retrieved January, 2015, from http://bie.org/", "Fox, E. A., Akbar, M., Abdelhamid, S. H. E. M., Elsherbiny, N. I., Farag, M. M. G., Jin, F., Leidig, J. P. and Neppali, S. T. Digital Libraries. In Computing Handbook, Third ed., vol. 2, Chapman & Hall/CRC Press, Taylor and Francis Group, 2014.", "Fox, E. A. and Leidig, J. P. Digital Library Applications: CBIR, Education, Social Networks, eScience/Simulation, and GIS. Morgan & Claypool Publishers, San Francisco, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756943"}, {"title": "Smith Search: Opinion-Based Restaurant Search Engine", "authors": ["Jaehoon Choi\n,", "Donghyeon Kim\n,", "Donghee Choi\n,", "Sangrak Lim\n,", "Seongsoon Kim\n,", "Jaewoo Kang\n,", "Youngjae Choi"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSearch engines have become an important decision-making tool today. Unfortunately, they still need to improve in answering complex queries. The answers to complex decision-making queries such as ``best burgers and fries'' and ``good restaurants for anniversary dinner,'' are often subjective. The most relevant answer to the query can be obtained by only collecting people's opinions about the query, which are expressed in various venues on the Web. Collected opinions are converted into a ``consensus'' list. All of this should be processed at query time, which is impossible under the current search paradigm. To address this problem, we introduce Smith, a novel opinion-based restaurant search engine. Smith actively processes opinions on the Web, blogs, review boards, and other forms of social media at index time, and produces consensus answers from opinions at query time. The Smith search app (iOS) is available for download at http://www.smithsearches.com/introduction/.", "references": ["J. Choi, D. Kim, S. Kim, J. Lee, S. Lim, S. Lee, and J. Kang. Consento: A new framework for opinion based entity search and summarization. In CIKM, 2012.", "K. Ganesan and C. Zhai. Opinion-based entity ranking. Information Retrieval, 15(2), 2012.", "E. Meij, K. Balog, and D. Odijk. Entity linking and retrieval for semantic search. In WSDM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742829"}, {"title": "CQADupStack: A Benchmark Data Set for Community Question-Answering Research", "authors": ["Doris Hoogeveen\n,", "Karin M. Verspoor\n,", "Timothy Baldwin"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nThis paper presents a benchmark dataset, CQADupStack, for use in community question-answering (cQA) research. It contains threads from twelve StackExchange subforums, annotated with duplicate question information. We provide pre-defined training and test splits, both for retrieval and classification experiments, to ensure maximum comparability between different studies using the set. Furthermore, it comes with a script to manipulate the data in various ways. We give an analysis of the data in the set, and report benchmark results on a duplicate question retrieval task using well established retrieval models.", "references": ["A. Bacchelli. Mining Challenge 2013: Stack Overflow. In The 10th Working Conference on Mining Software Repositories, page to appear, 2013.", "A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. Bridging the Lexical Chasm: Statistical Approaches to Answer-Finding. In Proceedings of the 23rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 192--199. ACM, 2000.", "D. Bernhard and I. Gurevych. Answering Learners' Questions by Retrieving Question Paraphrases from Social Q&A Sites. In Proceedings of the 3rd Workshop on Innovative Use of NLP for Building Educational Applications (BEA), pages 44--52. ACL, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838934"}, {"title": "Understanding Graph Structure of Wikipedia for Query Expansion", "authors": ["Joan Guisado-Gámez\n,", "Arnau Prat-Pérez"], "publication": "GRADES'15: Proceedings of the GRADES'15", "abstract": "ABSTRACT\nKnowledge bases are very good sources for knowledge extraction, the ability to create knowledge from structured and unstructured sources and use it to improve automatic processes as query expansion. However, extracting knowledge from unstructured sources is still an open challenge [9]. In this respect, understanding the structure of knowledge bases can provide significant benefits for the effectiveness of such purpose. In particular, Wikipedia has become a very popular knowledge base in the last years because it is a general encyclopedia that has a large amount of information and thus, covers a large amount of different topics. In this piece of work, we analyze how articles and categories of Wikipedia relate to each other and how these relationships can support a query expansion technique. In particular, we show that the structures in the form of dense cycles with a minimum amount of categories tend to identify the most relevant information.", "references": ["M. Almasri, C. Berrut, and J.P. Chevallet. Exploiting wikipedia structure for short query expansion in cultural heritage. In CORIA, pages 287--302, 2014.", "J. Arguello, J. Elsas, J. Callan, and J. Carbonell. Document representation and query expansion models for blog recommendation. In ICWSM, 2008.", "O. Egozi, S. Markovitch, and E. Gabrilovich. Concept-based information retrieval using explicit semantic analysis. TOIS, 29(2):8, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2764947.2764953"}, {"title": "Anytime Ranking for Impact-Ordered Indexes", "authors": ["Jimmy Lin\n,", "Andrew Trotman"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe ability for a ranking function to control its own execution time is useful for managing load, reigning in outliers, and adapting to different types of queries. We propose a simple yet effective anytime algorithm for impact-ordered indexes that builds on a score-at-a-time query evaluation strategy. In our approach, postings segments are processed in decreasing order of their impact scores, and the algorithm early terminates when a specified number of postings have been processed. With a simple linear model and a few training topics, we can determine this threshold given a time budget in milliseconds. Experiments on two web test collections show that our approach can accurately control query evaluation latency and that aggressive limits on execution time lead to minimal decreases in effectiveness.", "references": ["V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with effective early termination. SIGIR, 2001.", "V. N. Anh and A. Moffat. Pruned query evaluation using pre-computed impacts. SIGIR, 2006.", "V. N. Anh and A. Moffat. Inverted index compression using word-aligned binary codes. Software: Practice and Experience, 40(2):131--147, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809477"}, {"title": "A Semantic Hybrid Approach for Sound Recommendation", "authors": ["Vito Claudio Ostuni\n,", "Tommaso Di Noia\n,", "Eugenio Di Sciascio\n,", "Sergio Oramas\n,", "Xavier Serra"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this work we describe a hybrid recommendation approach for recommending sounds to users by exploiting and semantically enriching textual information such as tags and sounds descriptions. As a case study we used Freesound, a popular site for sharing sound samples which counts more than 4 million registered users. Tags and textual sound descriptions are exploited to extract and link entities to external ontologies such as WordNet and DBpedia. The enriched data are eventually merged with a domain specific tagging ontology to form a knowledge graph. Based on this latter, recommendations are then computed using a semantic version of the feature combination hybrid approach. An evaluation on historical data shows improvements with respect to state of the art collaborative algorithms.", "references": ["Robin Burke. Hybrid recommender systems: Survey and experiments. User Modeling and User-Adapted Interaction, 12(4):331--370, November 2002.", "Frederic Font and Sergio Oramas. Extending Tagging Ontologies with Domain Specific Knowledge. Interantional Semantic Web Conference (ISWC 2014), pages 1--4, 2014.", "Andrea Moro, Alessandro Raganato, and Roberto Navigli. Entity Linking meets Word Sense Disambiguation : a Unified Approach. Transactions of the Association for Computational Linguistics (TACL), 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742775"}, {"title": "A Cost-based Method for Location-Aware Publish/Subscribe Services", "authors": ["Minghe Yu\n,", "Guoliang Li\n,", "Jianhua Feng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nLocation-based services have attracted significant attentions from both industry and academia, thanks to modern smartphones and mobile Internet. To provide users with gratifications, location-aware publish/subscribe has been recently proposed, which delivers spatio-textual messages of publishers to subscribers whose registered spatio-textual subscriptions are relevant to the messages. Since there could be large numbers of subscriptions, it is necessary to devise an efficient location-aware publish/subscribe system to enable instant message filtering. To this end, in this paper we propose two novel indexing structures, mbrtrie and PKQ. Using the indexes, we devise two filtering algorithms to support fast message filtering. We analyze the complexities of the two filtering algorithms and develop a cost-based model to judiciously select the best filtering algorithm for different scenarios. The experimental results show that our method achieves high performance and significantly outperforms the baseline approaches", "references": ["G. Ausiello, A. D'Atri, and M. Protasi. Structure preserving reductions among convex optimization problems. J. Comput. Syst. Sci. , 21(1):136--153, 1980.", "X. Cao, G. Cong, and C. S. Jensen. Retrieving top-k prestige-based relevant spatial web objects. PVLDB, 3(1):373--384, 2010.", "L. Chen, G. Cong, and X. Cao. An efficient query indexing mechanism for filtering geo-textual data. In SIGMOD Conference, pages 749--760, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806427"}, {"title": "Personalized Semantic Ranking for Collaborative Recommendation", "authors": ["Song Xu\n,", "Shu Wu\n,", "Liang Wang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecently a ranking view of collaborative recommendation has received much attention in recommendation systems. Most of existing ranking approaches are based on pairwise assumption, i.e., everything that has not been selected is of less interest for a user. However it is usually not proper in many cases. To alleviate the limitation of this assumption, in this work, we present a unified framework, named Personalized Semantic Ranking (PSR). PSR models the personalized ranking and the user-generated content (UGC) simultaneously, and the semantic information extracted from UGC can make a remedy for the pairwise assumption. Moreover, utilizing the semantic information, PSR can capture the more subtle information of the user-item interaction and alleviate the overfitting problem caused by insufficient ratings. The learned topics in PSR can also serve as proper explanations for recommendation. Experimental results show that the proposed PSR yields significant improvements over the competitive compared methods on two typical datasets.", "references": ["D. Agarwal and B.-C. Chen. flda: Matrix factorization through latent dirichlet allocation. In WSDM, 2010.", "D. M. Blei, A. Y. Ng, and M. Jordan. Latent dirichlet allocation. JMLR, 2003.", "Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In ICDM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767772"}, {"title": "Modeling Information Diffusion in Social Media as Provenance with W3C PROV", "authors": ["Io Taxidou\n,", "Tom De Nies\n,", "Ruben Verborgh\n,", "Peter M. Fischer\n,", "Erik Mannens\n,", "Rik Van de Walle"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn recent years, research in information diffusion in social media has attracted a lot of attention, since the produced data is fast, massive and viral. Additionally, the provenance of such data is equally important because it helps to judge the relevance and trustworthiness of the information enclosed in the data. However, social media currently provide insufficient mechanisms for provenance, while models of information diffusion use their own concepts and notations, targeted to specific use cases. In this paper, we propose a model for information diffusion and provenance, based on the W3C PROV Data Model. The advantage is that PROV is a Web-native and interoperable format that allows easy publication of provenance data, and minimizes the integration effort among different systems making use of PROV.", "references": ["F. Abel, C. Hauff, G.-J. Houben, R. Stronkman, and K. Tao. Semantics+filtering+search= twitcident. Exploring information in social web streams. In HT, pages 285--294, 2012.", "E. Bakshy, J. M. Hofman, W. A. Mason, and D. J. Watts. Everyone's an influencer: quantifying influence on twitter. In WSDM, pages 65--74, 2011.", "R. A. Banos, J. Borge-Holthoefer, and Y. Moreno. The role of hidden influentials in the diffusion of online information cascades. EPJ Data Science, 2(1):1--16, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742475"}, {"title": "Identifying transitivity threats in social networks", "authors": ["Sorren Hanvey\n,", "Néstor Cataño"], "publication": "TELERISE '15: Proceedings of the First International Workshop on TEchnical and LEgal aspects of data pRIvacy", "abstract": "ABSTRACT\nTransitivity threats refer to the unintended disclosure of information to unintended recipients as a consequence of an unrelated action. In the context of social networking sites, transitivity threats refer to potential privacy policy breaches that stem from the automated transmission of data/content due to user actions within the social network. For example, commenting on some content within the social network makes the commented content visible to the recipients of the comment, thereby breaching the privacy policy under which the original/commented content was shared. This paper presents a novel approach for modelling and comparing social network privacy policies to deal with transitivity threats. Our approach differs from existing approaches in its use of formal methods techniques to compare social network privacy policies. This work builds on a predicate calculus definition for social networking, modelling social network content, people, friendship relations, and privacy policies as access permissions to content. We have implemented our approach as a tool called Poporo. The tool extends on a previous version of the Poporo tool that checked a third party application's compliance with system invariants. We validate our approach by using Poporo on several examples.", "references": ["R. Gross and A. Acquisti, \"Information revelation and privacy in online social networks,\" in WPES, 2005, pp. 71--80.", "J. M. Wing and M. C. Tschantz, \"Formal methods for privacy,\" in Formal Methods, ser. Lecture Notes in Computer Science, 2009.", "E. Clarke and J. Wing, \"Formal methods: State of the art and future directions,\" ACM Computing Surveys, vol. 28, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2821464.2821470"}, {"title": "An Analysis of Theories of Search and Search Behavior", "authors": ["Leif Azzopardi\n,", "Guido Zuccon"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nTheories of search and search behavior can be used to glean insights and generate hypotheses about how people interact with retrieval systems. This paper examines three such theories, the long standing Information Foraging Theory, along with the more recently proposed Search Economic Theory and the Interactive Probability Ranking Principle. Our goal is to develop a model for ad-hoc topic retrieval using each approach, all within a common framework, in order to (1) determine what predictions each approach makes about search behavior, and (2) show the relationships, equivalences and differences between the approaches. While each approach takes a different perspective on modeling searcher interactions, we show that under certain assumptions, they lead to similar hypotheses regarding search behavior. Moreover, we show that the models are complementary to each other, but operate at different levels (i.e., sessions, patches and situations). We further show how the differences between the approaches lead to new insights into the theories and new models. This contribution will not only lead to further theoretical developments, but also enables practitioners to employ one of the three equivalent models depending on the data available.", "references": ["C. W. Axelrod. The economic evaluation of information storage and retrieval systems. Information Processing & Management, 13(2):117--124, 1977.", "L. Azzopardi. The economics in interactive information retrieval. In Proc. of the 34th ACM SIGIR conference, pages 15--24, 2011.", "L. Azzopardi. Economic models of search. In Proceedings of the 18th Australasian Document Computing Symposium, ADCS '13, pages 1--1, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809447"}, {"title": "Towards Semantic Retrieval of Hashtags in Microblogs", "authors": ["Piyush Bansal\n,", "Somay Jain\n,", "Vasudeva Varma"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOn various microblogging platforms like Twitter, the users post short text messages ranging from news and information to thoughts and daily chatter. These messages often contain keywords called Hashtags, which are semantico-syntactic constructs that enable topical classification of the microblog posts. In this poster, we propose and evaluate a novel method of semantic enrichment of microblogs for a particular type of entity search -- retrieving a ranked list of the top-k hashtags relevant to a user's query Q. Such a list can help the users track posts of their general interest. We show that our technique significantly improved microblog retrieval as well. We tested our approach on the publicly available Stanford sentiment analysis tweet corpus. We observed an improvement of more than 10% in NDCG for microblog retrieval task, and around 11% in mean average precision for hashtag retrieval task.", "references": ["P. Bansal, R. Bansal, and V. Varma. Towards deep semantic analysis of hashtags. In Advances in Information Retrieval. Springer, 2015.", "B. Croft, D. Metzler, and T. Strohman. Search Engines: Information Retrieval in Practice. Addison-Wesley Publishing Company, 2009.", "M. Efron. Hashtag retrieval in a microblogging environment. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742717"}, {"title": "Improving Accessibility of Archived Raster Dictionaries of Complex Script Languages", "authors": ["Sawood Alam\n,", "Fateh ud din B. Mehmood\n,", "Michael L. Nelson"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWe propose an approach to index raster images of dictionary pages which in turn would require very little manual effort to enable direct access to the appropriate pages of the dictionary for lookup. Accessibility is further improved by feedback and crowdsourcing that enables highlighting of the specific location on the page where the lookup word is found, annotation, digitization, and fielded searching. This approach is equally applicable on simple scripts as well as complex writing systems. Using our proposed approach, we have built a Web application called \"Dictionary Explorer\" which supports word indexes in various languages and every language can have multiple dictionaries associated with it. Word lookup gives direct access to appropriate pages of all the dictionaries of that language simultaneously. The application has exploration features like searching, pagination, and navigating the word index through a tree-like interface. The application also supports feedback, annotation, and digitization features. Apart from the scanned images, \"Dictionary Explorer\" aggregates results from various sources and user contributions in Unicode. We have evaluated the time required for indexing dictionaries of different sizes and complexities in the Urdu language and examined various trade-offs in our implementation. Using our approach, a single person can make a dictionary of 1,000 pages searchable in less than an hour.", "references": ["ABBYY. ABBYY FineReader 11: Recognition Languages. http://finereader.abbyy.com/recognition_languages/, 2014.", "ABBYY. ABBYY FineReader for Personal Use. http://finereader.abbyy.com/, 2014.", "S. Abney and S. Bird. The Human Language Project: Building a Universal Corpus of the World's Languages. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 88--97, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756926"}, {"title": "Who Will You \"@\"?", "authors": ["Yeyun Gong\n,", "Qi Zhang\n,", "Xuyang Sun\n,", "Xuanjing Huang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn Twitter-like social networking services, people can use the \"@\" symbol to mention other users in tweets and send them a message or link to their profiles. In recent years, social media services are rapidly growing with thousands of millions of users participating in them every day. When the \"@\" symbol is entered, there should be an automatic suggestion function which recommends a small list of candidates in order to help users to easily identify and input usernames. In this paper, we present our work on building a recommendation system for the mention function in microblogging services. The recommendation strategy we used takes into consideration not only content of the microblog but also histories of candidate users. To better handle these textual information, we propose a novel method that extends the translation-based model. Experimental results on the dataset we collected from a real world microblogging service demonstrate that the proposed method outperforms state-of-the-art approaches.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "P. F. Brown, V. J. D. Pietra, S. A. D. Pietra, and R. L. Mercer. The mathematics of statistical machine translation: Parameter estimation. Computational linguistics, 1993.", "J. Bu, S. Tan, C. Chen, C. Wang, H. Wu, L. Zhang, and X. He. Music recommendation by unified hypergraph: combining social media information and music content. In Proceedings of MM '10, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806458"}, {"title": "A General Architecture for an Emotion-aware Content-based Recommender System", "authors": ["Fedelucio Narducci\n,", "Marco de Gemmis\n,", "Pasquale Lops"], "publication": "EMPIRE '15: Proceedings of the 3rd Workshop on Emotions and Personality in Personalized Systems 2015", "abstract": "ABSTRACT\nEmotions play a crucial role in the decision making process. Frequently, choices are strongly influenced by the mood of the moment, and the same person could take different decisions at different time on the same topic. Recommender systems, that are definitively recognized as tools for supporting the decision making process, demonstrated to be more accurate exploiting emotive labels in several work. For this reason a large number of researchers are focusing their attention on the analysis of the emotions by exploiting data that users daily disseminate on the Web (e.g.: Social Networks, Blogs, Forums, etc.). In this paper we propose a general architecture for implementing an emotion-aware content-based recommender system. Furthermore, we developed a web service that researchers can freely exploit for their own implementations. We carried out a user study on the domain of music recommendation, particularly influenced by the user emotion, and results are very promising.", "references": ["G. L. Clore, N. Schwarz, and M. Conway, \"Affective causes and consequences of social information processing,\" Handbook of social cognition, vol. 1, pp. 323--417, 1994.", "A. Bechara, H. Damasio, and A. R. Damasio, \"Emotion, decision making and the orbitofrontal cortex,\" Cerebral cortex, vol. 10, no. 3, pp. 295--307, 2000.", "A. Bechara, \"Risky business: emotion, decision-making, and addiction,\" Journal of Gambling Studies, vol. 19, no. 1, pp. 23--51, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809643.2809648"}, {"title": "Intensional data on the web", "authors": ["Antoine Amarilli\n,", "Silviu Maniu\n,", "Pierre Senellart"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nWe call data intensional when it is not directly available, but must be accessed through a costly interface. Intensional data naturally arises in a number of Web data management scenarios, such as Web crawling or ontology-based data access. Such scenarios require us to model an uncertain view of the world, for which, given a query, we must answer the question \"What is the best thing to do next?\" Once data has been retrieved, the knowledge of the world is revised, and the whole process is repeated, until enough knowledge about the world has been obtained for the particular application considered. In this article, we give an overview of the steps underlying all intensional data management scenarios, and illustrate them on three concrete applications: focused crawling, online influence maximization in social networks, and mining crowdsourced data.", "references": ["Amarilli, A., Amsterdamer, Y., and Milo, T. 2014. Uncertainty in crowd data sourcing under structural constraints. In UnCrowd.", "Amsterdamer, Y., Grossman, Y., Milo, T., and Senellart, P. 2013a. Crowd miner: Mining association rules from the crowd. In VLDB. Demonstration.", "Amsterdamer, Y., Grossman, Y., Milo, T., and Senellart, P. 2013b. Crowd mining. In SIGMOD."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808000.2808004"}, {"title": "Differences in Eye-Tracking Measures Between Visits and Revisits to Relevant and Irrelevant Web Pages", "authors": ["Jacek Gwizdka\n,", "Yinglong Zhang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis short paper presents initial results from a project, in which we investigated differences in how users view relevant and irrelevant Web pages on their visits and revisits. The users' viewing of Web pages was characterized by eye-tracking measures, with a particular attention paid to changes in pupil size. The data was collected in a lab-based experiment, in which users (N=32) conducted assigned information search tasks on Wikipedia. We performed non-parametric tests of significance as well as classification. Our findings demonstrate differences in eye-tracking measures on visits and revisits to relevant and irrelevant pages and thus indicate a feasibility of predicting perceived Web document relevance from eye-tracking data. In particular, relative changes in pupil size differed significantly in almost all conditions. Our work extends results from previous studies to more realistic search scenarios and to Web page visits and revisits.", "references": ["Azzopardi, L. 2014. Modelling Interaction with Economic Models of Search. Proceedings of the 37th International ACM SIGIR Conference on Research & Development in Information Retrieval (New York, NY, USA, 2014), 3--12.", "Bailey, E. and Kelly, D. 2011. Is amount of effort a better predictor of search success than use of specific search tactics? Proceedings of the American Society for Information Science and Technology. 48, 1 (2011), 1--10.", "Borlund, P. 2003. The concept of relevance in IR. Journal of the American Society for Information Science and Technology. 54, 10 (2003), 913--925."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767795"}, {"title": "A GPU implementation of an explicit compact FDTD algorithm with a digital impedance filter for room acoustics applications", "authors": ["Carlos Spa\n,", "Antón Rey\n,", "Erwin Hernández"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nIn recent years, computational engineering has undergone great changes due to the development of the graphics processing unit (GPU) technology. For example, in room acoustics, the wave-based methods, that formerly were considered too expensive for 3-D impulse response simulations, are now chosen to exploit the parallel nature of GPU devices considerably reducing the execution time of the simulations. There exist contributions related to this topic that have explored the performance of different GPU algorithms; however, the computational analysis of a general explicit model that incorporates algorithms with different neighboring orders and a general frequency dependent impedance boundary model has not been properly developed. In this paper, we present a GPU implementation of a complete room acoustic model based on a family of explicit finite-difference time-domain (FDTD) algorithms. We first develop a strategy for implementing a frequency independent (FI) impedance model which is free from thread divergences and then, we extend the model adding a digital impedance filter (DIF) boundary subroutine able to compute the acoustic pressure of different nodes such as corners or edges without an additional performance penalty. Both implementations are validated and deeply analyzed by performing different 3-D numerical experiments. Finally, we define a performance metric which is able to objectively measure the computing throughput of a FDTD implementation using a simple number. The robustness of this metric allows us to compare algorithms even if these have been run in different GPU cards or have been formulated with other explicit models.", "references": ["H. Kutruff, Room Acoustics, 4th ed. Abingdon, U.K.: Spon, 2000.", "D. Botteldooren, \"Finite-difference time-domain simulation of low-frequency room acoustic problems,\" J. Acoust. Soc. Amer., vol. 98, pp. 3302-3308, 1995.", "L. Savioja, T. J. Rinne, and T. Takala, \"Simulation of room acoustics with a 3-D finite difference mesh,\" in Dins Proc. Int. Computer Music Conf., Aarhus, Denmark, 1994, pp. 463-466."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2015.2434212"}, {"title": "Mapping Temporal Horizons: Analysis of Collective Future and Past related Attention in Twitter", "authors": ["Adam Jatowt\n,", "Émilien Antoine\n,", "Yukiko Kawai\n,", "Toyokazu Akiyama"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMicroblogging platforms such as Twitter have recently received much attention as great sources for live web sensing, real-time event detection and opinion analysis. Previous works usually assumed that tweets mainly describe \"what's happening now\". However, a large portion of tweets contains time expressions that refer to time frames within the past or the future. Such messages often reflect expectations or memories of social media users. In this work we investigate how microblogging users collectively refer to time. In particular, we analyze half a year long portion of Japanese and four months long collection of US tweets and we quantify collective temporal attention of users as well as other related temporal characteristics. This kind of knowledge is helpful in the context of growing interest for detection and prediction of important events within social media. The exploratory analysis we perform is possible thanks to the development of visual analytics framework for robust overview and easy detection of various regularities in the past and future-oriented thinking of Twitter users. We believe that the visualizations we provide and the findings we outline can be also valuable for sociologists and computer scientists to test and refine their models about time in natural language.", "references": ["Fabian Abel, Claudia Hauff, Geert-Jan Houben, Richard Stronkman, and Ke Tao. \"Twitcident: Fighting Fire with Information from Social Web Streams\". In: WWW Companion. 2012.", "Omar Alonso, Ricardo Baeza-yates, Jannik Strötgen, and Michael Gertz. \"Temporal Information Retrieval: Challenges and Opportunities\". In: TempWeb. 2011.", "Sebastien Ardon, Amitabha Bagchi, Anirban Mahanti, Amit Ruhela, Aaditeshwar Seth, Rudra Mohan Tripathy, and Sipat Triukose. \"Spatio-temporal and Events Based Analysis of Topic Popularity in Twitter\". In: CIKM. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741632"}, {"title": "Parallel AP Clustering and Re-ranking for Automatic Image-Text Alignment and Large-Scale Web Image Search", "authors": ["Yanyun Qu\n,", "Baopeng Zhang\n,", "Jianping Fan"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper, an automatic image-text alignment algorithm is developed for achieving more accurate indexing and retrieval of large-scale web images. First, large-scale web pages are crawled, where the informative images and their most relevant auxiliary text blocks are extracted. Second, parallel image clustering is performed to partition large-scale informative web images into a large number of clusters. By grouping the visually-similar (near-duplicate) web images into the same cluster, our parallel image clustering algorithm can significantly reduce the huge uncertainty on the relatedness between the web images and their auxiliary text terms, which can provide a good starting point for supporting automatic image-text alignment. Finally, a relevance re-ranking algorithm is developed to identify the most relevant visual text terms for the visually-similar web images in the same cluster. Our experiments on large-scale web images have obtained very positive results.", "references": ["S. Feng, V. Lavrenko, R. Manmatha, \"Multiple Bernoulli relevance models for image and video annotation\", ACM SIGIR, 2004.", "T. L. Berg, A. C. Berg, J. Edwards, D. A. Forsyth, \"Who's in the picture\", NIPS, 2004.", "N. Zhou, J. Fan, \"Automatic image-text alignment for large-scale web image indexing and retrieval\", Pattern Recognition, vol. 48, no. 1, pp. 205--219, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749294"}, {"title": "On the cost of mining very large open source repositories", "authors": ["Sean Banerjee\n,", "Bojan Cukic"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nOpen source bug tracking systems provide a rich information suite that is actively used by software engineering researchers to design solutions to triaging, duplicate classification and developer assignment problems. Today, open repositories often contain in excess of 100,000 reports, and in cases of RedHat and Mozilla, over a million. Obtaining and analyzing the contents of such datasets are both time and resource consuming. By summarizing the related work we demonstrate that researchers often focused on smaller subsets of the data, and seldom embrace the \"big-dataism\". With the emergence of cloud based computation systems such as Amazon EC2, one expects it to be easier to perform large scale analyses. However, our detailed time and cost analysis indicates that significant challenges still remain. Acquiring the open source data can be time intensive, and prone to being misinterpreted as Denial of Service attacks. Generating similarity scores for all prior reports, for example, is a polynomial time problem. In this paper, we present actual costs that we incurred when analyzing the complete repositories from Eclipse, Firefox and Open Office. In our approach, we relied on computing clusters to process the data in an attempt to reduce the cost of analyzing large datasets on the cloud. We present estimated costs for a researcher attempting to analyze complete datasets from Eclipse, Mozilla, Novell and RedHat using the best possible resources. In an ideal situation, with no bottlenecks, a researcher investing just over $40,000 and 2 weeks of non stop computing time would be able to measure similarity of problem reports within all four datasets.", "references": ["Hiew, Lyndon. \"Assisted detection of duplicate bug reports.\" MS diss., The University Of British Columbia, 2006.", "Wang, Xiaoyin, Lu Zhang, Tao Xie, John Anvik, and Jiasu Sun. \"An approach to detecting duplicate bug reports using natural language and execution information.\" In Proceedings of the 30th international conference on Software engineering, pp. 461--470. ACM, 2008.", "Jalbert, Nicholas, and Westley Weimer. \"Automated duplicate detection for bug tracking systems.\" In Dependable Systems and Networks With FTCS and DCC, 2008. DSN 2008. IEEE International Conference on, pp. 52--61. IEEE, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819301"}, {"title": "SINGA: Putting Deep Learning in the Hands of Multimedia Users", "authors": ["Wei Wang\n,", "Gang Chen\n,", "Anh Tien Tuan Dinh\n,", "Jinyang Gao\n,", "Beng Chin Ooi\n,", "Kian-Lee Tan\n,", "Sheng Wang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nRecently, deep learning techniques have enjoyed success in various multimedia applications, such as image classification and multi-modal data analysis. Two key factors behind deep learning's remarkable achievement are the immense computing power and the availability of massive training datasets, which enable us to train large models to capture complex regularities of the data. There are two challenges to overcome before deep learning can be widely adopted in multimedia and other applications. One is usability, namely the implementation of different models and training algorithms must be done by non-experts without much effort. The other is scalability, that is the deep learning system must be able to provision for a huge demand of computing resources for training large models with massive datasets. To address these two challenges, in this paper, we design a distributed deep learning platform called SINGA which has an intuitive programming model and good scalability. Our experience with developing and training deep learning models for real-life multimedia applications in SINGA shows that the platform is both usable and scalable.", "references": ["T. Chilimbi, Y. Suzue, J. Apacible, and K. Kalyanaraman. Project adam: Building an efficient and scalable deep learning training system. In OSDI, pages 571--582. USENIX Association, Oct. 2014.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. NUS-WIDE: A real-world web image database from National University of Singapore. In CIVR'09, July 8--10, 2009.", "D. C. Ciresan, U. Meier, L. M. Gambardella, and J. Schmidhuber. Deep big simple neural nets excel on handwritten digit recognition. CoRR, abs/1003.0358, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806232"}, {"title": "Co-clustering Document-term Matrices by Direct Maximization of Graph Modularity", "authors": ["Melissa Ailem\n,", "François Role\n,", "Mohamed Nadif"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe present Coclus, a novel diagonal co-clustering algorithm which is able to effectively co-cluster binary or contingency matrices by directly maximizing an adapted version of the modularity measure traditionally used for networks. While some effective co-clustering algorithms already exist that use network-related measures (normalized cut, modularity), they do so by using spectral relaxations of the discrete optimization problems. In contrast, Coclus allows to get even better co-clusters by directly maximizing modularity using an iterative alternating optimization procedure. Extensive comparative experiments performed on various document-term datasets demonstrate that our algorithm is very effective, stable and outperforms other co-clustering algorithms.", "references": ["I. Dhillon. Co-clustering documents and words using bipartite spectral graph partitioning. KDD'01, pages 269--274, 2001.", "G. Govaert and M. Nadif. Block clustering with bernoulli mixture models: Comparison of different approaches. Computational Statistics & Data Analysis, 52:3233--3245, 2008.", "G. Govaert and M. Nadif. Co-Clustering: Models, Algorithms and Applications. Wiley. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806639"}, {"title": "An efficient search algorithm for finding genomic-range overlaps based on the maximum range length", "authors": ["Ho-Sik Seok\n,", "Taemin Song\n,", "Sek Won Kong\n,", "Kyu-Baek Hwang"], "publication": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "abstract": "Abstract\nEfficient search algorithms for finding genomic-range overlaps are essential for various bioinformatics applications. A majority of fast algorithms for searching the overlaps between a query range (e.g., a genomic variant) and a set of N reference ranges (e.g., exons) has time complexity of O(k + logN), where k denotes a term related to the length and location of the reference ranges. Here, we present a simple but efficient algorithm that reduces k, based on the maximum reference range length. Specifically, for a given query range and the maximum reference range length, the proposed method divides the reference range set into three subsets: always, potentially, and never overlapping. Therefore, search effort can be reduced by excluding never overlapping subset. We demonstrate that the running time of the proposed algorithm is proportional to potentially overlapping subset size, that is proportional to the maximum reference range length if all the other conditions are the same. Moreover, an implementation of our algorithm was 13.8 to 30.0 percent faster than one of the fastest range search methods available when tested on various genomic-range data sets. The proposed algorithm has been incorporated into a disease-linked variant prioritization pipeline for WGS (http://gnome.tchlab.org) and its implementation is available at http://ml.ssu.ac.kr/gSearch.", "references": ["I. H. Lee, K. Lee, M. Hsing, Y. Choe, J. H. Park, S. H. Kim, J. M. Bohn, M. B. Neu, K. B. Hwang, R. C. Green, I. S. Kohane, and S. W. Kong, \"Prioritizing disease-linked variants, genes, and pathways with an interactive whole-genome analysis pipeline,\" Human Mutation, vol. 35, no. 5, pp. 537--547, May 2014.", "K. Wang, M. Li, and H. Hakonarson, \"ANNOVAR: Functional annotation of genetic variants from next-generation sequencing data,\" Nucleic Acids Res., vol. 38, p. e164, 2010.", "M. Yandell, C. Huff, H. Hu, M. Singleton, B. Moore, J. Xing, L. B. Jorde, and M. G. Reese, \"A probabilistic disease-gene finder for personal genomes,\" Genome Res., vol. 21, no. 9, pp. 1529--1542, Sep. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TCBB.2014.2369042"}, {"title": "Set Cover at Web Scale", "authors": ["Stergios Stergiou\n,", "Kostas Tsioutsiouliklis"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThe classic Set Cover problem requires selecting a minimum size subset A ⊆ F from a family of finite subsets F Of U such that the elements covered by A are the ones covered by F. It naturally occurs in many settings in web search, web mining and web advertising. The greedy algorithm that iteratively selects a set in F that covers the most uncovered elements, yields an optimum (1+ln |U|)-approximation but is inherently sequential. In this work we give the first MapReduce Set Cover algorithm that scales to problem sizes of ∼ 1 trillion elements and runs in logp Δ iterations for a nearly optimum approximation ratio of p ln Δ, where Δ is the cardinality of the largest set in F\nA web crawler is a system for bulk downloading of web pages. Given a set of seed URLs, the crawler downloads and extracts the hyperlinks embedded in them and schedules the crawling of the pages addressed by those hyperlinks for a subsequent iteration. While the average page out-degree is ∼ 50, the crawled corpus grows at a much smaller rate, implying a significant outlink overlap. Using our MapReduce Set Cover heuristic as a building block, we present the first large-scale seed generation algorithm that scales to ∼ 20 billion nodes and discovers new pages at a rate ∼ 4x faster than that obtained by prior art heuristics.", "references": ["R. M. Karp, \"Reducibility Among Combinatorial Problems,\" Complexity of Computer Computations, pp. 85--103, 1972.", "D. S. Johnson, \"Approximation algorithms for combinatorial problems,\" Journal of Computer and System Sciences, vol. 9, no. 3, pp. 256--278, 1974.", "U. Feige, \"A Threshold of In n for Approximating Set Cover,\" J. ACM, vol. 45, no. 4, pp. 634--652, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783315"}, {"title": "More Accurate Question Answering on Freebase", "authors": ["Hannah Bast\n,", "Elmar Haussmann"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nReal-world factoid or list questions often have a simple structure, yet are hard to match to facts in a given knowledge base due to high representational and linguistic variability. For example, to answer \"who is the ceo of apple\" on Freebase requires a match to an abstract \"leadership\" entity with three relations \"role\", \"organization\" and \"person\", and two other entities \"apple inc\" and \"managing director\". Recent years have seen a surge of research activity on learning-based solutions for this method. We further advance the state of the art by adopting learning-to-rank methodology and by fully addressing the inherent entity recognition problem, which was neglected in recent works.\nWe evaluate our system, called Aqqu, on two standard benchmarks, Free917 and WebQuestions, improving the previous best result for each benchmark considerably. These two benchmarks exhibit quite different challenges, and many of the existing approaches were evaluated (and work well) only for one of them. We also consider efficiency aspects and take care that all questions can be answered interactively (that is, within a second). Materials for full reproducibility are available on our website: http://ad.informatik.uni-freiburg.de/publications.", "references": ["H. Bast, F. Bäurle, B. Buchhold, and E. Haussmann. Broccoli: Semantic full-text search at your fingertips. CoRR, abs/1207.2615, 2012.", "J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic Parsing on Freebase from Question-Answer Pairs. In EMNLP, pages 1533--1544, 2013.", "J. Berant and P. Liang. Semantic Parsing via Paraphrasing. In ACL, pages 1415--1425, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806472"}, {"title": "Bayesian Ranker Comparison Based on Historical User Interactions", "authors": ["Artem Grotov\n,", "Shimon Whiteson\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe address the problem of how to safely compare rankers for information retrieval. In particular, we consider how to control the risks associated with switching from an existing production ranker to a new candidate ranker. Whereas existing online comparison methods require showing potentially suboptimal result lists to users during the comparison process, which can lead to user frustration and abandonment, our approach only requires user interaction data generated through the natural use of the production ranker. Specifically, we propose a Bayesian approach for (1) comparing the production ranker to candidate rankers and (2) estimating the confidence of this comparison. The comparison of rankers is performed using click model-based information retrieval metrics, while the confidence of the comparison is derived from Bayesian estimates of uncertainty in the underlying click model. These confidence estimates are then used to determine whether a risk-averse decision criterion for switching to the candidate ranker has been satisfied. Experimental results on several learning to rank datasets and on a click log show that the proposed approach outperforms an existing ranker comparison method that does not take uncertainty into account.", "references": ["C. M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.", "B. Carterette. System effectiveness, user models, and user utility: a conceptual framework for investigation. In SIGIR '11, pages 903--912. ACM, 2011.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In WWW '09, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767730"}, {"title": "TouRS'15: Workshop on Tourism Recommender Systems", "authors": ["Antonio Moreno\n,", "Laura Sebastiá\n,", "Pieter Vansteenwegen"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nTourism has been one of the most prominents fields of application of recommender systems in the last ten years.This summary gives an overview of the latest advances in the area, which have been presented in the RecSys 2015 workshop on Tourism Recommender Systems.", "references": ["Ardisono, L., Kuflik, T. and Petrelli, D. 2011. Personalization in cultural heritage: the road travelled and the one ahead. User Modeling and User-Adapted Interaction 22, 1--27.", "Borràs, J., Moreno, A. and Valls, A. 2014. Intelligent tourism recommender systems: A survey. Expert Systems with Applications 41(16), 7370--7389.", "Castro, J., Quesada, F.J., Palomares, I. and Martínez, L. 2015. A consensus-driven group recommender system. International Journal of Intelligent Systems 30 (8), 887--906."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798713"}, {"title": "Restaurant search with predictive multispace queries", "authors": ["Alexei Yatskov\n,", "Yasushi Kiyoki"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThis paper describes a web-based search application used for locating restaurants in a multidimensional content space via interactive space visualization. The primary goal of our research is to reduce the cognitive complexity of query selection, as well as to help the user avoid one of the common pitfalls of traditional search mechanisms: retrieving too many or too few results. Our method approaches this problem by continuously staying one step ahead of the user, constructing a graphical output to summarize how further query adjustments will impact subsequent search results. In actively precomputing queries ahead of the user we help them avoid the trial-and-error search process often associated with trying to find something in an unfamiliar, opaque database. We combine our visual search method with a profile-based knowledge system which helps users find restaurants accessed by people with similar interests.", "references": ["G. Grinstein, S. Laskowski, and A. Inselberg. Key problems and thorny issues in multidimensional visualization. In Proceedings of the Conference on Visualization '98, VIS '98, pages 505--506, Los Alamitos, CA, USA, 1998. IEEE Computer Society Press.", "J. K. Hall and Y. Kiyoki. Identifying and propagating contextually appropriate deep-topics amongst collaborating web-users. In EJC, pages 146--157, 2013.", "D. A. Keim, M. Ankerst, and H.-P. Kriegel. Recursive pattern: A technique for visualizing very large amounts of data. In Proceedings of the 6th Conference on Visualization '95, VIS '95, pages 279--, Washington, DC, USA, 1995. IEEE Computer Society."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837193"}, {"title": "Finding Answers in Web Search", "authors": ["Evi Yulianti"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThere are many informational queries that could be answered with a text passage, thereby not requiring the searcher to access the full web document. When building manual annotations of answer passages for TREC queries, Keikha et al. [6] confirmed that many such queries can be answered with just passages. By presenting the answers directly in the search result page, user information needs will be addressed more rapidly so that reduces user interaction (click) with the search result page [3] and gives a significant positive effect on user satisfaction [2, 7]. In the context of general web search, the problem of finding answer passages has not been explored extensively. Retrieving relevant passages has been studied in TREC HARD track [1] and in INEX [5], but relevant passages are not required to contain answers. One of the tasks in the TREC genomics track [4] was to find answer passages on biomedical literature. Previous work has shown that current passage retrieval methods that focus on topical relevance are not effective at finding answers [6]. Therefore, more knowledge is required to identify answers in a document. Bernstein et al. [2] has studied an approach to extract inline direct answers for search result using paid crowdsourcing service. Such an approach, however, is expensive and not practical to be applied for all possible information needs. A fully automatic process in finding answers remains a research challenge.\nThe aim of this thesis is to find passages in the documents that contain answers to a user's query. In this research, we proposed to use a summarization technique through taking advantage of Community Question Answering (CQA) content. In our previous work, we have shown the benefit of using social media to generate more accurate summaries of web documents [8], but this was not designed to present answer in the summary. With the high volume of questions and answers posted in CQA, we believe that there are many questions that have been previously asked in CQA that are the same as or related to actual web queries, for which their best answers can guide us to extract answers in the document. As an initial work, we proposed using term distributions extracted from best answers for top matching questions in one of leading CQA sites, Yahoo! Answers (Y!A), for answer summaries generation. An experiment was done by comparing our summaries with reference answers built in previous work [6], finding some level of success. A manuscript is prepared for this result.\nNext, as an extension of our work above, we were interested to see whether the documents that have better quality answer summaries should be ranked higher in the result list. A set of features are derived from answer summaries to re-rank documents in the result list. Our experiment shows that answer summaries can be used to improve state-of-the-art document ranking. The method is also shown to outperform a current re-ranking approach using comprehensive document quality features. A manuscript was submitted for this result.\nFor future work, we plan to conduct deeper analysis on top matching questions and their corresponding best answers from Y!A to better understand their benefit to the generated summaries and re-ranking results. For example, how do the results differ on different relevance level of top best answers from Y!A that were used to generate summaries. There are also opportunities to improve the use of Y!A in generating answer summaries, such as by predicting the quality of best answers from Y!A corresponding to the query. We also aim to combine the related Y!A pages into our initial result list when there is a question from Y!A, which is well matched with the query. Next, it is important to think about an approach to generate answer summaries for the queries that do not have related result from CQA.", "references": ["Allan, J. 2004. HARD Track Overview in TREC 2004 - high accuracy retrieval from documents. Proc of TREC.", "Bernstein, M.S., Teevan, J., Dumais, S., Liebling, D. and Horvitz, E. 2012. Direct Answers for Search Queries in the Long Tail. Proc of SIGCHI, 237--246.", "Chilton, L.B. and Teevan, J. 2011. Addressing People's Information Needs Directly in a Web Search Result Page. Proc of WWW, 27--36."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767846"}, {"title": "Flexible metadata mapping using OAI-PMH", "authors": ["Sarantos Kapidakis\n,", "Nikos Houssos\n,", "Kostas Stamatis\n,", "Panagiotis Koutsourakis"], "publication": "PETRA '15: Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nWe designed, implemented and tested enhancements allowing the transmission of richer information from sources, during the metadata transfer, to cater for the case that the desired harvested metadata format evolves. The new functionality will be useful in applications like disconnected health assistive environments that occasionally go online so that their information is polled, especially when the harvested data format is occasionally revised, like when replacing their sensors or their software with different versions. We provide the mechanisms to transfer the raw metadata of each source, while still converting it to the desired format locally at the OAI-PMH client, based on the provided XSLT mapping. The proposed solution ensures full interoperability with non enhanced OAI-PMH clients/servers, so that all OAI-PMH agents can be freely mixed, although the new functionality will only be available to client/data provider pairs that both incorporate the proposed enhanced features.", "references": ["Houssos, N., Stamatis, K., Banos, V., Kapidakis, S., Garoufallou, E., & Koulouris, A. (2011). Implementing enhanced OAI-PMH requirements for Europeana. In: Proceedings of the International Conference on Theory and Practice of Digital Libraries (TPDL 2011), September 25-29, 2011, and Lectures Notes in Computer Science (LNCS), vol. 6966, pp. 396--407.", "Lagoze, Carl, Herbert Van de Sompel, Michael Nelson, and Simeon Warner. 2002. The Open Archives Initiative Protocol for Metadata Harvesting - Version 2.0. &lt;http://www.openarchives.org/OAI/openarchivesprotocol.html&gt;", "Herbert Van de Sompel, Jeffrey A. Young, Thomas B. Hickey, Using the OAI-PMH ... Differently, D-Lib Magazine, 9(7/8), (2003), http://www.dlib.org/dlib/july03/young/07young.html"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2769493.2769531"}, {"title": "Distributed Community Detection with the WCC Metric", "authors": ["Matthew Saltz\n,", "Arnau Prat-Pérez\n,", "David Dominguez-Sal"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nCommunity detection has become an extremely active area of research in recent years, with researchers proposing various new metrics and algorithms to address the problem. Recently, the Weighted Community Clustering (WCC) metric was proposed as a novel way to judge the quality of a community partitioning based on the distribution of triangles in the graph, and was demonstrated to yield superior results over other commonly used metrics like modularity. The same authors later presented a parallel algorithm for optimizing WCC on large graphs. In this paper, we propose a new distributed, vertex-centric algorithm for community detection using the WCC metric. Results are presented that demonstrate the algorithm's performance and scalability on up to 32 worker machines and real graphs of up to 1.8 billion edges. The algorithm scales best with the largest graphs, finishing in just over an hour for the largest graph, and to our knowledge, it is the first distributed algorithm for optimizing the WCC metric.", "references": ["Y. Ahn, J. Bagrow, and S. Lehmann. Link communities reveal multiscale complexity in networks. Nature, 466(7307):761--764, 2010.", "S.-H. Bae, D. Halperin, J. West, M. Rosvall, and B. Howe. Scalable flow-based community detection for large-scale network analysis. In Data Mining Workshops (ICDMW), 2013 IEEE 13th International Conference on, pages 303--310. IEEE, 2013.", "J. P. Bagrow. Are communities just bottlenecks? trees and treelike networks have high modularity. CoRR, abs/1201.0745, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744715"}, {"title": "A Novel Visual-Region-Descriptor-based Approach to Sketch-based Image Retrieval", "authors": ["Cheng Jin\n,", "Zheming Wang\n,", "Tianhao Zhang\n,", "Qinen Zhu\n,", "Yuejie Zhang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nA novel Visual-Region-Descriptor-based approach is developed in this paper to facilitate more effective Sketch-based Image Retrieval (SBIR), which can be treated as a problem of bilateral visual mapping and modeled as an inter-related correlation distribution over visual semantic representations of sketches and images. For crossing the matching barrier between binary query sketches and full color natural images, we focus on constructing a visual pre-analysis via the sketch-like representation transformation to improve the general sketch-image resemblance, creating a special visual region descriptor to obtain better visual feature generation for sketches and images, and a dynamic sketch-image matching scheme to achieve more precise characterization of the correlations between sketches and images. Such a visual-region-descriptor-based SBIR pattern can not only enable users to present whatever they imagine in their mind on the sketch query panel but also return the most similar images to the picture in users' mind. Very positive results were obtained in our experiments using a large quantity of public data.", "references": ["Datta, R., Joshi, D., Li, J., and Wang, J. Z. 2008. Image Retrieval: Ideas, Influences, and Trends of the New Age. ACM Computing Survey, 40(2): 5:1--5:60.", "Cao, Y., Wang, H., Wang, C. H., Li, Z. W., Zhang, L. Q., and Zhang, L. 2010. MindFinder: Interactive Sketch-based Image Search on Millions of Images. In Proceedings of MM2010, 1605--1608.", "Furuya, T., and Ohbuchi, R. 2014. Visual Saliency Weighting and Cross-Domain Manifold Ranking for Sketch-based Image Retrieval. In Proceedings of MMM2014, 37--49."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749302"}, {"title": "BBookX: An Automatic Book Creation Framework", "authors": ["Chen Liang\n,", "Shuting Wang\n,", "Zhaohui Wu\n,", "Kyle Williams\n,", "Bart Pursel\n,", "Benjamin Brautigam\n,", "Sherwyn Saul\n,", "Hannah Williams\n,"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nAs more educational resources become available online, it is possible to acquire more up-to-date knowledge and information. We propose BBookX, a novel computer facilitated system that automatically and collaboratively builds free open online books using publicly available educational resources such as Wikipedia. BBookX has two separate components: one creates an open version of existing books by linking different book chapters to Wikipedia articles, while another with an interactive user interface supports interactive real-time book creation where users are allowed to modify a generated book from explicit feedback.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In Proceedings of SIGIR, pages 19--26, 2006.", "C. J. Bonk, M. M. Lee, N. Kim, and M.-F. G. Lin. The tensions of transformation in three cross-institutional wikibook projects. The Internet and Higher Education, pages 126--135, 2009.", "C. Buckley, G. Salton, J. Allan, and A. Singhal. Automatic query expansion using SMART: TREC 3. In Proceedings of TREC, pages 69--80, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797094"}, {"title": "Using Tags and Latent Factors in a Food Recommender System", "authors": ["Mouzhi Ge\n,", "Mehdi Elahi\n,", "Ignacio Fernaández-Tobías\n,", "Francesco Ricci\n,", "David Massimo"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nDue to the extensive growth of food varieties, making better and healthier food choices becomes more and more complex. Most of the current food suggestion applications offer just generic advices that are not tailored to the user's personal taste. To tackle this issue, we propose in this paper a novel food recommender system that provides high quality and personalized recipe suggestions. These recommendations are generated by leveraging a data set of users' preferences expressed in the form of users' ratings and tags, which signal the food's ingredients or features that the users like. Our empirical evaluation shows that the proposed recommendation technique significantly outperforms state-of-the-art algorithms. We have found that using tags in food recommendation algorithms can significantly increase the prediction accuracy, i.e., the match of the predicted preferences with the true user's preferred recipes. Furthermore, our user study shows that our system prototype is of high usability.", "references": ["N. Baghaei, S. Kimani, J. Freyne, E. Brindal, S. Berkovsky, and G. Smith. Engaging families in lifestyle changes through social networking. International Journal of Human-Computer Interaction, 27(10):971--990, 2011.", "J. Brooke. Sus: a quick and dirty usability scale. In Jordan, editor, Usability Evaluation in Industry. London: Taylor and Francis, 1996.", "R. Burke. Knowledge-based recommender systems. Encyclopaedia of Library and Information Systems, 69(32), 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750511.2750528"}, {"title": "Employing source code information to improve question-answering in stack overflow", "authors": ["Themistoklis Diamantopoulos\n,", "Andreas L. Symeonidis"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nNowadays, software development has been greatly influenced by question-answering communities, such as Stack Overflow. A new problem-solving paradigm has emerged, as developers post problems they encounter that are then answered by the community. In this paper, we propose a methodology that allows searching for solutions in Stack Overflow, using the main elements of a question post, including not only its title, tags, and body, but also its source code snippets. We describe a similarity scheme for these elements and demonstrate how structural information can be extracted from source code snippets and compared to further improve the retrieval of questions. The results of our evaluation indicate that our methodology is effective on recommending similar question posts allowing community members to search without fully forming a question.", "references": ["Annie T. T. Ying. Mining Challenge 2015: Comparing and combining different information sources on the Stack Overflow data set. In The 12th Working Conference on Mining Software Repositories, page to appear, 2015.", "Elasticsearch: Open source distributed real time search & analytics. http://www.elasticsearch.org/. {retrieved February, 2015}.", "R. Holmes and G. C. Murphy. Using structural context to recommend source code examples. In Proceedings of the 27th International Conference on Software Engineering, ICSE 2005, pages 117--125, St. Louis, MO, USA, May 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820585"}, {"title": "What Makes a Beautiful Landscape Beautiful: Adjective Noun Pairs Attention by Eye-Tracking and Gaze Analysis", "authors": ["Mohammad Al-Naser\n,", "Seyyed Saleh Mozafari Chanijani\n,", "Syed Saqib Bukhari\n,", "Damian Borth\n,", "Andreas Dengel"], "publication": "ASM '15: Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia", "abstract": "ABSTRACT\nThis paper asks the questions: what makes a beautiful landscape beautiful, what makes a damaged building look damaged? It tackles the challenge to understand which regions of Adjective Noun Pairs (ANP) images attract attention when observed by a human subject. We employ eye-tracking techniques to record the gaze over a set of multiple ANPs images and derive regions of interests for these ANPs. Our contribution is to study eye fixation pattern in the context of ANPs and their characteristics between being objective or subjective on the one hand and holistic vs. localizable on the other hand. Our finding indicate that subjects who differ in their assessment of ANP labels also have different eye fixation pattern. Further, we provide insights about ANP attention during implicit and explicit ANP assessment.", "references": ["S. Bhattacharya, B. Nojavanasghari, T. Chen, D. Liu, S.-F. Chang, and M. Shah. Towards a comprehensive computational model foraesthetic assessment of videos. In Proceedings of the 21st ACM international conference on Multimedia, pages 361--364. ACM, 2013.", "R. Biedert, J. Hees, G. Buscher, and A. Dengel. A robust realtime reading-skimming classifier, 2012. Proceedings of the Symposium on Eye Tracking Research and Applications, Pages 201--204, 2012.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale Visual Sentiment Ontology and Detectors Using Adjective Noun Pairs. In Proc. ACM Int. Conf. on Multimedia (ACM MM), pages 223--232, October 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813524.2813532"}, {"title": "Axiomatic Analysis of Smoothing Methods in Language Models for Pseudo-Relevance Feedback", "authors": ["Hussein Hazimeh\n,", "ChengXiang Zhai"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nPseudo-Relevance Feedback (PRF) is an important general technique for improving retrieval effectiveness without requiring any user effort. Several state-of-the-art PRF models are based on the language modeling approach where a query language model is learned based on feedback documents. In all these models, feedback documents are represented with unigram language models smoothed with a collection language model. While collection language model-based smoothing has proven both effective and necessary in using language models for retrieval, we use axiomatic analysis to show that this smoothing scheme inherently causes the feedback model to favor frequent terms and thus violates the IDF constraint needed to ensure selection of discriminative feedback terms. To address this problem, we propose replacing collection language model-based smoothing in the feedback stage with additive smoothing, which is analytically shown to select more discriminative terms. Empirical evaluation further confirms that additive smoothing indeed significantly outperforms collection-based smoothing methods in multiple language model-based PRF models.", "references": ["N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. Umass at trec 2004: Novelty and hard. Technical report, DTIC Document, 2004.", "J. Allan. Relevance feedback with too much data. In Proceedings of ACM SIGIR 1995, pages 337--343, 1995.", "C. Buckley, G. Salton, J. Allan, and A. Singhal. Automatic query expansion using smart: Trec 3. NIST special publication sp, pages 69--69, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809471"}, {"title": "Transparent inclusion, utilization, and validation of main memory domain indexes", "authors": ["Thanh Truong\n,", "Tore Risch"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nMain-memory database systems (MMDBs) are viable solutions for many scientific applications. Scientific and engineering data often require special indexing methods, and there is a large number of domain specific main memory indexing implementations developed. However, adding an index structure into a database system can be challenging. Mexima (Main-memory External Index Manager) provides an MMDB where new main-memory index structures can be plugged-in without modifying the index implementations. This has allowed to plug-into Mexima complex and highly optimized index structures implemented in C/C++ without code changes. To utilize new user-defined indexes in queries transparently, Mexima automatically transforms query fragments into index operations based on index property tables containing index meta-data. For scalable processing of complex numerical query expressions, Mexima includes an algebraic query transformation mechanism that reasons on numerical expressions to expose potential utilization of indexes. The index property tables furthermore enable validating the correctness of an index implementation by executing automatically generated test queries based on index meta-data. Experiments show that the performance penalty of using an index plugged into Mexima is low compared to using the corresponding stand-alone C/C++ implementation. Substantial performance gains are shown by the index exposing rewrite mechanisms.", "references": ["W. G. Aref and I. F. Ilyas: An extensible index for spatial databases, Proc. SSDBM, pp 49--58, 2001.", "D. Baskins: Judy home page {http://judy.sourceforge.net/}, 2003.", "D. Benoit, D. Das, K. Dias, K. Yagoub, M. Zait, and M. Ziauddin: Automatic SQL tuning in Oracle 10g, Proc. VLDB Conf, pp 1098--1109, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791375"}, {"title": "On the Cost of Phrase-Based Ranking", "authors": ["Matthias Petri\n,", "Alistair Moffat"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nEffective postings list compression techniques, and the efficiency of postings list processing schemes such as WAND, have significantly improved the practical performance of ranked document retrieval using inverted indexes. Recently, suffix array-based index structures have been proposed as a complementary tool, to support phrase searching. The relative merits of these alternative approaches to ranked querying using phrase components are, however, unclear. Here we provide: (1) an overview of existing phrase indexing techniques; (2) a description of how to incorporate recent advances in list compression and processing; and (3) an empirical evaluation of state-of-the-art suffix-array and inverted file-based phrase retrieval indexes using a standard IR test collection.", "references": ["D. Arroyuelo, S. González, M. Marın, M. Oyarzún, and T. Suel. To index or not to index: Time-space trade-offs in search engines with positional ranking functions. In Proc. SIGIR, pages 255--264, 2012.", "A. Z. Broder, D. Carmel, H. Herscovici, A. Soffer, and J. Zien. Efficient query evaluation using a two-level retrieval process. In Proc. CIKM, pages 426--434, 2003.", "A. Broschart and R. Schenkel. High-performance processing of text queries with tunable pruned term and term pair indexes. ACM Trans. Inf. Sys., 30 (1): 5, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767769"}, {"title": "AP-Tree: efficiently support location-aware Publish/Subscribe", "authors": ["Xiang Wang\n,", "Ying Zhang\n,", "Wenjie Zhang\n,", "Xuemin Lin\n,", "Wei Wang"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWe investigate the problem of efficiently supporting location-aware Publish/Subscribe (Pub/Sub for short), which is essential in many applications such as location-based recommendation and advertising, thanks to the proliferation of geo-equipped devices and the ensuing location-based social media applications. In a location-aware Pub/Sub system (e.g., an e-coupon system), subscribers can register their interest as spatial-keyword subscriptions (e.g., interest in nearby iphone discount); each incoming geo-textual message (e.g., geo-tagged e-coupon) will be delivered to all the relevant subscribers immediately. While there are several prior approaches aiming at providing efficient processing techniques for this problem, their approaches belong to spatial-prioritized indexing method which cannot well exploit the keyword distribution. In addition, their textual filtering techniques are built upon simple variants of traditional inverted indexes, which do not perform well for the textual constraint imposed by the problem. In this paper, we address the above limitations and provide a highly efficient solution based on a novel adaptive index, named AP-Tree. AP-Tree adaptively groups registered subscriptions using keyword and spatial partitions, guided by a cost model. AP-Tree also naturally indexes ordered keyword combinations. Furthermore, we show that our techniques can be extended to process moving spatial-keyword subscriptions, where subscribers can continuously update their locations. We present efficient algorithms to process both stationary and moving subscriptions, which can seamlessly and effectively integrate keyword and spatial partitions. Our extensive experiments demonstrate that AP-Tree and its variant AP $$^{+}$$+ -Tree can achieve up to an order of magnitude improvement on efficiency compared with prior state-of-the-art methods.", "references": ["Aguilera, M.K., Strom, R.E., Sturman, D.C., Astley, M., Chandra, T.D.: Matching events in a content-based subscription system. In: PODC, pp. 53---61 (1999)", "Bao, J., Mokbel, M.F., Chow, C.Y.: Geofeed: A location aware news feed system. In: ICDE, pp. 54---65 (2012)", "Bentley, J.L.: Solutions to Klees Rectangle Problems. Technical report, Carnegie-Mellon University, Pittsburgh, PA (1977)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0403-4"}, {"title": "Towards complete coverage in focused web harvesting", "authors": ["Mohammadreza Khelghati\n,", "Djoerd Hiemstra\n,", "Maurice van Keulen"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nWith the goal of harvesting all information about a given entity, in this paper, we try to harvest all matching documents for a given query submitted on a search engine. The objective is to retrieve all information about for instance \"Michael Jackson\", \"Islamic State\", or \"FC Barcelona\" from indexed data in search engines, or hidden data behind web forms, using a minimum number of queries. Policies of web search engines usually do not allow accessing all of the matching query search results for a given query. They limit the number of returned documents and the number of user requests. These limitations are also applied in deep web sources, for instance in social networks like Twitter. In this work, we propose a new approach which automatically collects information related to a given query from a search engine, given the search engine's limitations. The approach minimizes the number of queries that need to be sent by analysing the retrieved results and combining this analysed information with information from a large external corpus. The new approach outperforms existing approaches when tested on Google, measuring the total number of unique documents found per query.", "references": ["Manuel Álvarez, Juan Raposo, Alberto Pan, Fidel Cacheda, Fernando Bellas, and Víctor Carneiro. Deepbot: a focused crawler for accessing hidden web content. In Proceedings of the 3rd international workshop on Data enginering issues in E-commerce and services: In conjunction with ACM Conference on Electronic Commerce (EC '07), DEECS '07, pages 18--25, New York, NY, USA, 2007. ACM.", "Ziv Bar-Yossef and Maxim Gurevich. Efficient search engine measurements. Proceedings of the 16th international conference on World Wide Web, pages 401--410, 2007.", "Luciano Barbosa and Juliana Freire. Siphoning hidden-web data through keyword-based interfaces. In SBBD, pages 309--321, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837208"}, {"title": "Harnessing Semantics for Answer Sentence Retrieval", "authors": ["Ruey-Cheng Chen\n,", "Damiano Spina\n,", "W. Bruce Croft\n,", "Mark Sanderson\n,", "Falk Scholer"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nFinding answer passages from the Web is a challenging task. One major difficulty is to retrieve sentences that may not have many terms in common with the question. In this paper, we experiment with two semantic approaches for finding non-factoid answers using a learning-to-rank retrieval setting. We show that using semantic representations learned from external resources such as Wikipedia or Google News may substantially improve the quality of top-ranked retrieved answers.", "references": ["A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. Bridging the Lexical Chasm: Statistical Approaches to Answer-finding. In Proceedings of SIGIR'00, pages 192--199, 2000.", "P. Ferragina and U. Scaiella. Fast and accurate annotation of short texts with wikipedia pages. Software, IEEE, 29(1):70--75, 2012.", "J. H. Friedman. Greedy function approximation: a gradient boosting machine. Annals of statistics, pages 1189--1232, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810136"}, {"title": "When experts collaborate: sharing search and domain expertise within an organization", "authors": ["Dominic Stange\n,", "Andreas Nürnberger"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nData about how individuals explore an information space and collect facts about their topic of interest is valuable to analyze but difficult to come by. In this paper we outline how this data can be captured in a search task with the help of a special search environment. Domain experts sharing this data in an organization can enhance their collaborative search experience and benefit from each others' search and domain expertise. Our approach facilitates interaction mechanisms of an interface and data mining methods. We also lay out a business process where the system is applied.", "references": ["S. Amershi and M. R. Morris. Cosearch: a system for co-located collaborative web search. In M. Czerwinski, A. M. Lund, and D. S. Tan, editors, CHI, pages 1647--1656. ACM, 2008.", "K. E. Chang, Y. T. Sung, and I. D. Chen. The Effect of Concept Mapping to Enhance Text Comprehension and Summarization. The Journal of Experimental Education, 71(1):5--23, 2002.", "G. Golovchinsky, J. Pickens, and M. Back. A taxonomy of collaboration in online information seeking. CoRR, abs/0908.0704, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809582"}, {"title": "Energy-aware data transfer algorithms", "authors": ["Ismail Alan\n,", "Engin Arslan\n,", "Tevfik Kosar"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nThe amount of data moved over the Internet per year has already exceeded the Exabyte scale and soon will hit the Zettabyte range. To support this massive amount of data movement across the globe, the networking infrastructure as well as the source and destination nodes consume immense amount of electric power, with an estimated cost measured in billions of dollars. Although considerable amount of research has been done on power management techniques for the networking infrastructure, there has not been much prior work focusing on energy-aware data transfer algorithms for minimizing the power consumed at the end-systems. We introduce novel data transfer algorithms which aim to achieve high data transfer throughput while keeping the energy consumption during the transfers at the minimal levels. Our experimental results show that our energy-aware data transfer algorithms can achieve up to 50% energy savings with the same or higher level of data transfer throughput.", "references": ["The extreme science and engineering discovery environment (xsede). https://www.xsede.org/.", "Futuregrid testbed. http://www.futuregrid.org.", "IEEE energy efficient ethernet standards. 10.1109/IEEESTD.2010.5621025, Oct. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807628"}, {"title": "B-box Mixer: An Interactive UI for Generating B-box Music", "authors": ["Yi-Zhu Dai\n,", "Ting-Chia Lee\n,", "Xin-Yu Kuo\n,", "Tse-Yu Pan\n,", "Min-Chun Hu"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nB-box is a form of vocal percussion that imitates rhythms in various types of sound, especially musical instruments. As b-box becoming popular, more and more people want to learn b-box and make their own b-box music. However, not everyone has the talent for generating harmonic b-box music. In this work, we develop an interactive system which helps the user easily compose b-box music given two inputs: an unaccompanied vocal song and a piece of b-box rhythm. The audio signals of the two inputs are analyzed and adaptively matched on the basis of their beats. The state of the art beat detection technique does not perform well on vocal songs. Hence, we propose to partition the song into short segments and estimate the average tempo for each segment so that the adjustment of tempo will not be affected too much by the wrongly detected beats. With the proposed system, people who love b-box or are not familiar with b-box can enjoy producing their own b-box music.", "references": ["Piano Note Detection: http://www.oercommons.org/courses/matlab-code-that-implements-piano-note-detection/view"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807984"}, {"title": "Online Search Evaluation with Interleaving", "authors": ["Filip Radlinski"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline evaluation allows information retrieval systems to be assessed based on how real users respond to search results presented. Compared with traditional offline evaluation based on manual relevance assessments, online evaluation is particularly attractive in settings where reliable assessments are difficult or too expensive to obtain. However, the successful use of online evaluation requires the right metrics to be used, as real user behaviour is often difficult to interpret. I will present interleaving, a sensitive online evaluation approach that creates paired comparisons for every user query, and compare it with alternative A/B online evaluation approaches. I will also show how interleaving can be parameterized to create a family of evaluation metrics that can be chosen to best match the goals of an evaluation.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743064"}, {"title": "ECol 2015: First international workshop on the Evaluation on Collaborative Information Seeking and Retrieval", "authors": ["Leif Azzopardi\n,", "Jeremy Pickens\n,", "Tetsuya Sakai\n,", "Laure Soulier\n,", "Lynda Tamine"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nCollaborative Information Seeking/Retrieval (CIS/CIR) has given rise to several challenges in terms of search behavior analysis, retrieval model formalization as well as interface design. However, the major issue of evaluation in CIS/CIR is still underexplored. The goal of this workshop is to investigate the evaluation challenges in CIS/CIR with the hope of building standardized evaluation frameworks, methodologies, and task specifications that would foster and grow the research area (in a collaborative fashion).", "references": ["C. Foley and A. F. Smeaton. Synchronous collaborative information retrieval: Techniques and evaluation. In Springer ECIR, pages 42--53, 2009.", "J. Foster. Collaborative information seeking and retrieval. Annual Review of Information Science and Technology, 40(1), 2006.", "P. Hansen and K. Järvelin. Collaborative information retrieval in an information-intensive domain. Inf. Process. Manage., 41(5):1101--1119, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806881"}, {"title": "Seamless integration of urban mobility data: the Infoblu Traffic for Expo mobile app", "authors": ["Andrea Cerino\n,", "Maurilio Zuccalà\n,", "Irene Celino"], "publication": "MOBILESoft '15: Proceedings of the Second ACM International Conference on Mobile Software Engineering and Systems", "abstract": "ABSTRACT\nInfoblu Traffic for Expo is a mobile app for Android and iOS developed by Infoblu. It integrates real-time traffic information directly managed by Infoblu with third-party data: train and airline timetables, car parking etc. Such integration is enabled by the E015 digital ecosystem operating in Italy. This paper presents the innovative characteristics of this mobile app and provides a brief overview of E015.", "references": ["Infoblu Traffic for Expo -- Android version on Google Play (it). https://play.google.com/store/apps/details?id=it.packetloss.infobluexpo&hl=it", "Infoblu Traffic for Expo -- iOS version on Apple Store (it). https://itunes.apple.com/it/app/infoblu-milano-expo/id586221502?mt=8", "Infoblu Traffic for Expo -- Web version. http://e015.infoblutraffic.com"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2825041.2825089"}, {"title": "Evaluation Of MediaPlace: a geospatial semantic enrichment system for photographs", "authors": ["Andrew Ennis\n,", "Chris Nugent\n,", "Philip Morrow\n,", "Liming Chen\n,", "George Ioannidis\n,", "Alexandru Stan"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nIn today's world of internet connected devices and smart phones, it has become effortless to create and consume vast amounts of information. This is particularly the case with photographs, with vast amounts being created and shared online every day. Never-the-less, it still remains a challenge to discover the \"right\" information for the appropriate purpose. This paper describes and discusses the testing and evaluation of the MediaPlace system with the well-known dataset YFCC-100M, which contains 48 million geospatial geotagged photographs, from Flickr produced by Yahoo. MediaPlace is a system which we have developed to automatically enrich geotagged photographs with semantic geospatial information derived from several online geospatial datasets.", "references": ["Facebook, \"Instagram,\" 2013. {Online}. Available: http://instagram.com/.", "Flickr, \"Flickr,\" 2013. {Online}. Available: http://www.flickr.com/.", "YouTube LLC, \"YouTube,\" 2013. {Online}. Available: http://www.youtube.com/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2843847"}, {"title": "Learning by Example: Training Users with High-quality Query Suggestions", "authors": ["Morgan Harvey\n,", "Claudia Hauff\n,", "David Elsweiler"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe queries submitted by users to search engines often poorly describe their information needs and represent a potential bottleneck in the system. In this paper we investigate to what extent it is possible to aid users in learning how to formulate better queries by providing examples of high-quality queries interactively during a number of search sessions. By means of several controlled user studies we collect quantitative and qualitative evidence that shows: (1) study participants are able to identify and abstract qualities of queries that make them highly effective, (2) after seeing high-quality example queries participants are able to themselves create queries that are highly effective, and, (3) those queries look similar to expert queries as defined in the literature. We conclude by discussing what the findings mean in the context of the design of interactive search systems.", "references": ["P. Anick, Using terminological feedback for web search refinement: a log-based study, SIGIR '03, ACM, 2003, pp. 88--95.", "A. Arampatzis and J. Kamps, A study of query length, SIGIR '08, ACM, 2008, pp. 811--812.", "A. Aula, N. Jhaveri, and M. Kaki, Information search and re-access strategies of experienced web users, WWW '05, ACM, 2005, pp. 583--592."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767731"}, {"title": "Data Analytics for Bank Term Deposit by Combining Artificial Immune Network and Collaborative Filtering", "authors": ["Xiao-Yong Lu\n,", "Xiao-Qiang Chu\n,", "Meng-Hui Chen\n,", "Pei-Chann Chang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nTo predict the preference of customer is essential to every financial service company, and by developing a high-efficient classification model can make a company to increase their profit and reduce the cost. In marketing, the uses of big data include \"recommendation engines\" to make suggestions based on the prior interests of a customer as compared to others. Thus, the main idea of this research presents an artificial immune classification combining collaborative filtering approach for bank term deposit recommendation. Artificial Immune Network (AIN) is a network of customers with bank term deposit and it can be adopted as a group decision making model in predicting whether a new customer will have a term deposit or not. A series of experiments are conducted, and the results are very encouraging. In spite of the class imbalance problem in the test dataset, our proposed model outperformed other models with highest accuracy.", "references": ["Hu, X. H. 2005. a data mining approach for retailing bankcustomer attrition analysis. Applied Intelligence. 22, 1, 47--60.", "Nasir, A. N. M., Selamat, A. and Selamat, H. 2009. An artificial immune system for recommending relevant information through political weblog. Proceedings of iiWAS2009. 420--424.", "Dudek, G. 2012. An artificial immune system for classification with local feature selection. IEEE Transaction on Evolutionary Computation. 16, 6, 847--860."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818919"}, {"title": "Untangling Result List Refinement and Ranking Quality: a Framework for Evaluation and Prediction", "authors": ["Jiyin He\n,", "Marc Bron\n,", "Arjen de Vries\n,", "Leif Azzopardi\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nTraditional batch evaluation metrics assume that user interaction with search results is limited to scanning down a ranked list. However, modern search interfaces come with additional elements supporting result list refinement (RLR) through facets and filters, making user search behavior increasingly dynamic. We develop an evaluation framework that takes a step beyond the interaction assumption of traditional evaluation metrics and allows for batch evaluation of systems with and without RLR elements. In our framework we model user interaction as switching between different sublists. This provides a measure of user effort based on the joint effect of user interaction with RLR elements and result quality. We validate our framework by conducting a user study and comparing model predictions with real user performance. Our model predictions show significant positive correlation with real user effort. Further, in contrast to traditional evaluation metrics, the predictions using our framework, of when users stand to benefit from RLR elements, reflect findings from our user study.\nFinally, we use the framework to investigate under what conditions systems with and without RLR elements are likely to be effective. We simulate varying conditions concerning ranking quality, users, task and interface properties demonstrating a cost-effective way to study whole system performance.", "references": ["M. Agosti, N. Fuhr, E. Toms, and P. Vakkari. Evaluation methodologies in information retrieval dagstuhl seminar 13441. In ACM SIGIR Forum, volume 48, pages 36--41. ACM, 2014.", "L. Azzopardi. Modelling interaction with economic models of search. In SIGIR'14, pages 3--12, 2014.", "B. Carterette. System effectiveness, user models, and user utility: a conceptual framework for investigation. In SIGIR'11, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767740"}, {"title": "Temporal Matching Kernel with Explicit Feature Maps", "authors": ["Sébastien Poullot\n,", "Shunsuke Tsukatani\n,", "Anh Phuong Nguyen\n,", "Hervé Jégou\n,", "Shin'Ichi Satoh"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper proposes a framework for content-based video retrieval that addresses various tasks as particular event retrieval, copy detection or video synchronization. Given a video query, the method is able to efficiently retrieve, from a large collection, similar video events or near-duplicates with temporarily consistent excerpts. As a byproduct of the representation, it provides a precise temporal alignment of the query and the detected video excerpts.\nOur method converts a series of frame descriptors into a single visual-temporal descriptor, called a temporal invariant match kernel. This representation takes into account the relative positions of the visual frames: the frame descriptors are jointly encoded with their timestamps. When matching two videos, the method produces a score function for all possible relative timestamps, which is maximized to obtain both the similarity score and the relative time offset.\nThen, we propose two complementary contributions to further improve the detection and localization performance.The first is a novel query expansion method that takes advantage of the joint descriptor/timestamp representation to automatically align the first result set and produce an enriched temporal query. In contrast to other query expansion methods proposed for videos, it preserves the localization capability. Second, we improve the localization trade-off between quality and representation size by using several complementary temporal match kernels.\nWe evaluate our approach on benchmarks for particular event retrieval, copy detection and video synchronization. Our experiments show that our approach achieve excellent detection and localization results.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, Jun. 2012.", "R. Arandjelovic and A. Zisserman. All about VLAD. In CVPR, Jun. 2013.", "L. Bo, X. Ren, and D. Fox. Kernel descriptors for visual recognition. In NIPS, Dec. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806228"}, {"title": "TrueView: Harnessing the Power of Multiple Review Sites", "authors": ["Amanda J. Minnich\n,", "Nikan Chavoshi\n,", "Abdullah Mueen\n,", "Shuang Luan\n,", "Michalis Faloutsos"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline reviews on products and services can be very useful for customers, but they need to be protected from manipulation. So far, most studies have focused on analyzing online reviews from a single hosting site. How could one leverage information from multiple review hosting sites? This is the key question in our work. In response, we develop a systematic methodology to merge, compare, and evaluate reviews from multiple hosting sites. We focus on hotel reviews and use more than 15 million reviews from more than 3.5 million users spanning three prominent travel sites. Our work consists of three thrusts: (a) we develop novel features capable of identifying cross-site discrepancies effectively, (b) we conduct arguably the first extensive study of cross-site variations using real data, and develop a hotel identity-matching method with 93% accuracy, (c) we introduce the TrueView score, as a proof of concept that cross-site analysis can better inform the end user. Our results show that: (1) we detect 7 times more suspicious hotels by using multiple sites compared to using the three sites in isolation, and (2) we find that 20% of all hotels appearing in all three sites seem to have low trustworthiness score. Our work is an early effort that explores the advantages and the challenges in using multiple reviewing sites towards more informed decision making.", "references": ["Consumer complaints & reviews. http://www.consumeraffairs.com/travel/hotelsdotcom.html?page=2.", "Myrtle beach area chamber of commerce, page 10. http://www.myrtlebeachareachamber.com/research/docs/20statabstract.pdf.", "Supporting webpage containing data, slides and code. www.cs.unm.edu/~aminnich/trueview."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741655"}, {"title": "FedWeb Greatest Hits: Presenting the New Test Collection for Federated Web Search", "authors": ["Thomas Demeester\n,", "Dolf Trieschnigg\n,", "Dong Nguyen\n,", "Djoerd Hiemstra\n,", "Ke Zhou"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper presents 'FedWeb Greatest Hits', a large new test collection for research in web information retrieval. As a combination and extension of the datasets used in the TREC Federated Web Search Track, this collection opens up new research possibilities on federated web search challenges, as well as on various other problems.", "references": ["J. Callan. Distributed information retrieval. In W. B. Croft, editor, Advances in Information Retrieval, volume 7 of The Information Retrieval Series, pages 127--150. Springer US, 2000.", "T. Demeester, D. Trieschnigg, D. Nguyen, and D. Hiemstra. Overview of the TREC 2013 Federated Web Search Track. In TREC, 2013.", "T. Demeester, D. Trieschnigg, D. Nguyen, K. Zhou, and D. Hiemstra. Overview of the TREC 2014 Federated Web Search Track. In TREC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742755"}, {"title": "Tweet-Recommender: Finding Relevant Tweets for News Articles", "authors": ["Ralf Krestel\n,", "Thomas Werkmeister\n,", "Timur Pratama Wiradarma\n,", "Gjergji Kasneci"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nTwitter has become a prime source for disseminating news and opinions. However, the length of tweets prohibits detailed descriptions; instead, tweets sometimes contain URLs that link to detailed news articles. In this paper, we devise generic techniques for recommending tweets for any given news article. To evaluate and compare the different techniques, we collected tens of thousands of tweets and news articles and conducted a user study on the relevance of recommendations.", "references": ["X. Cao, K. Chen, R. Long, G. Zheng, and Y. Yu. News comments generation via mining microblogs. In WWW, pages 471--472. ACM, 2012.", "J. Sankaranarayanan, H. Samet, B. E. Teitler, M. D. Lieberman, and J. Sperling. Twitterstand: News in tweets. In GIS, pages 42--51. ACM, 2009.", "W. X. Zhao, J. Jiang, J. Weng, J. He, E.-P. Lim, H. Yan, and X. Li. Comparing twitter and traditional media using topic models. In ECIR, pages 338--349. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742716"}, {"title": "Overview of ACM RecSys CrowdRec 2015 Workshop: Crowdsourcing and Human Computation for Recommender Systems", "authors": ["Martha Larson\n,", "Domonkos Tikk\n,", "Roberto Turrin"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nCrowdRec 2015 provides the recommender system community with a forum at which to discuss crowdsourcing and human computation. Systems that explicitly collect information from human annotators to improve recommendations are becoming more widespread. At this year's workshop, we highlight incentivization and the issue of avoiding bias. We take a special look at how recommender systems can influence collective behavior, and the contribution that the crowd can make to recommender system evaluation.", "references": ["About the music genome project, https://www.pandora.com/about/mgp.", "Introducing Apple Music--all the ways you love music. all in one place. https://www.apple.com /pr/library/2015 /06/08Introducing-Apple-Music-All-The-Ways-You-Love-Music-All-in-One-Place-.html.", "J. Elker. Netflix tagging: Yes, it's a real job, http://www.washingtonpost.com/blogs/style-blog/wp/2015/06/11/netflix-tagging-yes-its-a-real-job Washington Post, June 11, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798719"}, {"title": "HyPER: A Flexible and Extensible Probabilistic Framework for Hybrid Recommender Systems", "authors": ["Pigi Kouki\n,", "Shobeir Fakhraei\n,", "James Foulds\n,", "Magdalini Eirinaki\n,", "Lise Getoor"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAs the amount of recorded digital information increases, there is a growing need for flexible recommender systems which can incorporate richly structured data sources to improve recommendations. In this paper, we show how a recently introduced statistical relational learning framework can be used to develop a generic and extensible hybrid recommender system. Our hybrid approach, HyPER (HYbrid Probabilistic Extensible Recommender), incorporates and reasons over a wide range of information sources. Such sources include multiple user-user and item-item similarity measures, content, and social information. HyPER automatically learns to balance these different information signals when making predictions. We build our system using a powerful and intuitive probabilistic programming language called probabilistic soft logic, which enables efficient and accurate prediction by formulating our custom recommender systems with a scalable class of graphical models known as hinge-loss Markov random fields. We experimentally evaluate our approach on two popular recommendation datasets, showing that HyPER can effectively combine multiple information types for improved performance, and can significantly outperform existing state-of-the-art approaches.", "references": ["S.H. Bach, M. Broecheler, B. Huang, and L. Getoor. Hinge-loss markov random fields and probabilistic soft logic. ArXiv:1505.04406 {cs.LG}, 2015.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Transactions on Knowledge and Data Engineering, 17(6), 2005.", "L. de Campos, J. Fernandez-Luna, J. Huete, and M. Rueda-Morales. Combining content-based and collaborative recommendations: A hybrid approach based on Bayesian networks. International Journal of Approximate Reasoning, 51(7), 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800175"}, {"title": "Skin Music (2012): an Audio-Haptic Composition for Ears and Body", "authors": ["Lauren Hayes"], "publication": "C&C '15: Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition", "abstract": "ABSTRACT\nSkin Music (2012) is a musical composition that is experienced as a private, multisensory installation by one person at a time. By lying on a piece of bespoke furniture, the listener perceives the music both through the usual auditory channels, as well as by different types of haptic sensation, through their body. The piece addresses the shared perceptual experiences of sonic and haptic sensation through an exploration of vibrational feedback.", "references": ["Chang, A., and O'Sullivan, C. An Audio-Haptic Aesthetic Framework Influenced by Visual Theory. In Haptic and Audio Interaction Design, T. I. Workshop, Ed. (Jyväskylä, Finland, September 2008).", "Glennie, E. Hearing essay. http://www.evelyn.co.uk/ Resources/Essays/Hearing%20Essay.pdf {accessed 23rd August 2013}, 1993.", "Hayes, L. Vibrotactile feedback-assisted performance. In Proceedings of the 2011 Conference on New Interfaces for Musical Expression, NIME (Oslo, 2011)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757226.2757370"}, {"title": "How to move towards digital era governance: the case of VDAB", "authors": ["Lieselot Danneels\n,", "Stijn Viaene"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nThis paper takes our research work with VDAB (Vlaamse Dienst voor Arbeidsbemiddeling en Beroepsopleiding), the public employment service for the Flemish region in Belgium, as a starting point to study the transformation of government from New Public Management (NPM) to Digital Era Governance (DEG). This study focuses on how to work towards disruptive DEG innovation in a turbulent strategic context by employing a strategy of simple rules. Together with VDAB we apply an Action Design Research (ADR) approach to develop a set of \"boundary breaking rules\". Coining these simple rules represents a first significant step in VDAB's journey towards achieving a radical business innovation. In addition to the main artifact designed using our ADR approach in the VDAB context, i.e. the \"boundary breaking rules\", we derive lessons from this approach concerning the nature of this artifact specific for the VDAB case. Although this paper represents an early stage of the research and has not yet reached the final ADR stage of formalization of learning, we aim for it to lay the foundations for a more broadly applicable design theory of simple rules, useful in contexts generalizable from the specific VDAB context.", "references": ["Argyris, C. 2002. Double-loop learning, teaching, and research. Academy of Management Learning & Education, 1, 2, pp. 206--218.", "Beck, K. et al. 2001. Manifesto for Agile Software Development. Agile Alliance, available at http://agilemanifesto.org, last accessed 12 November 2014.", "Bingham, C. B., Eisenhardt, K. M. 2008. Position, leverage and opportunity: a typology of strategic logics lining resources with competitive advantage. Managerial and Decision Economics, 29, 2-3, pp. 241--256."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757404"}, {"title": "Impact of the spatial context on human communication activity", "authors": ["Zolzaya Dashdorj\n,", "Stanislav Sobolevsky"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nTechnology development produces terabytes of data generated by human activity in space and time. This enormous amount of data often called big data becomes crucial for delivering new insights to decision makers. It contains behavioral information on different types of human activity influenced by many external factors such as geographic information and weather forecast. Early recognition and prediction of those human behaviors are of great importance in many societal applications like health-care, risk management and urban planning, etc. In this paper, we investigate relevant geographical areas based on their categories of human activities (i.e., working and shopping) in order to understand human-environmental relationships. We use spectral clustering approach followed by k-means algorithm based on TF/IDF cosine similarity metric. We evaluate the quality of the relevant area clusters with a use of silhouette coefficients which are estimated based on the similarities of the mobile communication activity temporal patterns. The area clusters are further used to explain typical or exceptional communication activities. We demonstrate our study using a real dataset containing 1 million Call Detailed Records. This type of analysis and application is important for discovering hidden relationships and unknown correlations.", "references": ["Amini, A., Kung, K., Kang, C., Sobolevsky, S., and Ratti, C. In Proc. of 3rd int. conference on the analysis of mobile phone datasets (2013).", "Anastasios, N., Salvatore, S., Cecilia, M., and Massimiliano, P. In The Social Mobile Web (2011).", "Calabrese, F., C., P. F., Di Lorenzo, G., Liu, L., and Ratti, C. (Pervasive'10), Springer-Verlag (Berlin, Heidelberg, 2010)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2801625"}, {"title": "Rank by Time or by Relevance?: Revisiting Email Search", "authors": ["David Carmel\n,", "Guy Halawi\n,", "Liane Lewin-Eytan\n,", "Yoelle Maarek\n,", "Ariel Raviv"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWith Web mail services offering larger and larger storage capacity, most users do not feel the need to systematically delete messages anymore and inboxes keep growing. It is quite surprising that in spite of the huge progress of relevance ranking in Web Search, mail search results are still typically ranked by date. This can probably be explained by the fact that users demand perfect recall in order to \"re-find\" a previously seen message, and would not trust relevance ranking. Yet mail search is still considered a difficult and frustrating task, especially when trying to locate older messages. In this paper, we study the current search traffic of Yahoo mail, a major Web commercial mail service, and discuss the limitations of ranking search results by date. We argue that this sort-by-date paradigm needs to be revisited in order to account for the specific structure and nature of mail messages, as well as the high-recall needs of users. We describe a two-phase ranking approach, in which the first phase is geared towards maximizing recall and the second phase follows a learning-to-rank approach that considers a rich set of mail-specific features to maintain precision. We present our results obtained on real mail search query traffic, for three different datasets, via manual as well as automatic evaluation. We demonstrate that the default time-driven ranking can be significantly improved in terms of both recall and precision, by taking into consideration time recency and textual similarity to the query, as well as mail-specific signals such as users' actions.", "references": ["S. AbdelRahman, B. Hassan, and R. Bahgat. A new email retrieval ranking approach. International Journal of Computer Science & Information Technology, 2(5), 2010.", "D. Aberdeen, O. Pacovsky, and A. Slater. The learning behind gmail priority inbox. In LCCC: NIPS 2010 Workshop on Learning on Cores, Clusters and Clouds, Vancouver, BC, Canada, Dec 2010.", "R. Baeza-Yates and Y. Maarek. (big) usage data in web search. In Proceedings of SIGIR, pages 1181--1182, Portland, Oregon, USA, 2012. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806471"}, {"title": "Enhanced Word Embeddings from a Hierarchical Neural Language Model", "authors": ["Xun Wang\n,", "Katsuhoto Sudoh\n,", "Masaaki Nagata"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper proposes a neural language model to capture the interaction of text units of different levels, i.e.., documents, paragraphs, sentences, words in an hierarchical structure. At each paralleled level, the model incorporates Markov property while each higher-level unit hierarchically influences its containing units. Such an architecture enables the learned word embeddings to encode both global and local information. We evaluate the learned word embeddings and experiments demonstrate the effectiveness of our model.", "references": ["Bengio, Y., Schwenk, H., Senécal, J.-S., Morin, F., and Gauvain, J.-L. (2006). Neural probabilistic language models. In Innovations in Machine Learning, pages 137--186. Springer.", "Blei, D. M., Ng, A. Y., and Jordan, M. I. (2003). Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022.", "Collobert, R. and Weston, J. (2008). A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160--167. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806637"}, {"title": "Discovering the Latent Similarities of the KNN Graph by Metric Transformation", "authors": ["Zhenzhong Kuang\n,", "Zongmin Li\n,", "Jianping Fan"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe manifold of the dataset turns out to be quite useful in refining the retrieval results, and the diffusion process provides an efficient solution by careful selection of the similarity neighborhood which is usually modeled as the K-nearest neighborhood (KNN) graph. However, existing works are sensitive to the topology noises induced by the first K neighbors. In this paper, we tackle the problem by studying metric transformation which aims at finding new functional relationship to dig the latent similarity. The advantage of the approach lies in its robustness towards the varying K values; that is to say, it could preserve high similarity performances even if K is very large. Except for discussing only the global KNN (i.e. the same K for all neighborhoods) graph, we also investigate to specify a different K for each neighborhood by incorporating the new penalized consensus information (PCI). We show that PCI works superior compared with the original consensus information for denoising. Experiments on multiple affinity matrices have corroborated the superiority of our method with surprising good results.", "references": ["A. M. Bronstein, M. M. Bronstein, L. J. Guibas, and M. Ovsjanikov. Shape google: Geometric words and expressions for invariant shape retrieval. ToG, 30(1):1, 2011.", "M. Donoser and H. Bischof. Diffusion processes for retrieval revisited. In CVPR, pages 1320--1327, 2013.", "J. Jiang, B. Wang, and Z. Tu. Unsupervised metric learning by self-smoothing operator. In ICCV, pages 794--801, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749303"}, {"title": "Concept Expansion Using Web Tables", "authors": ["Chi Wang\n,", "Kaushik Chakrabarti\n,", "Yeye He\n,", "Kris Ganjam\n,", "Zhimin Chen\n,", "Philip A. Bernstein"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe study the following problem: given the name of an ad-hoc concept as well as a few seed entities belonging to the concept, output all entities belonging to it. Since producing the exact set of entities is hard, we focus on returning a ranked list of entities. Previous approaches either use seed entities as the only input, or inherently require negative examples. They suffer from input ambiguity and semantic drift, or are not viable options for ad-hoc tail concepts. In this paper, we propose to leverage the millions of tables on the web for this problem. The core technical challenge is to identify the ``exclusive'' tables for a concept to prevent semantic drift; existing holistic ranking techniques like personalized PageRank are inadequate for this purpose. We develop novel probabilistic ranking methods that can model a new type of table-entity relationship. Experiments with real-life concepts show that our proposed solution is significantly more effective than applying state-of-the-art set expansion or holistic ranking techniques.", "references": ["Google Knowledge Graph. http://www.google.com/insidesearch/features/search/knowledge.html.", "Google Web Tables. http://research.google.com/tables.", "Microsoft Excel Power Query. http://office.microsoft.com/powerbi."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741644"}, {"title": "Pooling for User-Oriented Evaluation Measures", "authors": ["Gaurav Baruah\n,", "Adam Roegiest\n,", "Mark D. Smucker"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nTraditional TREC-style pooling methodology relies on using predicted relevance by systems to select documents for judgment. This coincides with typical search behaviour (e.g., web search). In the case of temporally ordered streams of documents, the order that users encounter documents is in this temporal order and not some predetermined rank order. We investigate a user oriented pooling methodology focusing on the documents that simulated users would likely read in such temporally ordered streams. Under this user model, many of the relevant documents found in the TREC 2013 Temporal Summarization Track's pooling effort would never be read. Not only does our pooling strategy focus on pooling documents that will be read by (simulated) users, the resultant pools are different from the standard TREC pools.", "references": ["J. Allan, R. Gupta, and V. Khandelwal. Temporal Summaries of New Topics. In SIGIR, pp. 10--18, 2001.", "J. Aslam, F. Diaz, M. Ekstrand-Abueg, V. Pavlu, and T. Sakai. TREC 2013 Temporal Summarization. In TREC, 2013.", "G. Baruah, M. D. Smucker, and C. L. A. Clarke. Evaluating Streams of Evolving News Events. In Proc. SIGIR, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809493"}, {"title": "Learning to Extract Local Events from the Web", "authors": ["John Foley\n,", "Michael Bendersky\n,", "Vanja Josifovski"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe goal of this work is extraction and retrieval of local events from web pages. Examples of local events include small venue concerts, theater performances, garage sales, movie screenings, etc. We collect these events in the form of retrievable calendar entries that include structured information about event name, date, time and location. Between existing information extraction techniques and the availability of information on social media and semantic web technologies, there are numerous ways to collect commercial, high-profile events. However, most extraction techniques require domain-level supervision, which is not attainable at web scale. Similarly, while the adoption of the semantic web has grown, there will always be organizations without the resources or the expertise to add machine-readable annotations to their pages. Therefore, our approach bootstraps these explicit annotations to massively scale up local event extraction.\nWe propose a novel event extraction model that uses distant supervision to assign scores to individual event fields (event name, date, time and location) and a structural algorithm to optimally group these fields into event records. Our model integrates information from both the entire source document and its relevant sub-regions, and is highly scalable.\nWe evaluate our extraction model on all 700 million documents in a large publicly available web corpus, ClueWeb12. Using the 217,000 unique explicitly annotated events as distant supervision, we are able to double recall with 85% precision and quadruple it with 65% precision, with no additional human supervision. We also show that our model can be bootstrapped for a fully supervised approach, which can further improve the precision by 30%.\nIn addition, we evaluate the geographic coverage of the extracted events. We find that there is a significant increase in the geo-diversity of extracted events compared to existing explicit annotations, while maintaining high precision levels.", "references": ["M. D. Adelfio and H. Samet. Schema extraction for tabular data on the web. VLDB'13, 6(6):421--432, 2013.", "H. Becker. Identification and characterization of events in social media. PhD thesis, Columbia University, 2011.", "C. Bizer, K. Eckert, R. Meusel, H. Mühleisen, M. Schuhmacher, and J. Völker. Deployment of rDFa, microdata, and microformats on the web--A quantitative analysis. ISWC, pages 17--32, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767739"}, {"title": "Taming subgraph isomorphism for RDF query processing", "authors": ["Jinha Kim\n,", "Hyungyu Shin\n,", "Wook-Shin Han\n,", "Sungpack Hong\n,", "Hassan Chafi"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nRDF data are used to model knowledge in various areas such as life sciences, Semantic Web, bioinformatics, and social graphs. The size of real RDF data reaches billions of triples. This calls for a framework for efficiently processing RDF data. The core function of processing RDF data is subgraph pattern matching. There have been two completely different directions for supporting efficient subgraph pattern matching. One direction is to develop specialized RDF query processing engines exploiting the properties of RDF data for the last decade, while the other direction is to develop efficient subgraph isomorphism algorithms for general, labeled graphs for over 30 years. Although both directions have a similar goal (i.e., finding subgraphs in data graphs for a given query graph), they have been independently researched without clear reason. We argue that a subgraph isomorphism algorithm can be easily modified to handle the graph homomorphism, which is the RDF pattern matching semantics, by just removing the injectivity constraint. In this paper, based on the state-of-the-art subgraph isomorphism algorithm, we propose an in-memory solution, TurboHOM++, which is tamed for the RDF processing, and we compare it with the representative RDF processing engines for several RDF benchmarks in a server machine where billions of triples can be loaded in memory. In order to speed up TurboHOM++, we also provide a simple yet effective transformation and a series of optimization techniques. Extensive experiments using several RDF benchmarks show that TurboHOM++ consistently and significantly outperforms the representative RDF engines. Specifically, TurboHOM++ outperforms its competitors by up to five orders of magnitude.", "references": ["D. J. Abadi et al. Sw-store: A vertically partitioned dbms for semantic web data management. The VLDB Journal, 385--406, 2009.", "M. Atre et al. Matrix \"bit\" loaded: A scalable lightweight join query processor for rdf data. In WWW '10, 41--50.", "C. Bizer and A. Schultz. The berlin sparql benchmark. International Journal on Semantic Web and Information Systems (IJSWIS), 1--24, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2809974.2809985"}, {"title": "Time-Aware Authorship Attribution for Short Text Streams", "authors": ["Hosein Azarbonyad\n,", "Mostafa Dehghani\n,", "Maarten Marx\n,", "Jaap Kamps"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIdentifying authors of short texts on Internet or social media based communication systems is an important tool against fraud and cybercrimes. Besides the challenges raised by the limited length of these short messages, evolving language and writing styles of authors of these texts makes authorship attribution difficult. Most current short text authorship attribution approaches only address the challenge of limited text length. However, neglecting the second challenge may lead to poor performance of authorship attribution for authors who change their writing styles.\nIn this paper, we analyse the temporal changes of word usage by authors of tweets and emails and based on this analysis we propose an approach to estimate the dynamicity of authors' word usage. The proposed approach is inspired by time-aware language models and can be employed in any time-unaware authorship attribution method. Our experiments on Tweets and the Enron email dataset show that the proposed time-aware authorship attribution approach significantly outperforms baselines that neglect the dynamicity of authors.", "references": ["G. Frantzeskou, E. Stamatatos, S. Gritzalis, C. E. Chaski, and B. S. Howald. Identifying authorship by byte-level n-grams: The source code author profile (SCAP) method. IJDE, 6(1), 2007.", "N. Kanhabua and K. Nørvåg. A comparison of time-aware ranking methods. SIGIR '11, pages 1257--1258, 2011.", "B. Klimt and Y. Yang. The enron corpus: A new dataset for email classification research. In ECML'04, pages 217--226, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767799"}, {"title": "Empowering Exploratory Search on Linked Movie Open Data with Semantic Technologies", "authors": ["Thi-Nhu Nguyen\n,", "Duy-Thanh Dinh\n,", "Tuan-Dung Cao"], "publication": "SoICT 2015: Proceedings of the Sixth International Symposium on Information and Communication Technology", "abstract": "ABSTRACT\nNowadays, Linked Open Data (LOD) has grown rapidly to become large open datasets defined by RDF standards. Thanks to development of Data Web, the information on LOD is increasingly deeper, larger and easier to link in multi-domains, constituting the Linked Open Data cloud. Recently end-users applications using linked data sources as background knowledge appeared [15]. Thus, the exploitation of information on LOD effectively brings tremendous values as well as challenges. Meanwhile, Exploratory Search (ES) describes information-seeking processes that are opportunistic, iterative, and multi-tactical [7]. Furthermore, systems based on ES capitalize on new technological capabilities and interface paradigms that facilitate an increased level of interaction with information. In this paper, we present a method on searching and recommending information to empower exploratory search with semantic technologies. Our aim is to use algorithms with incorporation of structured semantics in search to give users the best related-semantic results and enhance users' interactions. We have exploited the data within LinkedMDB1 to support users in finding some information in the movie domain.", "references": ["A. Passant,. 2010. dbrec -- music recommendations using dbpedia. ISWC 2010", "André Freitas, João Gabriel Oliveira, Edward Curry, Seán O'Riain, and João Carlos Pereira da Silva, \"Treo: Combining Entity-Search, Spreading Activation and Semantic Relatedness for Querying Linked Data\", Digital Enterprise Research Institute (DERI). http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.417.8446", "Bastian Quilitz, Ulf Leser, \"Querying Distributed RDF Data Sources with SPARQL\", The Semantic Web: Research and Applications Lecture Notes in Computer Science Volume 5021, 2008, pp 524--538"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833258.2833283"}, {"title": "OSMRec Tool for Automatic Recommendation of Categories on Spatial Entities in OpenStreetMap", "authors": ["Nikos Karagiannakis\n,", "Giorgos Giannopoulos\n,", "Dimitrios Skoutas\n,", "Spiros Athanasiou"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this demonstration, we present OSMRec, a command line utility and JOSM plugin for automatic recommendation of tags (categories) on newly created spatial entities in OpenStreetMap (OSM). JOSM allows downloading parts of OSM, editing the map (e.g. inserting, deleting, annotating with tags spatial entities) and re-uploading the updated part back on OSM. OSMRec plugin exploits already annotated entities within OSM to train category classification models and utilizes these models in order to recommend OSM categories for newly inserted spatial entities in OSM.", "references": ["Jilani, M. and Corcoran, P. and Bertolotto, M. Automated Highway Tag Assessment of OpenStreetMap Road Networks. In Proceedings of SIGSPATIAL'14, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796555"}, {"title": "Exploiting Multimodal Affect and Semantics to Identify Politically Persuasive Web Videos", "authors": ["Behjat Siddiquie\n,", "Dave Chisholm\n,", "Ajay Divakaran"], "publication": "ICMI '15: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nWe introduce the task of automatically classifying politically persuasive web videos and propose a highly effective multi-modal approach for this task. We extract audio, visual, and textual features that attempt to capture affect and semantics in the audio-visual content and sentiment in the viewers' comments. We demonstrate that each of the feature modalities can be used to classify politically persuasive content, and that fusing them leads to the best performance. We also perform experiments to examine human accuracy and inter-coder reliability for this task and show that our best automatic classifier slightly outperforms average human performance. Finally we show that politically persuasive videos generate more strongly negative viewer comments than non-persuasive videos and analyze how affective content can be used to predict viewer reactions.", "references": ["A. Abbasi. Affect intensity analysis of dark web forums. Intelligence and Security Informatics, IEEE, 2007.", "R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Susstrunk. Slic superpixels compared to state-of-the-art superpixel methods. In IEEE PAMI, 2012.", "M. R. Amer, B. Siddiquie, S. Khan, A. Divakaran, and H. Sawhney. Multimodal fusion using dynamic hybrid models. WACV, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818346.2820732"}, {"title": "Using Business Intelligence to Support Strategic Sustainability Information Management", "authors": ["Ross Haupt\n,", "Brenda Scholtz\n,", "Andre Calitz"], "publication": "SAICSIT '15: Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists", "abstract": "ABSTRACT\nThe concept of sustainability has become an important phenomenon globally with many organisations being affected by the heightened awareness in sustainability. Organisations are more aware of the importance of promoting sustainability in all areas of operations. This is no different in the higher education sector, with a number of Higher Education Institutions (HEIs) playing a leading role in promoting sustainable initiatives. Effectively managing these initiatives however can be a complex task and requires data and information from multiple aspects of operations. In an HEI, operating sustainably means ensuring financial sustainability, social sustainability, environmental sustainability and educational sustainability. In order to manage sustainability effectively, HEIs require an integrated tool that can provide information on all areas of sustainability.\nThis paper highlights the importance of effectively managing sustainability information and the challenges HEIs face in sustainability reporting. Business Intelligence (BI) is a solution to overcome the challenges and effectively managing sustainability information. However, HEIs need to overcome a number of challenges associated with BI to ensure a BI solution is correctly implemented and is effective in solving the problem of effective sustainability information management. This study focusses on the management of sustainability information in South African HEIs. The results indicate that there are many challenges to managing sustainability information in South African HEIs, including siloed data and information as well as poor sharing and communication of information. These two challenges can be overcome by a correctly implemented BI solution.", "references": ["Abdelfattah, M. 2013. A Comparison of Several Performance Dashboards Architectures. Intelligent Information Management. 05, (March 2013), 35--41.", "Adams, C. 2013. Sustainability reporting and performance management in universities: Challenges and benefits. Sustainability Accounting, Management and Policy Journal. 4, 384--392.", "Analytics8 2010. Business Intelligence Project Management 101."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815782.2815795"}, {"title": "Contextualizing Data on a Content Management System", "authors": ["Cátia Moreira\n,", "João Taborda\n,", "Rosa Del Gaudio\n,", "Lara dos Santos\n,", "Paulo Pereira"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nContent Management Systems (CMSs) are known for their ability for storing data, both structured and non-structured data. However they are not able to associate meaning and context to the stored information. Furthermore, these systems do not meet the needs and expectations of their users, because as the size of data increases, the system loses its capacity of retrieving meaningful results.\nIn order to overcome this issue, we propose a method to implement data contextualization on a CMS. The proposed method consists of enriching the data with semantic information, allowing a more accurate retrieval of results. The implementation of this approach was validated by applying this contextualization method to a currently used CMS with real information. With this improved CMS, it is expected that the users will be able to retrieve data related to their initial search.", "references": ["J. J. Carroll and P. Stickler. RDF Triples in XML. In Proceedings of the 13th International World Wide Web Conference on Alternate Track Papers & Posters, WWW Alt. '04, pages 412--413, New York, NY, USA, 2004. ACM.", "M. R. Ghorab, D. Zhou, A. O'Connor, and V. Wade. Personalised Information Retrieval: survey and classification. User Modeling and User-Adapted Interaction, 23(4):381--443, May 2012.", "G. Klyne and J. J. Carroll. Resource Description Framework (RDF): Concepts and Abstract Syntax. Technical report."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810134"}, {"title": "Bandwagon Effect in Facebook Discussion Groups", "authors": ["Keith C. Wang\n,", "Chun-Ming Lai\n,", "Teng Wang\n,", "S. Felix Wu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nA core issue in online social networks is identifying content that will result in greater traffic and interaction. In this paper we use a large Facebook dataset and the concepts of bandwagon effect and information cascade from the field of communications to predict a post's life cycle without analyzing its content. Results from two models indicate evidence of (a) both factors being found on most discussion pages and (b) both factors having predictive power regarding the final number of participants in a post. To test for the bandwagon effect, we designed a system to predict article lifecycles, and found that for most Facebook pages, such predictions can be made within 30 minutes. We offer our data and analysis in support of a better understanding of the linkage between online social media research and journalism/information science theory, one that facilitates accurate predictions regarding posts that attract strong interest.", "references": ["V. Allen. Situational factors in conformity. Advances in experimental social psychology, 2:133--175, 1966.", "S. Asch. Social psychology. Prentice-Hall, 1952.", "S. Bikhchandani, D. Hirshleifer, and I. Welch. A theory of fads, fashion, custom, and cultural change as informational cascades. Journal of political Economy, pages 992--1026, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818914"}, {"title": "Reachability based Ranking in Interactive Image Retrieval", "authors": ["Jiyi Li"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn some interactive image retrieval systems, users can select images from image search results and click to view their similar or related images until they reach the targets. Existing image ranking options are based on relevance, update time, interestingness and so on. Because the inexact description of user targets or unsatisfying performance of image retrieval methods, it is possible that users cannot reach their targets in single-round interaction. When we consider multi-round interactions, how to assist users to select the images that are easier to reach the targets in fewer rounds is a useful issue. In this paper, we propose a new kind of ranking option to users by ranking the images according to their difficulties of reaching potential targets. We model the interactive image search behavior as navigation on information network constructed by an image collection and an image retrieval method. We use the properties of this information network for reachability based ranking. Experiments based on a social image collection show the efficiency of our approach.", "references": ["R. Datta, D. Joshi, J. Li, and J.Z. Wang. Image retrieval: Ideas, influences, and trends of the new age. ACM Computing Surveys (CSUR), 40(2):1--60, 2008.", "Y. Rui, T.S. Huang, M. Ortega, and S. Mehrotra. Relevance feedback: a power tool for interactive content-based image retrieval. IEEE Trans. on CSVT, 8(5):644--655, 1998.", "K. Porkaew, S. Mehrotra, and M. Ortega. Query reformulation for content based multimedia retrieval in MARS. In ICMCS'99, pp. 747--751, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767777"}, {"title": "Dynamic Information Retrieval: Theoretical Framework and Application", "authors": ["Marc Sloan\n,", "Jun Wang"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nTheoretical frameworks like the Probability Ranking Principle and its more recent Interactive Information Retrieval variant have guided the development of ranking and retrieval algorithms for decades, yet they are not capable of helping us model problems in Dynamic Information Retrieval which exhibit the following three properties; an observable user signal, retrieval over multiple stages and an overall search intent. In this paper a new theoretical framework for retrieval in these scenarios is proposed. We derive a general dynamic utility function for optimizing over these types of tasks, that takes into account the utility of each stage and the probability of observing user feedback. We apply our framework to experiments over TREC data in the dynamic multi page search scenario as a practical demonstration of its effectiveness and to frame the discussion of its use, its limitations and to compare it against the existing frameworks.", "references": ["Agrawal, R., Gollapudi, S., Halverson, A., and Ieong, S. Diversifying search results. WSDM '09, ACM, pp. 5--14.", "Azzopardi, L. Modelling interaction with economic models of search. SIGIR '14, ACM, pp. 3--12.", "Bellman, R. E. Dynamic Programming. Dover Publications, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809457"}, {"title": "Improving Diversity in Image Search via Supervised Relevance Scoring", "authors": ["Eleftherios Spyromitros-Xioufis\n,", "Symeon Papadopoulos\n,", "Alexandru Lucian Ginsca\n,", "Adrian Popescu\n,", "Yiannis Kompatsiaris\n,", "Ioannis Vlahavas"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nResults returned by commercial image search engines should include relevant and diversified depictions of queries in order to ensure good coverage of users' information needs. While relevance has drastically improved in recent years, diversity is still an open problem. In this paper we propose a reranking method that could be implemented on top of such engines in order to provide a better balance between relevance and diversity. Our method formulates the reranking problem as an optimization of a utility function that jointly considers relevance and diversity. Our main contribution is the replacement of the unsupervised definition of relevance that is commonly used in this formulation with a supervised classification model that strives to capture a query and application-specific notion of relevance. This model provides more accurate relevance scores that lead to significantly improved diversification performance. Furthermore, we propose a stacking-type ensemble learning approach that allows combining multiple features in a principled way when computing the relevance of an image. An empirical evaluation carried out on the datasets of the MediaEval 2013 and 2014 \"Retrieving Diverse Social Images\" (RDSI) benchmarks confirms the superior performance of the proposed method compared to other participating systems as well as a state-of-the-art, unsupervised reranking method.", "references": ["T. Arni, P. Clough, M. Sanderson, and M. Grubinger. Overview of the imageclefphoto 2008 photographic retrieval task. In Evaluating Systems for Multilingual and Multimodal Information Access, pages 500--511. 2009.", "A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky. Neural codes for image retrieval. In ECCV, 2014.", "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In SIGIR, pages 335--336, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749334"}, {"title": "Utilizing Non-QA Data to Improve Questions Routing for Users with Low QA Activity in CQA", "authors": ["Ivan Srba\n,", "Marek Grznar\n,", "Maria Bielikova"], "publication": "ASONAM '15: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015", "abstract": "ABSTRACT\nCommunity Question Answering (CQA) systems, such as Yahoo! Answers and Stack Overflow, represent a well-known example of collective intelligence. The existing CQA systems, despite their overall successfulness and popularity, fail to answer a significant amount of questions in required time. One option for scaffolding collaboration in CQA systems is a recommendation of new questions to users who are suitable candidates for providing correct answers (so called question routing). Various methods have been proposed so far to find appropriate answerers, but almost all approaches heavily depend on previous users' activities in a particular CQA system (i.e. QA-data). In our work, we attempt to involve a whole community including users with no or minimal previous activity (e.g. newcomers or lurkers). We proposed a question routing method which analyses users' non-QA data from a CQA system itself as well as from external services and platforms, such as blogs, microblogs or social networking sites, in order to estimate users' interests and expertise early and more precisely. Consequently, we can recommend new questions to a wider part of a community as well as more accurately. Evaluation on a dataset from Stack Exchange platform showed that considering non-QA data leads not only to better recognition of users with low activity as suitable answerers, but also to higher overall precision of the recommendations. It implies that non-QA data can supplement QA data during expertise estimation in question routing and thus also improve a success rate of a questions answering process.", "references": ["Q. Liu, E. Agichtein, G. Dror, Y. Maarek, and I. Szpektor, \"When web search fails, searchers become askers,\" in Proc. of the 35th int. ACM SIGIR Conf. on Research and Development in Information Retrieval - SIGIR '12, 2012, pp. 801--810.", "B. Li and I. King, \"Routing questions to appropriate answerers in community question answering services,\" in Proc. of the 19th ACM Int. Conf. on Inf. and Knowl. Management - CIKM '10, 2010, pp. 1585--1588.", "T. C. Zhou, M. R. Lyu, and I. King, \"A classification-based approach to question routing in community question answering,\" in Proc. of the 21st Int. Conf. Comp. on World Wide Web - WWW '12, 2012, pp. 783--790."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808797.2809331"}, {"title": "The SHARC framework: utilizing personal dropbox accounts to provide a scalable solution to the storage and sharing of community generated locative media", "authors": ["Trien V. Do\n,", "Keith Cheverst"], "publication": "EICS '15: Proceedings of the 7th ACM SIGCHI Symposium on Engineering Interactive Computing Systems", "abstract": "ABSTRACT\nThe emergence of personal cloud storage services provides a new paradigm for storing and sharing data. In this paper we present the design of the SHARC framework and in particular focus on the utilization of personal Dropbox accounts to provide a scalable solution to the storage and sharing of community generated locative media relating to a community's Cultural Heritage. In addition to scalability issues, the utilization of personal Dropbox storage also supports 'sense of ownership' (relating to community media) which has arisen as an important requirement during our on-going 'research-in-the-wild' working with the rural village community of Wray and involving public display deployments to support the display and sharing of community photos and stories. While the framework presented here is currently being tested with a particular place-based community (Wray), it has been designed to provide a general solution that should support other place-based communities.", "references": ["AudioMountain. Audio file size calculations. http://www.audiomountain.com/tech/audio-file-size.html (Accessed May 2015).", "Balestrini, M., Bird, J., Marshall, P., Zaro, A., and Rogers, Y. Understanding sustained community engagement: a case study in heritage preservation in rural Argentina. Proc. CHI 2014, ACM Press (2014).", "Butchart, B., Pope, A., King, M., Hamilton, G., Terzis, P., and Koutroumpas, M. Fieldtrip GB: Creating a customisable mapping and data capture app for the HEFE community. GISUK 2013, (2013)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2774225.2774841"}, {"title": "Better Health Explorer: Designing for Health Information Seekers", "authors": ["Patrick Cheong-Iao Pang\n,", "Karin Verspoor\n,", "Jon Pearce\n,", "Shanton Chang"], "publication": "OzCHI '15: Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction", "abstract": "ABSTRACT\nA vast amount of health information has been published online, yet users often report difficulties in locating information in this particular domain. Based on our prior research, we consider four categories of online health information seekers who demonstrate mixed information needs. Although their searching needs are often well satisfied by entering keywords into search engines, their need to explore information is not so well supported, thus affecting their user experience and satisfaction. In this paper, we propose design principles for supporting the exploration of online health information. We present the rationale and the design process of a web app -- Better Health Explorer -- which is a proof-of-concept app tailored to health information exploration. This work contributes to the design of online health information systems as well as exploratory systems in general.", "references": ["Alhenshiri, A., Watters, C., Shepherd, M. and Duffy, J. Information gathering tasks on the Web: Attempting to identify the user search behaviour. In Proc. WEBIST 2012, LNBIP 140 (2013).", "Alzougool, B., Chang, S. and Gray, K. Towards a comprehensive understanding of health information needs. electronic Journal of Health Informatics, 3, 2 (2008).", "Alzougool, B., Chang, S. and Gray, K. The nature and constitution of informal carers' information needs: What you don't know you need is as important as what you want to know. information Research, 18, 1 (2013)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838739.2838772"}, {"title": "From Queries to Cards: Re-ranking Proactive Card Recommendations Based on Reactive Search History", "authors": ["Milad Shokouhi\n,", "Qi Guo"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe growing accessibility of mobile devices has substantially reformed the way users access information. While the reactive search by query remains as common as before, recent years have witnessed the emergence of various proactive systems such as Google Now and Microsoft Cortana. In these systems, relevant content is presented to users based on their context without a query. Interestingly, despite the increasing popularity of such services, there is very little known about how users interact with them.\nIn this paper, we present the first study on user interactions with information cards. We demonstrate that the usage patterns of these cards vary depending on time and location. We also show that while overall different topics are clicked by users on proactive and reactive platforms, the topics of the clicked documents by the same user tend to be consistent cross-platform. Furthermore, we propose a supervised framework for re-ranking proactive cards based on the user's context and past history. To train our models, we use the viewport duration and clicks to infer pseudo-relevance labels for the cards. Our results suggest that the quality of card ranking can be significantly improved particularly when the user's reactive search history is %leveraged and matched against the proactive data about the cards.", "references": ["Google, Inside AdWords. http://bit.ly/1JrajCg/. Accessed: 2015-05--14.", "Cortana - Microsoft - USA. http://www.microsoft.com/en-us/mobile/campaign-cortana/. Accessed: 2015-05--14.", "DMOZ - the Open Directory Project. http://www.dmoz.org/. Accessed: 2015-05--14."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767705"}, {"title": "UCUI'15: The 1st International Workshop on Understanding the City with Urban Informatics", "authors": ["Yashar Moshfeghi\n,", "Iadh Ounis\n,", "Craig Macdonald\n,", "Joemon M. Jose\n,", "Peter Triantafillou\n,", "Mark Livingston\n,", "Piyushimita Thakuriah"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUrban Informatics aims to exploit the large quantities of information produced by modern cities in order to gain insights into how they function. These insights lay the foundation for improving the lives of citizens, by improving the efficacy and efficiency of public services, and satisfying complex information needs arising within this context. The goal of the workshop is to provide a multidisciplinary forum which brings together researchers in Big Data (BD), Information Retrieval (IR), Data Mining, and Urban Studies, to explore novel solutions to the numerous theoretical, practical and ethical challenges arising in this context. These include difficulties in collecting city data, creating data management infrastructures, and providing new effective and efficient information access techniques to as many users as possible in the context of a smart city. To foster the development of new BD and IR approaches in Urban Informatics, the workshop makes available a representative dataset of city data, including Internet-based visual (Flickr) and textual (Tweets and News) media collections. The workshop provides enormous opportunities for data scientists who wish to understand the complexities of working with city data, conduct innovative research within Urban Informatics, and build a long-term community in this emerging research area.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806878"}, {"title": "Cold-Start Item and User Recommendation with Decoupled Completion and Transduction", "authors": ["Iman Barjasteh\n,", "Rana Forsati\n,", "Farzan Masrour\n,", "Abdol-Hossein Esfahanian\n,", "Hayder Radha"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nA major challenge in collaborative filtering based recommender systems is how to provide recommendations when rating data is sparse or entirely missing for a subset of users or items, commonly known as the cold-start problem. In recent years, there has been considerable interest in developing new solutions that address the cold-start problem. These solutions are mainly based on the idea of exploiting other sources of information to compensate for the lack of rating data. In this paper, we propose a novel algorithmic framework based on matrix factorization that simultaneously exploits the similarity information among users and items to alleviate the cold-start problem. In contrast to existing methods, the proposed algorithm decouples the following two aspects of the cold-start problem: (a) the completion of a rating sub-matrix, which is generated by excluding cold-start users and items from the original rating matrix; and (b) the transduction of knowledge from existing ratings to cold-start items/users using side information. This crucial difference significantly boosts the performance when appropriate side information is incorporated. We provide theoretical guarantees on the estimation error of the proposed two-stage algorithm based on the richness of similarity information in capturing the rating data. To the best of our knowledge, this is the first algorithm that addresses the cold-start problem with provable guarantees. We also conduct thorough experiments on synthetic and real datasets that demonstrate the effectiveness of the proposed algorithm and highlights the usefulness of auxiliary information in dealing with both cold-start users and items.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734--749, 2005.", "Gediminas Adomavicius and Alexander Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6), 2005.", "Jian-Feng Cai, Emmanuel J Candès, and Zuowei Shen. A singular value thresholding algorithm for matrix completion. SIAM Journal on Optimization, 20(4):1956--1982, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800196"}, {"title": "Semantic Topic-based Hybrid Learning Resource Recommendation", "authors": ["Lei Liu"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nRecommending learning resources to help readers understand any portion of the reading content where they have difficulty to understand is an useful and important task. Treating the whole unclear passage as the query and submit it to a search engine is unsuccessful since existing search engines were designed to accept small queries. In addition, as search engines usually transform the query and candidate resources into bags or vectors of words, the semantic topics underlying the content are totally overlooked. We believe that topics offer a better choice for truly understanding both the query and the candidate documents. In this paper, we propose a novel recommendation system for text content that facilitates the learning process by enabling search using as queries text passages of any length and retrieving a ranked list of resources (documents, videos, etc) that match the different topics covered within the selected passage. The recommended resources are ranked based on two criteria (a) how they match the different topics covered within the selected passage, and (b) the reading complexity level of the original text where the selected passage comes from. Our recommendation system has been built and being pilot from local universities and high schools, the user feedbacks from students who use our system in pilots for their courses suggest that our system is promising and effective. Beside this, we also provide a quantitative experimental evaluation, the results show that our proposed approach is promising and effective.", "references": ["J. P. Callan. Passage-level evidence in document retrieval. In 17th Annual ACM-SIGIR conference, 1994.", "J. S. Chall. Readability revisited: The new dale-chall readability formula. Brookline Books/Lumen Editions, 1995.", "P. M. Comar, L. Liu, S. Saha, P.-N. Tan, and A. Nucci. Weighted linear kernel with tree transformed features for malware detection. In CIKM'12, pages 2287--2290, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809941"}, {"title": "OverLay: Practical Mobile Augmented Reality", "authors": ["Puneet Jain\n,", "Justin Manweiler\n,", "Romit Roy Choudhury"], "publication": "MobiSys '15: Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services", "abstract": "ABSTRACT\nThe idea of augmented reality - the ability to look at a physical object through a camera and view annotations about the object - is certainly not new. Yet, this apparently feasible vision has not yet materialized into a precise, fast, and comprehensively usable system. This paper asks: What does it take to enable augmented reality (AR) on smartphones today? To build a ready-to-use mobile AR system, we adopt a top-down approach cutting across smartphone sensing, computer vision, cloud offloading, and linear optimization. Our core contribution is in a novel location-free geometric representation of the environment - from smartphone sensors - and using this geometry to prune down the visual search space. Metrics of success include both accuracy and latency of object identification, coupled with the ease of use and scalability in uncontrolled environments. Our converged system, OverLay, is currently deployed in the engineering building and open for use to regular public; ongoing work is focussed on campus-wide deployment to serve as a \"historical tour guide\" of UIUC. Performance results and user responses thus far have been promising, to say the least.", "references": ["Amazon fire phone. https://developer.amazon.com/public/solutions/devices/fire-phone.", "Google goggles. https://play.google.com/store/apps/details?id=com.google.android.apps.unveil&hl=en.", "Illinois distributed museum. http://distributedmuseum.blogspot.com/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742647.2742666"}, {"title": "Everything is Filed under 'File': Conceptual Challenges in Applying Semantic Search to Network Shares for Collaborative Work", "authors": ["Dirk Ahlers\n,", "Mahsa Mehrpoor"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nLots of professional collaborative work relies on shared networked file systems for easy collaboration, documentation, and as a joint workspace. We have found that in an engineering setting with tens of thousands of files, usual desktop search does not work as well, especially if the project space is huge, contains a large number of non-textual files that are difficult to search for, and is partially unknown by the users due to information needs reaching into previous years or projects.\nWe therefore propose an approach that joins content and metadata analysis, link derivation, grouping, and other measures to arrive at high-level features suitable for semantic similarity and retrieval to improve information access for this case of professional search.", "references": ["D. Ahlers and M. Mehrpoor. Semantic social recommendations in knowledge-based engineering. In Social Personalization Workshop 2014. CEUR, 2014.", "D. Bhagwat and N. Polyzotis. Searching a File System Using Inferred Semantic Links. Hypertext '05, 2005.", "O. Eck and D. Schaefer. A semantic file system for integrated product data management. Advanced Engineering Informatics, 25(2), 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791046"}, {"title": "Evaluating Retrieval Models through Histogram Analysis", "authors": ["Kriste Krstovski\n,", "David A. Smith\n,", "Michael J. Kurtz"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present a novel approach for efficiently evaluating the performance of retrieval models and introduce two evaluation metrics: Distributional Overlap (DO), which compares the clustering of scores of relevant and non-relevant documents, and Histogram Slope Analysis (HSA), which examines the log of the empirical distributions of relevant and non-relevant documents. Unlike rank evaluation metrics such as mean average precision (MAP) and normalized discounted cumulative gain (NDCG), DO and HSA only require calculating model scores of queries and a fixed sample of relevant and non-relevant documents rather than scoring the entire collection, even implicitly by means of an inverted index. In experimental meta-evaluations, we find that HSA achieves high correlation with MAP and NDCG on a monolingual and a cross-language document similarity task; on four ad-hoc web retrieval tasks; and on an analysis of ten TREC tasks from the past ten years. In addition, when evaluating latent Dirichlet allocation (LDA) models on document similarity tasks, HSA achieves better correlation with MAP and NCDG than perplexity, an intrinsic metric widely used with topic models.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. JMLR, 3: 993--1022, 2003.", "W. Croft. A model of cluster searching based on classification. Information Systems, 5 (3): 189--195, 1980.", "N. Jardine and C. J. van Rijsbergen. The use of hierarchical clustering in information retrieval. Information Storage and Retrieval, 7: 217--240, 1971."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767821"}, {"title": "Identifying Duplicate and Contradictory Information in Wikipedia", "authors": ["Sarah Weissman\n,", "Samet Ayhan\n,", "Joshua Bradley\n,", "Jimmy Lin"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIn this paper, we identify sentences in Wikipedia articles that are either identical or highly similar by applying techniques for near-duplicate detection of web pages. This is accomplished with a MapReduce implementation of minhash to identify sentences with high Jaccard similarity, followed by a pass to generate sentence clusters. Based on manual examination, we discovered that these clusters can be categorized into six different types: templates, identical sentences, copyediting, factual drift, references, and other. Two of these categories are particularly interesting: identical sentences quantify the extent to which content in Wikipedia is copied and pasted, and near-duplicate sentences that state contradictory facts point to quality issues in Wikipedia.", "references": ["R. J. Bayardo, Y. Ma, and R. Srikant. Scaling up all pairs similarity search. WWW, 2007.", "M. Bendersky and W. B. Croft. Finding text reuse on the web. WSDM, 200", "A. Z. Broder. On the resemblance and containment of documents. Compression and Complexity of Sequences, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756947"}, {"title": "Multilayer Formats and the Semantic Web: a Music Case Study", "authors": ["Adriano Baratè\n,", "Goffredo Haus\n,", "Luca A. Ludovico"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThe advent of the so-called Semantic Web led to the transformation of the World Wide Web into an environment where documents are associated with data and metadata. The latter kind of information specifies the semantic context of datain a format suitable to be queried and interpreted in an automatic way. Extensible Markup Language (XML) is extensively used in the Semantic Web, since this format supports not only human- but also machine-readable tags. On the one side the Semantic Web aims to create a set of automatically-detectable relationships among data, thus providing users with a number of non-trivial paths to navigate information in a geographically distributed framework. On the other side, multilayer formats typically operate in a similar way, but at a \"local\" level. In this case, information is contained, hierarchically structured and interconnected within a single document. Also in this context XML is extensively adopted. The goal of the present work is to discuss the possibilities emerging from a combined approach, namely by adopting multilayer formats in the Semantic Web, addressing in particular augmented-reality applications. From this point of view, an XML-based international standard known as IEEE 1599 will be employed to show a number of innovative applications in music.", "references": ["S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. Springer, 2007.", "D. Baggi and G. Haus. IEEE 1599: Music encoding and interaction. Computer, 3(42):84--87, 2009.", "D. L. Baggi and G. M. Haus. Music Navigation with Symbols and Layers: Toward Content Browsing with IEEE 1599 XML Encoding. John Wiley & Sons, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814910"}, {"title": "Implicit Preference Labels for Learning Highly Selective Personalized Rankers", "authors": ["Paul N. Bennett\n,", "Milad Shokouhi\n,", "Rich Caruana"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nInteraction data such as clicks and dwells provide valuable signals for learning and evaluating personalized models. However, while models of personalization typically distinguish between clicked and non-clicked results, no preference distinctions within the non-clicked results are made and all are treated as equally non-relevant.\nIn this paper, we demonstrate that failing to enforce a prior on preferences among non-clicked results leads to learning models that often personalize with no measurable gain at the risk that the personalized ranking is worse than the non-personalized ranking. To address this, we develop an implicit preference-based framework that enables learning highly selective rankers that yield large reductions in risk such as the percentage of queries personalized. We demonstrate theoretically how our framework can be derived from a small number of basic axioms that give rise to well-founded target rankings which combine a weight on prior preferences with the implicit preferences inferred from behavioral data.\nAdditionally, we conduct an empirical analysis to demonstrate that models learned with this approach yield comparable gains on click-based performance measures to standard methods with far fewer queries personalized. On three real-world commercial search engine logs, the method leads to substantial reductions in the number of queries re-ranked (2x - 7x fewer queries re-ranked) while maintaining 85-95% of the total gain achieved by the standard approach.", "references": ["E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. In Proc. SIGIR, 2006.", "E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In Proc. SIGIR, 2006.", "P. Bennett et al. Modeling the impact of short- and long-term behavior on search personalization. In Proc. SIGIR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809464"}, {"title": "Visual Search at Pinterest", "authors": ["Yushi Jing\n,", "David Liu\n,", "Dmitry Kislyuk\n,", "Andrew Zhai\n,", "Jiajing Xu\n,", "Jeff Donahue\n,", "Sarah Tavel"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWe demonstrate that, with the availability of distributed computation platforms such as Amazon Web Services and open-source tools, it is possible for a small engineering team to build, launch and maintain a cost-effective, large-scale visual search system. We also demonstrate, through a comprehensive set of live experiments at Pinterest, that content recommendation powered by visual search improves user engagement. By sharing our implementation details and learnings from launching a commercial visual search engine from scratch, we hope visual search becomes more widely incorporated into today's commercial applications.", "references": ["S. Bengio, J. Dean, D. Erhan, E. Ie, Q. V. Le, A. Rabinovich, J. Shlens, and Y. Singer. Using web co-occurrence statistics for improving image categorization. CoRR, abs/1312.5697, 2013.", "T. L. Berg, A. C. Berg, J. Edwards, M. Maire, R. White, Y.-W. Teh, E. Learned-Miller, and D. A. Forsyth. Names and faces in the news. In Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR), pages 848--854, 2004.", "K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In British Machine Vision Conference, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788621"}, {"title": "5e{x+y}: Searching over Mathematical Content in Digital Libraries", "authors": ["Arthur Oviedo\n,", "Nikos Kasioumis\n,", "Karl Aberer"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis paper presents 5ex+y, a system that is able to extract, index and query mathematical content expressed as mathematical expressions, complementing the CERN Document Server (CDS). We present the most important aspects of its design, our approach to model the relevant features of the mathematical content, and provide a demonstration of its searching capabilities.", "references": ["Snuggletex (1.2.2). http://www2.ph.ed.ac.uk/snuggletex/documentation/overview-and-features.html.", "About cern, 2014. http://home.web.cern.ch/about.", "Apache solr/lucene., 2014. http://lucene.apache.org/solr."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756953"}, {"title": "From Web Search Relevance to Vertical Search Relevance", "authors": ["Yi Chang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search relevance is a billion dollar challenge, while there is a disadvantage of backwardness in web search competition. Vertical search result can be incorporated to enrich web search content, therefore vertical search relevance is critical to provide differentiated search results. Machine learning based ranking algorithms have shown their effectiveness for both web search and vertical search tasks. In this talk, the speaker will not only introduce state-of-the-art ranking algorithms for web search, but also cover the challenges to improve relevance of various vertical search engines: local search, shopping search, news search, etc.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776787"}, {"title": "Improving Patent Search by Search Result Diversification", "authors": ["Youngho Kim\n,", "W. Bruce Croft"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nPatent retrieval has some unique features relative to web search. One major task in this domain is finding existing patents that may invalidate new patents, known as prior-art or invalidity search, where search queries can be formulated from query patents (i.e., new patents). Since a patent document generally contains long and complex descriptions, generating effective search queries can be complex and difficult. Typically, these queries must cover diverse aspects of the new patent application in order to retrieve relevant documents that cover the full scope of the patent. Given this context, search diversification techniques can potentially improve the retrieval performance of patent search by introducing diversity into the document ranking. In this paper, we examine the effectiveness for patent search of a recent term-based diversification framework. Using this framework involves developing methods to identify effective phrases related to the topics mentioned in the query patent. In our experiments, we evaluate our diversification approach using standard measures of retrieval effectiveness and diversity, and show significant improvements relative to state-of-the-art baselines.", "references": ["Agrawal, R., Gollapudi, S., Halverson, A., and Leong, S. (2009). Diversifying search results. WSDM, 5--14.", "Bashir, S. and Rauber, A. (2010). Improving retrievability of patents in prior-art search. ECIR, 457--470.", "Carbonell, J., and Goldstein, J. (1998). The use of MMR, diversity-based reranking for reordering documents and producing summaries. SIGIR, 335--336."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809455"}, {"title": "Women's inclusion in digital Bangladesh", "authors": ["Jude William Genilo\n,", "Marium Akther\n,", "Monami Haque"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nThis study argues that enabling policy environments on ICT instituted by the Government of Bangladesh over the past six years may not have necessarily improved digital inclusion, particularly with respect to women. Rather, the digital inclusion of women is facilitated by both the individual's socio-demographic context (age, education and experience) and the citizenship status of her local community in ethnic and religious terms as well as its proximity to the capital. The study compares ICT access and usage among men and women in the ICT telecentres of purposively chosen villages. Field observations were conducted in the first village (Kapasia, Gazipur, Dhaka Division) from June to July 2014 and in the second village (Sharsha, Jessore, Khulna Division) from August to September 2014. Twenty men and women from each village were interviewed in-depth along with opinion and political leaders. Data analysis and interpretation are still ongoing.", "references": ["Davis, N. Y, and Werbner P. Women Citizenship and Difference, Zubaan, New Delhi, 2005.", "Digital Bangladesh and Gender equality, September 2009. Retrieved August 30, 2014, from Protifolon, 01 (02), Bangladesh Online Research Network: http://www.bdresearch.org/home/protifolon_02.pdf", "Gurstein, M. What is community informatics (and Why Does It Matter)? Polimetrica, Italy, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2737857"}, {"title": "Systematic Review on Computer Literacy", "authors": ["Marco Alberto Wang\n,", "Edmir Parada Vasques Prado"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis systematic review aims to consolidate the understanding of the term \"Computer Literacy\", which corresponds to the classification of the first stage of learning skills and knowledge about the aspects of information and communication technology (ICT). In addition to this concept, the study also aims to assess the range of knowledge and skills related to computer literacy. This review was based on ACM and ERIC research bases, comprising the period of the last 10 years, and adding some extra articles that were deemed relevant. The conclusion indicates that Computer Literacy has a dynamic nature - exhibiting evolution over time - and an inherent need to upgrade constantly in order to keep up with information and communication technology's evolutionary curve.", "references": ["Bartholomew, K. W. 2004. Computer literacy: is the emperor still exposed after all these years?. J. Comput. Sci. Coll., 323-331.", "Burd, B., Barros J., and Johnson, C. 2012. Educating for mobile computing: addressing the new challenges. Proceedings of the final reports on innovation and technology in computer science education 2012 working groups -- ITiCSE-WGR'12, (Haifa, Israel, July 3-5 2012), 51-63.", "CGI.BR. 2014. TIC: Domicílios e Empresas 2013. Núcleo de Informação e Coordenação do Ponto BR, São Paulo, 658."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814149"}, {"title": "A Web Metric Collection and Reporting System", "authors": ["Ruchika Malhotra\n,", "Anjali Sharma"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nThe web genre classification distinguishes between pages by means of their features such as style, presentation layout, etc rather than on the topic; improving search results returned to the user by providing genre class of a web page apart from topic. Hence, if a user is able to specify the genre of search like Help, FAQ, Wikipedia etc, chances of getting results in accordance to his interest are high. The classification of web pages into genre is a challenging task as the information is semi-structured, heterogeneous and dynamic. Therefore it is required to find appropriate features which describes web page in the context of genre to increase the genre classification and accuracy of the search result.\nIn this paper we propose a Metric Collection and Reporting System (MCRS) for Web Application, an automated tool designed to collect 126 significant attributes of web pages for genre identification. MCRS collects and reports important style, presentation layout, form, linguistic, lexical and meta-content features of web page. It collects 88 HTML tags metrics clustered in five groups namely Text formatting tags, Document Structure Tags, External object tags, instruction tags and Navigation Tags. MCRS also reports thirty-eight text metrics including punctuation metrics to describe the lexical attributes of the web page. The NLP module has also been integrated into the system to identify linguistic properties of the web content. The MRCS can be used in parallel with topic search to increase the quality of information retrieval through web genre identification.", "references": ["A. Kennedy and M. Shepherd, \"Cybergenre: Automatic Identification of Home Pages on the Web\" Journal of Web Engineering, Vol 3(4), pp. 236--251, 2004.", "M. Santini, \"Characterizing Genres of Web Pages: Genre Hybridism and Individualization,\" Proceedings of 40th Annual Hawaii International Conference System Science, pp. 71--71, 2007.", "B. Stein and S. Eissen, \"Retrieval models for genre classification\" Scand. Journal of Information Systems, Vol. 20, No. 1, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791561"}, {"title": "Semantic annotation of BPMN: current approaches and new methodologies", "authors": ["Beniamino Di Martino\n,", "Antonio Esposito\n,", "Stefania Nacchia\n,", "Salvatore Augusto Maisto"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nBusiness Process management has attracted the attention of companies and organizations, which have heavily invested in the research and development of tools and standards for process representation and business requirement formalization. Several tools have been produced for the representation and management of Business processes, and many companies have designed their enterprise models using business process standards. In this paper we analyse different approaches to enrich the existing standards, in particular the Business Process Model Notation (BPMN), with the semantic information provided by OWL ontologies. We also discuss the motivations behind the need of a semantic annotation for Business Processes and provide an overview of existing research efforts and results.", "references": ["SUPER - Semantics Utilized for Process management within and between EnteRprises [online],. http://projects.kmi.open.ac.uk/super/.", "T. Andrews, F. Curbera, H. Dholakia, Y. Goland, J. Klein, F. Leymann, K. Liu, D. Roller, D. Smith, S. Thatte, et al. Business process execution language for web services, 2003.", "C. Di Francescomarino and P. Tonella. Supporting ontology-based semantic annotation of business processes with automated suggestions. International Journal of Information System Modeling and Design (IJISMD), 1(2):59--84, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837257"}, {"title": "Introduction to the 2015 social media and society conference", "authors": ["Anatoliy Gruzd\n,", "Jenna Jacobson\n,", "Philip Mai\n,", "Barry Wellman"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nThe Social Media & Society Conference is an annual international gathering of leading social media researchers from around the world. Now, in its sixth year, the 2015 conference is being held in Toronto, Canada, on July 27-29. The conference's intensive three-day program provides 18 full papers, 78 work-in-progress papers, 5 panels, and 52 posters. The wide-ranging topics in social media showcase research from nearly 400 scholars from 28 different countries working in many fields.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789188"}, {"title": "DrillBeyond: processing multi-result open world SQL queries", "authors": ["Julian Eberius\n,", "Maik Thiele\n,", "Katrin Braunschweig\n,", "Wolfgang Lehner"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nIn a traditional relational database management system, queries can only be defined over attributes defined in the schema, but are guaranteed to give single, definitive answer structured exactly as specified in the query. In contrast, an information retrieval system allows the user to pose queries without knowledge of a schema, but the result will be a top-k list of possible answers, with no guarantees about the structure or content of the retrieved documents.\nIn this paper, we present DrillBeyond, a novel IR/RDBMS hybrid system, in which the user seamlessly queries a relational database together with a large corpus of tables extracted from a web crawl. The system allows full SQL queries over the relational database, but additionally allows the user to use arbitrary additional attributes in the query that need not to be defined in the schema. The system then processes this semi-specified query by computing a top-k list of possible query evaluations, each based on different candidate web data sources, thus mixing properties of RDBMS and IR systems.\nWe design a novel plan operator that encapsulates a web data retrieval and matching system and allows direct integration of such systems into relational query processing. We then present methods for efficiently processing multiple variants of a query, by producing plans that are optimized for large invariant intermediate results that can be reused between multiple query evaluations. We demonstrate the viability of the operator and our optimization strategies by implementing them in PostgreSQL and evaluating on a standard benchmark by adding arbitrary attributes to its queries.", "references": ["TPC Benchmark H. http://tpc.org/tpch, 2015.", "M. J. Cafarella, A. Halevy, and N. Khoussainova. Data integration for the relational web. VLDB, pages 1090--1101, 2009.", "A. Deshpande, Z. Ives, and V. Raman. Adaptive query processing. Found. Trends databases, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791370"}, {"title": "Misleading Online Content: Recognizing Clickbait as \"False News\"", "authors": ["Yimin Chen\n,", "Niall J. Conroy\n,", "Victoria L. Rubin"], "publication": "WMDD '15: Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection", "abstract": "ABSTRACT\nTabloid journalism is often criticized for its propensity for exaggeration, sensationalization, scare-mongering, and otherwise producing misleading and low quality news. As the news has moved online, a new form of tabloidization has emerged: ?clickbaiting.? ?Clickbait? refers to ?content whose main purpose is to attract attention and encourage visitors to click on a link to a particular web page? [?clickbait,? n.d.] and has been implicated in the rapid spread of rumor and misinformation online. This paper examines potential methods for the automatic detection of clickbait as a form of deception. Methods for recognizing both textual and non-textual clickbaiting cues are surveyed, leading to the suggestion that a hybrid approach may yield best results.", "references": ["Adler, B. (2014, Mar 11). Tabloids in the age of social media. Columbia Journalism Review. http://www.cjr.org/news_literacy/national_enquirer_hoffman _hoax.php", "Allen, M. (2015). How click bait articles work http://www.thepinchandzoom.com/blog/2015/5/2/clickbait#sthash.MGkHil5p.dpuf", "An emerging science of clickbait. (2015, Mar 25). MIT Review. http://www.technologyreview.com/view/536161/anemerging- science-of-clickbait"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2823465.2823467"}, {"title": "Analyzing Crowd Rankings", "authors": ["Julia Stoyanovich\n,", "Marie Jacob\n,", "Xuemei Gong"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nRanked data is ubiquitous in real-world applications, arising naturally when users express preferences about products and services, when voters cast ballots in elections, and when funding proposals are evaluated based on their merits or university departments based on their reputation. This paper focuses on crowdsourcing and novel analysis of ranked data. We describe the design of a data collection task in which Amazon MT workers were asked to rank movies. We present results of data analysis, correlating our ranked dataset with IMDb, where movies are rated on a discrete scale rather than ranked. We develop an intuitive measure of worker quality appropriate for this task, where no gold standard answer exists. We propose a model of local structure in ranked datasets, reflecting that subsets of the workers agree in their ranking over subsets of the items, develop a data mining algorithm that identifies such structure, and evaluate in on our dataset. Our dataset is publicly available at https://github.com/stoyanovich/CrowdRank.", "references": ["Amazon Mechanical Turk. https://www.mturk.com.", "CrowdFlower. http://crowdflower.com/.", "R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In VLDB, 1994.", "S. Amer-Yahia et al. Crowds, clouds, and algorithms: exploring the human side of \"big data\" applications. In SIGMOD, 2010.", "M. Arenas, L. E. Bertossi, and J. Chomicki. Consistent query answers in inconsistent databases. In PODS, 1999.", "A. Bozzon, M. Brambilla, and S. Ceri. Answering search queries with CrowdSearcher. In WWW, 2012.", "X. Chen, P. N. Bennett, K. Collins-Thompson, and E. Horvitz. Pairwise ranking aggregation in a crowdsourced setting. In WSDM, 2013.", "J. Chomicki and J. Marcinkowski. Minimal-change integrity maintenance using tuple deletions. Inf. Comput., 197(1-2):90--121, 2005.", "S. B. Davidson, S. Khanna, T. Milo, and S. Roy. Using the crowd for top-k and group-by queries. In ICDT, pages 225--236, 2013.", "D. Deutch and T. Milo. Mob data sourcing. In SIGMOD, 2012.", "P. Diaconis. A generalization of spectral analysis with applications to ranked data. Annals of Statistics, 17(3):949--979, 1989.", "M. A. Fligner and J. S. Verducci. Distance-based ranking models. Journal of the Royal Statistical Society. Series B, 48(3):359--369, 1986.", "M. J. Franklin et al. CrowdDB: answering queries with crowdsourcing. In SIGMOD, 2011.", "I. C. Gormley and T. B. Murphy. A latent space model for rank data. In ICML, 2006.", "S. Guo, A. G. Parameswaran, and H. Garcia-Molina. So who won?: dynamic max discovery with the crowd. In SIGMOD, 2012.", "P. G. Ipeirotis and P. K. Paritosh. Managing crowdsourced human computation: a tutorial. In WWW (Companion Volume), pages 287--288, 2011.", "M. Jacob, B. Kimelfeld, and J. Stoyanovich. A system for management and analysis of preference data. PVLDB, 7(12), 2014.", "C. Jiang, F. Coenen, and M. Zito. A survey of frequent subgraph mining algorithms. The Knowledge Engineering Review, 1(1):1--31, 2013.", "T. Kamishima and S. Akaho. Supervised ordering by regression combined with thurstone's model. Artif. Intell. Rev., 25(3):231--246, 2006.", "A. Marcus, E. Wu, D. R. Karger, S. Madden, and R. C. Miller. Human-powered sorts and joins. PVLDB, 5(1):13--24, 2011.", "A. Maydeu. Thurstonian modeling of ranking data via mean and covariance structure analysis. Psychometrika, 64(3):325--340, 1999.", "A. G. Parameswaran et al. CrowdScreen: algorithms for filtering data with humans. In SIGMOD, 2012.", "C. V. Pelt and A. Sorokin. Designing a scalable crowdsourcing platform. In SIGMOD, 2012.", "V. S. Sheng, F. J. Provost, and P. G. Ipeirotis. Get another label? improving data quality and data mining using multiple, noisy labelers. In KDD, 2008.", "J. Stoyanovich, S. Amer-Yahia, and T. Milo. Making interval-based clustering rank-aware. In EDBT, 2011.", "J. Stoyanovich et al. Understanding local structure in ranked datasets. In CIDR, 2013.", "J. Wang, A. Ghose, and P. Ipeirotis. Bonus, disclosure, and choice: What motivates the creation of high-quality paid reviews? In ICIS, 2012.", "P. Welinder et al. The multidimensional wisdom of crowds. In NIPS, 2010.", "J. Whitehill et al. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In NIPS, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767110"}, {"title": "Session details: Main Track - Evidence-based Studies", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252432"}, {"title": "Combining Fuzzy DEMATEL with FMCDM for Evaluation the Service Quality of Portal Website", "authors": ["Chien-Hua Wang\n,", "Chin-Tzong Pang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn recent years, the Internet has been developed rapidly and brought great impact to various industries. In it, the portal website is the gate to enter the Internet. In the progress of development, the portal website has been reformed from single to multifunction and categorized services which stand out the importance of the site. However, the quality of each site that users conceive differs from person to person. Among them many intangible attributes are difficult to measure. Therefore, to overcome the obstacles of subjective respondents, we adopt fuzzy DEMATEL methods to create a system structure model to illustrate the influence relationship, and combining FMCDM to rank each performance of service quality of portal website. In empirical results shows that the dimension \"security\" would be the most valued and the criteria \"credit card payment security\" would be the most important.", "references": ["R. E. Bellman and L. A. Zadeh. 1970. Decision making in a fuzzy environment. Management Science. 17 (1970), 141--164. DOI= http://dx.doi.org/10.1287/mnsc.17.4.B141.", "Business Next, 2013 top 100 in Taiwan, http://www.bnext.com.tw/article/view/id/26755, Retrieved June 2013, 2013.", "Business Next, 2014 top 100 in Taiwan, http://www.bnext.com.tw/article/view/id/31260,Retrieved August 2014, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818910"}, {"title": "KinectSBR: A Kinect-Assisted 3D Sketch-Based 3D Model Retrieval System", "authors": ["Bo Li\n,", "Yijuan Lu\n,", "Azeem Ghumman\n,", "Bradley Strylowski\n,", "Mario Gutierrez\n,", "Safiyah Sadiq\n,", "Scott Forster\n,", "Natacha Feola\n,", "Travis Bugerin"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nHow to draw 3D sketches and how to search 3D models based on a hand-drawn 3D sketch are interesting but challenging questions. In this demonstration, we try to answer them by developing a novel Kinect-assisted 3D sketch-based 3D model retrieval system which also allows users to freely draw 3D sketches in a 3D space. We demonstrate its promising potentials in both collecting 3D sketch data and conducting 3D sketch-based 3D model retrieval.", "references": ["M. Ankerst, G. Kastenmüller, and et al. 3D shape histograms for similarity search and classification in spatial databases. In SSD, pages 207--226, 1999.", "B. Li, Y. Lu, and et al. SHREC'13 track: Large scale sketch-based 3D shape retrieval. In 3DOR, pages 89--96, 2013.", "B. Li, Y. Lu, and et al. A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries. CVIU, 131:1--27, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749350"}, {"title": "Session details: Session 1: Web and Social Network Privacy", "authors": ["Aylin Caliskan-Islam"], "publication": "WPES '15: Proceedings of the 14th ACM Workshop on Privacy in the Electronic Society", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3247578"}, {"title": "Geolocation with Subsampled Microblog Social Media", "authors": ["Miriam Cha\n,", "Youngjune L. Gwon\n,", "H.T. Kung"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe propose a data-driven geolocation method on microblog text. Key idea underlying our approach is sparse coding, an unsupervised learning algorithm. Unlike conventional positioning algorithms, we geolocate a user by identifying features extracted from her social media text. We also present an enhancement robust to a random erasure of words in the text and report our experimental results with uniformly or randomly subsampled microblog text. Our solution features a novel two-step procedure consisting of upconversion and iterative refinement by joint sparse coding. As a result, we can reduce the computational cost of geolocation while preserving accuracy. In the light of information preservation and privacy, we remark potential applications of this paper.", "references": ["J. Eisenstein, B. O'Connor, N.A. Smith, and E.P. Xing. A Latent Variable Model for Geographic Lexical Variation. In EMNLP, 2010.", "L. Hong, A. Ahmed, S. Gurumurthy, A.J. Smola, and K. Tsioutsiouliklis. Discovering Geographical Topics in the Twitter Stream. In WWW, 2012.", "C. Weidemann. Social Media Location Intelligence: The Next Privacy Battle|An ArcGIS andd-in and Analysis of Geospatial Data Collected from Twitter.com. Journal of Geoinfo., 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806357"}, {"title": "Parallel Lazy Semi-Naive Bayes Strategies for Effective and Efficient Document Classification", "authors": ["Felipe Viegas\n,", "Marcos André Gonçalves\n,", "Wellington Martins\n,", "Leonardo Rocha"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAutomatic Document Classification (ADC) is the basis of many important applications such as spam filtering and content organization. Naive Bayes (NB) approaches are a widely used classification paradigm, due to their simplicity, efficiency, absence of parameters and effectiveness. However, they do not present competitive effectiveness when compared to other modern statistical learning methods, such as SVMs. This is related to some characteristics of real document collections, such as class imbalance, feature sparseness and strong relationships among attributes. In this paper, we investigate whether the relaxation of the NB feature independence assumption (aka, Semi-NB approaches) can improve its effectiveness in large text collections. We propose four new Lazy Semi-NB strategies that exploit different ideas for alleviating the NB independence assumption. By being lazy, our solutions focus only on the most important features to classify a given test document, overcoming some Semi-NB issues when applied to ADC such as bias towards larger classes and overfitting and/or lack of generalization of the models. We demonstrate that our Lazy Semi-NB proposals can produce superior effectiveness when compared to state-of-the-art ADC classifiers such as SVM and KNN. Moreover, to overcome some efficiency issues of combining Semi-NB and lazy strategies, we take advantage of current manycore GPU architectures and present a massively parallelized version of the Semi-NB approaches. Our experimental results show that speedups of up to 63.36 times can be obtained when compared to serial solutions, making our proposals very practical in real-situations.", "references": ["A. P. Adewole, O. J. Fakorede, and S. O. N. Akwuegbo. Evaluation of linear interpolation smoothing on naive bayes spam classifier, 2014.", "G. Andrade, F. Viegas, G. S. Ramos, J. Almeida, L. Rocha, M. Goncalves, and R. Ferreira. Gpu-nb: A fast cuda-based implementation of naive bayes. SBAC'13, 0:168--175, 2013.", "L. Breiman and P. Spector. Submodel Selection and Evaluation in Regression. The X-Random Case. Int. Stat. Rev., 60(3), 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806565"}, {"title": "Structure, Personalization, Scale: A Deep Dive into LinkedIn Search", "authors": ["Asif Makhani"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nAll of us are familiar with search as users. And as software engineers, many of us have worked on search problems in the context of web search, site search, or enterprise search. But search at LinkedIn is different. Our corpus is a richly structured professional graph comprised of 364M+ people, 3M+ companies, 2M+ groups, and 1.5M+ publishers. Our members perform billions of searches (over 5.7B in 2012), and each of those searches is highly personalized based on the searcher's identity and relationships with other professional entities in LinkedIn's economic graph. And all this data is in constant flux as LinkedIn adds more than 2 members every second in over 200 countries (2/3 of our members are outside the United States). As a result, we've built a system quite different from those used for other search applications. In this talk, we will discuss some of the unique challenges we've faced as we deliver highly personalized search over semi-structured data at massive scale.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776785"}, {"title": "ASM'15: The 1st International Workshop on Affect and Sentiment in Multimedia", "authors": ["Mohammad Soleymani\n,", "Yi-Hsuan Yang\n,", "Yu-Gang Jiang\n,", "Shih-Fu Chang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nNo abstract available.", "references": ["D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In Proc. ACM Int. Conf. Multimedia (MM), pages 223--232, 2013.", "Y.-G. Jiang, B. Xu, and X. Xue. Predicting emotions in user-generated videos. In Proc. AAAI Conf. Artificial Intelligence, pages 73--79, 2014.", "A. Kappas. Smile when you read this, whether you like it or not: Conceptual challenges to affect detection. Affective Computing, IEEE Transactions on, 1(1):38--41, Jan 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806415"}, {"title": "Organizational Strategies for Cultural Heritage Preservation", "authors": ["Paul Logasa Bogen\n,", "Katherine Skinner\n,", "Piotr Adamczyk\n,", "Unmil Karadkar"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nCultural Heritage content is increasingly being both created digitally and digitized. Preserving this content has been a much discussed and debated question in the Digital Libraries and Digital Humanities communities. Many concerns that have been raised around the organizational challenges. Centralized preservation is often praised for unified access and consistency, but at the same are criticized for their reliance on the continued interest of a smaller number of maintainers. Alternatively, decentralized preservation leads to better longevity but often at a cost of consistency or ease of access. Beyond this question, there are many other organizational issues. Such as the role of states and commercial entities in preservation; and, dealing with concerns about ownership, privacy and acceptable use of materials. This panel will discuss these issues with the goal of finding a balance between these often conflicting approaches.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756975"}, {"title": "Towards a Psycho-Cognitive Recommender System", "authors": ["Fanjuan Shi\n,", "Jean-Luc Marini\n,", "Eliott Audry"], "publication": "ERM4CT '15: Proceedings of the International Workshop on Emotion Representations and Modelling for Companion Technologies", "abstract": "ABSTRACT\nCurrent personalized recommendation approaches have reached a limit of effectiveness. By incorporating cognitive and behavioral knowledge, personalized recommender systems could be friendlier and more human-centric, which can potentially enhance user experience and loyalty. Our research proposes a psycho-cognitive method to recommend items based on users' emotion state and center of interest. Meanwhile, we propose a novel behavioral concept (i.e. \"wandering status\") and highlight its importance in online behavioral research.", "references": ["Burke, R. (2007). Hybrid web recommender systems. In The adaptive web LNCS 4321, 377--408. Springer Berlin Heidelberg.", "Leavitt, N. (2006). Recommendation technology: Will it boost e-commerce?. Computer, 39(5), 13--16.", "Poirier, D. (2011). Thèse de Doctorat en Informatique intitule \"Des Textes Communautaires à la Recommendation\". Soutenance effectuée au LIFO (Laboiratoire d'Informatique fondamentale d'Orléans)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2829966.2829968"}, {"title": "MSoS: A Multi-Screen-Oriented Web Page Segmentation Approach", "authors": ["Mira Sarkis\n,", "Cyril Concolato\n,", "Jean-Claude Dufourd"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nIn this paper we describe a multiscreen-oriented approach for segmenting web pages. The segmentation is an automatic and hybrid visual and structural method. It aims at creating coherent blocks which have different functions determined by the multiscreen environment. It is also characterized by a dynamic adaptation to the page content.Experiments are conducted on a set of existing applications that contain multimedia elements, in particular YouTube and video player pages. Results are compared with one segmentation method from the literature and with a ground truth manually created. With a 81% precision, the MSoS is a promising method that is capable of producing good segmentation results.", "references": ["D. Cai, S. Yu, J.R. Wen, and W.Y. Ma. Vips: A vision-based page segmentation algorithm. Technical report, Microsoft, MSR-TR-2003-79, 2003.", "J. Chen, B. Zhou, J. Shi, H. Zhang, and Q. Fengwu. Function-based object model towards website adaptation. In Proceedings of the 10th International Conference on World Wide Web, WWW '01, pages 587--596, New York, NY, USA, 2001. ACM.", "J.C. Dufourd, M. Tritschler, L. Bassbouss, R. Bouazizi, and S. Steglich. An open platform for multiscreen services. In the 11th European Interactive TV conference EuroITV, Como, Italy, June 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797090"}, {"title": "A GA-based Small-scale Mobile Device for Environmental Data Collection", "authors": ["Tin-Yu Wu\n,", "Yu-Neng Hung\n,", "Yuew Wu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe purpose of this study is to use a small-scale mobile environmental data collection device together with a wireless feedback system to establish an efficient monitoring system that is usually operated by large-scale monitoring stations. The monitoring results will be compared with the regional environmental information provided by Environmental Protection Administration, Executive Yuan, and corrected based on a genetic algorithm (GA). In this study, the monitoring system refers to the air quality monitoring equipment attached to a bicycle which is developed by the Big Data Lab of Department of Computer Science and Information Engineering, National Ilan University.", "references": ["MA Xiao-ming, ZHANG Fan. A genetic algorithm based stochastic programming model for air quality management. Journal of Environmental Science, Vol.14, No.3, pp.367--374, 2002.", "Federico M. San Martini, Christa A. Hasenkopf, David C. Roberts. Statistical analysis of PM2.5 observations from diplomatic facilities in China. Office of Environmental Quality and Transboundary Issues, U.S. Department of State, Washington, DC 20520, USA, 2015", "Yan Cheng, Shun Cheng Lee. Real-time measurements of PM2.5, PM10-2.5, and BC in an urban street canyon. Particuology, Vol.20, pp.134--140, June 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818882"}, {"title": "Partially Labeled Supervised Topic Models for RetrievingSimilar Questions in CQA Forums", "authors": ["Debasis Ganguly\n,", "Gareth J.F. Jones"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nManual annotations, e.g. tags and links, of user generated content in community question answering forums and social media play an important role in making the content searchable. During the active phase of a new question entered into a CQA forum, a moderator or an answerer often has to make a significant effort to manually search for related question threads (which we refer to as documents), that he may consider linking to the current question. This manual effort can be greatly reduced by an automated search process to suggest a list of candidate documents to be linked to the new document. We described our investigation of link recommendation for this task. We approach the problem as an ad-hoc information retrieval (IR) task in which a new document (question) acts as the query and the intention is to retrieve a list of potentially relevant documents (previously asked questions in the forum), which could then be linked (manually) to the new one. In contrast to standard ad-hoc search, two pieces of human annotated additional information, namely the tags of the documents and the known links between existing document pairs, can potentially be used to improve the search quality for new questions. To utilize this additional information, we propose a generative model of tagged documents which jointly estimates the distribution of topics corresponding to each tag of a document along with the likelihood of a document being linked to another one. The model predictions are then incorporated in the query likelihood estimate of a standard language model (LM) of IR. Experiments conducted on three months of a crawled StackOverflow dataset show that utilizing the tag specific topic distributions results in a significant improvement in retrieval of the candidate set of related documents.", "references": ["D. M. Blei and J. D. McAuliffe. Supervised topic models. In Proceedings of NIPS '07, 2007.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003.", "G. Burel, Y. He, and H. Alani. Automatic Identification of Best Answers in Online Enquiry Communities. In Proceedings of ESWC'12, pages 514--529, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809460"}, {"title": "Fifty years of evolution in virtualization technologies: from the first IBM machines to modern hyperconverged infrastructures", "authors": ["Nectarios Koziris"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nThe evolution of virtualization is an exciting history of enabling technologies that have offered the ability to organize and utilize the hardware resources more efficiently. We will start from the origins of the first IBM machines back in 1960's, where the notion of virtualization was originally introduced to partition the hardware resources more efficiently. This was well before the onset of the majority of the operating systems in the early 1970's, which were initially introduced as a software alternative to partition and expose hardware resources to multiple users. In the late 1980's and 1990's the software hypervisors allowed the multiplexing of PC hardware and enabled the use of virtual machines, which in the 2000's became a commodity that needed to be efficiently orchestrated and provisioned in bulk. The IaaS cloud era had arrived, bringing more interesting challenges for the dynamic, thin provisioning of hardware and software resources to applications. Nowadays, we are living in the times of \"software defined everything\". We have hyper-convergence in all our datacenter infrastructures, where all compute, network and storage resources are controlled by software. The talk will present this exciting long technology journey that started more than 50 years ago and still continues, always driven by the notion of virtualizing expensive hardware resources to multiple users.", "references": ["M. Varian, \"Vm and the vm community: Past, present, and future,\" SHARE, 1997.", "R. Dittner and D. R. Jr., The Best Damn Server Virtualization Book Period: Including Vmware, Xen and Microsoft Virtual Server. Syngress, 1st ed., 2007.", "\"History of virtualization.\" http://everythingvm.com/content/history-virtualization."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802039"}, {"title": "Social set analysis: four demonstrative case studies", "authors": ["Ravi Vatrapu\n,", "Abid Hussain\n,", "Niels Buus Lassen\n,", "Raghava Rao Mukkamala\n,", "Benjamin Flesch\n,", "Rene Madsen"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nThis paper argues that the basic premise of Social Network Analysis (SNA) -- namely that social reality is constituted by dyadic relations and that social interactions are determined by structural properties of networks-- is neither necessary nor sufficient, for Big Social Data analytics of Facebook or Twitter data. However, there exist no other holistic computational social science approach beyond the relational sociology and graph theory of SNA. To address this limitation, this paper presents an alternative holistic approach to Big Social Data analytics called Social Set Analysis (SSA). Based on the sociology of associations and the mathematics of classical, fuzzy and rough set theories, this paper proposes a research program. The function of which is to design, develop and evaluate social set analytics in terms of fundamentally novel formal models, predictive methods and visual analytics tools for Big Social Data. Four demonstrative case studies, employing SSA, covering the range of descriptive, predictive, visual and prescriptive analytics are presented and briefly discussed.", "references": ["Montalvo, R. E. 2011. Social Media Management. International Journal of Management & Information Systems (IJMIS) 15, 3, 91--96.", "Vollmer, C. and Precourt, G. 2008. Always on: Advertising, marketing and media in an era of consumer control. McGraw-Hill Professional.", "McAfee, A. 2009. Enterprise 2.0: New collaborative tools for your organization's toughest challenges. Harvard Business School Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789203"}, {"title": "Brain science helps computers separate speakers in a crowded room", "authors": ["Chris Edwards"], "publication": "Communications of the ACM", "abstract": "Abstract\nPeople can listen to a single voice amid the hubbub of a cocktail party; algorithms can help computers do it, too.", "references": ["Narayanan A., and Wang, D. Improving Robustness of Deep Neural Network Acoustic Models via Speech Separation and Joint Adaptive Training, IEEE Transactions on Audio, Speech, and Language Processing, Vol.23, No.1 (2015).", "McDermott, J. The Cocktail Party Problem, Current Biology, Vol.19 No.22 (2010).", "Simpson, A. Deep Transform: Cocktail Party Source Separation via Probabilistic Re-Synthesis, arXiv preprint arXiv:1502.04617 (2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820425"}, {"title": "Tumblr Blog Recommendation with Boosted Inductive Matrix Completion", "authors": ["Donghyuk Shin\n,", "Suleyman Cetintas\n,", "Kuang-Chih Lee\n,", "Inderjit S. Dhillon"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPopular microblogging sites such as Tumblr have attracted hundreds of millions of users as a content sharing platform, where users can create rich content in the form of posts that are shared with other users who follow them. Due to the sheer amount of posts created on such services, an important task is to make quality recommendations of blogs for users to follow. Apart from traditional recommender system settings where the follower graph is the main data source, additional side-information of users and blogs such as user activity (e.g., like and reblog) and rich content (e.g., text and images) are also available to be exploited for enhanced recommendation performance. In this paper, we propose a novel boosted inductive matrix completion method (BIMC) for blog recommendation. BIMC is an additive low-rank model for user-blog preferences consisting of two components; one component captures the low-rank structure of follow relationships and the other captures the latent structure using side-information. Our model formulation combines the power of the recently proposed inductive matrix completion (IMC) model (for side-information) together with a standard matrix completion (MC) model (for low-rank structure). Furthermore, we utilize recently developed deep learning techniques to obtain semantically rich feature representations of text and images that are incorporated in BIMC. Experiments on a large-scale real-world dataset from Tumblr illustrate the effectiveness of the proposed BIMC method.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In SIGKDD, pages 19--28, 2009.", "M. G. Armentano, D. Godoy, and A. A. Amandi. Followee recommendation based on text analysis of micro-blogging activity. Information Systems, 38(8):1116--1127, 2013.", "R. M. Bell and Y. Koren. Lessons from the Netflix Prize Challenge. SIGKDD Explor. Newsl., 9(2):75--79, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806578"}, {"title": "Rise and Fall of Online Game Groups: Common Findings on Two Different Games", "authors": ["Ah Reum Kang\n,", "Juyong Park\n,", "Jina Lee\n,", "Huy Kang Kim"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nAmong many types of online games, Massively Multiplayer Online Role Playing Games (MMORPGs) provide players with the most realistic gaming experience inspired by the real, offline world. In particular, much stress is put upon socializing and collaboration with others as a condition for one's success, just as in real life. An advantage of studying MMORPGs is that since all actions are recorded, we can observe phenomena that are hard to observe in real life. For instance, we could observe how the all-important collaboration between people come into being, evolve, and eventually die out from the data to gain valuable insights to the group dynamics. In this paper, we analyzed the successes and failures of the online game groups in two different MMORPG, ArcheAge of XLGames, Inc. and Aion of NCsoft, Inc.. We find that there exist factors that influence the dynamics of group growth common to the games regardless of the games' maturity.", "references": ["Genre Breakdown of U.S. Computer Game Sales in 2011, http://www.statista.com/statistics/189660/breakdown-of-us-computergame- sales-2009-by-genre/. Source: Entertainment Software Association.", "Son, S., Kang, A. R., Kim, H. C., Kwon, T., Park, J., and Kim, H. K. 2012. Analysis of context dependence in social interaction networks of a massively multiplayer online role-playing game. PloS one. 7, 4 (April. 2012), e33918. DOI= http://dx.doi.org/10.1371/journal.pone.0033918.", "Woo, J., Kwak, B. I., Lim, J., Kim, H. K. 2014. Generosity as Social Contagion in Virtual Community. Exploration on Games and Gamers (Barcelona, Spain, November 10, 2014). EGG 2014"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744714"}, {"title": "Search Result Diversification Based on Hierarchical Intents", "authors": ["Sha Hu\n,", "Zhicheng Dou\n,", "Xiaojie Wang\n,", "Tetsuya Sakai\n,", "Ji-Rong Wen"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nA large percentage of queries issued to search engines are broad or ambiguous. Search result diversification aims to solve this problem, by returning diverse results that can fulfill as many different information needs as possible. Most existing intent-aware search result diversification algorithms formulate user intents for a query as a flat list of subtopics. In this paper, we introduce a new hierarchical structure to represent user intents and propose two general hierarchical diversification models to leverage hierarchical intents. Experimental results show that our hierarchical diversification models outperform state-of-the-art diversification methods that use traditional flat subtopics.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, 2009.", "J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR, 1998.", "B. Carterette and P. Chandar. Probabilistic models of ranking novel documents for faceted topic retrieval. In CIKM, pages 1287--1296, Hong Kong, China, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806455"}, {"title": "Mining Coordinated Intent Representation for Entity Search and Recommendation", "authors": ["Huizhong Duan\n,", "ChengXiang Zhai"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe study the problem of learning query intent representation for an entity search task such as product retrieval, where a user would use a keyword query to retrieve entities based on their structured attribute value descriptions. Existing intent representation has been mostly based on the query space. These methods overlook the critical information from the entity space and the connection in between. Consequently, when such representation methods are used in intent mining from user engagement logs in entity search, they cannot fully discover the comprehensive knowledge of user preference, which is essential for improving the effectiveness of entity search and recommendation, as well as many applications such as business intelligence.\nTo address this problem, we propose a novel Coordinated Intent Representation, where each user intent is represented collectively in both the query space and the entity space. Specifically, a coordinated intent representation consists of a language model to capture typical query terms used for search and a series of probabilistic distributions on entity attributes and attribute values to characterize the preferred features of entities for the corresponding intent. We propose a novel generative model to discover coordinated intent representations from the entity search logs. Evaluation in the domain of product search shows that the proposed model is effective for discovering meaningful coordinated shopping intents, and the discovered intent representation can be directly used for improving the accuracy of product search and recommendation.", "references": ["A. Broder. A taxonomy of web search. In ACM Sigir forum, volume 36, pages 3--10. ACM, 2002.", "O. Chapelle and Y. Zhang. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th International Conference on World Wide Web, WWW '09, pages 1--10, New York, NY, USA, 2009. ACM.", "S. Chaudhuri, G. Das, V. Hristidis, and G. Weikum. Probabilistic information retrieval approach for ranking of database query results. ACM Trans. Database Syst., 31(3), 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806557"}, {"title": "Pairwise Preferences Elicitation and Exploitation for Conversational Collaborative Filtering", "authors": ["Laura Blédaité\n,", "Francesco Ricci"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nThe research and development of recommender systems is dominated by models of user's preferences learned from ratings for items. However, ratings have several disadvantages, which we discuss, and in order to address these issues we analyse another way to articulate preferences, i.e., as pairwise comparisons: item A is preferred to item B. We have developed a recommendation technology that, combining ratings and pairwise preferences, can generate better recommendations than a state of the art solution uniquely based on ratings.", "references": ["G. Adomavicius, B. Mobasher, F. Ricci, and A. Tuzhilin. Context-aware recommender systems. AI Magazine, 32(3):67--80, 2011.", "A. Bellogín, A. Said, and A. P. de Vries. The magic barrier of recommender systems - no magic, just ratings. In User Modeling, Adaptation, and Personalization - 22nd International Conference, UMAP 2014, Aalborg, Denmark, July 7--11, 2014. Proceedings, pages 25--36, 2014.", "C. Desrosiers and G. Karypis. A comprehensive survey of neighborhood-based recommendation methods. In F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors, Recommender Systems Handbook, pages 107--144. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791049"}, {"title": "Temporality in Online Food Recipe Consumption and Production", "authors": ["Tomasz Kusmierczyk\n,", "Christoph Trattner\n,", "Kjetil Nørvåg"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper, we present work-in-progress of a recently started research effort that aims at understanding the hidden temporal dynamics in online food communities. In this context, we have mined and analyzed temporal patterns in terms of recipe production and consumption in a large German community platform. As our preliminary results reveal, there are indeed a range of hidden temporal patterns in terms of food preferences and in particular in consumption and production. We believe that this kind of research can be important for future work in personalized Web-based information access and in particular recommender systems.", "references": ["S. Abbar, Y. Mejova, and I. Weber. You tweet what you eat: Studying food consumption through twitter. In Proc. of CHI'15, 2015.", "P. G. Campos, F. Dıez, and I. Cantador. Time-aware recommender systems: A comprehensive survey and analysis of existing evaluation protocols. UMUAI, 24(1--2):67--119, 2014.", "M. Trevisiol, L. Chiarandini, and R. Baeza-Yates. Buon appetito-recommending personalized menus. In Proc. of HT'14, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742752"}, {"title": "Recursive Autoencoder with HowNet Lexicon for Sentence-Level Sentiment Analysis", "authors": ["Xianghua Fu\n,", "Yingying Xu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nSemantic word representations have been very useful but usually ignore the syntactic relationship. In the task of sentiment analysis, compositional vector representations require more structure information from natural language text and richer supervised training for more accuracy predictions. However, labeled data are generally expensive to acquire in reality. To remedy this, we propose a new method that train our model based on fully labeled parse tree using supervised learning without manual annotation. Our method not only significantly reduces the burden of manual labeling, but also allows the compositionality to capture syntactic and semantic information jointly. We show the effectiveness of this model on the task of sentence-level sentiment classification and conduct preliminary experiments to investigate its performance. Lastly, it can accurately predict the sentiment distribution and outperforms other approaches.", "references": ["Baroni, M. and Zamparelli, R., 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing Association for Computational Linguistics, 1183--1193.", "Bengio, Y., Ducharme, J., Vincent, P., and Janvin, C., 2003. A neural probabilistic language model. J. Mach. Learn. Res. 3, 1137--1155.", "Che, W., Spitkovsky, V. I., and Liu, T., 2012. A comparison of chinese parsers for stanford dependencies. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2 Association for Computational Linguistics, 11--16.", "Goller, C. and Kuchler, A., 1996. Learning task-dependent distributed representations by backpropagation through structure. In Neural Networks, 1996., IEEE International Conference on IEEE, 347--352.", "Johansson, R. and Moschitti, A., 2010. Syntactic and semantic structure for opinion expression detection. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning Association for Computational Linguistics, 67--76.", "Klein, D. and Manning, C. D., 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1 Association for Computational Linguistics, 423--430.", "Mikolov, T., Chen, K., Corrado, G., and Dean, J., 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818908"}, {"title": "Semi-automatic ground truth annotation in videos: An interactive tool for polygon-based object annotation and segmentation", "authors": ["Julius Schöning\n,", "Patrick Faion\n,", "Gunther Heidemann"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nKnowledge extraction from video data is challenging due to its high complexity in both the spatial and temporal domain. Ground truth is crucial for the evaluation and the adaptation of algorithms to new domains. Unfortunately, ground truth annotation is inconvenient and time consuming. Common annotation tools mostly rely on simple geometric primitives such as rectangles or ellipses. Here we propose a novel, interactive and semi-automatic process, which actively asks for user input if the result of the automatic annotation appears to be incorrect. After a brief review of related tools for video annotation, we explain our proposed semi-automatic method iSeg using a prototype implementation. iSeg has been tested on two visual stimulus datasets for eye tracking experiments and on two surveillance datasets. The experimental results and the usability are compared to existing annotation tools. Finally, we discuss the properties and opportunities of polygon-based video annotation.", "references": ["H. Alt and L. J. Guibas. Discrete geometric shapes: Matching, interpolation, and approximation: A survey. Technical report, Handbook of Computational Geometry, 1996.", "F. Cobos and J. Peetre. Interpolation of compact operators: the multidimensional case. Proceedings of the London Mathematical Society, 3(2):371--400, 1991.", "S. Dasiopoulou, E. Giannakidou, G. Litos, P. Malasioti, and Y. Kompatsiaris. A survey of semantic image and video annotation tools. Lecture Notes in Computer Science, pages 196--239, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2816947"}, {"title": "Introducing LUIMA: an experiment in legal conceptual retrieval of vaccine injury decisions using a UIMA type system and tools", "authors": ["Matthias Grabmair\n,", "Kevin D. Ashley\n,", "Ran Chen\n,", "Preethi Sureshkumar\n,", "Chen Wang\n,", "Eric Nyberg\n,", "Vern R. Walker"], "publication": "ICAIL '15: Proceedings of the 15th International Conference on Artificial Intelligence and Law", "abstract": "ABSTRACT\nThis paper presents first results from a proof of feasibility experiment in conceptual legal document retrieval in a particular domain (involving vaccine injury compensation). The conceptual markup of documents is done automatically using LUIMA, a law-specific semantic extraction toolbox based on the UIMA framework. The system consists of modules for automatic sub-sentence level annotation, machine learning based sentence annotation, basic retrieval using Apache Lucene and a machine learning based reranking of retrieved documents. In a leave-one-out experiment on a limited corpus, the resulting rankings scored higher for most tested queries than baseline rankings created using a commercial full-text legal information system.", "references": ["Ashley, K. & Brüninghaus, S., Automatically classifying case texts and predicting outcomes. Artificial Intelligence and Law, 2009, 125--165.", "Ashley, K., & Walker, V., From Information Retrieval (IR) to Argument Retrieval (AR) for Legal Cases: Report on a Baseline Study. Proc. Jurix 2013, 29--38.", "Ashley, K. & Walker, V., Toward Constructing Evidence-based Legal Arguments Using Legal Decision Documents and Machine Learning, ICAIL 2013 Proc., ACM, 2013, 176--180."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746090.2746096"}, {"title": "Information Retrieval with Verbose Queries", "authors": ["Manish Gupta\n,", "Michael Bendersky"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nRecently, the focus of many novel search applications shifted from short keyword queries to verbose natural language queries. Examples include question answering systems and dialogue systems, voice search on mobile devices and entity search engines like Facebook's Graph Search or Google's Knowledge Graph. However the performance of textbook information retrieval techniques for such verbose queries is not as good as that for their shorter counterparts. Thus, effective handling of verbose queries has become a critical factor for adoption of information retrieval techniques in this new breed of search applications. Over the past decade, the information retrieval community has deeply explored the problem of transforming natural language verbose queries using operations like reduction, weighting, expansion, reformulation and segmentation into more effective structural representations. However, thus far, there was not a coherent and organized tutorial on this topic. In this tutorial, we aim to put together various research pieces of the puzzle, provide a comprehensive and structured overview of various proposed methods, and also list various application scenarios where effective verbose query processing can make a significant difference.", "references": ["R. Agrawal, S. Gollapudi, A. Kannan, and K. Kenthapadi. Enriching Textbooks with Images. In Proc. of the 20th ACM Intl. Conf. on Information and Knowledge Management (CIKM), pages 1847--1856, 2011.", "A. Arampatzis and J. Kamps. A Study of Query Length. In Proc. of the 31st Annual Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR), pages 811--812, 2008.", "N. Balasubramanian, G. Kumaran, and V. R. Carvalho. Exploring Reductions for Long Web Queries. In Proc. of the 33rd Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR), pages 571--578, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767877"}, {"title": "Real-time Rumor Debunking on Twitter", "authors": ["Xiaomo Liu\n,", "Armineh Nourbakhsh\n,", "Quanzhi Li\n,", "Rui Fang\n,", "Sameena Shah"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we propose the first real time rumor debunking algorithm for Twitter. We use cues from 'wisdom of the crowds', that is, the aggregate 'common sense' and investigative journalism of Twitter users. We concentrate on identification of a rumor as an event that may comprise of one or more conflicting microblogs. We continue monitoring the rumor event and generate real time updates dynamically based on any additional information received. We show using real streaming data that it is possible, using our approach, to debunk rumors accurately and efficiently, often much faster than manual verification by professionals.", "references": ["C. Castillo, M. Mendoza, and B. Poblete. Information credibility on twitter. In Proc. International Conference on World Wide Web, pages 675--684, 2011.", "A. Friggeri, L. A. Adamic, D. Eckles, and J. Cheng. Rumor cascades. In Proceedings of the International AAAI Conference on Weblogs and Social Media, 2014.", "A. Gupta, H. Lamba, P. Kumaraguru, and A. Joshi. Faking sandy: characterizing and identifying fake images on twitter during hurricane sandy. In Proc. International Conference on World Wide Web Companion, pages 729--736, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806651"}, {"title": "Summarization-based Video Caption via Deep Neural Networks", "authors": ["Guang Li\n,", "Shubo Ma\n,", "Yahong Han"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nGenerating appropriate descriptions for visual content draws increasing attention recently, where the promising progresses were obtained owing to the breakthroughs in deep neural networks. Different from the traditional SVO (subject, verb, object) based methods, in this paper, we propose a novel framework of video caption via deep neural networks. For each frame, we extract visual features by a fine-tuned deep Convulutional Neural Networks (CNN), which are then fed into a Recurrent Neural Networks (RNN) to generate novel sentences descriptions for each frame. In order to obtain the most representative and high-quality descriptions for target video, a well-devised automatic summarization process is incorporated to reduce the noises by ranking on the sentence-sequence graph. Moreover, our framework owns the merit of describing out-of-sample videos by transferring knowledge from pre-captioned images. Experiments on the benchmark datasets demonstrate our method has better performance than the state-of-the-art methods of video caption in language generation metrics as well as SVO accuracy.", "references": ["S. Banerjee and A. Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pages 65--72, 2005.", "D. L. Chen and W. B. Dolan. Collecting highly parallel data for paraphrase evaluation. In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics, pages 190--200. Association for Computational Linguistics, 2011.", "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, pages 248--255, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806314"}, {"title": "Context Retrieval for Web Tables", "authors": ["Hong Wang\n,", "Anqi Liu\n,", "Jing Wang\n,", "Brian D. Ziebart\n,", "Clement T. Yu\n,", "Warren Shen"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nMany modern knowledge bases are built by extracting information from millions of web pages. Though existing extraction methods primarily focus on web pages' main text, a huge amount of information is embedded within other web structures, such as web tables. Previous studies have shown that linking web page tables and textual context is beneficial for extracting more information from web pages. However, using the text surrounding each table without carefully assessing its relevance introduces noise in the extracted information, degrading its accuracy. To the best of our knowledge, we provide the first systematic study of the problem of table-related context retrieval: given a table and the sentences within the same web page, determine for each sentence whether it is relevant to the table. We define the concept of relevance and introduce a Table-Related Context Retrieval system (TRCR) in this paper. We experiment with different machine learning algorithms, including a recently developed algorithm that is robust to biases in the training data, and show that our system retrieves table-related context with F1=0.735.", "references": ["A. Arnold, R. Nallapati, and W. W. Cohen. A comparative study of methods for transductive transfer learning. In Data Mining Workshops, 2007. ICDM Workshops 2007. Seventh IEEE International Conference on, pages 77--82. IEEE, 2007.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction for the web. In IJCAI, volume 7, pages 2670--2676, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809453"}, {"title": "Universal-DB: towards representation independent graph analytics", "authors": ["Yodsawalai Chodpathumwan\n,", "Amirhossein Aleyasen\n,", "Arash Termehchy\n,", "Yizhou Sun"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nGraph analytics algorithms leverage quantifiable structural properties of the data to predict interesting concepts and relationships. The same information, however, can be represented using many different structures and the structural properties observed over particular representations do not necessarily hold for alternative structures. Because these algorithms tend to be highly effective over some choices of structure, such as that of the databases used to validate them, but not so effective with others, graph analytics has largely remained the province of experts who can find the desired forms for these algorithms. We argue that in order to make graph analytics usable, we should develop systems that are effective over a wide range of choices of structural organizations. We demonstrate Universal-DB an entity similarity and proximity search system that returns the same answers for a query over a wide range of choices to represent the input database.", "references": ["S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases. Addison-Wesley, 1994.", "Y. Chodpathumwan et al. Representation Independence of Structural Proximity and Similarity Algorithms. Technical report, Oregon State University, 2015.", "W. Fan and P. Bohannon. Information Preserving XML Schema Embedding. TODS, 33(1):1--44, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824125"}, {"title": "Interpreting Advertiser Intent in Sponsored Search", "authors": ["Bhanu C. Vattikonda\n,", "Santhosh Kodipaka\n,", "Hongyan Zhou\n,", "Vacha Dave\n,", "Saikat Guha\n,", "Alex C. Snoeren"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nSearch engines derive revenue by displaying sponsored results along with organic results in response to user queries. In general, search engines run a per-query, on-line auction amongst interested advertisers to select sponsored results to display. In doing so, they must carefully balance the revenue derived from sponsored results against potential degradation in user experience due to less-relevant results. Hence, major search engines attempt to analyze the relevance of potential sponsored results to the user's query using supervised learning algorithms. Past work has employed a bag-of-words approach using features extracted from both the query and potential sponsored result to train the ranker.\nWe show that using features that capture the advertiser's intent can significantly improve the performance of relevance ranking. In particular, we consider the ad keyword the advertiser submits as part of the auction process as a direct expression of intent. We leverage the search engine itself to interpret the ad keyword by submitting the ad keyword as an independent query and incorporating the results as features when determining the relevance of the advertiser's sponsored result to the user's original query. We achieve 43.2% improvement in precision-recall AUC over the best previously published baseline and 2.7% improvement in the production system of a large search engine.", "references": ["Click Modeling in Search Advertising: Challenges & Solutions. http://advertise.bingads.microsoft.com/en-us/editorial-relevance-quality-guidelines.", "DMOZ - the Open Directory Project. http://www.dmoz.org.", "English Stop Words (CSV). http://www.textfixer.com/resources/common-english-words.txt."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788566"}, {"title": "Roomba: Automatic Validation, Correction and Generation of Dataset Metadata", "authors": ["Ahmad Assaf\n,", "Aline Senart\n,", "Raphaël Troncy"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nData is being published by both the public and private sectors and covers a diverse set of domains ranging from life sciences to media or government data. An example is the Linked Open Data (LOD) cloud which is potentially a gold mine for organizations and individuals who are trying to leverage external data sources in order to produce more informed business decisions. Considering the significant variation in size, the languages used and the freshness of the data, one realizes that spotting spam datasets or simply finding useful datasets without prior knowledge is increasingly complicated. In this paper, we propose Roomba, a scalable automatic approach for extracting, validating, correcting and generating descriptive linked dataset profiles. While Roomba is generic, we target CKAN-based data portals and we validate our approach against a set of open data portals including the Linked Open Data (LOD) cloud as viewed on the DataHub. The results demonstrate that the general state of various datasets and groups, including the LOD cloud group, needs more attention as most of the datasets suffer from bad quality metadata and lack some informative metrics that are required to facilitate dataset search.", "references": ["Z. Abedjan, T. Gruetze, A. Jentzsch, and F. Naumann. Profiling and mining RDF data with ProLOD", ". In 30$^th$ IEEE International Conference on Data Engineering (ICDE), pages 1198--1201, 2014.", "S. Auer, J. Demter, M. Martin, and J. Lehmann. LODStats - an Extensible Framework for High-performance Dataset Analytics. In 18$^th$ International Conference on Knowledge Engineering and Knowledge Management (EKAW), pages 353--362, Galway, Ireland, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742827"}, {"title": "Towards Serving \"Delicious\" Information within Its Freshness Date", "authors": ["Hao Han\n,", "Takashi Nakayama\n,", "Junxia Guo\n,", "Keizo Oyama"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLike freshness date of food, Web information also has its \"shelf life\". In this paper, we exploratively study the reflection of shelf life of information in browsing behaviors. Our analysis shows that the satisfaction of browsing behavior is modified if the shelf life of information could be considered by search engines.", "references": ["S. Chelaru, I. S. Altingovde, S. Siersdorfer, and W. Nejdl. Analyzing, detecting, and exploiting sentiment in Web queries. ACM Transactions on the Web, 8(1), 2013.", "J. Guo, C. Gao, N. Xu, G. Lu, and H. Han. Analyzing query trails and satisfaction based on browsing behaviors. In The Proceedings of the 10th Web Information System and Application Conference, pages 107--112, 2013.", "Weka2. http://www.cs.waikato.ac.nz/ml/weka/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742747"}, {"title": "Indexing and selecting hierarchical business logic", "authors": ["Alessandra Loro\n,", "Anja Gruenheid\n,", "Donald Kossmann\n,", "Damien Profeta\n,", "Philippe Beaudequin"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nBusiness rule management is the task of storing and maintaining company-specific decision rules and business logic that is queried frequently by application users. These rules can impede efficient query processing when they require the business rule engine to resolve semantic hierarchies. To address this problem, this work discusses hierarchical indexes that are performance and storage-conscious. In the first part of this work, we develop a tree-based hierarchical structure that represents client-defined semantic hierarchies as well as two variants of this structure that improve performance and main memory allocation. The second part of our work focuses on selecting the top rules out of those retrieved from the index. We formally define a priority score-based decision scheme that allows for a conflict-free rule system and efficient rule ranking. Additionally, we introduce a weight-based lazy merging technique for rule selection. All of these techniques are evaluated with real world and synthetic data sets.", "references": ["Bentley, J. L. Decomposable searching problems. Information Processing Letters, 8(5):244--251, 1979.", "Calado, Pável and da Silva, Altigran Soares and Vieira, Rodrigo C. and Laender, Alberto H. F. and Ribeiro-Neto, Berthier A. Searching Web Databases by Structuring Keyword-based Queries. CIKM, pages 26--33, 2002.", "J. Celko. Joe Celko's Trees and Hierarchies in SQL for Smarties. Morgan Kaufmann, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824064"}, {"title": "Finding the missing link to industry: LinkedIn professional groups as facilitators of empirical research", "authors": ["Naomi Unkelos-Shpigel\n,", "Sofia Sherman\n,", "Irit Hadar"], "publication": "CESI '15: Proceedings of the Third International Workshop on Conducting Empirical Studies in Industry", "abstract": "ABSTRACT\nConducting empirical research in industry is not an easy task. Previous research has discussed some of the challenges in this type of research and potential solutions have been proposed. However, conducting cross-organizational research introduces specific challenges, some of which are quite hard to overcome. In this paper, we present the use of professional interest groups in a professional social network, LinkedIn, as a way to recruit participant to an online survey. Using this social network, commonly used among practitioners, was found to be an effective research tool.", "references": ["M. Galster and D. Tofan, \"Exploring web advertising to attract industry professionals for software engineering survey\", In Conducting Empirical Studies in Industry (CESI), 2014 2nd International Workshop on, pp. 5--8.", "Y. Baruch and B. C. Holtom, \"Survey response rate levels and trends in organizational research\", Human Relations, 61(8), 2008, pp. 1139--1160.", "N. Unkelos-Shpigel and I. Hadar, \"Mind the gap and find common ground: empirical research in multiple firms\", In Conducting Empirical Studies in Industry (CESI), 2013 1st International Workshop on, pp. 33--36. IEEE."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819303.2819318"}, {"title": "Indexing highly dynamic hierarchical data", "authors": ["Jan Finis\n,", "Robert Brunel\n,", "Alfons Kemper\n,", "Thomas Neumann\n,", "Norman May\n,", "Franz Faerber"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMaintaining and querying hierarchical data in a relational database system is an important task in many business applications. This task is especially challenging when considering dynamic use cases with a high rate of complex, possibly skewed structural updates. Labeling schemes are widely considered the indexing technique of choice for hierarchical data, and many different schemes have been proposed. However, they cannot handle dynamic use cases well due to various problems which we investigate in this paper. We therefore propose our dynamic Order Indexes, which offer competitive query performance, unprecedented update efficiency, and robustness for highly dynamic workloads.", "references": ["T. Amagasa, M. Yoshikawa, and S. Uemura. QRS: A robust numbering scheme for XML documents. In ICDE, pages 705--707, 2003.", "P. Boncz, S. Manegold, and J. Rittinger. Updating the pre/post plane in MonetDB/XQuery. In XIME-P, 2005.", "R. Brunel, J. Finis, G. Franz, N. May, A. Kemper, T. Neumann, and F. Faerber. Supporting hierarchical data in SAP HANA. In ICDE, pages 1280--1291, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794369"}, {"title": "Prized assets for web tracking", "authors": ["Sylvia E. Peacock"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nIn this study, I pinpoint the group of online Canadians who are predominantly affected by online personal data extractions, sometimes called web tracking. Due to the lack of regulations and online information market failure, online personal data extraction is ubiquitous. Little knowledge exists about who the users are that are mainly affected by web tracking. Two large population surveys, called the Canadian Internet User Survey 2010 and 2012, offer comprehensive and comparable measures to gauge the intensity and extent of people's online activities. An Internet intensity index is proposed to measure Canadian online activity scaled between zero (offline) and 100 (intensely active Internet user). Results indicate that the data of mature, well-off and educated men and women are captured by the web tracking technologies of online companies, to an increasing degree. Other population segments appear less affected. From a marketing perspective, the targeted group is the most coveted of all consumer groups. Thus, corporate self-regulation seems unlikely in the light of the current results. The overuse of social media and the Internet commons for the purpose of personal user data extraction might lead to an underuse of the Internet's possibilities to connect via social media. Today a market-led approach that essentially leaves web tracking unregulated may present first indications of online companies steering us towards a virtual tragedy of the commons.", "references": ["Acquisti, A., Brandimarte, L., and Loewenstein, G. 2015. Privacy and human behavior in the age of information. Science 347, 6221, 509--514. DOI: http://dx.doi.org/10.1126/science.aaa1465.", "Arthur, C. 2015. Lenovo demonstrates that malware is big business. The Guardian (online), February 20, 2015, http://gu.com/p/462xy/stw.", "Ayanso, A., Cho, D. I., and Lertwachara, K. 2014. Information and communications technology development and the digital divide: A global and regional assessment. Information Technology for Development 20, 1, 60--77. DOI= http://dx.doi.org/10.1080/02681102.2013.797378."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789199"}, {"title": "A Hybrid Framework for Online Execution of Linked Data Queries", "authors": ["Mohamed M. Sabri"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLinked Data has been widely adopted over the last few years, with the size of the Linked Data cloud almost doubling every year. However, there is still no well-defined, efficient mechanism for querying such a Web of Data. We propose a framework that incorporates a set of optimizations to tackle various limitations in the state-of-the-art. The framework aims at combining the centralized query optimization capabilities of the data warehouse-based approaches with the result freshness and explorative data source discovery capabilities of link-traversal approaches. This is achieved by augmenting base-line link-traversal query execution with a set of optimization techniques. The proposed optimizations fall under two categories: metadata-based optimizations and semantics-based optimizations.", "references": ["Barry Bishop, Atanas Kiryakov, Damyan Ognyanov, Ivan Peikov, Zdravko Tashev, and Ruslan Velkov. Factforge: A fast track to the web of data. Semantic Web, 2(2):157--166, 2011.", "Eyal Oren, Renaud Delbru, Michele Catasta, Richard Cyganiak, Holger Stenzhorn, and Giovanni Tummarello. Sindice.com: a document-oriented lookup index for open linked data. Int. J. Metadata Semant. Ontologies, 3(1):37--52, November 2008.", "Andreas Harth, Jürgen Umbrich, Aidan Hogan, and Stefan Decker. YARS2: A federated repository for querying graph structured data from the web. In The Semantic Web, 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference, ISWC 2007"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741751"}, {"title": "Knowing the Brazilian Information Systems Community: A Comparative Study with Different Database Approaches", "authors": ["Natan de S. Rodrigues\n,", "Celia G. Ralha"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents the results of a research that has the objective to provide information about the Brazilian Information Systems Community. The study used data from the articles published on the main track of the Information Systems Brazilian Symposium (SBSI) from 2005 to 2014. The data were stored in two databases (DB), using different approaches database (relational and NoSQL).A study about efficiency aspects of both database approaches was conducted in order to investigate which alternative is better to store and retrieve information about the community.", "references": ["E. A. de Oliveira and V. M. F. Dias. Redes sociais do sbsi e o corte de vértices como base para identificar atores importantes na coesão de grupos de pesquisa. Simpósio Brasileiro de Sistemas de Informação 2012 (SBSI), 2012.", "M. J. A. Aaron Ai Tenenbaum, Yedidyah Langsam. Data Structures Using C. McGraw-Hill, Inc., 1989.", "C. Alberto Heuser. Projeto de Banco de dados: Uma visão prática. Editora Sagra Luzzato, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814146"}, {"title": "Whither Social Networks for Web Search?", "authors": ["Rakesh Agrawal\n,", "Behzad Golshan\n,", "Evangelos Papalexakis"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nAccess to diverse perspectives nurtures an informed citizenry. Google and Bing have emerged as the duopoly that largely arbitrates which English language documents are seen by web searchers. A recent study shows that there is now a large overlap in the top organic search results produced by them. Thus, citizens may no longer be able to gain different perspectives by using different search engines.\nWe present the results of our empirical study that indicates that by mining Twitter data one can obtain search results that are quite distinct from those produced by Google and Bing. Additionally, our user study found that these results were quite informative. The gauntlet is now on search engines to test whether our findings hold in their infrastructure for different social networks and whether enabling diversity has sufficient business imperative for them.", "references": ["Amazon Mechanical Turk, Requester Best Practices Guide. Amazon Web Services, June 2011.", "R. Agrawal, B. Golshan, and E. Papalexakis. A study of distinctiveness in web results of two search engines. In 24th international conference on World Wide Web, Web Science Track. ACM, 2015.", "O. Alonso, C. Carson, D. Gerster, X. Ji, and S. U. Nabar. Detecting uninteresting content in text streams. In SIGIR Crowdsourcing for Search Evaluation Workshop, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788571"}, {"title": "Learning to rank for question-oriented software text retrieval", "authors": ["Yanzhen Zou\n,", "Ting Ye\n,", "Yangyang Lu\n,", "John Mylopoulos\n,", "Lu Zhang"], "publication": "ASE '15: Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nQuestion-oriented text retrieval, aka natural language-based text retrieval, has been widely used in software engineering. Earlier work has concluded that questions with the same keywords but different interrogatives (such as how, what) should result in different answers. But what is the difference? How to identify the right answers to a question? In this paper, we propose to investigate the \"answer style\" of software questions with different interrogatives. Towards this end, we build classifiers in a software text repository and propose a re-ranking approach to refine search results. The classifiers are trained by over 16,000 answers from the StackOverflow forum. Each answer is labeled accurately by its question's explicit or implicit interrogatives. We have evaluated the performance of our classifiers and the refinement of our re-ranking approach in software text retrieval. Our approach results in 13.1% and 12.6% respectively improvement with respect to text retrieval criteria nDCG@1 and nDCG@10 compared to the baseline. We also apply our approach to FAQs of 7 open source projects and show 13.2% improvement with respect to nDCG@1. The results of our experiments suggest that our approach could find answers to FAQs more precisely.", "references": ["A. Bacchelli, A. Cleve, M. Lanza, and A. Mocci. Extracting structured data from natural language documents with island parsing. In Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on, pages 476--479. IEEE, 2011.", "C. M. Bishop et al. Pattern recognition and machine learning, volume 1. springer New York, 2006.", "S. Cai, Y. Zou, L. Wang, B. Xie, and W. Shao. A semi-supervised approach for component recommendation based on citations. In ICSR, pages 78--86. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/ASE.2015.24"}, {"title": "Statistical Audit via Gaussian Mixture Models in Business Intelligence Systems", "authors": ["Bruno H. A. Pilon\n,", "Joao Paulo C. L. da Costa\n,", "Juan J. Murillo-Fuentes\n,", "Rafael T. de Sousa"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nA Business Intelligence (BI) System employs tools from several areas of knowledge for the collection, integration and analysis of data to improve business decision making. The Brazilian Ministry of Planning, Budget and Management (MP) uses a BI System designed with the University of Brasilia to ascertain irregularities on the payroll of the Brazilian federal government, performing audit trails on selected items and fields of the payroll database. This current auditing approach is entirely deterministic, since the audit trails look for previously known signatures of irregularities which are composed by means of an ontological method used to represent auditors concept maps. In this work, we propose to incorporate a statistical filter in this existing BI system in order to increase its performance in terms of processing speed and overall system responsiveness. The proposed statistical filter is based on a generative Gaussian Mixture Model (GMM) whose goal is to provide a complete stochastic model of the process, specially the latent probability density function of the generative mixture, and use that model to filter the most probable payrolls. Inserting this statistical filter as a pre-processing stage preceding the deterministic auditing showed to be effective in reducing the amount of data to be analyzed by the audit trails, despite the penalty fee intrinsically associated with stochastic models due to the false negative outcomes that are not further processed. In our approach, gains obtained with the proposed pre-processing stage overcome impacts from false negative outcomes.", "references": ["Lee, K., Guillemot, L., Yue, Y., Kramer, M., Champion, D.: Application of the Gaussian mixture model in pulsar astronomy-pulsar classification and candidates ranking for the fermi 2fgl catalogue. Monthly Notices of the Royal Astronomical Society 424(4), 2832-2840 (2012).", "Lu, D., Moran, E., Batistella, M.: Linear mixture model applied to Amazonian vegetation classification. Remote sensing of environment 87(4), 456-469 (2003).", "Sönmez, M.K., Heck, L., Weintraub, M., Shriberg, E., Kemal, M., Larry, S., Mitchel, H., Shriberg, W.E.: A lognormal tied mixture model of pitch for prosody-based speaker recognition. SRI International (1997)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814165"}, {"title": "Product Sound Design: Form, Function, and Experience", "authors": ["Cumhur Erkut\n,", "Stefania Serafin\n,", "Michael Hoby\n,", "Jonniy Sårde"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nCurrent interactive products, services, and environments are appraised by their sensory attributes, in addition to their form and function. Sound is an important factor in these multisensory product appraisals. Integrating this sound opportunity into the design and development of interactive products, which are fit for real-world, yet constitute a strong brand identity, remains a challenge. We address this challenge by applying the research know-how of an academic institution and business practices of a sound agency SME within the core R&D and production process of the third industrial partner. Our approach has clear application scenarios in, e.g., extended wireless headsets, car audio appliances, and portable entertainment devices. We describe the prototypes developed during the project life span, and the activities and outcomes of a half-day workshop designed to disseminate the project results.", "references": ["Alves, V. N. N. and Roque, L. 2010. A pattern language for sound design in games. Proc. Audio Mostly (Piteå, Sweden, Sep. 2010), 12--8.", "Bech, S. and Zacharov, N. 2006. Perceptual Audio Evaluation. John Wiley & Sons, Ltd.", "Blauert, J. and Jekosch, U. 1997. Sound-Quality Evaluation A Multi-Layered Problem. Acta Acustica. 83, 3 (1997), 747--753."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814920"}, {"title": "Big Data Techniques For Supporting Accurate Predictions of Energy Production From Renewable Sources", "authors": ["Michelangelo Ceci\n,", "Roberto Corizzo\n,", "Fabio Fumarola\n,", "Michele Ianni\n,", "Donato Malerba\n,", "Gaspare Maria\n,", "Elio Masciari\n,"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nPredicting the output power of renewable energy production plants distributed on a wide territory is a really valuable goal, both for marketing and energy management purposes. Vi-POC (Virtual Power Operating Center) project aims at designing and implementing a prototype which is able to achieve this goal. Due to the heterogeneity and the high volume of data, it is necessary to exploit suitable Big Data analysis techniques in order to perform a quick and secure access to data that cannot be obtained with traditional approaches for data management. In this paper, we describe Vi-POC -- a distributed system for storing huge amounts of data, gathered from energy production plants and weather prediction services. We use HBase over Hadoop framework on a cluster of commodity servers in order to provide a system that can be used as a basis for running machine learning algorithms. Indeed, we perform one-day ahead forecast of PV energy production based on Artificial Neural Networks in two learning settings, that is, structured and non-structured output prediction. Preliminary experimental results confirm the validity of the approach, also when compared with a baseline approach.", "references": ["Big data. Nature, September 2008.", "Data, data everywhere. The Economist, Feb 2010.", "Drowning in numbers - digital data will flood the planet - and help us understand it better. The Economist, Nov 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790762"}, {"title": "N-gram IDF: A Global Term Weighting Scheme Based on Information Distance", "authors": ["Masumi Shirakawa\n,", "Takahiro Hara\n,", "Shojiro Nishio"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper first reveals the relationship between Inverse Document Frequency (IDF), a global term weighting scheme, and information distance, a universal metric defined by Kolmogorov complexity. We concretely give a theoretical explanation that the IDF of a term is equal to the distance between the term and the empty string in the space of information distance in which the Kolmogorov complexity is approximated using Web documents and the Shannon-Fano coding. Based on our findings, we propose N-gram IDF, a theoretical extension of IDF for handling words and phrases of any length. By comparing weights among N-grams of any N, N-gram IDF enables us to determine dominant N-grams among overlapping ones and extract key terms of any length from texts without using any NLP techniques. To efficiently compute the weight for all possible N-grams, we adopt two string processing techniques, i.e., maximal substring extraction using enhanced suffix array and document listing using wavelet tree. We conducted experiments on key term extraction and Web search query segmentation, and found that N-gram IDF was competitive with state-of-the-art methods that were designed for each application using additional resources and efforts. The results exemplified the potential of N-gram IDF.", "references": ["M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch. Replacing Suffix Trees with Enhanced Suffix Arrays. Journal of Discrete Algorithms, 2(1):53--86, Mar. 2004.", "A. Aizawa. An Information-Theoretic Perspective of TF-IDF Measures. Information Processing and Management, 39(1):45--65, Jan. 2003.", "C. H. Bennett, P. Gács, M. Li, P. M. Vitányi, and W. H. Zurek. Information Distance. IEEE Transactions on Information Theory, 44(4):1407--1423, July 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741628"}, {"title": "Privacy Disclosure from Wearable Devices", "authors": ["Tong Yan\n,", "Yachao Lu\n,", "Nan Zhang"], "publication": "PAMCO '15: Proceedings of the 2015 Workshop on Privacy-Aware Mobile Computing", "abstract": "ABSTRACT\nIn recent years, wearable devices have seen an explosive growth of popularity and a rapid enhancement of functionalities. Current off-the-shelf wearable devices offer pack sensors such as pedometer, gyroscope, accelerometer, altimeter, compass, GPS, and heart rate monitor. These sensors work together to quietly monitor various aspects of a user's daily life, enabling a wide spectrum of health- and social-related applications. Nevertheless, the data collected by such sensors, even in their aggregated form, may cause significant privacy concerns if shared with third-party applications and/or a user's social connections (as many wearable platforms now support). This paper studies a novel problem of the potential inference of sensitive user behavior from seemingly insensitive sensor outputs. Specifically, we examine whether it is possible to infer the behavioral sequence of a user such as moving from one place to another, visiting a coffee shop, grocery shopping, etc., based on the outputs of pedometer sensors (aggregated over certain time intervals, e.g., 1 minute). We demonstrate through real-world experiments that it is often possible to infer such behavior with a high success probability, raising privacy concerns on the sharing of such information as currently supported by various wearable devices.", "references": ["R. Agrawal, C. Faloutsos, and A. Swami. Efficient similarity search in sequence databases. Springer, 1993.", "F. J. Bianco. Pedometer and/or calorie measuring device and method, Aug. 8 1989. US Patent 4,855,942.", "K.-P. Chan and A.-C. Fu. Efficient time series matching by wavelets. In Data Engineering, 1999. Proceedings., 15th International Conference on, pages 126--133. IEEE, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757302.2757306"}, {"title": "When Personalization Meets Conformity: Collective Similarity based Multi-Domain Recommendation", "authors": ["Xi Zhang\n,", "Jian Cheng\n,", "Shuang Qiu\n,", "Zhenfeng Zhu\n,", "Hanqing Lu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nExisting recommender systems place emphasis on personalization to achieve promising accuracy. However, in the context of multiple domain, users are likely to seek the same behaviors as domain authorities. This conformity effect provides a wealth of prior knowledge when it comes to multi-domain recommendation, but has not been fully exploited. In particular, users whose behaviors are significant similar with the public tastes can be viewed as domain authorities. To detect these users meanwhile embed conformity into recommendation, a domain-specific similarity matrix is intuitively employed. Therefore, a collective similarity is obtained to leverage the conformity with personalization. In this paper, we establish a Collective Structure Sparse Representation(CSSR) method for multi-domain recommendation. Based on adaptive $k$-Nearest-Neighbor framework, we impose the lasso and group lasso penalties as well as least square loss to jointly optimize the collective similarity. Experimental results on real-world data confirm the effectiveness of the proposed method.", "references": ["S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Found. Trends Mach. Learn., 2011.", "A. Krohn-Grimberghe, L. Drumond, C. Freudenthaler, and L. Schmidt-Thieme. Multi-relational matrix factorization using bayesian personalized ranking for social network data. In WSDM, 2012.", "X. Ning and G. Karypis. SLIM: Sparse linear models for top-n recommender systems. In ICDM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767810"}, {"title": "Efficient similarity search in scientific databases with feature signatures", "authors": ["Merih Seran Uysal\n,", "Christian Beecks\n,", "Jochen Schmücking\n,", "Thomas Seidl"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nThe recent rapid growth of scientific data necessitates efficient similarity search techniques for which convenient object representation models are of vital importance. Feature signatures denoting highly flexible object feature representations have increasingly gained attention for which corresponding efficiency improvement techniques are developed. In this paper, we focus on efficient query processing with the well-known Earth Mover's Distance (EMD) on databases of feature signatures, and propose efficient approximation techniques successfully applicable to high-dimensional feature signatures via dimensionality reduction, guaranteeing both completeness and no false-dismissal within a filter-and-refine architecture. Rigorous experiments on real world data indicate a considerable reduction in the number of EMD computations and high efficiency of the proposed techniques which significantly reduce the query processing time.", "references": ["A. Andoni, P. Indyk, and R. Krauthgamer. Earth mover distance over high-dimensional spaces. SODA, pages 343--352, 2008.", "A. Armiti and M. Gertz. Geometric graph matching and similarity: A probabilistic approach. SSDBM '14, pages 27:1--27:12, 2014.", "I. Assent, A. Wenning, and T. Seidl. Approximation techniques for indexing the earth mover's distance in multimedia databases. In ICDE, page 11, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791384"}, {"title": "Browser GUI for generating web data extraction rules in Ducky", "authors": ["Kei Kanaoka\n,", "Motomichi Toyama"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nTo benefit from the invaluable data in the World Wide Web, manual extraction or creation of web scraping programs may be necessary. However, these processes can be tedious and complicated. To address these, we have proposed Ducky, which is a Web data extraction system including a web wrapper that extracts data from web sources and translates them into structured data based on user-defined data extraction rules. Ducky can extract data flexibly from various structured web pages, remove noise from extracted data and integrate data distributed to multiple pages from different sites. In this paper, we propose a browser GUI for Ducky. Instead of manually writing a configuration file, users can just click or point a cursor (mouse over) to objective elements. The users' actions are then automatically converted to data extraction rules and saved in a configuration file. Thus, we help users to extract the data by allowing intuitive operations and reduce users' burden in write the configuration file.", "references": ["K. Kanaoka, Y. Fujii, and M. Toyama. Ducky: A data extraction system for various structured web documents. In Proceedings of the 18th International Database Engineering & Applications Symposium, IDEAS '14, pages 342--347, New York, NY, USA, 2014. ACM.", "K. Kanaoka and M. Toyama. Effective web data extraction with ducky. In Proceedings of the 19th International Database Engineering & Applications Symposium, IDEAS '15, pages 212--213, New York, NY, USA, 2015. ACM.", "H. Sleiman and R. Corchuelo. A survey on region extractors from web documents. Knowledge and Data Engineering, IEEE Transactions on, 25(9):1960--1981, Sept. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837262"}, {"title": "Before the Repository: Defining the Preservation Threats to Research Data in the Lab", "authors": ["Stacy T. Kowalczyk"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThis paper describes the results of a large survey designed to quantify the risks and threats to the preservation of the research data in the lab and to determine the mitigating actions of researchers. A total of 724 National Science Foundation awardees completed this survey. Identifying risks and threats to digital preservation has been a significant research stream. Much of this work has been within the context of a preservation technology infrastructure such as data archives for a digital repository. This study looks at the risks and threats to research data prior to its inclusion in a preservation technology infrastructure. The greatest threat to preservation is human error, followed by equipment malfunction, obsolete software, and data corruption. Lost and mislabeled media are not components in the threat taxonomies developed for repositories; however, they do represent an important threat to research data in the lab. Researchers have recognized the need to mitigate the risks inherent in maintaining digital data by implementing data management in their lab environments and have taken their responsibility as data managers seriously; however, they would still prefer to have professional data management support.", "references": ["Altman, M., Adams, M. O., Crabtree, J., Donakowski, D., Maynard, M. M., Pienta, A., and Young, C. H. 2009. Digital preservation through archival collaboration: The data preservation alliance for the social sciences. American Archivist, 72,1, 170--184.", "Barateiro, J., Antunes, G., Cabral, M., Borbinha, J., and Rodrigues, R. 2008. Using a Grid for digital preservation. In Digital Libraries: Universal and Ubiquitous Access to Information, G. Buchanan, M. Masoodian, and S. J. Cunningham, Eds. Berlin: Springer, 225--235.", "Barateiro, J., Antunes, G., Freitas, F., and Borbinha, J. 2010. Designing digital preservation solutions: A risk management-based approach. International Journal of Digital Curation, 5, 1, 4--17."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756909"}, {"title": "Elsevier Journal Finder: Recommending Journals for your Paper", "authors": ["Ning Kang\n,", "Marius A. Doornenbal\n,", "Robert J.A. Schijvenaars"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRejection is the norm in academic publishing. One of the main reasons for rejections is that the topics of the submitted papers are not relevant to the scope of the journal, even when the papers themselves are excellent. Submission to a journal that fits well with the publication may avoid this issue. A system that is able to suggest journals that have published similar articles to the submitted papers may help authors choose where to submit. The Elsevier journal finder, a freely available online service, is one of the most comprehensive journal recommender systems, covering all scientific domains and more than 2,900 per-reviewed Elsevier journals. The system uses natural language processing for feature generation, and Okapi BM25 matching for the recommendation algorithm. The procedure is to paste text, such as an abstract, and get a list of recommend journals and relevant metadata. The website URL is http://journalfinder.elsevier.com.", "references": ["Bobadilla, J. et al. 2013. Recommender systems survey. Knowledge-Based Systems. 46, (2013), 109--132. DOI= http://dx.doi.org/10.1016/j.knosys.2013.03.012", "Burnham, J.F. 2006. Scopus database: a review. Biomedical digital libraries. 3, (2006), 1. DOI= http://dx.doi.org/10.1186%2F1742--5581--3--1", "Errami, M. et al. 2007. ETBLAST: A web server to identify expert reviewers, appropriate journals and similar publications. Nucleic Acids Research 35(S2)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799663"}, {"title": "Exploring Video Hyperlinking in Broadcast Media", "authors": ["Maria Eskevich\n,", "Quoc-Minh Bui\n,", "Hoang-An Le\n,", "Benoit Huet"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nMultimedia content produced by professionals and individual users on the daily basis and in constantly growing quantity requires creation of navigation systems that allow access to this data on different levels of granularity that can contribute to further discovery of a topic of user interest or to browsing by each user in an individual way. In this paper we describe our approach to enable the users to browse through the multimedia collection. We implement the hyperlinking approach that uses the fine-grained segmentation of the visual content based on the scene segmentation, as well as available metadata, transcripts, and information about extracted visual concepts.\nThe approach was tested at the MediaEval Search and Hyperlinking 2014 evaluation task, where it has shown its effectiveness at locating accurately relevant content in a large media archive.", "references": ["R. Aly, M. Eskevich, R. Ordelman, and G. J. F. Jones. Adapting binary information retrieval evaluation metrics for segment-based retrieval tasks. CoRR, abs/1312.1913, 2013.", "E. Apostolidis, V. Mezaris, M. Sahuguet, B. Huet, B. Cervenková, D. Stein, S. Eickeler, J. L. Redondo Garcia, R. Troncy, and L. Pikora. Automatic fine-grained hyperlinking of videos within a closed collection using scene segmentation. In ACMMM 2014, 22nd ACM International Conference on Multimedia, Orlando, Florida, USA, 11 2014.", "C. Bhatt, N. Pappas, M. Habibi, and A. Popescu-Belis. Idiap at MediaEval 2013: Search and Hyperlinking Task. In MediaEval 2013 Workshop, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814647"}, {"title": "Providing Services in an Intelligent Environment Conflict Management in Smart Home", "authors": ["Wassila Guebli\n,", "Abdelkader Belkhir"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nSmart house aims to improve the lives of people by meeting their needs and providing them with the comfort and well-being they desire. On the other hand, it should ensure good energy management by controlling all equipment of home. And to do this, it must allow the delegation of service between these equipment, example, if the heating is down it is replaced with the air conditioner. But the residents of this house have not necessarily the same needs or the same vision of comfort, which often created conflicts. In the following, we propose a service conflict management for detecting and resolving conflicts of multi-users in a smart home. The conflict occurs when users access to the same service remotely via the Web or being in the house. We describe house's services and define the types of conflicts. Then we introduce the concept of the necessary and preferred profiles to resolve conflict.", "references": ["N. King, \"Smart Home -- A Definition\", Housing LIN intro factsheet, Intertek Research & Testing Centre September 2003.", "D. Zeng, S. Guo, Z. Cheng, \"The Web of Things: A Survey\" Journal Of Communications, Vol. 6, No. 6, September 2011.", "S. Ramakrishnan, S. Ramakrishnan, \"WoT (Web of Things) for Energy Management in a Smart Grid-Connected Home\", Issues in Informing Science and Information Technology Volume 10, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816918"}, {"title": "Online Multimodal Co-indexing and Retrieval of Weakly Labeled Web Image Collections", "authors": ["Lei Meng\n,", "Ah-Hwee Tan\n,", "Cyril Leung\n,", "Liqiang Nie\n,", "Tat-Seng Chua\n,", "Chunyan Miao"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWeak supervisory information of web images, such as captions, tags, and descriptions, make it possible to better understand images at the semantic level. In this paper, we propose a novel online multimodal co-indexing algorithm based on Adaptive Resonance Theory, named OMC-ART, for the automatic co-indexing and retrieval of images using their multimodal information. Compared with existing studies, OMC-ART has several distinct characteristics. First, OMC-ART is able to perform online learning of sequential data. Second, OMC-ART builds a two-layer indexing structure, in which the first layer co-indexes the images by the key visual and textual features based on the generalized distributions of clusters they belong to; while in the second layer, images are co-indexed by their own feature distributions. Third, OMC-ART enables flexible multimodal search by using either visual features, keywords, or a combination of both. Fourth, OMC-ART employs a ranking algorithm that does not need to go through the whole indexing system when only a limited number of images need to be retrieved. Experiments on two published data sets demonstrate the efficiency and effectiveness of our proposed approach.", "references": ["J. C. Caicedo, J. BenAbdallah, F. A. González, and O. Nasraoui. Multimodal representation, indexing, automated annotation and retrieval of image collections via non-negative matrix factorization. Neurocomputing, 76(1):50--60, 2012.", "J. C. Caicedo, J. G. Moreno, E. A. Niño, and F. A. González. Combining visual features and text data for medical image retrieval using latent semantic kernels. In Proceedings of the international conference on Multimedia information retrieval, pages 359--366, 2010.", "P. Chandrika and C. V. Jawahar. Multi modal semantic indexing for image retrieval. In CIVR, pages 342--349, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749362"}, {"title": "D-Sieve: A Novel Data Processing Engine for Efficient Handling of Crises-Related Social Messages", "authors": ["Soudip Roy Chowdhury\n,", "Hemant Purohit\n,", "Muhammad Imran"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nExisting literature demonstrates the usefulness of system-mediated algorithms, such as supervised machine learning for detecting classes of messages in the social-data stream (e.g., topically relevant vs. irrelevant). The classification accuracies of these algorithms largely depend upon the size of labeled samples that are provided during the learning phase. Other factors such as class distribution, term distribution among the training set also play an important role on classifier's accuracy. However, due to several reasons (money / time constraints, limited number of skilled labelers etc.), a large sample of labeled messages is often not available immediately for learning an efficient classification model. Consequently, classifier trained on a poor model often mis-classifies data and hence, the applicability of such learning techniques (especially for the online setting) during ongoing crisis response remains limited. In this paper, we propose a post-classification processing step leveraging upon two additional content features-stable hashtag association and stable named entity association, to improve the classification accuracy for a classifier in realistic settings. We have tested our algorithms on two crisis datasets from Twitter (Hurricane Sandy 2012 and Queensland Floods 2013), and compared our results against the results produced by a \"best-in-class'' baseline online classifier. By showing the consistent better quality results than the baseline algorithm i.e., by correctly classifying the misclassified data points from the prior step (false negative and false positive to true positive and true negative classes, respectively), we demonstrate the applicability of our approach in practice.", "references": ["A. Bruns and Y. E. Liang. Tools and methods for capturing twitter data during natural disasters. First Monday, 17(4), 2012.", "M. A. Cameron, R. Power, B. Robinson, and J. Yin. Emergency situation awareness from twitter for crisis management. In Proceedings of the 21st international conference companion on World Wide Web, pages 695--698. ACM, 2012.", "D. Davidov, O. Tsur, and A. Rappoport. Enhanced sentiment learning using twitter hashtags and smileys. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 241--249. Association for Computational Linguistics, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741731"}, {"title": "Combining Advanced Information Retrieval and Text-Mining for Digital Humanities", "authors": ["Antoine Widlocher\n,", "Nicolas Bechet\n,", "Jean-Marc Lecarpentier\n,", "Yann Mathet\n,", "Julia Roger"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nDigital Humanities make more and more structured and richly annotated corpora available. Most of this data rely on well known and established standards, such as TEI, which especially enable scientists to edit and publish their work. However, one of the remaining problems is to give adequate access to this rich data, in order to produce higher-order knowledge.\nIn this paper, we present an integrated environment combining an advanced search engine and text-mining techniques for hermeneutics in Digital Humanities. Relying on semantic web technologies, the search engine uses full text as well as complex embedding structures and offers a single interface to access rich and heterogeneous data and meta-data. Text-mining possibilities enable scholars to exhibit regularities in corpora. Results obtained on the Cartesian corpus illustrate these principles and tools.", "references": ["TEI: Text Encoding Initiative, volume 24 of Cahiers Gutemberg, 1996.", "R. C. Agarwal, C. C. Aggarwal, and V. V. V. Prasad. Depth first generation of long patterns. In Proceedings of the sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Minin, pages 108--118. ACM Press, 2000.", "R. Agrawal, T. Imieliński, and A. Swami. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, SIGMOD '93, pages 207--216, New York, NY, USA, 1993. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797067"}, {"title": "A distributed file system with storage-media awareness", "authors": ["Herodotos Herodotou"], "publication": "UCC '15: Proceedings of the 8th International Conference on Utility and Cloud Computing", "abstract": "ABSTRACT\nImprovements in memory, storage devices, and network technologies are constantly exploited by distributed systems in order to meet the increasing data storage and I/O demands of modern large-scale data analytics. Some systems use memory and SSDs as a cache for local storage while others combine local with network-attached storage to increase performance. However, no work has ever looked at all layers together in a distributed setting. We present a novel design for a distributed file system that is aware of storage media (e.g., memory, SSDs, HDDs, NAS) with different capacities and performance characteristics. The storage media are explicitly exposed to users, allowing them to choose the distribution and placement of replicas in the cluster based on their own performance and fault tolerance requirements. Meanwhile, the system offers a variety of pluggable policies for automating data management with the dual goal of increased performance and better cluster utilization. These two features combined inspire new research opportunities for data-intensive processing systems.", "references": ["M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma et al., \"Resilient Distributed Datasets: A Fault-tolerant Abstraction for In-memory Cluster Computing,\" in Proc. of NSDI. USENIX, 2012, pp. 15--28.", "H. Li, A. Ghodsi, M. Zaharia, S. Shenker, and I. Stoica, \"Tachyon: Reliable, Memory Speed Storage for Cluster Computing Frameworks,\" in Proc. of SOCC. ACM, 2014, pp. 1--15.", "G. Ananthanarayanan, A. Ghodsi, A. Wang, D. Borthakur, S. Kandula, S. Shenker, and I. Stoica, \"PACMan: Coordinated Memory Caching for Parallel Jobs,\" in Proc. of NSDI. USENIX, 2012, pp. 267--280."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/3233397.3233469"}, {"title": "Current challenges in social media management", "authors": ["Kristian Tørning\n,", "Zeshan Jaffari\n,", "Ravi Vatrapu"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nSocial media management is an emerging field of academic research and organizational practice. It is concerned with the operational issues, managerial challenges, and comparative advantages that ensue from the adoption and use of social media platforms for organizational functions such as marketing and sales, customer support, product innovation etc. To investigate current social media managerial practices, we conducted a multiple case study, employing structured in-depth interviews with social media managers at some of the leading multi-national companies headquartered in Denmark (LEGO®, Mærsk®, PANDORA®, Novo Nordisk®, and Carlsberg®). Empirical findings uncover the prevailing perceptions about social media amongst the managers, typical managerial challenges tied directly to coordinating social media productions, and uncertainty about the return of investment on social media activities.", "references": ["Aral, S., and Walker, D. 2011. Creating social contagion through viral product design: A randomized trial of peer influence in networks. Management Science 57, 1623--1639.", "Chen, Y., Fay, S., and Wang, Q. 2011. The role of marketing in social media: How online consumer reviews evolve. Journal of Interactive Marketing 25, 85--94.", "Corbin, J. M. and Strauss, A. 1990. Grounded theory research: Procedures, canons, and evaluative criteria. Qualitative sociology 13, 3--21."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789191"}, {"title": "Multimedia Content Recommendation in Digital Convergence Environments: An Approach Based on Data Mining and Semantic Web", "authors": ["Priscilla Kelly Machado Vieira\n,", "Natasha Correia Queiroz Lino"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe emerging scenario of interactive Digital TV (iDTV) is promoting the increase of interactivity in the communication process and also in audiovisual production, thus raising the number of channels and resources available to the user. This reality makes the task of finding the desired content becoming a costly and possibly ineffective action. The incorporation of recommender systems in the iDTV environment is emerging as a possible solution to this problem. This work aims to propose a hybrid approach to content recommendation in iDTV, based on data mining techniques, integrated to the semantic web concepts, allowing structuring and standardization of data and consequently making possible sharing of information, providing semantics and automated reasoning. For the proposed service it is considered the Brazilian Digital TV System (SBTVD) and the middleware Ginga. A prototype has been developed and experiments carried out with a NetFlix database. As results, it was obtained an average accuracy of 30% using only the data mining technique. On the other hand, the evaluation including semantic rules obtained an average accuracy of 35%.", "references": ["Médola, A. S. L. (2009) Televisão Digital Brasileira e os Novos Processos de Produção de Conteúdos: Os Desafios para o Comunicador. Revista da Associação Nacional dos Programas de Pós-Graduação em Comunicagao | E-compós, Brasília, v. 12, n.3, set./dez.", "Resnick, P. and Varian, H. R. (1997) Recommender systems. Communications of the ACM. ACM 40, 3 (Mar. 1997), 56-58.", "Xu, M.; Berkovsky, S.; Ardon, S.; Triukose, S.; Mahanti, A.; Koprinska, I. Catch-up TV Recommendations: Show Old Favourites and Find New Ones. RecSys '13. p. 285-294."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814077"}, {"title": "Anchoring and Adjustment in Relevance Estimation", "authors": ["Milad Shokouhi\n,", "Ryen White\n,", "Emine Yilmaz"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPeople's tendency to overly rely on prior information has been well studied in psychology in the context of anchoring and adjustment. Anchoring biases pervade many aspects of human behavior. In this paper, we present a study of anchoring bias in information retrieval~(IR) settings. We provide strong evidence of anchoring during the estimation of document relevance via both human relevance judging and in natural user behavior collected via search log analysis. In particular, we show that sequential relevance judgment of documents collected for the same query could be subject to anchoring bias. That is, the human annotators are likely to assign different relevance labels to a document, depending on the quality of the last document they had judged for the same query.\nIn addition to manually assigned labels, we further show that the implicit relevance labels inferred from click logs can also be affected by anchoring bias. Our experiments over the query logs of a commercial search engine suggested that searchers' interaction with a document can be highly affected by the documents visited immediately beforehand. Our findings have implications for the design of search systems and judgment methodologies that consider and adapt to anchoring effects.", "references": ["B. Carterette and I. Soboroff. The effect of assessor error on ir system evaluation. In SIGIR, 2010.", "G. Dupret and C. Liao. A model to estimate intrinsic document relevance from the clickthrough logs of a web search engine. In WSDM, 2010.", "G. Dupret and B. Piwowarski. A user browsing model to predict search engine click data from past observations. In SIGIR, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767841"}, {"title": "Big Data?: Big Issues Degradation in Longitudinal Data and Implications for Social Sciences", "authors": ["Matthew S. Weber\n,", "Hai Nguyen"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nThis article analyzes the issue of degradation of data accuracy in large-scale longitudinal data sets. Recent research points to a number of issues with large-scale data, including problems of reliability, accuracy and quality over time. Simultaneously, large-scale data is increasingly being utilized in the social sciences. As scholars work to produce theoretically grounded research utilized \"small-scale\" methods, it is important for researchers to better understand the critical issues associated with the analysis of large-scale data. In order to illustrate the issues associated with this type of research, a case study analysis of archival Internet data is presented focusing on the issues of degradation of data accuracy over time. Suggestions for future studies are given.", "references": ["Tien, J. M. Big data: Unleashing information. Journal of Systems Science and Systems Engineering, 22, 2 2013), 127--151.", "Armstrong, K. Big data: a revolution that will transform how we live, work, and think. Information, Communication & Society, 17, 10 2014), 1300--1302.", "Lazer, D., Kennedy, R., King, G. and Vespignani, A. Big data. The parable of Google Flu: traps in big data analysis. Science, 343, 6176 (Mar 14 2014), 1203--1205."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786482"}, {"title": "Mining Scholarly Communication and Interaction on the Social Web", "authors": ["Asmelash Teka Hadgu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe explosion of Web 2.0 platforms including social networking sites such as Twitter, blogs and wikis affects all web users: scholars included. As a result, there is a need for a comprehensive approach to gain a broader understanding and timely signals of scientific communication as well as how researchers interact on the social web. Most current work in this area deals with either a low number of researchers and heavily relies on manual annotation or large-scale analysis without deep understanding of the underlying researcher population. In this proposal, we present a holistic approach to solve these problems. This research proposes novel methods to collect, filter, analyze and make sense of scholars and scholarly communication by integrating heterogeneous data sources from fast social media streams as well as the academic web. Applying reproducible research, contributing applications and data sets, the thesis proposal strives to add value by mining the social web for social good.", "references": ["J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1 -- 8, 2011.", "M. Conover, J. Ratkiewicz, M. Francisco, B. Gonçalves, A. Flammini, and F. Menczer. Political polarization on twitter. In Proc. 5th Intl. Conference on Weblogs and Social Media, 2011.", "G. Eysenbach. Can tweets predict citations? metrics of social impact based on twitter and correlation with traditional metrics of scientific impact. J Med Internet Res, 13(4), 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741749"}, {"title": "Detecting Clusters of Fake Accounts in Online Social Networks", "authors": ["Cao Xiao\n,", "David Mandell Freeman\n,", "Theodore Hwa"], "publication": "AISec '15: Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security", "abstract": "ABSTRACT\nFake accounts are a preferred means for malicious users of online social networks to send spam, commit fraud, or otherwise abuse the system. A single malicious actor may create dozens to thousands of fake accounts in order to scale their operation to reach the maximum number of legitimate members. Detecting and taking action on these accounts as quickly as possible is imperative in order to protect legitimate members and maintain the trustworthiness of the network. However, any individual fake account may appear to be legitimate on first inspection, for example by having a real-sounding name or a believable profile.\nIn this work we describe a scalable approach to finding groups of fake accounts registered by the same actor. The main technique is a supervised machine learning pipeline for classifying {\\em an entire cluster} of accounts as malicious or legitimate. The key features used in the model are statistics on fields of user-generated text such as name, email address, company or university; these include both frequencies of patterns {\\em within} the cluster (e.g., do all of the emails share a common letter/digit pattern) and comparison of text frequencies across the entire user base (e.g., are all of the names rare?).\nWe apply our framework to analyze account data on LinkedIn grouped by registration IP address and registration date. Our model achieved AUC 0.98 on a held-out test set and AUC 0.95 on out-of-sample testing data. The model has been productionalized and has identified more than 250,000 fake accounts since deployment.", "references": ["S. Adikari and K. Dutta. Identifying fake profiles in LinkedIn. Pacific Asia Conference on Information Systems Proceedings 2014, 2014.", "J. Beall. Publisher uses fake LinkedIn identities to attract submissions. http://scholarlyoa.com/2015/02/10/publisher-uses-fake-linkedin-identities-to-attract-submissions.", "B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. In Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, pages 144--152. ACM Press, 1992."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808769.2808779"}, {"title": "Preference-oriented Social Networks: Group Recommendation and Inference", "authors": ["Amirali Salehi-Abari\n,", "Craig Boutilier"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nSocial networks facilitate a variety of social, economic, and political interactions. Homophily---the tendency for people to associate or interact with similar peers---and social influence---the tendency to adopt certain characteristics of those with whom one interacts---suggest that preferences (e.g., over products, services, political parties) are likely to be correlated among people whom directly interact in a social network. We develop a model, preference-oriented social networks, that captures such correlations of individual preferences, where preferences take the form of rankings over a set of options. We develop probabilistic inference methods for predicting individual preferences given observed social connections and partial observations of the preferences of others in the network. We exploit these predictions in a social choice context to make group decisions or recommendations even when the preferences of some group members are unobserved. Experiments demonstrate the effectiveness of our algorithms and the improvements made possible by accounting for social ties.", "references": ["S. Amer-Yahia, S. B. Roy, A. Chawlat, G. Das, and C. Yu. Group recommendation: Semantics and efficiency. Proc. VLDB Endow., 2(1):754--765, 2009.", "K. Arrow. Social Choice and Individual Values. 1951.", "L. Baltrunas, T. Makcinskas, and F. Ricci. Group recommendations with rank aggregation and collaborative filtering. Proc. 4th ACM Conf. on RecommenderSystems (RecSys-10), pp.119--126, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800190"}, {"title": "Exploiting Spatial Relationship between Scenes for Hierarchical Video Geotagging", "authors": ["Yifang Yin\n,", "Luming Zhang\n,", "Roger Zimmermann"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nPredicting the location of a video based on its content is a very meaningful, yet very challenging problem. Most existing work has focused on developing representative visual features and then searching for visually nearest neighbors in the development set to achieve a prediction. Interestingly, the relationship between scenes has been overlooked in prior work. Two scenes that are visually different, but frequently co-occur in same location, should naturally be considered similar for the geotagging problem. To build upon the above ideas, we propose to model the geo-spatial distributions of scenes by Gaussian Mixture Models (GMMs) and measure the distribution similarity by the Jensen-Shannon divergence (JSD). Subsequently, we present the Spatial Relationship Model (SRM) for geotagging which integrates the geo-spatial relationship of scenes into a hierarchical framework. We segment the Earth's surface into multiple levels of grids and measure the likelihood of input videos with an adaptation to region granularities. We have evaluated our approach using the YFCC100M dataset in the context of the MediaEval 2014 placing task. The total set of 35,000 geotagged videos is further divided into a training set of 25,000 videos and a test set of 10,000 videos. Our experimental results demonstrate the effectiveness of our proposed framework, as our solution achieves good accuracy and outperforms existing visual approaches for video geotagging.", "references": ["Electronic Statistics Textbook. StatSoft, Inc, 2011.", "J. Almeida, N. Leite, and R. Torres. Comparison of Video Sequences with Histograms of Motion Patterns. In Image Processing, 2011.", "C. Brunsdon, A. Fotheringham, and M. Charlton. Geographically Weighted Summary Statistics - A Framework for Localised Exploratory Data Analysis. Computers, Environment and Urban Systems, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749354"}, {"title": "Greedy-Bayes for Targeted News Dissemination", "authors": ["Laurent Massoulié\n,", "Mesrob I. Ohannessian\n,", "Alexandre Proutière"], "publication": "SIGMETRICS '15: Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems", "abstract": "ABSTRACT\nThis work addresses user targeting for news content delivery. Specifically, we wish to disseminate a fresh news content, whose topic is yet unknown, to all interested users, while \"spamming\" a minimum number of uninterested users. We formulate this as an online stochastic optimization problem that extends in several ways the classical multi-armed bandit problem.\nWe introduce Greedy-Bayes, a policy with appealing robustness properties. We establish optimal scaling of a suitably defined regret measure in various scenarios of interest. To that end we develop an original proof technique based on martingale concentration inequalities. Numerical experiments show that Greedy-Bayes improves upon Thompson sampling, the state-of-the-art algorithm for bandit problems.\nOur analysis further implies that low regret can only be achieved if the assessment of content relevance for one user leverages feedback from users with widely distinct tastes. This impacts the design of efficient news dissemination platforms: existing systems typically do not leverage such negative feedback and could hence be improved upon with adequate extensions.", "references": ["D. A. Berry, R. W. Chen, A. Zame, D. C. Heath, and L. A. Shepp. Bandit problems with infinitely many arms. Annals of Statistics, 25(5):2103--2116, 1997.", "T. Bonald and A. Proutiere. Two-threshold algorithms for the infinite-armed bandits with Bernoulli rewards. In Advances in Neural Information Processing Systems 26, pages 2184--2192. 2013.", "S. Bubeck and N. Cesa-Bianchi. Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems. Foundations and Trends in Machine Learning, 5(1):1--122, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745844.2745868"}, {"title": "Searching and Stopping: An Analysis of Stopping Rules and Strategies", "authors": ["David Maxwell\n,", "Leif Azzopardi\n,", "Kalervo Järvelin\n,", "Heikki Keskustalo"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSearching naturally involves stopping points, both at a query level (how far down the ranked list should I go?) and at a session level (how many queries should I issue?). Understanding when searchers stop has been of much interest to the community because it is fundamental to how we evaluate search behaviour and performance. Research has shown that searchers find it difficult to formalise stopping criteria, and typically resort to their intuition of what is \"good enough\". While various heuristics and stopping criteria have been proposed, little work has investigated how well they perform, and whether searchers actually conform to any of these rules. In this paper, we undertake the first large scale study of stopping rules, investigating how they influence overall session performance, and which rules best match actual stopping behaviour. Our work is focused on stopping at the query level in the context of ad-hoc topic retrieval, where searchers undertake search tasks within a fixed time period. We show that stopping strategies based upon the disgust or frustration point rules - both of which capture a searcher's tolerance to non-relevance - typically result in (i) the best overall performance, and (ii) provide the closest approximation to actual searcher behaviour, although a fixed depth approach also performs remarkably well. Findings from this study have implications regarding how we build measures, and how we conduct simulations of search behaviours.", "references": ["L. Azzopardi. The economics in interactive information retrieval. In Proc. 34th ACM SIGIR, pages 15--24, 2011.", "F. Baskaya. Simulating Search Sessions in Interactive Information Retrieval Evaluation. PhD thesis, University of Tampere, School of Information Sciences, Finland, 2014.", "F. Baskaya, H. Keskustalo, and K. Järvelin. Time drives interaction: Simulating sessions in diverse searching environments. In Proc. 35th ACM SIGIR, pages 105--114, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806476"}, {"title": "Effective Fuzzy Possibilistic C-Means: An Analyzing Cancer Medical Database", "authors": ["S. Ramathilagam\n,", "S. R. Kannan\n,", "R. Devi"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nUsing clustering analysis for identifying cancer types in Colon cancer dataset is extremely difficult task because of high-dimensionality gene with noise. Most of the existing clustering methods for colon to achieve types of cancers often hamper the interpretability of the structure. Hence, this paper presents effective fuzzy c-means by incorporating the membership function of fuzzy c-means, the typicality of possibilistic c-means approaches, kernel functions, to find cancer subtypes in the colon cancer database. This paper successfully finds the subtypes of cancers in Colon database using the proposed method. The superiority of the proposed method has been proved through clustering accuracy.", "references": ["Alon. U et al., Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays, Proc. Natl. Acad. Sci. USA 96 (1999) 6745--6750.", "Bezdek J. C., Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum Press, New York, (1981).", "Hartigan, J. A. (1975) Clustering Algorithms. Wiley, NewYork."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818870"}, {"title": "Concurrent compaction using a field pinning protocol", "authors": ["Erik Österlund\n,", "Welf Löwe"], "publication": "ISMM '15: Proceedings of the 2015 International Symposium on Memory Management", "abstract": "ABSTRACT\nCompaction of memory in long running systems has always been important. The latency of compaction increases in today’s systems with high memory demands and large heaps. To deal with this problem, we present a lock-free protocol allowing for copying concurrent with the application running, which reduces the latencies of compaction radically. It provides theoretical progress guarantees for copying and application threads without making it practically infeasible, with performance overheads of 15% on average. The algorithm paves the way for a future lock-free Garbage Collector.", "references": ["A. W. Appel, J. R. Ellis, and K. Li. Real-time concurrent collection on stock multiprocessors. In ACM SIGPLAN Notices, volume 23, pages 11–20. ACM, 1988.", "D. F. Bacon, P. Cheng, and V. Rajan. The Metronome: A simpler approach to garbage collection in real-time systems. In On the Move to Meaningful Internet Systems 2003: OTM 2003 Workshops, pages 466–478. Springer, 2003.", "H. G. Baker Jr. List processing in real time on a serial computer. Communications of the ACM, 21(4):280–294, 1978."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2754169.2754177"}, {"title": "Granularity as a qualitative concept for GIR", "authors": ["Dirk Ahlers"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nWe examine the notion of granularity for qualitative thinking about geospatial data and location references. Granularity can be understood as an abstraction of level of detail or spatial resolution. Pure coordinates, which may exhibit strong overprecision for some entities, can be combined with not only hierarchical gazetteer information, but also with derived semantic data about extent of places and thus help in correct interpretations without necessarily more accuracy.", "references": ["D. Ahlers. Assessment of the Accuracy of GeoNames Gazetteer Data. GIR '13. ACM, 2013.", "D. Ahlers. Search and navigation in complex overlapping urban spaces. In Making Places Workshop @ NordiCHI2014, 2014.", "L. L. Hill. Core Elements of Digital Gazetteers: Placenames, Categories, and Footprints. ECDL, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837704"}, {"title": "Enhancing Exploration with a Faceted Browser through Summarization", "authors": ["Grzegorz Drzadzewski\n,", "Frank Wm. Tompa"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nAn enhanced faceted browsing system has been developed to support users' exploration of large multi-tagged document collections. It provides summary measures of document result sets at each step of navigation through a set of representative terms and a diverse set of documents. These summaries are derived from pre-materialized views that allow for quick calculation of centroids for various result sets. The utility and efficiency of the system is demonstrated on the New York Times Annotated Corpus.", "references": ["D. R. Cutting, J. O. Pedersen, D. R. Karger, and J. W. Tukey. Scatter/Gather: A cluster-based approach to browsing large document collections. In Proc. 15th Ann. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr., pages 318--329, 1992.", "V. Deolalikar. Distance or coverage?: Retrieving knowledge-rich documents from enterprise text collections. In Proc. 23rd ACM Int. Conf. on Inf. Knowl. Manage., CIKM 2014, pages 1771--1774, 2014.", "G. Drzadzewski. On-Line Analytical Systems for Multi-Tagged Document Collections. PhD thesis, Cheriton Sch. Comp. Sci., Univ. Waterloo, 2015. in preparation."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797083"}, {"title": "Non-Bayesian Additive Regularization for Multimodal Topic Modeling of Large Collections", "authors": ["Konstantin Vorontsov\n,", "Oleksandr Frei\n,", "Murat Apishev\n,", "Peter Romov\n,", "Marina Suvorova\n,", "Anastasia Yanina"], "publication": "TM '15: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications", "abstract": "ABSTRACT\nProbabilistic topic modeling of text collections is a powerful tool for statistical text analysis based on the preferential use of graphical models and Bayesian learning. Additive regularization for topic modeling (ARTM) is a recent semiprobabilistic approach, which provides a simpler inference for many models previously studied only in the Bayesian settings. ARTM reduces barriers to entry into topic modeling research field and facilitates combination of topic models. In this paper we develop the multimodal extension of ARTM approach and implement it in BigARTM open source project for online parallelized topic modeling. We demonstrate the ability of non-Bayesian regularization to combine modalities, languages and multiple criteria to find sparse, diverse, and interpretable topics.", "references": ["N. Bassiou and C. Kotropoulos. Online PLSA: Batch updating techniques including out-of-vocabulary words. Neural Networks and Learning Systems, IEEE Transactions on, 25(11):1953--1966, Nov 2014.", "D. M. Blei. Probabilistic topic models. Communications of the ACM, 55(4):77--84, 2012.", "D. M. Blei and M. I. Jordan. Modeling annotated data. In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, pages 127--134, New York, NY, USA, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809936.2809943"}, {"title": "Session details: Main Track - Artificial Intelligence for Information Systems", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252431"}, {"title": "Spoken content retrieval: beyond cascading speech recognition with text retrieval", "authors": ["Lin-shan Lee\n,", "James Glass\n,", "Hung-yi Lee\n,", "Chun-an Chan"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nSpoken content retrieval refers to directly indexing and retrieving spoken content based on the audio rather than text descriptions. This potentially eliminates the requirement of producing text descriptions for multimedia content for indexing and retrieval purposes, and is able to precisely locate the exact time the desired information appears in the multimedia. Spoken content retrieval has been very successfully achieved with the basic approach of cascading automatic speech recognition (ASR) with text information retrieval: after the spoken content is transcribed into text or lattice format, a text retrieval engine searches over the ASR output to find desired information. This framework works well when the ASR accuracy is relatively high, but becomes less adequate when more challenging real-world scenarios are considered, since retrieval performance depends heavily on ASR accuracy. This challenge leads to the emergence of another approach to spoken content retrieval: to go beyond the basic framework of cascading ASR with text retrieval in order to have retrieval performances that are less dependent on ASR accuracy. This overview article is intended to provide a thorough overview of the concepts, principles, approaches, and achievements of major technical contributions along this line of investigation. This includes five major directions: 1) Modified ASR for Retrieval Purposes: cascading ASR with text retrieval, but the ASR is modified or optimized for spoken content retrieval purposes; 2) Exploiting the Information not present in ASR outputs: to try to utilize the information in speech signals inevitably lost when transcribed into phonemes and words; 3) Directly Matching at the Acoustic Level without ASR: for spoken queries, the signals can be directly matched at the acoustic level, rather than at the phoneme or word levels, bypassing all ASR issues; 4) Semantic Retrieval of Spoken Content: trying to retrieve spoken content that is semantically related to the query, but not necessarily including the query terms themselves; 5) Interactive Retrieval and Efficient Presentation of the Retrieved Objects: with efficient presentation of the retrieved objects, an interactive retrieval process incorporating user actions may produce better retrieval results and user experiences.", "references": ["G. Tur and R. DeMori, Spoken Language Understanding: Systems for Extracting Semantic Information from Speech. New York, NY, USA: Wiley, 2011, ch. 15, pp. 417--446.", "C. Chelba, T. Hazen, and M. Saraclar, \"Retrieval and browsing of spoken content,\" IEEE Signal Process. Mag., vol. 25, no. 3, pp. 39--49, May 2008.", "M. Larson and G. J. F. Jones, \"Spoken content retrieval: A survey of techniques and technologies,\" Found. Trends Inf. Retr., vol. 5, pp. 235--422, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2015.2438543"}, {"title": "Answering questions based on gradually learned knowledge from the web using lightweight semantics", "authors": ["Lukas Loch\n,", "Pavol Navrat\n,", "Alena Kovarova"], "publication": "CompSysTech '15: Proceedings of the 16th International Conference on Computer Systems and Technologies", "abstract": "ABSTRACT\nIn this paper, we describe an approach to answering natural language questions that is based on knowledge acquired from the Web by a current search engine. Our system gradually builds a lightweight semantic knowledge base that is used to select the answer. Explicit feedback from the interested fellow helps readjust weights of the triplets in a learning-like process. Questions are not restricted to be of specific kinds. Already in an early stage of experimenting, our system was able to bring notable improvement in comparison to its underlying search engine.", "references": ["Bing, L., Lam, W., Wong, T. and Jameel, S. 2015. Web Query Reformulation via Joint Modeling of Latent Topic Dependency and Term Context. ACM Trans. Inf. Syst. 33, 2, Article 6 (February 2015), 38 pages.", "Dror, G., Maarek, Y., Mejer, A. and Szpektor, I. 2013. From query to question in one click: suggesting synthetic questions to searchers. In Proceedings of the 22nd international conference on World Wide Web (WWW '13). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 391--402.", "Elizabeth, E. R. P.; Ramprasath, M.; Hariharan, S. 2013. Improving QA processing by semantic reformulation, Computer Communication and Informatics (ICCCI), 2013 International Conference on, IEEE, 1--4."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2812428.2812435"}, {"title": "A Social Formalism and Survey for Recommender Systems", "authors": ["Daniel Bernardes\n,", "Mamadou Diaby\n,", "Raphaël Fournier\n,", "Françoise FogelmanSoulié\n,", "Emmanuel Viennet"], "publication": "ACM SIGKDD Explorations Newsletter", "abstract": "Abstract\nThis paper presents a general formalism for Recommender Systems based on Social Network Analysis. After introducing the classical categories of recommender systems, we present our Social Filtering formalism and show that it extends association rules, classical Collaborative Filtering and Social Recommendation, while providing additional possibilities. This allows us to survey the literature and illustrate the versatility of our approach on various publicly available datasets, comparing our results with the literature.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, 2005.", "D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 19--28. ACM, 2009.", "F. Aiolli. Efficient top-n recommendation for very large scale binary rated datasets. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys '13, pages 273--280, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783702.2783705"}, {"title": "Implementation and evaluation of cloud-based integration framework for indoor location", "authors": ["Long Niu\n,", "Sachio Saiki\n,", "Shinsuke Matsumoto\n,", "Masahide Nakamura"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThe emerging indoor positioning systems (IPS) enable indoor location-aware applications (InL-App) within indoor space where GPS cannot reach. In most conventional systems, however, IPS and InL-App are tightly coupled, where one system cannot reuse location data or operation of other systems. This fact yields expensive development cost and effort of InL-App. To cope with the problem, this paper propose a cloud-based integration framework, called CIF4InL. With a common data model, CIF4InL integrates indoor location data obtained from heterogeneous IPS. It then provides application-neutral API for various InL-Apps. To evaluate the practical feasibility, we integrate two different IPS (RedPin and BluePin) using CIF4InL, where the applications transparently access the indoor locations gathered by two different IPS. Since CIF4InL allows the loose coupling between IPS and InL-Apps, it significantly improves reusability of indoor location information and operation.", "references": ["P. Bolliger. Redpin - adaptive, zero-configuration indoor localization through user collaboration. In Proceedings of the First ACM International Workshop on Mobile Entity Localization and Tracking in GPS-less Environments, MELT '08, pages 55--60, September 2008.", "F. Brachmann. A multi-platform software framework for the analysis of multiple sensor techniques in hybrid positioning systems. In Proceedings of 10th Conference on Telematics Engineering, JITEL 2011, September 2011.", "K. Gubi, R. Wasinger, M. Fry, J. Kay, T. Kuflik, and R. Kummerfeld. Towards a generic platform for indoor localisation using existing infrastructure and symbolic maps. In Proceedings of 18th International Conference on User Modelling, Adaptation and Personalisation, June 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837220"}, {"title": "HPDBSCAN: highly parallel DBSCAN", "authors": ["Markus Götz\n,", "Christian Bodenstein\n,", "Morris Riedel"], "publication": "MLHPC '15: Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments", "abstract": "ABSTRACT\nClustering algorithms in the field of data-mining are used to aggregate similar objects into common groups. One of the best-known of these algorithms is called DBSCAN. Its distinct design enables the search for an apriori unknown number of arbitrarily shaped clusters, and at the same time allows to filter out noise. Due to its sequential formulation, the parallelization of DBSCAN renders a challenge. In this paper we present a new parallel approach which we call HPDBSCAN. It employs three major techniques in order to break the sequentiality, empower workload-balancing as well as speed up neighborhood searches in distributed parallel processing environments i) a computation split heuristic for domain decomposition, ii) a data index preprocessing step and iii) a rule-based cluster merging scheme.\nAs a proof-of-concept we implemented HPDBSCAN as an OpenMP/MPI hybrid application. Using real-world data sets, such as a point cloud from the old town of Bremen, Germany, we demonstrate that our implementation is able to achieve a significant speed-up and scale-up in common HPC setups. Moreover, we compare our approach with previous attempts to parallelize DBSCAN showing an order of magnitude improvement in terms of computation time and memory consumption.", "references": ["H. Abdi. Coefficient of variation. Encyclopedia of research design, pages 169--171, 2010.", "G. M. Amdahl. Validity of the single processor approach to achieving large scale computing capabilities. In Proceedings of the spring joint computer conference 1967, pages 483--485. ACM, 1967.", "D. Arlia and M. Coppola. Experiments in parallel clustering with dbscan. In Euro-Par 2001 Parallel Processing, pages 326--331. Springer, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834892.2834894"}, {"title": "Mining the metadata: and its consequences", "authors": ["Susan Landau"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 1", "abstract": "ABSTRACT\nTraditionally metadata, the who, when, where of a phone call, the IP address, time, date of an Internet connection, has been viewed as deserving of less privacy than the contents of the communication. But ubiquitous computing and communication has changed that equation, and such transactional information has become increasingly revelatory. In this talk, I will discuss how metadata is used in all sorts of investigations, from malware to malfeasance. I will also discuss how the ubiquity of metadata must mean a change in our approaches to it.", "references": ["Bellovin, Steven M., Matt Blaze, Susan Landau, and Stephanie Pell, \"It's Too Complicated: The Technological Implications of IP-Based Communications on Content/Non-Content Distinctions and the Third Party Doctrine\".", "Beard, Kate, \"A Structure for Organizing Information, Proceedings 3rd International Conference on Integrating GIS and Environmental Modeling, Sante Fe, NM. Jan 21--26. Santa Barbara, CA: NCGIA. http://www.ncgia.ucsb.edu/conf/sante-fe_cd_rom/main.html.", "Court of Justice of the European Union, Digital Rights Ireland Ltd. C-293/12) Minister for Communications, Marine and Natural Resources, Minister for Justice, Equality and Law Reform, Commissioner of the Garda Siochana, Ireland, The Attorney General, intervener: Irish Human Rights Commission, and Karntner Landesregierung (C-594/12) Michael Seitlinger, Christof Tschohl and others, April 8, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2818754.2818757"}, {"title": "Large-scale Efficient and Effective Video Similarity Search", "authors": ["Merih Seran Uysal\n,", "Christian Beecks\n,", "Daniel Sabinasz\n,", "Thomas Seidl"], "publication": "LSDS-IR '15: Proceedings of the 2015 Workshop on Large-Scale and Distributed System for Information Retrieval", "abstract": "ABSTRACT\nRecently, the rich diversity of the video capture devices and the high usage of the Internet have generated a great amount of video data, which attracts the attention of researchers with respect to the development of novel effective and efficient video retrieval approaches. In this paper, we investigate the effectiveness and efficiency of the lower-bounding filter distance functions of the well-known similarity measure Earth Mover's Distance (EMD) on signature databases, including the recently introduced Independent Minimization for Signatures (IM-Sig). We conduct the experiments on a public dataset comprising various categories with visually similar videos, and another large-scale real world video dataset consisting of 350,000 near-duplicate videos. To the best of our knowledge, this is the first work investigating the effectiveness and efficiency of the lower-bounding filter distance functions on databases consisting of signatures, i.e adaptive-binned representations. The experimental evaluation indicates both high effectiveness and efficiency of the IM-Sig, outperforming the state-of-the-art techniques.", "references": ["R. Agrawal, C. Faloutsos, and A. N. Swami. Efficient similarity search in sequence databases. In FODO, pages 69--84, 1993.", "R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows: Theory, Algorithms, and Applications. Pearson Education Limited, England, 2014.", "I. Assent, A. Wenning, and T. Seidl. Approximation techniques for indexing the earth mover's distance in multimedia databases. In ICDE, page 11, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809948.2809950"}, {"title": "The pros and cons of the 'PACM' proposal: point", "authors": ["Kathryn S. McKinley"], "publication": "Communications of the ACM", "abstract": "Abstract\nOn p. 5 of this issue, ACM Publications Board co-chairs Joseph A. Konstan and Jack W. Davidson introduce a proposal that would interweave conference and journal publishing. Here, computer scientists Kathryn S. McKinley and David S. Rosenblum argue for and against the proposal.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811406"}, {"title": "Big Scholarly Data in CiteSeerX: Information Extraction from the Web", "authors": ["Alexander G. Ororbia\n,", "Jian Wu\n,", "Madian Khabsa\n,", "Kyle WIlliams\n,", "Clyde Lee Giles"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe examine CiteSeerX, an intelligent system designed with the goal of automatically acquiring and organizing large-scale collections of scholarly documents from the world wide web. From the perspective of automatic information extraction and modes of alternative search, we examine various functional aspects of this complex system with an eye towards ongoing and future research developments.", "references": ["S. Bhatia, C. Caragea, H.-H. Chen, J. Wu, P. Treeratpituk, Z. Wu, M. Khabsa, P. Mitra, and C. L. Giles. Specialized research datasets in the CiteSeerX digital library. In D-Lib Magazine, volume 18, 2012.", "C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.", "C. Caragea, J. Wu, A. Ciobanu, K. Williams, J. Fernandez-Ramirez, H.-H. Chen, Z. Wu, and C. L. Giles. Citeseerx: A scholarly big dataset. ECIR '14, pages 311--322, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741736"}, {"title": "Coarse to fine keyword queries with user interactions", "authors": ["Khadim Dramé\n,", "Grégory Smits\n,", "Olivier Pivert"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nA large amount of linked data is now available, but to retrieve knowledge from these data, queries have to be formulated using formal query languages. While expressive query languages are developed, their use by end users, generally not familiar with formal languages, is limited. Keyword-based search is considered as a convenient and intuitive way for users to express their information needs. Keyword search over structured data is thus an interesting alternative but which raises challenging issues. The main challenge is to determine the meaning of a keyword query in order to translate it into a target formal query language, SPARQL in our case. In this paper, we address this challenge and propose a novel approach that relies on user interactions to determine the correct interpretation of the keyword query. The principle is to first ask the user to define a coarse keyword query, then to suggest candidate interpretations expressed in an explicit, thus unambiguous, and human readable form. Once the correct interpretation has been selected, the query may be refined with aggregate functions and comparatives. Experiments conducted on a large knowledge base show the effectiveness and the efficiency of the proposed approach.", "references": ["J. H. Reif, \"Depth-first search is inherently sequential,\" Information Processing Letters, vol. 20, no. 5, pp. 229--234, 1985.", "G. Li, B. C. Ooi, J. Feng, J. Wang, and L. Zhou, \"Ease: an effective 3-in-1 keyword search method for unstructured, semi-structured and structured data,\" in Proc of the 2008 ACM SIGMOD international conference on Management of data, 2008, pp. 903--914.", "P. Cimiano, V. Lopez, C. Unger, E. Cabrio, A. N. Ngomo, and S. Walter, \"Multilingual question answering over linked data (QALD-3): lab overview,\" in Proc of the 4th CLEF Conference, ser. Lecture Notes in Computer Science, P. Forner, H. Müller, R. Paredes, P. Rosso, and B. Stein, Eds., vol. 8138, 2013, pp. 321--332."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837210"}, {"title": "An adaptative semantic model for internet accessibility visually impaired users", "authors": ["Tatiana Sorrentino\n,", "Joaquim Macedo\n,", "Alexandre Santos\n,", "Cláudia Ribeiro"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThis study presents the design and the development of a semantic model to transcode Internet websites, in order to improve accessibility for visually impaired people. Accessibility standards, semantic web concepts and site adaptation are the main points of this proposal. As a strategy of scope definition and model validation, this work analyses two experimental scenarios: one in the context of Brazilian semiarid region and another in adaptation of online social networks interactions. The main goal is to make Internet navigation a more effective experience for visually impaired people. The results of the experiments are pages enriched with informations adapted for blind people.", "references": ["WCAG, \"W3C Web Content Accessibility Guidelines,\" 2008. [Online]. Available: http://www.w3.org/TR/WCAG10/. [Accessed: 18-Feb-2014].", "Y. Yesilada, R. Stevens, S. Harper, and C. Goble, \"Evaluating DANTE,\" ACM Transactions on Computer-Human Interaction, vol. 14, no. 3, Sep. 2007.", "A. S. E. For and O. In, \"SEMA4A: A K NOWLEDGE B ASE FOR ACCESSIBLE EVACUATION AND ALERT NOTIFICATIONS IN EMERGENCIES,\" Universidad Carlos III de Madrid, PHD Thesis, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837255"}, {"title": "Exploratory Keyword Search with Interactive Input", "authors": ["Zhifeng Bao\n,", "Yong Zeng\n,", "H.V. Jagadish\n,", "Tok Wang Ling"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nDue to the intrinsic ambiguity of keyword queries, users usually need to reformulate their queries multiple times to get the desired information. Even worse, users either have no way to precisely specify their search intention, or have limited domain knowledge on the data to precisely express their search intention. Moreover, they may just have a general interest to explore the data by keyword query. Therefore, our goal is to design an exploratory search paradigm that is able to bring humans more actively into the search process, in order to meet various user information needs, ranging from simple lookup to learning and understanding of the data.\nBesides, keyword queries against data with structure, such as XML, can run into multiple difficulties: how to identify the search target; more types of ambiguity arise as a keyword can be part of the structure as well as content of data, etc. Effectively addressing these requires solutions to multiple challenges. While some have been addressed to some extent individually, there is no previous effort to develop a comprehensive system to meet these important user needs and meet all of these challenges.\nTherefore, we propose a framework called ClearMap that natively supports visualized exploratory search paradigm on XML data. In particular, we offer an interactive and visualized mechanism to present the outcome of the query, enable user to explore and manipulate the underlying data to either quickly find desired information or learn the relationship among data items, as well as provide interactive suggestions when their expected results do not exist in the data. A preliminary version of ClearMap and its source code are available for try at http://xmlclearmap.comp.nus.edu.sg.", "references": ["XML ClearMap. http://xclearmap.comp.nus.edu.sg.", "Z. Bao, T. W. Ling, B. Chen, and J. Lu. Effective XML keyword search with relevance oriented ranking. In ICDE, pages 517--528, 2009.", "G. Koutrika, L. V. S. Lakshmanan, M. Riedewald, and K. Stefanidis. Exploratory search in databases and the web. In Workshops of the EDBT/ICDT, pages 158--159, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735361"}, {"title": "Improving Event Detection by Automatically Assessing Validity of Event Occurrence in Text", "authors": ["Andrea Ceroni\n,", "Ujwal Kumar Gadiraju\n,", "Marco Fisichella"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nManually inspecting text to assess whether an event occurs in a document collection is an onerous and time consuming task. Although a manual inspection to discard the false events would increase the precision of automatically detected sets of events, it is not a scalable approach. In this paper, we automatize event validation, defined as the task of determining whether a given event occurs in a given document or corpus. The introduction of automatic event validation as a post-processing step of event detection can boost the precision of the detected event set, discarding false events and preserving the true ones. We propose a novel automatic method for event validation, which relies on a supervised model to predict the occurrence of events in a non-annotated corpus. The data for training the model is gathered by exploiting the crowdsourcing paradigm. Experiments on real-world events and documents show that our proposed method (i) outperforms the state-of-the-art event validation approach and (ii) increases the precision of event detection while preserving recall.", "references": ["J. Allan, R. Papka, and V. Lavrenko. On-line new event detection and tracking. In SIGIR, 1998.", "J. Araki and J. Callan. An annotation similarity model in passage ranking for historical fact validation. In SIGIR, 2014.", "A. Ceroni and M. Fisichella. Towards an entity-based automatic event validation. In ECIR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806624"}, {"title": "Data Series Management: The Road to Big Sequence Analytics", "authors": ["Themis Palpanas"], "publication": "ACM SIGMOD Record", "abstract": "Abstract\nMassive data series collections are becoming a reality for virtually every scientific and social domain, and have to be processed and analyzed, in order to extract useful knowledge. Current data series management solutions are ad hoc, requiring huge investments in time and effort, and duplication of effort across different teams. Systems like relational databases, Column Stores, and Array Databases are not a suitable solution either, since none of these systems offers native support for data series. Our vision is to design and develop a generalpurpose Data Series Management System, able to copewith big data series, that is, very large and fast-changing collections of data series, which can be heterogeneous (i.e., originate from disparate domains and thus exhibit very different characteristics), and which can have uncertainty in their values (e.g., due to inherent errors in the measurements). Just like databases abstracted the relational data management problem and offered a black box solution that is now omnipresent, the proposed system will allow analysts that are not experts in data series management, as well as common users, to tap in the goldmine of the massive and ever-growing data series collections they (already) have", "references": ["Adhd-200. http://fcon_1000.projects.nitrc.org/ indi/adhd200/, 2011.", "Orleans: Distributed virtual actors for programmability and scalability. MSR-TR-2014-41, 2014.", "Sloan digital sky survey. https://www.sdss3.org/dr10/data_access/volume.php, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814710.2814719"}, {"title": "Subjective Similarity: Personalizing Alternative Item Recommendations", "authors": ["Tolga Könik\n,", "Rajyashree Mukherjee\n,", "Jayasimha Katukuri"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe present a new algorithm for recommending alternatives to a given item in an e-commerce setting. Our algorithm is an incremental improvement over an earlier system, which recommends similar items by first assigning the input item to clusters and then selecting best quality items within those clusters. The original algorithm does not consider the recent context and our new algorithm improves the earlier system by personalizing the recommendations to user intentions. The system measures user intention using the recent queries, which are used to determine the level of abstraction in similarity and relative importance of similarity dimensions. We show that user engagement increases when recommended item titles share more terms with most recent queries. Moreover, the new algorithm increases query coverage without sacrificing input item similarity and item quality.", "references": ["Linden, G., B. Smith, and J. York. 2003, Amazon.com Recommendations: Item-to-Item Collaborative Filtering. IEEE Internet Computing. 7, 1, 76--80.", "Davidson, J., Liebald, B., Liu, J., Nandy, P., Van Vleet, T., Gargi, U., Gupta, S., He, Y., Lambert, M. Livingston, B., and Sampath, D. 2010. The YouTube video recommendation system. In Proceedings of the Fourth ACM Conference on Recommender Systems (Barcelona, Spain). ACM, New York, NY, 293--296.", "Das, A. S., Datar, M., and Garg, A. 2007. Google news personalization: scalable online collaborative filtering. In Proceedings of the 16th International Conference on World Wide Web (Banff, Alberta, Canada). ACM, New York, NY, 271--280."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741999"}, {"title": "Fuzzy retrieval for software reuse", "authors": ["Erin Colvin\n,", "Donald Kraft"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nFinding software for reuse is a problem that programmers face. To reuse code that has been proven to work can increase any programmer's productivity, benefit corporate productivity, and also increase the stability of software programs. This paper shows that fuzzy retrieval has an improved retrieval performance over typical Boolean retrieval. Various methods of fuzzy information retrieval implementation and their use for software reuse will be examined. A deeper explanation of the fundamentals of designing a fuzzy information retrieval system for software reuse will be examined. Future research options and necessary data storage systems are explored.", "references": ["Crestani, F., & Lalmas, M. (2001). Logic and uncertainty in information retrieval. In Lectures on information retrieval Springer Berlin Heidelberg. 179--206.", "Fox, E. A., & Sharan, S. (1986). A comparison of two methods for soft Boolean operator interpretation in information retrieval. Dept. of Computer Science Virginia Tech. Tech Report.", "Frakes, W. B., Baeza-Yates, R. (1992). Information Retrieval Data Structures & Algorithms. Prentice Hall: Englewood Cliffs, New Jersey."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857141"}, {"title": "Bottom-up Faceted Search: Creating Search Neighbourhoods with Datacube Cells", "authors": ["Mark Sifer"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nBrowsing a collection can start with a keyword search. A user visits a library, performs a keyword search to find a few books of interest; finding their location in the library. Then they go to these locations; the corresponding bookshelves, where they do not just retrieve the found books, but rather they start browsing the nearby books; the books which have a similar Dewey classification. This paper extends this approach to curated corpora that contain items or documents that have been classified in multiple dimensions (facets), where each dimension classification may be a hierarchy. In particular (i) a technique for determining near items based on OLAP datacube cells and (ii) user interfaces that support browsing of near items are presented.", "references": ["Carmel D., Roitman H. and Zwerdling N. Enhancing cluster labeling using wikipedia. In ACM SIGIR'09, 139--146, 2009.", "Cooper, E. System and method for divisive textual clustering by label selection using variant-weighted TFIDF. US Patent Application 20140136542, 2014.", "Hearst, M. Clustering versus faceted categories for information exploration. CACM 49 (4), 59--61, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806593"}, {"title": "Fuzzy Clustering Systems in Analyzing High Dimensional Database", "authors": ["R. Devi\n,", "S. R. Kannan\n,", "T. P. Hong\n,", "S. Ramathilagam"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nFinding the division between malignant pleural mesothelioma (MPM) and adenocarcinoma (ADCA) from the gene expression of lung cancer database is difficult due to its high-dimensionality gene with noise. This paper proposes novel effective fuzzy soft clustering systems with the combination of possibilistic c-means to distinct the MPM and ADCA accurately gene expression ratios of lung cancer database. Since the proposed method is capable in clustering highly correlated gene expression of lung cancer database, first time all 181 tissue samples are used for finding MPM and ADCA during the experimental works using the proposed method. The performance of proposed method in clustering the Lung cancer database is shown through the clustering accuracy and error matrix.", "references": ["Alizadeh et al., \"Distinct Types of Diffuse Large b-Cell Lung Identified by Gene Expression Profiling,\" Nature, vol. 403, pp. 503--511, 2000.", "Berks et al., Fuzzy clustering - a versatile mean to explore medical database, ESIT2000, Aachen, Germany.", "Bezdek J. C., Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum Press, New York, (1981)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818879"}, {"title": "Sketch-based Image Retrieval via Shape Words", "authors": ["Changcheng Xiao\n,", "Changhu Wang\n,", "Liqing Zhang\n,", "Lei Zhang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe explosive growth of touch screens has provided a good platform for sketch-based image retrieval. However, most previous works focused on low level descriptors of shapes and sketches. In this paper, we try to step forward and propose to leverage shape words descriptor for sketch-based image retrieval. First, the shape words are defined and an efficient algorithm is designed for shape words extraction. Then we generalize the classic Chamfer Matching algorithm to address the shape words matching problem. Finally, a novel inverted index structure is proposed to make shape words representation scalable to large scale image databases. Experimental results show that our method achieves competitive accuracy but requires much less memory, e.g., less than 3% of memory storage of MindFinder. Due to its competitive accuracy and low memory cost, our method can scale up to much larger database.", "references": ["G. Borgefors. Hierarchical chamfer matching: A parametric edge matching algorithm. IEEE PAMI, 1988.", "J. Canny. A computational approach to edge detection. IEEE PAMI, 1986.", "Y. Cao, C. Wang, L. Zhang, and L. Zhang. Edgel index for large-scale sketch-based image search. CVPR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749360"}, {"title": "We Know Where You Should Work Next Summer: Job Recommendations", "authors": ["Fabian Abel"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nBusiness-oriented social networks like LinkedIn or XING support people in discovering career opportunities. In this talk, we will focus on the problem of recommending job offers to Millions of XING users. We will discuss challenges of building a job recommendation system that has to satisfy the demands of both job seekers who have certain wishes concerning their next career step and recruiters who aim to hire the most appropriate candidate for a job. Based on insights gained from a large-scale analysis of usage data and profile data such as curriculum vitae, we will study features of the recommendation algorithms that aim to solve the problem.\nJob advertisements typically describe the job role that the candidate will need to fill, required skills, the expected educational background that candidates should have and the company and environment in which candidates will be working. Users of professional social networks curate their profile and curriculum vitae in which they describe their skills, interests and previous career steps. Recommending jobs to users is however a non-trivial task for which pure content-based features that would just match the aforementioned properties are not sufficient. For example, we often observe that there is a gap between what people specify in their profiles and what they are actually interested in. Moreover, profile and CV typically describe the past and current situation of a user but do not reflect enough the actual demands that users have with respect to their next career step. Therefore, it is crucial to also analyze the behavior of the users and exploit interaction data such as search queries, clicks on jobs, bookmarks, clicks that similar users performed, etc.\nOur job recommendation system exploits various features in order to estimate whether a job posting is relevant for a user or not. Some of these features rather reflect social aspects (e.g. does the user have contacts that are living in the city in which the job is offered?) while others capture to what extent the user fulfills the requirements of the role that is described in the job advertisement (e.g. similarity of user's skills and required skills). To better understand appropriate next career steps, we mine the CVs of the users and learn association rules that describe the typical career paths. This information is also made publicly available via FutureMe - a tool that allows people to explore possible career opportunities and identify professions that may be interesting for them to work in.\nOne of the challenges when developing the job recommendation system is to collect explicit feedback and thus understanding (i) whether a recommended job was relevant for a user and (ii) whether the user was a good candidate for the job. We thus started to stronger involve users in providing feedback and build a feedback cycle that allows the recommender system to automatically adapt to the feedback that the crowd of users is providing. By displaying explanations about why certain items were suggested, we furthermore aim to increase transparency of how the recommender system works.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799496"}, {"title": "VSSD: Performance Isolation in a Solid-State Drive", "authors": ["Da-Wei Chang\n,", "Hsin-Hung Chen\n,", "Wei-Jian Su"], "publication": "ACM Transactions on Design Automation of Electronic Systems", "abstract": "Abstract\nPerformance isolation is critical in shared storage systems, a popular storage solution. In a shared storage system, interference between requests from different users can affect the accuracy of I/O cost accounting, resulting in poor performance isolation. Recently, NAND flash-memory-based solid-state drives (SSDs) have been increasingly used in shared storage systems. However, interference in SSD-based shared storage systems has not been addressed. In this article, two types of interference, namely, queuing delay (QD) interference and garbage collection (GC) interference, are identified in a shared SSD. Additionally, a framework called VSSD is proposed to address these types of interference. VSSD is composed of two components: the FACO credit-based I/O scheduler designed to address QD interference and the ViSA flash translation layer designed to address GC interference. The VSSD framework aims to be implemented in the firmware running on an SSD controller. With VSSD, interference in an SSD can be eliminated and performance isolation can be ensured. Both synthetic and application workloads are used to evaluate the effectiveness of the proposed VSSD framework. The performance results show the following. First, QD and GC interference exists and can result in poor performance isolation between users on SSD-based shared storage systems. Second, VSSD is effective in eliminating the interference and achieving performance isolation between users. Third, the overhead of VSSD is insignificant.", "references": ["J. An and D. Shin. 2013. Offline deduplication-aware block separation for solid state disk. In Proceedings of the 11th USENIX Conference on File and Storage Technologies.", "T. Austin, E. Larson, and D. Ernst. 2002. An infrastructure for computer system modeling. IEEE Computer 32, 2, 59--67.", "J. Axboe. 2004. Linux block IO—present and future. In Proceedings of the Ottawa Linux Symposium. 51--61."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2755560"}, {"title": "Memory Management Scheme to Improve Utilization Efficiency and Provide Fast Contiguous Allocation without a Statically Reserved Area", "authors": ["Myungsun Kim\n,", "Jinkyu Koo\n,", "Hyojung Lee\n,", "James R. Geraci"], "publication": "ACM Transactions on Design Automation of Electronic Systems", "abstract": "Abstract\nFast allocation of large blocks of physically contiguous memory plays a crucial role to boost the performance of multimedia applications in modern memory-constrained portable devices, such as smartphones, tablets, etc. Existing systems have addressed this issue by provisioning a large statically reserved memory area (SRA) in which only dedicated applications can allocate pages. However, this in turn degrades the performance of applications that are prohibited to utilize the SRA due to the reduced available memory pool. To overcome this drawback while maintaining the benefits of the SRA, we propose a new memory management scheme that uses a special memory region, called page-cache-preferred area (PCPA), in concert with a quick memory reclaiming algorithm. The key of the proposed scheme is to enhance the memory utilization efficiency by enabling to allocate page-cached pages of all applications in the PCPA until predetermined applications require to allocate big chunks of contiguous memory. At this point, clean page-cached pages in the PCPA are rapidly evicted without write-back to a secondary storage. Compared to the SRA scheme, experimental results show that the average launch time of real-world applications and the execution time of I/O-intensive benchmarks are reduced by 9.2% and 24.7%, respectively.", "references": ["Nadav Amit, Muli Ben-Yehuda, Dan Tsafrir, and Assaf Schuster. 2011. vIOMMU: Efficient IOMMU emulation. In Proceedings of the Annual USENIX Technical Conference (USENIXATC'11).", "Nadav Amit, Muli Ben-Yehuda, and Ben-Ami Yassour. 2010. IOMMU: Strategies for mitigating the IOTLB bottleneck. In Proceedings of the International Conference on Computer Architecture (ISCA'10). 256--274.", "Roberto Ammendola, Andrea Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Pier Stanislao Paolucci, Davide Rossetti, Francesco Simula, Laura Tosoratto, and Piero Vicini. 2013. Virtual-to-physical address translation for an FPGA-based interconnect with host and GPU remote DMA capabilities. In Proceedings of the International Conference on Field-Programmable Technology (FPT'13). 58--65."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2770871"}, {"title": "Time Pressure and System Delays in Information Search", "authors": ["Anita Crescenzi\n,", "Diane Kelly\n,", "Leif Azzopardi"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe report preliminary results of the impact of time pressure and system delays on search behavior from a laboratory study with forty-three participants. To induce time pressure, we randomly assigned half of our study participants to a treatment condition where they were only allowed five minutes to search for each of four ad-hoc search topics. The other half of the participants were given no task time limits. For half of participants' search tasks (n=2), five second delays were introduced after queries were submitted and SERP results were clicked. Results showed that participants in the time pressure condition queried at a significantly higher rate, viewed significantly fewer documents per query, had significantly shallower hover and view depths, and spent significantly less time examining documents and SERPs. We found few significant differences in search behavior for system delay or interaction effects between time pressure and system delay. These initial results show time pressure has a significant impact on search behavior and suggest the design of search interfaces and features that support people who are searching under time pressure.", "references": ["I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proc. of the 37th ACM SIGIR conference, pages 103--112, 2014.", "N. Bhatti, A. Bouch, and A. Kuchinsky. Integrating user-perceived quality into Web server design. Computer Networks, 33(1--6):1--16, 2000.", "P. Borlund. The IIR evaluation model: A framework for evaluation of interactive information retrieval systems. Information Research, 8(3):1--34, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767817"}, {"title": "Sorry kids, Iron Man's superpowers aren't unique", "authors": ["Lara Zupan\n,", "Marinka Zitnik"], "publication": "XRDS: Crossroads, The ACM Magazine for Students", "abstract": "Abstract\nNo abstract available.", "references": ["Newman, M. E. The structure and function of complex networks. SIAM Review 45, 2 (2003), 167--256.", "Alberich, R., Miro-Julia, J. and Rossello, F. Marvel Universe looks almost like a real social network. Feb. 2002. eprint arXiv:cond-mat/0202174.", "Gleiser, P. M. How to become a superhero. Journal of Statistical Mechanics: Theory and Experiment Sept. 2007, P09020."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810249"}, {"title": "Jigsaw: multi-modal big data management in digital film production", "authors": ["Simon Pabst\n,", "Hansung Kim\n,", "Lukáš Polok\n,", "Viorela Ila\n,", "Ted Waine\n,", "Adrian Hilton\n,", "Jeff Clifford"], "publication": "SIGGRAPH '15: ACM SIGGRAPH 2015 Posters", "abstract": "ABSTRACT\nModern digital film production uses large quantities of data captured on-set, such as videos, digital photographs, LIDAR scans, spherical photography and many other sources to create the final film frames. The processing and management of this massive amount of heterogeneous data consumes enormous resources. We propose an integrated pipeline for 2D/3D data registration aimed at film production, based around the prototype application Jigsaw. It allows users to efficiently manage and process various data types from digital photographs to 3D point clouds. A key step in the use of multi-modal 2D/3D data for content production is the registration into a common coordinate frame (match moving). 3D geometric information is reconstructed from 2D data and registered to the reference 3D models using 3D feature matching [Kim and Hilton 2014]. We present several highly efficient and robust approaches to this problem. Additionally, we have developed and integrated a fast algorithm for incremental marginal covariance calculation [Ila et al. 2015]. This allows us to estimate and visualize the 3D reconstruction error directly on-set, where insufficient coverage or other problems can be addressed right away. We describe the fast hybrid multi-core and GPU accelerated techniques that let us run these algorithms on a laptop. Jigsaw has been used and evaluated in several major digital film productions and significantly reduced the time and work required to manage and process on-set data.", "references": ["Ila, V., Polok, L., Solony, M., Zemcik, P., and Smrz, P. 2015. Fast Covariance Recovery in Incremental Nonlinear Least Squares Solvers. In Proc. ICRA 2015.", "Kim, H., and Hilton, A. 2014. Hybrid 3D Feature Description and Matching for Multi-modal Data Registration. In Proc. ICIP 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2787626.2792617"}, {"title": "Propagation of Policies in Rich Data Flows", "authors": ["Enrico Daga\n,", "Mathieu d'Aquin\n,", "Aldo Gangemi\n,", "Enrico Motta"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nGoverning the life cycle of data on the web is a challenging issue for organisations and users. Data is distributed under certain policies that determine what actions are allowed and in which circumstances. Assessing what policies propagate to the output of a process is one crucial problem. Having a description of policies and data flow steps implies a huge number of propagation rules to be specified and computed (number of policies times number of actions). In this paper we provide a method to obtain an abstraction that allows to reduce the number of rules significantly. We use the Datanode ontology, a hierarchical organisation of the possible relations between data objects, to compact the knowledge base to a set of more abstract rules. After giving a definition of Policy Propagation Rule, we show (1) a methodology to abstract policy propagation rules based on an ontology, (2) how effective this methodology is when using the Datanode ontology, (3) how this ontology can evolve in order to better represent the behaviour of policy propagation rules.", "references": ["G. Antoniou and G. Wagner. Rules and defeasible reasoning on the semantic web. In Schröder, Michael and Wagner, Gerd, editor, Rules and Rule Markup Languages for the Semantic Web, volume 2876 of Lecture Notes in Computer Science, pages 111--120. Springer Berlin Heidelberg, 2003.", "O. Boissier, M. Colombetti, M. Luck, J.-J. Meyer, and A. Polleres. Norms, organizations, and semantics. The Knowledge Engineering Review, 28(01):107--116, 2013.", "P. A. Bonatti and D. Olmedilla. Rule-based policy representation and reasoning for the semantic web. In Proceedings of the Third International Summer School Conference on Reasoning Web, RW07, pages 240--268, Berlin, Heidelberg, 2007. Springer-Verlag."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815839"}, {"title": "Dynamic Test Collections for Retrieval Evaluation", "authors": ["Ben Carterette\n,", "Ashraf Bah\n,", "Mustafa Zengin"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nBatch evaluation with test collections of documents, search topics, and relevance judgments has been the bedrock of IR evaluation since its adoption by Salton for his experiments on vector space systems. Such test collections have limitations: they contain no user interaction data; there is typically only one query per topic; they have limited size due to the cost of constructing them. In the last 15-20 years, it has become evident that having a log of user interactions and a large space of queries is invaluable for building effective retrieval systems, but such data is generally only available to search engine companies. Thus there is a gap between what academics can study using static test collections and what industrial researchers can study using dynamic user data.\nIn this work we propose dynamic test collections to help bridge this gap. Like traditional test collections, a dynamic test collection consists of a set of topics and relevance judgments. But instead of static one-time queries, dynamic test collections generate queries in response to the system. They can generate other actions such as clicks and time spent reading documents. Like static test collections, there is no human in the loop, but since the queries are dynamic they can generate much more data for evaluation than static test collections can. And since they can simulate user interactions across a session, they can be used for evaluating retrieval systems that make use of session history or other user information to try to improve results.", "references": ["E. Agichtein, R. White, S. T. Dumais, and P. Bennett. Search, interrupted: understanding and predicting search task continuation. In Proc. SIGIR, 2012.", "A. H. Awadallah, R. White, P. Pantel, S. T. Dumais, and Y. M. Wang. Supporting complex search tasks. In Proc. CIKM, 2014.", "A. Bah, K. Sabhnani, M. Zengin, and B. Carterette. University of delaware at TREC 2014. In Proc. TREC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809470"}, {"title": "Towards building an analytics platform in the cloud", "authors": ["Valentina Salapura\n,", "Kirk A. Beaty\n,", "Alan Bivens\n,", "Minkyong Kim\n,", "Min Li"], "publication": "CF '15: Proceedings of the 12th ACM International Conference on Computing Frontiers", "abstract": "ABSTRACT\nRecently enterprises have been able to leverage two revolutionary new tools for gaining a competitive advantage for their business -- cloud computing and analytic applications. Cloud computing unburdens them from running and maintaining their compute resources, whereas analytic applications comb through their big data to provide new insights for a competitive advantage in the market. Analytic applications are carefully tailored to their target problems. While there is a lot of work published on both the mechanics of cloud computing as well as analytic methods for distilling insights from a variety of data, there is little work available about the cloud influence on the analytics platforms which aim at lowering the barrier for the creation, deployment, scaling and maintenance of next generation analytic workloads. This paper discusses the challenges we are facing today in order to provide an analytics platform to reduce cost and increase performance of analytics applications in the cloud computing environment.", "references": ["Amazon EMR. http://aws.amazon.com/elasticmapreduce/", "Amazon S3. http://aws.amazon.com/s3/", "Apache. Hadoop. http://hadoop.apache.org/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742854.2747279"}, {"title": "Augmented Feature Fusion for Image Retrieval System", "authors": ["Yang Zhou\n,", "Dan Zeng\n,", "Shiliang Zhang\n,", "Qi Tian"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThe performance of current image retrieval system is largely determined by the quality and discriminative capability of features. Therefore, using what features and how to effectively combine the power of appropriate features are important in the system. We adopt the reciprocal neighbor based graph fusion approach for feature fusion. More importantly, we explicitly augment the original approach with the following two strategies: 1) we investigate the most suitable feature combinations on various datasets, including the deep learning feature, which has been popular for image retrieval recently; 2) we further improve the robustness of original graph fusion approach by the SVM prediction strategy.\nExtensive experiments are performed on three benchmark datasets including UKbench, Holidays and Corel-5K, to validate the impressive performance of the augmented feature fusion. On the three datasets, our retrieval system significantly outperforms several existing algorithms. For example on UKbench, the N-S score of our approach achieves 3.88, which is one of the highest accuracies to the best of our knowledge.", "references": ["D. Cai, X. He, and J. Han. Spectral regression: a unified subspace learning framework for content-based image retrieval. In MM, pages 403--412, 2007.", "R. Fagin, R. Kumar, and D. Sivakumar. Efficient similarity search and classification via rank aggregation. In SIGMOD, pages 301--312, 2003.", "P. Gehler and S. Nowozin. On feature combination for multiclass object classification. In ICCV, pages 221--228, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749288"}, {"title": "Random Walks on the Reputation Graph", "authors": ["Sabir Ribas\n,", "Berthier Ribeiro-Neto\n,", "Rodrygo L.T. Santos\n,", "Edmundo de Souza e Silva\n,", "Alberto Ueda\n,", "Nivio Ziviani"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe identification of reputable entities is an important task in business, education, and many other fields. On the other hand, as an arguably subjective, multi-faceted concept, quantifying reputation is challenging. In this paper, instead of relying on a single, precise definition of reputation, we propose to exploit the transference of reputation among entities in order to identify the most reputable ones. To this end, we propose a novel random walk model to infer the reputation of a target set of entities with respect to suitable sources of reputation. We instantiate our model in an academic search setting, by modeling research groups as reputation sources and publication venues as reputation targets. By relying on publishing behavior as a reputation signal, we demonstrate the effectiveness of our model in contrast to standard citation-based approaches for identifying reputable venues as well as researchers in the broad area of computer science. In addition, we demonstrate the robustness of our model to perturbations in the selection of reputation sources. Finally, we show that effective reputation sources can be chosen via the proposed model itself in a semi-automatic fashion.", "references": ["L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social networks. In Proc. of WSDM, pages 635--644, 2011.", "E. Bakshy, I. Rosenn, C. Marlow, and L. Adamic. The role of social networks in information diffusion. In Proc. of WWW, pages 519--528, 2012.", "K. Balog. Expertise retrieval. Found. Trends Inf. Retr., 6(2--3):127--256, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809462"}, {"title": "Specific Person Retrieval via Incomplete Text Description", "authors": ["Mang Ye\n,", "Chao Liang\n,", "Zheng Wang\n,", "Qingming Leng\n,", "Jun Chen\n,", "Jun Liu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nSearching for specific persons from surveillance videos captured by different cameras, is a key yet under-addressed challenge in multimedia system. Related person retrieval works mainly focus on searching person by visual appearance, known as person re-identification. However, the initial visual image may not be available in some practical applications. For example, the criminal is described by a text description indirectly, \"A young woman wearing a red casual with a backpack\", the traditional methods can not conquer this issue. Based on a set of pre-defined attributes that the text description query can be transformed to an attribute vector, thus can be used to retrieval in the gallery set. And yet, the user-provided attributes are sometimes incomplete. This new issue is defined as Specific Person Retrieval via Incomplete Text Description. In this paper, we conduct a specific attribute completion to enrich the original text query and generate a more expressive attribute vector. Then, a pairwise-based metric learning is introduced for completed attribute vectors. Extensive experiments conducted on two benchmark datasets have shown our superior performance.", "references": ["N. N. B, N. V. H, D. T. N, and et al. Attrel: An approach to person re-identification by exploiting attribute relationships. In Multimedia Modeling (MMM), 2015.", "X. Cao, H. Zhang, X. Guo, S. Liu, and X. Chen. Image retrieval and ranking via consistently reconstructing multi-attribute queries. In ECCV, 2014.", "Y. Deng, P. Luo, C. C. Loy, and X. Tang. Pedestrian attribute recognition at far distance. In ACM MM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749347"}, {"title": "Large-scale Contextual Query-to-Ad Matching and Retrieval System for Sponsored Search: (Abstract)", "authors": ["Ricardo Baeza-Yates\n,", "Nemanja Djuric\n,", "Mihajlo Grbovic\n,", "Vladan Radosavljevic\n,", "Fabrizio Silvestri"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSemantic embeddings of words (or objects in general) into a vector space have proven to be a powerful tool in many applications. In this talk we are going to show one possible application of semantic embeddings to sponsored search. Sponsored search represents the major source of revenue for web search engines and it is based on the following mechanism: each advertiser maintains a list of keywords they deem of interest with regards to their business. According to this targeting model, when a query is issued, all advertisers with a matching keyword are entered into an auction according to the amount they bid for the query, and the winner gets to show their ad, usually paying the next largest bid (this is called second price). The main challenges is that a query may not match many keywords, resulting in lower auction value, lower ad quality, and lost revenue for both, advertisers and publishers. We address them by applying semantic embeddings to this problem by learning how to project queries and ads in a common embedding, thus sharing the same feature space. The major novelty of the techniques we show is that learning is done by jointly modeling their content (words in queries and ad metadata), as well as their context within a search session. This model has several advantages and can be applied to at least three tasks. First, it can be used to generate query rewrites with a specific bias towards rewrites able to match relevant advertising. Second, it can be used also to retrieve for a given a query a set of relevant ads to be sent to the auction phase. Third, given an ad we are able to retrieve all the queries for which that ad can be considered relevant. The major advantage of learning both content and context embeddings is in the fact that a context-based model may suffer from coverage issue: if a query or an ad does not appear in the training set it cannot be treated by the model; content-based embeddings instead can be used to also build models capturing similarities between content, e.g. for a query not appearing in the model built we may capture some of its sub-queries by using content vectors. Another very interesting characteristic of this method is that all the tasks mentioned above are basically solved by means of a simple K-nearest neighbor search over the set of vectors in the embedding. The method has been trained up to 12 billion sessions, one of the largest corpora reported so far. We report offline and online experimental results, as well as post-deployment metrics. The results show that this approach significantly outperforms existing state-of-the-art, substantially improving a number of key business metrics.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744112"}, {"title": "Chinese social media analysis for disease surveillance", "authors": ["Xiaohui Cui\n,", "Nanhai Yang\n,", "Zhibo Wang\n,", "Cheng Hu\n,", "Weiping Zhu\n,", "Hanjie Li\n,", "Yujie Ji\n,", "Cheng Liu"], "publication": "Personal and Ubiquitous Computing", "abstract": "Abstract\nIt is reported that there are hundreds of thousands of deaths caused by seasonal flu all around the world every year. More other diseases such as chickenpox, malaria, etc. are also serious threats to people's physical and mental health. There are 250,000---500,000 deaths every year around the world. Therefore proper techniques for disease surveillance are highly demanded. Recently, social media analysis is regarded as an efficient way to achieve this goal, which is feasible since growing number of people have been posting their health information on social media such as blogs, personal websites, etc. Previous work on social media analysis mainly focused on English materials but hardly considered Chinese materials, which hinders the application of such technique to Chinese people. In this paper, we proposed a new method of Chinese social media analysis for disease surveillance. More specifically, we compared different kinds of methods in the process of classification and then proposed a new way to process Chinese text data. The Chinese Sina micro-blog data collected from September to December 2013 are used to validate the effectiveness of the proposed method. The results show that a high classification precision of 87.49?% in average has been obtained. Comparing with the data from the authority, Chinese National Influenza Center, we can predict the outbreak time of flu 5?days earlier.", "references": ["IResearch (2010) In 2010 the global Internet users spend most of their time in social media. http://service.iresearch.cn/others//20101129/128573.shtml", "Infographic (2012) The growing impact of social media. http://www.sociallyawareblog.com/2012/11/21/time-americans-spend-per-month-on-social-media-sites/", "Collier N, Son NT, Nguyen NM (2011) OMG u got flu? Analysis of shared health messages for bio-surveillance. J. Biomed Semant 2(S---5):S9"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00779-015-0877-5"}, {"title": "Mining big data for detecting, extracting and recommending architectural design concepts", "authors": ["Mehdi Mirakhorli\n,", "Hong-Mei Chen\n,", "Rick Kazman"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nAn architecture recommender system can help programmers make better design choices to address their architectural quality attribute concerns while doing their daily programming tasks. We mine big data to detect and extract a large set of architectural design concepts, such as design patterns, design tactics, architecture styles, etc., to be used in our architecture recommender system called ARS. However, mining big data poses many practical challenges for system implementation. The volume, velocity and variety of our data set, like all other big data systems, requires careful planning. This first challenge is to select appropriate technologies from the large number of available products for our system implementation. Building on these technologies our greatest challenge is to custom-fit our algorithms to the parallel processing platform we have selected for ARS, to meet our performance goals.", "references": ["M. Mirakhorli and J. Cleland Huang, \"A decision-centric approach for tracing reliability concerns in embedded software systems,\" in Proceedings of the Workshop on Embedded Software Reliability (ESR), held at ISSRE10, November 2010.", "M. Mirakhorli, Y. Shin, J. Cleland-Huang, and M. Cinar, \"A tactic centric approach for automating traceability of quality concerns,\" in International Conference on Software Engineering, ICSE (1), 2012.", "M. Mirakhorli, P. Mäder, and J. Cleland-Huang, \"Variability points and design pattern usage in architectural tactics,\" in Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, ser. FSE '12. ACM, 2012, pp. 52:1--52:11."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819295"}, {"title": "Context-Aware Event Recommendation in Event-based Social Networks", "authors": ["Augusto Q. Macedo\n,", "Leandro B. Marinho\n,", "Rodrygo L.T. Santos"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe Web has grown into one of the most important channels to communicate social events nowadays. However, the sheer volume of events available in event-based social networks (EBSNs) often undermines the users' ability to choose the events that best fit their interests. Recommender systems appear as a natural solution for this problem, but differently from classic recommendation scenarios (e.g. movies, books), the event recommendation problem is intrinsically cold-start. Indeed, events published in EBSNs are typically short-lived and, by definition, are always in the future, having little or no trace of historical attendance. To overcome this limitation, we propose to exploit several contextual signals available from EBSNs. In particular, besides content-based signals based on the events' description and collaborative signals derived from users' RSVPs, we exploit social signals based on group memberships, location signals based on the users' geographical preferences, and temporal signals derived from the users' time preferences. Moreover, we combine the proposed signals for learning to rank events for personalized recommendation. Thorough experiments using a large crawl of Meetup.com demonstrate the effectiveness of our proposed contextual learning approach in contrast to state-of-the-art event recommenders from the literature.", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Proc. of RecSys, pages 335--336, 2008.", "J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proc. of SIGSPATIAL/GIS, pages 199--208, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800187"}, {"title": "Using Contextual Information to Understand Searching and Browsing Behavior", "authors": ["Julia Kiseleva"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThere is great imbalance in the richness of information on the web and the succinctness and poverty of search requests of web users, making their queries only a partial description of the underlying complex information needs. Finding ways to better leverage contextual information and make search context-aware holds the promise to dramatically improve the search experience of users. We conducted a series of studies to discover, model and utilize contextual information in order to understand and improve users' searching and browsing behavior on the web. Our results capture important aspects of context under the realistic conditions of different online search services, aiming to ensure that our scientific insights and solutions transfer to the operational settings of real world applications.", "references": ["J. Kiseleva. Context mining and integration into predictive web analytics. In WWW (Companion Volume), pages 383--388, 2013.", "Kiseleva, Lam, Pechenizkiy, and Calders}kiseleva_dddm_2013J. Kiseleva, H. T. Lam, M. Pechenizkiy, and T. Calders. Predicting current user intent with contextual markov models. In ICDM Workshops, 2013\\natexlaba.", "Kiseleva, Lam, Pechenizkiy, and Calders}kiselevalpc_www13J. Kiseleva, H. T. Lam, M. Pechenizkiy, and T. Calders. Discovering temporal hidden contexts in web sessions for user trail prediction. In Proceedings of WWW (Companion Volume), pages 1067--1074. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767852"}, {"title": "Machine Learning Algorithms for Environmental Sound Recognition: Towards Soundscape Semantics", "authors": ["Vasileios Bountourakis\n,", "Lazaros Vrysis\n,", "George Papanikolaou"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis paper investigates methods aiming at the automatic recognition and classification of discrete environmental sounds, for the purpose of subsequently applying these methods to the recognition of soundscapes. Research in audio recognition has traditionally focused on the domains of speech and music. Comparatively little research has been done towards recognizing non-speech environmental sounds. For this reason, in this paper, we apply existing techniques that have been proved efficient in the other two domains. These techniques are comprehensively compared to determine the most appropriate one for addressing the problem of environmental sound recognition.", "references": ["Bountourakis, V. Semantic Analysis of Environmental Sounds through Audio Feature Extraction and use of Machine Learning Methods, Aristotle University of Thessaloniki, 2015.", "Bullock, J., and Conservatoire, U. C. E. B. Libxtract: A lightweight library for audio feature extraction. In Proceedings of the International Computer Music Conference (Vol. 43), 2007.", "Cannam, C., Landone, C., Sandler, M. B., and Bello, J. P. The Sonic Visualiser: A Visualisation Platform for Semantic Descriptors from Musical Signals. In ISMIR, 2006, 324--327."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814905"}, {"title": "SIGS-S Mobile Saude: A Mobile Application to Support the Collection of Health Data", "authors": ["Eduardo Fernandes\n,", "Marcelo Turine\n,", "Maria Istela Cagnin"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe Brazilian government has asked for information systems to support government activities such as health care. Aiming to support the collection of health data in the context of the Health in The Family Program (Programa Saude na Familia) promoted by the Single Health System of Mato Grosso do Sul (Sistema Unico de Saude do Estado de Mato Grosso do Sul - SUS-MS), it was developed the mobile application SIGS-S Mobile Saude. The purpose of the mobile application is to provide the collection of health data in places where there is no internet connection using mobile devices such as tablets, providing the collected data to a web system called SIGS-S Web Saude via internet data transfer. A software process, named ProFap, was used to support the mobile application development. As a result, the mobile application was developed and its documentation was prepared to help future software maintenance and the deployment of SIGS-S Mobile Saude in the context of health care by SUS-MS. The application was developed and validated with participation of stakeholders consisting of health users and Brazilian government managers.", "references": ["Brazil. e-SUS Primary Care. Portal da Saúude. Available at: http://dab.saude.gov.br/portaldab/esus.php (in portuguese).", "Brazil. e-SUS Primary Care. Guia para instalação e utilização do prontuário eletrônico do cidadão na Atenção Domiciliar (módulo e-SUS AD). 2014. Available at: http://189.28.128.100/dab/docs/portaldab/documentos/guia_ad_v_1_3.pdf. (in portuguese).", "Brazil. Health Ministry. Primary Care National Policy. Brasília: Health Ministry (Health Legislation Series). 2012. Available at: http://dab.saude.gov.br/portaldab/pnab.php (in portuguese)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814159"}, {"title": "Safely managing data variety in big data software development", "authors": ["Thomas Cerqueus\n,", "Eduardo Cunha de Almeida\n,", "Stefanie Scherzinger"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nWe consider the task of building Big Data software systems, offered as software-as-a-service. These applications are commonly backed by NoSQL data stores that address the proverbial Vs of Big Data processing: NoSQL data stores can handle large volumes of data and many systems do not enforce a global schema, to account for structural variety in data. Thus, software engineers can design the data model on the go, a flexibility that is particularly crucial in agile software development. However, NoSQL data stores commonly do not yet account for the veracity of changes when it comes to changes in the structure of persisted data. Yet this is an inevitable consequence of agile software development. In most NoSQL-based application stacks, schema evolution is completely handled within the application code, usually involving object mapper libraries. Yet simple code refactorings, such as renaming a class attribute at the source code level, can cause data loss or runtime errors once the application has been deployed to production. We address this pain point by contributing type checking rules that we have implemented within an IDE plugin. Our plugin ControVol statically type checks the object mapper class declarations against the code release history. ControVol is thus capable of detecting common yet risky cases of mismatched data and schema, and can even suggest automatic fixes.", "references": ["Google Developers, \"Google Cloud Datastore,\" 2015, https://developers.google.com/datastore/.", "\"MongoDB,\" 2015, http://www.mongodb.org/.", "M. Hartung, J. F. Terwilliger, and E. Rahm, \"Recent Advances in Schema and Ontology Evolution,\" in Schema Matching and Mapping, 2011, pp. 149--190."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819293"}, {"title": "Implementation of Software-Defined Storage Service with Heterogeneous Object Storage Technologies", "authors": ["Yu-Chuan Shen\n,", "Chao-Tung Yang\n,", "Shuo-Tsung Chen\n,", "Wei-Hsun Cheng"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nWith the rapid development of information, personal computers are not only popular but also provide cloud services. Cloud Service is a concept that users can upload their requirement via Internet to cloud environment and then receive a response by postprocessing of the cloud environment, for example cloud storage. Software-defined storage (SDS) is a kind of virtualization technology for cloud storage. It uses the software to integrate the resources so as to improve accessibility and usability. There are many different open source projects for SDS in the Internet. This work aims to utilize these open source projects of SDS to improve the integration of the hardware and software resources effectively. In other words, we integrate various SDS open source projects or technologies to implement a cloud system. In the system architecture, we use some open-source software to make the proposed system more compatible and automatically assign a file to an appropriate storage location after users upload files. In addition, a manager can set some parameters to make this system more flexible. We also provide a high usability user interface. The user interface is designed as a web application. According to the concept of cloud services, this interface can be used anywhere and anytime.", "references": ["I. Foster, Yong Zhao, I. Raicu, and Shiyong Lu. Cloud computing and grid computing 360-degree compared. In Grid Computing Environments Workshop, 2008. GCE '08, pages 1--10, Nov 2008.", "D. Nurmi, R. Wolski, C. Grzegorczyk, G. Obertelli, S. Soman, L. Youseff, and D. Zagorodnov. The eucalyptus open-source cloud-computing system. In Cluster Computing and the Grid, 2009. CCGRID '09. 9th IEEE/ACM International Symposium on, pages 124--131, May 2009.", "G. Vernik, A. Shulman-Peleg, S. Dippl, C. Formisano, M. C. Jaeger, E. K. Kolodner, and M. Villari. Data on-boarding in federated storage clouds. In Cloud Computing (CLOUD), 2013 IEEE Sixth International Conference on, pages 244--251, June 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818891"}, {"title": "The effect of assessor coverage and assessor accuracy on rank aggregation precision", "authors": ["Laurence A. F. Park\n,", "Glenn Stone"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nRank aggregation is the process of aggregating multiple rankings provided by multiple assessors, of a given set of items, into a single ranking. Each assessor, whether it be human or computer based, is a resource that we use to obtain the multiple rankings. The accuracy of the aggregated ranking depends on the accuracy of the assessor ranking and the assessor coverage of the items. Our question is, given limited assessment resources, should each assessor rank many items to obtain item coverage, spending little time on each item, or should each assessor rank only a few items, but spend more time on each item to obtain a high accuracy ranking? In this article, we take a first step towards answering this question, by developing a model, based on simulation, showing the effect of the number of items assigned to an assessor and the accuracy of the assessment on the precision of the aggregated ranking. We find that when using Binomial allocation of items to assessors, increasing the assessor accuracy provides a greater increase in aggregated rank accuracy.", "references": ["N. Ailon. Aggregation of partial rankings, p-ratings and top-m lists. Algorithmica, 57(2):284--300, 2010.", "N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: ranking and clustering. Journal of the ACM (JACM), 55(5):23, 2008.", "R. Arora and M. Meila. Consensus ranking with signed permutations. In Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics, pages 117--125, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838937"}, {"title": "Influence of Vertical Result in Web Search Examination", "authors": ["Zeyang Liu\n,", "Yiqun Liu\n,", "Ke Zhou\n,", "Min Zhang\n,", "Shaoping Ma"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nResearch in how users examine results on search engine result pages (SERPs) helps improve result ranking, advertisement placement, performance evaluation and search UI design. Although examination behavior on organic search results (also known as \"ten blue links\") has been well studied in existing works, there lacks a thorough investigation on how users examine SERPs with verticals. Considering the fact that a large fraction of SERPs are served with one or more verticals in the practical Web search scenario, it is of vital importance to understand the influence of vertical results on search examination behaviors. In this paper, we focus on five popular vertical types and try to study their influences on users' examination processes in both cases when they are relevant or irrelevant to the search queries. With examination behavior data collected with an eye-tracking device, we show the existence of vertical-aware user behavior effects including vertical attraction effect, examination cut-off effect in the presence of a relevant vertical, and examination spill-over effect in the presence of an irrelevant vertical. Furthermore, we are also among the first to systematically investigate the internal examination behavior within the vertical results. We believe that this work will promote our understanding of user interactions with federated search engines and bring benefit to the construction of search performance evaluations.", "references": ["J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 539--548. ACM, 2014.", "J. Arguello, F. Diaz, and J. Callan. Learning to aggregate vertical results into web search results. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 201--210. ACM, 2011.", "J. Arguello, F. Diaz, J. Callan, and J.-F. Crespo. Sources of evidence for vertical selection. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 315--322. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767714"}, {"title": "Elimination of impulsive disturbances from stereo audio recordings using vector autoregressive modeling and variable-order Kalman filtering", "authors": ["Maciej Niedzwiecki\n,", "Marcin Ciołek\n,", "Krzysztof Cisowski"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nThis paper presents a new approach to elimination of impulsive disturbances from stereo audio recordings. The proposed solution is based on vector autoregressive modeling of audio signals. Online tracking of signal model parameters is performed using the exponentially weighted least squares algorithm. Detection of noise pulses and model-based interpolation of the irrevocably distorted samples is realized using an adaptive, variable-order Kalman filter. The proposed approach is evaluated on a set of clean audio signals contaminated with real click waveforms extracted from old gramophone recordings.", "references": ["S. V. Vaseghi and P. J. W. Rayner, \"Detection and suppression of impulsive noise in speech communication systems,\" in IEE Proc., 1990, vol. 137, pp. 38-46.", "S. V. Vaseghi and R. Frayling-Cork, \"Restoration of old gramophone recordings,\" J. Audio Eng. Soc., vol. 40, pp. 791-801, 1992.", "M. Niedzwiecki and K. Cisowski, \"Adaptive scheme for elimination of broadband noise and impulsive disturbances from audio signals,\" in Proc. Quatrozieme Colloque GRETSI, Juan-les-Pins, France, 1993, pp. 519-522."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2015.2414823"}, {"title": "Developers' networks contribution to web application design", "authors": ["Devis Bianchini\n,", "Valeria De Antonellis\n,", "Michele Melchiori"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nNovel web application development techniques rely on selection of the right data services, and this task assumes relevance to properly support creativity of developers. To this aim, developers should not merely leverage service descriptions, that are often very simple, in terms of categories and (semantic) tags. Data service selection criteria should include the experience of other developers who used the services in the past for designing their own web applications. According to this viewpoint, a data service might be relevant since: (i) it has been already used in similar contexts (i.e., in applications designed with similar data services); (ii) it has been used by other developers whose service selection experiences are considered as relevant by the developer who is designing the new application. The importance given to past experiences of other developers might be qualified by exploring the social network that relates the developers themselves and its topology. In this paper, we test the effectiveness of a multi-layered model meant for the selection of data services for web application design, taking into account such a developers' network.", "references": ["A. Fuxman, P. Giorgini, M. Kolp, J. Mylopoulos, Information Systems as Social Structures, Formal Ontology in Information Systems (2001) 12--21.", "E. Blasch, Y. Chen, G. Chen, D. Shen, R. Kohler, Information Fusion in a Cloud-Enabled Environment, in: High Performance Cloud Auditing and Applications, 2013.", "S. Ceri, D. Braga, F. Corcoglioniti, M. Grossniklaus, S. Vadacca, Search Computing Challenges and Directions, in: Objects and Databases, Lecture Notes in Computer Sciences, Vol. 6348, 2010, pp. 1--5."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837241"}, {"title": "Real-time Analysis and Visualization of the YFCC100m Dataset", "authors": ["Sebastian Kalkowski\n,", "Christian Schulze\n,", "Andreas Dengel\n,", "Damian Borth"], "publication": "MMCommons '15: Proceedings of the 2015 Workshop on Community-Organized Multimodal Mining: Opportunities for Novel Solutions", "abstract": "ABSTRACT\nWith the Yahoo Flickr Creative Commons 100 Million (YFCC100m) dataset, a novel dataset was introduced to the computer vision and multimedia research community. To maximize the benefit for the research community and utilize its potential, this dataset has to be made accessible by tools allowing to search for target concepts within the dataset and mechanism to browse images and videos of the dataset. Following best practice from data collections, such as ImageNet and MS COCO, this paper presents means of accessibility for the YFCC100m dataset. This includes a global analysis of the dataset and an online browser to explore and investigate subsets of the dataset in real-time. Providing statistics of the queried images and videos will enable researchers to refine their query successively, such that the users desired subset of interest can be narrowed down quickly. The final set of image and video can be downloaded as URLs from the browser for further processing.", "references": ["J. Bernd, D. Borth, B. Elizalde, G. Friedland, H. Gallagher, L. Gottlieb, A. Janin, S. Karabashlieva, J. Takahashi, and J. Won. The yli-med corpus: Characteristics, procedures, and plans. arXiv preprint arXiv:1503.04250, 2015.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale Visual Sentiment Ontology and Detectors Using Adjective Noun Pairs. In Proc. ACM Int. Conf. on Multimedia (ACM MM), pages 223--232, October 2013.", "L. Cao, S.-F. Chang, N. Codella, C. Cotton, D. Ellis, L. Gong, M. Hill, G. Hua, J. Kender, M. Merler, Y. Mu amd A. Natsev, and J. Smith. IBM Research and Columbia University TRECVID-2011 Multimedia Event Detection (MED) System. In Proc. NIST TRECVID Workshop (unreviewed workshop paper), December 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814815.2814820"}, {"title": "Session details: Oral Session 2: Content analysis", "authors": ["Yu-Gang Jiang"], "publication": "ASM '15: Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3260946"}, {"title": "Improving Collaborative Filtering via Hidden Structured Constraint", "authors": ["Qing Zhang\n,", "Houfeng Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMatrix factorization models, as one of the most powerful Collaborative Filtering approaches, have greatly advanced the recommendation tasks. However, few of them are able to explicitly consider structured constraint for modeling user interests. To solve this problem, we propose a novel matrix factorization model with adaptive graph regularization framework, which can automatically discover latent user communities jointly with learning latent user representations, to enhance the discriminative power for recommendation. Experiments on real-world datasets demonstrate the effectiveness of the proposed method.", "references": ["D. Agarwal and B. Chen. flda: matrix factorization through latent dirichlet allocation. In Proceedings of the WSDM, pages 91--100, 2010.", "J. Feng, Z. Lin, H. Xu, and S. Yan. Robust subspace segmentation with block-diagonal prior. In CVPR, pages 3818--3825, 2014.", "Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In ICDM, pages 263--272, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806623"}, {"title": "Building Representative Composite Items", "authors": ["VIncent Leroy\n,", "Sihem Amer-Yahia\n,", "Eric Gaussier\n,", "Hamid Mirisaee"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe problem of summarizing a large collection of homogeneous items has been addressed extensively in particular in the case of geo-tagged datasets (e.g. Flickr photos and tags). In our work, we study the problem of summarizing large collections of heterogeneous items. For example, a user planning to spend extended periods of time in a given city would be interested in seeing a map of that city with item summaries in different geographic areas, each containing a theater, a gym, a bakery, a few restaurants and a subway station. We propose to solve that problem by building representative Composite Items (CIs).\nTo the best of our knowledge, this is the first work that addresses the problem of finding representative CIs for heterogeneous items. Our problem naturally arises when summarizing geo-tagged datasets but also in other datasets such as movie or music summarization. We formalize building representative CIs as an optimization problem and propose KFC, an extended fuzzy clustering algorithm to solve it. We show that KFC converges and run extensive experiments on a variety of real datasets that validate its effectiveness.", "references": ["D. Aloise, A. Deshpande, P. Hansen, and P. Popat. NP-hardness of euclidean sum-of-squares clustering. Mach. Learn., 75(2):245--248, May 2009.", "S. Amer-Yahia, F. Bonchi, C. Castillo, E. Feuerstein, I. Méndez-Díaz, and P. Zabala. Composite retrieval of diverse and complementary bundles. IEEE Trans. Knowl. Data Eng., 26(11):2662--2675, 2014.", "A. Angel, S. Chaudhuri, G. Das, and N. Koudas. Ranking objects based on relationships and fixed associations. In M. L. Kersten, B. Novikov, J. Teubner, V. Polutin, and S. Manegold, editors, EDBT, volume 360 of ACM International Conference Proceeding Series, pages 910--921. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806465"}, {"title": "Optimizing Text Quantifiers for Multivariate Loss Functions", "authors": ["Andrea Esuli\n,", "Fabrizio Sebastiani"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nWe address the problem of quantification, a supervised learning task whose goal is, given a class, to estimate the relative frequency (or prevalence) of the class in a dataset of unlabeled items. Quantification has several applications in data and text mining, such as estimating the prevalence of positive reviews in a set of reviews of a given product or estimating the prevalence of a given support issue in a dataset of transcripts of phone calls to tech support. So far, quantification has been addressed by learning a general-purpose classifier, counting the unlabeled items that have been assigned the class, and tuning the obtained counts according to some heuristics. In this article, we depart from the tradition of using general-purpose classifiers and use instead a supervised learning model for structured prediction, capable of generating classifiers directly optimized for the (multivariate and nonlinear) function used for evaluating quantification accuracy. The experiments that we have run on 5,500 binary high-dimensional datasets (averaging more than 14,000 documents each) show that this method is more accurate, more stable, and more efficient than existing state-of-the-art quantification methods.", "references": ["Rocío Alaíz-Rodríguez, Alicia Guerrero-Curieses, and Jesús Cid-Sueiro. 2011. Class and subclass probability re-estimation to adapt a classifier in the presence of concept drift. Neurocomputing 74, 16 (2011), 2614--2623.", "Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2013. Variable-Constraint classification and quantification of radiology reports under the ACR Index. Expert Systems and Applications 40, 9 (2013), 3441--3449.", "Jose Barranquero, Jorge Díez, and Juan José del Coz. 2015. Quantification-oriented learning based on reliable classifiers. Pattern Recognition 48, 2 (2015), 591--604."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700406"}, {"title": "Data citation quantity and quality in research output of a large-scale educational panel study", "authors": ["Nadine Mahrholz\n,", "Anke Reinhold\n,", "Marc Rittberger"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nIn this paper, we report preliminary results of a small-scale case study about the data citation quantity and quality in research output of the National Educational Panel Study (NEPS), a longitudinal study analyzing educational processes in Germany across the lifespan. In order to collect research output based on NEPS data, we searched for and examined publications of a randomly selected sample of 72 NEPS data users. Altogether, we found 18 publications to be relevant for citation analysis. Compared to previous studies, the citation behavior in our sample can be assessed as better. However, publications often lack the inclusion of central data citation elements, such as a persistent identifier. The quality of data citations seems to vary across different types of research output. In a follow-up study, we plan to do a comprehensive sampling and analysis of NEPS related research output in order to verify our findings, and also to include further panel studies to compare citation behavior across different studies.", "references": ["Altman, M. and King, G. 2007. A proposed standard for the scholarly citation of quantitative data. D-lib Magazine 13, 3/4 (March/April 2007).", "Andrés, A. 2009. Measuring academic research: How to undertake a bibliometric study. Chandos Publishing, Oxford.", "Borgman, C. L. 2012. The Conundrum of Sharing Research Data. Journal of the American Society for Information Science and Technology 63, 6, 1059--1078."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809617"}, {"title": "EchoTag: Accurate Infrastructure-Free Indoor Location Tagging with Smartphones", "authors": ["Yu-Chih Tung\n,", "Kang G. Shin"], "publication": "MobiCom '15: Proceedings of the 21st Annual International Conference on Mobile Computing and Networking", "abstract": "ABSTRACT\nWe propose a novel mobile system, called EchoTag, that enables phones to tag and remember indoor locations without requiring any additional sensors or pre-installed infrastructure. The main idea behind EchoTag is to actively generate acoustic signatures by transmitting a sound signal with a phone's speakers and sensing its reflections with the phone's microphones. This active sensing provides finer-grained control of the collected signatures than the widely-used passive sensing. For example, because the sensing signal is controlled by EchoTag, it can be intentionally chosen to enrich the sensed signatures and remove noises from useless reflections. Extensive experiments show that EchoTag distinguishes 11 tags at 1cm resolution with 98% accuracy and maintains 90% accuracy even a week after its training. With this accurate location tagging, one can realize many interesting applications, such as automatically turning on the silent mode of a phone when it is placed at a pre-defined location/area near the bed or streaming favorite songs to speakers if it is placed near a home entertainment system. Most participants of our usability study agree on the usefulness of EchoTag's potential applications and the adequacy of its sensing accuracy for supporting these applications.", "references": ["Monsoon Power Monitor. http://www.msoon.com/LabEquipment/PowerMonitor/.", "Near Field Communication. http://www.nfc-forum.org.", "Azizyan, M., Constandache, I., and Roy Choudhury, R. Surroundsense: Mobile phone localization via ambience fingerprinting. In Proceedings of ACM MobiCom '09, pp. 261--272."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789168.2790102"}, {"title": "Searchlight: enabling integrated search and exploration over large multidimensional data", "authors": ["Alexander Kalinin\n,", "Ugur Cetintemel\n,", "Stan Zdonik"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe present a new system, called Searchlight, that uniquely integrates constraint solving and data management techniques. It allows Constraint Programming (CP) machinery to run efficiently inside a DBMS without the need to extract, transform and move the data. This marriage concurrently offers the rich expressiveness and efficiency of constraint-based search and optimization provided by modern CP solvers, and the ability of DBMSs to store and query data at scale, resulting in an enriched functionality that can effectively support both data- and search-intensive applications. As such, Searchlight is the first system to support generic search, exploration and mining over large multi-dimensional data collections, going beyond point algorithms designed for point search and mining tasks.\nSearchlight makes the following scientific contributions:\n• Constraint solvers as first-class citizens Instead of treating solver logic as a black-box, Searchlight provides native support, incorporating the necessary APIs for its specification and transparent execution as part of query plans, as well as novel algorithms for its optimized execution and parallelization.\n• Speculative solving Existing solvers assume that the entire data set is main-memory resident. Searchlight uses an innovative two stage Solve-Validate approach that allows it to operate speculatively yet safely on main-memory synopses, quickly producing candidate search results that can later be efficiently validated on real data.\n• Computation and I/O load balancing As CP solver logic can be computationally expensive, executing it on large search and data spaces requires novel CPU-I/O balancing approaches when performing search distribution.\nWe built a prototype implementation of Searchlight on Google's Or-Tools, an open-source suite of operations research tools, and the array DBMS SciDB. Extensive experimental results show that Searchlight often performs orders of magnitude faster than the next best approach (SciDB-only or CP-solver-only) in terms of end response time and time to first result.", "references": ["Google or-tools. https://code.google.com/p/or-tools/.", "The sloan digital sky survey. http://www.sdss.org/.", "C.-H. Ang, T. W. Ling, and X. M. Zhou. Qualitative spatial relationships representation io&t and its retrieval. In DEXA, pages 270--279, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794378"}, {"title": "Gibberish, Assistant, or Master?: Using Tweets Linking to News for Extractive Single-Document Summarization", "authors": ["Zhongyu Wei\n,", "Wei Gao"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSingle-document summarization is a challenging task. In this paper, we explore effective ways using the tweets linking to news for generating extractive summary of each document. We reveal the very basic value of tweets that can be utilized by regarding every tweet as a vote for candidate sentences. Base on such finding, we resort to unsupervised summarization models by leveraging the linking tweets to master the ranking of candidate extracts via random walk on a heterogeneous graph. The advantage is that we can use the linking tweets to opportunistically \"supervise\" the summarization with no need of reference summaries. Furthermore, we analyze the influence of the volume and latency of tweets on the quality of output summaries since tweets come after news release. Compared to truly supervised summarizer unaware of tweets, our method achieves significantly better results with reasonably small tradeoff on latency; compared to the same using tweets as auxiliary features, our method is comparable while needing less tweets and much shorter time to achieve significant outperformance.", "references": ["G. Erkan and D. R. Radev. Lexrank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research, 22:457--479, 2004.", "Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efficient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933--969, 2003.", "W. Gao, P. Li, and K. Darwish. Joint topic modeling for event summarization across news and social media streams. In CIKM, pages 1173--1182, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767835"}, {"title": "Understanding Temporal Query Intent", "authors": ["Mohammed Hasanuzzaman\n,", "Sriparna Saha\n,", "Gaël Dias\n,", "Stéphane Ferrari"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUnderstanding the temporal orientation of web search queries is an important issue for the success of information access systems. In this paper, we propose a multi-objective ensemble learning solution that (1) allows to accurately classify queries along their temporal intent and (2) identifies a set of performing solutions thus offering a wide range of possible applications. Experiments show that correct representation of the problem can lead to great classification improvements when compared to recent state-of-the-art solutions and baseline ensemble techniques.", "references": ["R. Campos, G. Dias, A. Jorge, and C. Nunes. Gte: A distributional second-order co-occurrence approach to improve the identification of top relevant dates in web snippets. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM), pages 2035--2039, 2012.", "K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2):181--197, 2002.", "G. H. Dias, M. Hasanuzzaman, S. Ferrari, and Y. Mathet. Tempowordnet for sentence time tagging. In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion (WWW), pages 833--838, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767792"}, {"title": "Summarizing Contrastive Themes via Hierarchical Non-Parametric Processes", "authors": ["Zhaochun Ren\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nGiven a topic of interest, a contrastive theme is a group of opposing pairs of viewpoints. We address the task of summarizing contrastive themes: given a set of opinionated documents, select meaningful sentences to represent contrastive themes present in those documents. Several factors make this a challenging problem: unknown numbers of topics, unknown relationships among topics, and the extraction of comparative sentences. Our approach has three core ingredients: contrastive theme modeling, diverse theme extraction, and contrastive theme summarization. Specifically, we present a hierarchical non-parametric model to describe hierarchical relations among topics; this model is used to infer threads of topics as themes from the nested Chinese restaurant process. We enhance the diversity of themes by using structured determinantal point processes for selecting a set of diverse themes with high quality. Finally, we pair contrastive themes and employ an iterative optimization algorithm to select sentences, explicitly considering contrast, relevance, and diversity. Experiments on three datasets demonstrate the effectiveness of our method.", "references": ["A. Ahmed, L. Hong, and A. Smola. Nested chinese restaurant franchise process: Applications to user tracking and document modeling. In ICML, 2013.", "J. Allan, C. Wade, and A. Bolivar. Retrieval and novelty detection at the sentence level. In SIGIR, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Machine Learning research, 3: 993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767713"}, {"title": "Intuition vs. truth: evaluation of common myths about stackoverflow posts", "authors": ["Verena Honsel\n,", "Steffen Herbold\n,", "Jens Grabowski"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nPosting and answering questions on StackOverflow (SO) is everyday business for many developers. We asked a group of developers what they expect to be true about questions and answers on SO. Most of their expectations were related to the likelihood of getting an answer or to voting behavior. From their comments, we formulated nine myths that they think are true about the platform. Then, we proceeded to use rather simple methods from statistics to check if these myths are supported by the data in the SO dump provided. Through our analysis, we determined that there is an effect for eight of the nine myths the developers believed in. However, for only four of the myths the effect size is large enough to actually make a difference. Hence, we could bust five myths the developers believed in.", "references": ["H. B. Mann and D. R. Whitney, \"On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other,\" The Ann. of Math. Stat., vol. 18, no. 1, pp. pp. 50--60, 1947.", "D. Movshovitz-Attias, Y. Movshovitz-Attias, P. Steenkiste, and C. Faloutsos, \"Analysis of the Reputation System and User Contributions on a Question Answering Website: StackOverflow,\" in Proc. 2013 IEEE/ACM Int. Conf. on Advances in Social Netw. Anal. and Mining. ACM, 2013.", "A. Bosu, C. S. Corley, D. Heaton, D. Chatterji, J. C. Carver, and N. A. Kraft, \"Building Reputation in StackOverflow: An Empirical Investigation,\" in Proc. 10th Working Conf. on Mining Softw. Repositories (MSR). IEEE Computer Society, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820581"}, {"title": "The TIB|AV Portal as a Future Linked Media Ecosystem", "authors": ["Paloma Marín Arraiza\n,", "Sven Strobel"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nVarious techniques for video analysis, concept mapping, semantic search and metadata management are part of the current features of the TIB|AV Portal as described in this demo. The segment identification and ontology annotation make the portal a good platform to support the Linked Data and Media. Weaving into a machine-readable metadata format will complete this task.", "references": ["Berners -- Lee, T. 2006. Linked Data. Design Issues. Available in: http://goo.gl/katw", "Lichtenstein, A.; Plank, M.; Neumann, J. 2014. TIB's Portal for Audiovisual Media: Combining Manual and Automatic Indexing. Cataloging & Classification Quarterly 52:5, pp. 562--577, DOI: 10.1080/01639374.2014.917135.", "Nixon, L., Troncy. R. 2014. Survey of Semantic Media Annotation Tools for the Web: Towards new Media Applications with Linked Media. 11th ESWC 2014, Demos Track, Vol. CCIS 476. http://goo.gl/BonAvl."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742912"}, {"title": "Expanding the utility of geospatial knowledge bases by linking concepts to WikiText and to polygonal boundaries", "authors": ["Bruno Martins\n,", "Francisco J. López-Pellicer\n,", "Dirk Ahlers"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nThis vision paper argues that a geospatial knowledge base combining textual descriptions for concepts such as places, together with place types, semantic relations between concepts and, most importantly, polygonal geometries associated to the geospatial concepts, constitutes a valuable resource for researchers working on the computational modeling of spatial language. We describe a simple procedure for producing one such resource from existing open datasets, and discuss possible ways for moving beyond the current state-of-the-art within the general area of geospatial text mining, through studies supported by one such knowledge base.", "references": ["J. Hoffart, F. M. Suchanek, K. Berberich, and G. Weikum. YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia. Artif. Intell., 194, 2013.", "A. Khan, M. Vasardani, and S. Winter. Extracting spatial information from place descriptions. In ACM SIGSPATIAL Workshop on Computational Models of Place, 2013.", "J. Nothman, N. Ringland, W. Radford, T. Murphy, and J. R. Curran. Learning multilingual named entity recognition from Wikipedia. Artif. Intell., 194, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837693"}, {"title": "Inferring Companies Similarities from Brazilian Government Expenditure Data", "authors": ["Marcelo Pita\n,", "Gustavo da Gama Torres"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nA graph-based method is proposed for inferring similarities among companies from their affiliations in the context of expenditure financial transactions in the Brazilian Federal Government. There are trusted and untrusted companies. We performed a basic cluster analysis in the companies network to verify whether clusters (connected components) are discriminative concerning companies trustworthiness. Results show evidences that this is true, reinforcing the following hypotheses: (1) there are suppliers associations, which evidences the formation of cartels; and (2) public agencies and agents play an important role in the legality of financial transactions.", "references": ["Duit, A.: Galaz V. Governance and Complexity: Emerging issues for governance theory. In: Governance: An International Journal of Policy, Administration and Institutions, v. 21(3), 2008, pp. 311-335.", "Feitelson, D. Experimental Computer Science: The need for a cultural change. School of Computer Science and Engineering, Hebrew University, Jerusalem, Technical report, 2005.", "Van Assche, K., Beunen, R. and Duineveld, M. Evolutionary Governance Theory: an introduction. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814168"}, {"title": "Expressive Multimedia: Bringing Action to Physical World by Dancing-Tablet", "authors": ["Muhammad Sikandar Lal Khan\n,", "Haibo Li\n,", "Shafiq ur Réhman"], "publication": "HCMC '15: Proceedings of the 2nd Workshop on Computational Models of Social Interactions: Human-Computer-Media Communication", "abstract": "ABSTRACT\nThe design practice based on embodied interaction concept focuses on developing new user interfaces for computer devices that merge the digital content with the physical world. In this work we have proposed a novel embodied interaction based design in which the 'action' information of the digital content is presented in the physical world. More specifically, we have mapped the 'action' information of the video content from the digital world into the physical world. The motivating example presented in this paper is our novel dancing-tablet, in which a tablet-PC dances on the rhythm of the song, hence the 'action' information is not just confined into a 2D flat display but also expressed by it. This paper presents i) hardware design of our mechatronic dancing-tablet platform, ii) software algorithm for musical feature extraction and iii) embodied computational model for mapping 'action' information of the musical expression to the mechatronic platform. Our user study shows that the overall perception of audio-video music is enhanced by our dancing-tablet setup.", "references": ["S. Allen, V. Graupera, and L. Lundrigan. The smartphone is the new pc. In Pro Smartphone Cross-Platform Development, pages 1--14. 2010.", "P. M. Brossier. The aubio library at mirex 2006. MIREX 2006, page 1, 2006.", "K. Dobson. Blendie. In 5th conf. on Designing interactive systems, pages 309--309. ACM, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810397.2810399"}, {"title": "Word Embedding based Generalized Language Model for Information Retrieval", "authors": ["Debasis Ganguly\n,", "Dwaipayan Roy\n,", "Mandar Mitra\n,", "Gareth J.F. Jones"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWord2vec, a state-of-the-art word embedding technique has gained a lot of interest in the NLP community. The embedding of the word vectors helps to retrieve a list of words that are used in similar contexts with respect to a given word. In this paper, we focus on using the word embeddings for enhancing retrieval effectiveness. In particular, we construct a generalized language model, where the mutual independence between a pair of words (say t and t') no longer holds. Instead, we make use of the vector embeddings of the words to derive the transformation probabilities between words. Specifically, the event of observing a term t in the query from a document d is modeled by two distinct events, that of generating a different term t', either from the document itself or from the collection, respectively, and then eventually transforming it to the observed query term t. The first event of generating an intermediate term from the document intends to capture how well does a term contextually fit within a document, whereas the second one of generating it from the collection aims to address the vocabulary mismatch problem by taking into account other related terms in the collection. Our experiments, conducted on the standard TREC collection, show that our proposed method yields significant improvements over LM and LDA-smoothed LM baselines.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993--1022, March 2003.", "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. J. Mach. Learn. Res., 12:2493--2537, Nov. 2011.", "S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. Indexing by latent semantic analysis. JASIS, 41(6):391--407, 1990."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767780"}, {"title": "\"Implicit search feature based approach to assist users in exploratory search tasks\" by Chathra Hendahewa, with Prateek Jainas as coordinator", "authors": ["Chathra Hendahewa"], "publication": "ACM SIGWEB Newsletter", "abstract": "Abstract\nChathra Hendahewa is a Ph.D. candidate in Department of Computer Science at Rutgers University in New Jersey, currently finishing up her dissertation (Expected Graduation Date: Jan 2016) under the guidance of Prof. Chirag Shah. Her major research interests lie in user search behavior analysis, data mining/machine learning for user interaction analysis and time series analysis. She has published and presented her research work at reputable conferences such as SIGIR, WSDM and ICMLA and also co-authored multiple journal papers published in ACM TOIS, IP&M and JASIST.\nShe holds a Master of Science in Computer Science from Rutgers University, USA (Jan 2013). Before joining Rutgers, she received her Bachelors in Information Technology from University of Moratuwa, Sri Lanka (Jan 2007), where she was awarded the best information technology graduate award. Chathra was a recipient of the International Fulbright Science and Technology Award (2008-2011) to pursue her doctoral studies. For more information see: http://paul.rutgers.edu/~chathrah/", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833219.2833222"}, {"title": "An Intelligent GIS Database Framework Featuring Building Query Functionality Using n-grams Encoding and k-means Classification", "authors": ["Georgios Bardis\n,", "Nikolaos Sideris\n,", "Nikolaos Vassilas\n,", "Georgios Miaoulis"], "publication": "EANN '15: Proceedings of the 16th International Conference on Engineering Applications of Neural Networks (INNS)", "abstract": "ABSTRACT\nIn the current work we present the design and synthesis of a GIS framework with emphasis in building classification and identification. Its fundamental functionality comprises the submission of the geometric representation of a building as a query sample, subsequently encoded and employed by a classifying mechanism in order to discover similar occurrences within a pre-processed GIS-based building database. The encoding of both the query sample and the existing building database relies on n-grams whereas the classification and identification scheme combines k-means and a set of global and local features for the construction of similarity classes.", "references": ["Hugentobler M., Quantum GIS, Encyclopedia of GIS, pp. 935--939, 2008.", "Neteler M., Beaudette D.E., Cavallini P., Lami L., Cepicky J., GRASS GIS, Advances in Geographic Information Science Volume 2, pp. 171--199, 2008.", "Maguire D., ArcGIS: General Purpose GIS Software System, Encyclopedia of GIS, pp. 25--31, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797143.2797148"}, {"title": "Improving biological significance of gene expression biclusters with key missing genes", "authors": ["Shufan Ji\n,", "Xing Tian\n,", "Jin Chen"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nIdentifying condition-specific co-expressed gene groups is critical for gene functional and regulatory analysis. However, given that genes with critical functions (such as transcription factors) may not co-express with their target genes, it is insufficient to uncover gene functional associations only from gene expression data. In this paper, we propose a novel integrative biclustering approach to build high quality biclusters from gene expression data, and to identify critical missing genes in biclusters based on Gene Ontology as well. Our approach delivers a complete inter- and intra-bicluster functional relationship, thus provides biologists a clear picture for gene functional association study. We experimented with the Yeast cell cycle and Arabidopsis cold-response gene expression datasets. Experimental results show that a clear inter- and intra-bicluster relationship is identified, and the biological significance of the biclusters is considerably improved.", "references": ["M. Ashburner, C. Ball, J. Blake, et al. Gene ontology: tool for the unification of biology. Nat Genet, 25(1):25--29, 2000.", "S. Awad, N. Panchy, S.-K. Ng, and J. Chen. Inferring the regulatory interaction models of transcription factors in transcriptional regulatory networks. Journal of bioinformatics and computational biology, 10(05):1250012, 2012.", "C. Benedict, M. Geisler, J. Trygg, N. Huner, and V. Hurry. Consensus by democracy. using meta-analyses of microarray and genomic data to model the cold acclimation signaling pathway in arabidopsis. Plant Physiol, 141(4):1219--1232, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2808747"}, {"title": "An Improved System For Real-Time Scene Text Recognition", "authors": ["Haojin Yang\n,", "Cheng Wang\n,", "Xiaoyin Che\n,", "Sheng Luo\n,", "Christoph Meinel"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper we showcase a system for real-time text detection and recognition. We apply deep features created by Convolutional Neural Networks (CNNs) for both text detection and word recognition task. For text detection we follow the common localization-verification scheme which already shown its excellent ability in numerous previous work. In text localization stage, textual regions are roughly detected by using a MSERs (Maximally Stable Extremal Regions) detector with high recall rate. False alarms are then eliminated by using a CNNs classifier, and remaining text regions are further grouped into words. In the word recognition stage, we developed an skeleton-based text binarization method for segmenting text from its background. A CNNs based recognizer is then applied for recognizing character. The initial experiments show the powerful ability of deep features for text classification comparing with commonly used visual features. Our current implementation demonstrates real-time performance for recognizing scene text by using a standard PC with webcam.", "references": ["M. Anthimopoulos, B. Gatos, and I. Pratikakis. A two-stage scheme for text detection in video images. Journal of Image and Vision Computing, 28:1413--1426, 2010.", "H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up robust features (surf). Comput. Vis. Image Underst., 110(3):346--359, June 2008.", "A. Coates, B. Carpenter, C. Case, S. Satheesh, B. Suresh, T. Wang, D. J. Wu, and A. Y. Ng. Text detection and character recognition in scene images with unsupervised feature learning. In Proc. of International Conference on Document Analysis and Recognition, ICDAR '11, pages 440--445, Washington, DC, USA, 2011. IEEE Computer Society."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749352"}, {"title": "Linking a Community Platform to the Linked Open Data Cloud", "authors": ["Enayat Rajabi\n,", "Ivana Marenzi"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLinked Data promises access to a vast amount of resources for learners and teachers. Various research projects have focused on providing educational resources as Linked Data. In many of these projects the focus has been on interoperability of metadata and on linking them into the linked data cloud. In this paper we focus on the community aspect. We start from the observation that sharing data is most valuable within communities of practice with common interests and goals, and community members are interested in suitable resources to be used in specific learning scenarios. The community of practice we are focusing on is an English language teaching and learning community, which we have been supporting through the LearnWeb2.0 platform for the last two years. We analyse the requirements of this specific community as a basis to enrich the current collected materials with open educational resources taken from the Linked Data Cloud. To this aim, we performed an interlinking approach in order to enrich the learning resources exposed as RDF (Resource Description Framework) in the LearnWeb2.0 platform with additional information taken from the Web.", "references": ["Bizer, C. 2004. D2RQ - treating non-RDF databases as virtual RDF graphs. In Proceedings of the 3rd International Semantic Web Conference (ISWC2004).", "Bizer, C., Heath, T., Berners-Lee, T. 2009. Linked Data - The Story So Far. Int. J. Semantic Web Inf. Syst. 5, 1--22.", "Bortoluzzi, M., and Marenzi,.I. 2013. YELLing for Partnership: A social platform for sharing practice and reflection in teacher training for language learning. In Riem, A., Dolce, M.R., Mercanti, S. and Colomba, C. (Eds.).The Tapestry of the Creative Word in Anglophone Literatures, 249--262. Udine: Forum."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741742"}, {"title": "Social and Collaborative Information Seeking: State of the Union", "authors": ["Chirag Shah"], "publication": "ECol '15: Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking", "abstract": "ABSTRACT\nIncreasingly, people are utilizing collaboration and sharing technologies to address needs in their work and personal lives. Information plays a key role in today's world, and many problems require us to use social and collaborative ties to search for and locate information. Examples range from corporate teams doing business intelligence gathering to a couple planning their vacation to a diabetes patient looking for information and support regarding treatment options. This emerging area of scholarly inquiry that involves incorporating social and/or collaborative dimensions to information seeking/retrieval processes has attracted researchers, developers, and students from a wide variety of domains, providing a rich multidisciplinary and interdisciplinary ground in which many new ideas have flourished and problems have come forth. In this keynote I will review some of these recent efforts, including my own, covering key theories, models, and tools. Going beyond individual search models, I will talk about how we ought to consider both social and collaborative dimensions under a larger umbrella that focus on communicative processes and social interactions to investigate and support social and collaborative dimensions of information seeking, retrieval, and use. The central thesis of my talk is that social and collaborative information seeking (SCIS) addresses some of the limitations of other information seeking methods by integrating individual, community-based, socially oriented, and small-group focused information retrieval and usage activities. I will draw on examples and applications from different domains to highlight when and how SCIS could lead to improvements, enlightenments, and failures. The talk will also provide an overview of the current state of research methods and evaluation techniques for SCIS.", "references": ["Hansen, P., Shah, C., & Klas, C.-P. (Eds.) (2015). Collaborative information seeking: Best practices, new domains, new thoughts (Computer-Supported Cooperative Work (CSCW) Series). Berlin, Germany: Springer. http://www.springer.com/en/book/9783319185415", "Shah, C. (2012). Collaborative information seeking: The art and science of making the whole greater than the sum of all (The Information Retrieval Series). Berlin, Germany: Springer. http://www.springer.com/en/book/9783642288128", "Shah, C., Capra, R., & Hansen, P. (2014). Collaborative Information Seeking {Guest editors' introduction}. IEEE Computer, 47(3), 22--25. doi:10.1109/MC.2014.54."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2812376.2812381"}, {"title": "Computer aided breast cancer diagnosis system with fuzzy multiple-parameter support vector machine", "authors": ["Chulwoo Pack\n,", "Sung Shin\n,", "Seong Ho Son\n,", "Soon Ik Jeon"], "publication": "RACS: Proceedings of the 2015 Conference on research in adaptive and convergent systems", "abstract": "ABSTRACT\nComputer Aided Diagnosis (CAD) system has been proven that it can be utilized as the secondary option for physicians for early breast cancer detection. A typical CAD system consists of several phases like image segmentation, feature extraction and selection, classification. Among those phases, the classification phase is one of the important phases that directly affect the performance of the entire system. Therefore the main issue is to enhance the classification phase to construct better decision-making procedure comparing to conventional classification phase by assigning enhanced logic. In this paper, we propose a Fuzzy Multiple-parameter Support Vector Machine (SVM), which will be used in the CAD system. The proposed method uses fuzzy membership to tune up each training data points by assigning proper weight, corresponding to its feature, and adopts multiple parameters as a classifier for SVM, which further improves the machine-learning process to a more robust level. The experimental result shows that the proposed method is far more superior to the existing SVM in terms of performance, sensitivity and accuracy. Additionally, the result suggests for more sophisticated and complex approach to the current classification for CAD system.", "references": ["World Health Organization. (2014, Sep 10). U.S. Available: http://www.who.int/cancer/detection/breastcancer/en/", "Sharma, S., & Khanna, P. (2014). Computer-Aided Diagnosis of Malignant Mammograms using Zernike Moments and SVM. Journal of digital imaging, 28(1), 77--90.", "Baker, J. A., Rosen, E. L., Lo, J. Y., Gimenez, E. I., Walsh, R., & Soo, M. S. (2003). Computer-aided detection (CAD) in screening mammography: sensitivity of commercial CAD systems for detecting architectural distortion. American Journal of Roentgenology, 181(4), 1083--1088."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811411.2811504"}, {"title": "Ontology-assisted keyword search for NeuroML models", "authors": ["Justas Birgiolas\n,", "Suzanne W. Dietrich\n,", "Sharon Crook\n,", "Ashwin Rajadesingan\n,", "Chao Zhang\n,", "Shriharsha Velugoti Penchala\n,", "Veerasekhar Addepalli"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nNeuroML is an extensible markup language for describing complex mathematical models of neurons and neuronal networks. NeuroML is unique in its modular, multi-scale structure -- not only can entire NeuroML models be exchanged, but subcomponents of these models that correspond to neuroscience objects, like channels or synapses, also can be shared and reimplemented in a different model. This paper presents the design, implementation, and evaluation of an ontology-assisted search for NeuroML models. Specifically, the paper describes the design of the system, including the database that stores the modular NeuroML models and the architecture of the Web-based search (neuroml-db.org). The implementation takes advantage of the nested structure of NeuroML models and the NeuroLex ontology for neuroscience to provide additional semantic information to enhance the search. In addition to NeuroLex terms that may exist in model metadata, this initial implementation takes advantage of several semantic relationships provided by the NeuroLex ontology: Is_part_of, Located_in, and Neurotransmitter. An evaluation of the system illustrates its effectiveness both for functionality and performance, covering various types of searches broken down by keyword searches over the database and ontology searches using the semantic relationships.", "references": ["Agrawal, S., Chaudhuri, S., and Das, G. 2002. DBXplorer: A system for keyword-based search over relational databases. Proceedings of the 18th International Conference on Data Engineering. ICDE '02. IEEE Computer Society, Washington, DC, 5--16.", "Bachle, M., and Kirchberg, P. 2007. Ruby on Rails. IEEE Software. 24, 6 (November 2007), 105--108. DOI = http://dx.doi.org/10.1109/MS.2007.176.", "Crook, S. M., Bednar, J. A., Berger, S. D., Cannon, R. C., Davison, A. P., Djurfeldt, M., Eppler, J., Kriener, B., Furber, S., Graham, B., Hull, M., Plesser, H. E., Schwabe, L., Smith, L., Steuber, V., van Albada, S. 2012. Creating, documenting and sharing network models. Network: Computation in Neural Systems. 23, 4, 131--149. DOI = http://informahealthcare.com/doi/abs/10.3109/0954898X.2012.722743."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791360"}, {"title": "Evaluating Streams of Evolving News Events", "authors": ["Gaurav Baruah\n,", "Mark D. Smucker\n,", "Charles L.A. Clarke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPeople track news events according to their interests and available time. For a major event of great personal interest, they might check for updates several times an hour, taking time to keep abreast of all aspects of the evolving event. For minor events of more marginal interest, they might check back once or twice a day for a few minutes to learn about the most significant developments. Systems generating streams of updates about evolving events can improve user performance by appropriately filtering these updates, making it easy for users to track events in a timely manner without undue information overload. Unfortunately, predicting user performance on these systems poses a significant challenge. Standard evaluation methodology, designed for Web search and other adhoc retrieval tasks, adapts poorly to this context. In this paper, we develop a simple model that simulates users checking the system from time to time to read updates. For each simulated user, we generate a trace of their activities alternating between away times and reading times. These traces are then applied to measure system effectiveness. We test our model using data from the TREC 2013 Temporal Summarization Track (TST) comparing it to the effectiveness measures used in that track. The primary TST measure corresponds most closely with a modeled user that checks back once a day on average for an average of one minute. Users checking more frequently for longer times may view the relative performance of participating systems quite differently. In light of this sensitivity to user behavior, we recommend that future experiments be built around clearly stated assumptions regarding user interfaces and access patterns, with effectiveness measures reflecting these assumptions.", "references": ["KBA Stream Corpus 2013. http://trec-kba.org/kba-stream-corpus-2013.shtml.", "J. Allan, R. Gupta, and V. Khandelwal. Temporal Summaries of New Topics. In SIGIR, pp. 10--18, 2001.", "E. Amigó, J. Gonzalo, and S. Mizzaro. A Formal Approach to Effectiveness Metrics for Information Access: Retrieval, Filtering, and Clustering. In ECIR, pp. 817--821. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767751"}, {"title": "Handling shape variations in geographical distance rankings for local news recommendation", "authors": ["Jon Espen Ingvaldsen\n,", "Dirk Ahlers"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nGeographical proximity is an important ranking feature in many context aware recommendation systems. News recommender systems are an example of such systems where the proximity between users and the news' geographical context is a particularly important relevance factor. In this paper, we will discuss ways to improve distance ranking by taking geographical entity sizes, shapes, and footprints into account when handling news items that are ranked for specific users.", "references": ["M. D. Adelfio and H. Samet. Structured toponym resolution using combined hierarchical place categories. In GIR '13, 2013.", "D. Ahlers. Granularity as a Qualitative Concept for GIR. In GIR'15. ACM, 2015.", "J. E. Ingvaldsen and J. A. Gulla. Taming news streams with linked data. In RCIS 2015. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837702"}, {"title": "Scaling Out Link Prediction with SNAPLE: 1 Billion Edges and Beyond", "authors": ["Anne-Marie Kermarrec\n,", "Francois Taiani\n,", "Juan M. Tirado"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nA growing number of organizations are seeking to analyze extra large graphs in a timely and resource-efficient manner. With some graphs containing well over a billion elements, these organizations are turning to distributed graph-computing platforms that can scale out easily in existing data-centers and clouds. Unfortunately such platforms usually impose programming models that can be ill suited to typical graph computations, fundamentally undermining their potential benefits.\nIn this paper, we consider how the emblematic problem of link-prediction can be implemented efficiently in gather-apply-scatter (GAS) platforms, a popular distributed graph-computation model. Our proposal, called SNAPLE, exploits a novel highly-localized vertex scoring technique, and minimizes the cost of data flow while maintaining prediction quality. When used within GraphLab, SNAPLE can scale to very large graphs that a standard implementation of link prediction on GraphLab cannot handle. More precisely, we show that SNAPLE can process a graph containing 1.4 billions edges on a 256 cores cluster in less than three minutes, with no penalty in the quality of predictions. This result corresponds to an over-linear speedup of 30 against a 20-core standalone machine running a non-distributed state-of-the-art solution.", "references": ["Apache. Apache giraph. http://giraph.apache.org/, 2014.", "L. Backstrom, D. Huttenlocher, J. Kleinberg, and X. Lan. Group formation in large social networks: Membership, growth, and evolution. In KDD, 2006.", "Bagel. Bagel. https://github.com/mesos/spark/wiki/Bagel-Programming-Guide, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814810"}, {"title": "Features of Disagreement Between Retrieval Effectiveness Measures", "authors": ["Timothy Jones\n,", "Paul Thomas\n,", "Falk Scholer\n,", "Mark Sanderson"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany IR effectiveness measures are motivated from intuition, theory, or user studies. In general, most effectiveness measures are well correlated with each other. But, what about where they don't correlate? Which rankings cause measures to disagree? Are these rankings predictable for particular pairs of measures? In this work, we examine how and where metrics disagree, and identify differences that should be considered when selecting metrics for use in evaluating retrieval systems.", "references": ["A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between IR effectiveness measures and user satisfaction. In Proc SIGIR, pages 773--774, 2007.", "J. A. Aslam, E. Yilmaz, and V. Pavlu. The maximum entropy method for analyzing retrieval measures. In Proc SIGIR, pages 27--34, 2005.", "C. Buckley and E. M. Voorhees. Evaluating evaluation measure stability. In Proc SIGIR, pages 33--40, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767824"}, {"title": "A vulnerability's lifetime: enhancing version information in CVE databases", "authors": ["Leonid Glanz\n,", "Sebastian Schmidt\n,", "Sebastian Wollny\n,", "Ben Hermann"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nThe National Vulnerability Database (NVD) is a rich source of information for system administrators, software engineers, IT security consultants, and researchers in software security. Relevant information is provided in machine readable form and hence can be used for automated software security management. However, we discovered that information on affected software versions and fix information is not always available in structured form. We therefore propose to enrich the NVD database with this information and use a rule-based approach to extract this information from the informal vulnerability description. Such information is useful in software development to exchange or avoid vulnerable components as well as in security research for directed cause analysis.", "references": ["D. W. Baker, S. M. Christey, W. H. Hill, and D. E. Mann. The Development of a Common Enumeration of Vulnerabilities and Exposures. In Recent Advances in Intrusion Detection, volume 7, page 9, 1999.", "P. Mell, K. Scarfone, and S. Romanosky. Common Vulnerability Scoring System. IEEE Security Privacy, 4(6):85--89, Nov. 2006.", "H. S. Venter, J. H. P. Eloff, and Y. L. Li. Standardising Vulnerability Categories. Computers & Security, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809612"}, {"title": "Session details: Session 5F: Sentiment and Content Analysis", "authors": ["Ke Deng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252308"}, {"title": "Predicting Search Intent Based on Pre-Search Context", "authors": ["Weize Kong\n,", "Rui Li\n,", "Jie Luo\n,", "Aston Zhang\n,", "Yi Chang\n,", "James Allan"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhile many studies have been conducted on query understanding, there is limited understanding on why users start searches and how to predict search intent. In this paper, we propose to study this important but less explored problem. Our key intuition is that searches are triggered by different pre-search contexts, but the triggering relations are often hidden. For example, a user may search \"bitcoin\" because of a news article or an email the user just read, but the system does not know which of the pre-search contexts (the news article or the email) is the triggering source. Following this intuition, we conduct an in-depth analysis of pre-search context on a large-scale user log, which not only verifies the hidden triggering relations in the real world but also identifies a set of important characteristics of pre-search context and their triggered queries. Since the hidden triggering relations make it challenging to directly use pre-search context for intent prediction, we develop a mixture generative model to learn without any supervision how queries are triggered by different types of pre-search context. Further, we discuss how to apply our model to improve query prediction and query auto-completion. Our experiments on a large-scale of real-world data show that our model could accurately predict user search intent with pre-search context and improve upon the state-of-the-art methods significantly.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In WWW'11.", "P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui. Modeling the impact of short-and long-term behavior on search personalization. In SIGIR'12.", "I. Bordino, G. De Francisci Morales, I. Weber, and F. Bonchi. From machu_picchu to rafting the urubamba river: anticipating information needs via the entity-query graph. In WSDM'13."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767757"}, {"title": "User Latent Preference Model for Better Downside Management in Recommender Systems", "authors": ["Jian Wang\n,", "David Hardtke"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nDownside management is an important topic in the field of recommender systems. User satisfaction increases when good items are recommended, but satisfaction drops significantly when bad recommendations are pushed to them. For example, a parent would be disappointed if violent movies are recommended to their kids and may stop using the recommendation system entirely. A vegetarian would feel steak-house recommendations useless. A CEO in a mid-sized company would feel offended by receiving intern-level job recommendations. Under circumstances where there is penalty for a bad recommendation, a bad recommendation is worse than no recommendation at all. While most existing work focuses on upside management (recommending the best items to users), this paper emphasizes on achieving better downside management (reducing the recommendation of irrelevant or offensive items to users). The approach we propose is general and can be applied to any scenario or domain where downside management is key to the system.\nTo tackle the problem, we design a user latent preference model to predict the user preference in a specific dimension, say, the dietary restrictions of the user, the acceptable level of adult content in a movie, or the geographical preference of a job seeker. We propose to use multinomial regression as the core model and extend it with a hierarchical Bayesian framework to address the problem of data sparsity. After the user latent preference is predicted, we leverage it to filter out downside items. We validate the soundness of our approach by evaluating it with an anonymous job application dataset on LinkedIn. The effectiveness of the latent preference model was demonstrated in both offline experiments and online A/B testings. The user latent preference model helps to improve the VPI (views per impression) and API (applications per impression) significantly which in turn achieves a higher user satisfaction.", "references": ["G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender systems handbook, pages 217--253. Springer, 2011.", "L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In Context-aware Recommender Systems Workshop at RecSys09. ACM, 2009.", "M. Beal. Variational algorithms for approximate Bayesian inference. PhD thesis, University of London, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741126"}, {"title": "E-commerce Recommendation with Personalized Promotion", "authors": ["Qi Zhao\n,", "Yi Zhang\n,", "Daniel Friedman\n,", "Fangfang Tan"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMost existing e-commerce recommender systems aim to recommend the right products to a consumer, assuming the properties of each product are fixed. However, some properties, including price discount, can be personalized to respond to each consumer's preference. This paper studies how to automatically set the price discount when recommending a product, in light of the fact that the price will often alter a consumer's purchase decision. The key to optimizing the discount is to predict consumer's willingness-to-pay (WTP), namely, the highest price a consumer is willing to pay for a product. Purchase data used by traditional e-commerce recommender systems provide points below or above the decision boundary. In this paper we collected training data to better predict the decision boundary. We implement a new e-commerce mechanism adapted from laboratory lottery and auction experiments that elicit a rational customer's exact WTP for a small subset of products, and use a machine learning algorithm to predict the customer's WTP for other products. The mechanism is implemented on our own e-commerce website that leverages Amazon's data and subjects recruited via Mechanical Turk. The experimental results suggest that this approach can help predict WTP, and boost consumer satisfaction as well as seller profit.", "references": ["J. Abrams. A new method for testing pricing decisions. The Journal of Marketing, pages 6--9, 1964.", "G. M. Allenby, N. Arora, and J. L. Ginter. Incorporating prior knowledge into the analysis of conjoint studies. Journal of Marketing Research, pages 152--162, 1995.", "G. M. Allenby, N. Arora, and J. L. Ginter. On the heterogeneity of demand. Journal of Marketing Research, pages 384--389, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800178"}, {"title": "Perception-based interactive sound synthesis of morphing solids' interactions", "authors": ["Laurent Pruvost\n,", "Bertrand Scherrer\n,", "Mitsuko Aramaki\n,", "Sølvi Ystad\n,", "Richard Kronland-Martinet"], "publication": "SA '15: SIGGRAPH Asia 2015 Technical Briefs", "abstract": "ABSTRACT\nThis brief introduces a novel framework for the interactive and real-time synthesis of solids' interaction sounds driven by a game engine. The sound synthesizer used in this work relies on an action-object paradigm, itself based on the notion of perceptual invariants. An intuitive control strategy, based on those invariants and inspired by physics, was developed. The action and the object can be controlled independently, simultaneously, and continuously. This allows the synthesis of sounds for solids' interactions whose nature evolves continuously over time (e.g. from rolling to slipping) and/or where the objects' properties (shape, size and material) vary continuously in time.", "references": ["Aramaki, M., Gondre, C., Kronland-Martinet, R., Voinier, T., and Ystad, S. 2010. Imagine the sounds: An intuitive control of an impact sound synthesizer. In Auditory Display, S. Ystad, M. Aramaki, R. Kronland-Martinet, and K. Jensen, Eds., vol. 5954 of Lecture Notes in Computer Science. Springer Berlin Heidelberg, 408--421.", "Aramaki, M., Besson, M., Kronland-Martinet, R., and Ystad, S. 2011. Controlling the Perceived Material in an Impact Sound Synthesizer. IEEE Transactions on Audio, Speech and Language Processing 19, 2 (February), 301--314.", "Chadwick, J. N., An, S. S., and James, D. L. 2009. Harmonic shells: A practical nonlinear sound model for near-rigid thin shells. In ACM Transaction on Graphics (SIGGRAPH ASIA Conference Proceedings)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820903.2820914"}, {"title": "LRP: A Theory of Link Formation in Directed Networks", "authors": ["Dawei Liu\n,", "Yuanna Lv\n,", "Zhihua Yu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nUnderstanding the link patterns of networks is important for many tasks in link mining such as link prediction, friend recommendation, community detection and network evolution models. Recently, more and more models based on directed networks are present to formulate the underlying networks in various applications. However, most existing studies of link analysis are focused only in the undirected settings. In this paper, a theory of link formation named as Local Relative Position Theory (LRP) is proposed by analyzing the local structures to reveal the microscopic organizing principles of directed networks. Then a corresponding link prediction algorithm is proposed combing with existing microscopic mechanisms. Extensive experiments were applied on real world directed networks and the results testified the effectiveness of our link formation theory.", "references": ["L. Getoor and C. P. Diehl. 2005. Link Mining: A Survey. ACM SIGKDD Explorations Newsletter, 7, 2 (December 2005), 3--12. DOI=http://dx.doi.org/10.1145/1117454.1117456.", "QM Zhang, LY Lv, WQ Wang, YX Zhu and T. Zhou. 2013. Potential Theory for Directed Networks. PLoS ONE. 8(2): e55437.", "L. M. Aiello, A. Barrat, R. Schifanella, C. Cattuto, B. Markines and F. Menczer. 2012. Friendship Prediction and Homophily in Social Media. ACM Transactions on the Web, 6, 2 (May, 2012). DOI=http://dx.doi.org/10.1145/2180861.2180866."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818918"}, {"title": "Spectral Subtraction using Modified Cascaded Median based Noise Estimation for Speech Enhancement", "authors": ["Bittu Kumar"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nA modified version of the cascaded median based noise estimation for speech enhancement using spectral subtraction has been proposed. The proposed method involves less storage as compared to the original cascaded median based method reported earlier. In this method, the connection of median block is in cascaded but operation of that blocks are different from original cascaded median based method. Here, single median is calculated for each frame from samples of noisy spectra. It is simulated on MATLAB with 16 kHz sampling frequency, half-overlapped hamming window and tested through Perceptual Evaluation of Speech Quality (PESQ) measure. The perceptual speech quality gets improved with the proposed method and at the same time, simulation time is marginally less than the cascaded median based method.", "references": ["S. F. Boll, \"Suppression of acoustic noise in speech using spectral subtraction\", IEEE Trans. on Acoust. Speech & Signal Processing, Vol. ASSP-27, April 1979, 113--120.", "Amol Chaudhari, S. B. Dhonde, \"A review on speech enhancement techniques\", IEEE, International Conference on Pervasive Computing (ICPC), Vadgaon, Pune, Maharashatra (India), 2015.", "Chung-Chien Hsu, Tse-En Lin, Jian-Hueng Chen, Tai-Shih Chi, \"Spectro-Temporal Subband Wiener Filter for Speech Enhancement\", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Kyoto, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818608"}, {"title": "Defining and Evaluating Video Hyperlinking for Navigating Multimedia Archives", "authors": ["Roeland J.F. Ordelman\n,", "Maria Eskevich\n,", "Robin Aly\n,", "Benoit Huet\n,", "Gareth Jones"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMultimedia hyperlinking is an emerging research topic in the context of digital libraries and (cultural heritage) archives. We have been studying the concept of video-to-video hyperlinking from a video search perspective in the context of the MediaEval evaluation benchmark for several years. Our task considers a use case of exploring large quantities of video content via an automatically created hyperlink structure at the media fragment level. In this paper we report on our findings, examine the features of the definition of video hyperlinking based on results, and discuss lessons learned with respect to evaluation of hyperlinking in real-life use scenarios.", "references": ["R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Div ersifying search results. In WSDM '09: Proceedings of the Second ACM International Conference on Web Search and, pages 5--14, New York, NY, USA, 2009. ACM.", "R. Aly, K. McGuinness, M. Kleppe, R. Ordelman, N. E. O'Connor, and F. de Jong. Link anchors in images: Is there truth? In Proceedings of the 12th Dutch Belgian Information Retrieval Workshop (DIR 2012), pages 1--4, Ghent, 2012. University Ghent.", "R. Aly, R. Ordelman, M. Eskevich, G. F. Jones, and S. Chen. Linking inside a video collection -- what and how to measure? In Proceedings of the 22nd International Conference on World Wide Web Companion, IW3C2 2013, Rio de Janeiro, Brazil, pages 457--460, Brazil, May 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742915"}, {"title": "Active learning in keyword search-based data integration", "authors": ["Zhepeng Yan\n,", "Nan Zheng\n,", "Zachary G. Ives\n,", "Partha Pratim Talukdar\n,", "Cong Yu"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe problem of scaling up data integration, such that new sources can be quickly utilized as they are discovered, remains elusive: Global schemas for integrated data are difficult to develop and expand, and schema and record matching techniques are limited by the fact that data and metadata are often under-specified and must be disambiguated by data experts. One promising approach is to avoid using a global schema, and instead to develop keyword search-based data integration--where the system lazily discovers associations enabling it to join together matches to keywords, and return ranked results. The user is expected to understand the data domain and provide feedback about answers' quality. The system generalizes such feedback to learn how to correctly integrate data. A major open challenge is that under this model, the user only sees and offers feedback on a few \"top-$$k$$k\" results: This result set must be carefully selected to include answers of high relevance and answers that are highly informative when feedback is given on them. Existing systems merely focus on predicting relevance, by composing the scores of various schema and record matching algorithms. In this paper, we show how to predict the uncertainty associated with a query result's score, as well as how informative feedback is on a given result. We build upon these foundations to develop an active learning approach to keyword search-based data integration, and we validate the effectiveness of our solution over real data from several very different domains.", "references": ["Agrawal, S., Chaudhuri, S., Das, G.: DBXplorer: A system for keyword-based search over relational databases. In: ICDE (2002)", "Arasu, A., Götz, M., Kaushik, R.: On active learning of record matching packages. In: SIGMOD Conference, pp. 783---794 (2010)", "Auer, S., Bizer, C., Kobilarov, G., Lehmann, J., Cyganiak, R., Ives, Z.G.: DBpedia: A nucleus for a web of open data. In: ISWC/ASWC (2007)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-014-0374-x"}, {"title": "Beyond \"Hitting the Hits\": Generating Coherent Music Playlist Continuations with the Right Tracks", "authors": ["Dietmar Jannach\n,", "Lukas Lerche\n,", "Iman Kamehkhosh"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAutomated playlist generation is a special form of music recommendation and a common feature of digital music playing applications. A particular challenge of the task is that the recommended items should not only match the general listener's preference but should also be coherent with the most recently played tracks. In this work, we propose a novel algorithmic approach and optimization scheme to generate playlist continuations that address these requirements. In our approach, we first use collections of shared music playlists, music metadata, and user preferences to select suitable tracks with high accuracy. Next, we apply a generic re-ranking optimization scheme to generate playlist continuations that match the characteristics of the last played tracks. An empirical evaluation on three collections of shared playlists shows that the combination of different input signals helps to achieve high accuracy during track selection and that the re-ranking technique can both help to balance different quality optimization goals and to further increase accuracy.", "references": ["G. Adomavicius and Y. Kwon. Improving aggregate recommendation diversity using ranking-based techniques. IEEE TKDE, 24(5):896--911, 2012.", "W. Balkema and F. van der Heijden. Music Playlist Generation by Assimilating GMMs into SOMs. Pattern Recognition Letters, 31(11):1396--1402, 2010.", "G. Bonnin and D. Jannach. Evaluating the Quality of Playlists Based on Hand-Crafted Samples. In Proc. ISMIR, pages 263--268, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800182"}, {"title": "Improving MapReduce-based Entity-resolution by Data-load Balancing", "authors": ["Ming-Yen Lin\n,", "Tien-Jing Wang\n,", "Sue-Chen Hsueh"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nEntity resolution (ER) is to identify the entities referring to the same entity in the dataset. The nature of pairwise similarity computation from ER combined with growth of data size today leads to utilization of distributed computing such as MapReduce. The blocking techniques reduce the number of comparisons in ER. However, single blocking key suffers from incomplete results but multiple blocking keys may introduce duplicated comparisons. The issues of duplicated matching and data-load balancing have not been fully studied. In this paper, we propose a data-load balanced MapReduce algorithm for entity resolution using multiple keys. Our experiments using two real datasets show that the proposed algorithm is both efficient and effective.", "references": ["Halbert L. Dunn, \"Record Linkage,\" American Journal of Public Health, pp. 1412--1416, Dec. 1946.", "Mauricio A. Hernández and Salvatore J. Stolfo, \"The Merge/Purge Problem for Large Databases,\" in Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data, San Jose, California, USA, 1995, pp. 127--138.", "Peter M. Mell and Timothy Grance, \"The NIST Definition of Cloud,\" 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818886"}, {"title": "Rating quality in metadata harvesting", "authors": ["Sarantos Kapidakis"], "publication": "PETRA '15: Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nThe quality of the data and metadata affects the interoperability of the collections and the quality of all processing. Our metadata quality metric helps the metadata harvester collection administrators detecting and improving the weaknesses of their metadata, and harvesters locating the most problematic collections, in terms of metadata quality, and prompt their administrators to improve their metadata. We extended and used an adaptive quantitative metadata quality metric and a tool to implement it. In controlled values, their value distribution is considered, and in free text values the length of their description. Moreover, we also consider additional information in the OAI-PMH XML responces, that is not normally mapped in metadata elements, but still contains metadata information, such as XML attributes. We used the tool to make quality observations, to examine collections for patterns and irregularities and to produce the appropriate advice for the collection administrators. Some of these observations are demonstrated here. We compared the reported quality over a 3-year period, to get a general quantitative and qualitative feeling of the diversity in the record descriptions, and the changes in their quality during their lifetime. We verified the assumption that the quality increases over time: usually by a tiny amount, in every collection, and by a lot on a small number of collections. Also, the lower quality collections are the ones that stop responding and vanish.", "references": ["Beall, J., \"Metadata and data quality problems in the digital library,\" (2005) Journal of Digital Information, vol. 6 No. 3.", "Bui, Y. & Park, J., \"An assessment of metadata quality: a case study of the National Science Digital Library Metadata Repository,\" (2005) In Haidar Moukdad (Ed.) CAIS/ACSI 2006 Information Science Revisited: Approaches to Innovation. Proceedings of the 2005 annual conference of the Canadian Association for Information Science held with the Congress of the Social Sciences and Humanities of Canada at York University, Toronto, Ontario.", "Daas, P. J. H. & Ossen, S. J. L., \"Metadata quality evaluation of secondary data sources,\" (2011) International Journal for Quality Research, vol. 5, pp.57--66."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2769493.2769512"}, {"title": "To lock, swap, or elide: on the interplay of hardware transactional memory and lock-free indexing", "authors": ["Darko Makreshanski\n,", "Justin Levandoski\n,", "Ryan Stutsman"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe release of hardware transactional memory (HTM) in commodity CPUs has major implications on the design and implementation of main-memory databases, especially on the architecture of high-performance lock-free indexing methods at the core of several of these systems. This paper studies the interplay of HTM and lock-free indexing methods. First, we evaluate whether HTM will obviate the need for crafty lock-free index designs by integrating it in a traditional B-tree architecture. HTM performs well for simple data sets with small fixed-length keys and payloads, but its benefits disappear for more complex scenarios (e.g., larger variable-length keys and payloads), making it unattractive as a general solution for achieving high performance. Second, we explore fundamental differences between HTM-based and lock-free B-tree designs. While lock-freedom entails design complexity and extra mechanism, it has performance advantages in several scenarios, especially high-contention cases where readers proceed uncontested (whereas HTM aborts readers). Finally, we explore the use of HTM as a method to simplify lock-free design. We find that using HTM to implement a multi-word compare-and-swap greatly reduces lock-free programming complexity at the cost of only a 10-15% performance degradation. Our study uses two state-of-the-art index implementations: a memory-optimized B-tree extended with HTM to provide multi-threaded concurrency and the Bw-tree lock-free B-tree used in several Microsoft production environments.", "references": ["M. Abadi, T. Harris, and M. Mehrara. Transactional Memory with Strong Atomicity Using Off-the-shelf Memory Protection Hardware. In PPoPP, pages 185--196, 2009.", "J. H. Anderson and M. Moir. Universal Constructions for Multi-Object Operations. In PODC, pages 184--193, 1995.", "C. Blundell, E. C. Lewis, and M. M. Martin. Subtleties of Transactional Memory Atomicity Semantics. IEEE Comput. Archit. Lett., 5(2):--, Feb 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809990"}, {"title": "Retrieval of Relevant Opinion Sentences for New Products", "authors": ["Dae Hoon Park\n,", "Hyun Duk Kim\n,", "ChengXiang Zhai\n,", "Lifan Guo"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWith the rapid development of Internet and E-commerce, abundant product reviews have been written by consumers who bought the products. These reviews are very useful for consumers to optimize their purchasing decisions. However, since the reviews are all written by consumers who have bought and used a product, there are generally very few or even no reviews available for a new product or an unpopular product. We study the novel problem of retrieving relevant opinion sentences from the reviews of other products using specifications of a new or unpopular product as query. Our key idea is to leverage product specifications to assess product similarity between the query product and other products and extract relevant opinion sentences from the similar products where a consumer may find useful discussions. Then, we provide ranked opinion sentences for the query product that has no user-generated reviews. We first propose a popular summarization method and its modified version to solve the problem. Then, we propose our novel probabilistic methods. Experiment results show that the proposed methods can effectively retrieve useful opinion sentences for products that have no reviews.", "references": ["A. Berger and J. Lafferty. Information retrieval as statistical translation. In Proceedings of ACM SIGIR 1999, pages 222--229, 1999.", "I. Bhattacharya, S. Godbole, and S. Joshi. Structured entity identification and document categorization: two tasks with one joint model. In Proceedings of ACM KDD 2008, pages 25--33, 2008.", "C. Dellarocas, X. M. Zhang, and N. F. Awad. Exploring the value of online product reviews in forecasting sales: The case of motion pictures. Journal of Interactive marketing, 21(4):23--45, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767748"}, {"title": "Phase registration improves classification and clustering of cycles based on self-organizing maps", "authors": ["Juan-Carlos Quintana-Duque\n,", "Dietmar Saupe"], "publication": "iWOAR '15: Proceedings of the 2nd international Workshop on Sensor-based Activity Recognition and Interaction", "abstract": "ABSTRACT\nSelf-Organizing Maps (SOMs), also known as Self-Organizing Feature Maps, have been used to reduce the complexity of joint kinematic and kinetic data in order to cluster, classify and visualize cyclic motion data. In this paper we describe the results after training SOMs with preprocessed data based on phase registration by dynamic time warping. For validation, we recorded acceleration data of human locomotion varying the treadmill slope, activity (i.e., walking, jogging, running), and whether or not 1.5 kg weights were attached to the ankles. The topological quality of the SOMs after training improved when the phase registration was applied. Furthermore, test (i.e., combination of treadmill slope and type of gait) and subject classification improved, in particular for walking data, when the phase registration was applied for each individual activity. Activity classification improved when the phase registration was calculated from all cycles of our experiments together.", "references": ["Barton, G., Lees, A., Lisboa, P., and Attfield, S. Visualisation of gait data with Kohonen self-organising neural maps. Gait & Posture 24, 1 (2006), 46--53.", "Begg, R., and Kamruzzaman, J. A comparison of neural networks and support vector machines for recognizing young-old gait patterns. In TENCON, vol. 1 (2003), 354--358.", "Cappellini, G., Ivanenko, Y. P., Poppele, R. E., and Lacquaniti, F. Motor patterns in human walking and running. Journal of Neurophysiology 95, 6 (2006), 3426--3437."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790044.2790053"}, {"title": "Use case study of HDD-SSD hybrid storage, distributed storage and HDD storage on OpenStack", "authors": ["Yoji Yamato"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nFor typical IaaS cloud usage, frequent provisioning of virtual volumes is needed. However, performance of HDD storage is not sufficient and becomes bottleneck in IaaS cloud. In this paper, we studied a comparison of HDD-SSD hybrid storage, distributed storage and normal HDD storage as block storage of OpenStack Cinder and evaluated applicability of these 3 types storage to IaaS cloud. Hybrid storage can show much higher performances than HDD storage and is suitable for analysis applications, and distributed storage performance degradation is lower than HDD storage when concurrent processing number is increased and is suitable for archive or file services.", "references": ["OpenStack web site, http://www.openstack.org/", "Y. Yamato, N. Shigematsu and N. Miura, \"Evaluation of Agile Software Development Method for Carrier Cloud Service Platform Development,\" IEICE Transactions on Information and Systems, Vol.E97-D, No.11, pp.2959-2962, Nov. 2014.", "Y. Yamato, \"Automatic verification technology of software patches for user virtual environments on IaaS cloud,\" Springer Journal of Cloud Computing 2015, 4:4, DOI: 10.1186/s13677-015-0028-6, Feb. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790795"}, {"title": "A Study of Priors for Relevance-Based Language Modelling of Recommender Systems", "authors": ["Daniel Valcarce\n,", "Javier Parapar\n,", "Alvaro Barreiro"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nProbabilistic modelling of recommender systems naturally introduces the concept of prior probability into the recommendation task. Relevance-Based Language Models, a principled probabilistic query expansion technique in Information Retrieval, has been recently adapted to the item recommendation task with success. In this paper, we study the effect of the item and user prior probabilities under that framework. We adapt two priors from the document retrieval field and then we propose other two new probabilistic priors. Evidence gathered from experimentation indicates that a linear prior for the neighbour and a probabilistic prior based on Dirichlet smoothing for the items improve the quality of the item recommendation ranking.", "references": ["A. Bellogın, P. Castells, and I. Cantador. Precision-Oriented Evaluation of Recommender Systems. In RecSys '11, page 333, Oct. 2011.", "A. Bellogın, J. Parapar, and P. Castells. Probabilistic Collaborative Filtering with Negative Cross Entropy. In RecSys '13, pages 387--390, 2013.", "R. Blanco and A. Barreiro. Probabilistic Document Length Priors for Language Models. In ECIR '08, pages 394--405, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799677"}, {"title": "Multilingual Word Sense Induction to Improve Web Search Result Clustering", "authors": ["Lorenzo Albano\n,", "Domenico Beneventano\n,", "Sonia Bergamaschi"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn [Marco2013] a novel approach to Web search result clustering based on Word Sense Induction, i.e. the automatic discovery of word senses from raw text was presented; key to the proposed approach is the idea of, first, automatically inducing senses for the target query and, second, clustering the search results based on their semantic similarity to the word senses induced. In [1] we proposed an innovative Word Sense Induction method based on multilingual data; key to our approach was the idea that a multilingual context representation, where the context of the words is expanded by considering its translations in different languages, may improve the WSI results; the experiments showed a clear performance gain. In this paper we give some preliminary ideas to exploit our multilingual Word Sense Induction method to Web search result clustering.", "references": ["L. Albano, D. Beneventano, and S. Bergamaschi. Word sense induction with multilingual features representation. In Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2014 IEEE/WIC/ACM International Joint Conferences on, volume 2, pages 343--349. IEEE, 2014.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. Dbpedia: A nucleus for a web of open data. Springer, 2007.", "D. Beneventano, S. Bergamaschi, and S. Sorrentino. Extending wordnet with compound nouns for semi-automatic annotation in data integration systems. In Natural Language Processing and Knowledge Engineering, 2009. NLP-KE 2009. International Conference on, pages 1--8, Sept 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743009"}, {"title": "Location-Aware Model for News Events in Social Media", "authors": ["Mauricio Quezada\n,", "Vanessa Peña-Araya\n,", "Barbara Poblete"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNowadays, social media services are being used extensively as news sources and for spreading information on real-world events. Several studies have focused on detecting those events and locating them geographically. However, in order to study real-world events, for example, finding relationships between locations or detecting high impact events based on their coverage, we need more suitable models to represent events. In this work we propose a simple model to represent real-world news events using two sources of information: the locations that are mentioned in the event (where the event occurs), and the locations of users that discuss or comment on it. We then characterize a country based on the amount of events in which that country is mentioned and also participates on the event. We show some applications of the model: we find clusters of news events based on the level of participation of countries, identifying global and impactful events in certain areas. Also, we show groups of similar countries, finding promising insights about their relationships. This model can be useful at finding unsuspected relations among countries based on the news coverage and country participation, identifying different levels of news coverage in the world, and finding bias in international news sources.", "references": ["H. Abdelhaq, C. Sengstock, and M. Gertz. EvenTweet: Online Localized Event Detection from Twitter. Proceedings of the VLDB Endowment, 6(12):1326--1329, Aug. 2013.", "T. Inc. Twitter Developers. https://dev.twitter.com/. Accessed: 2015-01--30.", "K. Y. Kamath, J. Caverlee, K. Lee, and Z. Cheng. Spatio-temporal Dynamics of Online Memes: A Study of Geo-tagged Tweets. In Proceedings of the 22Nd International Conference on World Wide Web, WWW '13, pages 667--678, Republic and Canton of Geneva, Switzerland, 2013. International World Wide Web Conferences Steering Committee."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767815"}, {"title": "How to improve the space utilization of dedup-based PCM storage devices?", "authors": ["Chun-Ta Lin\n,", "Yuan-Hao Chang\n,", "Tei-Wei Kuo\n,", "Hung-Sheng Chang\n,", "Hsiang-Pang Li"], "publication": "CODES '15: Proceedings of the 10th International Conference on Hardware/Software Codesign and System Synthesis", "abstract": "ABSTRACT\nThere is a growing demand to introduce more and more intelligence to storage devices in recent years, especially with the rapid increasing of hardware computing power. This paper targets on essential design issues in space utilization for dedup-based non-volatile phase-change memory (PCM). We explore the adoption of data duplication techniques to reduce potential data duplicates over PCM storage devices to provide more storage space than the physical storage space does. Among various data deduplication techniques, variable-sized chunking is considered in less cost-effective PCM-based storage devices because variable-sized chunking has better data deduplication capability than fixed-sized chunking. However, in a typical system architecture, data are written or updated in the fixed management units (e.g., LBAs). Thus, to ultimately improve the space utilization of PCM-based storage device, the technical problem falls on (1) how to map fixed-sized LBAs to variable-sized chunks and (2) how to efficiently manage (i.e., allocated and deallocate) free PCM storage space for variable-sized chunks. In this work, we propose a free space manager, called container-based space manager, to resolve the above two issues by exploiting the fact that (1) a storage system initially has more free space to relax the complexity on space management and (2) the space optimization of a storage system can grow with the time when it contains more and more data. The proposed design is evaluated over popular benchmarks, for which we have very encouraging results.", "references": ["AgigA Tech. Bulletproof Memory for RAID Servers, Part 3, 2009.", "W. J. Bolosky, S. Corbin, D. Goebel, and J. R. Douceur. Single instance storage in windows 2000. In Proceedings of the 4th USENIX Windows Systems Symposium, pages 13--24. Seattle, WA, 2000.", "F. Chen, T. Luo, and X. Zhang. Caftl: A content-aware flash translation layer enhancing the lifespan of flash memory based solid state drives. In Proceedings of the 9th USENIX Conference on File and Stroage Technologies, FAST'11, pages 6--6, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2830840.2830842"}, {"title": "Examining Personalization in Academic Web Search", "authors": ["Sara Salehi\n,", "Jia Tina Du\n,", "Helen Ashman"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nPersonalization promises to improve the accuracy of Web search and has been drawing much research attention recently. Some evidence indicates that for educational purposes, the disadvantages of personalized search are not justified by its benefits. The potential issues with search personalization, especially in an educational context, include loss of serendipity and capability, commercialization of education and the \"Filter Bubble\" effect where users are denied information if search engine algorithms decide it is irrelevant to them. The majority of students in higher education make use of general-purpose search engines to find academic information, however we have little knowledge about the effects of personalization on learners' experience and achievements. This observation motivates the research in this paper. First, we surveyed 120 university students to investigate which research sources, including search engines they predominately use and how much they depend on each for educational purposes. We learned that the majority of students prefer Google to other search engines; indeed sometimes it is their primary or only information-seeking tool. Additionally, about 80% of them use search engines for educational purposes on daily basis. Second, we measured the difference between personalized and non-personalized search results for 120 academic search queries divided equally into four categories: Education, IT, Health sciences and Business. Our results showed that on average only 53% of links appear, not necessarily in the same order, in both personalized and non-personalized search results. Interestingly, we observed only slight differences in the extent of personalization based on academic topics.", "references": ["Ashman, H. Brailsford, T and Brusilovsky, P. 2009. Personal Services: Debating the Wisdom of Personalisation. In Proceedings of the 8th International Conference on Advances in Web Based Learning (Aachen, Germany, August 19-21, 2009). Springer-Verlag Berlin, Heidelberg, 1--11.", "Ashman, H. Brailsford, T. Cristea, A.I. Sheng, Q.Z. Stewart, C. Toms, E.G. and Wade, V. 2014. The Ethical and Social Implications of Personalization Technologies for e-learning. Inf. Manage. 51 (Sep. 2014), 819--832.", "Broder, A. 2002. A Taxonomy of Web Search. ACM SIGIR Forum. 36 (Fall 2002), 3--10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791039"}, {"title": "Exploiting Collective Hidden Structures in Webpage Titles for Open Domain Entity Extraction", "authors": ["Wei Song\n,", "Shiqi Zhao\n,", "Chao Zhang\n,", "Hua Wu\n,", "Haifeng Wang\n,", "Lizhen Liu\n,", "Hanshi Wang"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe present a novel method for open domain named entity extraction by exploiting the collective hidden structures in webpage titles. Our method uncovers the hidden textual structures shared by sets of webpage titles based on generalized URL patterns and a multiple sequence alignment technique. The highlights of our method include: 1) The boundaries of entities can be identified automatically in a collective way without any manually designed pattern, seed or class name. 2) The connections between entities are also discovered naturally based on the hidden structures, which makes it easy to incorporate distant or weak supervision. The experiments show that our method can harvest large scale of open domain entities with high precision. A large ratio of the extracted entities are long-tailed and complex and cover diverse topics. Given the extracted entities and their connections, we further show the effectiveness of our method in a weakly supervised setting. Our method can produce better domain specific entities in both precision and recall compared with the state-of-the-art approaches.", "references": ["A. Arasu and H. Garcia-Molina. Extracting structured data from web pages. In SIGMOD 2003, pages 337--348. ACM, 2003.", "M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction for the web. In IJCAI, volume 7, pages 2670--2676, 2007.", "R. Barzilay and L. Lee. Bootstrapping lexical choice via multiple-sequence alignment. In EMNLP 2002, pages 164--171. Association for Computational Linguistics, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741107"}, {"title": "Accessibility in Electronic Government: a study on the implementation of web standads in sites gov.br", "authors": ["Alberto Dumont Alves Oliveira\n,", "Marcelo Medeiros Eler"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn Brazil, the use of e-government is a relatively new. It first started in 2000, and since then, the web platform, through the web sites, has been widely used to strengthen the relationship with the Brazilian citizen, to provide services and to enhance transparency and access to information. Among the main patterns of e-government, the e-MAG and e-PWG models stand out. The first model is responsible for digital accessibility guidelines, and the second model is a set of technical guidelines for the development of sites and managing digital content. The Brazilian government is also implementing, since 2013, the Government Digital Identity, a project that aims to standardize the navigation logic and the structure of government sites from the federal level. This article aims to show that key government sites, despite all efforts, still do not implement the standards set by the Brazilian Electronic Government properly. We used code validators to evaluate and to analyze thirty-nine sites related to the ministries of the federal government. During our analysis, we found errors that compromise the access to digital information guaranteed by specific legislation to any Brazilian citizen.", "references": ["Caldwell, Ben. Diretrizes De Acessibilidade Para Conteúdo Web (WCAG) 2.0. Disponível em: ¿http://www.w3.org/TranslationsAVCAG20-pt-PT¿. Acesso em: 20 fev. 2015.", "Castells, Manuel. A Internet. In A Sociedade Em Rede. Paz e Terra, São Paulo, 2011.", "DaSilva. DaSilva, O Primeiro Avaliador De Acessibilidade Em Português. Disponivel em: ¿http://www.dasilva.org.br/¿. Acesso em: 23 fev. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814166"}, {"title": "Sentential query rewriting via mutual reinforcement of paraphrase-coordinate relationships", "authors": ["Meng Zhao\n,", "Hiroaki Ohshima\n,", "Katsumi Tanaka"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThe effectiveness of retrieval decreases with the increase in query length. We target at sentential queries and propose a method for improving their retrieval performance, called query rewriting. Briefly, given a sentential query, our method acquires paraphrases from the noisy Web and uses them to avoid returning no answers. In particular, since a relation can be represented either intensionally (referred to as paraphrase templates) or extensionally (referred to as coordinate tuples), the mutual reinforcement between them are taken into account. The experimental results show that for declarative sentences, the average precision of our method is 68.1%, compared to 44.2% of the baseline. Besides, the relative recall of our method is 95.9%, nearly 3 times compared to that of the baseline. While for questions, the average precision of our method is 46.9%, compared to 39.9% of the baseline. We also show the effectiveness of query rewriting in two applications.", "references": ["Google Received 72 Percent of U.S. Searches in January 2009. http://image.exct.net/lib/fefc1774726706/d/1/SearchEngines_Jan09.pdf.", "E. Agichtein and L. Gravano. Snowball: Extracting relations from large plain-text collections. In Proceedings of DL, pages 85--94, 2000.", "N. Balasubramanian, G. Kumaran, and V. R. Carvalho. Exploring reductions for long web queries. In Proceedings of SIGIR, pages 571--578, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837222"}, {"title": "Entropy based content filtering for Mobile Web Page Adaptation", "authors": ["Neetu Narwal\n,", "Sanjay Kumar Sharma\n,", "Amit Prakash Singh"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nA global increase in the usage of mobile devices and the availability of internet services on the phone has increased the usage of internet on these devices. However, these devices face a major challenge of limited screen space, less bandwidth and processing capability. A majority of the website are designed to be viewed on PCs, Desktop etc. Hence mobile Internet user finds it difficult to browse the web page. In this paper we present an approach to filter the informative web page content and rearrange it on the available screen space of mobile device. In this process the web page is segmented into visual blocks and then the entropy measure of each visual block is computed in terms of content entropy and feature entropy. The model is trained using neural network classifier to segregate main content and noise content.", "references": ["Web Article, 2015. Research Analysis: global mobile statistics.(Jan 2015) DOI= http://mobiforge.com/research-analysis/global-mobile-statistics-2014-part-a-mobile-subscribers-handset-market-share-mobile-operators#subscribers.", "Shian-Hua Lin, Jan-Ming Ho, 2002. Discovering Informative Content Blocks from Web Documents, Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining Pages 588--593. DOI= http://dl.acm.org/citation.cfm?id=775134", "Yan Liu, Qiang Wang, Qing Xian Wang, Yao Liu, and Liang Wei, 2006. An Adaptive Scoring Method for Block Importance Learning, Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence Pages 761--764. DOI= http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4061468"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791470"}, {"title": "A Method to Identify Variability in Knowledge Intensive Processes", "authors": ["Anderson S. do Nascimento\n,", "Flavia Maria Santoro\n,", "Jose Ricardo Cereja"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nOne of the most important features of an Knowledge Intensive Process (KIP) is the variability: different activities can be performed by certain factors, i.e., certain behaviors lead to different directions at runtime. Despite the variability to be a key point in PIC, the various existing proposals in the literature are not treated satisfactorily aspects of reasons why the behavior of processes to be modified. This article aims to present the KIP-Organon method, designed to identify the elements that can cause variability in Knowledge Intensive Processes.", "references": ["Abecker, A. 2001. Workflow-Embedded Organizational Memory Access: The DECOR Project. Knowtech.", "Anastassiu, M., 2012. Um método para identificação de elementos contextuais que impactam em processos de negócio. Departamento de Informática Aplicada (DIA), Universidade Federal do Estado do Rio de Janeiro (UNIRIO), Rio de Janeiro, RJ, BR.", "Azevedo, L.G., Baiao, F., Revoredo, J., Pereira, V., Herlain, I. 2009. Identificação de serviços a partir da modelagem de processos de negócio. Simpósio Brasileiro de Sistemas de Informação, Brasília."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814175"}, {"title": "Semantically aware time evolution tracking of communities in co-authorship networks", "authors": ["Dionisios N. Sotiropoulos\n,", "Demitrios E. Pournarakis\n,", "George M. Giaglis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nThis is paper addresses the problem of tracking the time evolution of communities within co-authorship networks. We consider an evolutionary clustering approach which adapts the statistical framework of shrinkage estimation to obtain a smoothed version of the overall affinity matrix as the optimal weighted average between the matrices of past and current affinities. Moreover, the current affinity matrix at each time step is formed as the optimal mixing between the raw structural relationships between authors coupled with the semantic similarity of their published works, captured by performing LDA-based topic modeling on the corresponding corpora of abstracts. The proposed parametric weighting scheme is simultaneously optimized on a real co-authorship dataset emerging from the network of participants in the ICMB conferences, held from 2002 to 2013. Finally, community detection at each time step is conducted by employing spectral clustering on the estimated overall weight matrix. The obtained results justify that our approach provides a clearer revelation of the inherent authors' communities dynamics when compared against incremental cluster formations that rely exclusively on the structural information of the co-authorship network.", "references": ["A.-L. Barabasi, H. Jeong, Z. NÃl'da, E. Ravasz, A. Schubert, and T. Vicsek. Evolution of the social network of scientific collaborations. arXiv preprint cond-mat/0104162, 2001.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "D. Chakrabarti, R. Kumar, and A. Tomkins. Evolutionary clustering. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 554--560. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802008"}, {"title": "Textual Analysis for Studying Chinese Historical Documents and Literary Novels", "authors": ["Chao-Lin Liu\n,", "Guan-Tao Jin\n,", "Hongsu Wang\n,", "Qing-Feng Liu\n,", "Wen-Huei Cheng\n,", "Wei-Yun Chiu\n,", "Richard Tzong-Han Tsai\n,", "Yu-Chun Wang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nWe analyzed historical and literary documents in Chinese to gain insights into research issues, and overview our studies which utilized four different sources of text materials in this paper. We investigated the history of concepts and transliterated words in China with the Database for the Study of Modern China Thought and Literature, which contains historical documents about China between 1830 and 1930. We also attempted to disambiguate names that were shared by multiple government officers who served between 618 and 1912 and were recorded in Chinese local gazetteers (地方志 /di4 fang1 zhi4/). To showcase the potentials and challenges of computer-assisted analysis of Chinese literatures, we explored some interesting yet non-trivial questions about two of the Four Great Classical Novels of China: (1) Which monsters attempted to consume the Buddhist monk Xuanzang in the Journey to the West (西遊記 /xi1 you2 ji4/, JTTW), which was published in the 16th century, (2) Which was the most powerful monster in JTTW, and (3) Which major role smiled the most in the Dream of the Red Chamber (紅樓夢 /hong2 lou2 meng4/), which was published in the 18th century. Similar approaches can be applied to the analysis and study of modern documents, such as the newspaper articles published about the 228 incident that occurred in 1947 in Taiwan.", "references": ["P. K. Bol, an unpublished report on name disambiguation, Harvard University.", "C.-Y. Chan and N.-X. Wang, \"Isms\" of the digital humanities, in New Approaches to Historical Studies, J. Hsiang, Ed. Taipei: National Taiwan University, 2014, pp. 219--245. (in Chinese)", "W.-Y. Chiu, G-T. Jin, Q.-F. Liu, and C.-L. Liu, A digital humanities research about the transition of modern China conception: The concept \"Equality\" as an example, in Proceedings of the Fourth International Conference of Digial Archives and Digital Humanities, pp. 329--373, 2012. (in Chinese)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818912"}, {"title": "Time Pressure in Information Search", "authors": ["Anita Crescenzi"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe primary purpose of this research is to explore the impact of perceived time pressure on search behaviors, searcher perceptions of the search system and the search experience. Are there observable behavioral changes when a searcher is time-pressured? To what extent are search behavior differences attributable to objective experimental manipulation versus to the subjective experience of time pressure? An important secondary purpose of this work is to identify appropriate outcome measures that allow for the comparison of session-level search behaviors when time is manipulated.", "references": ["I. Arapakis, X. Bai, and B. B. Cambazoglu. Impact of response latency on user behavior in web search. In Proc. of the 37th ACM SIGIR conference, pages 103--112, 2014.", "P. Borlund, S. Dreier, and K. Byström. What does time spent on searching indicate? In Proc. of the 4th IIiX Symposium, pages 184--193, 2012.", "A. Crescenzi, D. Kelly, and L. Azzopardi. Time pressure and system delays in information search. In Proc. of the 38th ACM SIGIR conference, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767851"}, {"title": "EmotiveModeler", "authors": ["Philippa Mothersill\n,", "V. Michael Bove"], "publication": "Interactions", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830315"}, {"title": "Learning User Preferences for Topically Similar Documents", "authors": ["Mustafa Zengin\n,", "Ben Carterette"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSimilarity measures have been used widely in information retrieval research. Most research has been done on query-document or document-document similarity without much attention to the user's perception of similarity in the context of the information need. In this study, we collect user preference judgements of web document similarity in order to investigate: (1) the correlation between similarity measures and users' perception of similarity, (2) the correlation between the web document features plus document-query features and users' similarity judgements. We analyze the performance of various similarity methods at predicting user preferences, in both unsupervised and supervised settings. We show that a supervised approach using many features is able to predict user preferences close to the level of agreement between users, and moreover achieve a 15% improvement in AUC over an unsupervised approach.", "references": ["B. Carterette, P. N. Bennett, D. M. Chickering, and S. T. Dumais. Here or there: preference judgments for relevance In Proceedings of the ECIR, pages 16--27, 2008", "M. E. Rorvig. The simple scalability of documents. JASIS, 41(8):590--598, 1990", "Michael D. Lee and Matthew Welsh. An empirical evaluation of models of text document similarity. In CogSci2005, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806617"}, {"title": "Automatic Extraction of Figures from Scholarly Documents", "authors": ["Sagnik Ray Choudhury\n,", "Prasenjit Mitra\n,", "Clyde Lee Giles"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nScholarly papers (journal and conference papers, technical reports, etc.) usually contain multiple ``figures'' such as plots, flow charts and other images which are generated manually to symbolically represent and illustrate visually important concepts, findings and results. These figures can be analyzed for automated data extraction or semantic analysis. Surprisingly, large scale automated extraction of such figures from PDF documents has received little attention. Here we discuss the challenges of how to build a heuristic independent trainable model for such an extraction task and how to extract figures at scale. Motivated by recent developments in table extraction, we define three new evaluation metrics: figure-precision, figure-recall, and figure-F1-score. Our dataset consists of a sample of 200 PDFs, randomly collected from five million scholarly PDFs and manually tagged for 180 figure locations. Initial results from our work demonstrate an accuracy greater than 80%.", "references": ["D. S. Bloomberg. Multiresolution morphological approach to document image analysis. In Proc. of the International Conference on Document Analysis and Recognition, Saint-Malo, France, 1991.", "W. Browuer, S. Kataria, S. Das, P. Mitra, and C. L. Giles. Segregating and extracting overlapping data points in two-dimensional plots. In Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries, JCDL '08, pages 276--279, New York, NY, USA, 2008. ACM.", "S. S. Bukhari, F. Shafait, and T. M. Breuel. Improved document image segmentation algorithm using multiresolution morphology. In IS&T/SPIE Electronic Imaging, pages 78740D--78740D. International Society for Optics and Photonics, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2797085"}, {"title": "Trajectory similarity measures", "authors": ["Kevin Toohey\n,", "Matt Duckham"], "publication": "SIGSPATIAL Special", "abstract": "Abstract\nStoring, querying, and analyzing trajectories is becoming increasingly important, as the availability and volumes of trajectory data increases. One important class of trajectory analysis is computing trajectory similarity. This paper introduces and compares four of the most common measures of trajectory similarity: longest common subsequence (LCSS), Fréchet distance, dynamic time warping (DTW), and edit distance. These four measures have been implemented in a new open source R package, freely available on CRAN [19]. The paper highlights some of the differences between these four similarity measures, using real trajectory data, in addition to indicating some of the important emerging applications for measurement of trajectory similarity.", "references": ["H. Alt and M. Godau. Computing the Fréchet distance between two polygonal curves. International Journal of Computational Geometry and Applications, 5(01n02):75--91, 1995.", "D. Berndt and J. Clifford. Using dynamic time warping to find patterns in time series. In KDD workshop, volume 10, pages 359--370. Seattle, WA, 1994.", "K. Buchin, M. Buchin, J. Gudmundsson, M. Löffler, and J. Luo. Detecting commuting patterns by clustering subtrajectories. In S.-H. Hong, H. Nagamochi, and T. Fukunaga, editors, Algorithms and Computation, volume 5369 of Lecture Notes in Computer Science, pages 644--655. Springer, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2782759.2782767"}, {"title": "Geographic information extraction, disambiguation and ranking techniques", "authors": ["Yisleidy Linares Zaila\n,", "Danilo Montesi"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nAn important part of textual information around the world contains some kind of geographic features. User queries with geographic references are becoming very common and human expectations from a search engine are even higher. Although several works have been focused on this area, the interpretation of the geographic information in order to better satisfy the user needs continues being a challenge. This work proposes different techniques which are involved in the process of identifying and analyzing the geographic information in textual documents and queries in natural languages. A geographic ontology GeoNW has been built by combining GeoNames, WordNet and Wikipedia resources. Based on the information stored in GeoNW, geographic terms are identified and an algorithm for solving the toponym disambiguation problem is proposed. Once the geographic information is processed, we obtain a geographic ranking list of documents which is combined with a standard textual ranking list of documents for producing the final results. GeoCLEF test collection is used for evaluating the accuracy of the result.", "references": ["A. I. Abdelmoty, P. D. Smart, C. B. Jones, G. Fu, and D. Finch. A critical evaluation of ontology languages for geographic information retrieval on the internet. In Journal of Visual Languages and Computing, volume 16, pages 331--358. Elsevier, 2005.", "M. Boehm, B. Schlegel, P. B. Volk, U. Fischer, D. Habich, and W. Lehner. Efficient in-memory indexing with generalized prefix trees. In BTW, volume 180, pages 227--246, 2011.", "D. Buscaldi. Approaches to disambiguating toponyms. SIGSPATIAL Special, 3(2):16--19, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837695"}, {"title": "Interactive Spaces: Models and Algorithms for Reality-based Music Applications", "authors": ["Marcella Mandanici"], "publication": "ITS '15: Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces", "abstract": "ABSTRACT\nReality-based interfaces have the property of linking the user's physical space with the computer digital content, bringing in intuition, plasticity and expressiveness. Moreover, applications designed upon motion and gesture tracking technologies involve a lot of psychological features, like space cognition and implicit knowledge. All these elements are the background of three presented music applications, employing the characteristics of three different interactive spaces: a user centered three dimensional space, a floor bi-dimensional camera space, and a small sensor centered three dimensional space. The basic idea is to deploy the application's spatial properties in order to convey some musical knowledge, allowing the users to act inside the designed space and to learn through it in an enactive way.", "references": ["1. Brower, C. A cognitive theory of musical meaning. Journal of Music Theory (2000), 323--379.", "2. Bruner, J. S. The act of discovery. Harvard educational review (1961).", "3. Engelbart, D. C. Augmenting human intellect: a conceptual framework (1962). Packer, Randall and Jordan, Ken. Multimedia. From Wagner to Virtual Reality. New York: WW Norton & Company (2001), 64--90."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2817721.2820986"}, {"title": "Speeding up Document Ranking with Rank-based Features", "authors": ["Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Raffaele Perego\n,", "Nicola Tonellotto"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLearning to Rank (LtR) is an effective machine learning methodology for inducing high-quality document ranking functions. Given a query and a candidate set of documents, where query-document pairs are represented by feature vectors, a machine-learned function is used to reorder this set. In this paper we propose a new family of rank-based features, which extend the original feature vector associated with each query-document pair. Indeed, since they are derived as a function of the query-document pair and the full set of candidate documents to score, rank-based features provide additional information to better rank documents and return the most relevant ones. We report a comprehensive evaluation showing that rank-based features allow us to achieve the desired effectiveness with ranking models being up to 3.5 times smaller than models not using them, with a scoring time reduction up to 70%.", "references": ["N. Asadi and J. Lin. Training efficient tree-based models for document ranking. In Proc. ECIR, pages 146--157, 2013.", "N. Asadi, J. Lin, and A. P. de Vries. Runtime optimizations for prediction with tree-based models. IEEE TKDE, 99:1, 2013.", "C. J. Burges, K. M. Svore, P. N. Bennett, A. Pastusiak, and Q. Wu. Learning to rank using an ensemble of lambda-gradient models. Journal of Machine Learning, 14:25--35, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767776"}, {"title": "Rank-GeoFM: A Ranking based Geographical Factorization Method for Point of Interest Recommendation", "authors": ["Xutao Li\n,", "Gao Cong\n,", "Xiao-Li Li\n,", "Tuan-Anh Nguyen Pham\n,", "Shonali Krishnaswamy"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWith the rapid growth of location-based social networks, Point of Interest (POI) recommendation has become an important research problem. However, the scarcity of the check-in data, a type of implicit feedback data, poses a severe challenge for existing POI recommendation methods. Moreover, different types of context information about POIs are available and how to leverage them becomes another challenge. In this paper, we propose a ranking based geographical factorization method, called Rank-GeoFM, for POI recommendation, which addresses the two challenges. In the proposed model, we consider that the check-in frequency characterizes users' visiting preference and learn the factorization by ranking the POIs correctly. In our model, POIs both with and without check-ins will contribute to learning the ranking and thus the data sparsity problem can be alleviated. In addition, our model can easily incorporate different types of context information, such as the geographical influence and temporal influence. We propose a stochastic gradient descent based algorithm to learn the factorization. Experiments on publicly available datasets under both user-POI setting and user-time-POI setting have been conducted to test the effectiveness of the proposed method. Experimental results under both settings show that the proposed method outperforms the state-of-the-art methods significantly in terms of recommendation accuracy.", "references": ["J. Bao, Y. Zheng, D. Wilkie, and M. F. Mokbel. A survey on recommendations in location-based social networks. GeoInformatica, 2014.", "R. M. Bell and Y. Koren. Lessons from the Netflix prize challenge. ACM SIGKDD Explorations Newsletter, 9(2):75--79, 2007.", "C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. In AAAI, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767722"}, {"title": "A Case Study on the Usage of the Value Blueprint for Ecosystem Design", "authors": ["Luciana A. Almeida\n,", "Cleidson R. B. de Souza\n,", "Adailton M. Lima\n,", "Rodrigo Reis"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nEcosystems are an important aspect of today's software business. Different companies aim to create an ecosystem around their products so that they can benefit from this. Unfortunately, creating such ecosystems is not an easy task. One of the few tools that can be used to facilitate this process is Adner's Value Blueprint. This tool allows a company to identify the different types of risks that it faces during the establishment of an ecosystem. Adner presents several examples of blueprints he has built and provides some guidelines to create new ones. Given the potential of the approach in addressing some of the issues faced by ecosystem designers, we decided to assess the usage of the Value Blueprint through a case study using data from the Apple Watch ecosystem. We report our results from the Apple ecosystem, and more importantly, our evaluation of the value blueprint tool. We conclude by providing recommendations for practitioners interested in establishing their own ecosystems and researchers interested in the design of ecosystems.", "references": ["Gawer, A., Cusumano, M.: Platform Leadership. Cambridge, MA: Harvard Business Review Press, p. 2. (2002).", "Moore, J.F.: Predators and Prey, A New Ecology of Competition. Harvard Business Review, May-June (1993) Available in: http://blogs.law.harvard.edu/jim/files/2010/04/Predators-and-Prey.pdf.", "Adner, R.: The Wide Lens - What Successful Innovators See That Others Miss Penguin Group (USA) Inc., 375 Hudson Street, New York, New York 10014, USA (2012)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814129"}, {"title": "Learning Features from Large-Scale, Noisy and Social Image-Tag Collection", "authors": ["Hanwang Zhang\n,", "Xindi Shang\n,", "Huanbo Luan\n,", "Yang Yang\n,", "Tat-Seng Chua"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nFeature representation for multimedia content is the key to the progress of many fundamental multimedia tasks. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application to domains where high-quality and large-scale training data are hard to obtain. In this paper, we propose a novel deep feature learning paradigm based on large, noisy and social image-tag collections, which can be acquired from the inexhaustible social multimedia content on the Web. Instead of learning features from high-quality image-label supervision, we propose to learn from the image-word semantic relations, in a way of seeking a unified image-word embedding space, where the pairwise feature similarities preserve the semantic relations in the original image-word pairs. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible for integrating into any state-of-the-art deep architectures. Experiments on NUSWIDE benchmark demonstrate that the features learned by our method significantly outperforms other state-of-the-art ones.", "references": ["T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In CIVR, 2009.", "J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, M. Mao, A. Senior, P. Tucker, K. Yang, Q. V. Le, et al. Large scale distributed deep networks. In NIPS, 2012.", "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806286"}, {"title": "Reducing Layered Database Applications to their Essence through Vertical Integration", "authors": ["Kristian F. D. Rietveld\n,", "Harry A. G. Wijshoff"], "publication": "ACM Transactions on Database Systems", "abstract": "Abstract\nIn the last decade, improvements on single-core performance of CPUs has stagnated. Consequently, methods for the development and optimization of software for these platforms have to be reconsidered. Software must be optimized such that the available single-core performance is exploited more effectively. This can be achieved by reducing the number of instructions that need to be executed. In this article, we show that layered database applications execute many redundant, nonessential, instructions that can be eliminated without affecting the course of execution and the output of the application. This elimination is performed using a vertical integration process which breaks down the different layers of layered database applications. By doing so, applications are being reduced to their essence, and as a consequence, transformations can be carried out that affect both the application code and the data access code which were not possible before. We show that this vertical integration process can be fully automated and, as such, be integrated in an operational workflow. Experimental evaluation of this approach shows that up to 95% of the instructions can be eliminated. The reduction of instructions leads to a more efficient use of the available hardware resources. This results in greatly improved performance of the application and a significant reduction in energy consumption.", "references": ["Frances E. Allen and John Cocke. 1976. A program data flow analysis procedure. Commun. ACM 19, 3 (March 1976), 137.", "John R. Allen. 1983. Dependence analysis for subscripted variables and its applications to program transformations. Ph.D. Dissertation, Rice University.", "Randy Allen and Ken Kennedy. 1987. Automatic translation of FORTRAN programs to vector form. ACM Trans. Program. Lang. Syst. 9, 4 (October 1987), 491--542."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818180"}, {"title": "High Quality Graph-Based Similarity Search", "authors": ["Weiren Yu\n,", "Julie Ann McCann"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSimRank is an influential link-based similarity measure that has been used in many fields of Web search and sociometry. The best-of-breed method by Kusumoto et. al., however, does not always deliver high-quality results, since it fails to accurately obtain its diagonal correction matrix D. Besides, SimRank is also limited by an unwanted \"connectivity trait\": increasing the number of paths between nodes a and b often incurs a decrease in score s(a,b). The best-known solution, SimRank++, cannot resolve this problem, since a revised score will be zero if a and b have no common in-neighbors. In this paper, we consider high-quality similarity search. Our scheme, SR#, is efficient and semantically meaningful: (1) We first formulate the exact D, and devise a \"varied-D\" method to accurately compute SimRank in linear memory. Moreover, by grouping computation, we also reduce the time of from quadratic to linear in the number of iterations. (2) We design a \"kernel-based\" model to improve the quality of SimRank, and circumvent the \"connectivity trait\" issue. (3) We give mathematical insights to the semantic difference between SimRank and its variant, and correct an argument: \"if D is replaced by a scaled identity matrix, top-K rankings will not be affected much\". The experiments confirm that SR# can accurately extract high-quality scores, and is much faster than the state-of-the-art competitors.", "references": ["I. Antonellis, H. G. Molina, and C. Chang. SimRank+: Query rewriting through link analysis of the click graph. PVLDB, 1(1), 2008.", "D. Fogaras and B. Rácz. Scaling link-based similarity search. In WWW, 2005.", "Y. Fujiwara, M. Nakatsuji, H. Shiokawa, and M. Onizuka. Efficient search algorithm for SimRank. In ICDE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767720"}, {"title": "InterFS: An Interplanted Distributed File System to Improve Storage Utilization", "authors": ["Peng Wang\n,", "Le Cao\n,", "Chunbo Lai\n,", "Leqi Zou\n,", "Guangyu Sun\n,", "Jason Cong"], "publication": "APSys '15: Proceedings of the 6th Asia-Pacific Workshop on Systems", "abstract": "ABSTRACT\nResource under-utilization is a common problem in modern data centers. Though researchers have proposed consolidation techniques to improve utilization of computing resources, there still lacks an approach to mitigate particularly low utilization of storage capacity in clusters for online services. A potential solution is to \"interplant\" a distributed storage system together with the services on these clusters to leverage the unused storage. However, avoiding performance interference with existing services is an essential prerequisite for interplanting. Thus, we propose InterFS, a POSIX-compliant distributed file system aiming at fully exploiting the storage resource on data center clusters. We adopt intelligent resource isolation, peak load dodging, and region-based replica placement schemes in InterFS. Therefore, it can be interplanted with other resource-intensive services without interfering with them, and amply fulfill the storage requirements of small-scale applications in the data center. Currently InterFS is deployed in 20,000+ servers at Baidu, providing 80 PB storage space to 200+ long-tailed services.", "references": ["GlusterFS. http://www.gluster.org/.", "Lustre. http://lustre.org/.", "MooseFS. http://www.moosefs.org/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797022.2797036"}, {"title": "A Framework of Knowledge Management as a Service over Cloud Computing Platform", "authors": ["Muhammad Al-Qurishi\n,", "Mabrook Al-Rakhami\n,", "Majed AlRubaian\n,", "Atif Alamri"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nThe significant growth in the use of technologies in all life domains created many hurdles that derailed many knowledge management projects. Cloud computing choices are commencement to untangle these obstacles. Linking Cloud computing with knowledge management (KM) is a challenging task. Small amount of researches have been conducted regarding cloud computing and knowledge management. In this paper, we proposed a framework of knowledge management as a Service (KMaaS) over cloud. Our framework consists of six components (KM Users, KM Domain Registration/content Integration, KM Service Directory, Cloud Manager, Resource Allocation Manager, and Monitoring and Payment). Accessing the different KM services from KM service directory will be easily at anytime, anywhere and from any device based on users' subscription to specific domain.", "references": ["Jin Chen, \"Framework of SOA-based equipment maintenance knowledge management system,\" Computer Science and Education (ICCSE), 2010 5th International Conference on, vol., no., pp.912,917, 24--27 Aug. 2010 doi: 10.1109/ICCSE.2010.5593463", "Pappas, N.; Kazasis, F. G.; Anestis, G.; Gioldasis, N.; Christodoulakis, S., \"A Knowledge Management Platform for Supporting Digital Business Ecosystems based on P2P and SOA technologies,\" Digital EcoSystems and Technologies Conference, 2007. DEST '07. Inaugural IEEEIES, vol., no., pp.196,202, 21--23 Feb. 2007 doi: 10.1109/DEST.2007.371970", "Pingchuan, Wen; Xianbo, Luo, \"The study of SOA-based Community Management Information System,\" E -Business and E -Government (ICEE), 2011 International Conference on, vol., no., pp.1,4, 6-8 May 2011 doi: 10.1109/ICEBEG.2011.5881888"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816908"}, {"title": "Poster: Extremely Parallel Resource Pre-Fetching for Energy Optimized Mobile Web Browsing", "authors": ["Mohammad A. Hoque\n,", "Sasu Tarkoma\n,", "Tuikku Anttila"], "publication": "MobiCom '15: Proceedings of the 21st Annual International Conference on Mobile Computing and Networking", "abstract": "ABSTRACT\nMobile web browsing is experienced slow because of the limited rendering capability of the mobile devices, wireless latency, and incremental rendering of the page or resource loading. The browser renders resources in between two consecutive resource downloads. However, during this period, the wireless interfaces consume energy doing nothing useful. In this work, we measure the performance of SPDY for mobile web browsing. We demonstrate that mobile devices waste energy by keeping the wireless network interface idle between consecutive resource downloads. We next show that by identifying the embedded resources in a web page and downloading those resources in parallel at the very beginning can reduce the small idle periods and thus energy consumption by 20-50%, depending on the wireless network type.", "references": ["J. Erman, V. Gopalakrishnan, R. Jana, and K. K. Ramakrishnan. Towards a spdy'ier mobile web? In Proceedings of the Ninth ACM Conference on Emerging Networking Experiments and Technologies, CoNEXT '13, pages 303--314, New York, NY, USA, 2013. ACM.", "Google and Chromium. Quick UDP Internet Connections. http://www.ietf.org/proceedings/88/slides/slides-88-tsvarea-10.pdf.", "Google and Chromium. Spdy: An experimental protocol for a faster web, white paper, June 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789168.2795167"}, {"title": "Conditional heavy hitters: detecting interesting correlations in data streams", "authors": ["Katsiaryna Mirylenka\n,", "Graham Cormode\n,", "Themis Palpanas\n,", "Divesh Srivastava"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nThe notion of heavy hitters--items that make up a large fraction of the population--has been successfully used in a variety of applications across sensor and RFID monitoring, network data analysis, event mining, and more. Yet this notion often fails to capture the semantics we desire when we observe data in the form of correlated pairs. Here, we are interested in items that are conditionally frequent: when a particular item is frequent within the context of its parent item. In this work, we introduce and formalize the notion of conditional heavy hitters to identify such items, with applications in network monitoring and Markov chain modeling. We explore the relationship between conditional heavy hitters and other related notions in the literature, and show analytically and experimentally the usefulness of our approach. We introduce several algorithm variations that allow us to efficiently find conditional heavy hitters for input data with very different characteristics, and provide analytical results for their performance. Finally, we perform experimental evaluations with several synthetic and real datasets to demonstrate the efficacy of our methods and to study the behavior of the proposed algorithms for different types of data.", "references": ["Agrawal, R., Imielinski, T., Swami, A.N.: Mining association rules between sets of items in large databases. In: ACM SIGMOD International Conference on Management of Data, pp. 207---216 (1993)", "Alon, N., Matias, Y., Szegedy, M.: The space complexity of approximating the frequency moments. In: ACM Symposium on Theory of Computing, pp. 20---29 (1996)", "Arasu, A., Manku, G.S.: Approximate counts and quantiles over sliding windows. In: Proceedings of the Twenty-Third ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, pp. 286---296. ACM (2004)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0382-5"}, {"title": "Retrieval of High Resolution Satellite Images Based on Steerable Pyramids", "authors": ["Bouteldja Samia\n,", "Kourgli Assia"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nIn this paper we propose a new rotation and scale invariant representation for high resolution satellite image retrieval based on Steerable Pyramid Decomposition. By calculating the statistical measures of decomposed image subbands, the texture feature vectors are extracted. To obtain rotation and scale invariance, the feature vectors are circularly shifted until obtaining the minimum possible distance. Experiments were conducted using 8 image classes from land-use/land-cover (LULC) UCMerced dataset. Results obtained are compared with color Gabor opponent texture features. Tests and evaluation measures demonstrate that the proposed technique gives a good performance in terms of high precision.", "references": ["Benjelil, M., Kanoun, S., Mullot, R., Alimi, A. M., 2009. \"Steerable pyramid based complex documents images segmentation\", 2009 10th International Conference on Document Analysis and Recognition.", "Chua, T. S., Tan, K.-L., and Ooi, B. C. 1997. \"Fast signature-based color-spatial image retrieval\", in Proc. IEEE Conf.on Multimedia Computing and Systems, 1997.", "Deepak, U., « content-based satellite cloud image retrieval »,thesis of the degree of Master of Science in Geo-information Science and Earth Observation. India 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816916"}, {"title": "Replicable Evaluation of Recommender Systems", "authors": ["Alan Said\n,", "Alejandro Bellogín"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender systems research is by and large based on comparisons of recommendation algorithms' predictive accuracies: the better the evaluation metrics (higher accuracy scores or lower predictive errors), the better the recommendation algorithm. Comparing the evaluation results of two recommendation approaches is however a difficult process as there are very many factors to be considered in the implementation of an algorithm, its evaluation, and how datasets are processed and prepared. This tutorial shows how to present evaluation results in a clear and concise manner, while ensuring that the results are comparable, replicable and unbiased. These insights are not limited to recommender systems research alone, but are also valid for experiments with other types of personalized interactions and contextual information access.", "references": ["Adamopoulos, P., Bellogın, A., Castells, P., Cremonesi, P., and Steck, H. REDD 2014 - international workshop on recommender systems evaluation: dimensions and design. In Eighth ACM Conference on Recommender Systems, RecSys '14, Foster City, Silicon Valley, CA, USA - October 06 - 10, 2014 (2014), pp. 393--394.", "Amatriain, X., Castells, P., de Vries, A. P., and Posse, C. Workshop on recommendation utility evaluation: beyond RMSE - RUE 2012. In Sixth ACM Conference on Recommender Systems, RecSys '12, Dublin, Ireland, September 9--13, 2012 (2012), pp. 351--352.", "Bellogın, A. Evaluating recommender systems:ensuring replicability of evaluation. http://ir.ii.uam.es/ alejandro/2014/ht.pdf, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2792841"}, {"title": "Querying RDF data with text annotated graphs", "authors": ["Lushan Han\n,", "Tim Finin\n,", "Anupam Joshi\n,", "Doreen Cheng"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nScientists and casual users need better ways to query RDF databases or Linked Open Data. Using the SPARQL query language requires not only mastering its syntax and semantics but also understanding the RDF data model, the ontology used, and URIs for entities of interest. Natural language query systems are a powerful approach, but current techniques are brittle in addressing the ambiguity and complexity of natural language and require expensive labor to supply the extensive domain knowledge they need. We introduce a compromise in which users give a graphical \"skeleton\" for a query and annotates it with freely chosen words, phrases and entity names. We describe a framework for interpreting these \"schema-agnostic queries\" over open domain RDF data that automatically translates them to SPARQL queries. The framework uses semantic textual similarity to find mapping candidates and uses statistical approaches to learn domain knowledge for disambiguation, thus avoiding expensive human efforts required by natural language interface systems. We demonstrate the feasibility of the approach with an implementation that performs well in an evaluation on DBpedia data.", "references": ["I. Androutsopoulos, G. Ritchie, and P. Thanisch. Natural language interfaces to databases -- an introduction. Natural Language Engineering, 1(01):29--81, 1995.", "S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. Ives. DBpedia: A Nucleus for a Web of Open Data. In 6th Int. Semantic Web Conf., pages 722--735. Springer, 2007.", "P. Auxerre and R. Inder. Masque modular answering system for queries in english - user's manual. Technical report, Artificial Intelligence Applications Institute, University of Edinburgh, 1986."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791381"}, {"title": "Challenges and Opportunities in Online Evaluation of Search Engines", "authors": ["Pavel Serdyukov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nYandex is one of the largest Internet companies in Europe, operating Russia's most popular search engine, generating 58.6\\% of all search traffic in Russia (as of April 2015). As all modern search engines, Yandex increasingly relies on online evaluation methods such as A/B tests and interleaving. These online evaluation methods test various changes in the search engine by analyzing the changes in the character of its interactions with its users. There are several grand challenges in online evaluation, including the choice of an appropriate online metric and the need to deal the limited number of user interactions available for a search engine for experimentation. In my talk, I will overview our latest research on improving the sensitivity of well-known online metrics, on discovery of more sensitive and robust online metrics, on scheduling and early stopping of online experiments.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776786"}, {"title": "Adding structured information to the ANVISA's \"Bulario Eletronico\"", "authors": ["Joao Vitor F. da Silva\n,", "Carlos N. Silla\n,", "Andre Y. Kashiwabara"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe Brazilian Ministry of Health and other related organizations are concerned with the issue of self-medication. Although these organizations warn about the risks of concomitantly using different drugs, they do not provide any tools to facilitate this process. ANVISA offers a collection of 6.076 medication guides in PDF file format. However, the information available in this guides are in an unstructured format. One of challenges of this work consisted in the automatic retrieval of information from ANVISAS's medication guides. This paper presents a semiautomatic procedure that maps ANVISAS's medication guides to DrugBank and SNOMEDCT. The medications, the diseases, the drugs, and their relations were structured and stored on a graph database using the Neo4j technology.", "references": ["R. M. d. A. B. J. e. A. d. P. O. A. R. Lamas, J. L. Filho. Ontologias e web services aplicados ao desenvolvimento de sistemas de informação geográfica móveis sensíveis ao contexto. Anais do V Simpósio Brasileiro de Sistemas de Informaçao (SBSI), pages p. 157-168, 2009.", "ANVISA. Resolução-rdc no 47, de 8 de setembro de 2009, 2009.", "S. H. D. B. Cassiani. A segurança do paciente e o paradoxo no uso de medicamentos. Rev Bras Enferm, 58(1):95-99, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814141"}, {"title": "Similarity Search over the Cloud Based on Image Descriptors' Dimensions Value Cardinalities", "authors": ["Stefanos Antaris\n,", "Dimitrios Rafailidis"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nIn recognition that in modern applications billions of images are stored into distributed databases in different logical or physical locations, we propose a similarity search strategy over the cloud based on the dimensions value cardinalities of image descriptors. Our strategy has low preprocessing requirements by dividing the computational cost of the preprocessing steps into several nodes over the cloud and locating the descriptors with similar dimensions value cardinalities logically close. New images are inserted into the distributed databases over the cloud efficiently, by supporting dynamical update in real-time. The proposed insertion algorithm has low computational complexity, depending exclusively on the dimensionality of descriptors and a small subset of descriptors with similar dimensions value cardinalities. Finally, an efficient query processing algorithm is proposed, where the dimensions of image descriptors are prioritized in the searching strategy, assuming that dimensions of high value cardinalities have more discriminative power than the dimensions of low ones. The computation effort of the query processing algorithm is divided into several nodes over the cloud infrastructure. In our experiments with seven publicly available datasets of image descriptors, we show that the proposed similarity search strategy outperforms competitive methods of single node, parallel and cloud-based architectures, in terms of preprocessing cost, search time and accuracy.", "references": ["M. Aly, M. Munich, and P. Perona. 2011. Distributed kd-trees for retrieval from very large image collections. In Proceedings of the British Machine Vision Conference (BMVC'11).", "A. Babenko and V. Lempitsky. 2012. The inverted multi-index. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 3069--3076.", "M. Batko, D. Novak, F. Falchi, and P. Zezula. 2008. Scalability comparison of peer-to-peer similarity search structures. Future Generation Computer Syst. 24, 8, 834--848."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2716315"}, {"title": "A Priori Relevance Based On Quality and Diversity Of Social Signals", "authors": ["Ismail Badache\n,", "Mohand Boughanem"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSocial signals (users' actions) associated with web resources (documents) can be considered as an additional information that can play a role to estimate a priori importance of the resource. In this paper, we are particularly interested in: first, showing the impact of signals diversity associated to a resource on information retrieval performance; second, studying the influence of their social networks origin on their quality. We propose to model these social features as prior that we integrate into language model. We evaluated the effectiveness of our approach on IMDb dataset containing 167438 resources and their social signals collected from several social networks. Our experimental results are statistically significant and show the interest of integrating signals diversity in the retrieval process.", "references": ["O. Alonso and V. Kandylas. A study on placement of social buttons in web pages. arXiv, 2014.", "A. Angel and N. Koudas. Efficient diversity-aware search. In SIGMOD, pages 781--792, 2011.", "I. Badache and M. Boughanem. Social priors to estimate relevance of a resource. In IIiX, pages 106--114, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767807"}, {"title": "How Well Sentence Embeddings Capture Meaning", "authors": ["Lyndon White\n,", "Roberto Togneri\n,", "Wei Liu\n,", "Mohammed Bennamoun"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nSeveral approaches for embedding a sentence into a vector space have been developed. However, it is unclear to what extent the sentence's position in the vector space reflects its semantic meaning, rather than other factors such as syntactic structure. Depending on the model used for the embeddings this will vary -- different models are suited for different down-stream applications. For applications such as machine translation and automated summarization, it is highly desirable to have semantic meaning encoded in the embedding. We consider this to be the quality of semantic localization for the model -- how well the sentences' meanings coincides with their embedding's position in vector space. Currently the semantic localization is assessed indirectly through practical benchmarks for specific applications.\nIn this paper, we ground the semantic localization problem through a semantic classification task. The task is to classify sentences according to their meaning. A SVM with a linear kernel is used to perform the classification using the sentence vectors as its input. The sentences from subsets of two corpora, the Microsoft Research Paraphrase corpus and the Opinosis corpus, were partitioned according to their semantic equivalence. These partitions give the target classes for the classification task. Several existing models, including URAE, PV--DM and PV--DBOW, were assessed against a bag of words benchmark.", "references": ["H. Borko and M. Bernick. Automatic document classification. Journal of the ACM (JACM), 10(2):151--162, 1963.", "R. Collobert and J. Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160--167. ACM, 2008.", "W. B. Dolan and C. Brockett. Automatically constructing a corpus of sentential paraphrases. In Third International Workshop on Paraphrasing (IWP2005). Asia Federation of Natural Language Processing, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838932"}, {"title": "Get off my internets: the audience commodity and the mommy blog backlash", "authors": ["Andrea Hunter"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nThis article uses Dallas Smythe's [54, 55] conception of the audience commodity, as well as more recent conceptions of the prosumer commodity [13, 14, 15] to examine the role of audiences in mommy blogging. The popularity of 'mommy' blogging has been built on the idea that these blogs are publishing honest and intimate account of women's lives. However, this paper argues that the move towards monetizing these blogs and the commodification of the audience is contributing to an online backlash. Using the site Get Off My Internets (GOMI) as a case study, this paper examines how blog readers are attuned to the fact that they are being commodified through these blogs, and are resistant to this move. At the same time, while GOMI exists as a place to critique what users see as the false sense of community and intimacy that mommy blogs are creating, they are in fact creating their own community that at times is a source of validation and mutual support for participants.", "references": ["Andrews, P. 2003. Is blogging journalism? Nieman Reports. 57, 3, 63--64.", "Armstrong, H. 2015. http://heatherbarmstrong. com/", "Belkin, L. 2011. Queen of the mommy bloggers. New York Times. http://www.nytimes.com/2011/02/27/magazine/27armstrongt.html?pagewanted=all&_r=0"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789192"}, {"title": "Big omics data experience", "authors": ["Patricia Kovatch\n,", "Anthony Costa\n,", "Zachary Giles\n,", "Eugene Fluder\n,", "Hyung Min Cho\n,", "Svetlana Mazurkova"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nAs personalized medicine becomes more integrated into healthcare, the rate at which human genomes are being sequenced is rising quickly together with a concomitant acceleration in compute and storage requirements. To achieve the most effective solution for genomic workloads without re-architecting the industry-standard software, we performed a rigorous analysis of usage statistics, benchmarks and available technologies to design a system for maximum throughput. We share our experiences designing a system optimized for the \"Genome Analysis ToolKit (GATK) Best Practices\" whole genome DNA and RNA pipeline based on an evaluation of compute, workload and I/O characteristics. The characteristics of genomic-based workloads are vastly different from those of traditional HPC workloads, requiring different configurations of the scheduler and the I/O subsystem to achieve reliability, performance and scalability. By understanding how our researchers and clinicians work, we were able to employ techniques not only to speed up their workflow yielding improved and repeatable performance, but also to make more efficient use of storage and compute resources.", "references": ["Fromer, M. et al. 2014. De novo mutations in schizophrenia implicate synaptic networks. Nature 506 (2014), 179--84.", "Purcell, S. et al. 2014. A polygenic burden of rare disruptive mutations in schizophrenia. Nature 506 (2014), 185--90.", "Gaugler, T. et al. 2014. Most genetic risk for autism resides with common variation. Nat. Genet. 46 (2014), 881--885."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807595"}, {"title": "A Two-step Approach to Cross-modal Hashing", "authors": ["Kaiye Wang\n,", "Wei Wang\n,", "Liang Wang\n,", "Ran He"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWith the rapid growth of multimedia data, it is very desirable to effectively and efficiently search objects of interest across different modalities from large scale databases. Cross-modal hashing provides a very promising way to address such problem. In this paper, we propose a two-step cross-modal hashing approach to obtain compact hash codes and learn hash functions from multimodal data. Our approach decomposes the cross-modal hashing problem into two steps: generating hash code and learning hash function. In the first step, we obtain the hash codes for all modalities of data via a joint multi-modal graph, which takes into consideration both the intra-modality and inter-modality similarity. In the second step, learning hashing function is formulated as a binary classification problem. We train binary classifiers to predict the hash code for any data object unseen before. Experimental results on two cross-modal datasets show the effectiveness of our proposed approach.", "references": ["M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, pages 3594--3601, 2010.", "T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, , and Y.-T. Zheng. NUS-WIDE: A real-world web image database from national university of singapore. In ACM International Conference on Image and Video Retrieval, 2009.", "R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification. JMLR, 9:1871--1874, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749297"}, {"title": "Opinion Spam Detection in Web Forum: A Real Case Study", "authors": ["Yu-Ren Chen\n,", "Hsin-Hsi Chen"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOpinion spamming refers to the illegal marketing practice which involves delivering commercially advantageous opinions as regular users. In this paper, we conduct a real case study based on a set of internal records of opinion spams leaked from a shady marketing campaign. We explore the characteristics of opinion spams and spammers in a web forum to obtain some insights, including subtlety property of opinion spams, spam post ratio, spammer accounts, first post and replies, submission time of posts, activeness of threads, and collusion among spammers. Then we present features that could be potentially helpful in detecting spam opinions in threads. The results of spam detection on first posts show: (1) spam first posts put more focus on certain topics such as the user experiences' on the promoted items, (2) spam first posts generally use more words and pictures to showcase the promoted items in an attempt to impress people, (3) spam first posts tend to be submitted during work time, and (4) the threads that spam first posts initiate are more active to be placed at striking positions. The spam detection on replies is more challenging. Besides lower spam ratio and less content, replies even do not mention the promoted items. Their major intention is to keep the discussion in a thread alive to attract more attention on it. Submission time of replies, thread activeness, position of replies, and spamicity of first post are more useful than content-based features in spam detection on replies.", "references": ["Enrico Blanzieri and Anton Bryl. A survey of learning-based techniques of email spam filtering. Artificial Intelligence Review, 29(1):63--92, 2008.", "Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1--27:27, 2011.", "Song Feng, Ritwik Banerjee, and Yejin Choi. Syntactic stylometry for deception detection. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 171--175. Association for Computational Linguistics, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741085"}, {"title": "Random walk on co-word network: ranking terms using structural features", "authors": ["Wanying Chiu\n,", "Kun Lu"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nThis study proposes a weighted random walk method on co-word networks to identify important themes of a field using structural features of the networks. The goal is to test whether the weighted random walk method can be used to produce meaningful results on co-word networks. In addition, we examined the relationships among the results from the random walk method and other two common metrics for identifying important themes in a field: frequency and point centrality. Using a dataset of 17K bibliographic records for the articles in the LIS field from the Web of Science, our results indicate that all three measures are significantly correlated. A detailed comparison of the top terms ranked by the three metrics from the years of 2002-2006 and 2007-2012 is provided. The results show that the three measures are generally similar in revealing hotspots and development of the field. However, some noticeable differences are also found. The random walk method boosted the rankings of some lower ranked terms in the other two metrics (e.g. \"universe\", \"servic\" and \"develop\") due to their co-occurrences with top ranked terms (e.g. \"information\"). The findings of this study help to understand the use of random walk method on co-word networks.", "references": ["Ahlgren, P., Jarneving, B., & Rousseau, R. (2003). Requirements for a cocitation similarity measure, with special reference to Pearson's correlation coefficient. Journal of the American Society for Information Science and Technology, 54(6), 550--560.", "Assefa, S. G., & Rorissa, A. (2013). A bibliometric mapping of the structure of STEM education using co-word analysis. Journal of the American Society for Information Science and Technology, 64(12), 2513--2536.", "Baldwin, C., Hughes, J., Hope, T., Jacoby, R., & Ziebland, S. (2003). Ethics and dementia: mapping the literature by bibliometric analysis. International Journal of Geriatric Psychiatry, 18(1), 41--54."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857098"}, {"title": "PPTLens: Create Digital Objects with Sketch Images", "authors": ["Changcheng Xiao\n,", "Changhu Wang\n,", "Liqing Zhang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this work, we introduce the PPTLens system to convert sketch images captured by smart phones to digital flowcharts in PowerPoint. Different from existing sketch recognition system, which is based on hand-drawn strokes, PPTLens enables users to use sketch images as inputs directly. It's more challenging since strokes extracted from sketch images might not only be very messy, but also without temporal information of the drawings. To implement the 'Image to Object' (I2O) scenario, we propose a novel sketch image recognition framework, including an effective stroke extraction strategy and a novel offline sketch parsing algorithm. By enabling sketch images as inputs, our system makes flowchart/diagram production much more convenient and easier.", "references": ["C. Carton, A. Lemaitre, and B. Couasnon. Fusion of statistical and structural information for flowchart recognition. In ICDAR, 2013.", "B. Epshtein, E. Ofek, and Y. Wexler. Detecting text in natural scenes with stroke width transform. CVPR, 2010.", "L. B. Kara and T. F. Stahovich. Hierarchical parsing and recognition of hand-sketched diagrams. UIST, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807974"}, {"title": "Modelling Term Dependence with Copulas", "authors": ["Carsten Eickhoff\n,", "Arjen P. de Vries\n,", "Thomas Hofmann"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany generative language and relevance models assume conditional independence between the likelihood of observing individual terms. This assumption is obviously naive, but also hard to replace or relax. There are only very few term pairs that actually show significant conditional dependencies while the vast majority of co-located terms has no implications on the document's topical nature or relevance towards a given topic. It is exactly this situation that we capture in a formal framework: A limited number of meaningful dependencies in a system of largely independent observations. Making use of the formal copula framework, we describe the strength of causal dependency in terms of a number of established term co-occurrence metrics. Our experiments based on the well known ClueWeb'12 corpus and TREC 2013 topics indicate significant performance gains in terms of retrieval performance when we formally account for the dependency structure underlying pieces of natural language text.", "references": ["Jing Bai, Dawei Song, Peter Bruza, Jian-Yun Nie, and Guihong Cao. Query expansion using term relationships in language models for information retrieval. In Proceedings of the 14th ACM international conference on Information and knowledge management, pages 688--695. ACM, 2005.", "Michael Bendersky and W Bruce Croft. Modeling higher-order term dependencies in information retrieval using query hypergraphs. In Proceedings of the 35th international ACM SIGIR conference, pages 941--950. ACM, 2012.", "Michael Bendersky, Donald Metzler, and W Bruce Croft. Learning concept importance using a weighted dependence model. In Proceedings of the third ACM international conference on Web search and data mining, pages 31--40. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767831"}, {"title": "Two Operators to Define and Manipulate Themes of a Document Collection", "authors": ["Emanuele Di Buccio\n,", "Massimo Melucci"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we propose the theme model, which will provide the end user with join and meet operators to define and manipulate themes. These operators have properties that cannot be reduced to the classical logic operators, thus allowing the researchers to model the informative content of documents in a novel way and to rank documents in ways other than those provided by the classical logic. To this end, we introduce the main definitions and properties of the theme model and we link the model to a number of related techniques, thus suggesting how the model can be implemented and applied.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "A. Caputo, B. Piwowarski, and M. Lalmas. A Query Algebra for Quantum Information Retrieval. In Proceedings of the IIR Workshop, 2011.", "C. Carpineto and G. Romano. A survey of automatic query expansion in information retrieval. ACM Computing Surveys, 44(1):1:1--1:50, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809482"}, {"title": "Large Video Event Ontology Browsing, Search and Tagging (EventNet Demo)", "authors": ["Hongliang Xu\n,", "Guangnan Ye\n,", "Yitong Li\n,", "Dong Liu\n,", "Shih-Fu Chang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this demo we present PITAGORA\\footnote{Demo video available at http://bit.ly/1GgtUrN}: a mobile web contextual social network designed for the check-in area of an airport. The app provides recommendation of potential friends, local experts and targeted services. Recommendation is hybrid and combines social media analysis and collaborative filtering techniques. Users' recommendation has been evaluated through a user study with good results.", "references": ["Z. Rubin. Disclosing oneself to a stranger: Reciprocity and its limits. Journal of Experimental Social Psychology, 11(3):233 -- 260, 1975.", "Y. Zheng, L. Zhang, X. Xie, and W.-Y. Ma. Mining correlation between locations using human location history. In Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS '09, pages 472--475, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807973"}, {"title": "MobiTop: bringing topic-based reflection to mobile browsing habits", "authors": ["Souneil Park\n,", "Jose San Pedro\n,", "Nuria Oliver"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nThe advancement in wireless Internet access and mobile devices has made online content consumption a spontaneous and habitual activity. Content browsing in mobile devices often starts without a clear purpose and continues for a long time. The browsing history in mobile devices is not merely a record of URL accesses but is becoming a comprehensive reflection of users due to the frequent usage of the phone, which is connected to user's interest and information needs. In this paper, we motivate the use of mobile browsing history as an important source for personal informatics systems and present MobiTop, a novel self-reflection tool for understanding the browsing habits.", "references": ["Blei, D. M., Ng, A. Y., and Jordan, M. I. \"Latent dirichlet allocation.\" the Journal of machine Learning research 3 (2003): 993--1022.", "Cavnar, W. B., and John M. Trenkle. \"N-gram-based text categorization.\"Ann Arbor MI 48113.2 (1994): 161--175.", "Carreras, Xavier, Isaac Chao, Lluis Padró, and Muntsa Padró. \"FreeLing: An Open-Source Suite of Language Analyzers.\" In Proc. of LREC. 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2800958"}, {"title": "LDP4ROs: Managing Research Objects with the W3C Linked Data Platform", "authors": ["Daniel Garijo\n,", "Nandana Mihindukulasooriya\n,", "Oscar Corcho"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this demo we present LDP4ROs, a prototype implementation that allows creating, browsing and updating Research Objects (ROs) and their contents using typical HTTP operations. This is achieved by aligning the RO model with the W3C Linked Data Platform (LDP).", "references": ["K. Belhajjame, O. Corcho, D. Garijo, J. Zhao, et al. Workflow-Centric Research Objects: First Class Citizens in Scholarly Discourse. In SePublica2012 workshop at ESWC2012, 2012.", "M. Esteban-Gutiérrez, N. Mihindukulasooriya, and R. García-Castro. LDP4j: A framework for the development of interoperable read-write Linked Data applications. In Proceedings of the 1st ISWC Developers Workshop, Riva del Garda, Italy, Oct 2014.", "S. Soiland-Reyes, D. Cruickshank, F. Bacall, J. Zhao, K. Belhajjame, D. D. Roure, and C. A. Goble. my Experiment Research Objects: Beyond Workflows and Packs. Technical report, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742016"}, {"title": "Session details: Session 1: Multimedia Indexing and Search", "authors": ["Heng Tao Shen"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3257792"}, {"title": "Learning Context-aware Latent Representations for Context-aware Collaborative Filtering", "authors": ["Xin Liu\n,", "Wei Wu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we propose a generic framework to learn context-aware latent representations for context-aware collaborative filtering. Contextual contents are combined via a function to produce the context influence factor, which is then combined with each latent factor to derive latent representations. We instantiate the generic framework using biased Matrix Factorization as the base model. A Stochastic Gradient Descent (SGD) based optimization procedure is developed to fit the model by jointly learning the weight of each context and latent factors. Experiments conducted over three real-world datasets demonstrate that our model significantly outperforms not only the base model but also the representative context-aware recommendation models.", "references": ["Gediminas Adomavicius, Ramesh Sankaranarayanan, Shahana Sen, and Alexander Tuzhilin. Incorporating contextual information in recommender systems using a multidimensional approach. ACM Trans. Inf. Syst., 23(1):103--145, 2005.", "Deepak Agarwal, Bee-Chung Chen, and Bo Long. Localized factor models for multi-context recommendation. In Proceedings of the 17th SIGKDD, 2011.", "Tianqi Chen, Hang Li, Qiang Yang, and Yong Yu. General functional matrix factorization using gradient boosting. In Proceedings of the 30th ICML, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767775"}, {"title": "Scaling Down Distributed Infrastructure on Wimpy Machines for Personal Web Archiving", "authors": ["Jimmy Lin"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWarcbase is an open-source platform for storing, managing, and analyzing web archives using modern \"big data\" infrastructure on commodity clusters---specifically, HBase for storage and Hadoop for data analytics. This paper describes an effort to scale \"down\" Warcbase onto a Raspberry Pi, an inexpensive single-board computer about the size of a deck of playing cards. Apart from an interesting technology demonstration, such a design presents new opportunities for personal web archiving, in enabling a low-cost, low-power, portable device that is able to continuously capture a user's web browsing history---not only the URLs of the pages that a user has visited, but the contents of those pages---and allowing the user to revisit any previously-encountered page, as it appeared at that time. Experiments show that data ingestion throughput and temporal browsing latency are adequate with existing hardware, which means that such capabilities are already feasible today.", "references": ["D. Abrams, R. Baecker, and M. Chignell. Information archiving with bookmarks: Personal web space construction and organization. CHI, 1998.", "A. Aiyer, M. Bautin, G. Chen, P. Khemani, K. Muthukkaruppan, K. Spiegelberg, L. Tang, and M. Vaidya. Storage infrastructure behind Facebook Messages:\\ Using HBase at scale. IEEE Data Engineering Bulletin, 35(2):4--13, 2012.", "D. G. Andersen, J. Franklin, M. Kaminsky, A. Phanishayee, L. Tan, and V. Vasudevan. FAWN: A Fast Array of Wimpy Nodes. SOSP, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741695"}, {"title": "Search-based design of large software systems-of-systems", "authors": ["Robert Lagerström\n,", "Pontus Johnson\n,", "Mathias Ekstedt"], "publication": "SESoS '15: Proceedings of the Third International Workshop on Software Engineering for Systems-of-Systems", "abstract": "ABSTRACT\nThis work in progress paper presents the foundation for an Automatic Designer of large software systems-of-systems. The core formalism for the Automatic Designer is UML. The Automatic Designer extends UML with a fitness function, which uses analysis of non-functional requirements, utility theory, and stakeholder requirements, as the basis for its design suggestions. This extension logic is formalized using an OCL-based Predictive, Probabilistic Architecture Modeling Framework (called P2AMF). A set of manipulation operators is used on the UML model in order to modify it. Then, from a component library (with OTS products), new components will be introduced to the design. Using operators, a search algorithm will look for an optimal solution.", "references": ["Keeney, Ralph L., and Howard Raiffa, Decisions with Multiple Objectives - Preferences and Value Trade-Offs, Cambridge University Press, 1993.", "Harman, Mark, and Bryan F. Jones, \"Search-based software engineering,\" Information and Software Technology, vol. 43, no. 14, pp. 833--839, 2001.", "Shaw, Mary, and David Garlan, Software Architecture - Perspectives on an Emerging Discipline, Prentice-Hall, 1996."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2821418.2821428"}, {"title": "Enhancing wifi-based localization with visual clues", "authors": ["Han Xu\n,", "Zheng Yang\n,", "Zimu Zhou\n,", "Longfei Shangguan\n,", "Ke Yi\n,", "Yunhao Liu"], "publication": "UbiComp '15: Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nIndoor localization is of great importance to a wide range of applications in the era of mobile computing. Current mainstream solutions rely on Received Signal Strength (RSS) of wireless signals as fingerprints to distinguish and infer locations. However, those methods suffer from fingerprint ambiguity that roots in multipath fading and temporal dynamics of wireless signals. Though pioneer efforts have resorted to motion-assisted or peer-assisted localization, they neither work in real time nor work without the help of peer users, which introduces extra costs and constraints, and thus degrades their practicality. To get over these limitations, we propose Argus, an image-assisted localization system for mobile devices. The basic idea of Argus is to extract geometric constraints from crowdsourced photos, and to reduce fingerprint ambiguity by mapping the constraints jointly against the fingerprint space. We devise techniques for photo selection, geometric constraint extraction, joint location estimation, and build a prototype that runs on commodity phones. Extensive experiments show that Argus triples the localization accuracy of classic RSS-based method, in time no longer than normal WiFi scanning, with negligible energy consumption.", "references": ["http://maps.google.com/help/maps/indoormaps/faqs.html. Accessed: 2014-11-25.", "Adib, F., Kumar, S., Aryan, O., Gollakota, S., and Katabi, D. Interference Alignment by Motion. In Proc. of ACM MobiCom (2013).", "Arkin, E. M., Chew, L. P., Huttenlocher, D. P., Kedem, K., and Mitchell, J. S. An Efficiently Computable Metric for Comparing Polygonal Shapes. IEEE Transactions on Pattern Analysis and Machine Intelligence 13, 3 (1991), 209--216."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750858.2807516"}, {"title": "A Priority Based Lookup Model for VoIP Applications in Unstructured P2P Networks", "authors": ["Mourad Amad\n,", "Djamil Aïssani\n,", "Ahmed Meddahi\n,", "Nouria Madi\n,", "Razika Bouiche"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nRegarding the shortcoming of fundamental existing solutions for VoIP (eg. SIP and H.323) such as centralization. Recently, both academia and industry have initiated research projects directed on integration of P2P-SIP paradigm into communication systems. P2P-SIP utilizes the advantages of an overlay network to provide SIP based services with high optimization and interoperability.\nIn this paper, we propose a new model for lookup optimization in P2P-SIP that takes into consideration the priority aspect of some particular requests. We use Gnutella as underlying P2P architecture representative of unstructured P2P networks and M/M/1 mathematical model as a queuing network. Performance evaluation of our proposition show that results are globally satisfactory.", "references": ["M. Amad and A. Meddahi. DV-Flood: An Optimized Flooding and Clustering based Approach for Lookup Acceleration in P2P networks. the International Wireless Communications and Mobile Computing Conference (IWCMC 2008), 2008.", "M. Amad, A. Meddahi, D. Aïssani, and Z. Zhang. HPM:A Novel Hierarchical Peer-To-Peer Model for Lookup Acceleration With Provision of Physical Proximity. Journal of Network and Computer Applications (JNCA), vol. 35:pp. 1818--1830, 2012.", "S. A. Baset and H. Schulzrinne. An analysis of the Skype Peer to Peer Internet telephony protocol. Technical report, Columbia university, September 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816924"}, {"title": "Location, Location, Location: The Impact of Geolocation on Web Search Personalization", "authors": ["Chloe Kliman-Silver\n,", "Aniko Hannak\n,", "David Lazer\n,", "Christo Wilson\n,", "Alan Mislove"], "publication": "IMC '15: Proceedings of the 2015 Internet Measurement Conference", "abstract": "ABSTRACT\nTo cope with the immense amount of content on the web, search engines often use complex algorithms to personalize search results for individual users. However, personalization of search results has led to worries about the Filter Bubble Effect, where the personalization algorithm decides that some useful information is irrelevant to the user, and thus prevents them from locating it. In this paper, we propose a novel methodology to explore the impact of location-based personalization on Google Search results. Assessing the relationship between location and personalization is crucial, since users' geolocation can be used as a proxy for other demographic traits, like race, income, educational attainment, and political affiliation. In other words, does location-based personalization trap users in geolocal Filter Bubbles?\nUsing our methodology, we collected 30 days of search results from Google Search in response to 240 different queries. By comparing search results gathered from 59 GPS coordinates around the US at three different granularities (county, state, and national), we are able to observe that differences in search results due to personalization grow as physical distance increases. However these differences are highly dependent on what a user searches for: queries for local establishments receive 4-5 different results per page, while more general terms exhibit essentially no personalization.", "references": ["Alexa Top 500 Global Sites. http://www.alexa.com/topsites.", "J. Burn-Murdoch. US web statistics released for May 2012: which sites dominate, and where do we go for online news? phThe Guardian, 2012.", "P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz. Inferring and Using Location Metadata to Personalize Web Search. phSIGIR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815675.2815714"}, {"title": "Behavior query discovery in system-generated temporal graphs", "authors": ["Bo Zong\n,", "Xusheng Xiao\n,", "Zhichun Li\n,", "Zhenyu Wu\n,", "Zhiyun Qian\n,", "Xifeng Yan\n,", "Ambuj K. Singh\n,", "Guofei Jiang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nComputer system monitoring generates huge amounts of logs that record the interaction of system entities. How to query such data to better understand system behaviors and identify potential system risks and malicious behaviors becomes a challenging task for system administrators due to the dynamics and heterogeneity of the data. System monitoring data are essentially heterogeneous temporal graphs with nodes being system entities and edges being their interactions over time. Given the complexity of such graphs, it becomes time-consuming for system administrators to manually formulate useful queries in order to examine abnormal activities, attacks, and vulnerabilities in computer systems.\nIn this work, we investigate how to query temporal graphs and treat query formulation as a discriminative temporal graph pattern mining problem. We introduce TGMiner to mine discriminative patterns from system logs, and these patterns can be taken as templates for building more complex queries. TGMiner leverages temporal information in graphs to prune graph patterns that share similar growth trend without compromising pattern quality. Experimental results on real system data show that TGMiner is 6-32 times faster than baseline methods. The discovered patterns were verified by system experts; they achieved high precision (97%) and recall (91%).", "references": ["Splunk. http://www.splunk.com/.", "Ssh brute force - the 10 year old attack that still persists. http://blog.sucuri.net/2013/07/.", "U. Bayer, I. Habibi, D. Balzarotti, E. Kirda, and C. Kruegel. A view on current malware behaviors. In LEET, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2856318.2856320"}, {"title": "Ranking Entities for Web Queries Through Text and Knowledge", "authors": ["Michael Schuhmacher\n,", "Laura Dietz\n,", "Simone Paolo Ponzetto"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhen humans explain complex topics, they naturally talk about involved entities, such as people, locations, or events. In this paper, we aim at automating this process by retrieving and ranking entities that are relevant to understand free-text web-style queries like Argentine British relations, which typically demand a set of heterogeneous entities with no specific target type like, for instance, Falklands_-War} or Margaret-_Thatcher, as answer. Standard approaches to entity retrieval rely purely on features from the knowledge base. We approach the problem from the opposite direction, namely by analyzing web documents that are found to be query-relevant. Our approach hinges on entity linking technology that identifies entity mentions and links them to a knowledge base like Wikipedia. We use a learning-to-rank approach and study different features that use documents, entity mentions, and knowledge base entities -- thus bridging document and entity retrieval. Since established benchmarks for this problem do not exist, we use TREC test collections for document ranking and collect custom relevance judgments for entities. Experiments on TREC Robust04 and TREC Web13/14 data show that: i) single entity features, like the frequency of occurrence within the top-ranke documents, or the query retrieval score against a knowledge base, perform generally well; ii) the best overall performance is achieved when combining different features that relate an entity to the query, its document mentions, and its knowledge base representation.", "references": ["N. Balasubramanian and S. Cucerzan. Beyond ranked lists in web search: Aggregating web content into topic pages. International Journal of Semantic Computing, 4(4):509--534, 2010.", "K. Balog, A. P. de Vries, P. Serdyukov, P. Thomas, and T. Westerveld. Overview of the TREC 2009 entity track. In Proc. of TREC-09, 2010.", "C. Biemann and M. Riedl. Text: Now in 2D! A framework for lexical expansion with contextual similarity. Journal of Language Modelling, 1:55--95, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806480"}, {"title": "Towards Understanding the Impact of Length in Web Search Result Summaries over a Speech-only Communication Channel", "authors": ["Johanne R. Trippas\n,", "Damiano Spina\n,", "Mark Sanderson\n,", "Lawrence Cavedon"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nPresenting search results over a speech-only communication channel involves a number of challenges for users due to cognitive limitations and the serial nature of speech. We investigated the impact of search result summary length in speech-based web search, and compared our results to a text baseline. Based on crowdsourced workers, we found that users preferred longer, more informative summaries for text presentation. For audio, user preferences depended on the style of query. For single-facet queries, shortened audio summaries were preferred, additionally users were found to judge relevance with a similar accuracy compared to text-based summaries. For multi-facet queries, user preferences were not as clear, suggesting that more sophisticated techniques are required to handle such queries.", "references": ["W. Albert, T. Tullis, and D. Tedesco. Beyond the Usability Lab: Conducting Large-Scale Online User Experience Studies. Morgan Kaufmann, 2009.", "S. Buchholz, J. Latorre, and K. Yanagisawa. Crowdsourced assessment of speech synthesis. Crowdsourcing for Speech Processing, pages 173--216, 2013.", "C. Callison-Burch and M. Dredze. Creating speech and language data with amazon's mechanical turk. In Proc. of NAACL HLT CSLDAMT'10 Workshop, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767826"}, {"title": "SmartGuide: Towards Single-image Building Localization with Smartphone", "authors": ["Xi Xiong\n,", "Zheng Yang\n,", "Longfei Shangguan\n,", "Yun Fei\n,", "Milos Stojmenovic\n,", "Yunhao Liu"], "publication": "MobiHoc '15: Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing", "abstract": "ABSTRACT\nWe introduce SmartGuide, a light-weighted and efficient approach to localize and recognize a distant unknown building. Our approach relies on shooting only a single photo of a target building via a smartphone and a local 2D Google map. SmartGuide first extracts a partial top view contour of a building from its side-view photo by applying vanishing point and the Manhattan World Assumption, and then fetches a candidate building set from a local 2D Google map based on smartphone's GPS readings. Partial top view shape, orientation and distance relative to the camera are used as input parameters in a probability model, which adversely recognizes the best candidate building in the local map. Our model is developed based on kernel density estimation that helps reduce noise in the smartphone sensors, such as GPS readings and camera ray direction reported by noisy accelerometer and compass. Experimental results demonstrate that our approach recognizes buildings ranging from 20m to 520m and achieves 92.7% accuracy in downtown areas where the Manhattan World Assumption is applicable. In addition, the processing time is no more than 6 seconds for 87% of cases. Compared with existing building localization schemes, SmartGuide offers numerous advantages. Our method avoids taking multiple photos, intricate 3D reconstruction or any initial deployment cost of database construction, making it faster and less labor-intensive than existing solutions.", "references": ["Developers Android. Opencv, 2014. http://opencv.org/platforms/android.html.", "Ionut Constandache, Xuan Bao, Martin Azizyan, and Romit Roy Choudhury. Did you see bob?: human localization using mobile phones. In Proceedings of the MobiCom 2010, pages 149--160, 2010.", "James M Coughlan and Alan L Yuille. Manhattan world: Compass direction from a single image by bayesian inference. In Proceedings of the ICCV 1999, volume 2, pages 941--947, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2746285.2746294"}, {"title": "An Approach to Manage Evaluations Using an Interactive Board Game: The Ludo Educational Atlantis", "authors": ["Thiago Jabur Bittar\n,", "Luanna Lopes Lobato\n,", "Leandro Agostini do Amaral\n,", "Elson Longo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe use of digital games for educational support can motivate students, but this use should be well exploited for pedagogical success, behaving as allies in the conventional process, addressing the concepts seen in the classroom. Thus, this paper presents considerations and results on the creation and testing of Ludo Educational Atlantis, which is an educational digital game system, in which students of elementary school can participate in an electronic board game. It challenges are presented in the form of questions and answers defined by a responsible teacher who can monitor the results of their students. For initial validation, the game was used in a State School of Sao Carlos-SP, in a Science discipline, being reported in this paper the considerations and results from this experience.", "references": ["Crawford, C. The Art of Digital Game Design, Washington State University, Vancouver, 1982.", "Lucchese, F., Ribeiro B. (2012). Conceituação de Jogos Digitais. Universidade Estadual de Campinas.", "McClarty, K. L.; Frey, P. M. e Dolan, R. P. A Literature Review of Gaming in Education Research Report. n. June, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814142"}, {"title": "Online News Tracking for Ad-Hoc Information Needs", "authors": ["Jeroen B.P. Vuurens\n,", "Arjen P. de Vries\n,", "Roi Blanco\n,", "Peter Mika"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nFollowing online news about a specific event can be a difficult task as new information is often scattered across web pages. In such cases, an up-to-date summary of the event would help to inform users and allow them to navigate to articles that are likely to contain relevant and novel details. We propose a three-step approach to online news tracking for ad-hoc information needs. First, we continuously cluster the titles of all incoming news articles. Then, we select the clusters that best fit a user's ad-hoc information need and identify salient sentences. Finally, we select sentences for the summary based on novelty and relevance to the information seen, without requiring an a-priori model of events of interest. We evaluate this approach using the 2013 TREC Temporal Summarization test set and show that compared to existing systems our approach retrieves news facts with significantly higher F-measure and Latency-Discounted Expected Gain.", "references": ["J. Abello and F. Queyroi. Fixed points of graph peeling. In Advances in Social Networks Analysis and Mining (ASONAM), 2013 IEEE/ACM International Conference on, pages 256--263. IEEE, 2013.", "C. C. Aggarwal and S. Y. Philip. On clustering massive text and categorical data streams. Knowledge and information systems, 24(2):171--196, 2010.", "J. Allan, R. Gupta, and V. Khandelwal. Temporal summaries of new topics. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 10--18. ACM, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809474"}, {"title": "Cache locality is not enough: high-performance nearest neighbor search with product quantization fast scan", "authors": ["Fabien André\n,", "Anne-Marie Kermarrec\n,", "Nicolas Le Scouarnec"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nNearest Neighbor (NN) search in high dimension is an important feature in many applications (e.g., image retrieval, multimedia databases). Product Quantization (PQ) is a widely used solution which offers high performance, i.e., low response time while preserving a high accuracy. PQ represents high-dimensional vectors (e.g., image descriptors) by compact codes. Hence, very large databases can be stored in memory, allowing NN queries without resorting to slow I/O operations. PQ computes distances to neighbors using cache-resident lookup tables, thus its performance remains limited by (i) the many cache accesses that the algorithm requires, and (ii) its inability to leverage SIMD instructions available on modern CPUs.\nIn this paper, we advocate that cache locality is not sufficient for efficiency. To address these limitations, we design a novel algorithm, PQ Fast Scan, that transforms the cache-resident lookup tables into small tables, sized to fit SIMD registers. This transformation allows (i) in-register lookups in place of cache accesses and (ii) an efficient SIMD implementation. PQ Fast Scan has the exact same accuracy as PQ, while having 4 to 6 times lower response time (e.g., for 25 million vectors, scan time is reduced from 74ms to 13ms).", "references": ["Intel® 64 and IA-32 Architectures Optimization Reference Manual, April 2012.", "Intel® 64 and IA-32 Architectures Software Developer's Manual, Volume 1: Basic Architecture, June 2015.", "D. J. Abadi, S. R. Madden, and M. C. Ferreira. Integrating Compression and Execution in Column-Oriented Database Systems. In SIGMOD, pages 671--682, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2856318.2856324"}, {"title": "Harnessing emergence: the control and design of emergent behavior in system of systems engineering", "authors": ["Saurabh Mittal\n,", "Larry Rainey"], "publication": "SummerSim '15: Proceedings of the Conference on Summer Computer Simulation", "abstract": "ABSTRACT\nAccording to Ashby, emergent behavior manifest itself due to a lack of understanding of the system. The problem while apparent in monolithic systems takes on center-stage in a system of system (SoS), components of which are geographically displaced and have independent managerial, evolutionary and operational controls. The emergent behavior in SoS manifests in-situ and lack computational and systems engineering approaches to prevent the engineering of emergent behaviors in SoS modeling and simulation (M&S). The subject of computational emergence requires a much needed focus. This article will discuss key emergent behaviors important to SoS engineering. We will apply Systems Theory, Control Theory and principles of Cybernetics to suggest a way forward for engineering of emergent behaviors in SoS M&S.", "references": ["Lewes, G. H., Problems of life and mind (First Series), 2, London: Trubner. ISBN 1-4255-5578-0. 1875", "Ashby, W. R., An Introduction to Cybernetics, University Paperbacks, Methuen, London 1964", "Wolf, T. D., Holvoet, T., Emergence versus self-organization: Different concepts but promising when combined. Lecture Notes in Artificial Intelligence, 3464: 1--15, 2005"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2874916.2874979"}, {"title": "Aligning Multi-Cultural Knowledge Taxonomies by Combinatorial Optimization", "authors": ["Natalia Prytkova\n,", "Gerhard Weikum\n,", "Marc Spaniol"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nLarge collections of digital knowledge have become valuable assets for search and recommendation applications. The taxonomic type systems of such knowledge bases are often highly heterogeneous, as they reflect different cultures, languages, and intentions of usage. We present a novel method to the problem of multi-cultural knowledge alignment, which maps each node of a source taxonomy onto a ranked list of most suitable nodes in the target taxonomy. We model this task as combinatorial optimization problems, using integer linear programming and quadratic programming. The quality of the computed alignments is evaluated, using large heterogeneous taxonomies about book categories.", "references": ["R. Agrawal, R. Srikant. On Integrating Catalogs. WWW 2001.", "A. Doan, A. Halevy, Z. G. Ives. Principles of Data Integration. 2012.", "J. Euzenat, P. Shvaiko. Ontology Matching. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742721"}, {"title": "Constructing concept clouds from company websites", "authors": ["Rosa Tsegaye Aga\n,", "Christian Wartena"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nWord clouds are used for the visual representation of texts. The font size and color of a word show its importance, and the position of a word in the cloud can be arbitrary or reflect its relation to other words. In this paper, we present a tool that generates concept clouds from German company websites. The main idea of the visualization is to show the overall work and main interests of companies in a detailed information cloud based solely on their own web page. The concepts are taken from the STW Thesaurus of Economics. The colors of the concepts show the categories of the concepts in the thesaurus while the cloud layout is organized by semantic proximity of the concepts. To compute the similarity between concepts we use the semantic representation that is generated from DeWaC corpus. The distributional similarity is fundamentally different from the co-occurrence statistics which often used to generate word clouds.", "references": ["M. Abulaish and T. Anwar. A keyphrase-based tag cloud generation framework to conceptualize textual data. International Journal of Adaptive, Resilient and Autonomic Systems (IJARAS), 4(2):72--93, 2013.", "M. Baroni, S. Bernardini, A. Ferraresi, and E. Zanchetta. The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora. Language Resources and Evaluation 43 (3): 209--226, 43(3):209--226, 2009.", "M. Bastian, S. Heymann, and M. Jacomy. Gephi: An open source software for exploring and manipulating networks. 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809615"}, {"title": "Incremental Matrix Factorization via Feature Space Re-learning for Recommender System", "authors": ["Qiang Song\n,", "Jian Cheng\n,", "Hanqing Lu"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nMatrix factorization is widely used in Recommender Systems. Although existing popular incremental matrix factorization methods are effectively in reducing time complexity, they simply assume that the similarity between items or users is invariant. For instance, they keep the item feature matrix unchanged and just update the user matrix without re-training the entire model. However, with the new users growing continuously, the fitting error would be accumulated since the extra distribution information of items has not been utilized. In this paper, we present an alternative and reasonable approach, with a relaxed assumption that the similarity between items (users) is relatively stable after updating. Concretely, utilizing the prediction error of the new data as the auxiliary features, our method updates both feature matrices simultaneously, and thus users' preference can be better modeled than merely adjusting one corresponded feature matrix. Besides, our method maintains the feature dimension in a smaller size through taking advantage of matrix sketching. Experimental results show that our proposal outperforms the existing incremental matrix factorization methods.", "references": ["M. Brand. Fast online svd revisions for lightweight recommender systems. In SDM, pages 37--46. SIAM, 2003.", "S. Han, Y. Yang, and W. Liu. Incremental learning for dynamic collaborative filtering. Journal of Software, 6(6):969--976, 2011.", "Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, (8):30--37, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799668"}, {"title": "Search Engine Evaluation based on Search Engine Switching Prediction", "authors": ["Olga Arkhipova\n,", "Lidia Grauer\n,", "Igor Kuralenok\n,", "Pavel Serdyukov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we present a novel application of the search engine switching prediction model for online evaluation. We propose a new metric pSwitch for A/B-testing, which allows us to evaluate the quality of search engines in different aspects such as the quality of the user interface and the quality of the ranking function. pSwitch is a search session-level metric, which relies on the predicted probability that the session contains a switch to another search engine and reflects the degree of the failure of the session. We demonstrate the effectiveness and validity of pSwitch using A/B-testing experiments with real users of search engine Yandex. We compare our metric with recently proposed SpU (sessions per user) metric and other widely used query-level A/B metrics, such as Abandonment Rate and Time to First Click, which we used as our baseline metrics. We observed that pSwitch metric is more sensitive in comparison with those baseline metrics and also that pSwitch and SpU are more consistent with ground truth, than Abandonment Rate and Time to First Click.", "references": ["M. R. Chernick and R. A. LaBudde. An Introduction to Bootstrap Methods with Applications to R. Wiley Publishing, 1st edition, 2011.", "C. Cleverdon. Readings in information retrieval. chapter The Cranfield Tests on Index Language Devices, pages 47--59. Morgan Kaufmann Publishers Inc., 1997.", "H. A. Feild, J. Allan, and R. Jones. Predicting searcher frustration. In Proc. SIGIR 2010, pages 34--41. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767786"}, {"title": "The Semantic Gap Between Software and the Memory System", "authors": ["Jim Stevens\n,", "Paul Tschirhart\n,", "Bruce Jacob"], "publication": "MEMSYS '15: Proceedings of the 2015 International Symposium on Memory Systems", "abstract": "ABSTRACT\nNo abstract available.", "references": ["Linux kernel documentation. https://github.com/torvalds/linux, 2015.", "I. Bhati, Z. Chishti, and B. Jacob. Coordinated refresh: Energy efficient techniques for dram refresh scheduling. In Low Power Electronics and Design (ISLPED), 2013 IEEE International Symposium on, pages 205--210, Sept 2013.", "T. H. Cormen, C. Stein, R. L. Rivest, and C. E. Leiserson. Introduction to Algorithms. McGraw-Hill Higher Education, 2nd edition, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818950.2818957"}, {"title": "Impact of Surrogate Assessments on High-Recall Retrieval", "authors": ["Adam Roegiest\n,", "Gordon V. Cormack\n,", "Charles L.A. Clarke\n,", "Maura R. Grossman"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe are concerned with the effect of using a surrogate assessor to train a passive (i.e., batch) supervised-learning method to rank documents for subsequent review, where the effectiveness of the ranking will be evaluated using a different assessor deemed to be authoritative. Previous studies suggest that surrogate assessments may be a reasonable proxy for authoritative assessments for this task. Nonetheless, concern persists in some application domains---such as electronic discovery---that errors in surrogate training assessments will be amplified by the learning method, materially degrading performance. We demonstrate, through a re-analysis of data used in previous studies, that, with passive supervised-learning methods, using surrogate assessments for training can substantially impair classifier performance, relative to using the same deemed-authoritative assessor for both training and assessment. In particular, using a single surrogate to replace the authoritative assessor for training often yields a ranking that must be traversed much lower to achieve the same level of recall as the ranking that would have resulted had the authoritative assessor been used for training. We also show that steps can be taken to mitigate, and sometimes overcome, the impact of surrogate assessments for training: relevance assessments may be diversified through the use of multiple surrogates; and, a more liberal view of relevance can be adopted by having the surrogate label borderline documents as relevant. By taking these steps, rankings derived from surrogate assessments can match, and sometimes exceed, the performance of the ranking that would have been achieved, had the authority been used for training. Finally, we show that our results still hold when the role of surrogate and authority are interchanged, indicating that the results may simply reflect differing conceptions of relevance between surrogate and authority, as opposed to the authority having special skill or knowledge lacked by the surrogate.", "references": ["Memorandum in Support of Motion for Protective Order Approving the Use of Predictive Coding, Global Aerospace v. Landow Aviation, No. CL 61040, 2012 WL 1419842 (Va. Cir. Ct., Loudoun Cnty., Apr. 9, 2012).", "Da Silva Moore v. Publicis Groupe, 287 F.R.D. 182 (S.D.N.Y., 2012).", "P. Bailey, N. Craswell, I. Soboroff, P. Thomas, A. P. de Vries, and E. Yilmaz. Relevance assessment: are judges exchangeable and does it matter? In Proc. SIGIR, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767754"}, {"title": "The Role of Query Sessions in Interpreting Compound Noun Phrases", "authors": ["Marius Pasca"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe meaning of compound noun phrases can be approximated in the form of lexical interpretations extracted from text. The interpretations hint at the role that modifiers play relative to heads within the noun phrases. In a study examining the role of query sessions in explaining compound noun phrases, candidate interpretations of compound noun phrases are extracted from pairs of queries that belong to the same query session. Experimental results over multiple evaluation sets of noun phrases show a higher accuracy of the interpretations when extracted from query sessions rather than from individual queries.", "references": ["K. Balog, M. Bron, and M. de Rijke. Category-based query modeling for entity search. In Proceedings of the 32nd European Conference on Information Retrieval (ECIR-10), pages 319--331, Milton Keynes, United Kingdom, 2010.", "M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction from the Web. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07), pages 2670--2676, Hyderabad, India, 2007.", "B. Billerbeck, G. Demartini, C. Firan, T. Iofciu, and R. Krestel. Ranking entities using Web search query logs. In Proceedings of the 14th European Conference on Research and Advanced Technology for Digital Libraries (ECDL-10), pages 273--281, Glasgow, Scotland, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806571"}, {"title": "Supervised Multi-scale Locality Sensitive Hashing", "authors": ["Li Weng\n,", "I-Hong Jhuo\n,", "Miaojing Shi\n,", "Meng Sun\n,", "Wen-Huang Cheng\n,", "Laurent Amsaleg"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nLSH is a popular framework to generate compact representations of multimedia data, which can be used for content based search. However, the performance of LSH is limited by its unsupervised nature and the underlying feature scale. In this work, we propose to improve LSH by incorporating two elements - supervised hash bit selection and multi-scale feature representation. First, a feature vector is represented by multiple scales. At each scale, the feature vector is divided into segments. The size of a segment is decreased gradually to make the representation correspond to a coarse-to-fine view of the feature. Then each segment is hashed to generate more bits than the target hash length. Finally the best ones are selected from the hash bit pool according to the notion of bit reliability, which is estimated by bit-level hypothesis testing.\nExtensive experiments have been performed to validate the proposal in two applications: near-duplicate image detection and approximate feature distance estimation. We first demonstrate that the feature scale can influence performance, which is often a neglected factor. Then we show that the proposed supervision method is effective. In particular, the performance increases with the size of the hash bit pool. Finally, the two elements are put together. The integrated scheme exhibits further improved performance.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In Proc. of 47th IEEE Symposium on Foundations of Computer Science (FOCS), pages 459--468, 2006.", "R. Balu, T. Furon, and H. Jégou. Beyond \"project and sign\" for cosine estimation with binary codes. In Proc. of International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 6884--6888, May 2014.", "M. S. Charikar. Similarity estimation techniques from rounding algorithms. In Proc. of 34th ACM Symposium on Theory of Computing (STOC), pages 380--388, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749291"}, {"title": "SimplePARQL: a new approach using keywords over SPARQL to query the web of data", "authors": ["Sonia Djebali\n,", "Thomas Raimbault"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nThe SimplePARQL is a new and intuitive approach to query the Web of Data through existing SPARQL endpoints by using keywords in addition to SPARQL elements. Thus, the user is able to write more expressive pseudo-SPARQL queries where knowing the ontology (classes and properties) and resources' identifiers from an RDF base are not required. Concretely, a SimplePARQL query is transformed into N valid SPARQL queries that extend the initial query in order to reach the IRIs or literals in the RDF bases corresponding to keywords. We implemented our approach on the platform universal-endpoint.com, where SimplePARQL queries can be written and executed on different RDF bases at the same time; SPARQL queries are accepted too.", "references": ["M. Arias, J. D. Fernández, M. A. Martínez-Prieto, and P. de la Fuente. An empirical study of real-world sparql queries. In Proc. of the USEWOD Workshop in the 20th WWW Conference, 2011.", "H. Bast, F. Bäurle, B. Buchhold, and E. Haußmann. Easy access to the freebase dataset. In Proc. of the 23rd WWW Conference, pages 95--98, 2014.", "T. Berners-Lee, J. Hendler, and O. Lassila. The Semantic Web. Scientific American, 279(5):34--43, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814890"}, {"title": "TRIFL: A Generic Trajectory Index for Flash Storage", "authors": ["Dai Hai Ton That\n,", "Iulian Sandu Popa\n,", "Karine Zeitouni"], "publication": "ACM Transactions on Spatial Algorithms and Systems", "abstract": "Abstract\nDue to several important features, such as high performance, low power consumption, and shock resistance, NAND flash has become a very popular stable storage medium for embedded mobile devices, personal computers, and even enterprise servers. However, the peculiar characteristics of flash memory require redesigning the existing data storage and indexing techniques that were devised for magnetic hard disks.\nIn this article, we propose TRIFL, an efficient and generic TRajectory Index for FLash. TRIFL is designed around the key requirements of trajectory indexing and flash storage. TRIFL is generic in the sense that it is efficient for both simple flash storage devices such as SD cards and more powerful devices such as solid state drives. In addition, TRIFL is supplied with an online self-tuning algorithm that allows adapting the index structure to the workload and the technical specifications of the flash storage device to maximize the index performance. Moreover, TRIFL achieves good performance with relatively low memory requirements, which makes the index appropriate for many application scenarios. The experimental evaluation shows that TRIFL outperforms the representative indexing methods on magnetic disks and flash disks.", "references": ["Devesh Agrawal, Deepak Ganesan, Ramesh Sitaraman, Yanlei Diao, and Shashi Singh. 2009. Lazy-adaptive tree: An optimized index structure for flash devices. PVLDB 2, 1 (2009), 361--372.", "Victor T. D. Almeida and Ralf H. Guting. 2005. Indexing the trajectories of moving objects in networks. GeoInformatica 9, 1 (2005), 33--60.", "Nicolas Anciaux, Luc Bouganim, Philippe Pucheral, Yanli Guo, Lionel L. Folgoc, and Shaoyi Yin. 2014. MILo-DB: A personal, secure and portable database machine. Distributed and Parallel Databases 32, 1 (2014), 37--63."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786758"}, {"title": "ORec: An Opinion-Based Point-of-Interest Recommendation Framework", "authors": ["Jia-Dong Zhang\n,", "Chi-Yin Chow\n,", "Yu Zheng"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nAs location-based social networks (LBSNs) rapidly grow, it is a timely topic to study how to recommend users with interesting locations, known as points-of-interest (POIs). Most existing POI recommendation techniques only employ the check-in data of users in LBSNs to learn their preferences on POIs by assuming a user's check-in frequency to a POI explicitly reflects the level of her preference on the POI. However, in reality users usually visit POIs only once, so the users' check-ins may not be sufficient to derive their preferences using their check-in frequencies only. Actually, the preferences of users are exactly implied in their opinions in text-based tips commenting on POIs. In this paper, we propose an opinion-based POI recommendation framework called ORec to take full advantage of the user opinions on POIs expressed as tips. In ORec, there are two main challenges: (i) detecting the polarities of tips (positive, neutral or negative), and (ii) integrating them with check-in data including social links between users and geographical information of POIs. To address these two challenges, (1) we develop a supervised aspect-dependent approach to detect the polarity of a tip, and (2) we devise a method to fuse tip polarities with social links and geographical information into a unified POI recommendation framework. Finally, we conduct a comprehensive performance evaluation for ORec using two large-scale real data sets collected from Foursquare and Yelp. Experimental results show that ORec achieves significantly superior polarity detection and POI recommendation accuracy compared to other state-of-the-art polarity detection and POI recommendation techniques.", "references": ["J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In ACM SIGSPATIAL, 2012.", "R. Dong, M. Schaal, M. P. O'Mahony, and B. Smyth. Topic extraction from online reviews for classification and recommendation. In IJCAI, 2013.", "H. Gao, J. Tang, and H. Liu. gSCorr: Modeling geo-social correlations for new check-ins on location-based social networks. In ACM CIKM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806516"}, {"title": "A Classification Schema for Fast Disambiguation of Spatial Prepositions", "authors": ["André Dittrich\n,", "Maria Vasardani\n,", "Stephan Winter\n,", "Timothy Baldwin\n,", "Fei Liu"], "publication": "IWGS '15: Proceedings of the 6th ACM SIGSPATIAL International Workshop on GeoStreaming", "abstract": "ABSTRACT\nIn the field of Artificial Intelligence the task of spatial language understanding is a particularly complex one. Textual spatial information is frequently represented by so-called locative expressions, incorporating spatial prepositions. However, apart from the spatial domain, these prepositions can occur in a wide range of senses (e.g., temporal, manner, cause, instrument) as well as in semantically transformed senses (e.g., metaphors and metonymies). Existing practical approaches usually disregard semantic transformations or falsely classify them as spatial, although they represent the majority of cases. For the efficient extraction of locative expressions from data streams (e.g. from social media sources), a fast filter mechanism for this non-spatial information is needed. Hence, we present a classification schema to quickly and robustly disambiguate spatial from non-spatial uses of prepositions. We conduct an inter-annotator agreement test to highlight the feasibility and comprehensibility of our schema based on examples sourced from a large social media corpus. We further identify the most promising existing natural language processing tools in order to combine machine learning features with fixed rules.", "references": ["A. Baddeley, V. B. H. L. Roediger, and J. R. Pomerantz, editors. Saying, Seeing and Acting: The Psychological Semantics of Spatial Prepositions. Taylor & Francis, Hove, UK, 2004.", "T. Baldwin, P. Cook, M. Lui, A. MacKinlay, and L. Wang. How noisy social media text, how diffrnt social media sources? In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 356--364, 2013.", "T. Baldwin, V. Kordoni, and A. Villavicencio. Prepositions in applications: A survey and introduction to the special issue. Computational Linguistics, 35(2):119--149, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2833165.2833167"}, {"title": "Topic Modeling Users' Interpretations of Songs to Inform Subject Access in Music Digital Libraries", "authors": ["Kahyun Choi\n,", "Jin Ha Lee\n,", "Craig Willis\n,", "J. Stephen Downie"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe assignment of subject metadata to music is useful for organizing and accessing digital music collections. Since manual subject annotation of large-scale music collections is labor-intensive, automatic methods are preferred. Topic modeling algorithms can be used to automatically identify latent topics from appropriate text sources. Candidate text sources such as song lyrics are often too poetic, resulting in lower-quality topics. Users' interpretations of song lyrics provide an alternative source. In this paper, we propose an automatic topic discovery system from web-mined user-generated interpretations of songs to provide subject access to a music digital library. We also propose and evaluate filtering techniques to identify high-quality topics. In our experiments, we use 24,436 popular songs that exist in both the Million Song Dataset and songmeanings.com. Topic models are generated using Latent Dirichlet Allocation (LDA). To evaluate the coherence of learned topics, we calculate the Normalized Pointwise Mutual Information (NPMI) of the top ten words in each topic based on occurrences in Wikipedia. Finally, we evaluate the resulting topics using a subset of 422 songs that have been manually assigned to six subjects. Using this system, 71% of the manually assigned subjects were correctly identified. These results demonstrate that topic modeling of song interpretations is a promising method for subject metadata enrichment in music digital libraries. It also has implications for affording similar access to collections of poetry and fiction.", "references": ["D. Bainbridge, S. J. Cunningham, and J. S. Downie, \"How people describe their music information needs: A grounded theory analysis of music queries,\" In Proc. of 4th Int. Soc. for Music Inform. Retrieval Conf., 2003, 221--222.", "J. H. Lee and J. S. Downie, \"Survey Of Music Information Needs, Uses, And Seeking Behaviors: Preliminary Findings,\" In Proc. of 5th Int. Soc. for Music Inform. Retrieval Conf., Barcelona, Spain, Oct. 2004, 441--446.", "J. P. Mahedero, Á. Martínez, and P. Cano, \"Natural language processing of lyrics,\" In Proc. of the 13th annual ACM Int. Conf. on Multimedia, Singapore, Nov. 2005, 475--478."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756936"}, {"title": "Performance and scalability of indexed subgraph query processing methods", "authors": ["Foteini Katsarou\n,", "Nikos Ntarmos\n,", "Peter Triantafillou"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nGraph data management systems have become very popular as graphs are the natural data model for many applications. One of the main problems addressed by these systems is subgraph query processing; i.e., given a query graph, return all graphs that contain the query. The naive method for processing such queries is to perform a subgraph isomorphism test against each graph in the dataset. This obviously does not scale, as subgraph isomorphism is NP-Complete. Thus, many indexing methods have been proposed to reduce the number of candidate graphs that have to underpass the subgraph isomorphism test. In this paper, we identify a set of key factors-parameters, that influence the performance of related methods: namely, the number of nodes per graph, the graph density, the number of distinct labels, the number of graphs in the dataset, and the query graph size. We then conduct comprehensive and systematic experiments that analyze the sensitivity of the various methods on the values of the key parameters. Our aims are twofold: first to derive conclusions about the algorithms' relative performance, and, second, to stress-test all algorithms, deriving insights as to their scalability, and highlight how both performance and scalability depend on the above factors. We choose six well-established indexing methods, namely Grapes, CT-Index, GraphGrepSX, gIndex, Tree+Δ, and gCode, as representative approaches of the overall design space, including the most recent and best performing methods. We report on their index construction time and index size, and on query processing performance in terms of time and false positive ratio. We employ both real and synthetic datasets. Specifically, four real datasets of different characteristics are used: AIDS, PDBS, PCM, and PPI. In addition, we generate a large number of synthetic graph datasets, empowering us to systematically study the algorithms' performance and scalability versus the aforementioned key parameters.", "references": ["H. M. Berman, J. Westbrook, Z. Feng, G. Gilliland, T. Bhat, H. Weissig, I. N. Shindyalov, and P. E. Bourne. The protein data bank. Nucleic acids research, 28(1):235--242, 2000.", "V. Bonnici, A. Ferro, R. Giugno, A. Pulvirenti, and D. Shasha. Enhancing graph database indexing by suffix tree structure. In Proc. IAPR PRIB, pages 195--203. 2010.", "C. Chen, X. Yan, P. S. Yu, J. Han, D.-Q. Zhang, and X. Gu. Towards graph containment search and indexing. In Proc. VLDB, pages 926--937, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824054"}, {"title": "Incorporating Non-sequential Behavior into Click Models", "authors": ["Chao Wang\n,", "Yiqun Liu\n,", "Meng Wang\n,", "Ke Zhou\n,", "Jian-yun Nie\n,", "Shaoping Ma"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nClick-through information is considered as a valuable source of users' implicit relevance feedback. As user behavior is usually influenced by a number of factors such as position, presentation style and site reputation, researchers have proposed a variety of assumptions (i.e.~click models) to generate a reasonable estimation of result relevance. The construction of click models usually follow some hypotheses. For example, most existing click models follow the sequential examination hypothesis in which users examine results from top to bottom in a linear fashion. While these click models have been successful, many recent studies showed that there is a large proportion of non-sequential browsing (both examination and click) behaviors in Web search, which the previous models fail to cope with. In this paper, we investigate the problem of properly incorporating non-sequential behavior into click models. We firstly carry out a laboratory eye-tracking study to analyze user's non-sequential examination behavior and then propose a novel click model named Partially Sequential Click Model (PSCM) that captures the practical behavior of users. We compare PSCM with a number of existing click models using two real-world search engine logs. Experimental results show that PSCM outperforms other click models in terms of both predicting click behavior (perplexity) and estimating result relevance (NDCG and user preference test). We also publicize the implementations of PSCM and related datasets for possible future comparison studies.", "references": ["E. Agichtein, E. Brill, S. T. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. SIGIR'06, pages 3--10, Aug. 2006.", "A. Broder. A taxonomy of web search. In SIGIR'02, volume 36, pages 3--10. ACM, 2002.", "G. Buscher, S. White, Ryen W, and J. Huang. Large-scale analysis of individual and task differences in search result page examination strategies. In WSDM'12, pages 373--382. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767712"}, {"title": "Mining, Ranking and Recommending Entity Aspects", "authors": ["Ridho Reinanda\n,", "Edgar Meij\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nEntity queries constitute a large fraction of web search queries and most of these queries are in the form of an entity mention plus some context terms that represent an intent in the context of that entity. We refer to these entity-oriented search intents as entity aspects. Recognizing entity aspects in a query can improve various search applications such as providing direct answers, diversifying search results, and recommending queries. In this paper we focus on the tasks of identifying, ranking, and recommending entity aspects, and propose an approach that mines, clusters, and ranks such aspects from query logs. We perform large-scale experiments based on users' search sessions from actual query logs to evaluate the aspect ranking and recommendation tasks. In the aspect ranking task, we aim to satisfy most users' entity queries, and evaluate this task in a query-independent fashion. We find that entropy-based methods achieve the best performance compared to maximum likelihood and language modeling approaches. In the aspect recommendation task, we recommend other aspects related to the aspect currently being queried. We propose two approaches based on semantic relatedness and aspect transitions within user sessions and find that a combined approach gives the best performance. As an additional experiment, we utilize entity aspects for actual query recommendation and find that our approach improves the effectiveness of query recommendations built on top of the query-flow graph.", "references": ["E. Amigó, J. Gonzalo, J. Artiles, and F. Verdejo. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Inf. Retr., 12 (4): 461--486, 2009.", "N. Balasubramanian and S. Cucerzan. Topic pages: An alternative to the ten blue links. In IEEE-ICSC 2010, 2010.", "R. Blanco, B. B. Cambazoglu, P. Mika, and N. Torzec. Entity recommendations in web search. In ISWC '13, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767724"}, {"title": "Gestural control in electronic music performance: sound design based on the `striking' and `bowing' movement metaphors", "authors": ["Frederic Robinson\n,", "Cedric Spindler\n,", "Volker Böhm\n,", "Erik Oña"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nFollowing a call for clear movement-sound relationships in motion-controlled digital musical instruments (DMIs), we developed a sound design concept and a DMI implementation with a focus on transparency through intuitive control metaphors. In order to benefit from the listener's and performer's natural understanding of physical processes around them, we use gestures with strong physical associations as control metaphors, which are then mapped to sound modules specifically designed to represent these associations sonically. The required motion data can be captured by any low-latency sensor device worn on the hand or wrist, that has an inertial measurement unit with six degrees of freedom. A dimension space analysis was applied on the current implementation in order to compare it to existing DMIs and illustrate its characteristics. In conclusion, our approach resulted in a DMI with strong results in transparency, intuitive control metaphors, and a coherent audio-visual link.", "references": ["D. Birnbaum, R. Fiebrink, J. Malloch, and M. M. Wanderley. Towards a dimension space for musical devices. In Proceedings of the International Conference on New Interfaces for Musical Expression, pages 192--195, Vancouver, BC, Canada, 2005.", "C. Cadoz. Proceedings of the international computer music conference. In Proceedings of International Computer Music Conference, pages 1--12, San Francisco, 1988.", "C. Cadoz and M. M. Wanderley. Trends in Gestural Control of Music, chapter Gesture-Music, page 101. Ircam - Centre Pompidou Paris, IRCAM - Centre Georges Pompidou, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814901"}, {"title": "Recommending Web Service Based on Ontologies for Digital Repositories", "authors": ["Anderson Salles\n,", "Roberto Willrich"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nDigital Repositories (DRs) offer functionalities for managing, storing and accessing digital contents. DRs may make available a wide range of content types, including theses, dissertations, papers, videos, works of art and literacy works. Some DRs have used recommendation systems to offer users suggestions about digital contents that they might be interested. In this paper, we propose a multi-domain Recommender Web Service supporting multiple types of recommendation audience. The flexibility of domain and audience is provided by the use of ontologies to represent domain-specific knowledge. In order to test the feasibility of our proposal, the paper presents two use cases of our Recommending Web Service.", "references": ["M. Anjorin, I. Dackiewicz, A. Fernández, C. Rensing, et al. A framework for cross-platform graph-based recommendations for tel. In Proceedings of the 2nd workshop on recommender systems in technology enhanced learning, pages 83--88, 2012.", "S. Batra and C. Tyagi. Comparative analysis of relational and graph databases. International Journal of Soft Computing and Engineering, 2012.", "G. Beham, B. Kump, T. Ley, and S. Lindstaedt. Recommending knowledgeable people in a work-integrated learning system. Procedia Computer Science, 1(2):2783--2792, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2820432"}, {"title": "AutoGuitarTab: computer-aided composition of rhythm and lead guitar parts in the tablature space", "authors": ["Matt McVicar\n,", "Satoru Fukayama\n,", "Masataka Goto"], "publication": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "abstract": "Abstract\nWe present AutoGuitarTab, a system for generating realistic guitar tablature given an input symbolic chord and key sequence. Our system consists of two modules: AutoRhythm-Guitar and AutoLeadGuitar. The first of these generates rhythm guitar tablatures which outline the input chord sequence in a particular style (using Markov chains to ensure playability) and performs a structural analysis to produce a structurally consistent composition. AutoLeadGuitar generates lead guitar parts in distinct musical phrases, guiding the pitch classes towards chord tones and steering the evolution of the rhythmic and melodic intensity according to user preference. Experimentally, we uncover musician-specific trends in guitar playing style, and demonstrate our system's ability to produce playable, realistic and style-specific tablature using a combination of algorithmic, user-surveyed and expert evaluation techniques.", "references": ["S. Nierhaus, Algorithmic Composition. New York, NY, USA: Springer Wein, 2009.", "L. Hiller and L. Isaacson, \"Musical composition with a high speed digital computer,\" in Audio Engineering Society Convention. New York, NY, USA: Audio Engineering Soc., 1957.", "F. Pachet, \"The continuator: Musical interaction with style,\" J. New Music Res., vol. 32, no. 3, pp. 333-341, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TASLP.2015.2419976"}, {"title": "Execution of data-dependent programs over encrypted data", "authors": ["Philipp Burtyka\n,", "Oleg Makarevich"], "publication": "SIN '15: Proceedings of the 8th International Conference on Security of Information and Networks", "abstract": "ABSTRACT\nFully homomorphic encryption (FHE) is a tool of key importance to organize computations over encrypted data. But its misuse leads to privacy violation in spite of the encryption security. To use FHE correctly in applications one needs to solve a number of rather sophisticated problems.\nThis paper considers delegation of programs evaluation over encrypted data to the untrusted server in the case when algorithms for evaluation are public. The main question in this case is how to organize computations in such a way that their structures don't reveal any information about the encrypted data. This information is called data-dependence. The aim of the study is to construct such protocols for interaction with untrusted server that don't allow it accurately determine the relationship between the amount of computations and the encrypted data.\nThe known solutions to the problem are briefly reviewed, analyzed and their disadvantages are shown. Then we present our three protocols for secure computations. The first protocol solves the problem by hiding the exact number of steps from untrusted server. This is achieved by intentional delay of feedback from the client and without any transformation of the evaluated program. The second protocol simplifies client actions, allowing computation to be fully self-contained. It requires only two communications between the client and server while ensuring the final result achievement and keeping the perfect secrecy. But it significantly increases the amount of computations that server must perform, namely for any input data server carries out the greatest possible number of steps. And third protocol involves the functional encryption. It allows getting final result of computations surely in two interactions between client and server, while not overloading the server too much. Such a protocol is well suited even for computations with worst-case exponential complexity.", "references": ["D. Boneh, A. Sahai, and B. Waters. Functional encryption: Definitions and challenges. In Theory of Cryptography, pages 253--273. Springer, 2011.", "P. Burtyka and O. Makarevich. Symmetric fully homomorphic encryption using decidable matrix equations. In Proceedings of the 7th International Conference on Security of Information and Networks, pages 186--198. ACM, 2014.", "P. B. Burtyka. Batch symmetric fully homomorphic encryption using matrix polynomials. The Proceedings of Institute for System Programming RAS, 26(5): 99--115, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2799979.2800010"}, {"title": "Crowdsourcing biking times", "authors": ["Mingsheng Wu\n,", "Vanessa Frias-Martinez"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nUrban cyclists often rely on Google's biking directions to consult routes and times. However, cyclists have reported that those estimates can sometimes be inaccurate [1]. In this paper, we explore the accuracy of Google biking times using a crowdsourced approach. Specifically, we use real biking data from a bike sharing system as ground truth and evaluate the automatic computation of Google's biking times. We analyze similarities and differences between the two as well as the role that measurable factors such as trip distance or slope might play in the temporal differences. Finally, we propose a predictive model based on a set of measurable factors that improves the accuracy of Google's biking time computations by 5%.", "references": ["2014. How accurate are Google Maps Cycling time estimates? http://www.betterbybicycle.com/2014/09/how-accurate-are-google-maps-cycling.html. (2014).", "2015. League of American Bicyclists. www.bikerleague.org/content/resources. (2015).", "E. Come and L. Oukhellou. 2014. Model-Based Count Series Clustering for Bike Sharing System Usage Mining: A Case Study with the VélibSystem of Paris. ACM Transactions on Intelligent Systems and Technology (TIST) 5, 3 (2014), 39."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2800976"}, {"title": "Integrating and Evaluating Neural Word Embeddings in Information Retrieval", "authors": ["Guido Zuccon\n,", "Bevan Koopman\n,", "Peter Bruza\n,", "Leif Azzopardi"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nRecent advances in neural language models have contributed new methods for learning distributed vector representations of words (also called word embeddings). Two such methods are the continuous bag-of-words model and the skipgram model. These methods have been shown to produce embeddings that capture higher order relationships between words that are highly effective in natural language processing tasks involving the use of word similarity and word analogy. Despite these promising results, there has been little analysis of the use of these word embeddings for retrieval.\nMotivated by these observations, in this paper, we set out to determine how these word embeddings can be used within a retrieval model and what the benefit might be. To this aim, we use neural word embeddings within the well known translation language model for information retrieval. This language model captures implicit semantic relations between the words in queries and those in relevant documents, thus producing more accurate estimations of document relevance.\nThe word embeddings used to estimate neural language models produce translations that differ from previous translation language model approaches; differences that deliver improvements in retrieval effectiveness. The models are robust to choices made in building word embeddings and, even more so, our results show that embeddings do not even need to be produced from the same corpus being used for retrieval.", "references": ["L. Azzopardi, M. Girolami, & M. Crowe. Probabilistic hyperspace analogue to language. In SIGIR'05, pg. 575--576, 2005.", "J. Bai, D. Song, P. Bruza, J.-Y. Nie, & G. Cao. Query expansion using term relationships in language models for information retrieval. In CIKM'05, pg. 688--695, 2005.", "M. Bendersky, D. Metzler, & W. B. Croft. Learning concept importance using a weighted dependence model. In WSDM'10, pg. 31--40, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838936"}, {"title": "An Ontology Enrichment Approach by Using DBpedia", "authors": ["Meisam Booshehri\n,", "Peter Luksch"], "publication": "WIMS '15: Proceedings of the 5th International Conference on Web Intelligence, Mining and Semantics", "abstract": "ABSTRACT\nOver the past decade, an increasing number of methods have been proposed for (semi-) automatic generation of ontology from text. However, the ontology generated by these methods usually does not meet the needs of many reasoning-based applications in different domains since most of these methods aim at generating inexpressive ontologies e.g. bare taxonomies. In this paper, a new ontology enrichment approach is proposed in which Web of Linked Data (in particular, DBpedia as one of the huge Linked Data datasets) is used as background knowledge beside text in order to recognize new ontological relations, specifically object properties, for ontology enrichment. In other words, this enrichment approach can be considered as a post-processing step for the \"Relations\" layer (i.e. the fifth layer) in Ontology Learning Stack, aiming at recommending new object properties to the ontology engineers enabling them to create much more expressive ontologies. This is actually a complementary approach to our recent approach towards adding Linked Data to ontology learning layers where we aimed at improving the functions associated to the \"Synonyms\" layer, the \"Concept Formation\" layer and the \"Concept Hierarchy\" layer of ontology learning stack. In order to evaluate the approach, a customized experimental design is introduced called the \"Pseudo Gold Standard based Ontology Evaluation\" in which the results obtained by a human expert are compared against those obtained automatically. Finally, the experimental results showed a satisfactory improvement in learning object properties.", "references": ["Davies, J., Studer, R. and Warren, P. Semantic Web technologies: trends and research in ontology-based systems. Wiley. com, 2006.", "Völker, J., Haase, P. and Hitzler, P. Learning expressive ontologies. IOS Press, 2009.", "Buitelaar, P. and Cimiano, P. Ontology learning and population: bridging the gap between text and knowledge. Citeseer, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797115.2797127"}, {"title": "Factorization Machines for Hybrid Recommendation Systems Based on Behavioral, Product, and Customer Data", "authors": ["Stijn Geuens"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis study creates a hybrid recommendation system for online offer personalization of an e-commerce company. The system goes beyond existing literature by combining four different data sources, i.e. customer data, product data, implicit and explicit behavioral data, in a single algorithm. Factorization machines are employed as model-based algorithm and have as advantage that the four data sources are incorporated in a single model by feature combination. Results show that hybridization of the four distinct data sources improves accuracy compared to (i) factorization machines based on a single data source and (ii) a real-life company benchmark model using collaborative filtering.", "references": ["Adomavicius, G. and Tuzhilin, A., 2005. Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Trans. on Knowl. and Data Eng. 17, 6, 734--749.", "Al-Shamri, M.Y.H. and Bharadwaj, K.K., 2008. Fuzzy-Genetic Approach to Recommender Systems Based on a Novel Hybrid User Model. Expert Syst. with Appl. 35, 3, 1386--1399.", "Basu, C., Hirsh, H., and Cohen, W., 1998. Recommendation as Classification: Using Social and Content-Based Information in Recommendation. In Proceedings of the 15th National Conference on Artificial Intelligence/Innovative Applications of Artificial Intelligence (Madison, WI), American Association for Artificial Intelligence, 714--720."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796542"}, {"title": "Effect of Corpus Size Selection on Performance of Map-Reduce Based Distributed K-Means for Big Textual Data Clustering", "authors": ["Shwet Ketu\n,", "Bakshi Rohit Prasad\n,", "Sonali Agarwal"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nIn current era, we are experiencing tremendous growth in database sizes, types, users, working environments and data access speeds. This situation coined a new term Big Data which are large and complex datasets used for extracting meaningful knowledge. One of the main challenges in processing Big Data is its huge volume which is a common characteristic of huge collection of textual data also. Handling such voluminous big textual data using conventional data mining techniques such as clustering becomes impractical because of algorithmic incompetence to address the large computation time. This research work is mainly focused on big text data clustering using MapReduce based Distributed K-Means algorithm combined with corpus selection technique for a significant decrement of overall computation time. Four benchmark datasets have been used to explore the relationship between corpus size and computation time. It is found that the corpus selection technique significantly effective in reduction of overall processing time.", "references": ["Fahad, A., Alshatri, N., Tari, Z., Alamri, A., Khalil, I., Zomaya, A. Y., Foufou, S., and Bouras, A. 2014. A survey of clustering algorithms for big data: Taxonomy and empirical analysis. Emerging Topics in Computing, IEEE Transactions on, 2(3), 267--279.", "Jacobs, A. 2009. The pathologies of big data. Communications of the ACM, 52(8), 36--44.", "Zikopoulos, P., and Eaton, C. 2011. Understanding big data: Analytics for enterprise class hadoop and streaming data. McGraw-Hill Osborne Media."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818653"}, {"title": "Social Tag Relevance Estimation via Ranking-Oriented Neighbour Voting", "authors": ["Chaoran Cui\n,", "Jialie Shen\n,", "Jun Ma\n,", "Tao Lian"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nUser-generated tags associated with social images are frequently imprecise and incomplete. Therefore, a fundamental challenge in tag-based applications is the problem of tag relevance estimation, which concerns how to interpret and quantify the relevance of a tag with respect to the contents of an image. In this paper, we address the key problem from a new perspective of learning to rank, and develop a novel approach to facilitate tag relevance estimation to directly optimize the ranking performance of tag-based image search. A supervision step is introduced into the neighbour voting scheme, in which tag relevance is estimated by accumulating votes from visual neighbours. Through explicitly modelling the neighbour weights and tag correlations, the risk of making heuristic assumptions is effectively avoided for conventional methods. Extensive experiments on a benchmark dataset in comparison with the state-of-the-art methods demonstrate the promise of our approach.", "references": ["Z. Cheng, J. Shen, and H. Miao. The effects of multiple query evidences on social image retrieval. Multimedia Systems, 2014.", "T.-S. Chua and J. Tang. Nus-wide: a real-world web image database from national university of singapore. In CIVR, 2009.", "T. Joachims, T. Finley, and C. Yu. Cutting-plane training of structural svms. Machine Learning, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806358"}, {"title": "The Sum of All Human Knowledge in Your Pocket: Full-Text Searchable Wikipedia on a Raspberry Pi", "authors": ["Jimmy Lin"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWe demonstrate a prototype that takes advantage of open-source software to put a full-text searchable copy of Wikipedia on a Raspberry Pi, providing nearby devices access to content via wifi or bluetooth without requiring internet connectivity. This short paper articulates the advantages of such a form factor and provides an evaluation of browsing and search capabilities. We believe that personal digital libraries on lightweight mobile computing devices represent an interesting research direction to pursue.", "references": ["R. Balani. Energy consumption analysis for bluetooth, wifi and cellular networks, 2007.", "C. Clarke, N. Craswell, and I. Soboroff. Overview of the {TREC} 2009 web track. TREC, 2009.", "A. Trotman, X.-F. Jia, and M. Crane. Towards an efficient and effective search engine. SIGIR 2012 Workshop on Open Source Information Retrieval}, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756938"}, {"title": "Annotating Needles in the Haystack without Looking: Product Information Extraction from Emails", "authors": ["Weinan Zhang\n,", "Amr Ahmed\n,", "Jie Yang\n,", "Vanja Josifovski\n,", "Alex J. Smola"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nBusiness-to-consumer (B2C) emails are usually generated by filling structured user data (e.g.purchase, event) into templates. Extracting structured data from B2C emails allows users to track important information on various devices.\nHowever, it also poses several challenges, due to the requirement of short response time for massive data volume, the diversity and complexity of templates, and the privacy and legal constraints. Most notably, email data is legally protected content, which means no one except the receiver can review the messages or derived information.\nIn this paper we first introduce a system which can extract structured information automatically without requiring human review of any personal content. Then we focus on how to annotate product names from the extracted texts, which is one of the most difficult problems in the system. Neither general learning methods, such as binary classifiers, nor more specific structure learning methods, suchas Conditional Random Field (CRF), can solve this problem well.\nTo accomplish this task, we propose a hybrid approach, which basically trains a CRF model using the labels predicted by binary classifiers (weak learners). However, the performance of weak learners can be low, therefore we use Expectation Maximization (EM) algorithm on CRF to remove the noise and improve the accuracy, without the need to label and inspect specific emails. In our experiments, the EM-CRF model can significantly improve the product name annotations over the weak learners and plain CRFs.", "references": ["N. Ailon, Z. S. Karnin, E. Liberty, and Y. Maarek. Threading machine generated email. In WSDM. ACM, 2013.", "S. M. Aji and R. J. McEliece. The generalized distributive law. IEEE Transactions on Information Theory, 46(2), 2000.", "C. Bird, A. Gourley, P. Devanbu, M. Gertz, and A. Swaminathan. Mining email social networks. In Workshop on Mining software repositories, pages 137--143. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2788580"}, {"title": "SciNet: Interactive Intent Modeling for Information Discovery", "authors": ["Tuukka Ruotsalo\n,", "Jaakko Peltonen\n,", "Manuel J.A. Eugster\n,", "Dorota Głowacka\n,", "Aki Reijonen\n,", "Giulio Jacucci\n,", "Petri Myllymäki\n,", "Samuel Kaski"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nCurrent search engines offer limited assistance for exploration and information discovery in complex search tasks. Instead, users are distracted by the need to focus their cognitive efforts on finding navigation cues, rather than selecting relevant information. Interactive intent modeling enhances the human information exploration capacity through computational modeling, visualized for interaction. Interactive intent modeling has been shown to increase task-level information seeking performance by up to 100%. In this demonstration, we showcase SciNet, a system implementing interactive intent modeling on top of a scientific article database of over 60 million documents.", "references": ["P. Auer. Using confidence bounds for exploitation-exploration trade-offs. J. Mach. Learn. Res., 3:397 -- 422, 2002.", "G. W. Furnas, T. K. Landauer, L. M. Gomez, and S. T. Dumais. The vocabulary problem in human-system communication. Commun. ACM, 30(11):964--971, Nov. 1987.", "D. Glowacka, T. Ruotsalo, K. Konuyshkova, K. Athukorala, S. Kaski, and G. Jacucci. Directing exploratory search: Reinforcement learning from user interactions with keywords. In Proc. IUI'13, pages 117--128, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767863"}, {"title": "Multi-facet Learning using Deep Convolutional Neural Network for Person-Related Categories in Photos", "authors": ["Liangliang Cao\n,", "Zhicheng Yan\n,", "John R. Smith"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper proposes to leverage multiple facets of person photos to improve the training of deep neural networks. Existing studies usually require a lot of labeled images to train deep convolutional networks. Our study suggests exploring multiple datasets and learning effective representation to learn related visual concepts. The practice of learning from multiple facets implicitly enforces to share features for image recognition. We show deep neural network benefits from the learning of multiple person-related categories in photos. Faceted classification systems learn from multiple resources, and alleviate the overfitting problems in deep learning. Moreover, by exploring multiple taxonomies of an object, it provides a finer annotation for the query images.", "references": ["L. Cao, L. Gong, J. R. Kender, N. C. Codella, and J. R. Smith. Learning by focusing: A new framework for concept recognition and feature selection. In ICME, 2013.", "T.-S. Chua, J. Tang, R. Hong, and et al. NUS-WIDE: A real-world web image database from national university of singapore. In CIVR, 2009.", "D. C. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In CVPR, pages 3642--3649, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749356"}, {"title": "A spatiotemporal model of Twitter information diffusion: an example of Egyptian revolution 2011", "authors": ["K. Hazel Kwon\n,", "Haiyan Wang\n,", "Ross Raymond\n,", "Weiai Wayne Xu"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nRecent social movements demonstrate an important role of social media information diffusion in promoting social changes. Transnational information diffusion may be influenced by spatial proximity between the origin nation and other parts of the world. Proximity implies more than just physical distance. This paper develops a mathematical spatiotemporal diffusion model based on partial differential equations, called \"diffusion-advection\" model. The model is applied to four sets of global spatial arrangements, respectively based on geographical, ideological, economic and diaspora perspective on proximity. Twitter data on Egyptian Revolution 2011 is used for the model validation. The developed model shows an acceptable accuracy rate. Among the different definition of proximity, ideology-based arrangement (i.e., democracy) explained most effectively the spatial diffusion process over the course of the revolution, showing that different types of messages are diffused at a different pace.", "references": ["Bennett, W. L. and Segerberg, A. 2012. The logic of connective action. Information, Communication, and Society 15, 5, 739--768. DOI = 10.1080/1369118X.2012.670661", "Andrews, K. T. and Biggs, M. 2006. The dynamics of protest diffusion: Movement organizations, social networks, and news media in the 1960 sit-ins. American Sociological Review 71, 5, 752--777. DOI = 10.1177/000312240607100503", "Granovetter, M. 1978. Threshold models of collective behavior. American Journal of Sociology 83, 1420--1443. Stable URL = http://www.jstor.org/stable/2778111"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789205"}, {"title": "Cross-Modal Image-Tag Relevance Learning for Social Images", "authors": ["Yong Cheng\n,", "Zhengxiang Cai\n,", "Rui Feng\n,", "Cheng Jin\n,", "Yuejie Zhang\n,", "Tao Zhang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nA new algorithm is developed in this paper to support more effective cross-modal image-tag relevance learning for large-scale social images, which integrates the multimodal feature representation, multimodal relevance measurement, and cross- modal relevance fusion. The main contribution of our work is that we provide a more reasonable base to learn cross-modal relevance among social images, which can be acquired from integrating multimodal image and tag relevance with multiple features in different modalities. Very positive results were obtained in our experiments using a large quantity of public social image data.", "references": ["Wu, L., Jin, R., and Jain, A.K. 2013. Tag Completion for Image Retrieval. IEEE Transactions on PAMI, 35(3):716--727.", "Li, X.R., Snoek, C.G.M., and Worring, M. 2009. Learning Social Tag Relevance by Neighbor Voting. IEEE Transactions on Multimedia, 11(7):1310--1322.", "Liu, D., Hua, X.S., Wang, M., and Zhang, H.J. 2010. Image Retagging. In Proceedings of MM 2010, 491--500."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806294"}, {"title": "Crowdsourcing based spatial mining of urban emergency events using social media", "authors": ["Zheng Xu\n,", "Vijayan Sugumaran\n,", "Hui Zhang"], "publication": "EM-GIS '15: Proceedings of the 1st ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management", "abstract": "ABSTRACT\nWith the advances of information communication technologies, it is critical to improve the efficiency and accuracy of emergency management systems through modern data processing techniques. The past decade has witnessed the tremendous technical advances in Sensor Networks, Internet/Web of Things, Cloud Computing, Mobile/Embedded Computing, Spatial/Temporal Data Processing, and Big Data, and these technologies have provided new opportunities and solutions to emergency management. GIS models and simulation capabilities are used to exercise response and recovery plans during non-disaster times. They help the decision-makers understand near real-time possibilities during an event. In this paper, a crowdsourcing based model for mining spatial information of urban emergency events is introduced. Firstly, basic definitions of the proposed method are given. Secondly, positive samples are selected to mine the spatial information of urban emergency events. Thirdly, location and GIS information are extracted from positive samples. At last, the real spatial information is determined based on address and GIS information. At last, a case study on an urban emergency event is given.", "references": ["Business Models for the Next Generation of Software. http://www.oreillynet.com/pub/a/oreilly/tim/news/2005/09/30/what-is-web-20.html (2005).", "Goodchild, M. F. Citizens as Voluntary Sensors: Spatial Data Infrastructure in the World of Web 2.0. International Journal of Spatial Data Infrastructures Research 2, (2007), 24--32.", "T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake Shakes Twitter Users: Real-time Event Detection by Social Sensors. In Proceedings of the 19th international World Wide Web conference, pp. 851--860, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835596.2835610"}, {"title": "ImmersiveMe'15: 3rd ACM International Workshop on Immersive Media Experiences", "authors": ["Teresa Chambel\n,", "Paula Viana\n,", "V. Michael Bove\n,", "Sharon Strover\n,", "Graham Thomas"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis ACM International Workshop on Immersive Media Experiences is in its 3rd edition. Since 2013 in Barcelona, it has been a meeting point of researchers, students, media producers, service providers and industry players in the area of immersive media environments, applications and experiences. After the successful first edition at ACM Multimedia 2013 and the consolidation of the theme and the team at Orlando in 2014, ImmersiveMe'15 aims at bringing to the stage new ideas and developments that keep this topic as appealing as in the previous editions. ImmersiveMe'15 will now take place in Brisbane and, again, it will be a platform to present interesting and out-of-the-box new work that contributes to make the world more interactive, immersive and engaging.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806410"}, {"title": "A Hybrid Big Data Analytics Method for Yield Improvement in Semiconductor Manufacturing", "authors": ["Chung-Hong Lee\n,", "Hsin-Chang Yang\n,", "Shou-Chen Cheng\n,", "Sheng-Wen Tsai"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn the manufacturing of semiconductor encapsulation, the production yield is one of critical issues concerned by all foundries. It is because that yield rate can directly affects the quality of the final product and the profitability. In this work we take the defect-products as samples and use machine learning techniques to classify the samples and verify the accuracy and feasibility of the experiment. We use Support Vector Machines (SVM) model to perform classification and compare the resulting accuracy with the results of Back Propagation Neural Network (BPN) model. Furthermore, we employ a statistical method namely Pearson product-moment correlation coefficient to identify the influential factors for production quality. The experimental result demonstrates that our hybrid method has great potentials for yield improvement in semiconductor manufacturing.", "references": ["Nallapati, R., Allan, J. 2002. Capturing term dependencies using a languagemodel based on sentence trees. In Proceedings of the 8th international conferenceon information and knowledge management. (McLean, Virginia, USA, 2002). DOI=http://doi.acm.org/10.1145/584792.584855.", "Cortes, C., Vapnik, V. 1995. Support Vector Networks. Mach Learning. 20, 3 (September 1995), 273--295.", "Yan, W. W., Shao, H. H. 2002. Application of Support Vector Machine Nonlinear Classifier to Fault Diagnoses. In Proceedings of the Fourth World Congress Intelligent Control and Automation. (Shanghai, China, June. 2002), 2697--2670. DOI= http://dx.doi.org/10.1109/WCICA.2002.1020004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818934"}, {"title": "The shepard tone and higher-order multi-rate synchronous data-flow programming in Sig", "authors": ["Baltasar Trancón y Widemann\n,", "Markus Lepper"], "publication": "FARM 2015: Proceedings of the 3rd ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design", "abstract": "ABSTRACT\nThe total functional real-time data-flow programming language Sig features a core layer with elegant denotational semantics, in terms of Mealy stream transducers and coiterative causal stream functions, that is convenient for domain experts in the primary application domains, such as scientific modeling and digital music and event arts. The core suffices for the implementation of many basic signal processing components. For the expression of more sophisticated computations, a second layer of Sig provides additional features, namely higher-order functional programming and multi-rate synchronicity, reducible by transformational semantics to the core layer. Here we describe the design of the upper layer of Sig and demonstrate its usage with the Shepard Tone, a well-known sound synthesis problem and model of psycho-acoustically paradoxical perception of relative musical pitch.", "references": ["T. Bartenstein and Y. D. Liu. Rate types for stream programs. In A. P. Black and T. D. Millstein, editors, Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages & Applications, OOPSLA 2014, part of SPLASH 2014, Portland, OR, USA, October 20-24, 2014, pages 213––232. ACM, 2014.", "P. Caspi. Clocks in dataflow languages. Theoretical Computer Science, 94:125–140, 1992.", "P. Caspi and M. Pouzet. Lucid Synchrone, a functional extension of Lustre. Technical report, Université Pierre et Marie Curie, Laboratoire LIP6, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808083.2808086"}, {"title": "BPM Maturity Models: A Qualitative Study under the Perspective of Specialists", "authors": ["Simone Nunes da Nobrega\n,", "Joyce Aline Oliveira\n,", "Rodrigo Reboucas"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe adoption of Business Process Management requires organizational, technological and cultural change hat must continually evolve to achieve the advantages offered by this approach. Maturity models help in the evolution of BPM by proposing guidelines and techniques that seek to evaluate the actual status of the initiative for achieving a higher level. The variety of existing models motivated the identification of distinctions and similarities through an analysis of documents proponents of the models. The analysis was complemented with the perception of specialists about the theme. It was concluded that the maturity models proposed by Rosemann and De Bruim and the OMG are, theoretically, the most complete, intuitive and easy to use compared with others researched models. It was highlighted yet that a maturity model needs to be objective, clear and simple to effectively evaluate the BPM maturity of an organization.", "references": ["ABPMP. BPM CBOK - Guide to the Business Process Management Common Body of Knowledge. Versão 2. 2009.", "Baldan, Roquemar de Lima. (2007) \"Gerenciamento de processos de negócios: BPM - Business Process Managment.\"", "Baldan, Roquemar; Valle, R; PEREIRA, H; Hilst, S; Abreu, M; Sobral, V.(2007) \"Gerenciamento de Processos de Negócio: BPM - Business Process Management\", p. 239."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814171"}, {"title": "Entity Matching across Heterogeneous Sources", "authors": ["Yang Yang\n,", "Yizhou Sun\n,", "Jie Tang\n,", "Bo Ma\n,", "Juanzi Li"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nGiven an entity in a source domain, finding its matched entities from another (target) domain is an important task in many applications. Traditionally, the problem was usually addressed by first extracting major keywords corresponding to the source entity and then query relevant entities from the target domain using those keywords. However, the method would inevitably fails if the two domains have less or no overlapping in the content. An extreme case is that the source domain is in English and the target domain is in Chinese.\nIn this paper, we formalize the problem as entity matching across heterogeneous sources and propose a probabilistic topic model to solve the problem. The model integrates the topic extraction and entity matching, two core subtasks for dealing with the problem, into a unified model. Specifically, for handling the text disjointing problem, we use a cross-sampling process in our model to extract topics with terms coming from all the sources, and leverage existing matching relations through latent topic layers instead of at text layers. Benefit from the proposed model, we can not only find the matched documents for a query entity, but also explain why these documents are related by showing the common topics they share. Our experiments in two real-world applications show that the proposed model can extensively improve the matching performance (+19.8% and +7.1% in two applications respectively) compared with several alternative methods.", "references": ["E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic blockmodels. JMLR, 9:1981--2014, 2008.", "K. Barnard, P. Duygulu, D. Forsyth, N. De Freitas, D. Blei, and M. Jordan. Matching words and pictures. JMLR, 3:1107--1135, 2003.", "K. Bellare, S. Iyengar, A. G. Parameswaran, and V. Rastogi. Active sampling for entity matching. In KDD'12, pages 1131--1139. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783353"}, {"title": "Automatic generation of Japanese traditional funny scenario from web content based on web intelligence", "authors": ["Ryo Mashimo\n,", "Tomohiro Umetani\n,", "Tatsuya Kitamura\n,", "Akiyo Nadamoto"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nToday there is much information and knowledge on the internet, and many studies have examined the extraction of many kinds of knowledge from the internet. In addition, numerous studies have examined entertainment robots that communicate with people, but it is difficult for robots to communicate smoothly with people. We specifically examine communication between robots based on dialogue. Here, we create a dialogue-based scenario for the robots to undertake automatically, but it is difficult because the dialogue requires knowledge of many kinds. We consider the use of the knowledge from the web and create scenarios automatically. As described herein, we propose a system that generates dialogue scenarios automatically from web news articles in real time. We used the Manzai metaphor, which is Japanese traditional humorous comedy in our system. Our generated Manzai scenario consists of snappy patter and a misunderstanding dialogue based on the gap of our structure of funny points. We create communication robots to amuse people with our generated humorous robot dialogue scenarios.", "references": ["T. Abe. Dynamism in manzai. Bulletin of the Graduate Division of Letters, Arts and Sciences of Waseda University. III, Japanese literature, theatre and film arts, history of fine arts, Japanese language and culture, pages 69--79, 2006.", "F. Bouchet and J.-P. Sansonnet. Persuading users through counseling dialogue with a conversational agent. In Proceedings of the 4th International Conference on Persuasive Technology, Persuasive 2009, pages 1--8. ACM, 2009.", "F. Bouchet and J.-P. Sansonnet. Subjectivity and cognitive biases modeling for a realistic and efficient assisting conversational agent. In Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2009, pages 209--216. IET, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837232"}, {"title": "MemScope: Analyzing Memory Duplication on Android Systems", "authors": ["Byeoksan Lee\n,", "Seong Min Kim\n,", "Eru Park\n,", "Dongsu Han"], "publication": "APSys '15: Proceedings of the 6th Asia-Pacific Workshop on Systems", "abstract": "ABSTRACT\nMain memory is one of the most important and valuable resources in mobile devices. While resource efficiency, in general, is important in mobile computing where programs run on limited battery power and resources, managing main memory is especially critical because it has a significant impact on user experience. However, there is mounting evidence that Android systems do not utilize main memory efficiently, and actually cause page-level duplications in the physical memory. This paper takes the first step in accurately measuring the level of memory duplication and diagnosing the root cause of the problem. To this end, we develop a system called MemScope that automatically identifies and measures memory duplication levels for Android systems. It identifies which memory segment contains duplicate memory pages by analyzing the page table and the memory content. We present the design of MemScope and our preliminary evaluation. The results show that 10 to 20% of memory pages used by applications are redundant. We identify several possible causes of the problem.", "references": ["Android Developer's Guide, Android Debug Bridge. http://developer.android.com/tools/help/adb.html, Retrieved March 1st, 2011.", "Android Developer's Guide, Managing Your App's Memory. https://developer.android.com/training/articles/memory.html, Retrieved January, 2014.", "Average memory usage for google play app categories. http://devsbuild.it/content/Average-Memory-Usage-Google-Play-App-Categories."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797022.2797023"}, {"title": "The RMap Project: Capturing and Preserving Associations amongst Multi-Part Distributed Publications", "authors": ["Karen L. Hanson\n,", "Tim DiLauro\n,", "Mark Donoghue"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe goal of the RMap Project is to create a prototype service that can capture and preserve maps of relationships amongst the increasingly distributed components (article, data, software, workflow objects, multimedia, etc.) that comprise the new model for scholarly publication. The demonstration will provide a tour of some of the features of the initial web service prototype. This will include examples of Distributed Scholarly Complex Objects (DiSCOs) and associated provenance data in RMap, as well as some of the options that users might have for interacting with the framework.", "references": ["Berners-Lee, T., Hendler, J., and Lassila, O. (2001). The semantic web. Scientific American, 284(5), 28--37.", "Fielding, R. T. 2000. \"Architectural Styles and the Design of Network-based Software Architectures\". Dissertation. University of California, Irvine. Retrieved 26 January 2015 from https://www.ics.uci.edu/~fielding/pubs/dissertation/fielding_dissertation.pdf", "Lavoie, B., Childress, E., Erway, R., Faniel, I., Malpas, C., Schaffner, J., and van der Werf, Titia. 2014. The Evolving Scholarly Record. Dublin, Ohio: OCLC Research. Retrieved 26 January 2015 from http://www.oclc.org/content/dam/research/publications/library/2014/oclcresearch-evolving-scholarly-record-2014.pdf"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756952"}, {"title": "Rank aggregation with ties: experiments and analysis", "authors": ["Bryan Brancotte\n,", "Bo Yang\n,", "Guillaume Blin\n,", "Sarah Cohen-Boulakia\n,", "Alain Denise\n,", "Sylvie Hamel"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe problem of aggregating multiple rankings into one consensus ranking is an active research topic especially in the database community. Various studies have implemented methods for rank aggregation and may have come up with contradicting conclusions upon which algorithms work best. Comparing such results is cumbersome, as the original studies mixed different approaches and used very different evaluation datasets and metrics. Additionally, in real applications, the rankings to be aggregated may not be permutations where elements are strictly ordered, but they may have ties where some elements are placed at the same position. However, most of the studies have not considered ties.\nThis paper introduces the first large scale study of algorithms for rank aggregation with ties. More precisely, (i) we review rank aggregation algorithms and determine whether or not they can handle ties; (ii) we propose the first implementation to compute the exact solution of the Rank Aggregation with ties problem; (iii) we evaluate algorithms for rank aggregation with ties on a very large panel of both real and carefully generated synthetic datasets; (iv) we provide guidance on the algorithms to be favored depending on dataset features.", "references": ["N. Ailon. Aggregation of partial rankings, p-ratings and top-m lists. Algorithmica, 57(2):284--300, 2010.", "N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: ranking and clustering. Journal of the ACM (JACM), 55(5):23, 2008.", "A. Ali and M. Meilă. Experiments with kemeny ranking: What works when? Mathematical Social Sciences, 64(1):28--40, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809982"}, {"title": "Flickr group recommendation via heterogeneous information networks", "authors": ["Yueyang Wang\n,", "Yuanfang Xia\n,", "Siliang Tang\n,", "Fei Wu\n,", "Yueting Zhuang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nAs an important characteristic of social media (i.e. Flickr or Facebook), user communities or groups are beginning to attract increasing attention. Most of the previous studies on group recommendation only consider a homogeneous relationship, such as the rating of users to groups in social network. In real world, each group has its textual descriptions (e.g. the \"Sky & Cloud\" group in Flickr), and the describing words about a given group may mention particular entities as well as their belonging categories (e.g. \"Nature\"). In fact, the group recommendation can be conducted in a heterogeneous information network, where informative cues are in general multi-typed. Motivated by the assumption that different types of relationships in heterogeneous information network can be potentially used to boost the performance of the group recommendation. We propose to combine heterogeneous relationship information for users with implicit user feedback. In general, the group recommendation in this paper is formulated as a non-negative matrix factorization (NMF) method regularized with user-user similarity via heterogeneous information networks. Experiments show that our proposed approach outperforms other counterpart recommendation techniques.", "references": ["C. Basu, H. Hirsh, W. Cohen, et al. Recommendation as classification: Using social and content-based information in recommendation. In AAAI/IAAI, pages 714--720, 1998.", "D. Cai, X. He, J. Han, and T. S. Huang. Graph regularized nonnegative matrix factorization for data representation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 33(8):1548--1560, 2011.", "L. Chen, Y. Wang, T. Liang, L. Ji, and J. Wu. Data augmented maximum margin matrix factorization for flickr group recommendation. In Advances in Knowledge Discovery and Data Mining, pages 473--484. Springer, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808512"}, {"title": "A Study of Distinctiveness in Web Results of Two Search Engines", "authors": ["Rakesh Agrawal\n,", "Behzad Golshan\n,", "Evangelos Papalexakis"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nGoogle and Bing have emerged as the diarchy that arbitrates what documents are seen by Web searchers, particularly those desiring English language documents. We seek to study how distinctive are the top results presented to the users by the two search engines. A recent eye-tracking has shown that the web searchers decide whether to look at a document primarily based on the snippet and secondarily on the title of the document on the web search result page, and rarely based on the URL of the document. Given that the snippet and title generated by different search engines for the same document are often syntactically different, we first develop tools appropriate for conducting this study. Our empirical evaluation using these tools shows a surprising agreement in the results produced by the two engines for a wide variety of queries used in our study. Thus, this study raises the open question whether it is feasible to design a search engine that would produce results distinct from those produced by Google and Bing that the users will find helpful.", "references": ["D. Antoniades, I. Polakis, G. Kontaxis, E. Athanasopoulos, S. Ioannidis, E. P. Markatos, and T. Karagiannis. we.b: The web of short URLs. In 20th international conference on World Wide Web, pages 715--724. ACM, 2011.", "B. W. Bader and T. G. Kolda. Matlab tensor toolbox version 2.2. Albuquerque, NM, USA: Sandia National Laboratories, 2007.", "J. Bar-Ilan. Search engine ability to cope with the changing web. In Web dynamics, pages 195--215. Springer, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743060"}, {"title": "Face recognition using nonlinear locality preserving with deep networks", "authors": ["Ying Wang\n,", "Peng Fei\n,", "Xin Fan\n,", "Haojie Li"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nWe address the challenges in automatic face recognition (AFR) applications when probe images present multiple variations including pose and resolution changes. Existing approaches attempt to seek a common feature space shared by these variations through linear or local linear mappings. In this paper, we leverage deep learning as a natural feature representation to discover intrinsic nonlinear relationships between images of multiple variations. Our method also extends the locality preserving projection (LPP) with nonlinear mappings learned through optimizing the objective function that preserves local neighboring structures between couterpart images. We perform the experiments on images from several available databases where only one frontal upright image presents in the gallery and variations on pose and resolution appear in the probe. The experiments show the superior recognition rates of our approach over the latest linear (or locally linear) methods.", "references": ["The ORL Face Database {Online}. Available: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html.", "A. F. Abate, M. Nappi, D. Riccio, and G. Sabatino. 2D and 3D face recognition: A survey. Pattern Recognition Letters, 28(14): 1885--1906, 2007.", "T. Ahonen, A. Hadid, and M. Pietikainen. Face recognition with local binary patterns. In Proc. of ECCV, pages 469--481, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808558"}, {"title": "Intelligent contextual data stream monitoring", "authors": ["Kostas Kolomvatsos\n,", "Christos Anagnostopoulos\n,", "Stathes Hadjiefhtymiades"], "publication": "PETRA '15: Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments", "abstract": "ABSTRACT\nContextual data monitoring plays an important role in increasing the quality of life of humans. Sensors observing specific activities report contextual data to a central system capable of situational reasoning. The system responds to any event related to the observed phenomenon. We propose an intelligent mechanism that builds on top of sensors measurements and derives the appropriate decisions for immediate identification of events. The mechanism adopts multivariate data fusion, time-series prediction, and consensus theory for aggregating measurements. We adopt Fuzzy Logic for handling the induced uncertainty in the decision making on the derived alerts. Simulations over real contextual data showcase the advantages and disadvantages of our monitoring mechanism.", "references": ["Banae, H., et al. 'Data Mining for Wearable Sensors in Helath MonitoringSystems: A Review of Recent Trends and Challenges', Sensors, vol. 13, 2013.", "Banos, O., et al., 'mHealthDroid: a novel framework for agile development of mobile health applications', In 6th IWAAL, 2014.", "Bauer, P., et al., 'The mobile patient: wireless distributed sensor networks for patient monitoring and care', IEEE Int. Conf. on Information Technology Applications in Biomedicine, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2769493.2769568"}, {"title": "An Overview of Microsoft Academic Service (MAS) and Applications", "authors": ["Arnab Sinha\n,", "Zhihong Shen\n,", "Yang Song\n,", "Hao Ma\n,", "Darrin Eide\n,", "Bo-June (Paul) Hsu\n,", "Kuansan Wang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: field of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees significant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.", "references": ["Google inclusion guidelines. In http://www.google.com/intl/en/scholar/inclusion.html#indexing.", "Microsoft academic data. In http://datamarket.azure.com/dataset/mrc/microsoftacademic, November 2013.", "A. Acharya, A. Verstak, H. Suzuki, S. Henderson, M. Iakhiaev, C. C. Lin, and N. Shetty. Rise of the rest: The growing impact of non-elite journals. CoRR, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742839"}, {"title": "Towards a Formal Framework for Utility-oriented Measurements of Retrieval Effectiveness", "authors": ["Marco Ferrante\n,", "Nicola Ferro\n,", "Maria Maistro"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn this paper we present a formal framework to define and study the properties of utility-oriented measurements of retrieval effectiveness, like AP, RBP, ERR and many other popular IR evaluation measures. The proposed framework is laid in the wake of the representational theory of measurement, which provides the foundations of the modern theory of measurement in both physical and social sciences, thus contributing to explicitly link IR evaluation to a broader context. The proposed framework is minimal, in the sense that it relies on just one axiom, from which other properties are derived. Finally, it contributes to a better understanding and a clear separation of what issues are due to the inherent problems in comparing systems in terms of retrieval effectiveness and what others are due to the expected numerical properties of a measurement.", "references": ["M. Angelini, N. Ferro, G. Santucci, and G. Silvello. VIRTUE: A visual tool for information retrieval performance evaluation and failure analysis. JVLC, 25(4):394--413, 2014.", "E. Amigó, J. Gonzalo, J. Artiles, and M. F. Verdejo. A comparison of extrinsic clustering evaluation metrics based on formal constraints. IR, 12(4):461--486, 2009.", "E. Amigó, J. Gonzalo, and M. F. Verdejo. A General Evaluation Measure for Document Organization Tasks. In SIGIR 2013, pp. 643--652."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809452"}, {"title": "Image Profiling for History Events on the Fly", "authors": ["Jia Chen\n,", "Qin Jin\n,", "Yong Yu\n,", "Alexander G. Hauptmann"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nHistory event related knowledge is precious and imagery is a powerful medium that records diverse information about the event. In this paper, we propose to automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements. Such a simple input requirement makes our solution easy to scale up and support a wide range of culture preservation and curation related applications ranging from wikipedia enrichment to history education. However, history relevant information on the web is available as \"wild and dirty\" data, which is quite different from clean, manually curated and structured information sources. There are two major challenges to build our proposed image profiles: 1) unconstrained image genre diversity. We categorize images into genres of documents/maps, paintings or photos. Image genre classification involves a full-spectrum of features from low-level color to high-level semantic concepts. 2) image content diversity. It can include faces, objects and scenes. Furthermore, even within the same event, the views and subjects of images are diverse and correspond to different facets of the event. To solve this challenge, we group images at two levels of granularity: iconic image grouping and facet image grouping. These require different types of features and analysis from near exact matching to soft semantic similarity. We develop a full-range feature analysis module which is composed of several levels, each suitable for different types of image analysis tasks. The wide range of features are based on both classical hand-crafted features and different layers of a convolutional neural network. We compare and study the performance of the different levels in the full-range features and show their effectiveness on handling such a wild, unconstrained dataset.", "references": ["B-25 empire state building crash. http://en.wikipedia.org/wiki/B-25_Empire_State_Building_crash.", "Victor hugo quotes. http://www.brainyquote.com/quotes/quotes/v/victorhugo385868.html.", "O. Chum and J. Matas. Optimal randomized RANSAC. IEEE Trans. Pattern Anal. Mach. Intell., 30(8):1472--1482, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806242"}, {"title": "On Skewed Distributions and Straight Lines: A Case Study on the Wiki Collaboration Network", "authors": ["Osnat Mokryn\n,", "Alexey Reznik"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nIn this paper, we present a hypothesis that power laws are found only in datasets sampled from a static data, in which each and every item has gained its maximal importance and is not in the process of changing it during the sampling period. We motivate our hypothesis by examining languages, and word-ranking distribution as it appears in books, and in the Bible. To demonstrate the validity of our hypothesis, we experiment with the Wikipedia edit collaboration network. We find that the dataset fits a skewed distribution. Next, we identify its dynamic part. We then show that when the modified part is removed from the obtained dataset, the remaining static part exhibits a good fit to a power law distribution.", "references": ["M. Faloutsos, P. Faloutsos, and C. Faloutsos, \"On power-law relationships of the internet topology,\" in ACM SIGCOMM Computer Communication Review, 1999, vol. 29, no. 4, pp. 251--262.", "L. A. Adamic and B. A. Huberman, \"Power-law distribution of the world wide web,\" Science (80-. )., vol. 287, no. 5461, p. 2115, 2000.", "Z. Bi, C. Faloutsos, and F. Korn, \"The DGX distribution for mining massive, skewed data,\" in Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, 2001, pp. 17--26."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2744716"}, {"title": "Provenance-Driven Data Curation Workflow Analysis", "authors": ["Tianhong Song"], "publication": "SIGMOD '15 PhD Symposium: Proceedings of the 2015 ACM SIGMOD on PhD Symposium", "abstract": "ABSTRACT\nManually designed workflows can be error-prone and inefficient. Workflow provenance contains fine-grained data processing information that can be used to detect workflow design problems. In this paper, we propose a provenance-driven workflow analysis framework that exploits both prospective and retrospective provenance. We show how provenance information can help the user gain a deeper understanding of a workflow and provide the user with insights into how to improve workflow design.", "references": ["Barker, A. and Hemert, J. Van Scientific workflow: a survey and research directions. Parallel Processing and Applied Mathematics. (2008), 746--753.", "Batini, C. and Scannapieco, M. Data quality: concepts, methodologies and techniques. Springer, 2006.", "Bowers, S. Scientific Workflow, Provenance, and Data Modeling Challenges and Approaches. Journal on Data Semantics. 1, 1 (Apr. 2012), 19--30."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744680.2744691"}, {"title": "Deep Semantic Frame-Based Deceptive Opinion Spam Analysis", "authors": ["Seongsoon Kim\n,", "Hyeokyoon Chang\n,", "Seongwoon Lee\n,", "Minhwan Yu\n,", "Jaewoo Kang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUser-generated content is becoming increasingly valuable to both individuals and businesses due to its usefulness and influence in e-commerce markets. As consumers rely more on such information, posting deceptive opinions, which can be deliberately used for potential profit, is becoming more of an issue. Existing work on opinion spam detection focuses mainly on linguistic features such as n-grams, syntactic patterns, or LIWC. However, deep semantic analysis remains largely unstudied. In this paper, we propose a frame-based deep semantic analysis method for understanding rich characteristics of deceptive and truthful opinions written by various types of individuals including crowdsourcing workers, employees who have expert-level domain knowledge about local businesses, and online users who post on Yelp and TripAdvisor. Using our proposed semantic frame feature, we developed a classification model that outperforms the baseline model and achieves an accuracy of nearly 91%. Also, we performed qualitative analysis of deceptive and truthful review datasets and considered their semantic differences. Finally, we successfully found some interesting features that existing methods were unable to identify.", "references": ["2013 study: 79% of consumers trust online reviews as much as personal recommendations, \"http://searchengineland.com/2013-study-79-of-consumers-trust-online-reviews-as-much-as-personal-recommendations-164565\". Accessed: 2015-04-05.", "A. A. Benczur, K. Csalogany, T. Sarlos, and M. Uher. Spamrank--fully automatic link spam detection work in progress. In Proceedings of the first international workshop on adversarial information retrieval on the web, AIRWeb '05, Chiba, Japan, 2005.", "C. Castillo, D. Donato, A. Gionis, V. Murdock, and F. Silvestri. Know your neighbors: Web spam detection using the web topology. In Proceedings of SIGIR, Amsterdam, Netherlands, July 2007. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806551"}, {"title": "A Tool for Searching in Unstructured Code AspectJ", "authors": ["Rodrigo Castro Gil\n,", "Eduardo Kessler Piveta\n,", "Deise de Brum Saccol\n,", "Cristiano de Faveri"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nWith the increasing size of information systems and their complexity and the limitations that currently have available the IDEs for more complex searches in source code, tools that can help software developers in the retrieval of relevant information becomes very useful . In this context, this paper presents a tool that enables the retrieval, informations in AspectJ code in an unstructured way. This tool allows you to search the structures using only the syntactic value of the query or adding semantic value and thereby improving their results.", "references": ["R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1999.", "S. Basu. Ohloh. http://www.makeuseof.com/tag/open-source-matters-6-source-code-search-engines-you-can-use-for-programming-projects/, 2013. Acessado em Outubro/2013.", "D. Bielik and S. Sonnes. Nerdydata. http://nerdydata.com/, 2013. Acessado em Dezembro/2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814066"}, {"title": "iCrowd: An Adaptive Crowdsourcing Framework", "authors": ["Ju Fan\n,", "Guoliang Li\n,", "Beng Chin Ooi\n,", "Kian-lee Tan\n,", "Jianhua Feng"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nCrowdsourcing is widely accepted as a means for resolving tasks that machines are not good at. Unfortunately, Crowdsourcing may yield relatively low-quality results if there is no proper quality control. Although previous studies attempt to eliminate \"bad\" workers by using qualification tests, the accuracies estimated from qualifications may not be accurate, because workers have diverse accuracies across tasks. Thus, the quality of the results could be further improved by selectively assigning tasks to the workers who are well acquainted with the tasks. To this end, we propose an adaptive crowdsourcing framework, called iCrowd. iCrowd on-the-fly estimates accuracies of a worker by evaluating her performance on the completed tasks, and predicts which tasks the worker is well acquainted with. When a worker requests for a task, iCrowd assigns her a task, to which the worker has the highest estimated accuracy among all online workers. Once a worker submits an answer to a task, iCrowd analyzes her answer and adjusts estimation of her accuracies to improve subsequent task assignments. This paper studies the challenges that arise in iCrowd. The first is how to estimate diverse accuracies of a worker based on her completed tasks. The second is instant task assignment. We deploy iCrowd on Amazon Mechanical Turk, and conduct extensive experiments on real datasets. Experimental results show that iCrowd achieves higher quality than existing approaches.", "references": ["http://crowdflower.com/.", "Amazon Mechanical Turk. https://www.mturk.com.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. Knowl. Data Eng., 17(6):734--749, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2750550"}, {"title": "HbbTV goes Cloud: Decoupling Application Signaling and Application Execution in Hybrid TV", "authors": ["Alexandra Mikityuk\n,", "Oliver Friedrich\n,", "Randolph Nikutta"], "publication": "TVX '15: Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video", "abstract": "ABSTRACT\nThe cloud-based execution of the User Interface has already begun to disrupt the TV domain. Indeed, in European Hybrid TV Standard - Hybrid Broadcast Broadband (HbbTV) - the signaling of applications is terminated by special libraries on the client. Therefore, the cloud-based UI execution does directly affect the HbbTV. This work presents an architecture that enables the shift of HbbTV functionality into the Cloud. This is based on the decoupling of HbbTV application signaling and application execution on the client side. The shift is executed by defining new interfaces for HbbTV-to-cloud and cloud-to-device. This work describes possible approaches for such architectures, relevant open issues and corresponding challenges.", "references": ["David Dorwin, Adrian Bateman and Mark Watson. W3C Editor's Draft - Encrypted Media Extensions., 2014.", "DVB. Signalling and carriage of interactive applications and services in Hybrid broadcast/broadband environments (TS 102 809 V1.1.1), Jan. 2010.", "EUROMEDIA Magazine. STB and Home Gateway Survey. http://irdeto.com/documents/Articles/art_ euromedia-magazine_JulAug_2014.pdf, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745197.2755523"}, {"title": "Software Processes Improvement in light of Cognitive Biases: A Cross-Case Analysis", "authors": ["Jose Adson O. G. da Cunha\n,", "Jose Jorge L. Dias\n,", "Livia Maria R. de V. Cunha\n,", "Hermano Perrelli de Moura"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nWhen making judgments, people rely on heuristics or \"shortcuts\" that can lead them to good solutions. In certain situations, however, these techniques can cause inconsistencies and promote cognitive biases. Referring to software processes improvement initiatives, it is important that the practices, techniques, methods and tools suggested for the processes provide mechanisms to support decision-making, thus minimizing the negative effects of such biases. This paper, based on a qualitative research applied in two IT companies in Brazil and Portugal, aims to examine eight biases: anchoring bias, exposure effect, hindsight bias, halo effect, planning fallacy, sunk-cost fallacy, availability-related bias, and Parkinson's law effect. Through semi-structured interviews with project managers (PMs), roots causes were identified for each bias, as well as methods and tools used to minimize its negative effects, which were consolidated into a concepts map. Agile practices and knowledge management activities were cited as essential in software processes focusing on decision-making improvement.", "references": ["Rezende, D. A. 2005. Engenharia de software e sistemas de informação. 3 ed. Rio de Janeiro: Brasport.", "Damian, D. E. and Zowghi, D. 2003. RE challenges in multisite software development organisations. Requirements engineering 8, 3, 149-160.", "Mens, T. 2008. Introduction and roadmap: History and challenges of software evolution. Springer Berlin Heidelberg."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814100"}, {"title": "Efficient indexing for large-scale image search", "authors": ["Shiliang Zhang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn content-based image retrieval, inverted indexes allow fast access to database images and summarize all knowledge about the database. Indexing multiple clues of image contents allows retrieval algorithms search for relevant images from different perspectives, which is appealing to deliver satisfactory user experiences. However, when incorporating diverse image features during online retrieval, it is challenging to ensure retrieval efficiency and scalability. Besides that, most of current image indexing systems for retrieval view database as a set of individual images. It limits the flexibility of the retrieval framework to conduct sophisticated cross image analysis, resulting in higher memory consumption and sub-optimal retrieval accuracy. To conquer these two issues and achieve highly efficient indexing system, we propose a semantic-aware co-indexing algorithm to jointly embed multiple cues into the inverted indexes and a cross indexing strategy to group highly relevant image together. In this talk, these two algorithms will be introduced. A real-time large-scale image search system built on these algorithms will also be presented.", "references": ["Large scale visual recognition challenge. http://www.image-net.org/challenges/LSVRC/2010, 2010.", "R. Fagin, R. Kumar, and D. Sivakumar. Efficient similarity search and classification via rank aggregation. In ACM SIGMOD, 2003.", "A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808578"}, {"title": "Data Center Energy Efficiency Standards in India", "authors": ["Sanyukta Raje\n,", "Hemant Maan\n,", "Suprotim Ganguly\n,", "Tanvin Singh\n,", "Nisha Jayaram\n,", "Girish Ghatikar\n,", "Steve Greenberg\n,", "Satish Kumar\n,", "Dale Sartor"], "publication": "e-Energy '15: Proceedings of the 2015 ACM Sixth International Conference on Future Energy Systems", "abstract": "ABSTRACT\nGlobal data center energy consumption is growing rapidly. In India, information technology industry growth, fossil-fuel generation, and rising energy prices add significant operational costs and carbon emissions from energy-intensive data centers. Adoption of energy-efficient practices can improve the global competitiveness and sustainability of data centers in India. Previous studies have concluded that advancement of energy efficiency standards through policy and regulatory mechanisms is the fastest path to accelerate the adoption of energy-efficient practices in the Indian data centers. In this study, we reviewed data center energy efficiency practices in the United States, Europe, and Asia. Using evaluation metrics, we identified an initial set of energy efficiency standards applicable to the Indian context using the existing policy mechanisms. These preliminary findings support next steps to recommend energy efficiency standards and inform policy makers on strategies to adopt energy-efficient technologies and practices in Indian data centers.", "references": ["National Resources Defence Council. 2014. Data Center Efficiency Assessment.", "NASSCOM. 2012. Data Center Landscape in India.", "Whitney, P. D. Josh. 2014. Data Center Efficiency Assessment. NRDC."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2768510.2768524"}, {"title": "Leveraging Procedural Knowledge for Task-oriented Search", "authors": ["Zi Yang\n,", "Eric Nyberg"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMany search engine users attempt to satisfy an information need by issuing multiple queries, with the expectation that each result will contribute some portion of the required information. Previous research has shown that structured or semi-structured descriptive knowledge bases (such as Wikipedia) can be used to improve search quality and experience for general or entity-centric queries. However, such resources do not have sufficient coverage of procedural knowledge, i.e. what actions should be performed and what factors should be considered to achieve some goal; such procedural knowledge is crucial when responding to task-oriented search queries. This paper provides a first attempt to bridge the gap between two evolving research areas: development of procedural knowledge bases (such as wikiHow) and task-oriented search. We investigate whether task-oriented search can benefit from existing procedural knowledge (search task suggestion) and whether automatic procedural knowledge construction can benefit from users' search activities (automatic procedural knowledge base construction). We propose to create a three-way parallel corpus of queries, query contexts, and task descriptions, and reduce both problems to sequence labeling tasks. We propose a set of textual features and structural features to identify key search phrases from task descriptions, and then adapt similar features to extract wikiHow-style procedural knowledge descriptions from search queries and relevant text snippets. We compare our proposed solution with baseline algorithms, commercial search engines, and the (manually-curated) wikiHow procedural knowledge; experimental results show an improvement of +0.28 to +0.41 in terms of Precision@8 and mean average precision (MAP).", "references": ["A. Addis and D. Borrajo. From unstructured web knowledge to plan descriptions. In DART'2009, volume 324, pages 41--59, 2011.", "J. R. Anderson. Cognitive psychology and its implications . WH Freeman/Times Books/Henry Holt & Co, 1990.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In Proceedings of EDBT'2004, pages 588--596, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767744"}, {"title": "Finding prophets in the blogosphere: bloggers who predicted buzzwords before they become popular", "authors": ["Jianwei Zhang\n,", "Seiya Tomonaga\n,", "Shinsuke Nakajima\n,", "Yoichi Inagaki\n,", "Reyn Nakamoto"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nIdentifying important users from social media has recently attracted much attention in information and knowledge management community. Although researchers have focused on users' knowledge levels on certain topics or influence degrees on other users in social networks, previous works have not studied users' prediction ability on future popularity. In this paper, we propose a novel approach to find important bloggers based on their buzzword prediction ability. We conduct a time-series analysis in the blogosphere considering four factors: post earliness, content similarity, entry frequency and buzzword coverage. We perform preparatory work in categorizing a blogger into knowledgeable categories, identifying past buzzwords, analyzing a buzzword's peak time content and growth period, and finally evaluate a blogger's prediction ability on a buzzword and on a category. Experimental results on real-world blog data consisting of 150 million entries from 11 million bloggers demonstrate that the proposed approach can find prophetic bloggers and outperforms others that do not take temporal features into account.", "references": ["S. Nakajima, J. Zhang, Y. Inagaki, T. Kusano and R. Nakamoto: Blog Ranking Based on Bloggers' Knowledge Level for Providing Credible Information. In WISE 2009: 227--234.", "K. W. Church, P. Hanks: Word Association Norms, Mutual Information, and Lexicography. Computational Linguistics, 16(1) (1990): 22--29.", "A. Kilgarriff, D. Tugwell: Sketching words. Lexicography and Natural Language Processing: A Festschrift in Honour of B. T. S. Atkins., (2002): 125--137."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837188"}, {"title": "A Novel Machine Learning Data Preprocessing Method for Enhancing Classification Algorithms Performance", "authors": ["Theodoros Iliou\n,", "Christos-Nikolaos Anagnostopoulos\n,", "Marina Nerantzaki\n,", "George Anastassopoulos"], "publication": "EANN '15: Proceedings of the 16th International Conference on Engineering Applications of Neural Networks (INNS)", "abstract": "ABSTRACT\nData preprocessing describes any type of processing methods performed on raw data to prepare it for another processing procedure. Commonly used as a preliminary data mining practice, data preprocessing methods transforms the data into a format that will be more easily and effectively processed for the classification algorithms. In this paper, a novel data preprocessing method is proposed and evaluated in three difficult classification data sets of the well known UCI Repository, in which various classifiers have average performance lower than 75%. The three UCI repository datasets that have been used are the Mammographic masses, Indian Liver and Contraceptive Method. The performance of our proposed data preprocessing method and Principal Component Analysis preprocessing method was evaluated using the 10-fold cross validation method assessing five classification algorithms, Nearest-neighbour classifier (IB1), C4.5 algorithm implementation (J48), Random Forest, Multilayer Perceptron and Rotation Forest, respectively. The classification results are presented and compared analytically. The results indicate that the generated features after our proposed preprocessing method implementation to the original dataset markedly improve the performance of the classification algorithms.", "references": ["I. H. Witten, E. Frank, M. Hall, A. Mark, Data Mining: Practical Machine Learning Tools and Techniques (3 ed.), Elsevier, 2011, ISBN 978-0-12-374856-0.", "S. B. Kotsiantis, D. Kanellopoulos, and P. E. Pintelas, \"Data Preprocessing for Supervised Leaning\", World Academy of Science, Engineering and Technology, vol. 1, 2007, pp. 856--861.", "https://archive.ics.uci.edu/ml/about.html, {Accessed 10 May 2015}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797143.2797155"}, {"title": "Analysis of Profile and Role from Business Analysts in National Context", "authors": ["Viviane Cortese Zadra\n,", "Josiane Brietzke Porto"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn Business Process Management understanding the profile and the role of the Business Analyst is important, because that professional helps an organization to identify risks and opportunities, avoids costs and realizes benefits in the business and its processes. But what are the skills required to work as a Business Analyst and the responsibilities of that role in an organization? This paper contributes to the debate on this issue, identifying and analyzing skills required, the key responsibilities of this role, through a survey carried out with Business Analysts, in the national context. From the perception of these professionals we obtained a set of the main competencies and responsibilities to act as Business Analyst and a mapping of the presence level of these skills and responsibilities in the current scenario.", "references": ["Cooper, D.; Schindler, P. 2003. Método de pesquisa em Administração, 7a ed. Porto Alegre: Bookman.", "Hair, J. F. 2005. Fundamentos de métodos de pesquisa em Administração. Porto Alegre: Bookman.", "Hoppen, N. E. 1996. Um guia para a avaliação de artigos de pesquisas em sistemas de informações. Porto Alegre: READ."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814170"}, {"title": "Optimal Packing in Simple-Family Codecs", "authors": ["Andrew Trotman\n,", "Michael Albert\n,", "Blake Burgess"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe Simple family of codecs is popular for encoding postings lists for a search engine because they are both space effective and time efficient at decoding. These algorithms pack as many integers into a codeword as possible before moving on to the next codeword. This technique is known as left-greedy. This contribution proves that left-greedy is not optimal and then goes on to introduce a dynamic programming solution to find the optimal packing. Experiments on .gov2 and INEX Wikipedia 2009 show that although this is an interesting theoretical result, left-greedy is empirically near optimal in effectiveness and efficiency.", "references": ["Anh, V. N., A. Moffat, Inverted Index Compression Using Word-Aligned Binary Codes. Information Retrieval, 8(1):151--166, 2005.", "Anh, V. N., A. Moffat, Simplified Similarity Scoring Using Term Ranks. In SIGIR 2005, pp. 226--233.", "Anh, V. N., A. Moffat, Index Compression Using 64-bit words. Software Practice & Experience, 40(2):131--147, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809483"}, {"title": "Poster: VPN Tunnels for Energy Efficient Multimedia Streaming", "authors": ["Mohammad A. Hoque\n,", "Kasperi Saarikoski\n,", "Eemil Lagerspetz\n,", "Julien Mineraud\n,", "Sasu Tarkoma"], "publication": "MobiCom '15: Proceedings of the 21st Annual International Conference on Mobile Computing and Networking", "abstract": "ABSTRACT\nMinimizing the energy consumption of mobile devices for wireless network access is important. In this article, we analyze the energy efficiency of a new set of applications which use Virtual Private Network (VPN) tunnels for secure communication. First, we discuss the energy efficiency of a number of VPN applications from a large scale deployment of 500 K devices. We next measure the energy consumption of some of these applications with different use cases. Finally, we demonstrate that a VPN tunnel can be instrumented for enhanced energy efficiency with multimedia streaming applications. Our results indicate energy savings of 40% for this class of applications.", "references": ["ICS OpenVPN, https://github.com/schwabe/ics-openvpn.", "Power Monitor, www.msoon.com.", "M. A. Hoque, M. Siekkinen, and J. K. Nurminen. Using crowd-sourced viewing statistics to save energy in wireless video streaming. In Proceedings of the 19th Annual International Conference on Mobile Computing & Networking, MobiCom '13, pages 377--388, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789168.2795168"}, {"title": "Evaluating tooth brushing performance with smartphone sound data", "authors": ["Joseph Korpela\n,", "Ryosuke Miyaji\n,", "Takuya Maekawa\n,", "Kazunori Nozaki\n,", "Hiroo Tamagawa"], "publication": "UbiComp '15: Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nThis paper presents a new method for evaluating tooth brushing performance using audio collected from a smartphone. To do this, we use hidden Markov models (HMMs) to recognize audio data that include various types of tooth brushing actions, such as brushing the outer surface of the front teeth and brushing the inner surface of the back teeth. We then use the output of the HMMs to build regression models to estimate tooth brushing performance scores, such as stroke quality of brushing for the back inner teeth and duration of brushing for the front teeth. The scores used to train these regression models are obtained from a dentist who specializes in dental care instruction, with the resulting regression models estimating performance scores that closely correspond to the scores assigned by the dentist.", "references": ["Addy, M., and Hunter, M. Can tooth brushing damage your health? effects on oral and dental tissues. International Dental Journal 53, S3 (2003), 177--186.", "Bartle, R. Bartle test of gamer psychology. gamerdna. Tech. rep., Retrieved 2010-12-08 from http://www.gamerdna.com/quizzes/bartle-test-of-gamerpsychology.", "Bartle, R. Hearts, clubs, diamonds, spades: Players who suit MUDs. Journal of MUD research 1, 1 (1996), 19."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750858.2804259"}, {"title": "Correlation analysis among the metadata-based similarity, acoustic-based distance, and serendipity of music", "authors": ["Naoki Kito\n,", "Kenta Oku\n,", "Kyoji Kawagoe"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nWith the aim of realizing a serendipity-oriented music recommendation, we analyzed the correlation between music similarity and serendipity. A user may be familiar with the musical piece if its metadata, such as the artist's names, and the title, is similar to the music he/she has ever listened to. In addition, a user may prefer the music if it is acoustically similar to the music he/she prefers. Based on these notions, we set up the following hypotheses: Hypothesis I: the user is familiar with the music is if the metadata-based similarity between it and the music he/she prefers is high. Hypothesis II: the music is preferred by the user if the acoustic-based distance between it and the music he/she prefers is low. Hypothesis III: the music is serendipitous (unexpected and useful) if the music has both a low metadata-based similarity and low acoustic-based distance with his/her preferred music. This paper presents our examination of the above hypotheses using data from 1,000 real musical recording.", "references": ["D. Bogdanov, M. Haro, F. Fuhrmann, E. Gomez, and P. Herrera, Content-based music recommendation based on user preference examples Categories and Subject Descriptors, in Womrad 2010: The 4th ACM Conference on Recommender Systems. Workshop on Music Recommendation and Discovery, 2010.", "B. Logan and A. Salomon, A Content-Based Music Similarity Function, 2001.", "M. Levy and M. Sandler. Music information retrieval using social tags and audio. IEEE Transactions on Multimedia, 11(3):383--395, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790786"}, {"title": "PVSS: portable visual search service for researchers", "authors": ["Siriwat Kasamwattanarote\n,", "Shin'ichi Satoh"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nImage retrieval researchers aim to build good algorithms and devise methods to produce accurate ranked lists. However, the search results themselves appear rather repetitious, and the experience of viewing them is akin to listening to the same song 100 times a day. Imagine a better search in which the researcher has a ready-to-use demonstration interface for showing his results to audiences who can interactively send image queries and see the results effortlessly; this is our aim.\nWe present a Portable Visual Search Service for a researcher who desires to make his or her algorithm appear to be as \"cool\" as the best interactive demos at image retrieval conferences. Our service is a handy package, powered by VMWare virtualization technology, that is booted and served locally within a local network on a medium-spec laptop PC. The package contains all the necessary stuff to launch an on-site demo, e.g., a database, algorithm, and libraries. Moreover, our service is accessible using standard web browsers and client architectures, e.g. PC, iPhone, iPad, and Android.\nThis interactive system has been tested together with a large database at conferences and other events. The audience of a demo/poster session was impressed by the features of our service. In this context, our service handles the user interaction with the audience and gives researchers more freedom to explain their algorithm.", "references": ["Virtualbox, http://www.virtualbox.org.", "Vmware, http://www.vmware.com.", "V. Chandrasekhar, D. M. Chen, A. Lin, G. Takacs, S. S. Tsai, N.-M. Cheung, Y. A. Reznik, R. Grzeszczuk, and B. Girod. Comparison of local feature descriptors for mobile visual search. In ICIP, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808556"}, {"title": "Membrane Computing to Model Feature Selection of Microarray Cancer Data", "authors": ["Naeimeh Elkhani\n,", "Ravie Chandren Muniyandi"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nCancer is the main public health issue in most places of the world due to the difficulties in its early diagnosis and to begin early treatment. In the recent years many techniques have been proposed to tackle the high dimensionality in cancer datasets. This paper proposed a membrane-inspired feature selection method to utilize the potentials of membrane computing features such as decentralization, non-determinism, and maximal parallel computing for feature selection of cancer data. Kernel p system- one of the variants of membrane computing- is defined based on multi objective binary particle swarm optimization feature selection method through nine steps involving definitions of objects, compartments, rules and output. Matlab software is used to model the proposed approach. The proposed model evaluated by cell line data of breast cancer with six samples of papillary infiltrating ductal carcinoma and Carcinosarcoma disease state. As the initial attempt to come out with a model, division rule and sequential computation on Matlab are used as tools to define potential of membrane computing in trading space against time computation. The evaluation results indicate the proposed model based on kernel p system computation with distributed compartments is capable in distinguishing marker genes.", "references": ["Rebecca, S., Jiemin, M., Zhaohui, Z. and Ahmedin, J. 2014. Cancer statistics. CA Cancer J. Clin, 64, 1, 9--29.", "Chiristina, A. H., Carsten, R. and Jacques, R. 2000. Monitoring gene expression using DNA microarrays. Current Opinion in Microbiology, 3, 3, 285--91.", "Geraldine, M. G., Amanda, F., Francesco, G., Michael, E., Luca, D. G. and Amy, V. M. 2004. DNA Arrays in Clinical Oncology: Promises and Challenges. Anticancer Research, 24, 441--448."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818885"}, {"title": "Quantitative Study of Music Listening Behavior in a Smartphone Context", "authors": ["Yi-Hsuan Yang\n,", "Yuan-Ching Teng"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nContext-based services have attracted increasing attention because of the prevalence of sensor-rich mobile devices such as smartphones. The idea is to recommend information that a user would be interested in according to the user’s surrounding context. Although remarkable progress has been made to contextualize music playback, relatively little research has been made using a large collection of real-life listening records collected in situ. In light of this fact, we present in this article a quantitative study of the personal, situational, and musical factors of musical preference in a smartphone context, using a new dataset comprising the listening records and self-report context annotation of 48 participants collected over 3wk via an Android app. Although the number of participants is limited and the population is biased towards students, the dataset is unique in that it is collected in a daily context, with sensor data and music listening profiles recorded at the same time. We investigate 3 core research questions evaluating the strength of a rich set of low-level and high-level audio features for music usage auto-tagging (i.e., music preference in different user activities), the strength of time-domain and frequency-domain sensor features for user activity classification, and how user factors such as personality traits are correlated with the predictability of music usage and user activity, using a closed set of 8 activity classes. We provide an in-depth discussion of the main findings of this study and their implications for the development of context-based music services for smartphones.", "references": ["N. Aharony, W. Pan, C. Ip, I. Khayal, and A. Pentland. 2011. Social fMRI: Investigating and shaping social mechanisms in the real world. Pervasive and Mobile Computing 7, 6, 643--659.", "L. Atallah and G.-Z. Yang. 2009. The use of pervasive sensing for behaviour profiling—a survey. Pervasive and Mobile Computing 5, 5, 447--464.", "D. Auguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz. 2012. Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine. In Proceedings of the International Workshop of Ambient Assisted Living. 216--223."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2738220"}, {"title": "R-Apriori: An Efficient Apriori based Algorithm on Spark", "authors": ["Sanjay Rathee\n,", "Manohar Kaul\n,", "Arti Kashyap"], "publication": "PIKM '15: Proceedings of the 8th Workshop on Ph.D. Workshop in Information and Knowledge Management", "abstract": "ABSTRACT\nAssociation rule mining remains a very popular and effective method to extract meaningful information from large datasets. It tries to find possible associations between items in large transaction based datasets. In order to create these associations, frequent patterns have to be generated. The \"Apriori\" algorithm along with its set of improved variants, which were one of the earliest proposed frequent pattern generation algorithms still remain a preferred choice due to their ease of implementation and natural tendency to be parallelized.\nWhile many efficient single-machine methods for Apriori exist, the massive amount of data available these days is far beyond the capacity of a single machine. Hence, there is a need to scale across multiple machines to meet the demands of this ever-growing data. MapReduce is a popular fault-tolerant framework for distributed applications. Nevertheless, heavy disk I/O at each MapReduce operation hinders the implementation of efficient iterative data mining algorithms, such as Apriori, on MapReduce platforms.\nA newly proposed in-memory distributed dataflow platform called Spark overcomes the disk I/O bottlenecks in MapReduce. Therefore, Spark presents an ideal platform for distributed Apriori. However, in the implementation of Apriori, the most computationally expensive task is the generation of candidate sets having all possible pairs for singleton frequent items and comparing each pair with every transaction record. Here, we propose a new approach which dramatically reduces this computational complexity by eliminating the candidate generation step and avoiding costly comparisons.\nWe conduct in-depth experiments to gain insight into the effectiveness, efficiency and scalability of our approach. Our studies show that our approach outperforms the classical Apriori and state-of-the-art on Spark by many times for different datasets.", "references": ["Anna L. Buczak and Christopher M. Gifford. Fuzzy Association Rule Mining for Community Crime Pattern Discovery. In ISI-KDD 2010, ACM, USA, 2010.", "Apache hadoop. http://hadoop.apache.org/2013.", "Datasets. http://www.philippe-fournier-viger.com/spmf/index.php?link=datasets.php."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809890.2809893"}, {"title": "KNET: A General Framework for Learning Word Embedding Using Morphological Knowledge", "authors": ["Qing Cui\n,", "Bin Gao\n,", "Jiang Bian\n,", "Siyu Qiu\n,", "Hanjun Dai\n,", "Tie-Yan Liu"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nNeural network techniques are widely applied to obtain high-quality distributed representations of words (i.e., word embeddings) to address text mining, information retrieval, and natural language processing tasks. Most recent efforts have proposed several efficient methods to learn word embeddings from context such that they can encode both semantic and syntactic relationships between words. However, it is quite challenging to handle unseen or rare words with insufficient context. Inspired by the study on the word recognition process in cognitive psychology, in this article, we propose to take advantage of seemingly less obvious but essentially important morphological knowledge to address these challenges. In particular, we introduce a novel neural network architecture called KNET that leverages both words’ contextual information and morphological knowledge to learn word embeddings. Meanwhile, this new learning architecture is also able to benefit from noisy knowledge and balance between contextual information and morphological knowledge. Experiments on an analogical reasoning task and a word similarity task both demonstrate that the proposed KNET framework can greatly enhance the effectiveness of word embeddings.", "references": ["Y. Bengio and J.-S. Senecal, and others. 2003. Quick Training of Probabilistic Neural Nets by Importance Sampling.", "Y. Bengio and J.-S. Senecal. 2008. Adaptive importance sampling to accelerate training of a neural probabilistic language model. Trans. Neur. Netw. 19, 4, 713--722.", "J. Bian, B. Gao, and T.-Y. Liu. 2014. Knowledge-powered deep learning for word embedding. In Proc. of ECML/PKDD."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797137"}, {"title": "Content-based Image Retrieval Using Rotation-invariant Histograms of Oriented Gradients", "authors": ["Jinhui Chen\n,", "Toru Nakashika\n,", "Tetsuya Takiguchi\n,", "Yasuo Ariki"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nOur research focuses on the question of feature descriptors for robust effective computing, proposing a novel feature representation method, namely, rotation-invariant histograms of oriented gradients (Ri-HOG) for image retrieval. Most of the existing HOG techniques are computed on a dense grid of uniformly-spaced cells and use overlapping local contrast of rectangular blocks for normalization. However, we adopt annular spatial bins type cells and apply radial gradient to attain gradient binning invariance for feature extraction. In this way, it significantly enhances HOG in regard to rotation-invariant ability and feature descripting accuracy. In experiments, the proposed method is evaluated on Corel-5k and Corel-10k datasets. The experimental results demonstrate that the proposed method is much more effective than many existing image feature descriptors for content-based image retrieval.", "references": ["N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pages 886--893, Jun. 2005.", "G.-H. Liu, Z.-Y. Li, L. Zhang, and Y. Xu. Image retrieval based on micro-structure descriptor. Pattern Recognition, 44(9):2123--2133, 2011.", "G.-H. Liu, L. Zhang, Y.-K. Hou, Z.-Y. Li, and J.-Y. Yang. Image retrieval based on multi-texton histogram. Pattern Recognition, 43(7):2380--2389, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749287"}, {"title": "How and why do users change their assessment of search results over time?", "authors": ["Maayan Zhitomirsky-Geffet\n,", "Judit Bar-Ilan\n,", "Mark Levene"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nIn this study we investigate whether and why users change their preferences when assessing search engine results over time. We conducted a study with 35 subjects who were asked to rank and assign relevance scores to the same set of search results for three times, with a few weeks period between each round. The subjects were then exposed to the differences in their judgements and were asked to explain them. A new coefficient to measure change was introduced to assess the results of the experiment. We found that all the subjects judge the vast majority of the results differently in every round. However, there was less change in relevance judgements than in rankings. Most of the subjects were satisfied with their changes, and did not perceive them as mistakes but rather as a legitimate phenomenon, since they believe that time influences the relevance assessment. Our analysis reveals that the main factors that caused these changes were due to categorical thinking, influence of the learnt information, and environmental and emotional changes.", "references": ["Bar-Ilan J., Keenoy K., Yaari E., & Levene M. (2007). User rankings of search engine results. Journal of the American Society for Information Science & Technology, 58(9): 1254--1266.", "Bar-Ilan J., Keenoy K., Yaari E., & Levene M. (2009). Presentation bias is significant in determining user preference for search results -- A user study. Journal of the American Society for Information Science and Technology, 60(1): 135--149.", "Bar-Ilan J., & Levene M. (2011). A method to assess search engine results. Online Information Review, 35(6): 854--868."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857137"}, {"title": "Quantitative temporal association rule mining by genetic algorithm", "authors": ["Sergio F. da Silva\n,", "Marcos A. Batista\n,", "Agma J. M. Traina"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nAssociation rule mining has shown great potential to extract knowledge from multidimensional data sets. However, existing methods in the literature are not effectively applicable to quantitative temporal data. This article extends the concepts of association rule mining from the literature. Based on the extended concepts is presented a method to mine rules from multidimensional temporal quantitative data sets using genetic algorithm, called GTARGA, in reference to Quantitative Temporal Association Rule Mining by Genetic Algorithm. Experiments with QTARGA in four real data sets show that it allows to mine several high-confidence rules in a single execution of the method.", "references": ["S. Amo, N. A. Silva, R. P. Silva, and F. S. Pereira. Tree pattern mining with tree automata constraints. Information Systems, 35:570-591, 2010.", "B. Catania and A. Maddalena. A unified framework for heterogeneous patterns. Information Systems, 37:460-483, 2012.", "D.-A. Chiang, C.-T. Wang, S.-P. Chen, and C.-C. Chen. The cyclic model analysis on sequential patterns. IEEE Transactions on Knowledge and Data Engineering, 21(11):1617-1628, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814090"}, {"title": "Pannier: A Container-based Flash Cache for Compound Objects", "authors": ["Cheng Li\n,", "Philip Shilane\n,", "Fred Douglis\n,", "Grant Wallace"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nClassic caching algorithms leverage recency, access count, and/or other properties of cached blocks at per-block granularity. However, for media such as flash which have performance and wear penalties for small overwrites, implementing cache policies at a larger granularity is beneficial. Recent research has focused on buffering small blocks and writing in large granularities, called containers, but it has not explored the ramifications and best strategies for caching compound blocks consisting of logically distinct, but physically co-located, blocks. Containers may have highly diverse blocks, with mixtures of frequently accessed, infrequently accessed, and invalidated blocks.\nWe propose and evaluate Pannier, a flash cache middleware that provides high performance while extending flash lifespan. Pannier uses three main techniques: (1) leveraging block access counts to manage cache containers, (2) incorporating block liveness as a property to improve flash cache space efficiency, and (3) designing a multi-step feedback controller to ensure a flash cache does not wear out in its lifespan while maintaining performance. Our evaluation shows that Pannier improves flash cache performance and extends lifespan beyond previous per-block and container-aware caching policies. More fundamentally, our investigation highlights the importance of creating new policies for caching compound blocks in flash.", "references": ["A. Badam and V. S. Pai. SSDAlloc: Hybrid SSD/RAM Memory Management Made Easy. NSDI, 2011.", "L. A. Belady. A Study of Replacement Algorithms for a Virtual-storage Computer. IBM Syst. J., 1966.", "L. Breslau et al. Web Caching and Zipf-like Distributions: Evidence and Implications. INFOCOM, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814734"}, {"title": "High Recall-Low Cost Model for Patent Retrieval", "authors": ["Justin JongSu Song\n,", "Wookey Lee"], "publication": "BigDAS '15: Proceedings of the 2015 International Conference on Big Data Applications and Services", "abstract": "ABSTRACT\nPatenting has been considered as a key enabler for many information-centric companies and organizations. The higher the required patent capability, the more important the need for an effective and efficient patent retrieval system. Many conventional patent retrieval systems have produced unsatisfactory results for the patent queries because the inherent systems have come from traditional keyword based models, which inevitably have resulted too many unrelated items in the search outcomes. Consequently, these systems have required the patent experts lots of time to refine iterative search results manually. In this paper, we propose a specialized patent-searching method where the keyword vectors in each and every document and their implication for each patent vectors are investigated. With the elaborated vector finding algorithm and the ranking capability, the documents for valid patents are placed in higher ranks and those for noise patents are placed in sub-ranked positions. As a benefit, our method can find the target documents efficiently so that the noise data in return can significantly be eliminated from the results. Hence, our method can be verified by the real data sets as a de facto standard method for the recall-oriented patent retrieval. Experimental results with real-life datasets show that our method outperformed many conventional patent retrieval systems with respect to time and cost.", "references": ["http://web2.wipo.int/.", "http://www.uspto.gov/.", "C. Benson and C. Magee. Technology structural implications from the extension of a patent search method. Scientometrics, 102(3):1965--1985, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837060.2837098"}, {"title": "Characterizing and Predicting Viral-and-Popular Video Content", "authors": ["David Vallet\n,", "Shlomo Berkovsky\n,", "Sebastien Ardon\n,", "Anirban Mahanti\n,", "Mohamed Ali Kafaar"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe proliferation of online video content has triggered numerous works on its evolution and popularity, as well as on the effect of social sharing on content propagation. In this paper, we focus on the observable dependencies between the virality of video content on a micro-blogging social network (in this case, Twitter) and the popularity of such content on a video distribution service (YouTube). To this end, we collected and analysed a corpus of Twitter posts containing links to YouTube clips and the corresponding video meta-data from YouTube. Our analysis highlights the unique properties of content that is both popular and viral, which allows such content to attract high number of views on YouTube and achieve fast propagation on Twitter. With this in mind, we proceed to the predictions of popular-and-viral clips and propose a framework that can, with high degree of accuracy and low amount of training data, predict videos that are likely to be popular, viral, and both. The key contribution of our work is the focus on cross-system dynamics between YouTube and Twitter. We conjecture and validate that cross-system prediction of both popularity and virality of videos is feasible, and can be performed with a reasonably high degree of accuracy. One of our key findings is that YouTube features capturing user engagement, have strong virality prediction capabilities. This findings allows to solely rely on data extracted from a video sharing service to predict popularity and virality aspects of videos.", "references": ["F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing user modeling on twitter for personalized news recommendations. In Proceedings of the International Conference on User Modeling, Adaption, and Personalization, pages 1--12, 2011.", "A. Abisheva, V. R. K. Garimella, D. Garcia, and I. Weber. Who watches (and shares) what on youtube? and when?: Using twitter to understand youtube viewership. In Proceedings of the international conference on Web search and data mining, pages 593--602, 2014.", "M. Ahmed, S. Spagna, F. Huici, and S. Niccolini. A peek into the future: Predicting the evolution of popularity in user generated content. In Proceedings of the International Conference on Web Search and Data Mining, pages 607--616, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806556"}, {"title": "CARONTE: Detecting Location Leaks for Deanonymizing Tor Hidden Services", "authors": ["Srdjan Matic\n,", "Platon Kotzias\n,", "Juan Caballero"], "publication": "CCS '15: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security", "abstract": "ABSTRACT\nAnonymity networks such as Tor are a critical privacy-enabling technology. Tor's hidden services provide both client and server anonymity. They protect the location of the server hosting the service and provide encryption at every hop from a client to the hidden service. This paper presents Caronte, a tool to automatically identify location leaks in hidden services, i.e., sensitive information in the content served by the hidden service or its configuration that discloses the server's IP address. Compared to prior techniques that deanonymize hidden services Caronte implements a novel approach that does not rely on flaws on the Tor protocol and assumes an open-world, i.e., it does not require a short list of candidate servers known in advance. Caronte visits the hidden service, extracts Internet endpoints and looks up unique strings from the hidden service's content, and examines the hidden service's certificate chain to extract candidate Internet endpoints where the hidden service could be hosted. Then, it validates those candidates by connecting to them. We apply Caronte to 1,974 hidden services, fully recovering the IP address of 101 (5%) of them.", "references": ["Certificate Transparency. http://www.certificate-transparency.org/.", "Deep web links: .onion hidden service urls list. http://deepweblinks.org/.", "Duckduckgo. http://3g2upl4pq6kufc4m.onion."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810103.2813667"}, {"title": "Improving Consistency of Crowdsourced Multimedia Similarity for Evaluation", "authors": ["Peter Organisciak\n,", "J. Stephen Downie"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nBuilding evaluation datasets for information retrieval is a time-consuming and exhausting activity. To evaluate research over novel corpora, researchers are increasingly turning to crowdsourcing to efficiently distribute the evaluation dataset creation among many workers. However, there has been little investigation into the effect of instrument design on data quality in crowdsourced evaluation datasets. We pursue this question through a case study, music similarity judgments in a music digital library evaluation, where we find that even with trusted graders song pairs are not consistently rated the same. We find that much of this low intra-coder consistency can be attributed to the task design and judge effects, concluding with recommendations for achieving reliable evaluation judgments for music similarity and other normative judgment tasks.", "references": ["J. S. Downie. The music information retrieval evaluation eXchange (MIREX). D-Lib Magazine, 12(12):795--825, 2006.", "J. S. Downie. The music information retrieval evaluation exchange: Some observations and insights. In Advances in music information retrieval. Springer Berlin/Heidelberg, 2010.", "M. B. Eisenberg. Measuring relevance judgments. Information Processing & Management, 24(4):373--389, 1988."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756942"}, {"title": "Social media analytics and research test-bed (SMART dashboard)", "authors": ["Ming-Hsiang Tsou\n,", "Chin-Te Jung\n,", "Chris Allen\n,", "Jiue-An Yang\n,", "Jean-Mark Gawron\n,", "Brian H. Spitzberg\n,", "Su Han"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nWe developed a social media analytics and research testbed (SMART) dashboard for monitoring Twitter messages and tracking the diffusion of information in different cities. SMART dashboard is an online geo-targeted search and analytics tool, including an automatic data processing procedure to help researchers to 1) search tweets in different cities; 2) filter noise (such as removing redundant retweets and using machine learning methods to improve precision); 3) analyze social media data from a spatiotemporal perspective, and 4) visualize social media data in various ways (such as weekly and monthly trends, top URLs, top retweets, top mentions, or top hashtags). By monitoring social messages in geo-targeted cities, we hope that SMART dashboard can assist researchers investigate and monitor various topics, such as flu outbreaks, drug abuse, and Ebola epidemics at the municipal level.", "references": ["Nagel, A. C., Tsou, M. H., Spitzberg, B. H., An Li, Gawron, J. M., Gupta, D. K., Yang, J. A., Han Su, Peddecord, K. M., Lindsay, S., Sawyer, M. H. 2013 The complex relationship of realspace events and messages in cyberspace: Case study of influenza and pertussis using tweets. The Journal of Medical Internet Research 15, 10, 237. doi:10.2196/jmir.2705.", "Aslam, A. A., Tsou, M. H., Spitzberg, B. H., An L, Gawron, J. M., Gupta, D. K., Peddecord, K. M., Nagel, A. C., Allen, C., Yang, J. A., and Lindsay, S. 2014. The reliability of tweets as a supplementary method of seasonal influenza surveillance. Journal of Medical Internet Research 16, 11. doi:10.2196/jmir.3532.", "Ming-Hsiang, T., Yang, J. A., Lusher, D., Han, S., Spitzberg, B., Gawron, J. M., Gupta, D., and An, L.2012. Mapping social activities and concepts with social media (Twitter) and web search engines (Yahoo and Bing): A case study in 2012 U.S. presidential election. Cartography and Geographic Information Science."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789196"}, {"title": "A Proposed Method to Recognize the Research Trends using Web-based Search Engines", "authors": ["Mohammed R. Elkobaisi\n,", "Abdelsalam M. Maatuk\n,", "Shadi Aljawarneh"], "publication": "ICEMIS '15: Proceedings of the The International Conference on Engineering & MIS 2015", "abstract": "ABSTRACT\nThis paper presents a novel approach to recognize research trends in a particular domain of research (i.e. Agent development) that is based on the number of data extracted from search engines. Several well-known mathematical and statistical theories have been used, from which a mathematical model has been derived to predict the agent development. The proposed solution attempts to convert the raw resulted number of documents found on the Internet (in PDF format) into useful information, and fit a curve representing the number of searched data of every year. A prototype has been designed, to search multi-keywords at the same time and collect the required data automatically to eliminate the useless data, before converting it into usable data.", "references": ["Chris A. 2014. Top 10 search engines in the World. {Online}. Available:https://www.reliablesoft.net/top-10-search-engines-in-the-world/.", "Levitt T. 1965. Exploit the Product Life Cycle. Harvard Business Review, vol. 43(6), pp. 81--94.", "Rodgers J. and Nicewander W. 1988. Thirteen ways to look at the correlation coefficient. In The American Statistician. vol. 42(1), pp. 59--66."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2832987.2833012"}, {"title": "Distribution Regularized Nonnegative Matrix Factorization for Transfer Visual Feature Learning", "authors": ["Yuchen Guo\n,", "Guiguang Ding\n,", "Qiang Liu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nTransfer visual feature learning (TVFL), which learns compact representations for images such that we can build accurate classifier for target domain by leveraging rich labeled data in the source domain, has attracted increasingly attention recently. Previous methods mainly focus on reducing the distribution difference between domains but ignore the intrinsic hidden semantics in data. In this paper, we put forward a novel method for TVFL, called Distribution Regularized Nonnegative Matrix Factorization (DRNMF). Specifically, we employ Nonnegative Matrix Factorization (NMF) to uncover the intrinsic information in visual data, and regularize it with geometrical distribution, marginal probability distribution and conditional probability distribution. Thus, DRNMF can discover the intrinsic information, preserve the manifold structure and reducing both marginal and conditional probability distribution difference simultaneously, which all perspectives above are important for TVFL. We also propose an effective and efficient algorithm for the optimization of DRNMF and theoretically prove the convergence. Extensive experiments on three types of cross-domain image classification tasks in comparison with several state-of-the-art methods demonstrate the superiority of our DRNMF, which validates its effectiveness.", "references": ["Y. Aytar and A. Zisserman. Tabula rasa: Model transfer for object category detection. In International Conference on Computer Vision, 2011.", "L. Bruzzone and M. Marconcini. Domain adaptation problems: A dasvm classification technique and a circular validation strategy. IEEE TPAMI, 2010.", "D. Cai, X. He, J. Han, and T. S. Huang. Graph regularized nonnegative matrix factorization for data representation. IEEE TPAMI, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749316"}, {"title": "Linse: A Distributional Semantics Entity Search Engine", "authors": ["Juliano Efson Sales\n,", "André Freitas\n,", "Siegfried Handschuh\n,", "Brian Davis"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nEntering 'Football Players from United States' when searching for 'American Footballers' is an example of vocabulary mismatch, which occurs when different words are used to express the same concepts. In order to address this phenomenon for entity search targeting descriptors for complex categories, we propose a compositional-distributional semantics entity search engine, which extracts semantic and commonsense knowledge from large-scale corpora to address the vocabulary gap between query and data.", "references": ["A. Freitas, et al., On the Semantic Representation and Extraction of Complex Category Descriptors, In Proc. of NLDB, 2014.", "D. Carvalho, et al., EasyESA: A Low-effort Infrastructure for Explicit Semantic Analysis, In Proc. of ISWC, 2014.", "P. D. Turney and P. Pantel., From frequency to meaning: Vector space models of semantics. J. Artif. Int. Res., 37(1) : pp. 141 - 188, January 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767871"}, {"title": "EchoWear: smartwatch technology for voice and speech treatments of patients with Parkinson's disease", "authors": ["Harishchandra Dubey\n,", "Jon C. Goldberg\n,", "Mohammadreza Abtahi\n,", "Leslie Mahler\n,", "Kunal Mankodiya"], "publication": "WH '15: Proceedings of the conference on Wireless Health", "abstract": "ABSTRACT\nAbout 90 percent of people with Parkinson's disease (PD) experience decreased functional communication due to the presence of voice and speech disorders associated with dysarthria that can be characterized by monotony of pitch (or fundamental frequency), reduced loudness, irregular rate of speech, imprecise consonants, and changes in voice quality. Speech-language pathologists (SLPs) work with patients with PD to improve speech intelligibility using various intensive in-clinic speech treatments. SLPs also prescribe home exercises to enhance generalization of speech strategies outside of the treatment room. Even though speech therapies are found to be highly effective in improving vocal loudness and speech quality, patients with PD find it difficult to follow the prescribed exercise regimes outside the clinic and to continue exercises once the treatment is completed. SLPs need techniques to monitor compliance and accuracy of their patients' exercises at home and in ecologically valid communication situations. We have designed EchoWear, a smartwatch-based system, to remotely monitor speech and voice exercises as prescribed by SLPs. We conducted a study of 6 individuals; three with PD and three healthy controls. To assess the performance of EchoWear technology compared with high-quality audio equipment obtained in a speech laboratory. Our preliminary analysis shows promising outcomes for using EchoWear in speech therapies for people with PD.", "references": ["DeLau, L. M., and Breteler, M. M. Epidemiology of Parkinson's disease. Lancet Neurol 2006; 5(6):525--535. DOI=10.1016/S1474-4422(06)70471-9.", "Dorsey, E. R., Constantinescu, R., Thompson, J. P., Biglan, K. M., Holloway, R. G., Kieburtz, K., Marshall, F. J., Ravina, B. M., Schifitto, G., Siderowf, A., and Tanner, C. M. Projected number of people with Parkinson disease in the most populous nations, 2005 through 2030. Neurology 2007;68:384--6. DOI= http://dx.doi.org/10.1212/01.wnl.0000247740.47667.03.", "Hartelius, L., and Svensson, P. Speech and swallowing symptoms associated with Parkinson's disease and multiple sclerosis: a survey. Folia PhoniatrLogop 1994, 46(1):9--17. DOI= http://dx.doi.org/10.1159/000266286."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811780.2811957"}, {"title": "Analysis of cyberbullying tweets in trending world events", "authors": ["Keith Cortis\n,", "Siegfried Handschuh"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nThe use of social media amongst children, adolescents and families is nowadays a common practise in our everyday lives. Social networking sites allow social interaction between people through various channels, such as Twitter, Facebook, YouTube and blogs. Even if this interaction is generally healthy, these sites bring several risks, such as cyberbullying, depression and exposure of inappropriate content. In this paper we tackle the problem of cyberbullying via a novel approach that analyses online posts in trending world events. These generally cause a lot of interest and controversy among online Web users. Twitter is the social network of choice, where a large dataset of tweets is collected. The two current world events selected are the Ebola virus outbreak in Africa and the shooting of Michael Brown in Ferguson, Missouri. Collected tweets are carefully analysed to identify the most popular hashtags and named entities used within cyberbullying tweets. This analysis provides a basis towards several useful applications, such as a cyberbullying online post detector for certain current trending world events. This will help reduce the number of cyberbullying cases in social networking sites. Results obtained from this evaluation can be applied to other cyberbullying scenarios.", "references": ["A. Al Mazari. Cyber-bullying taxonomies: Definition, forms, consequences and mitigation strategies. In CSIT, pages 126--133, 2013.", "K. Bontcheva, L. Derczynski, A. Funk, M. A. Greenwood, D. Maynard, and N. Aswani. TwitIE: An open-source information extraction pipeline for microblog text. In Proceedings of the International Conference on RANLP. ACL, 2013.", "A. J. Calvin, A. Bellmore, J.-M. Xu, and X. Zhu. #bully: Uses of hashtags in posts about bullying on twitter. Journal of School Violence, pages 1--21, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809605"}, {"title": "SEMA-JOIN: joining semantically-related tables using big table corpora", "authors": ["Yeye He\n,", "Kris Ganjam\n,", "Xu Chu"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nJoin is a powerful operator that combines records from two or more tables, which is of fundamental importance in the field of relational database. However, traditional join processing mostly relies on string equality comparisons. Given the growing demand for ad-hoc data analysis, we have seen an increasing number of scenarios where the desired join relationship is not equi-join. For example, in a spreadsheet environment, a user may want to join one table with a subject column country-name, with another table with a subject column country-code. Traditional equi-join cannot handle such joins automatically, and the user typically has to manually find an intermediate mapping table in order to perform the desired join.\nWe develop a SEMA-JOIN approach that is a first step toward allowing users to perform semantic join automatically, with a click of the button. Our main idea is to utilize a data-driven method that leverages a big table corpus with over 100 million tables to determine statistical correlation between cell values at both row-level and column-level. We use the intuition that the correct join mapping is the one that maximizes aggregate pairwise correlation, to formulate the join prediction problem as an optimization problem. We develop a linear program relaxation and a rounding argument to obtain a 2-approximation algorithm in polynomial time. Our evaluation using both public tables from the Web and proprietary Enterprise tables from a large company shows that the proposed approach can perform automatic semantic joins with high precision for a variety of common join scenarios.", "references": ["Fips country codes. http://en.wikipedia.org/wiki/List_of_FIPS_country_codes.", "Google Web Tables. http://research.google.com/tables.", "Iso country codes. http://en.wikipedia.org/wiki/ISO_3166-1."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824036"}, {"title": "The Recommendation Game: Using a Game-with-a-Purpose to Generate Recommendation Data", "authors": ["Sam Banks\n,", "Rachael Rafter\n,", "Barry Smyth"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis paper describes a casual Facebook game to capture recommendation data as a side-effect of gameplay. We show how this data can be used to make successful recommendations as part of a live-user trial.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734--749, June 2005.", "G. K. Christian Desrosiers. A Comprehensive Survey of Neighborhood-based Recommendation Methods. In F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors, Recommender Systems Handbook, pages 107--144. 2011.", "S. Cooper, F. Khatib, A. Treuille, J. Barbero, J. Lee, M. Beenen, A. Leaver-Fay, D. Baker, Z. Popović, and F. Players. Predicting Protein Structures with a Multiplayer Online Game. Nature, 466(7307):756--760, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799675"}, {"title": "Efficient Latent Link Recommendation in Signed Networks", "authors": ["Dongjin Song\n,", "David A. Meyer\n,", "Dacheng Tao"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nSigned networks, in which the relationship between two nodes can be either positive (indicating a relationship such as trust) or negative (indicating a relationship such as distrust), are becoming increasingly common. A plausible model for user behavior analytics in signed networks can be based upon the assumption that more extreme positive and negative relationships are explored and exploited before less extreme ones. Such a model implies that a personalized ranking list of latent links should place positive links on the top, negative links at the bottom, and unknown status links in between. Traditional ranking metrics, e.g., area under the receiver operating characteristic curve (AUC), are however not suitable for quantifying such a ranking list which includes positive, negative, and unknown status links. To address this issue, a generalized AUC (GAUC) which can measure both the head and tail of a ranking list has been introduced. Since GAUC weights each pairwise comparison equally and the calculation of GAUC requires quadratic time, we derive two lower bounds of GAUC which can be computed in linear time and put more emphasis on ranking positive links on the top and negative links at the bottom of a ranking list. Next, we develop two efficient latent link recommendation (ELLR) algorithms in order to recommend links by directly optimizing these two lower bounds, respectively. Finally, we compare these two ELLR algorithms with top-performing baseline methods over four benchmark datasets, among which the largest network has more than 100 thousand nodes and seven million entries. Thorough empirical studies demonstrate that the proposed ELLR algorithms outperform state-of-the-art approaches for link recommendation in signed networks at no cost in efficiency.", "references": ["L. A. Adamic and E. Adar. Friends and neighbors on the web. Social Networks, 25(3):211 -- 230, 2003.", "L. Backstrom and J. Leskovec. Supervised random walks: predicting and recommending links in social network. In Proceedings of the 4th ACM international Conference on Web Search and Data Mining, pages 635--644, Hong Kong, China, 2011.", "M. J. Brozzowski, T. Hogg, and G. Szabo. Friends and foes: ideological social networking. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 817--820, Florence, Italy, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783358"}, {"title": "Query Auto-Completion for Rare Prefixes", "authors": ["Bhaskar Mitra\n,", "Nick Craswell"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuery auto-completion (QAC) systems typically suggest queries that have previously been observed in search logs. Given a partial user query, the system looks up this query prefix against a precomputed set of candidates, then orders them using ranking signals such as popularity. Such systems can only recommend queries for prefixes that have been previously seen by the search engine with adequate frequency. They fail to recommend if the prefix is sufficiently rare such that it has no matches in the precomputed candidate set.\nWe propose a design of a QAC system that can suggest completions for rare query prefixes. In particular, we describe a candidate generation approach using frequently observed query suffixes mined from historical search logs. We then describe a supervised model for ranking these synthetic suggestions alongside the traditional full-query candidates. We further explore ranking signals that are appropriate for both types of candidates based on n-gram statistics and a convolutional latent semantic model (CLSM). Within our supervised framework the new features demonstrate significant improvements in performance over the popularity-based baseline. The synthetic query suggestions complement the existing popularity-based approach, helping users formulate rare queries.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proc. WWW, pages 107--116, 2011.", "S. Bhatia, D. Majumdar, and P. Mitra. Query suggestions in the absence of query logs. In Proc. SIGIR, pages 795--804, 2011.", "S. Bickel, P. Haider, and T. Scheffer. Learning to complete sentences. In Proc. ECML, pages 497--504. Springer, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806599"}, {"title": "Inter-Category Variation in Location Search", "authors": ["Chia-Jung Lee\n,", "Nick Craswell\n,", "Vanessa Murdock"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhen searching for place entities such as businesses or points of interest, the desired place may be close (finding the nearest ATM) or far away (finding a hotel in another city). Understanding the role of distance in predicting user interests can guide the design of location search and recommendation systems. We analyze a large dataset of location searches on GPS-enabled mobile devices with 15 location categories. We model user-location distance based on raw geographic distance (kilometers) and intervening opportunities (nth closest). Both models are helpful in predicting user interests, with the intervening opportunity model performing somewhat better. We find significant inter-category variation. For instance, the closest movie theater is selected in 17.7% of cases, while the closest restaurant in only 2.1% of cases. Overall, we recommend taking category information into account when modeling location preferences of users in search and recommendation systems.", "references": ["K. Berberich, A. C. Koenig, D. Lymberopoulos, and P. Zhao. Improving local search ranking through external logs. In Proc. of SIGIR, 2011.", "K. Church, B. Smyth, P. Cotter, and K. Bradley. Mobile information access: A study of emerging search behavior on the mobile internet. ACM Trans. Web, 1(1), 2007.", "N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An experimental comparison of click position bias models. In Proc. of WSDM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767797"}, {"title": "Good Times Bad Times: A Study on Recency Effects in Collaborative Filtering for Social Tagging", "authors": ["Santiago Larrain\n,", "Christoph Trattner\n,", "Denis Parra\n,", "Eduardo Graells-Garrido\n,", "Kjetil Nørvåg"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nIn this paper, we present work-in-progress of a recently started project that aims at studying the effect of time in recommender systems in the context of social tagging. Despite the existence of previous work in this area, no research has yet made an extensive evaluation and comparison of time-aware recommendation methods. With this motivation, this paper presents results of a study where we focused on understanding (i) \"when\" to use the temporal information into traditional collaborative filtering (CF) algorithms, and (ii) \"how\" to weight the similarity between users and items by exploring the effect of different time-decay functions. As the results of our extensive evaluation conducted over five social tagging systems (Delicious, BibSonomy, CiteULike, MovieLens, and Last.fm) suggest, the step (when) in which time is incorporated in the CF algorithm has substantial effect on accuracy, and the type of time-decay function (how) plays a role on accuracy and coverage mostly under pre-filtering on user-based CF, while item-based shows stronger stability over the experimental conditions.", "references": ["P. G. Campos, F. Dıez, and I. Cantador. Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols. UMUAI, pages 67--119, 2014.", "Y. Ding and X. Li. Time weight collaborative filtering. In Proc. CIKM'05, pages 485--492, 2005.", "J. Gemmell, T. Schimoler, M. Ramezani, L. Christiansen, and B. Mobasher. Improving FolkRank with item-based collaborative filtering. In Proc. Workshop on Recommender Systems and the Social Web, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799682"}, {"title": "Twister Tries: Approximate Hierarchical Agglomerative Clustering for Average Distance in Linear Time", "authors": ["Michael Cochez\n,", "Hao Mou"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nMany commonly used data-mining techniques utilized across research fields perform poorly when used for large data sets. Sequential agglomerative hierarchical non-overlapping clustering is one technique for which the algorithms' scaling properties prohibit clustering of a large amount of items. Besides the unfavorable time complexity of O(n2), these algorithms have a space complexity of O(n2), which can be reduced to O(n) if the time complexity is allowed to rise to O(n2 log2n). In this paper, we propose the use of locality-sensitive hashing combined with a novel data structure called twister tries to provide an approximate clustering for average linkage. Our approach requires only linear space. Furthermore, its time complexity is linear in the number of items to be clustered, making it feasible to apply it on a larger scale. We evaluate the approach both analytically and by applying it to several data sets.", "references": ["A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Commun. ACM, 51(1):117--122, Jan. 2008.", "M. Bawa, T. Condie, and P. Ganesan. LSH forest: self-tuning indexes for similarity search. In Proceedings of the 14th international conference on World Wide Web, pages 651--660. ACM, 2005.", "A. Broder. Some applications of rabin's fingerprinting method. In R. Capocelli, A. Santis, and U. Vaccaro, editors, Sequences II, pages 143--152. Springer New York, 1993."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2751521"}, {"title": "Modeling Faceted Browsing with Category Theory to Support Interoperability and Reuse", "authors": ["Daniel R. Harris"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nFaceted browsing has become ubiquitous with modern digital libraries and online search engines, yet the process is still difficult to abstractly model in a manner that supports the development of interoperable and reusable interfaces. Existing efforts in facet modeling are based upon set theory, formal concept analysis, and light-weight ontologies, but in many regards, they are implementations of faceted browsing rather than a specification of the basic, underlying structures and interactions. We propose category theory as a theoretical foundation for faceted browsing and demonstrate how the interactive process can be mathematically abstracted in a way that naturally supports interoperability and reuse.", "references": ["M. Barr and C. Wells. Category theory for computing science. Prentice Hall New York, 1990.", "D. R. Harris, R. Kavuluru, S. Yu, R. Theakston, J. W. Jaromczyk, and T. R. Johnson. Delve: A document exploration and visualization engine. In Proceedings of the Summit on Clinical Research Informatics, page 17 AMIA, 2014.", "M. A. Hearst. Clustering versus faceted categories for information exploration. Communications of the ACM, 49(4):59--61, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756972"}, {"title": "Preserving the internet", "authors": ["Esther Shein"], "publication": "Communications of the ACM", "abstract": "Abstract\nIs the Internet ephemeral by its nature, or can it be archived?", "references": ["Althaus, S. and Leetaru, K., University of Illinois Urbana-Champaign, 2008. Airbrushing History, American Style. http://courseweb.lis.illinois.edu/~katewill/spring2011-502/502%20and%20other%20 readings/althous%20and%20leetaru%20 Airbrushing%20History.pdf", "\"Blue Magic\": A Review University of Michigan Computing News, Volume 3, Number 19, p. 14, 1988, http://bit.ly/1NoZst2.", "Venkataraman, B., The Race to Preserve Disappearing Data, The Boston Globe, May 17, 2015, http://bit.ly/1XGpKiS"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2843553"}, {"title": "Learning Temporal Tagging Behaviour", "authors": ["Toni Gruetze\n,", "Gary Yao\n,", "Ralf Krestel"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSocial networking services, such as Facebook, Google+, and Twitter are commonly used to share relevant Web documents with a peer group. By sharing a document with her peers, a user recommends the content for others and annotates it with a short description text. This short description yield many chances for text summarization and categorization. Because today's social networking platforms are real-time media, the sharing behaviour is subject to many temporal effects, i.e., current events, breaking news, and trending topics. In this paper, we focus on time-dependent hashtag usage of the Twitter community to annotate shared Web-text documents. We introduce a framework for time-dependent hashtag recommendation models and introduce two content-based models. Finally, we evaluate the introduced models with respect to recommendation quality based on a Twitter-dataset consisting of links to Web documents that were aligned with hashtags.", "references": ["P. A. Chirita, S. Costache, W. Nejdl, and S. Handschuh. P-tag: Large scale automatic generation of personalized annotation tags for the Web. In Proceedings of WWW, pages 845--854, 2007.", "S. A. Golder and B. A. Huberman. Usage patterns of collaborative tagging systems. Journal of information science, 32(2):198--208, 2006.", "M. Gupta, R. Li, Z. Yin, and J. Han. Survey on social tagging techniques. SIGKDD Explorations, 12(1):58--72, Nov. 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741701"}, {"title": "Dispatchable Indoor Location for Mobile Phones Calling for Emergency Services", "authors": ["Carol Davids\n,", "Javier Moreno Valdecantos\n,", "Bartlomiej Dworak\n,", "Cruz Tovar\n,", "Bharat Ramaswamy Nandakumar\n,", "Mahak Patil"], "publication": "IPTComm '15: Proceedings of the Principles, Systems and Applications on IP Telecommunications", "abstract": "ABSTRACT\nThis paper describes a proof of concept, working system that provides the indoor location of a caller who calls a Next Generation 9-1-1 Public Safety Answering Point using a smartphone. The paper includes descriptions of the system requirements and scope; The phone application that was developed; The location module that was developed; and the path taken by the call as it is delivered to the Public Safety Answering Point where the indoor location is displayed. The paper describes several architectures into which the modules of the service can be fit as well as plans for future development.", "references": ["Roadmap for Improving E911 Location Accuracy, November 2014. http://apps.fcc.gov/ecfs/document/view?id=60000986637.", "APCO, April 2015. https://www.apcointl.org/.", "Detailed Functional and Interface Standards for the NENA i3 Solution, April 2015. http://www.nena.org/Standards."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2843491.2843902"}, {"title": "Top-k representative queries with binary constraints", "authors": ["Arijit Khan\n,", "Vishwakarma Singh"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nGiven a collection of binary constraints that categorize whether a data object is relevant or not, we consider the problem of online retrieval of the top-k objects that best represent all other relevant objects in the underlying dataset. Such top-k representative queries naturally arise in a wide range of complex data analytic applications including advertisement, search, and recommendation. In this paper, we aim at identifying the top-k representative objects that are high-scoring, satisfy diverse subsets of given binary constraints, as well as representative of various other relevant objects in the dataset. We formulate our problem with the well-established notion of the top-k representative skylines, and we show that the problem is NP-hard. Hence, we design efficient techniques to solve our problem with theoretical performance guarantees. As a side-product of our algorithm, we also improve the asymptotic time-complexity of skyline computation to log-linear time in the number of data points when all dimensions except one are binary in nature. Our empirical results attest that the proposed method efficiently finds high-quality top-k representative objects, while our technique is one order of magnitude faster than state-of-the-art methods for finding the top-k skylines with binary constraints.", "references": ["A. Angel and N. Koudas. Efficient Diversity-aware Search. In SIGMOE, 2011.", "S. Börzsönyi, D. Kossmann, and K. Stocker. The Skyline Operator. In ICDE, 2001.", "J. L. Bentley, H. T. Kung, M. Schkolnick, and C. D. Thompson. On the Average Number of Maxima in a Set of Vectors and Applications. J. ACM, 25(4):536--543, 1978."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791367"}, {"title": "An Optimal Online Algorithm For Retrieving Heavily Perturbed Statistical Databases In The Low-Dimensional Querying Model", "authors": ["Krzysztof Marcin Choromanski\n,", "Afshin Rostamizadeh\n,", "Umar Syed"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe give the first Õ(1 over √ T)-error online algorithm for reconstructing noisy statistical databases, where T is the number of (online) sample queries received. The algorithm is optimal up to the poly(log(T)) factor in terms of the error and requires only O(log T) memory. It aims to learn a hidden database-vector w* Ε in ℜ D in order to accurately answer a stream of queries regarding the hidden database, which arrive in an online fashion from some unknown distribution D. We assume the distribution D is defined on the neighborhood of a low-dimensional manifold. The presented algorithm runs in O(dD)-time per query, where d is the dimensionality of the query-space. Contrary to the classical setting, there is no separate training set that is used by the algorithm to learn the database --- the stream on which the algorithm will be evaluated must also be used to learn the database-vector. The algorithm only has access to a binary oracle Ο that answers whether a particular linear function of the database-vector plus random noise is larger than a threshold, which is specified by the algorithm. We note that we allow for a significant O(D) amount of noise to be added while other works focused on the low noise o(√D)-setting. For a stream of T queries our algorithm achieves an average error Õ(1 over √T) by filtering out random noise, adapting threshold values given to the oracle based on its previous answers and, as a consequence, recovering with high precision a projection of a database-vector w* onto the manifold defining the query-space. Our algorithm may be also applied in the adversarial machine learning context to compromise machine learning engines by heavily exploiting the vulnerabilities of the systems that output only binary signal and in the presence of significant noise.", "references": ["Cynthia Dwork. Differential privacy. In ICALP (2), pages 1--12, 2006.", "Cynthia Dwork. Differential privacy in new settings. In Moses Charikar, editor, SODA, pages 174--183. SIAM, 2010.", "Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. In Leonard J. Schulman, editor, STOC, pages 715--724. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806421"}, {"title": "Computational design of metallophone contact sounds", "authors": ["Gaurav Bharaj\n,", "David I. W. Levin\n,", "James Tompkin\n,", "Yun Fei\n,", "Hanspeter Pfister\n,", "Wojciech Matusik\n,", "Changxi Zheng"], "publication": "ACM Transactions on Graphics", "abstract": "Abstract\nMetallophones such as glockenspiels produce sounds in response to contact. Building these instruments is a complicated process, limiting their shapes to well-understood designs such as bars. We automatically optimize the shape of arbitrary 2D and 3D objects through deformation and perforation to produce sounds when struck which match user-supplied frequency and amplitude spectra. This optimization requires navigating a complex energy landscape, for which we develop Latin Complement Sampling to both speed up finding minima and provide probabilistic bounds on landscape exploration. Our method produces instruments which perform similarly to those that have been professionally-manufactured, while also expanding the scope of shape and sound that can be realized, e.g., single object chords. Furthermore, we can optimize sound spectra to create overtones and to dampen specific frequencies. Thus our technique allows even novices to design metallophones with unique sound and appearance.", "references": ["Angell, T., Jiang, X., and Kleinman, R. 1997. A distributed source method for inverse acoustic scattering. Inverse Problems 13, 2, 531.", "Arthur, D., and Vassilvitskii, S. 2007. k-means++: The advantages of careful seeding. In Proceedings of the 18th annual ACM-SIAM symposium on Discrete algorithms, 1027--1035.", "Bängtsson, E., Noreland, D., and Berggren, M. 2003. Shape optimization of an acoustic horn. Computer methods in applied mechanics and engineering 192, 11, 1533--1571."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816795.2818108"}, {"title": "How to de-identify your data", "authors": ["Olivia Angiuli\n,", "Joe Blitzstein\n,", "Jim Waldo"], "publication": "Communications of the ACM", "abstract": "Abstract\nBalancing statistical accuracy and subject privacy in large social-science datasets.", "references": ["Daries, J.P. et al. Privacy, anonymity, and big data in the social sciences. Commun. ACM 57, 9 (Sept. 2014), 56--63.", "Sweeney, L. k-anonymity: A model for protecting privacy. Intern. J. Uncertainty, Fuzziness and Knowledge-Based Systems 10, 5 (2002), 557--570.", "Young, E. Educational privacy in the online classroom: FERPA, MOOCs, and the big data conundrum. Harvard Journal of Law & Technology 28, 2 (2015), 549--592."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814340"}, {"title": "Expert-guided semantic linking of music-library metadata for study and reuse", "authors": ["David M. Weigl\n,", "David Lewis\n,", "Tim Crawford\n,", "Kevin R. Page"], "publication": "DLfM '15: Proceedings of the 2nd International Workshop on Digital Libraries for Musicology", "abstract": "ABSTRACT\nThe process of aligning datasets that lack mutually-shared identifiers is fraught with ambiguity and difficult to automate. Manual performance of such a process may be time-consuming and error-prone. We present the Semantic Alignment and Linking Tool (SALT) that addresses this problem by applying semantic technologies and Linked Data approaches in order to produce candidate alignment suggestions that may be confirmed or disputed by a user with domain expertise. These decisions are integrated back into the knowledge base and are available for further iterative comparison by the user; the complete RDF graph is published and can be queried through the same SPARQL endpoint that also underlies the SALT user interface. Provenance of the musicologist's judgement is captured and added to the descriptive graph, supporting further discourse and counter-proposals. We report on a use case and perform an evaluation of this tool within a musicological context, joining metadata from the British Library and other sources with programme data from BBC Radio 3 in a project focusing on early music.", "references": ["D. Bretherton, D. A. Smith, J. Lambert, and M. C. Schraefel. Musicnet: Aligning musicology's metadata. In Music Linked Data Workshop, May 2011.", "B. V. Cherkassky, A. V. Goldberg, and T. Radzik. Shortest paths algorithms: Theory and experimental evaluation. Mathematical programming, 73(2):129--174, 1996.", "T. Crawford, B. Fields, D. Lewis, and K. Page. Explorations in linked data practice for early music corpora. In Digital Libraries (JCDL), 2014, pages 309--312. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2785527.2785528"}, {"title": "Cardinality estimation using neural networks", "authors": ["Henry Liu\n,", "Mingbin Xu\n,", "Ziting Yu\n,", "Vincent Corvinelli\n,", "Calisto Zuzarte"], "publication": "CASCON '15: Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nDatabase query optimizers benefit greatly from accurate cardinality estimation; however, this is hard to achieve on tables with correlated and/or skewed columns. We present a novel approach using neural networks to learn and approximate selectivity functions that take a bounded range on each column as input, effectively estimating selectivities for all relational operators. Experimental results with a simplified prototype show a significant improvement over state-of-the-art cardinality estimators on constructed datasets in terms of accuracy, efficiency, and amount of user input required.", "references": ["T. Beavin, B. Iyer, A. Shibamiya, H. Tie, and M. Wang. Query optimization through the use of multi-column statistics to avoid the problems of column correlation. (U.S. Patent 5995957A), November 1999.", "T. Beavin, B. Iyer, A. Shibamiya, H. Tie, and M. Wang. Query optimization through the use of multi-column statistics to avoid the problems of non-indexed column correlation. (U.S. Patent 6272487B1), August 2001.", "J. Boulos and Y. Viemont. Selectivity estimation using neural networks."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2886444.2886453"}, {"title": "Improving the classification of quantified self activities and behaviour using a fisher kernel", "authors": ["Peng Wang\n,", "Lifeng Sun\n,", "Shiqiang Yang\n,", "Alan F. Smeaton"], "publication": "UbiComp/ISWC'15 Adjunct: Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nVisual recording of everyday human activities and behaviour over the long term is now feasible and with the widespread use of wearable devices embedded with cameras this offers the potential to gain real insights into wearers' activities and behaviour. To date we have concentrated on automatically detecting semantic concepts from within visual lifelogs yet identifying human activities from such lifelogged images or videos is still a major challenge if we are to use lifelogs to maximum benefit. In this paper, we propose an activity classification method from visual lifelogs based on Fisher kernels, which extract discriminative embeddings from Hidden Markov Models (HMMs) of occurrences of semantic concepts. By using the gradients as features, the resulting classifiers can better distinguish different activities and from that we can make inferences about human behaviour. Experiments show the effectiveness of this method in improving classification accuracy, especially when the semantic concepts are initially detected with low degrees of accuracy.", "references": ["Robin Aly, Djoerd Hiemstra, Franciska de Jong, and Peter Apers. 2011. Simulating the future of concept-based video retrieval under improved detector performance. Multimedia Tools and Applications (2011), 1--29.", "Subhabrata Bhattacharya, Mahdi Kalayeh, Rahul Sukthankar, and Mubarak Shah. 2014. Recognition of Complex Events exploiting Temporal Dynamics between Underlying Concepts. In CVPR 2014. 2243--2250.", "Daragh Byrne, AidenR. Doherty, Cees G. M. Snoek, Gareth J. F. Jones, and AlanF. Smeaton. 2010. Everyday concept detection in visual lifelogs: validation, relationships and trends. Multimedia Tools and Applications 49, 1 (2010), 119--144. DOI: http://dx.doi.org/10.1007/s11042-009-0403-8"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2800835.2800947"}, {"title": "Query from examples: an iterative, data-driven approach to query construction", "authors": ["Hao Li\n,", "Chee-Yong Chan\n,", "David Maier"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn this paper, we propose a new approach, called Query from Examples (QFE), to help non-expert database users construct SQL queries. Our approach, which is designed for users who might be unfamiliar with SQL, only requires that the user is able to determine whether a given output table is the result of his or her intended query on a given input database. To kick-start the construction of a target query Q, the user first provides a pair of inputs: a sample database D and an output table R which is the result of Q on D. As there will be many candidate queries that transform D to R, QFE winnows this collection by presenting the user with new database-result pairs that distinguish these candidates. Unlike previous approaches that use synthetic data for such pairs, QFE strives to make these distinguishing pairs as close to the original (D,R) pair as possible. By doing so, it seeks to minimize the effort needed by a user to determine if a new database-result pair is consistent with his or her desired query. We demonstrate the effectiveness and efficiency of our approach using real datasets from SQLShare, a cloud-based platform designed to help scientists utilize RDBMS technology for data analysis.", "references": ["Sloan digital sky survey. http://www.sdss.org/.", "J. Akbarnejad, G. Chatzopoulou, M. Eirinaki, S. Koshy, S. Mittal, D. On, N. Polyzotis, and J. S. V. Varman. SQL QueRIE recommendations. PVLDB, 3(1-2), 2010.", "B. Alexe, L. Chiticariu, R. J. Miller, and W. C. Tan. Muse: Mapping understanding and design by example. In ICDE, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2831360.2831369"}, {"title": "\"I could play here for hours..\" (thinks the visitor and leaves): Why People Disengage from Public Interactives", "authors": ["Ben Bengler\n,", "Nick Bryan-Kinns"], "publication": "C&C '15: Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition", "abstract": "ABSTRACT\nThis paper examines factors that influence how long audience members actively engage with an interactive installation in public settings. The study draws on data from three field studies of an interactive multi-person installation, encompassing questionnaires,video recordings and user-system interaction data. The studies were conducted with unsolicited exhibition audiences during public exhibitions in the UK, China and Spain. In all three studies it was found that the time participants spent interacting with the installation was largely determined by social and contextual factors rather than by how they rated their playing experience. Common triggers identified for leaving were an 'obligation to leave' to accommodate other, potentially waiting audience members, and 'leaving by necessity' in order to follow companions who were moving on.", "references": ["Bengler, B., and Bryan-Kinns, N. Designing collaborative musical experiences for broad audiences. In Proceedings of the 9th ACM Conference on Creativity & Cognition, C&C '13, ACM (New York, NY, USA, 2013), 234--242.", "Bengler, B., and Bryan-Kinns, N. In the wild: Evaluating collaborative interactive musical experiences in public settings. In Interactive experience in the digital age: Evaluating new art practice, L. Candy and S. Ferguson, Eds., Springer Series on Cultural Computing, Springer, London (2014), 169--186.", "Bollo, A., and Dal Pozzolo, L. Analysis of visitor behaviour inside the museum: An empirical study. In Proceedings of the 8th International Conference on Arts and Cultural Management (Montreal, Canada, 2005)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757226.2764548"}, {"title": "From Script Idea to TV Rerun: The Idea of Linked Production Data in the Media Value Chain", "authors": ["Harald Sack"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWithin the process of the production of a film or tv program a significant amount of metadata is created and - most times - lost again. As a consequence most of this valuable information has to be costly recreated in subsequent steps of media production, distribution, and archival. On the other hand, there is no commonly used metadata exchange format throughout all steps of the media value chain. Furthermore, technical systems and software applications used in the media production process often have proprietary interfaces for data exchange. In the course of the D-Werft project funded by the German government, metadata exchange through all steps of the media value chain is to be fostered by the application of Linked Data principles. Starting with the idea for a script, metadata from existing systems and applications will be mapped to ontologies to be reused in subsequent production steps. Also for distribution and archival, metadata collected during the production process is a valuable asset to be reused for semantic and exploratory search as well as for intelligent movie recommendation and customized advertising.", "references": ["Heath, T. and Bizer, C. 2011. Linked Data: Evolving the Web into a Global Data. Synthesis Lectures on the Semantic Web: Theory and Technology, 1:1, 1--136. Morgan & Claypool. DOI= 10.2200/S00334ED1V01Y201102WBE001", "Steinmetz, N. and Sack, H. 2013. Semantic Multimedia Information Retrieval Based on Contextual Descriptions, In Proc. of 10th Extended Semantic Web Conference (ESWC 2013) - Semantics and Big Data, Lecture Notes in Computer Science LNCS 7882, 283--396.", "Waitelonis, J. and Sack, H. 2012. Towards exploratory video search using linked data, In Multimedia Tools and Applications, Volume 59, Number 2. 645--672. DOI= 10.1007/s11042-011-0733--1."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742917"}, {"title": "Mining HTML5 code: a view to how humans use emerging web standards", "authors": ["Sotiris P. Christodoulou\n,", "Giannis Tzimas\n,", "Andreas Gizas\n,", "Emmanouil Viennas\n,", "Marios Kendea"], "publication": "EANN '15: Proceedings of the 16th International Conference on Engineering Applications of Neural Networks (INNS)", "abstract": "ABSTRACT\nCurrently, Web quality research term mainly refers to the quality of content of web pages. There are some research efforts on Javascript code and CSS code quality metrics, but none for measuring metrics of HTML5 code and estimating its quality and quantity. Towards this direction the aim of this work is to determine what characteristics of HTML5 code can be measured, to specify concrete metrics to measure those characteristics, to implement a tool for calculating them for a small set of representative web pages and finally evaluate experimentally the results based on statistical analysis and data mining techniques.", "references": ["Halstead, Maurice H. (1977). Elements of Software Science. Amsterdam: Elsevier North-Holland, Inc. ISBN 0-444-00205-7.", "Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry (1999) The PageRank Citation Ranking: Bringing Order to the Web. Technical Report. Stanford InfoLab."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2797143.2797177"}, {"title": "Automatically encapsulating HPC best practices into data transfers", "authors": ["Paul Z. Kolano"], "publication": "HUST '15: Proceedings of the Second International Workshop on HPC User Support Tools", "abstract": "ABSTRACT\nThis paper presents the Shift automated transfer tool and the mechanisms it employs to achieve better performance while preserving the stability of HPC environments. Shift encapsulates best practices understood by domain experts during transfers so that scientists can focus on their science without the need to study file transports, resource management, and file systems as well. Shift understands how to utilize the variety of transports that might be deployed throughout a widely distributed user base, how to maximize the performance achievable by each, and the scenarios in which each is most effective. Shift understands which resources are available in a particular HPC environment and how to utilize them for significant performance increases while preventing resource exhaustion. Finally, Shift understands the file systems to which and from which files may be transferred and the nuances to their use that affect performance and stability behind the scenes.", "references": ["W. Allcock, J. Bresnahan, R. Kettimuthu, M. Link, C. Dumitrescu, I. Raicu, I. Foster: The Globus Striped GridFTP Framework and Server. ACM/IEEE Supercomputing 2005 Conf., Nov. 2005.", "B. Allen, J. Bresnahan, L. Childers, et al.: Globus Online: Radical Simplification of Data Movement via SaaS. Preprint CI-PP-5-0611, Computation Institute, Univ. of Chicago, Jun. 2011.", "BbFTP. http://doc.in2p3.fr/bbftp."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834996.2834997"}, {"title": "Collaborative Datasets Retrieval for Interlinking on Web of Data", "authors": ["Haichi Liu\n,", "Jintao Tang\n,", "Dengping Wei\n,", "Peilei Liu\n,", "Hong Ning\n,", "Ting Wang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nDataset interlinking is a great important problem in Linked Data. We consider this problem from the perspective of information retrieval in this paper, thus propose a learning to rank based framework, which combines various similarity measures to retrieve the relevant datasets for a given dataset. Specifically, inspired by the idea of collaborative filtering, an effective similarity measure called collaborative similarity is proposed. Experimental results show that the collaborative similarity measure is effective for dataset interlinking, and the learning to rank based framework can significantly increase the performance.", "references": ["Ferrara, A., Nikolov, A., & Scharffe, F. 2011. Data Linking for the Semantic Web. International Journal on Semantic Web and Information Systems (IJSWIS), 7(3), 46--76.", "Nikolov, Andriy and d'Aquin, Mathieu. 2011. Identifying relevant sources for data linking using a semantic web index. In: Linked Data on the Web Workshop at 20th International World Wide Web Conference (WWW 2011), India.", "Lopes G. R., Leme L.A.P.P, Nunes B.P., et al. Two Approaches to the Dataset Interlinking Recommendation Problem. 2014. In: 15th International Conference on Web Information System Engineering (WISE 2014).71--74."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742762"}, {"title": "Big Data Applications: Adaptive User Interfaces to Enhance Managerial Decision Making", "authors": ["S. L. See"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nBig data applications may present opportunity for business executives to make better informed decisions. However, how well such application can support and effect managerial decision making still remains a challenge. From a case study of a traditional business in adopting new technology, it was found that an underlying issue that impeded effective and efficient managerial decision making lied in the human computer interaction process, and the design of the system user interface can be the culprit. With the rise of big data revolution, it seems that this underlying issue has still not been resolved for the applications to best support the executive users. This paper therefore shares research findings and developments in the social media and human language technology, and suggests employing adaptive user interfaces for big data applications to better support managerial decision making.", "references": ["See S.L. 2000. An Investigation into the Use of the Computer as a Communication Tool in Managerial Work. Master Thesis. Monash University, Australia.", "Meredith, R. and O'Donnell, P. 2010. A functional model of social media and its application to business intelligence. In Bridging the Socio-technical Gap in Decision Support Systems, A. Respicio et al, Eds. IOS Press. DOI= 10.3233/978-1-60750-577-8-129.", "Meredith, R., Remington, S., O'Donnell, P. and Sharma, N. 2012. Transforming organizations with business intelligence: comparing theory with the vendor perspective. In Fusing Decision Support Systems into the Fabric of the Context, A. Respicio and F.Burstein, Eds. IOS Press. DOI= 10.3233/978-1-61499-073-4-89."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781574"}, {"title": "Demo: KinVocal: Detecting Agitated Vocal Events", "authors": ["Asif Salekin\n,", "Hongning Wang\n,", "John Stankovic"], "publication": "SenSys '15: Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems", "abstract": "ABSTRACT\nMany elderly who are suffering from dementia are also suffering from agitation. While most assisted living facilities and home health care situations rely upon caregivers to monitor and record agitation of their patients, the accuracy is limited because the caregiver must be present during the agitation and must record the event properly. Accurate 24-7 data would help physicians with improved diagnoses and care. To solve this problem we developed KinVocal, a system that continuously monitors and detects agitated vocal events and can be used for the elderly population suffering from dementia. KinVocal, using a novel combination of acoustic signal processing and multiple text mining techniques, automatically detects and records the 8 major vocal agitations for dementia patients as defined by the medical community. This includes: constant unwarranted request for attention or help, making verbal sexual advances, crying, screaming, laughing, cursing, speaking in repetitive sentences, and negativism. The novelty of KinVocal includes the comprehensiveness of addressing all 8 vocal events, using the text of the vocalizations only when accurate, combining text and acoustic features when necessary, and employing text mining and feature identification. A comprehensive performance evaluation includes using data from Youtube and movies, controlled experiments, and real in-home deployments. The results show high accuracy for all 8 vocal events.", "references": ["S. Banerjee and T. Pedersen. An adapted lesk algorithm for word sense disambiguation using wordnet. In Computational linguistics and intelligent text processing, pages 136--145. Springer, 2002.", "J. Cohen-Mansfield. Instruction manual for the cohen-mansfield agitation inventory (cmai). Research Institute of the Hebrew Home of Greater Washington, 1991.", "S. Nirjon, C. Greenwood, C. Torres, S. Zhou, J. A. Stankovic, H. J. Yoon, H.-K. Ra, C. Basaran, T. Park, and S. H. Son. Kintense: A robust, accurate, real-time and evolving system for detecting aggressive actions from streaming 3d skeleton data. In Pervasive Computing and Communications (Per- Com), 2014 IEEE International Conference on, pages 2--10. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809695.2817853"}, {"title": "How to design and build new musical interfaces", "authors": ["Sidney Fels\n,", "Michael Lyons"], "publication": "SIGGRAPH '15: ACM SIGGRAPH 2015 Courses", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2776880.2792703"}, {"title": "Resolving Common Analytical Tasks in Text Databases", "authors": ["Sebastian Arnold\n,", "Alexander Löser\n,", "Torsten Kilias"], "publication": "DOLAP '15: Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP", "abstract": "ABSTRACT\nWith the convergence of data warehousing, online analytical processing and the Semantic Web, analytical tasks are no longer only designed and executed by experts. Instead, various users expect to query keyword search engines with analytical intentions. One efficient approach to answer these tasks is to leverage the factual information stored in large-scale text databases. These systems enable analysts to access unstructured text sources from the Web with structured query languages. The challenge of mapping keyword queries to structured queries has been approached in various forms. However, these systems are not able to detect the underlying intent of a task. Thus, they cannot infer the user's expectations towards specificity and form of the results. Moreover, a large fraction of queries for retrieving analytical results is rare. As a result, services for intent-aware task recognition perform poorly or are not even triggered on these long-tail queries. We report from a study over 102,360 query and click patterns from a factual search engine. Our analysis reveals six common analytical tasks: explore, relate, resolve, list, compare and answer. To distinguish among these, we study the effects of syntactical structures in the query, methods for interactive entity detection and query segmentation techniques. We evaluate these features on language models and Naive Bayes classifiers. From our evaluation we report a combined F1 score of 90% for the prediction of task intent from keyword queries.", "references": ["E. Agichtein and L. Gravano. Querying Text Databases for Efficient Information Extraction. In ICDE'03, pages 113--124. IEEE, 2003.", "S. Agrawal, S. Chaudhuri, and G. Das. DBXplorer: A System for Keyword-Based Search over Relational Databases. In ICDE'02, pages 5--16, San Jose, CA, USA, 2002. IEEE.", "A. Aula and D. M. Russell. Complex and Exploratory Web Search. In ISSS'08, Chapel Hill, NC, USA, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811222.2811224"}, {"title": "Tackling variety in event-based systems", "authors": ["Souleiman Hasan\n,", "Edward Curry"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nEvent-based systems follow an interaction model based on three decoupling dimensions: space, time, and synchronization. However, event producers and consumers are tightly coupled by event semantics: types, attributes, and values. That limits scalability in large-scale heterogeneous environments with significant variety such as the Internet of Things (IoT) due to difficulties in establishing semantic agreements at such scales. This paper studies this problem and investigates the suitability of different traditional and emerging approaches for tackling the issue.", "references": ["C. C. Aggarwal, N. Ashish, and A. Sheth. The internet of things: A survey from the data-centric perspective. In Managing and mining sensor data, pages 383--428. Springer, 2013.", "L. Atzori, A. Iera, and G. Morabito. The internet of things: A survey. Computer Networks, 54(15):2787--2805, 2010.", "P. R. Carlile. Transferring, translating, and transforming: An integrative framework for managing knowledge across boundaries. Organization science, 15(5):555--568, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2774215"}, {"title": "A Two-Iteration Clustering Method to Reveal Unique and Hidden Characteristics of Items Based on Text Reviews", "authors": ["Alon Dayan\n,", "Osnat Mokryn\n,", "Tsvi Kuflik"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper presents a new method for extracting unique features of items based on their textual reviews. The method is built of two similar iterations of applying a weighting scheme and then clustering the resultant set of vectors. In the first iteration, restaurants of similar food genres are grouped together into clusters. The second iteration reduces the importance of common terms in each such cluster, and highlights those that are unique to each specific restaurant. Clustering the restaurants again, now according to their unique features, reveals very interesting connections between the restaurants.", "references": ["A. Popescu and O. Etzioni, \"Extracting Product Features and Opinions from Reviews,\" 2004.", "A. Levi, O. Mokryn, C. Diot, and N. Taft, \"Finding a needle in a haystack of reviews: cold start context-based hotel recommender system,\" in Proceedings of the sixth ACM conference on Recommender systems, 2012, pp. 115--122.", "J. McAuley and J. Leskovec, \"Hidden factors and hidden topics,\" in Proceedings of the 7th ACM conference on Recommender systems - RecSys '13, 2013, pp. 165--172."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741707"}, {"title": "Learning Lessons for Second Screen from Board Games", "authors": ["Rinze Leenheer\n,", "David Geerts\n,", "Jeroen Vanattenhoven"], "publication": "TVX '15: Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video", "abstract": "ABSTRACT\nThis paper identifies important requirements for second screen (game) companion apps. Participants were invited to create their own (board) game to play alongside a TV show. Afterwards they were interviewed about their experience. Analyses of the games and interviews lead to some valuable insights in what contributes to an engaging \"TV game\". Lessons learned include: using events on the TV show to influence the game, and striking the right balance between luck and skill elements.", "references": ["Almeida, P., Ferraz, J., Pinho, A., & Costa, D. (2012, July). Engaging viewers through social TV games. In Proceedings of the 10th European conference on Interactive tv and video (pp. 175--184). ACM.", "Cesar, P., Bulterman, D. C., & Jansen, A. J. (2008). Usages of the Secondary Screen in an Interactive Television Environment: Control, Enrich, Share, and Transfer Television Content. In Proc. of the 6th European Conf. on Changing Television Environments (pp. 168--177). Berlin, Heidelberg: Springer-Verlag.", "Geerts, D., Leenheer, R.A., De Grooff, D., Negenman, J., Heijstraten, S. (2014) In Front of And Behind The Second Screen: Viewer and Producer Perspectives on a Companion App. TVX 2014"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745197.2755515"}, {"title": "Tagging of temporal expressions and geological features in scientific articles", "authors": ["Johannes Leveling"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nWe investigate tagging figure and table captions in scientific articles from geology to support visualization of research findings on maps and time-lines. Our proposed approach comprises identifying geological time expressions and geographic and geologic locations without requiring large pre-annotated data. Different tagging approaches are tested and evaluated on a corpus of captions extracted from scientific geological articles. Our baseline method builds on geologic timescale ontologies and GeoNames as gazetteers to facilitate lookup of times and location names. The baseline is evaluated on a development set of captions from 20 documents and the results are analyzed manually to identify causes for tagging errors. We found that the poor performance of the baseline approach is mainly due to i) lack of coverage in the gazetteers, ii) incorrect tagging of person names as location names, and iii) a simplistic gazetteer lookup for capitalized words. We augmented the baseline approach by extending the gazetteers, by adding reference identification to block person names being tagged as locations, by filtering trivial matches, and by augmenting the lookup by correcting capitalization using true casing of words. The different configurations of our extended approach were evaluated on a test set of 80 documents, achieving an improved precision and recall of more than 90%.", "references": ["K. Cohen, S. Finney, and P. Gibbard. International chronostratigraphic chart. Technical report, International Commission on Stratigraphy, 2015.", "S. Cox and S. Richard. A geologic timescale ontology and service. Earth Science Informatics, 8(1):5--19, 2015.", "L. Ferro, L. Gerber, I. Mani, B. Sundheim, and G. Wilson. TIDES 2005 standard for the annotation of temporal expressions. Technical report, Mitre, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837701"}, {"title": "A virtual microgrid platform for the efficient orchestration of multiple energy prosumers", "authors": ["Ioannis Mamounakis\n,", "Dimitrios J. Vergados\n,", "Prodromos Makris\n,", "Emmanouel Varvarigos\n,", "Tasos Mavridis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nThe Smart Energy Grid concept aims to exploit Information and Communication Technologies (ICT) towards making the energy sector more secure, reliable and efficient, while the electricity markets are rapidly becoming more liberalized with new business actors/models being introduced. In particular, passive energy consumers are being transformed into active energy prosumers (i.e. both producers and consumers), while energy aggregation/services companies are emerging as intermediaries in the so called \"Internet of Energy\" arena. Prosumers need to have their energy assets efficiently managed and participate in the market independently of their size and negotiating power, while aggregators aim at maximizing prosumers' benefits by representing them as a single big power entity in the wholesale energy market. This paper introduces the Virtual MicroGrid (VMG) concept, in which multiple energy prosumers are orchestrated into bigger associations towards optimizing the association's benefits. An innovative decision support system platform is presented showcasing that the management of aggregated energy resources can outperform state-of-the-art solutions that manage resources at the individual prosumer's level. The platform's implementation is based on virtualization techniques and a wide range of functionalities are described, tested and validated. Datasets from 37 real-life prosumers are used and results of various decision-making algorithms show that under different system operation contexts, dynamic formation of prosumers' groups (clusterings) can provide remarkable energy savings and monetary profits to the end users.", "references": ["X. Fang, S. Misra, G. Xue, and D. Yang, \"Smart Grid The New and Improved Power Grid: A Survey\", IEEE Communications Surveys & Tutorials, vol. 14(4), pp. 944--980, 2012.", "G. Lyberopoulos, E. Theodoropoulou, I. Mesogiti, P. Makris and E. Varvarigos, \"A Highly-Dynamic and Distributed Operational Framework for Smart Energy Networks\", proceedings of IEEE CAMAD 2014, pp. 120--124, 1--3 December, Athens.", "A. Vaccaro, M. Popov, D. Villacci, and V. V. Terzija, \"An integrated framework for smart microgrids modeling, monitoring, control, communication, and verification,\" Proc. IEEE, vol. 99, no. 1, pp. 119--132, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802012"}, {"title": "Learning Binary Codes for Hashing via Feature Decomposition", "authors": ["Xiao-Jiao Mao\n,", "Zhen-Fei Ju\n,", "Rui Xu\n,", "Yu-Bin Yang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nBinary code learning techniques have been actively studied for hashing based nearest neighbor search in recent years. However, most existing techniques directly map the data into a Hamming space, which ignores the inherent property that original features may lie in different subspaces. To address this issue, this paper proposes a novel method by learning binary codes on the latent components decomposed from the original features of the data. We assume that each latent component represents an underlying feature subspace and similar/dissimilar data may contain the same/different latent components. As a result, the decomposition step distinguishes the original data better and consequently improves the discriminative power of binary codes. The experimental results of image retrieval tasks carried out on the commonly used benchmark datasets show that the proposed method outperforms other state-of-the-art methods on generating similarity-preserving binary codes.", "references": ["M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In ACM SoCG, pages 253--262, 2004.", "J. H. Friedman, J. L. Bentley, and R. A. Finkel. An algorithm for finding best matches in logarithmic expected time. ACM TOMS, 3(3):209--226, 1977.", "A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In VLDB, pages 518--529, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749397"}, {"title": "A Secure Search Engine for the Personal Cloud", "authors": ["Saliha Lallali\n,", "Nicolas Anciaux\n,", "Iulian Sandu Popa\n,", "Philippe Pucheral"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nThe emerging Personal Could paradigm holds the promise of a Privacy-by-Design storage and computing platform where personal data remain under the individual's control while being shared by valuable applications. However, leaving the data management control to user's hands pushes the security issues to the user's platform. This demonstration presents a Secure Personal Cloud Platform relying on a query and access control engine embedded in a tamper resistant hardware device connected to the user's platform. The main difficulty lies in the design of an inverted document index and its related search and update algorithms capable of tackling the strong hardware constraints of these devices. We have implemented our engine on a real tamper resistant hardware device and present its capacity to regulate the access to a personal dataspace. The objective of this demonstration is to show (1) that secure hardware is a key enabler of the Personal Cloud paradigm and (2) that new embedded indexing and querying techniques can tackle the hardware constraints of tamper-resistant devices and provide scalable solutions for the Personal Cloud.", "references": ["Aggarwal, C. C., Ashish, N., and Sheth, A. The internet of things: A survey from the data-centric perspective. In Managing and mining sensor data, 2013.", "Agrawal, D., Ganesan, D., Sitaraman, R., Diao, Y. and Singh, S. Lazy-adaptive tree: An optimized index structure for flash devices. In VLDB, 2(1), 2009.", "Anciaux, N., Bonnet, P., Bouganim, L., Nguyen, B., Sandu Popa, I., and P. Pucheral. Trusted cells: A sea change for personal data services. In CIDR, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735376"}, {"title": "Predicting Continuous Probability Distribution of Image Emotions in Valence-Arousal Space", "authors": ["Sicheng Zhao\n,", "Hongxun Yao\n,", "Xiaolei Jiang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nPrevious works on image emotion analysis mainly focused on assigning a dominated emotion category or the average dimension values to an image for affective image classification and regression. However, this is often insufficient in many applications, as the emotions that are evoked in viewers by an image are highly subjective and different. In this paper, we propose to predict the continuous probability distribution of dimensional image emotions represented in valence-arousal space. By the statistical analysis on the constructed Image-Emotion-Social-Net dataset, we represent the emotion distribution as a Gaussian mixture model (GMM), which is estimated by the EM algorithm. Then we extract commonly used features of different levels for each image. Finally, we formulize the emotion distribution prediction as a multi-task shared sparse regression (MTSSR) problem, which is optimized by iteratively reweighted least squares. Besides, we introduce three baseline algorithms. Experiments conducted on the Image-Emotion-Social-Net dataset demonstrate the superiority of the proposed method, as compared to some state-of-the-art approaches.", "references": ["D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In ACM International Conference on Multimedia, pages 223--232, 2013.", "C. Chen, J. Huang, L. He, and H. Li. Preconditioning for accelerated iteratively reweighted least squares in structured sparsity reconstruction. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2713--2720, 2014.", "T. Chen, F. X. Yu, J. Chen, Y. Cui, Y.-Y. Chen, and S.-F. Chang. Object-based visual sentiment concept analysis and application. In ACM International Conference on Multimedia, pages 367--376, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806354"}, {"title": "Building Effective Query Classifiers: A Case Study in Self-harm Intent Detection", "authors": ["Ashiqur R. KhudaBukhsh\n,", "Paul N. Bennett\n,", "Ryen W. White"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuery-based triggers play a crucial role in modern search systems, e.g., in deciding when to display direct answers on result pages. We address a common scenario in designing such triggers for real-world settings where positives are rare and search providers possess only a small seed set of positive examples to learn query classification models. We choose the critical domain of self-harm intent detection to demonstrate how such small seed sets can be expanded to create meaningful training data with a sizable fraction of positive examples. Our results show that with our method, substantially more positive queries can be found compared to plain random sampling. Additionally, we explored the effectiveness of traditional active learning approaches on classification performance and found that maximum uncertainty performs the best among several other techniques that we considered.", "references": ["Attenberg, J., Melville, P., and Provost, F. (2010). A unified approach to active dual supervision for labeling features and examples. In Machine Learning and Knowledge Discovery in Databases, 40--55.", "Broder, A. (2002). A taxonomy of web search. SIGIR Forum, 36(2): 3--10.", "Broder, A., Fontoura, M., Gabrilovich, E., Joshi, A., Josifovski, V., and Zhang, T. (2007). Robust classification of rare queries using Web knowledge. SIGIR, 231--238."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806594"}, {"title": "An Efficient Astronomical Cross-matching model Based on MapReduce Mechanism", "authors": ["Kuei-sheng Lee\n,", "Meng-feng Tsai\n,", "Yuji Urata\n,", "Kui-yun Huang\n,", "Chi-sheng Huang"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn order to perform an effective cross-matching computation on an enormous amount of text-file-based astronomical observation data, this study proposes an algorithm based on the MapReduce distributed architecture. Such an approach not only greatly enhances the computation speed, but also provides a data structure for storing the computation results. It provides a satisfactory solution not only for cross-matching the entirety of the data, but also for simply updating the changes.", "references": ["Gray, J., Szalay, A., Budavári, T., Lupton, R., Nieto-Santisteban, M. and Thakar, A. Cross-matching multiple spatial observations and dealing with missing data. arXiv preprint cs/07011722007).", "Gray, J., Nieto-Santisteban, M. A. and Szalay, A. S. The zones algorithm for finding points-near-a-point or cross-matching spatial datasets. arXiv preprint cs/07011712007).", "Zhao, Q., Sun, J., Yu, C., Cui, C., Lv, L. and Xiao, J. A paralleled large-scale astronomical cross-matching function. Springer, City, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818888"}, {"title": "A Systematic Study on Approaches to deal with the Systems' Evolution and Customization", "authors": ["Fernanda A. Passos\n,", "Kleber T. O. Santos\n,", "Raphael F. S. Barreto\n,", "Galileu S. de Jesus\n,", "Glayderson J. Nunes\n,", "Lidiany C. Santos"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nSystem developers often face problems in the maintenance and evolution of software systems when they need to customize products to meet different customers needs, by creating new components and modifying existing source code. In this work, it is presented a comparative analysis of existing approaches that deal with variations in Software Product Lines (LPS) through a rigorous study of the state of the art, observing their applicability to handle customizations.", "references": ["M. Antkiewicz and K. Czarnecki. Featureplugin: feature modeling plug-in for eclipse. In Proceedings of the 2004 OOPSLA workshop on eclipse technology eXchange, pages 67-72, Vancouver, British Columbia, Canada, 2004. ACM.", "S. Apel and C. Lengauer. Superimposition: A language-independent approach to software composition. In 7th International Symposium Software Composition, pages 20-35, Budapest, Hungary, 2008. Springer.", "D. Batory. Feature-oriented programming and the ahead tool suite. In Proceedings of the 26th International Conference on Software Engineering (ICSE'04), pages 702-703, Scotland, UK, 2004. IEEE Computer Society."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814133"}, {"title": "Using degraded music quality to encourage a health improving walking pace: BeatClearWalker", "authors": ["Andreas Komninos\n,", "Mark D. Dunlop\n,", "David Rowe\n,", "Allan Hewitt\n,", "Steven Coull"], "publication": "PervasiveHealth '15: Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare", "abstract": "ABSTRACT\nMeeting the target of 8000 steps/day, as recommended by many national governments and health authorities, can provide considerable physical and mental health benefits and is seen as a key target for reducing obesity levels and improving public health. However, to optimize the health benefits, walking should be performed at a \"moderate\" intensity. While there are numerous mobile fitness applications that monitor distance walked, none directly support walking at this cadence nor has there been any research into live feedback for walking cadence. We present a smartphone fitness application to help users learn how to walk at a moderate cadence and maintain that cadence. We apply real-time audio effects that diminish the audio quality of music when the target walking cadence is not being reached. This provides an immersive and intuitive application that can easily be integrated into everyday life as allows users to walk while listening to their own music and encourages eyes-free interaction. In this paper, we introduce our approach, design, initial lab evaluation and a controlled outdoor study. Results show that using music degradation decreases the number of below-cadence steps, that users felt they worked harder with our player and would use it while exercise walking.", "references": ["Brox, E., Fernandez-Luque, L., and Tøllefsen, T. Healthy Gaming--Video Game Design to promote Health. Appl Clin Inf 2, (2011).", "Buttussi, F., Chittaro, L., and Nadalutti, D. Bringing Mobile Guides and Fitness Activities Together: A Solution Based on an Embodied Virtual Trainer. Proc MobileHCI 2006, ACM (2006).", "Cheok, A. D., Goh, K. H., Liu, W., et al. Human Pacman: a mobile, widearea entertainment system based on physical, social, and ubiquitous computing. Personal & Ubiquitous Comp. 8, 2 (2004)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2826165.2826174"}, {"title": "Loosely Coupled In Situ Visualization: A Perspective on Why It's Here to Stay", "authors": ["James Kress\n,", "Scott Klasky\n,", "Norbert Podhorszki\n,", "Jong Choi\n,", "Hank Childs\n,", "David Pugmire"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nIn this position paper, we argue that the loosely coupled in situ processing paradigm will play an important role in high performance computing for the foreseeable future. Loosely coupled in situ is an enabling technique that addresses many of the current issues with tightly coupled in situ, including, ease-of-integration, usability, and fault tolerance. We survey the prominent positives and negatives of both tightly coupled and loosely coupled in situ and present our recommendation as to why loosely coupled in situ is an enabling technique that is here to stay. We then report on some recent experiences with loosely coupled in situ processing, in an effort to explore each of the discussed factors in a real-world environment.", "references": ["S. Ahern, A. Shoshani, K.-L. Ma, A. Choudhary, T. Critchlow, S. Klasky, V. Pascucci, J. Ahrens, E. Bethel, H. Childs, et al. Scientific discovery at the exascale. Report from the DOE ASCR 2011 Workshop on Exascale Data Management, 2011.", "J. C. Bennett, H. Abbasi, P.-T. Bremer, R. Grout, A. Gyulassy, T. Jin, S. Klasky, H. Kolla, M. Parashar, V. Pascucci, et al. Combining in-situ and in-transit processing to enable extreme-scale scientific analysis. In High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for, pages 1--9. IEEE, 2012.", "C. Chang, S. Ku, P. Diamond, Z. Lin, S. Parker, T. Hahm, and N. Samatova. Compressed ion temperature gradient turbulence in diverted tokamak edgea). Physics of Plasmas (1994-present), 16(5):056108, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828623"}, {"title": "I++: interactive galleries for promoting interactive curiosities in web designs", "authors": ["Sergio Peña-Arrázola\n,", "Dimitri H. Masson\n,", "Alexandre Demeure\n,", "Gaëlle Calvary\n,", "Yann Laurillau"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nWeb design galleries are important sources of inspiration in early phases of web design. However they showcase graphical elements without any promotion of interactive features. This paper presents I++, a web design gallery, centered on interaction: it pinpoints the key innovative interactive features of web sites through three levels of presentation of interactivity.", "references": ["Barros, G., & Carneiro, G. (2013, October). A technique to improve sketches of rich interactions. Brazilian Symposium on Human Factors in Computing Systems (pp. 22--31). Brazilian Computer Society.", "Herring, S. R., Chang, C., Krantzler, J., and Bailey B. P. (2009). Getting inspired!: understanding how and why examples are used in creative design practice. SIGCHI Conference on Human Factors in Computing Systems (CHI '09).", "Kumar, R., Talton, J. O., Ahmad, S., & Klemmer, S. R. (2011, May). Bricolage: example-based retargeting for web design. SIGCHI Conference on Human Factors in Computing Systems (pp. 2197--2206). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783614"}, {"title": "Digital public space between layers", "authors": ["Gökcen Keskin"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nToday, when we go out and wander through the city, our digital presence comes with us too. This project tries to define digital public space as a dynamic of urban space, and conceptualizes physical and digital worlds as layers that interacts with each other. In this manner, we are in the space between these two layers and influenced by both.\nMy two cubes illustrate specific influences of digital data in my urban environment, which is Istanbul for this work, through a scenario, in two different conditions. The first condition is our world today where mobile connectivity is ubiquitous and information systems are pervasive. In the second condition, we go back to a decade ago where we do not have our smart phones, hence mobile connectivity. And the scenario is, two friends call each other to meet at a restaurant and travel to their destination.\nBase of the cubes represent the physical world, and our physical presence on it, while the ceiling represents digital realm. The threads show the data flow between these two; the red threads show the digital public date we receive or send and blue ones show phone calls. The 1st cube is full of red threads that stand for our location services, location based social media connections and transportation informations. On the other hand, the 2nd scenario's cube has only two public data transfer which I sent with my public transportation travel card.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783634"}, {"title": "Towards a Distributed Digital Library for Sign Language Content", "authors": ["Frank Shipman\n,", "Ricardo Gutierrez-Osuna\n,", "Tamra Shipman\n,", "Caio Monteiro\n,", "Virendra Karappa"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nThe Internet provides access to content in almost all languages through a combination of crawling, indexing, and ranking capabilities. The ability to locate content on almost any topic has become expected for most users. But it is not the case for those whose primary language is a sign language. Members of this community communicate via the Internet, but they pass around links to videos via email and social media. In this paper, we describe the need for, the architecture of, and initial software components of a distributed digital library of sign language content, called SLaDL. Our initial efforts have been to develop a model of collection development that enables community involvement without assuming it. This goal necessitated the development of video processing techniques that automatically detect sign language content in video.", "references": ["J. Adcock, M. Cooper, L. Denoue, H. Pirsiavash, and L.A. Rowe, \"TalkMiner: A lecture webcast search engine\", Proc. MM, 2010, pp. 241--250.", "N. Cherniavsky, R.E. Ladner, and E.A. Riskin, \"Activity detection in conversational sign language video for mobile telecommunication\", Proc. FG '08, 2008, pp.1--6.", "E. Fox, et al. \"Ensemble PDP-8: eight principles for distributed portals\". Proc. JCDL, 2010, pp. 341--344."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756945"}, {"title": "From Cyber Security Information Sharing to Threat Management", "authors": ["Sarah Brown\n,", "Joep Gommers\n,", "Oscar Serrano"], "publication": "WISCS '15: Proceedings of the 2nd ACM Workshop on Information Sharing and Collaborative Security", "abstract": "ABSTRACT\nAcross the world, organizations have teams gathering threat data to protect themselves from incoming cyber attacks and maintain a strong cyber security posture. Teams are also sharing information, because along with the data collected internally, organizations need external information to have a comprehensive view of the threat landscape. The information about cyber threats comes from a variety of sources, including sharing communities, open-source and commercial sources, and it spans many different levels and timescales. Immediately actionable information are often low-level indicators of compromise, such as known malware hash values or command-and-control IP addresses, where an actionable response can be executed automatically by a system. Threat intelligence refers to more complex cyber threat information that has been acquired or inferred through the analysis of existing information. Information such as the different malware families used over time with an attack or the network of threat actors involved in an attack, is valuable information and can be vital to understanding and predicting attacks, threat developments, as well as informing law enforcement investigations. This information is also actionable, but on a longer time scale. Moreover, it requires action and decision-making at the human level. There is a need for effective intelligence management platforms to facilitate the generation, refinement, and vetting of data, post sharing. In designing such a system, some of the key challenges that exist include: working with multiple intelligence sources, combining and enriching data for greater intelligence, determining intelligence relevance based on technical constructs, and organizational input, delivery into organizational workflows and into technological products. This paper discusses these challenges encountered and summarizes the community requirements and expectations for an all-encompassing Threat Intelligence Management Platform. The requirements expressed in this paper, when implemented, will serve as building blocks to create systems that can maximize value out of a set of collected intelligence and translate those findings into action for a broad range of stakeholders.", "references": ["Allen, J. and Lehrer, N. 1992. DARPA/Rome Laboratory Planning and Scheduling Initiative Knowledge Representation Specification Language (KRSL), Version 2.0.1 Reference Manual. ISX Corporation.", "Aziz, A. System and method of detecting malicious traffic while reducing false positives. US8776229 B1.", "Bonifacio, M. et al. 2004. Peer-Mediated Distributed Knowledge Management. Agent-Mediated Knowledge Management. L. van Elst et al., eds. Springer Berlin Heidelberg. 31--47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808128.2808133"}, {"title": "Towards Use And Reuse Driven Big Data Management", "authors": ["Zhiwu Xie\n,", "Yinlin Chen\n,", "Julie Speer\n,", "Tyler Walters\n,", "Pablo A. Tarazaga\n,", "Mary Kasarda"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWe propose a use and reuse driven big data management approach that fuses the data repository and data processing capabilities in a co-located, public cloud. It answers to the urgent data management needs from the growing number of researchers who don't fit in the big science/small science dichotomy. This approach will allow researchers to more easily use, manage, and collaborate around big data sets, as well as give librarians the opportunity to work alongside the researchers to preserve and curate data while it is still fresh and being actively used. This also provides the technological foundation to foster a sharing culture more aligned with the open source software development paradigm than the lone-wolf, gift-exchanging small science sharing or the top-down, highly structured big science sharing. To materialize this vision, we provide a system architecture consisting of a scalable digital repository system coupled with the co-located cloud storage and cloud computing, as well as a job scheduler and a deployment management system. Motivated by Virginia Tech's Goodwin Hall instrumentation project, we implemented and evaluated a prototype. The results show not only sufficient capacities for this particular case, but also near perfect linear storage and data processing scalabilities under moderately high workload.", "references": ["Academic Preservation Trust: http://aptrust.org/. Accessed: 2015-01--23.", "Amerio, S., Chiarelli, L., dell'Agnello, L., Girolamo, D.D., Gregori, D., Pezzi, M., Prosperini, A., Ricci, P., Rosso, F. and Zani, S. 2014. Long Term Data Preservation for CDF at INFN-CNAF. Journal of Physics: Conference Series. 513, 4 (Jun. 2014), 042011.", "Arora, R., Esteva, M. and Trelogan, J. 2014. Leveraging High Performance Computing for Managing Large and Evolving Data Collections. International Journal of Digital Curation. 9, 2 (Oct. 2014), 17--27."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756924"}, {"title": "The elephant in the room: getting value from Big Data", "authors": ["Serge Abiteboul\n,", "Luna Dong\n,", "Oren Etzioni\n,", "Divesh Srivastava\n,", "Gerhard Weikum\n,", "Julia Stoyanovich\n,", "Fabian M. Suchanek"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2770014"}, {"title": "The Search Strategies of Smartphone Users for Tourism Information: A Reflection of Big Data", "authors": ["Chaang-Iuan Ho\n,", "Yu-Lan Yuan"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis study explores individual and collaborative search strategies used on smartphone platform. Two sample groups (university students and non-students) and three travel products/phases (pre-trip, train/flight ticket and on-site information) were designed as six situational conditions to investigate the usage of various mobile search strategies. Traditional paper-based surveys were conducted to collect data. The research results showed that the student group employed the mobile search strategies either individually or collaboratively more often than their counterpart. In addition, they were better than the non-student group at changing their ways to achieve the goals, on the basis of the characteristics of travel products.", "references": ["Y. Yuan, U. Gretzel and D. Fesenmaier, \"The Role of Information Technology Use in American Convention and Visitors Bureaus\", Tourism Management, Vol. 27, No. 2, pp. 326--341, 2006.", "J. L. Gómez-Barroso, M. Bacigalupo, S. G. Nikolov, R. Companó and C. Feijóo, \"Factors Required for Mobile Search Going Mainstream\", Online Information Review, Vol. 36, No. 6, pp. 846--857, 2012.", "B. Brown and M. Chalmers, \"Tourism and Mobile Technology\", In Proceedings of the 8th European Conference on Computer Supported Cooperative Work, pp. 335--54, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818905"}, {"title": "Clustering Large Undirected Graphs on External Memory", "authors": ["Qin Liu\n,", "Jiakai Xiao\n,", "Weixiong Rao"], "publication": "HotPlanet '15: Proceedings of the 6th International Workshop on Hot Topics in Planet-Scale Measurement", "abstract": "ABSTRACT\nTraditional graph clustering methods perform poorly on real world power-law graphs out of core. To tackle this challenge, in this paper, we propose an algorithm to cluster such large power law graphs in case of small memory size. In the proposed method, clusters (connected components) are formed by removing top degree nodes (hubs) from the graph. In order to minimize the time for selecting hubs, a divide and conquer strategy is adopted so hubs are selected locally. Compared with the state of art Slashbrun [slashburn2], the proposed algorithm can achieve 30$\\times$ faster running time with about 6% more storage cost.", "references": ["P. Boldi and S. Vigna. The webgraph framework i: compression techniques, 2004.", "F. Chierichetti, R. Kumar, S. Lattanzi, M. Mitzenmacher, A. Panconesi, and P. Raghavan. On compressing social networks, 2009.", "T. M. Cover and J. A. Thomas. Elements of information theory. 1991."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2798087.2798089"}, {"title": "Automatically Generating a Concept Hierarchy with Graphs", "authors": ["Pucktada Treeratpituk\n,", "Madian Khabsa\n,", "C. Lee Giles"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWe propose a novel graph-based approach for constructing concept hierarchy from a large text corpus. Our algorithm incorporates both statistical co-occurrences and lexical similarity in optimizing the structure of the taxonomy. To automatically generate topic-dependent taxonomies from a large text corpus, we first extracts topical terms and their relationships from the corpus. The algorithm then constructs a weighted graph representing topics and their associations. A graph partitioning algorithm is then used to recursively partition the topic graph into a taxonomy. For evaluation, we apply our approach to articles, primarily computer science, in the CiteSeerX digital library and search engine.", "references": ["T. Fountain and M. Lapata. Taxonomy induction using hierarchical random graphs. In NAACL HLT, pages 466--476. ACL, 2012.", "G. Karypis and V. Kumar. Multilevel algorithms for multi-constraint graph partitioning. Proceedings of the 1998 ACM/IEEE conference on Supercomputing (CDROM).", "G. Karypis and V. Kumar. A fast and high quality multilevel scheme for partitioning irregular graphs. SIAM Journal on Scientific Computing, Jan 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756967"}, {"title": "Struggling and Success in Web Search", "authors": ["Daan Odijk\n,", "Ryen W. White\n,", "Ahmed Hassan Awadallah\n,", "Susan T. Dumais"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWeb searchers sometimes struggle to find relevant information. Struggling leads to frustrating and dissatisfying search experiences, even if searchers ultimately meet their search objectives. Better understanding of search tasks where people struggle is important in improving search systems. We address this important issue using a mixed methods study using large-scale logs, crowd-sourced labeling, and predictive modeling. We analyze anonymized search logs from the Microsoft Bing Web search engine to characterize aspects of struggling searches and better explain the relationship between struggling and search success. To broaden our understanding of the struggling process beyond the behavioral signals in log data, we develop and utilize a crowd-sourced labeling methodology. We collect third-party judgments about why searchers appear to struggle and, if appropriate, where in the search task it became clear to the judges that searches would succeed (i.e., the pivotal query). We use our findings to propose ways in which systems can help searchers reduce struggling. Key components of such support are algorithms that accurately predict the nature of future actions and their anticipated impact on search outcomes. Our findings have implications for the design of search systems that help searchers struggle less and succeed more.", "references": ["E. Agapie, G. Golovchinsky, and P. Qvarfordt. Leading people to longer queries. In CHI'13, pages 3019--3022, 2013.", "M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: A game for modeling different types of web search success using interaction data. In SIGIR'11, pages 345--354, 2011.", "P. Anick. Using terminological feedback for web search refinement: a log-based study. In SIGIR'03, pages 88--95. ACM, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806488"}, {"title": "Acquiring resource descriptions using social annotations", "authors": ["Zakaria Saoud\n,", "Samir Kechid"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn distributed information retrieval, resource descriptions play a principal role for facilitating the task of other processes, especially the source selection process and the merging process. The previous approach for acquiring resource descriptions was based in different techniques to improve the retrieval process, but they have many limitations. In this paper, we describe a new approach for acquiring precise resource descriptions, based in social annotations available in the bookmarking service.", "references": ["Aly, R., Hiemstra, D., & Demeester, T. (2013, July). Taily: shard selection using the tail of score distributions. In Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval(pp. 673--682). ACM.", "Baillie, M., Carman, M. J., & Crestani, F. (2009). A topic-based measure of resource description quality for distributed information retrieval. In Advances in Information Retrieval (pp. 485--496). Springer Berlin Heidelberg.", "Balakrishnan, R., & Kambhampati, S. (2011, March). SourceRank: relevance and trust assessment for deep web sources based on inter-source agreement. In Proceedings of the 20th international conference on World wide web (pp. 227--236). ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818929"}, {"title": "A general framework to resolve the MisMatch problem in XML keyword search", "authors": ["Zhifeng Bao\n,", "Yong Zeng\n,", "Tok Wang Ling\n,", "Dongxiang Zhang\n,", "Guoliang Li\n,", "H. V. Jagadish"], "publication": "The VLDB Journal — The International Journal on Very Large Data Bases", "abstract": "Abstract\nWhen users issue a query to a database, they have expectations about the results. If what they search for is unavailable in the database, the system will return an empty result or, worse, erroneous mismatch results. We call this problem the MisMatch problem. In this paper, we solve the MisMatch problem in the context of XML keyword search. Our solution is based on two novel concepts that we introduce: target node type and Distinguishability. Target Node Type represents the type of node a query result intends to match, and Distinguishability is used to measure the importance of the query keywords. Using these concepts, we develop a low-cost post-processing algorithm on the results of query evaluation to detect the MisMatch problem and generate helpful suggestions to users. Our approach has three noteworthy features: (1) for queries with the MisMatch problem, it generates the explanation, suggested queries and their sample results as the output to users, helping users judge whether the MisMatch problem is solved without reading all query results; (2) it is portable as it can work with any lowest common ancestor-based matching semantics (for XML data without ID references) or minimal Steiner tree-based matching semantics (for XML data with ID references) which return tree structures as results. It is orthogonal to the choice of result retrieval method adopted; (3) it is lightweight in the way that it occupies a very small proportion of the whole query evaluation time. Extensive experiments on three real datasets verify the effectiveness, efficiency and scalability of our approach. A search engine called XClear has been built and is available at http://xclear.comp.nus.edu.sg.", "references": ["Berkeley, D.B.: http://www.sleepycat.com", "Bao, Z., Ling, T.W., Chen, B., Lu, J.: Effective xml keyword search with relevance oriented ranking. In: ICDE (2009)", "Bao, Z., Lu, J., Ling, T.W., Chen, B.: Towards an effective xml keyword search. IEEE Trans. Knowl. Data Eng. 22(8), 1077---1092 (2010)"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00778-015-0386-1"}, {"title": "Hands and Eyes Free Search", "authors": ["Mark Sanderson"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nThe main focus of IR interface research and development has been on graphical user interfaces. However, a range of user needs are emerging that will drive us to focus increasingly on the challenge of building search engines where both queries and search results are spoken. Now is the time to examine this topic as speech recognition error rates are steadily dropping and are crossing thresholds where text can be reliably recognised. In this talk, I will outline some of the user groups that might need such systems, explain how existing systems, such as SIRI, Google Now, or Cortana, are incomplete solutions, and speculate on how such systems might evolve.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810361"}, {"title": "Developing 3D Imaging Programmes--Workflow and Quality Control", "authors": ["Mona Hess\n,", "Stuart Robson\n,", "Margaret Serpico\n,", "Giancarlo Amati\n,", "Ivor Pridden\n,", "Tonya Nelson"], "publication": "Journal on Computing and Cultural Heritage", "abstract": "Abstract\nThis article reports on a successful project for 3D imaging research, digital applications, and use of new technologies in the museum. The article will focus on the development and implementation of a viable workflow for the production of high-quality 3D models of museum objects, based on the 3D laser scanning and photogrammetry of selected ancient Egyptian artefacts. The development of a robust protocol for the complete process chain for imaging cultural heritage artefacts, from the acquisition of 2D and/or 3D images to the development of interactive applications for the public audience, was a specific objective of the project. The workflow devised by the university museum team combines reference photography and 3D imaging with a curatorial review of the actual object to its digital counterpart. It also integrates methodologies for managing the accompanying metadatasets to record these activities. As final stage deliverables from the process, the museum is making high-quality 3D images of artefacts from its collection available through creation and dissemination of digital 3D multiplatform interactive applications in order to allow remote access and to enhance the museum's public engagement. This short article concludes with practical considerations for a 3D imaging workflow such as time and skills needed, 3D model quality, and expectation management.", "references": ["3DPetrie. 2014. The virtual lives of things. Retrieved September 29, 2015 from http://www.ucl.ac.uk/3dpetriemuseum.", "3DPetrie team. 2014. 3DPetrie: 3D imaging research, digital applications and use of new technologies in the museum. Retrieved September 29, 2015 from http://www.ucl.ac.uk/museums/petrie/research/research-projects/3dpetrie.", "Giancarlo Amati. 2014. The journey of a 3D model into interactive applications. UCL Museums Collection Blog. Retrieved September 29, 2015 from http://www.ucl.ac.uk/museums/petrie/research/research-projects/3dpetrie/3dpetrie-news/2014-02-02Blog."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786760"}, {"title": "In the Mood for Vlog: Multimodal Inference in Conversational Social Video", "authors": ["Dairazalia Sanchez-Cortes\n,", "Shiro Kumano\n,", "Kazuhiro Otsuka\n,", "Daniel Gatica-Perez"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nThe prevalent “share what's on your mind” paradigm of social media can be examined from the perspective of mood: short-term affective states revealed by the shared data. This view takes on new relevance given the emergence of conversational social video as a popular genre among viewers looking for entertainment and among video contributors as a channel for debate, expertise sharing, and artistic expression. From the perspective of human behavior understanding, in conversational social video both verbal and nonverbal information is conveyed by speakers and decoded by viewers. We present a systematic study of classification and ranking of mood impressions in social video, using vlogs from YouTube. Our approach considers eleven natural mood categories labeled through crowdsourcing by external observers on a diverse set of conversational vlogs. We extract a comprehensive number of nonverbal and verbal behavioral cues from the audio and video channels to characterize the mood of vloggers. Then we implement and validate vlog classification and vlog ranking tasks using supervised learning methods. Following a reliability and correlation analysis of the mood impression data, our study demonstrates that, while the problem is challenging, several mood categories can be inferred with promising performance. Furthermore, multimodal features perform consistently better than single-channel features. Finally, we show that addressing mood as a ranking problem is a promising practical direction for several of the mood categories studied.", "references": ["Nalini Ambady and Robert Rosenthal. 1992. Thin slices of expressive behavior as predictors of interpersonal consequences. A meta-analysis. Psychological Bulletin 111, 256--274.", "Joan-Isaac Biel and Daniel Gatica-Perez. 2011. VlogSense: Conversational behavior and social attention in YouTube. ACM Transactions on Multimedia Computing, Communications 7, 1, 33:1--33:21.", "Joan-Isaac Biel and Daniel Gatica-Perez. 2012. The good, the bad, and the angry: Analyzing crowdsourced impressions of vloggers. In Proceedings of International Conference on Weblogs and Social Media."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2641577"}, {"title": "Non-volatile storage", "authors": ["Mihir Nanavati\n,", "Malte Schwarzkopf\n,", "Jake Wires\n,", "Andrew Warfield"], "publication": "Communications of the ACM", "abstract": "Abstract\nImplications of the datacenter's shifting center.", "references": ["Belay, A., et al. IX: A protected dataplane operating system for high throughput and low latency. In Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation.", "Bjørling, M., Axboe, J., Nellans, D. and Bonnet, P. Linux block IO: introducing multi-queue SSD access on multi-core systems. In Proceedings of the 6th International Systems and Storage Conference, 2013.", "Bryant R. E. and O'Hallaron, D.R. Computer Systems: A Programmer's Perspective, Vol. 2. Prentice Hall, Englewood Cliffs, NJ, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814342"}, {"title": "ReqStore: A Software Project Requirements Repository for Supporting PBL Methodology", "authors": ["Paulo Ivo Alves Pordeus\n,", "Carla Ilane Moreira Bezerra\n,", "Emanuel Ferreira Coutinho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nWith the growth of the Information Technology market (IT), a strong demand for different ways to develop software quality has arisen, and therefore a demand for qualified professionals. To enable these professionals, an effective teaching model is necessary for the development and improvement of skills and competencies oriented to the development of real projects with similar complexity to those found in the labor market. For this, the method of teaching Problem Based Learning (PBL) has been applied in different market areas. The PBL use problems designed to initiate, motivate and focus in the acquisition of knowledge through practice, and encourage the development of skills needed in a professional context. This study aims to develop a tool, called ReqStore, to help the teacher while using the PBL methodology with a project requirements repository. As a result of this work, we carried out an experiment in a class of Programming Fundamentals of discipline to validate the effectiveness of tool with use of PBL methodology.", "references": ["Martin, K. and Chinn, Donald. 2005. Collaborative, problem-based learning in computer science. Journal of Computing Sciences in Colleges, v. 21, n. 1, p. 239-245, 2005.", "Savery, J. R. and Duffy, T. M. 1995. Problem based learning: An instructional model and its constructivist framework. Educ Technology, 35(5):31-7.", "Paiva, S. R. 2011. Uma Revisão Sistemática das Pesquisas Realizadas sobre a melhoria no ensino de Engenharia de Software. João Pessoa, UFPB. Relatório Técnico - FPB/CCEN."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814152"}, {"title": "Behavioral Dynamics from the SERP's Perspective: What are Failed SERPs and How to Fix Them?", "authors": ["Julia Kiseleva\n,", "Jaap Kamps\n,", "Vadim Nikulin\n,", "Nikita Makarov"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWeb search is always in a state of flux: queries, their intent, and the most relevant content are changing over time, in predictable and unpredictable ways. Modern search technology has made great strides in keeping up to pace with these changes, but there remain cases of failure where the organic search results on the search engine result page (SERP) are outdated, and no relevant result is displayed. Failing SERPs due to temporal drift are one of the greatest frustrations of web searchers, leading to search abandonment or even search engine switch. Detecting failed SERPs timely and providing access to the desired out-of-SERP results has huge potential to improve user satisfaction. Our main findings are threefold: First, we refine the conceptual model of behavioral dynamics on the web by including the SERP and defining (un)successful SERPs in terms of observable behavior. Second, we analyse typical patterns of temporal change and propose models to predict query drift beyond the current SERP, and ways to adapt the SERP to include the desired results. Third, we conduct extensive experiments on real world search engine traffic demonstrating the viability of our approach. Our analysis of behavioral dynamics at the SERP level gives new insight in one of the primary causes of search failure due to temporal query intent drifts. Our overall conclusion is that the most detrimental cases in terms of (lack of) user satisfaction lead to the largest changes in information seeking behavior, and hence to observable changes in behavior we can exploit to detect failure, and moreover not only detect them but also resolve them.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: a game for modeling different types of web search success using interaction data. In SIGIR, 2011.", "E. Agichtein, E. Brill, and S. T. Dumais. Improving web search ranking by incorporating user behavior information. In SIGIR, pages 19--26, 2006.", "A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between ir effectiveness measures and user satisfaction. In SIGIR, pages 773--774, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806483"}, {"title": "Cross-Scenario Eyeglasses Retrieval via EGYPT Model", "authors": ["Xiaoling Gu\n,", "Pai Peng\n,", "Mengwen Li\n,", "Sai Wu\n,", "Lidan Shou\n,", "Gang Chen"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper, we present FGSS (Fashion Glasses Search System), an innovative cross-scenario eyeglasses retrieval system which automatically recognizes eyeglasses in real-world photos, e.g. the photo of a fashion girl with a stylish pair of eyeglasses, and retrieves a ranking list of visually similar product instances from the database. We propose a novel segmentation-free framework for FGSS to bridge two search gaps, semantic gap and feature gap, where a new type of keypoint-based scheme called EGYPT is tailored for eyeglasses to facilitate the search. In the EGYPT, we use the hybrid descriptors which combine the shape, color and texture features as a feature representation for eyeglasses. The experimental study on the real-world photo dataset and eyeglasses product dataset demonstrates the effectiveness of EGYPT model.", "references": ["S. Belongie, J. Malik, and J. Puzicha. Shape context: A new descriptor for shape matching and object recognition. In NIPS, 2000.", "Y. Kalantidis, L. Kennedy, and L.-J. Li. Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos. In ICMR, 2013.", "S. Liu, Z. Song, G. Liu, C. Xu, H. Lu, and S. Yan. Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set. In CVPR, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749298"}, {"title": "Joint Workshop on Interfaces and Human Decision Making for Recommender Systems (#IntRS)", "authors": ["John O'Donovan\n,", "Nava Tintarev\n,", "Alexander Felfernig\n,", "Peter Brusilovsky\n,", "Giovanni Semeraro\n,", "Pasquale Lops"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAs an interactive intelligent system, recommender systems are developed to give recommendations that match users' preferences. Since the emergence of recommender systems, a large majority of research focuses on objective accuracy criteria and less attention has been paid to how users interact with the system and the efficacy of interface designs from users' perspectives. The field has reached a point where it is ready to look beyond algorithms, into users' interactions, decision making processes, and overall experience. Following from the success of the joint IntRS 2014 workshop and previous workshops on Interfaces and Decisions in Recommender Systems, this workshop will focus on the aspect of integrating different theories of human decision making into the construction of recommender systems. It will focus particularly on the impact of interfaces on decision support and overall satisfaction, and on ways to compare and evaluate novel techniques and applications in this area.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798714"}, {"title": "Exploiting Document Content for Efficient Aggregation of Crowdsourcing Votes", "authors": ["Martin Davtyan\n,", "Carsten Eickhoff\n,", "Thomas Hofmann"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe use of crowdsourcing for document relevance assessment has been found to be a viable alternative to corpus annotation by highly trained experts. The question of quality control is a recurring challenge that is often addressed by aggregating multiple individual assessments of the same topic-document pair from independent workers. In the past, such aggregation schemes have been weighted or filtered by estimates of worker reliability based on a multitude of behavioral features. In this paper, we propose an alternative approach by relying on document information. Inspired by the clustering hypothesis of information retrieval, we assume textually similar documents to show similar degrees of relevance towards a given topic. Following up on this intuition, we propagate crowd-generated relevance judgments to similar documents, effectively smoothing the distribution of relevance labels across the similarity space.\nOur experiments are based on TREC Crowdsourcing Track data and show that even simple aggregation methods utilizing document similarity information significantly improve over majority voting in terms of accuracy as well as cost efficiency.", "references": ["Omar Alonso, Daniel E Rose, and Benjamin Stewart. Crowdsourcing for relevance evaluation. In ACM SigIR Forum, volume 42, pages 9--15. ACM, 2008.", "Roi Blanco, Harry Halpin, Daniel M Herzig, Peter Mika, Jeffrey Pound, Henry S Thompson, and Thanh Tran Duc. Repeatable and reliable search system evaluation using crowdsourcing. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 923--932. ACM, 2011.", "Daren C Brabham. Moving the crowd at threadless: Motivations for participation in a crowdsourcing application. Information, Communication & Society, 13(8):1122--1145, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806460"}, {"title": "TriRank: Review-aware Explainable Recommendation by Modeling Aspects", "authors": ["Xiangnan He\n,", "Tao Chen\n,", "Min-Yen Kan\n,", "Xiao Chen"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMost existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions.", "references": ["S. Baluja, R. Seth, and D. Sivakumar. Video suggestion and discovery for Youtube: Taking random walks through the view graph. In Proc. of WWW '08, pages 895--904, 2008.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003.", "P. Cremonesi, Y. Koren, and R. Turrin. Performance of recommender algorithms on top-n recommendation tasks. In Proc. of RecSys '10, pages 39--46, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806504"}, {"title": "Shuffle Index: Efficient and Private Access to Outsourced Data", "authors": ["Sabrina De Capitani Di Vimercati\n,", "Sara Foresti\n,", "Stefano Paraboschi\n,", "Gerardo Pelosi\n,", "Pierangela Samarati"], "publication": "ACM Transactions on Storage", "abstract": "Abstract\nData outsourcing and cloud computing have been emerging at an ever-growing rate as successful approaches for allowing users and companies to rely on external services for storing and managing data. As data and access to them are not under the control of the data owner, there is a clear need to provide proper confidentiality protection. Such requirements concern the confidentiality not only of the stored data (content) but also of the specific accesses (or patterns of them) that users make on such data.\nIn this article, we address these issues and propose an approach for guaranteeing content, access, and pattern confidentiality in a data outsourcing scenario. The proposed solution is based on the definition of a shuffle index structure, which adapts traditional B +-trees and, by applying a combination of techniques (covers, caches, and shuffling), ensures confidentiality of the data and of queries over them, protecting each single access as well as sequences thereof. The proposed solution also supports update operations over the data, while making reads and writes not recognizable as such by the server. We show that the shuffle index exhibits a limited performance cost, thus resulting effectively usable in practice.", "references": ["D. Agrawal, A. El Abbadi, and S. Wang. 2013. Secure and privacy-preserving database services in the cloud. In Proc. of the 29th International Conference on Data Engineering (ICDE’13).", "R. Agrawal, J. Kierman, R. Srikant, and Y. Xu. 2004. Order preserving encryption for numeric data. In Proc. of the 30th ACM International Conference on Management of Data (SIGMOD’04).", "V. Atluri, B. Shafiq, S. Ae Chun, G. Nabi, and J. Vaidya. 2011. UICDS-based information sharing among emergency response application systems. In Proc. of the 12th Annual International Digital Government Research Conference: Digital Government Innovation in Challenging Times (DG.O’11)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2747878"}, {"title": "A Reputation Revision Mechanism to Mitigate the Negative Effects of Misreported Ratings", "authors": ["Siyuan Liu\n,", "Chunyan Miao\n,", "Yuan Liu\n,", "Hui Fang\n,", "Han Yu\n,", "Jie Zhang\n,", "Yueting Chai\n,", "Cyril Leung"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nReputation systems aggregate the ratings provided by buyers to gauge the reliability of sellers in e-marketplaces. The evaluation accuracy of seller reputation significantly impacts the sellers' future utility. The existence of unfair ratings is well-recognized to negatively affect the accuracy of reputation evaluation. Most of the existing approaches dealing with unfair ratings focus on filtering/discounting/aligning the possible unfair ratings caused by malicious attacks or subjective difference. However, these approaches are not effective against unfair ratings in the form of misreporting (e.g., a well-behaving buyer misjudged a seller and provided a negative rating to a transaction which deserves a positive one, and the buyer is willing to revert the misreported negative rating). In this case, how should the buyer undo the damage caused by such misreported ratings and help the seller recover utility loss? In this paper, we propose a reputation revision mechanism to mitigate the negative effects of the misreported ratings. The proposed mechanism temporarily inflates the reputation of the misjudged seller for a period of time, which allows the seller to recover his utility loss caused by the misreported ratings. Extensive realistic simulation based experiments demonstrate the necessity and effectiveness of the proposed mechanism.", "references": ["http://bbs.taobao.com/catalog/thread/154521-259744203.htm.", "http://community.ebay.com/t5/archive-feedback/recall-a-feedback/qaq-p/5865187.", "http://pages.ebay.com.sg/help/feedback/revision-request.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781570"}, {"title": "Predicting Online Performance of News Recommender Systems Through Richer Evaluation Metrics", "authors": ["Andrii Maksai\n,", "Florent Garcin\n,", "Boi Faltings"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWe investigate how metrics that can be measured offline can be used to predict the online performance of recommender systems, thus avoiding costly A-B testing. In addition to accuracy metrics, we combine diversity, coverage, and serendipity metrics to create a new performance model. Using the model, we quantify the trade-off between different metrics and propose to use it to tune the parameters of recommender algorithms without the need for online testing. Another application for the model is a self-adjusting algorithm blend that optimizes a recommender's parameters over time. We evaluate our findings on data and experiments from news websites.", "references": ["D. Agarwal, B.-C. Chen, P. Elango, and X. Wang. Click shaping to optimize multiple objectives. In KDD, 2011.", "R. Burke. Evaluating the dynamic properties of recommendation algorithms. In RecSys, 2010.", "A. S. Das, M. Datar, A. Garg, and S. Rajaram. Google news personalization: scalable online collaborative filtering. In WWW, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800184"}, {"title": "Web Identity Translator: Behavioral Advertising and Identity Privacy with WIT", "authors": ["Fotios Papaodyssefs\n,", "Costas Iordanou\n,", "Jeremy Blackburn\n,", "Nikolaos Laoutaris\n,", "Konstantina Papagiannaki"], "publication": "HotNets-XIV: Proceedings of the 14th ACM Workshop on Hot Topics in Networks", "abstract": "ABSTRACT\nOnline Behavioral Advertising (OBA) is an important revenue source for online publishers and content providers. However, the extensive user tracking required to enable OBA raises valid privacy concerns. Existing and proposed solutions either block all tracking, therefore breaking OBA entirely, or require significant changes on the current advertising infrastructure, making adoption hard. We propose Web Identity Translator (WIT), a new privacy service running as a proxy or middlebox. WIT stops the original tracking cookies from being set on the browser of users and instead substitutes them by private cookies it controls. Manipulating the mapping between tracking and private cookies WIT maintains permits transparent OBA to continue while simultaneously protecting the identity of users from attacks based on behavioral analysis of browsing patterns.", "references": ["H. Beales. The value of behavioral targeting. http://www.networkadvertising.org/pdfs/Beales_NAI_Study.pdf, 2010.", "S. Guha, B. Cheng, and P. Francis. Privad: Practical privacy in online advertising. In Proceedings of the 8th USENIX Conference on Networked Systems Design and Implementation, NSDI '11, 2011.", "S. Han, V. Liu, Q. Pu, S. Peter, T. Anderson, A. Krishnamurthy, and D. Wetherall. Expressive privacy control with pseudonyms. SIGCOMM Comput. Commun. Rev., 43(4):291--302, Aug. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834050.2834105"}, {"title": "Report on RecSys 2014: Workshop on New Trends in Content-Based Recommender Systems", "authors": ["Toine Bogers\n,", "Marijn Koolen\n,", "Iván Cantador"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nWhile content-based recommendation has been applied successfully in many different domains, it has not seen the same level of attention as collaborative filtering techniques have. However, there are many recommendation domains and applications where content and metadata play a key role, either in addition to or instead of ratings and implicit usage data. For some domains, such as movies, the relationship between content and usage data has seen thorough investigation already, but for many other domains, such as books, news, scientific articles, andWeb pages we still do not know if and how these data sources should be combined to provided the best recommendation performance. The CBRecSys 2014 workshop aimed to address this by providing a dedicated venue for papers dedicated to all aspects of content-based recommender systems.", "references": ["K. Bauman and A. Tuzhilin. Discovering contextual information from user reviews for recommendation purposes. In Proceedings of the 1st Workshop on New Trends in Content-based Recommender Systems co-located with the 8th ACM Conference on Recommender Systems, CBRecSys@RecSys 2014, Foster City, Silicon Valley, California, USA, October 6, 2014., pages 2--9, 2014.", "A. Chow, M. N. Foo, and G. Manai. Hybridrank: A hybrid content-based approach to mobile game recommendations. In Proceedings of the 1st Workshop on New Trends in Content-based Recommender Systems co-located with the 8th ACM Conference on Recommender Systems, CBRecSys@RecSys 2014, Foster City, Silicon Valley, California, USA, October 6, 2014., pages 10--13, 2014.", "O. D. Clercq, M. Schuhmacher, S. P. Ponzetto, and V. Hoste. Exploiting framenet for content-based book recommendation. In Proceedings of the 1st Workshop on New Trends in Content-based Recommender Systems co-located with the 8th ACM Conference on Recommender Systems, CBRecSys@RecSys 2014, Foster City, Silicon Valley, California, USA, October 6, 2014., pages 14--21, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795411"}, {"title": "Improving Microblog Retrieval with Feedback Entity Model", "authors": ["Feifan Fan\n,", "Runwei Qiang\n,", "Chao Lv\n,", "Jianwu Yang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWhen searching over the microblogging, users prefer using queries including terms that represent some specific entities. Meanwhile, tweets, though limited within 140 characters, are often generated with one or more entities. Entities, as an important part of tweets, usually convey rich information for modeling relevance from new perspectives. In this paper, we propose a feedback entity model and integrate it into an adaptive language modeling framework in order to improve the retrieval performance. The feedback entity model is estimated with the latest entity-associated tweets based upon a regularized maximum likelihood criterion. More specifically, we assume that the entity-associated tweets are generated by a mixture model, which consists of the entity model, the domain-specific language model and the collection language model. Experimental results on two public Text Retrieval Conference (TREC) Twitter corpora demonstrate the significant superiority of our approach over the state-of-the-art baselines.", "references": ["A. Z. Broder, M. Fontoura, E. Gabrilovich, A. Joshi, V. Josifovski, and T. Zhang. Robust classification of rare queries using web knowledge. In SIGIR, pages 231--238, New York, NY, USA, 2007. ACM.", "G. Cao, J.-Y. Nie, J. Gao, and S. Robertson. Selecting good expansion terms for pseudo-relevance feedback. In SIGIR, pages 243--250, 2008.", "J. Dalton, L. Dietz, and J. Allan. Entity query feature expansion using knowledge base links. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806461"}, {"title": "Searching Persuasively: Joint Event Detection and Evidence Recounting with Limited Supervision", "authors": ["Xiaojun Chang\n,", "Yao-Liang Yu\n,", "Yi Yang\n,", "Alexander G. Hauptmann"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nMultimedia event detection (MED) and multimedia event recounting (MER) are fundamental tasks in managing large amounts of unconstrained web videos, and have attracted a lot of attention in recent years. Most existing systems perform MER as a post-processing step on top of the MED results. In order to leverage the mutual benefits of the two tasks, we propose a joint framework that simultaneously detects high-level events and localizes the indicative concepts of the events. Our premise is that a good recounting algorithm should not only explain the detection result, but should also be able to assist detection in the first place. Coupled in a joint optimization framework, recounting improves detection by pruning irrelevant noisy concepts while detection directs recounting to the most discriminative evidences. To better utilize the powerful and interpretable semantic video representation, we segment each video into several shots and exploit the rich temporal structures at shot level. The consequent computational challenge is carefully addressed through a significant improvement of the current ADMM algorithm, which, after eliminating all inner loops and equipping novel closed-form solutions for all intermediate steps, enables us to efficiently process extremely large video corpora. We test the proposed method on the large scale TRECVID MEDTest 2014 and MEDTest 2013 datasets, and obtain very promising results for both MED and MER.", "references": ["Trecvid MED 2013. http://nist.gov/itl/iad/mig/med13.cfm.", "Trecvid MED 2014. http://nist.gov/itl/iad/mig/med14.cfm.", "S. Agarwal. The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list. In SDM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806218"}, {"title": "Social Spammer and Spam Message Co-Detection in Microblogging with Social Context Regularization", "authors": ["Fangzhao Wu\n,", "Jinyun Shu\n,", "Yongfeng Huang\n,", "Zhigang Yuan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe popularity of microblogging platforms, such as Twitter, makes them important for information dissemination and sharing. However, they are also recognized as ideal places by spammers to conduct social spamming. Massive social spammers and spam messages heavily hurt the user experience and hinder the healthy development of microblogging systems. Thus, effectively detecting the social spammers and spam messages in microblogging is of great value. Existing studies mainly regard social spammer detection and spam message detection as two separate tasks. However, social spammers and spam messages have strong connections, since social spammers tend to post more spam messages and spam messages have high probabilities to be posted by social spammers. Combining social spammer detection with spam message detection has the potential to boost the performance of each task. In this paper, we propose a unified framework for social spammer and spam message co-detection in microblogging. Our framework utilizes the posting relations between users and messages to combine social spammer detection with spam message detection. In addition, we extract the social relations between users as well as the connections between messages, and incorporate them into our framework as regularization terms over the prediction results. Besides, we introduce an efficient optimization method to solve our framework. Extensive experiments on a real-world microblog dataset demonstrate that our framework can significantly and consistently improve the performance of both social spammer detection and spam message detection.", "references": ["L. Becchetti, C. Castillo, D. Donato, S. Leonardi, and R. A. Baeza-Yates. Link-based characterization and detection of web spam. In AIRWeb, pages 1--8, 2006.", "A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183--202, 2009.", "K. Beck. Analyzing tweets to identify malicious messages. In IEEE International Conference on Electro/Information Technology (EIT), pages 1--5. IEEE, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806560"}, {"title": "Individuality-Preserving Voice Reconstruction for Articulation Disorders Using Text-to-Speech Synthesis", "authors": ["Reina Ueda\n,", "Tetsuya Takiguchi\n,", "Yasuo Ariki"], "publication": "ICMI '15: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nThis paper presents a speech synthesis method for people with articulation disorders. Because the movements of such speakers are limited by their athetoid symptoms, their prosody is often unstable and their speech rate differs from that of a physically unimpaired person, which causes their speech to be less intelligible and, consequently, makes communication with physically unimpaired persons difficult. In order to deal with these problems, this paper describes a Hidden Markov Model(HMM)-based text-to-speech synthesis approach that preserves the individuality of a person with an articulation disorder and aids them in their communication. In our method, a duration model of a physically unimpaired person is used for the HMM synthesis system and an F0 model in the system is trained using the F0 patterns of the physically unimpaired person, with the average F0 being converted to the target F0 in advance. In order to preserve the target speaker's individuality, a spectral model is built from target spectra. Through experimental evaluations, we have confirmed that the proposed method successfully synthesizes intelligible speech while maintaining the target speaker's individuality.", "references": ["Z. Ahmad Khan, P. Green, S. Creer, and S. Cunningham. Reconstructing the voice of an individual following laryngectomy. Augmentative and Alternative Communication, 27(1):61--66, 2011.", "T. Canale and W. C. Campbell. Campbell's operative orthopaedics, volume 12. Technical report, Mosby Year Book, June 2002.", "S. Creer, S. Cunningham, P. Green, and J. Yamagishi. Building personalised synthetic voices for individuals with severe speech impairment. Computer Speech & Language, 27(6):1178--1193, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818346.2820770"}, {"title": "On the k-Independence Required by Linear Probing and Minwise Independence", "authors": ["Mihai Pǎtraşcu\n,", "Mikkel Thorup"], "publication": "ACM Transactions on Algorithms", "abstract": "Abstract\nWe show that linear probing requires 5-independent hash functions for expected constant-time performance, matching an upper bound of Pagh et al. [2009]. More precisely, we construct a random 4-independent hash function yielding expected logarithmic search time for certain keys. For (1 + ϵ)-approximate minwise independence, we show that Ω(lg 1/ϵ)-independent hash functions are required, matching an upper bound of Indyk [2001]. We also show that the very fast 2-independent multiply-shift scheme of Dietzfelbinger [1996] fails badly in both applications.", "references": ["Noga Alon, Martin Dietzfelbinger, Peter Bro Miltersen, Erez Petrank, and Gábor Tardos. 1999. Linear hash functions. Journal of the ACM 46, 5, 667--683.", "Noga Alon and Asaf Nussboim. 2008. k-Wise independent random graphs. In Proceedings of the 49th IEEE Symposium on Foundations of Computer Science (FOCS). 813--822.", "Martin Aumüller, Martin Dietzfelbinger, and Philipp Woelfel. 2014. Explicit and efficient hash families suffice for cuckoo hashing with a stash. Algorithmica 70, 3, 428--456."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2716317"}, {"title": "Identifying cognitive authority in social networks: a conceptual framework", "authors": ["Douglas Francisquini Toledo\n,", "Roberto Pereira\n,", "Edson Oliveira"], "publication": "IHC '15: Proceedings of the 14th Brazilian Symposium on Human Factors in Computing Systems", "abstract": "ABSTRACT\nThe popularization of online social networks has contributed to the appearance of new strategies that consider the relationship and interaction between people as a means to support information search and recommendation. The literature has indicated that a cognitive authority produces and shares information of better quality and relevance for those who recognizes that authority, being a promising concept to support information retrieval and quality judgement on the web. However, identifying such authorities is still a challenge. In this paper, we introduce the idAuthority: a conceptual framework to support the identification of cognitive authorities in social networks. To illustrate its application in a practical context, we instantiate the framework for a real online social network of Inclusive Education teachers, and evaluate its results with a group of six teachers. The results indicate the idAuthority as a promising framework to support the creation of mechanisms for identifying cognitive authorities in specific social networks.", "references": ["Basili, V. R., Selby, R. W., and Hutchens, D. H. Experimentation in software engineering. IEEE Trans. Softw. Eng. 12, 7 (July 1986), 733--743.", "Côgo, F. R. Uma abordagem para o uso do conceito de Folkauthority em sistemas de recuperação de informação. Master's thesis, Universidade Estadual de Maringá, 2012.", "Côgo, F. R., and Pereira, R. We have good information for you: Cognitive authority and information retrieval on the web. In The Evolution of the Internet in the Business Sector: Web 1.0 to Web 3.0. IGI Global, Hershey, 2015, 191--2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3148456.3148498"}, {"title": "Big Crisis Data, an Open Invitation", "authors": ["Carlos Castillo"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe talk will be an introduction for researchers and developers to algorithms and systems for dealing with social media messages during time-critical events, with a focus on natural and man-made disasters. Current methods bring together computational methods from many disciplines, including natural language processing, data mining, and information retrieval.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2822359"}, {"title": "SINGA: A Distributed Deep Learning Platform", "authors": ["Beng Chin Ooi\n,", "Kian-Lee Tan\n,", "Sheng Wang\n,", "Wei Wang\n,", "Qingchao Cai\n,", "Gang Chen\n,", "Jinyang Gao\n,", "Zhaojing Luo\n,", "Anthony K.H. Tung\n,"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nDeep learning has shown outstanding performance in various machine learning tasks. However, the deep complex model structure and massive training data make it expensive to train. In this paper, we present a distributed deep learning system, called SINGA, for training big models over large datasets. An intuitive programming model based on the layer abstraction is provided, which supports a variety of popular deep learning models. SINGA architecture supports both synchronous and asynchronous training frameworks. Hybrid training frameworks can also be customized to achieve good scalability. SINGA provides different neural net partitioning schemes for training large models. SINGA is an Apache Incubator project released under Apache License 2.", "references": ["J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. V. Le, M. Z. Mao, M. Ranzato, A. W. Senior, P. A. Tucker, K. Yang, and A. Y. Ng. Large scale distributed deep networks. In NIPS, pages 1232--1240, 2012.", "G. Hinton, L. Deng, D. Yu, A. rahman Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. S. G. Dahl, and B. Kingsbury. Deep neural networks for acoustic modeling in speech recognition. IEEE Signal Processing Magazine, 29(6):82--97, November 2012.", "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807410"}, {"title": "Report on the Fourth Workshop on Location and the Web (LocWeb 2014)", "authors": ["Dirk Ahlers\n,", "Erik Wilde\n,", "Bruno Martins"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nLocation is a major aspect behind many approaches in Information Retrieval, naturally appearing in diverse forms and as a cross-cutting topic. To give the location topic an adequate venue, LocWeb 2014 restarted a workshop series at the intersection of geospatial search, information management, and Web architecture, with a main focus on location-aware information access. LocWeb has in the past been a 'travelling' workshop, gathering views from different communities, but always centered on the topic of location. As previously, contributions to the workshop reflected a multitude of fields that demand and use location features and geospatial information, and LocWeb 2014 featured presentations that look at the topic of location on the Web from an interdisciplinary perspective. Reflecting this interdisciplinarity, LocWeb 2014 consisted of an interesting variety of contributions from a range of topics: one keynote, four long and two short papers, and a discussion session. This report gives an overview of the workshop and summarizes its major contributions.", "references": ["D. Ahlers, E. Wilde, and B. Martins, editors. LocWeb '14: Proceedings of the 4th International Workshop on Location and the Web, CIKM 2014, New York, NY, USA, 2014. ACM.", "D. Ahlers, E. Wilde, and B. Martins. LocWeb'14 - 4th International Workshop on Location and the Web: CIKM 2014 Workshop Summary. In Proceedings of the 23rd ACM International Conference on Information and Knowledge Management, New York, NY, USA, 2014. ACM.", "C.-W. Chang, Y.-C. Fan, and A. Chen. On the Semantic Annotation of Daily Places: A Machine-Learning Approach. In {1}."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795413"}, {"title": "EBSCAN: An Entanglement-based Algorithm for Discovering Dense Regions in Large Geo-social Data Streams with Noise", "authors": ["Shohei Yokoyama\n,", "Ágnes Bogárdi-Mészöly\n,", "Hiroshi Ishikawa"], "publication": "LBSN'15: Proceedings of the 8th ACM SIGSPATIAL International Workshop on Location-Based Social Networks", "abstract": "ABSTRACT\nThe remarkable growth of social networking services on global positioning system (GPS)-enabled handheld devices has produced enormous amounts of georeferenced big data. Given a large spatial dataset, the challenge is to effectively discover dense regions from the dataset. Dense regions might be the most attractive area in a city or the most dangerous zone of a town. A solution to this problem can be useful in many applications, including marketing, tourism, and social research. Density-based clustering methods, such as DBSCAN, are often used for this purpose. Nevertheless, current spatial clustering methods emphasize density while neglecting human behavior derived from geographical features. In this paper, we propose EBSCAN, which is based on the novel idea of an entanglement-based approach. Our method considers not only spatial information but also human behavior derived from geographical features. Another problem is that competing methods such as DBSCAN have two input parameters. Thus, it is difficult to determine optimal values. EBSCAN requires only a single intuitive parameter, tooFar, to discover dense regions. Finally, we evaluate the effectiveness of the proposed method using both toy examples and real datasets. Our experimentally obtained results reveal the properties of EBSCAN and show that it is >10 times faster than the competitor.", "references": ["Gartner says worldwide pc, tablet and mobile phone combined shipments to reach 2.4 billion units in 2013. http://www.gartner.com/newsroom/id/2408515.", "Most social networks are now mobile first. http://www.statista.com/chart/2109/.", "M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. Optics: Ordering points to identify the clustering structure. In ACM Sigmod Record, volume 28, pages 49--60. ACM, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830657.2830661"}, {"title": "A Customized Checklist for Analyzing Software Transparency in Websites", "authors": ["Fabio Bittencourt Forte\n,", "Patricia Vilain\n,", "Fabiola Ferreira de Macedo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe access to information, in the public sphere, is considered a fundamental right and it is advocated in declarations, conventions and laws. This study is inserted in this context and uses a checklist to identify and explore problems of transparency in existing websites. This checklist is based on checkTrans, where some actions were excluded and some were customized. 30 websites were evaluated through the execution of predefined tasks, observing if they work as the actions suggested by the checklist. The quantitative analysis of the results exhibited evidences of a relation between the quality of the institutions and how their websites complied with checklist suggestions. This analysis also indicates transparency problems in all of the analyzed websites and suggests some corrective actions.", "references": ["Cappelli, C., Leite, J. C. S. P. Transparência de Processos Organizacionais. Universidade Federal Fluminense, LATEC. II Simpósio Internacional de Transparência nos Negócios. 2008.", "Cappelli, C. Uma Abordagem para Transparência em Processos Organizacionais Utilizando Aspectos. 2009. 328p. Tese de Doutorado - Departamento de Informática, Pontifícia Universidade Católica do Rio de Janeiro, Rio de Janeiro, 2009.", "Engiel P., Leite, L. Evoluindo o Catálogo de Transparência: o Estudo do Requisito Não funcional de Entendimento. 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814116"}, {"title": "Describing and Understanding Neighborhood Characteristics through Online Social Media", "authors": ["Mohamed Kafsi\n,", "Henriette Cramer\n,", "Bart Thomee\n,", "David A. Shamma"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nGeotagged data can be used to describe regions in the world and discover local themes. However, not all data produced within a region is necessarily specifically descriptive of that area. To surface the content that is characteristic for a region, we present the geographical hierarchy model (GHM), a probabilistic model based on the assumption that data observed in a region is a random mixture of content that pertains to different levels of a hierarchy. We apply the GHM to a dataset of 8 million Flickr photos in order to discriminate between content (i.e. tags) that specifically characterizes a region (e.g. neighborhood) and content that characterizes surrounding areas or more general themes. Knowledge of the discriminative and non-discriminative terms used throughout the hierarchy enables us to quantify the uniqueness of a given region and to compare similar but distant regions. Our evaluation demonstrates that our model improves upon traditional Naive Bayes classification by 47% and hierarchical TF-IDF by 27%. We further highlight the differences and commonalities with human reasoning about what is locally characteristic for a neighborhood, distilled from ten interviews and a survey that covered themes such as time, events, and prior regional knowledge.", "references": ["S. Ahern, M. Naaman, R. Nair, and J. Yang. World explorer: visualizing aggregate data from unstructured text in geo-referenced collections. In Proceedings of Digital Libraries, pages 1--10. ACM Press, 2007.", "A. Ahmed, L. Hong, and A. Smola. Hierarchical geographical modeling of user locations from social media posts. In Proceedings of WWW'13, 2013.", "L. Backstrom, J. Kleinberg, R. Kumar, and J. Novak. Spatial variation in search engine queries. In Proceedings of WWW'08, pages 357--366. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741133"}, {"title": "Efficient Top-k Query Answering through its Top-N Rewritings Using Views", "authors": ["Wissem Labbadi\n,", "Jalel Akaichi"], "publication": "PIKM '15: Proceedings of the 8th Workshop on Ph.D. Workshop in Information and Knowledge Management", "abstract": "ABSTRACT\nRecently, various algorithms were proposed to speed up top-k query answering by using multiple materialized query results. Nevertheless, for most of the proposed algorithms, a potentially costly view selection operation is required. In fact, the processing cost has been shown to be linear with respect to the number of views and can be exorbitant given the large number of views to be considered. In this paper, we address the problem of identifying the top-N promising views to use for top-k query answering in the presence of a collection of views. We propose a novel algorithm, for handling this problem, which aims to achieve significant reduction in query execution time. Indeed, it considers minimal amount of rewritings that are likely necessary to return the top-k tuples for a top-k query. We consider, also, the problem of how to efficiently exploit the output of the rewritings algorithm to retrieve the top-k tuples through two possible solutions. The results of a thorough experimental study indicate that the proposed algorithm offers a robust solution to the problem of efficient top-k query answering using views since it discards non-promising query rewritings from the view selection process.", "references": ["Pottinger, R., and Levy, A. Y. 2000. A scalable algorithm for answering queries using views. In Proceedings of the 26th VLDB Conference (Cairo, Egypt, 2000), 484--495.", "Ilyas, I. F., Beskales, G., and Soliman, M. A. 2008. A survey of top-k query processing techniques in relational database systems. ACM Comput. Surv. 40, 4 (Oct. 2008).", "Hristidis, V., and Papakonstantinou, Y. 2004. Algorithms and applications for answering ranked queries using ranked views. J. VLDB. 13, 1 (Jan. 2004), 49--70."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809890.2809895"}, {"title": "Generation of a Video Summary on a News Topic Based on SNS Responses to News Stories", "authors": ["Kosuke Kato\n,", "Ichiro Ide\n,", "Daisuke Deguchi\n,", "Hiroshi Murase"], "publication": "CrowdMM '15: Proceedings of the Fourth International Workshop on Crowdsourcing for Multimedia", "abstract": "ABSTRACT\nArchiving news videos is important since they accumulate valuable real-world information. When exploiting them, it is important to track the flow of news topics to understand them thoroughly. In order to do so, a method that structures the chronological semantic relations between news stories, namely the \"topic thread structure\" has been proposed in the past. However, simply viewing videos that compose this structure imposes a user to spend a long time watching detailed reports. On the other hand, Social Networking Services (SNS) have become very popular. SNS users often send and receive information in which they are interested while watching TV. Thus, we propose a method that automatically generates a video summary on a news topic from the general users' viewpoint based on responses of SNS users.", "references": ["P. Duygulu, J. Pan, and D. A. Forsyth. Towards auto-documentary: Tracking the evolution of news stories. In Proceedings of the 12th ACM International Multimedia Conference, pages 820--827. ACM, October 2004. DOI=http://dx.doi.org/10.1145/1027527.1027719", "X. Wu, C.-W. Ngo, and Q. Li. Threading and autodocumenting news videos. IEEE Signal Processing Mag., 23(2):59--68, March 2006. DOI=http://dx.doi.org/10.1109/MSP.2006.1621449%", "I. Ide, T. Kinoshita, T. Takahashi, H. Mo, N. Katayama, S. Satoh, and H. Murase. Efficient tracking of news topics based on chronological semantic structures in a large-scale news video archive. IEICE Trans. on Information and Systems, E95-D(5):1288--1300, May 2012. DOI=http://dx.doi.org/10.1587/transinf.E95.D.1288"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810188.2810189"}, {"title": "How Was It?: Exploiting Smartphone Sensing to Measure Implicit Audience Responses to Live Performances", "authors": ["Claudio Martella\n,", "Ekin Gedik\n,", "Laura Cabrera-Quiros\n,", "Gwenn Englebienne\n,", "Hayley Hung"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nIn this paper, we present an approach to understand the response of an audience to a live dance performance by the processing of mobile sensor data. We argue that exploiting sensing capabilities already available in smart phones enables a potentially large scale measurement of an audience's implicit response to a performance. In this work, we leverage both tri-axial accelerometers, worn by ordinary members of the public during a dance performance, to predict responses to a number of survey answers, comprising enjoyment, immersion, willingness to recommend the event to others, and change in mood. We also analyse how behaviour as a result of seeing a dance performance might be reflected in a people's subsequent social behaviour using proximity and acceleration sensing. To our knowledge, this is the first work where pervasive mobile sensing has been used to investigate spontaneous responses to predict the affective evaluation of a live performance. Using a single body worn accelerometer to monitor a set of audience members, we were able to predict whether they enjoyed the event with a balanced classification accuracy of 90\\%. The collective coordination of the audience's bodily movements also highlighted memorable moments that were reported later by the audience. The effective use of body movements to measure affective responses in such a setting is particularly surprising given that traditionally, physiological signals such as skin conductance or brain-based signals are the more commonly accepted methods to measure implicit affective response. Our experiments open interesting new directions for research on both automated techniques and applications for the implicit tagging of real world events via spontaneous and implicit audience responses during as well as after a performance.", "references": ["USA Today. Providence theater experiments with 'tweet seats', 2013. http://www.usatoday.com/story/tech/2013/01/27/theater-tweet-seats/18686%93/.", "L. Bao and S. Intille. Activity recognition from user-annotated acceleration data. Pervasive Computing, page 1--17, 2004.", "X. Bao, S. Fan, A. Varshavsky, K. Li, and R. Roy Choudhury. Your Reactions Suggest You Liked the Movie: Automatic Content Rating via Reaction Sensing. In Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing, UbiComp '13, page 197--206, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806276"}, {"title": "To Keep or not to Keep: An Expectation-oriented Photo Selection Method for Personal Photo Collections", "authors": ["Andrea Ceroni\n,", "Vassilios Solachidis\n,", "Claudia Niederée\n,", "Olga Papadopoulou\n,", "Nattiya Kanhabua\n,", "Vasileios Mezaris"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nWhen selecting important photos from a personal photo collection - e.g. for creating an enjoyable sub-collection for revisiting or preservation - photos are not considered in isolation. Therefore, collection-level criteria are also taken into account by automated photo selection methods. However, the typical two-step process of first clustering and subsequently picking from the clusters seems to overstress coverage as a criterion when applied to the task of selecting the photos most important to a user. We, therefore, propose a novel expectation-oriented photo selection method, which combines a variety of collection-level and image-level selection criteria in a flexible way. In our evaluation, which is based on large real-world personal photo collections with overall more than 18,000 images, we show that our method outperforms state-of-the-art photo selection methods. In addition, the proposed method does not rely on any manual annotations, making it applicable in realistic settings of personal photo collections.", "references": ["K. Apostolidis, C. Papagiannopoulou, and V. Mezaris. CERTH at MediaEval 2014 synchronization of multi-user event media task. In Proc. of MediaEval 2014 Workshop, 2014.", "R. Arandjelovic and A. Zisserman. All about vlad. In Proc. of CVPR '13, 2013.", "W.-T. Chu and C.-H. Lin. Automatic selection of representative photo and smart thumbnailing using near-duplicate detection. In Proc. of MM '08, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749372"}, {"title": "Combining Generic and Specific Information for Cross-modal Retrieval", "authors": ["Thi Quynh Nhi Tran\n,", "Hervé Le Borgne\n,", "Michel Crucianu"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nCross-modal retrieval increasingly relies on joint statistical models built from large amounts of data represented according to several modalities. However, some information that is poorly represented by these models can be very significant for a retrieval task. We show that, by appropriately identifying and taking such information into account, the results of cross-modal retrieval can be strongly improved. We apply our model to three benchmarks for the text illustration task and find that the more data has misrepresented information, the more our model is comparatively effective.", "references": ["J. Costa Pereira, E. Coviello, G. Doyle, N. Rasiwasia, G. Lanckriet, R. Levy, and N. Vasconcelos. On the role of correlation and abstraction in cross-modal multimedia retrieval. TPAMI, 36(3):521--535, 2014.", "F. Feng, X. Wang, and R. Li. Cross-modal retrieval with correspondence autoencoder. In Proc. of ACM Intl. Conf. on Multimedia, MM '14, 2014.", "Y. Feng and M. Lapata. Topic models for image annotation and text illustration. In Human Language Technologies: 2010 Annual Conf. of the North American Chapter of the Association for Computational Linguistics, HLT '10, pages 831--839, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749348"}, {"title": "Optimization of common table expressions in MPP database systems", "authors": ["Amr El-Helw\n,", "Venkatesh Raghavan\n,", "Mohamed A. Soliman\n,", "George Caragea\n,", "Zhongxian Gu\n,", "Michalis Petropoulos"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nBig Data analytics often include complex queries with similar or identical expressions, usually referred to as Common Table Expressions (CTEs). CTEs may be explicitly defined by users to simplify query formulations, or implicitly included in queries generated by business intelligence tools, financial applications and decision support systems. In Massively Parallel Processing (MPP) database systems, CTEs pose new challenges due to the distributed nature of query processing, the overwhelming volume of underlying data and the scalability criteria that systems are required to meet. In these settings, the effective optimization and efficient execution of CTEs are crucial for the timely processing of analytical queries over Big Data. In this paper, we present a comprehensive framework for the representation, optimization and execution of CTEs in the context of Orca -- Pivotal's query optimizer for Big Data. We demonstrate experimentally the benefits of our techniques using industry standard decision support benchmark.", "references": ["PostgreSQL. http://www.postgresql.org.", "L. Antova, A. El-Helw, M. A. Soliman, Z. Gu, M. Petropoulos, and F. Waas. Optimizing Queries over Partitioned Tables in MPP Systems. In SIGMOD, pages 373--384, 2014.", "C. Bear, A. Lamb, and N. Tran. The Vertica Database: SQL RDBMS for Managing Big Data. In MBDS, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824068"}, {"title": "Public domain rank: identifying notable individuals with the wisdom of the crowd", "authors": ["Allen B. Riddell"], "publication": "OpenSym '15: Proceedings of the 11th International Symposium on Open Collaboration", "abstract": "ABSTRACT\nIdentifying literary, scientific, and technical works of enduring interest is challenging. Few are able to name significant works across more than a handful of domains or languages. This paper introduces an automatic method for identifying authors of notable works throughout history. Notability is defined using the record of which works volunteers have made available in public domain digital editions. A significant benefit of this bottom-up approach is that it also provides a novel and reproducible index of notability for all individuals with Wikipedia pages. This method promises to supplement the work of cultural organizations and institutions seeking to publicize the availability of notable works and prioritize works for preservation and digitization.", "references": ["David Bamman and Noah Smith. Unsupervised Discovery of Biographical Structure in Text. Transactions of the Association for Computational Linguistics, 2, 2014. URL http://www.transacl.org/volume2/.", "Wray L. Buntine and Swapnil Mishra. Experiments with Non-parametric Topic Models. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, pages 881--890, New York, NY, USA, 2014. ACM. ISBN 978-1-4503-2956-9. doi: 10.1145/2623330.2623691. URL http://doi.acm.org/10.1145/2623330.2623691.", "Communia Association. Public Domain Day - 1 January 2011, January 2011. URL http://publicdomainday.org/2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788993.2789850"}, {"title": "Towards a Complete Event Type Taxonomy", "authors": ["Aljaž Košmerlj\n,", "Evgenia Belyaeva\n,", "Gregor Leban\n,", "Marko Grobelnik\n,", "Blaž Fortuna"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe present initial results of our effort to build an extensive and complete taxonomy of events described in news articles. By crawling Wikipedia's current events portal we identified nine top-level event types. Using articles referenced by the portal we built a event type classification model for news articles using lexical and semantic features and present a small-scale manual evaluation of its results. Results show that our model can accurately distinguish between event types but its coverage could still be significantly improved.", "references": ["X. Carreras, L. Padró, L. Zhang, A. Rettinger, Z. Li, E. García-Cuesta, v. Agić, B. Bekavec, B. Fortuna, and T.vStajner. Xlike project language analysis services. In Proceedings of the Demonstrations Session at EACL 2014, pages 9--12, Gothenburg, Sweden, April 2014. Association for Computational Linguistics.", "N. Chambers. Event schema induction with a probabilistic entity-driven model. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1797--1807, 2013.", "N. Chambers and D. Jurafsky. Template-Based Information Extraction without the Templates. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 976--986, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742005"}, {"title": "Multimodal Graph-based Event Detection and Summarization in Social Media Streams", "authors": ["Manos Schinas\n,", "Symeon Papadopoulos\n,", "Georgios Petkos\n,", "Yiannis Kompatsiaris\n,", "Pericles A. Mitkas"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe paper describes a multimodal graph-based system for addressing the Yahoo-Flickr Event Summarization Challenge of ACM Multimedia 2015. The objective is to automatically uncover structure within a collection of 100 million photos/videos in the form of detecting and identifying events, and summarizing them succinctly for consumer consumption. The presented system uses a sliding window over the stream of multimedia items to build and maintain a multimodal same-event image graph and applies a graph clustering algorithm to detect events. In addition, it makes use of a graph-based diversity-oriented ranking approach and a versatile event retrieval mechanism to access summarized instances of the events of interest. A demo of the system is online at http://mklab.iti.gr/acmmm2015-gc/.", "references": ["H. Becker, M. Naaman, and L. Gravano. Learning similarity metrics for event identification in social media. In Proceedings of the Third ACM International Conference on Web Search and Data Mining, WSDM '10, pages 291--300, New York, NY, USA, 2010. ACM.", "J. Bian, Y. Yang, and T.-S. Chua. Multimedia summarization for trending topics in microblogs. In Proceedings of the 22nd ACM international conference on Conference on Information and Knowledge Management, CIKM '13, pages 1807--1812, NY, USA, 2013. ACM.", "D. Chakrabarti and K. Punera. Event summarization using tweets. ICWSM, 11:66--73, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2809933"}, {"title": "Query-based Graph Cuboid Outlier Detection", "authors": ["Ayushi Dalmia\n,", "Manish Gupta\n,", "Vasudeva Varma"], "publication": "ASONAM '15: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015", "abstract": "ABSTRACT\nVarious projections or views of a heterogeneous information network can be modeled using the graph OLAP (On-line Analytical Processing) framework for effective decision making. Detecting anomalous projections of the network can help the analysts identify regions of interest from the graph specific to the projection attribute. While most previous studies on outlier detection in graphs deal with outlier nodes, edges or subgraphs, we are the first to propose detection of graph cuboid outliers. Further we perform this detection in a query sensitive way. Given a general subgraph query on a heterogeneous network, we study the problem of finding outlier cuboids from the graph OLAP lattice. A Graph Cuboid Outlier (GCOutlier) is a cuboid with exceptionally high density of matches for the query. The GCOutlier detection task is clearly challenging because: (1) finding matches for the query (subgraph isomorphism) is NP-hard; (2) number of matches for the query can be very high; and (3) number of cuboids can be large. We provide an approximate solution to the problem by computing only a fraction of the total matches originating from a select set of candidate nodes and including a select set of edges, chosen smartly. We perform extensive experiments on synthetic datasets to showcase the execution time versus accuracy trade-off. Experiments on real datasets like Four Area and Delicious containing thousands of nodes reveal interesting GCOutliers.", "references": ["Chen, C., Yan, X., Zhu, F., Han, J., Yu, P.: Graph OLAP: Towards Online Analytical Processing on Graphs. In: ICDM. (2008) 103--112", "Akoglu, L., McGlohon, M., Faloutsos, C.: Oddball: Spotting Anomalies in Weighted Graphs. In: PAKDD. (2010) 410--421", "Gupta, M., Gao, J., Sun, Y., Han, J.: Integrating Community Matching and Outlier Detection for Mining Evolutionary Community Outliers. In: KDD. (2012) 859--867"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808797.2810061"}, {"title": "Harnessing Big Personal Data, with Scrutable User Modelling for Privacy and Control", "authors": ["Judy Kay"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nMy work aims to enable people to harness, control and manage their big personal data. This is challenging because people are generating vast, and growing, collections of personal data. That data is captured by a rich personal digital ecosystems of devices, some worn or carried, and others are fixed or embedded in the environment. Users explicitly store some data but systems also capture the user's digital footprints, ranging from simple clicks and touches, to images, audio and video. This personal data resides in a quite bewildering range of places, from personal devices to cloud stores, in multitudes of silos.\nBig personal data differs from the scientific big data in important ways. Because it is personal, it should be handled in ways that enable people to ensure it is managed and used as they wish. It may be of modest size compared with scientific big data, but people consider their data stores as big, because they are complex and hard to manage. A driving goal for my research has been to tackle the challenges of big personal data by creating infrastructures, representations and interfaces that enable a user to scrutinize and control their personal data in a scrutable user model.\nOne important role for users models is personalisation, where the user model is a dynamic set of evidence-based beliefs about the user. This is the foundation for personalization, ranging from recommenders to teaching systems. User models may represent anything from the user's attributes to their knowledge, beliefs, goals, plans and preferences.", "references": ["D. Barua, J. Kay, B. Kummerfeld, and C. Paris. Theoretical foundations for user-controlled forgetting in scrutable long term user models. In Proceedings of the 23rd Australian Computer-Human Interaction Conference, pages 40--49. ACM, 2011.", "S. Bull and J. Kay. Open learner models as drivers for metacognitive processes. In International Handbook of Metacognition and Learning Technologies, pages 349--365. Springer, 2013.", "J. Kay and B. Kummerfeld. Creating personalized systems that people can scrutinize and control: Drivers, principles and experience. ACM Transactions on Interactive Intelligent Systems (TiiS), 2(4):24, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806280"}, {"title": "HCI in VANET IR-CAS: Multimodal Interface for VANET Context Aware IR Systems", "authors": ["Lobna Nassar\n,", "Parmit Chilana\n,", "Mohamed S. Kamel\n,", "Fakhri Karray"], "publication": "DIVANet '15: Proceedings of the 5th ACM Symposium on Development and Analysis of Intelligent Vehicular Networks and Applications", "abstract": "ABSTRACT\nWe propose VANET IR-CAS visual-manual and speech-visual dual-mode interface. It improves safety by reducing eye-off road time; compared to two other designs, it has the least eye off road time with < 2 seconds longest eye off road glance. It highly increases convenience and speed of option selection by using large image icons aligned to screen borders or pinned to corners which facilitates options blind selection useful in emergencies or under risky conditions; 95% of usability tests users successfully selected interface options blindly. The speech-visual version proved to be the least distracting with an average of 0.4 seconds longest eye off road glance which is at least five times faster than the second fastest design; the IR-CAS visual-manual version. The interface options adapt to user profiles. Users visually view received services matching their interest and context ordered by relevance. It provides fast access to the continuously updated congestion/crash notifications.", "references": ["American College of Emergency Physicians (ACEP) policy statement. Automatic Crash Notification and Intelligent Transportation Systems: Implications for the Emergency Physician. Policy Resource Education Paper. (2009). Available under Injury prevention category: http://www.acep.org/policystatements/", "Gould, J. D., Conti, J., Hovanyecz, T. Composing letters with a simulated listening typewriter, Communications of the ACM, April (1983), v.26 n.4, 295--308, {doi&gt;10.1145/2163.358100}", "Gross, Jason, \"Improving Usability with Fitts' Law,\" (2011). {Online}. Available from: {http://sixrevisions.com/usabilityaccessibility/improving-usability-with-fitts-law/}"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815347.2830325"}, {"title": "And We Did It Our Way: A Case for Crowdsourcing in a Digital Library for Musicology", "authors": ["David Bainbridge"], "publication": "DLfM '15: Proceedings of the 2nd International Workshop on Digital Libraries for Musicology", "abstract": "ABSTRACT\nThis article makes the case for a digital library based on a crowdsourcing approach for musicology. At its heart, the argument draws upon ideas present in the popular music video TV show Pop-Up Video, a format devised in the late 1990s that embellishes the shown content with info nuggets that popup as bubbles and then disappear, as the video plays. We updated and extended the concept to operate in a web environment, choosing a digital library framework as a way to organize the set of videos contained in the site, and casting the popup information collated and displayed as metadata---aspects that further progress the argument for the developed software architecture being fit-for-purpose as a tool for musicologists. The article presents a walkthrough of the developed site, and then goes on to show how the elements present---particularly the gamification elements that focus on symbolic note content entered through a range of virtual musical instruments: piano, drum-kit and guitar---can be re-purposed for use by musicology scholars.", "references": ["D. Bainbridge and T. C. Bell. An AJAX-based digital music stand for greenstone. In Proc. of the 2009 Joint Int. Conf. on Digital Libraries, JCDL 2009, Austin, TX, USA, June 15--19, 2009, pages 463--464, 2009.", "D. Bainbridge, M. Dewsnip, and I. H. Witten. Searching digital music libraries. Information processing &amp; management, 41(1):41--56, 2005.", "D. Bainbridge, X. Hu, and J. S. Downie. A musical progression with Greenstone: How music content analysis and linked data is helping redefine the boundaries to a music digital library. In Proc. of the 1st Int. Workshop on Digital Libraries for Musicology, DLfM '14, pages 1--8, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2785527.2785529"}, {"title": "Cyberinfrastructure resources enabling creation of the loblolly pine reference transcriptome", "authors": ["Le-Shin Wu\n,", "Carrie L. Ganote\n,", "Thomas G. Doak\n,", "William Barnett\n,", "Keithanne Mockaitis\n,", "Craig A. Stewart"], "publication": "XSEDE '15: Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure", "abstract": "ABSTRACT\nToday's genomics technologies generate more sequence data than ever before possible, and at substantially lower costs, serving researchers across biological disciplines in transformative ways. Building transcriptome assemblies from RNA sequencing reads is one application of next-generation sequencing (NGS) that has held a central role in biological discovery in both model and non-model organisms, with and without whole genome sequence references. A major limitation in effective building of transcriptome references is no longer the sequencing data generation itself, but the computing infrastructure and expertise needed to assemble, analyze and manage the data. Here we describe a currently available resource dedicated to achieving such goals, and its use for extensive RNA assembly of up to 1.3 billion reads representing the massive transcriptome of loblolly pine, using four major assembly software installations. The Mason cluster, an XSEDE second tier resource at Indiana University, provides the necessary fast CPU cycles, large memory, and high I/O throughput for conducting large-scale genomics research. The National Center for Genome Analysis Support, or NCGAS, provides technical support in using HPC systems, bioinformatic support for determining the appropriate method to analyze a given dataset, and practical assistance in running computations. We demonstrate that a sufficient supercomputing resource and good workflow design are elements that are essential to large eukaryotic genomics and transcriptomics projects such as the complex transcriptome of loblolly pine, gene expression data that inform annotation and functional interpretation of the largest genome sequence reference to date.", "references": ["Birol, I., et al., Assembling the 20 Gb white spruce (Picea glauca) genome from whole-genome shotgun sequencing data. Bioinformatics, 2013. 29(12): p. 1492--1497.", "Nystedt, B., et al., The Norway spruce genome sequence and conifer genome evolution. Nature, 2013. 497(7451): p. 579--584.", "Nix, S. Ten Most Common Trees in the United States. About.com Forestry. {cited 2015 4 Apr}; Available from: http://forestry.about.com/b/2012/07/21/ten-most-common-trees-in-the-united-states.htm."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792745.2792748"}, {"title": "Second Workshop on New Trends in Content-based Recommender Systems (CBRecSys 2015)", "authors": ["Toine Bogers\n,", "Marijn Koolen"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWhile content-based recommendation has been applied successfully in many different domains, it has not seen the same level of attention as collaborative filtering techniques have. However, there are many recommendation domains and applications where content and metadata play a key role, either in addition to or instead of ratings and implicit usage data. For some domains, such as movies, the relationship between content and usage data has seen thorough investigation already, but for many other domains, such as books, news, scientific articles, and Web pages we still do not know if and how these data sources should be combined to provided the best recommendation performance. The CBRecSys 2015 workshop aims to address this by providing a dedicated venue for papers dedicated to all aspects of content-based recommendation.", "references": ["T. Bogers, M. Koolen, and I. Cantador, editors. Proceedings of the 1st Workshop on New Trends in Content-based Recommender Systems, co-located with the 8th ACM Conference on Recommender Systems, CBRecSys@RecSys 2014, Foster City, Silicon Valley, California, USA, October 6, 2014, volume 1245 of CEUR Workshop Proceedings. CEUR-WS.org, 2014.", "T. Bogers, M. Koolen, and I. Cantador. Workshop on New Trends in Content-based Recommender Systems: (CBRecSys 2014). In Eighth ACM Conference on Recommender Systems, RecSys '14, Foster City, Silicon Valley, CA, USA - October 06 - 10, 2014, pages 379--380, 2014.", "T. Bogers, M. Koolen, and I. Cantador. Report on RecSys 2014 Workshop on New Trends in Content-Based Recommender Systems. ACM SIGIR Forum, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798718"}, {"title": "Community detection in social networks: an in-depth benchmarking study with a procedure-oriented framework", "authors": ["Meng Wang\n,", "Chaokun Wang\n,", "Jeffrey Xu Yu\n,", "Jun Zhang"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nRevealing the latent community structure, which is crucial to understanding the features of networks, is an important problem in network and graph analysis. During the last decade, many approaches have been proposed to solve this challenging problem in diverse ways, i.e. different measures or data structures. Unfortunately, experimental reports on existing techniques fell short in validity and integrity since many comparisons were not based on a unified code base or merely discussed in theory.\nWe engage in an in-depth benchmarking study of community detection in social networks. We formulate a generalized community detection procedure and propose a procedure-oriented framework for benchmarking. This framework enables us to evaluate and compare various approaches to community detection systematically and thoroughly under identical experimental conditions. Upon that we can analyze and diagnose the inherent defect of existing approaches deeply, and further make effective improvements correspondingly.\nWe have re-implemented ten state-of-the-art representative algorithms upon this framework and make comprehensive evaluations of multiple aspects, including the efficiency evaluation, performance evaluations, sensitivity evaluations, etc. We discuss their merits and faults in depth, and draw a set of take-away interesting conclusions. In addition, we present how we can make diagnoses for these algorithms resulting in significant improvements.", "references": ["C. C. Aggarwal and H. Wang. A survey of clustering algorithms for graph data. Managing and Mining Graph Data, pages 275--301. Springer, 2010.", "B. Bollobás. Modern Graph Theory, volume 184. Springer, 1998.", "D. Bortner and J. Han. Progressive clustering of networks using structure-connected order of traversal. ICDE, pages 653--656, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794370"}, {"title": "Heterogeneous Graph-based Video Search Reranking using Web Knowledge via Social Media Network", "authors": ["Soh Yoshida\n,", "Takahiro Ogawa\n,", "Miki Haseyama"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nGraph-based reranking is effective for refining text-based video search results by making use of the social network structure. Unlike previous works which only focus on an individual video graph, the proposed method leverages the mutual reinforcement of heterogeneous graphs, such as videos and their associated tags obtained by social influence mining. Specifically, propagation of information relevancy across different modalities is performed by exchanging information of inter- and intra-relations among heterogeneous graphs. The proposed method then formulates the video search reranking as an optimization problem from the perspective of Bayesian framework. Furthermore, in order to model the consistency over the modified video graph topology, a local learning regularization with a social community detection scheme is introduced to the framework. Since videos within the same social community have strong semantic correlation, the consistency score estimation becomes feasible. Experimental results obtained by applying the proposed method to a real-world video collection show its effectiveness.", "references": ["E. Apostolidis and V. Mezaris. Fast Shot Segmentation Combining Global and Local Visual Descriptors. In Proc. Int'l Conf. Acoust., Speech., Signal Process., pages 6583--6587, 2014.", "S. Bird, E. Klein, and E. Loper. Natural language processing with Python. O'Reilly, 2009.", "V. Blondel, J. Guillaume, R. Lambiotte, and E. Mech. Fast Unfolding of Communities in Large Networks. J. Stat. Mech, page P10008, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806352"}, {"title": "Cost-Effective Conceptual Design for Information Extraction", "authors": ["Arash Termehchy\n,", "Ali Vakilian\n,", "Yodsawalai Chodpathumwan\n,", "Marianne Winslett"], "publication": "ACM Transactions on Database Systems", "abstract": "Abstract\nIt is well established that extracting and annotating occurrences of entities in a collection of unstructured text documents with their concepts improves the effectiveness of answering queries over the collection. However, it is very resource intensive to create and maintain large annotated collections. Since the available resources of an enterprise are limited and/or its users may have urgent information needs, it may have to select only a subset of relevant concepts for extraction and annotation. We call this subset a conceptual design for the annotated collection. In this article, we introduce and formally define the problem of cost-effective conceptual design where, given a collection, a set of relevant concepts, and a fixed budget, one likes to find a conceptual design that most improves the effectiveness of answering queries over the collection. We provide efficient algorithms for special cases of the problem and prove it is generally NP-hard in the number of relevant concepts. We propose three efficient approximations to solve the problem: a greedy algorithm, an approximate popularity maximization (APM for short), and approximate annotation-benefit maximization (AAM for short). We show that, if there are no constraints regrading the overlap of concepts, APM is a fully polynomial time approximation scheme. We also prove that if the relevant concepts are mutually exclusive, the greedy algorithm delivers a constant approximation ratio if the concepts are equally costly, APM has a constant approximation ratio, and AAM is a fully polynomial-time approximation scheme. Our empirical results using a Wikipedia collection and a search engine query log validate the proposed formalization of the problem and show that APM and AAM efficiently compute conceptual designs. They also indicate that, in general, APM delivers the optimal conceptual designs if the relevant concepts are not mutually exclusive. Also, if the relevant concepts are mutually exclusive, the conceptual designs delivered by AAM improve the effectiveness of answering queries over the collection more than the solutions provided by APM.", "references": ["Serge Abiteboul, Ioana Manolescu, Philippe Rigaux, Marie-Christine Rousset, and Pierre Senellart. 2011. Web Data Management. Cambridge University Press.", "Eugene Agichtein and Luis Gravano. 2003. Querying text databases for efficient information extraction. In Proceedings of the IEEE International Conference on Data Engineering (ICDE'03).", "Michael Anderson, Dolan Antenucci, Victor Bittorf, Matthew Burgess, Michael Cafarella, Arun Kumar, Feng Niu, Yongjoo Park, Christopher Re, and Ce Zhang. 2013. Brainwash: A data system for feature engineering. In Proceedings of the Conference on Innovative Data Systems Research (CIDR'13)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2716321"}, {"title": "adaQAC: Adaptive Query Auto-Completion via Implicit Negative Feedback", "authors": ["Aston Zhang\n,", "Amit Goyal\n,", "Weize Kong\n,", "Hongbo Deng\n,", "Anlei Dong\n,", "Yi Chang\n,", "Carl A. Gunter\n,", "Jiawei Han"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuery auto-completion (QAC) facilitates user query composition by suggesting queries given query prefix inputs. In 2014, global users of Yahoo! Search saved more than 50% keystrokes when submitting English queries by selecting suggestions of QAC. Users' preference of queries can be inferred during user-QAC interactions, such as dwelling on suggestion lists for a long time without selecting query suggestions ranked at the top. However, the wealth of such implicit negative feedback has not been exploited for designing QAC models. Most existing QAC models rank suggested queries for given prefixes based on certain relevance scores.\nWe take the initiative towards studying implicit negative feed- back during user-QAC interactions. This motivates re-designing QAC in the more general \"(static) relevance\"(adaptive) implicit negative feedback? framework. We propose a novel adaptive model adaQAC that adapts query auto-completion to users' implicit negative feedback towards unselected query suggestions. We collect user-QAC interaction data and perform large-scale experiments. Empirical results show that implicit negative feedback significantly and consistently boosts the accuracy of the investigated static QAC models that only rely on relevance scores. Our work compellingly makes a key point: QAC should be designed in a more general framework for adapting to implicit negative feedback.", "references": ["E. Adar, D. S. Weld, B. N. Bershad, and S. S. Gribble. Why we search: visualizing and predicting user behavior. In WWW, 2007.", "Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In WWW, 2011.", "C. M. Bishop. Pattern recognition and machine learning, volume 1. 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767697"}, {"title": "Report on the Evaluation-as-a-Service (EaaS) Expert Workshop", "authors": ["Frank Hopfgartner\n,", "Allan Hanbury\n,", "Henning Müller\n,", "Noriko Kando\n,", "Simon Mercer\n,", "Jayashree Kalpathy-Cramer\n,", "Martin Potthast\n,", "Tim Gollub\n,"], "publication": "ACM SIGIR Forum", "abstract": "Abstract\nIn this report, we summarize the outcome of the \"Evaluation-as-a-Service\" workshop that was held on the 5th and 6th March 2015 in Sierre, Switzerland. The objective of the meeting was to bring together initiatives that use cloud infrastructures, virtual machines, APIs (Application Programming Interface) and related projects that provide evaluation of information retrieval or machine learning tools as a service.", "references": ["Georgios Balikas, Anastasia Krithara, Ioannis Partalas, and Georgios Paliouras. BioASQ: A challenge on large-scale biomedical semantic indexing and questionanswering. In MRMD'15: Proceedings of the Multimodal Retrieval in the Medical Domain Workshop, 2015.", "Georgios Balikas, Ioannis Partalas, Axel-Cyrille Ngonga Ngomo, Anastasia Krithara, and Georgios Paliouras. Results of the BioASQ track of the question answering lab at CLEF 2014. In CLEF'14: Proceedings of the 5th International Conference of the CLEF Initiative, pages 1181--1193. Springer, 2014.", "Krisztian Balog, Liadh Kelly, and Anne Schuth. Head first: Living labs for ad-hoc search evaluation. In CIKM'14: Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 1815--1818, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2795403.2795416"}, {"title": "Boosting the Quality of Approximate String Matching by Synonyms", "authors": ["Jiaheng Lu\n,", "Chunbin Lin\n,", "Wei Wang\n,", "Chen Li\n,", "Xiaokui Xiao"], "publication": "ACM Transactions on Database Systems", "abstract": "Abstract\nA string-similarity measure quantifies the similarity between two text strings for approximate string matching or comparison. For example, the strings “Sam” and “Samuel” can be considered to be similar. Most existing work that computes the similarity of two strings only considers syntactic similarities, for example, number of common words or q-grams. While this is indeed an indicator of similarity, there are many important cases where syntactically-different strings can represent the same real-world object. For example, “Bill” is a short form of “William,” and “Database Management Systems” can be abbreviated as “DBMS.” Given a collection of predefined synonyms, the purpose of this article is to explore such existing knowledge to effectively evaluate the similarity between two strings and efficiently perform similarity searches and joins, thereby boosting the quality of approximate string matching.\nIn particular, we first present an expansion-based framework to measure string similarities efficiently while considering synonyms. We then study efficient algorithms for similarity searches and joins by proposing two novel indexes, called SI-trees and QP-trees, which combine signature-filtering and length-filtering strategies. In order to improve the efficiency of our algorithms, we develop an estimator to estimate the size of candidates to enable an online selection of signature filters. This estimator provides strong low-error, high-confidence guarantees while requiring only logarithmic space and time costs, thus making our method attractive both in theory and in practice. Finally, the experimental results from a comprehensive study of the algorithms with three real datasets verify the effectiveness and efficiency of our approaches.", "references": ["N. Alon, Y. Matias, and M. Szegedy. 1996. The space complexity of approximating the frequency moments. In Proceedings of the 31st Annual ACM Symposium on Theory of Computing (STOC'99). 20--29.", "A. Arasu, S. Chaudhuri, and R. Kaushik. 2008. Transformation-based Framework for Record Matching. In Proceedings of the IEEE 24th International Conference on Data Engineering (ICDE'08). 40--49.", "A. Arasu, S. Chaudhuri, and R. Kaushik. 2009. Learning string transformations from examples. Proc. VLDB 2, 1, 514--525."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818177"}, {"title": "Update Summarization using Semi-Supervised Learning Based on Hellinger Distance", "authors": ["Dingding Wang\n,", "Sahar Sohangir\n,", "Tao Li"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUpdate summarization aims to generate brief summaries of recent documents to capture new information different from earlier documents. In this paper, we propose a new method to generate the sentence similarity graph using a novel similarity measure based on Helliger distance and apply semi-supervised learning on the sentence graph to select the sentences with maximum consistency and minimum redundancy to form the summaries. We use TAC 2011 data to evaluate our proposed method and compare it with existing baselines. The experimental results show the effectiveness of our proposed method.", "references": ["F. Boudin, M. El-Beze, and J. Torres-Moreno. The lia update summarization systems at tac 2008. In Proceedings of TAC 2008, 2008.", "J.-Y. Delort and E. Alfonseca. Dualsum: A topic-model based approach for update summarization. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL '12, pages 214--223, 2012.", "C. Ding, H. D. Simon, R. Jin, and T. Li. A learning framework using green's function and kernel regularization with application to recommender system. In Proceedings of ACM SIGKDD 2007, pages 260--269, ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806628"}, {"title": "Query Suggestion and Data Fusion in Contextual Disambiguation", "authors": ["Milad Shokouhi\n,", "Marc Sloan\n,", "Paul N. Bennett\n,", "Kevyn Collins-Thompson\n,", "Siranush Sarkizova"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nQueries issued to a search engine are often under-specified or ambiguous. The user's search context or background may provide information that disambiguates their information need in order to automatically predict and issue a more effective query. The disambiguation can take place at different stages of the retrieval process. For instance, contextual query suggestions may be computed and recommended to users on the result page when appropriate, an approach that does not require modifying the original query's results. Alternatively, the search engine can attempt to provide efficient access to new relevant documents by injecting these documents directly into search results based on the user's context.\nIn this paper, we explore these complementary approaches and how they might be combined. We first develop a general framework for mining context-sensitive query reformulations for query suggestion. We evaluate our context-sensitive suggestions against a state-of-the-art baseline using a click-based metric. The resulting query suggestions generated by our approach outperform the baseline by 13% overall and by 16% on an ambiguous query subset.\nWhile the query suggestions generated by our approach have higher quality than the existing baselines, we demonstrate that using them naively for injecting new documents into search results can lead to inferior rankings. To remedy this issue, we develop a classifier that decides when to inject new search results using features based on suggestion quality and user context. We show that our context-sensitive result fusion approach (Corfu) improves retrieval quality for ambiguous queries by up to 2.92%. Our approaches can efficiently scale to massive search logs, enabling a data-driven strategy that benefits from observing how users issue and reformulate queries in different contexts.", "references": ["R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. EDBT'04, pages 588--596. Springer-Verlag, 2004.", "Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. WWW '11, pages 107--116. ACM, 2011.", "N. Belkin, P. Kantor, E. Fox, and J. Shaw. Combining the evidence of multiple query representations for information retrieval. Information Processing and Management, 31:431--448, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741646"}, {"title": "Towards contextualized models of spatial relations", "authors": ["Jan Oliver Wallgrün\n,", "Alexander Klippel\n,", "Morteza Karimzadeh"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nWe argue that Geographic Information Retrieval has a lot to gain from the creation of contextualized models of spatial relations that capture how human usage of spatial relational expressions is affected by contextual factors. We propose a framework to develop such models and discuss challenges.", "references": ["K. R. Coventry and S. Garrod. Saying, Seeing, and Acting: The Psychological Semantics of Spatial Prepositions. Psychology Press, Hove, 2004.", "C. Derungs and R. Purves. Where's near? Using web n-grams to explore spatial relations. In GIScience 2014-Extended abstracts, 2014.", "M. Gahegan. Proximity operators for qualitative spatial reasoning. In A. U. Frank and W. Kuhn, editors, Spatial Information Theory, pages 31--44. 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837692"}, {"title": "Towards Efficient Vehicle Classification in Intelligent Transportation Systems", "authors": ["Abdul Jabbar Siddiqui\n,", "Abdelhamid Mammeri\n,", "Azzedine Boukerche"], "publication": "DIVANet '15: Proceedings of the 5th ACM Symposium on Development and Analysis of Intelligent Vehicular Networks and Applications", "abstract": "ABSTRACT\nThe classification of vehicles is an important task in Intelligent Transportation Systems (ITS) for applications such as analyzing traffic, checking for fraud, tracking targets, and other security applications. In the recent years, automated systems to recognize makes and models of oncoming vehicles are gaining attention, utilizing existing infrastructure of traffic cameras. To this end, we present an unexplored approach for vehicle make and model recognition (VMMR) and demonstrate its highly accurate and real-time performance, using a recently published real-world dataset. The encouraging results of our approach pave the way towards efficient large-scale and distributed vehicular surveillance in ITS.", "references": ["D. Arthur and S. Vassilvitskii. K-means+: The Advantages of Careful Seeding. In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 1027--1035, 2007.", "H. Bay, A. Ess, T. Tuytelaars, and L. V. Gool. Speeded-Up Robust Features (SURF). Computer Vision and Image Understanding, 110(3):346 -- 359, 2008.", "L. Breiman. Random forests. Machine Learning, 45(1):5--32, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815347.2815354"}, {"title": "Why creating web page objects manually if it can be done automatically?", "authors": ["Andrea Stocco\n,", "Maurizio Leotta\n,", "Filippo Ricca\n,", "Paolo Tonella"], "publication": "AST '15: Proceedings of the 10th International Workshop on Automation of Software Test", "abstract": "ABSTRACT\nPage Object is a design pattern aimed at making web test scripts more readable, robust and maintainable. The effort to manually create the page objects needed for a web application may be substantial and unfortunately existing tools do not help web developers in such task.\nIn this paper we present Apogen, a tool for the automatic generation of page objects for web applications. Our tool automatically derives a testing model by reverse engineering the target web application and uses a combination of dynamic and static analysis to generate Java page objects for the popular Selenium WebDriver framework. Our preliminary evaluation shows that it is possible to use around 3/4 of the automatic page object methods as they are, while the remaining 1/4 need only minor modifications.", "references": ["S. R. Choudhary, D. Zhao, H. Versee, and A. Orso. WATER: Web application test repair. In Proc. of ETSE 2011, pages 24--29. ACM.", "G. A. Di Lucca, A. R. Fasolino, and P. Tramontana. Reverse engineering web applications: The WARE approach. Journal of Software Maintenance and Evolution, 16(1-2):71--101, 2004.", "M. Leotta, D. Clerissi, F. Ricca, and C. Spadaro. Improving test suites maintainability with the page object pattern: an industrial case study. In Proc. of 6th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2013, pages 108--113. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819261.2819283"}, {"title": "An introduction to information retrieval and the use of map-reduce for text processing", "authors": ["Daniel Taipala"], "publication": "Journal of Computing Sciences in Colleges", "abstract": "Abstract\nAccording to projections by the IDC (International Data Corporation), in their Digital Universe study released in 2012, the amount of data on the planet that is stored and accessible in some fashion will grow to exceed 44 zettabytes by the year 2020 [1]. To give some sense of the scale of a zettabyte, it is one billion terabytes. Most of this data is unstructured meaning that it is not stored or managed in traditional data management or database solutions. Much of this unstructured data is textual or is described with textual meta data meaning that the need for technologies that are able to search for and find useful and meaningful data within this massive universe of data is increasingly important and the demand for IT professionals who understand and can develop solutions capable of searching and analyzing such data is high. This tutorial will introduce basic concepts of text search and analytics. Participants will use map-reduce processes to develop text search and analytics solutions. Applications for search and other text analytics will also be discussed.", "references": ["Adshead, A. (2014, April 9). Data set to grow 10-fold by 2020 as internet of things takes off. Retrieved March 16, 2015, from http://www.computerweekly.com/news/2240217788/Data-set-to-grow-10-fold-by-2020-as-internet-of-things-takes-off"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2831373.2831385"}, {"title": "Session details: Storage systems", "authors": ["Andrew Baumann"], "publication": "SOSP '15: Proceedings of the 25th Symposium on Operating Systems Principles", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3257819"}, {"title": "Comparing Text Mining Algorithms for Predicting Irregularities in Public Accounts", "authors": ["Breno Santana Santos\n,", "Methanias Colaco\n,", "Bruno Cruz da Paixao\n,", "Rafael M. Santos\n,", "Andre Vinicius R. P. Nascimento\n,", "Hallan Cosmo dos Santos\n,"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nInformation systems that support public sector daily activities generate large data sets. As a large proportion of the data in these data sets are text, Text Mining can play an important role in deriving potentially useful and previously unknown information. The overall goal of this paper is evaluate the performance and quality of three text mining classification algorithms applied to detect irregularities in public sector records. To evaluate the algorithms, a tool was designed and a case study was carried out at the Court of Accounts of Sergipe. Performance and Quality metrics were evaluated: mean execution time, accuracy, precision, coverage and F-measure. The results show that the multinomial naive bayes algorithm using inverse document frequency was the best approach to find evidences of travel reimbursement irregularities.", "references": ["Araújo, I. da P. S. 2006. Introdução à Auditoria Operacional (3rd. ed.). FGV Editora, Rio de Janeiro, RJ.", "Araújo, I. da P. S. 1998. Introdução à auditoria: breves apontamentos de aula aplicáveis à área governamental. Egba, Salvador, BA.", "Balinski, R. 2002. Filtragem de informações no ambiente do direito. Master's thesis. Federal University of Rio Grande do Sul (UFRGS), Porto Alegre, Brazil."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814163"}, {"title": "Incomplete Multi-view Clustering via Subspace Learning", "authors": ["Qiyue Yin\n,", "Shu Wu\n,", "Liang Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMulti-view clustering, which explores complementary information between multiple distinct feature sets for better clustering, has a wide range of applications, e.g., knowledge management and information retrieval. Traditional multi-view clustering methods usually assume that all examples have complete feature sets. However, in real applications, it is often the case that some examples lose some feature sets, which results in incomplete multi-view data and notable performance degeneration. In this paper, a novel incomplete multi-view clustering method is therefore developed, which learns unified latent representations and projection matrices for the incomplete multi-view data. To approximate the high level scaled indicator matrix defined to represent class label matrix, the latent representations are expected to be non-negative and column orthogonal. Besides, since data are often with high dimensional and noisy features, the projection matrices are enforced to be sparse so as to select relevant features when learning the latent space. Furthermore, the inter-view and intra-view data structure is preserved to further enhance the clustering performance. To these ends, an objective is developed with efficient optimization strategy and convergence analysis. Extensive experiments demonstrate that our model performs better than the state-of-the-art multi-view clustering methods in various settings.", "references": ["S. Bickel and T. Scheffer. Multi-view clustering. International Conference on Data Mining, 4:19--26, 2004.", "A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. Annual Conference on Computational Learning Theory, pages 92--100, 1998.", "E. Bruno and S. Marchand-Maillet. Multiview clustering: a late fusion approach using latent models. ACM SIGIR Conference on Research and Development in Information Retrieval, pages 736--737, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806526"}, {"title": "RALFIE: a life-logging system for reducing potential radiation exposures", "authors": ["Kyoung-Sook Kim\n,", "Isao Kojima\n,", "Ryoichi Suzuki\n,", "Wataru Naito\n,", "Hirotaka Ogawa"], "publication": "EM-GIS '15: Proceedings of the 1st ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management", "abstract": "ABSTRACT\nAfter the nuclear power plant accident in Fukushima, a significant amount of radioactive materials were released into the environment. The radiation exposure has brought lots of concerns about environments contamination, as well as economic and social consequences. Japan governmental agencies have started to continuously monitor and collect radiation levels by monitoring posts, probe cars and airborne surveys. These monitoring data contribute to estimate the external dose levels of radioactive materials and analyze human effects in the future. In this paper, we introduce the RALFIE (RAdiation Exposure LiFelog Indicator) system to help residents and experts to search for contaminated spots in daily activities and develop a reference guideline for reducing external exposures for individuals with their own data. First we design a model to integrate personal spatio-temporal positions with air dose rates on the real-time radiation monitoring data. Then we compare the relationship between ambient dose equivalent and individuals from D-shuttle sensors. Finally, we discuss how to create semantic trajectories with users' real-time annotation and geographic features with future directions.", "references": ["J. Beyea et al. Accounting for long-term doses in \"worldwide health effects of the fukushima daiichi nuclear accident\". Energy Environmental Science, 6:1042--1045, 2013.", "H. Crabbe et al. Using gis and dispersion modelling tools to assess the effect of the environment on health. Transactions in GIS, 4(3):235--244, 2000.", "J. E. T. Hoeve and M. Z. Jacobson. Worldwide health effects of the fukushima daiichi nuclear accident. Energy Environmental Science, 5:8743--8757, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835596.2835615"}, {"title": "A Map-Reduce based Approach for Mining Group Stock Portfolio", "authors": ["Chun-Hao Chen\n,", "Chao-Chun Chen"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIn this paper, the map-reduce technique is utilized for speeding up the mining process and derived as similar results as our previous approach. The chromosome representation consists of four parts that are a mapper number, grouping part, stock part and portfolio part. According to mapper number, chromosomes in population are divided into subsets and sent to respective mappers. Fitness evaluation and genetic operations are the same with our previous approach, and executed on reducers. The evolution process is repeated until reaching the terminal conditions. Experiments are conducted on a real dataset to show the performance of proposed approach.", "references": ["V. Bevilacqua, V. Pacelli and S. Saladino, \"A novel multi objective genetic algorithm for the portfolio optimization,\" Advanced Intelligent Computing, pp. 186--193, 2012.", "A. L. Blum and R. L. Rivest, \"Training a 3-node neural networks is NP-complete,\" Neural Networks, Vol. 5, pp. 117--127, 1992.", "J. Bermúdez, J. Segura and E. Vercher, \"A multi-objective genetic algorithm for cardinality constrained fuzzy portfolio selection,\" Fuzzy Sets and Systems, Vol. 188, pp. 16--26, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818901"}, {"title": "Ebola data from the Internet: An Opportunity for Syndromic Surveillance or a News Event?", "authors": ["Elad Yom-Tov"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nSyndromic surveillance refers to the analysis of medical information for the purpose of detecting outbreaks of disease earlier than would have been possible otherwise and to estimate the prevalence of the disease in a population. Internet data, especially search engine queries and social media postings, have shown promise in contributing to syndromic surveillance for influenza and dengue fever. Here we focus on the recent outbreak of Ebola Virus Disease and ask whether three major sources of Internet data could have been used for early detection of the outbreak and for its ongoing monitoring. We analyze queries submitted to the Bing search engine, postings made by people using Twitter, and news articles in mainstream media, all collected from both the main infected countries in Africa and from across the world between November 2013 and October 2014.\nOur results indicate that it is unlikely any of the three sources would have provided an alert more than a week before the official announcement of the World Health Organization. Furthermore, over time, the number of Twitter messages and Bing queries related to Ebola are better correlated with the number of news articles than with the number of cases of the disease, even in the most affected countries. Information sought by users was predominantly from news sites and Wikipedia, and exhibited temporal patterns similar to those typical of news events. Thus, it is likely that the majority of Internet data about Ebola stems from news-like interest, not from information needs of people with Ebola. We discuss the differences between the current Ebola outbreak and seasonal influenza with respect to syndromic surveillance, and suggest further research is needed to understand where Internet data can assist in surveillance, and where it cannot.", "references": ["D. Butler. When google got flu wrong. Nature, 494(7436):155, 2013.", "A. Culotta. Towards detecting influenza epidemics by analyzing Twitter messages. In Proceedings of the First Workshop on Social Media Analytics - SOMA '10, pages 115--122, New York, New York, USA, 2010. ACM Press.", "G. Eysenbach. Infodemiology: Tracking flu-related searches on the web for syndromic surveillance. In AMIA 2006 Symposium Proceedings, pages 244--248, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750511.2750512"}, {"title": "Web Intelligence and Communities", "authors": ["Pierre Maret\n,", "Rajendra Akerkar\n,", "Laurent Vercouter"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe World Wide Web (WWW) provides precious means for communication, which goes far beyond the traditional communication media. Web-based communities have become imperative spaces for individuals to seek and share expertise. Networks in these communities usually differ in their topology from other networks such as the World Wide Web. In this paper, we explore some research issues of web intelligence and communities. We will also introduce the WI&C'15 workshop's goal and structure.", "references": ["Akerkar, R. 2013. Big Data Computing. Taylor and Francis/CRC.", "El Morr, C. and Maret P. 2012. Virtual Community Building and the Information Society: Current and Future Directions. IGI Global.", "Rheingold, H. 2000. The Virtual Community: Homesteading on the Electronic Frontier. MIT Press, London."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742137"}, {"title": "Splitting Water: Precision and Anti-Precision to Reduce Pool Bias", "authors": ["Aldo Lipani\n,", "Mihai Lupu\n,", "Allan Hanbury"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nFor many tasks in evaluation campaigns, especially those modeling narrow domain-specific challenges, lack of participation leads to a potential pooling bias due to the scarce number of pooled runs. It is well known that the reliability of a test collection is proportional to the number of topics and relevance assessments provided for each topic, but also to same extent to the diversity in participation in the challenges. Hence, in this paper we present a new perspective in reducing the pool bias by studying the effect of merging an unpooled run with the pooled runs. We also introduce an indicator used by the bias correction method to decide whether the correction needs to be applied or not. This indicator gives strong clues about the potential of a \"good\" run tested on an \"unfriendly\" test collection (i.e. a collection where the pool was contributed to by runs very different from the one at hand). We demonstrate the correctness of our method on a set of fifteen test collections from the Text REtrieval Conference (TREC). We observe a reduction in system ranking error and absolute score difference error.", "references": ["Y. Benjamini and Y. Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society, B57(1), 1995.", "D. Bodoff and P. Li. Test theory for assessing ir test collections. In Proc. of SIGIR, 2007.", "C. Buckley, D. Dimmick, I. Soboroff, and E. Voorhees. Bias and the limits of pooling for large collections. Inf. Ret., 10(6), 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767749"}, {"title": "Crowdsourced Rumour Identification During Emergencies", "authors": ["Richard McCreadie\n,", "Craig Macdonald\n,", "Iadh Ounis"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWhen a significant event occurs, many social media users leverage platforms such as Twitter to track that event. Moreover, emergency response agencies are increasingly looking to social media as a source of real-time information about such events. However, false information and rumours are often spread during such events, which can influence public opinion and limit the usefulness of social media for emergency management. In this paper, we present an initial study into rumour identification during emergencies using crowdsourcing. In particular, through an analysis of three tweet datasets relating to emergency events from 2014, we propose a taxonomy of tweets relating to rumours. We then perform a crowdsourced labeling experiment to determine whether crowd assessors can identify rumour-related tweets and where such labeling can fail. Our results show that overall, agreement over the tweet labels produced were high (0.7634 Fleiss Kappa), indicating that crowd-based rumour labeling is possible. However, not all tweets are of equal difficulty to assess. Indeed, we show that tweets containing disputed/controversial information tend to be some of the most difficult to identify.", "references": ["F. H. Allport and M. Lepkin. Wartime rumors of waste and special privilege: why some people believe them. Abnormal and Social Psychology, 40(1):3, 1945.", "G. W. Allport and L. Postman. The psychology of rumor. 1947.", "O. Alonso and R. Baeza-Yates. Design and implementation of relevance assessments using crowdsourcing. In Advances in information retrieval, pages 153--164. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742573"}, {"title": "Dynamic Matrix Factorization with Priors on Unknown Values", "authors": ["Robin Devooght\n,", "Nicolas Kourtellis\n,", "Amin Mantrach"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nAdvanced and effective collaborative filtering methods based on explicit feedback assume that unknown ratings do not follow the same model as the observed ones not missing at random). In this work, we build on this assumption, and introduce a novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values. When new ratings, users, or items enter the system, we can update the factorization in time independent of the size of data (number of users, items and ratings). Hence, we can quickly recommend items even to very recent users. We test our methods on three large datasets, including two very sparse ones, in static and dynamic conditions. In each case, we outrank state-of-the-art matrix factorization methods that do not use a prior on unknown ratings.", "references": ["S. Balakrishnan and S. Chopra. Collaborative ranking. In Proc. of the 5th ACM WSDM, pages 143--152, 2012.", "S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2009.", "W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin. A fast parallel stochastic gradient method for matrix factorization in shared memory systems. ACM TIST, 6(1):2, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783346"}, {"title": "Knowledge Discovery for research Documents using Improved K-means Technique", "authors": ["Sachin Shinde\n,", "Bharat Tidke"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nClustering focuses to organize a collection of data items into clusters, such that items within a cluster are more \"similar\" to each other than they are to items in the other clusters. The k-means method is one of the most widely used clustering techniques for various applications. Applications like Searching, Retrieving as well as Reading research Documents are more Time consuming because we need more time for searching or reading single papers or document, so it is required that use enhanced search engine which is based on fastest reading algorithm which provides best output or results. So we are proposed Enhanced architecture with improved k-means algorithm, which proposes a method for making the algorithm more effective and efficient, so as to get better clustering with reduced complexity. It will search the base keyword or string of the content from the knowledge database. Proposed work uses the search engine based on clustering and text mining.", "references": ["A. M. Fahim, A. M. Salem, F. A. Torkey and M. A. Ramadan, \"An Efficient enhanced k-means clustering algorithm\", journal of Zhejiang University, 10(7): 16261633, 2006.", "K. A. Abdul Nazeer and M. P. Sebastian, \"Improving the accuracy and e_ciency of the k-means clustering algorithm\", in International Conference on Data Mining and Knowledge Engineering (ICDMKE), Proceedings of the World Congress on Engineering (WCE-2009), Vol 1, London, UK, July 2009.", "Chen Zhang and Shixiong Xia, \"K-means Clustering Algorithm with Improved Initial center\", in Second International Workshop on Knowledge Discovery and Data Mining (WKDD), pp. 790--792, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818570"}, {"title": "A brief perspective on microtask crowdsourcing workflows for interface design", "authors": ["Mengyao Zhao\n,", "André van der Hoek"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nUser interface design, as a crucial part of software design, is complex. Current microtask crowdsourcing workflows do not support its complexity well. The difficulty particularly relates to the process to decompose an interface design task into microtasks. In order to make microtask crowdsourcing more supportive for interface design, we need a workflow that can help task owners to break down interface design tasks more easily. This paper briefly describes three experiments that help inform various aspects of workflow design for interface design through microtask crowdsourcing.", "references": ["J. Howe, \"The rise of crowdsourcing,\" Wired, 14(6), 2006, pp. 1--4.", "A. Kittur, \"Crowdsourcing, collaboration and creativity,\" ACM Crossroads, 17(2), 2010, pp. 22--26.", "A. Kittur, J. Nickerson, M. Bernstein, E. Gerber, A. Shaw, J. Zimmerman, M. Lease, and J. Horton, \"The future of crowd work,\" Conference on Computer Supported Cooperative Work, 2013, pp. 1301--1318."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820125"}, {"title": "Propagating Expiration Decisions in a Search Engine Result Cache", "authors": ["Fethi Burak Sazoglu\n,", "Özgür Ulusoy\n,", "Ismail Sengor Altingovde\n,", "Rifat Ozcan\n,", "Berkant Barla Cambazoglu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nDetecting stale queries in a search engine result cache is an important problem. In this work, we propose a mechanism that propagates the expiration decision for a query to similar queries in the cache to re-adjust their time-to-live values.", "references": ["S. Alici, I. S. Altingovde, R. Ozcan, B. B. Cambazoglu, and O. Ulusoy. Timestamp-based result cache invalidation for web search engines. In SIGIR, pages 973--982, 2011.", "S. Alici, I. S. Altingovde, R. Ozcan, B. B. Cambazoglu, and O. Ulusoy. Adaptive time-to-live strategies for query result caching in web search engines. In ECIR, pages 401--412, 2012.", "X. Bai and F. P. Junqueira. Online result cache invalidation for real-time web search. In SIGIR, pages 641--650, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742772"}, {"title": "Semantic Recommendation Using Linked Open Data", "authors": ["Hsin-Chang Yang\n,", "Chia-Chi Hsu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nIssues on open data have attracted lots of attention from researchers and practitioners of various areas. Besides simply publicizing the data, linked open data (LOD) provide excessive information on relations among data items. Such relations can be used to furniture various tasks for possible performance improvement. In this work, we try to suggest an approach which incorporates semantic information provided through the links in LOD for resource recommendation. We performed experiments on DBpedia and obtained promising results.", "references": ["Open Knowledge Foundation 2012. Open Data Handbook Documentation, Open Knowledge Foundation.", "Berners-Lee, T. 2006. Linked Data. Available at http://www.w3.org/DesignIssues/LinkedData.html.", "Schmachtenberg, M., Bizer, C., and Paulheim, H. 2014. State of the LOD Cloud 2014. Available at http://linkeddatacatalog.dws.informatik.uni-mannheim.de/state/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818933"}, {"title": "Advanced Click Models and their Applications to IR: SIGIR 2015 Tutorial", "authors": ["Aleksandr Chuklin\n,", "Ilya Markov\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis tutorial concerns with more advanced and more recent topics in the area of click models. Here, we discuss recent developments in the area with a particular focus on applications of click models. The tutorial features a guest talk and a live demo where participants have a chance to build their own advanced click model.\nWhile this is the second part of the two half-day tutorials, it is not required for participants to attend the first one. In the beginning of this part, a short introduction to basic click models will be given so that all participants share a common vocabulary. Then, recent advances in click models will be discussed.", "references": ["A. Chuklin, I. Markov, and M. de Rijke. phClick Models for Web Search. Morgan & Claypool, 2015. To appear."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767882"}, {"title": "High-Dimensional Indexing by Sparse Approximation", "authors": ["Pedro Borges\n,", "André Mourão\n,", "João Magalhães"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nIn this paper we propose a high-dimensional indexing technique, based on sparse approximation techniques to speed up the search and retrieval of similar images given a query image feature vector. Feature vectors are stored on an inverted indexed based on a sparsifying dictionary for l0 regression, optimized to reduce the data dimensionality. It concentrates the energy of the original vector on a few coefficients of a higher dimensional representation. The index explores the coefficient locality of the sparse representations, to guide the search through the inverted index. Evaluation on three large-scale datasets showed that our method compares favorably to the state-of-the-art. On a 1 million dataset of SIFT vectors, our method achieved 60.8% precision at 50 by inspecting only 5% of the full dataset, and by using only 1/4 of the time a linear search takes.", "references": ["M. Aharon, M. Elad, and A. Bruckstein. K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation. IEEE Trans. on Sig. Proc., 54(11):4311--4322, Nov. 2006.", "A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. ACM Commun., 51(1):117--122, Jan. 2008.", "A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM J. Img. Sci., 2(1):183--202, Mar. 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749371"}, {"title": "Formation Period Matters: Towards Socially Consistent Group Detection via Dense Subgraph Seeking", "authors": ["Yanhao Zhang\n,", "Lei Qin\n,", "Shengping Zhang\n,", "Hongxun Yao\n,", "Qingming Huang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nGroup detection becomes an important task in crowd behavior surveillance. However, most existing methods ignore the formation persistency characteristics, which predict unreliable interactions when the crowd is realistic and complex. To address this issue, we propose a novel graph-based method to declare that the formation period really matters for detecting social groups in crowd. First, we develop a socially motivated representation by modeling the formation period probability in a Bayesian manner, which results in social and temporal consistency for group member interactions. A graph is then established using individuals as nodes and formation periods as edge weights to reflect pedestrian relationships. In this way, seeking of socially consistent groups is converted into an optimization problem which seeks dense subgraphs with maximum formation likelihood within the graph structure. We employ graph shift optimization to detect groups by finding all the dense subgraphs due to its robust performance. In the experimental results on public datasets, our proposed method clearly outperforms other related state-of-the-art methods.", "references": ["M.-C. Chang et al. Probabilistic group-level motion analysis and scenario recognition. In IEEE ICCV, 2011.", "M. Cristani and Bazzani. Social interaction discovery by statistical analysis of f-formations. In BMVC, 2011.", "W. Ge, R. Collins, and B. Ruback. Automatically detecting the small group structure of a crowd. In IEEE WACV, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749305"}, {"title": "Happy online and in real life too?: how social media interactions affect real life well-being of students in the U.S. and Germany", "authors": ["Anne Suphan\n,", "Bozena Mierzejewska"], "publication": "SMSociety '15: Proceedings of the 2015 International Conference on Social Media & Society", "abstract": "ABSTRACT\nResearch examining the impact of social media use on the well-being of digital natives has resulted in a myriad of opposing outcomes indicating both positive and negative effects. In this paper we examine whether there is a boundary between online and offline interpersonal sphere in the cohort of student digital natives and how does it differ between German student populations and U.S.. From data collected in 2013 and 2014 we find that involvement in Social Networking Sites (SNS) results more in positive emotional outcomes than in negative ones. Secondly, we conclude that there is no significant impact of SNS interactions on real life activities. We explain this striking result by focusing on separation of communication activities in online and offline life contexts. We also report on differences between U.S. and German students. The results of our study show that German students tend to separate between online and offline sphere more strongly.", "references": ["Bargh, J. A. and Mckenna KYA. 2004. The Internet and social life. Annual Review of Psychology 55, 573--590.", "Barker, V. 2012. A generational comparison of social networking sites: The influence of age and social identity. The International Journal of Aging and Human Development 74,2, 163--187.", "Berwick, D. M., Murphy, J. M., Goldman, P. A., Ware, J. E., Barsky AJ and Weinstein MC (1991) Performance of a five-item mental health screening test. Medical Care 29, 2, 169--176."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2789187.2789189"}, {"title": "Profession-Based Person Search in Microblogs: Using Seed Sets to Find Journalists", "authors": ["Mossaab Bagdouri\n,", "Douglas W. Oard"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWe introduce the problem of searching for professionals in microblogging platforms. We describe a study of how a group of professional journalists with some common characteristics (e.g., works in a specific language, belongs to certain region, or specializes in a particular media) can be found. Starting from seed sets of different sizes, social network features and profile content features are used to find additional journalists. The results show that combining the social network features of the reciprocated mentions and a bidirectional friend/follower graph provides a signal stronger than either of them taken independently, that both social network and profile content features are useful, and that profile content features are able to find larger numbers of less prominent journalists. We apply our methods to find the Twitter accounts of British and Arab journalists.", "references": ["M. Bagdouri, W. Webber, D. D. Lewis, and D. W. Oard. Towards minimizing the annotation cost of certified text classification. In CIKM, 2013.", "S. Bergsma, M. Dredze, B. V. Durme, T. Wilson, and D. Yarowsky. Broadly improving user classification via communication-based name and location clustering on Twitter. In NAACL, 2013.", "S. Bergsma, P. McNamee, M. Bagdouri, C. Fink, and T. Wilson. Language identification for creating language-specific Twitter collections. In LSM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806466"}, {"title": "An iterative MapReduce framework for sports-based tweet clustering", "authors": ["Gaurangi Saxena\n,", "Siddharth Santurkar"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nIn recent years, social media has evolved into a vital source for real-time information. Sports is one of the most popular topics on social media and attracts the attention of users all over the world. However, a large amount of data is generated on a daily basis, making it difficult for the fans to follow the topics of their interest. Clustering of these posts can resolve this issue by retrieving unambiguous and distinct topics. MapReduce is a programming paradigm that is very effective in designing distributed applications that can be deployed on the cloud. Clustering algorithms are generally iterative in nature. The performance gain offered by MapReduce cannot be completely realized by these algorithms due to the inherent architectural bottlenecks associated with iterative tasks. Twister is a MapReduce-based framework designed to minimize these bottlenecks. In this paper, we propose a distributed framework that gathers sports-related tweets and clusters them into distinct topics using the DBSCAN algorithm customized for Twister. The accuracy of the framework was analysed using the precision-recall scoring mechanism to determine the set of DBSCAN and framework parameters that result in the best set of clusters. The performance of our framework is evaluated based on our clustering results and simulations using the MRSim simulator. We expect that this framework could be used as a model for performing topic detection over generic tweets. We have used the domain of sports to establish the proof of this concept.", "references": ["Sanderson, Jimmy, and Jeffrey W. Kassing. \"Tweets and blogs.\" Sports media: Transformation, integration, consumption 114 (2011).", "Benhardus, James, and Jugal Kalita. \"Streaming trend detection in twitter.\" International Journal of Web Based Communities 9.1 (2013): 122--139. doi:10.1504/IJWBC.2013.051298", "Tsur, Oren, and Ari Rappoport. \"What's in a hashtag?: content based prediction of the spread of ideas in microblogging communities.\" Proceedings of the fifth ACM international conference on Web search and data mining. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818569"}, {"title": "Gradient-based Signatures for Efficient Similarity Search in Large-scale Multimedia Databases", "authors": ["Christian Beecks\n,", "Merih Seran Uysal\n,", "Judith Hermanns\n,", "Thomas Seidl"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWith the continuous rise of multimedia, the question of how to access large-scale multimedia databases efficiently has become of crucial importance. Given a multimedia database comprising millions of multimedia objects, how to approximate the content-based properties of the corresponding feature representations in order to carry out similarity search efficiently and with high accuracy? In this paper, we propose the concept of gradient-based signatures in order to aggregate content-based features of multimedia objects by means of generative models. We provide theoretical insights into our approach including closed-form expressions for the computation of gradient-based signatures with respect to Gaussian mixture models and additionally investigate different binarization methods for gradient-based signatures in order to query databases comprising millions of multimedia objects with high accuracy in less than one second.", "references": ["R. Agrawal, C. Faloutsos, and A. N. Swami. Efficient similarity search in sequence databases. In FODO, pp. 69--84, 1993.", "I. Assent, A. Wenning, and T. Seidl. Approximation techniques for indexing the earth mover's distance in multimedia databases. In ICDE, page 11, 2006.", "I. Assent, M. Wichterich, T. Meisen, and T. Seidl. Efficient similarity search using the earth mover's distance for large multimedia databases. In ICDE, pp. 307--316, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806459"}, {"title": "A Theoretical Analysis of Two-Stage Recommendation for Cold-Start Collaborative Filtering", "authors": ["Xiaoxue Zhao\n,", "Jun Wang"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we present a theoretical framework for tackling the cold-start collaborative filtering problem, where unknown targets (items or users) keep coming to the system, and there is a limited number of resources (users or items) that can be allocated and related to them. The solution requires a trade-off between exploitation and exploration since with the limited recommendation opportunities, we need to, on one hand, allocate the most relevant resources right away, but, on the other hand, it is also necessary to allocate resources that are useful for learning the target's properties in order to recommend more relevant ones in the future. In this paper, we study a simple two-stage recommendation combining a sequential and a batch solution together. We first model the problem with the partially observable Markov decision process (POMDP) and provide its exact solution. Then, through an in-depth analysis over the POMDP value iteration solution, we identify that an exact solution can be abstracted as selecting resources that are not only highly relevant to the target according to the initial-stage information, but also highly correlated, either positively or negatively, with other potential resources for the next stage. With this finding, we propose an approximate solution to ease the intractability of the exact solution. Our initial results on synthetic data and the MovieLens 100K dataset confirm our theoretical development and analysis.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 2005.", "O. Anava, S. Golan, N. Golbandi, Z. Karnin, R. Lempel, O. Rokhlenko, and O. Somekh. Budget-constrained item cold-start handling in collaborative filtering recommenders via optimal design. In WWW, 2015.", "P. Auer. Using confidence bounds for exploitation-exploration trade-offs. JMLR, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809459"}, {"title": "Analyzing User's Sequential Behavior in Query Auto-Completion via Markov Processes", "authors": ["Liangda Li\n,", "Hongbo Deng\n,", "Anlei Dong\n,", "Yi Chang\n,", "Hongyuan Zha\n,", "Ricardo Baeza-Yates"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nQuery auto-completion (QAC) plays an important role in assisting users typing less while submitting a query. The QAC engine generally offers a list of suggested queries that start with a user's input as a prefix, and the list of suggestions is changed to match the updated input after the user types each keystroke. Therefore rich user interactions can be observed along with each keystroke until a user clicks a suggestion or types the entire query manually. It becomes increasingly important to analyze and understand users' interactions with the QAC engine, to improve its performance. Existing works on QAC either ignored users' interaction data, or assumed that their interactions at each keystroke are independent from others. Our paper pays high attention to users' sequential interactions with a QAC engine in and across QAC sessions, rather than users' interactions at each keystroke of each QAC session separately. Analyzing the dependencies in users' sequential interactions improves our understanding of the following three questions: 1) how is a user's skipping/viewing move at the current keystroke influenced by that at the previous keystroke? 2) how to improve search engines' query suggestions at short keystrokes based on those at latter long keystrokes? and 3) facing a targeted query shown in the suggestion list, why does a user decide to continue typing rather than click the intended suggestion? We propose a probabilistic model that addresses those three questions in a unified way, and illustrate how the model determines users' final click decisions. By comparing with state-of-the-art methods, our proposed model does suggest queries that better satisfy users' intents.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proceedings of the 20th international conference on World wide web, pages 107--116. ACM, 2011.", "H. Bast and I. Weber. Type less, find more: fast autocompletion search with a succinct index. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 364--371. ACM, 2006.", "D. Blei and M. Jordan. Variational inference for dirichlet process mixtures. In Bayesian Analysis, volume 1, pages 121--144, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767723"}, {"title": "A frequency-filtering strategy of obtaining PHI-free sentences from clinical data repository", "authors": ["Dingcheng Li\n,", "Majid Rastegar-Mojarad\n,", "Ravikumar Komandur Elayavilli\n,", "Yanshan Wang\n,", "Saeed Mehrabi\n,", "Yue Yu\n,", "Sunghwan Sohn\n,"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nClinical natural language processing (NLP) has become indispensable in the secondary use of electronic medical records (EMRs). However, it is found that current clinical NLP tools face the problem of portability among different institutes. An ideal solution to this problem is cross-institutional data sharing. However, the legal enforcement of no revelation of protected health information (PHI) obstructs this practice even with the availability of state-of-the-art de-identification tools. In this paper, we investigated the use of a frequency-filtering approach to extract PHI-free sentences utilizing the Enterprise Data Trust (EDT), a large collection of EMRs at Mayo Clinic. Our approach is based on the assumption that sentences appearing frequently tend to contain no PHI. This assumption originates from the observation that there exist a large number of redundant descriptions of similar patient conditions in EDT. Both manual and automatic evaluations on the sentence set with frequencies higher than one show no PHI are found. The promising results demonstrate the potential of sharing highly frequent sentences among institutes.", "references": ["D. Demner-Fushman, W. W. Chapman, and C. J. McDonald, \"What can natural language processing do for clinical decision support?,\" Journal of biomedical informatics, vol. 42, pp. 760--772, 2009.", "D. Demner-Fushman and J. Lin, \"Answer extraction, semantic clustering, and extractive summarization for clinical question answering,\" in Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, 2006, pp. 841--848.", "S. T. Wu, H. Liu, D. Li, C. Tao, M. A. Musen, C. G. Chute, et al., \"Unified Medical Language System term occurrences in clinical notes: a large-scale corpus analysis,\" Journal of the American Medical Informatics Association, pp. amiajnl-2011-000744, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2808752"}, {"title": "Crowdsourced Multimedia Enhanced Spatio-temporal Constraint Based on-Demand Social Network for Group Mobility", "authors": ["Bilal Sadiq\n,", "Md. Abdur Rahman\n,", "Abdullah Murad\n,", "Muhammad Shahid\n,", "Faizan Ur Rehman\n,", "Ahmed Lbath\n,", "Akhlaq Ahmad\n,", "Ahmad Qamar"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper presents a system that enables efficient and scalable real-time user and vehicle discovery using textual, audio and video mechanisms. The system allows users to group together for shared intra-city transportation with the aid of multimedia that helps individuals to 1) find community of common interest (CoCI), 2) locate individual users in a large crowd and 3) locate vehicles for mobility in an efficient and cost effective manner. The system is a pilot project and will be deployed during Hajj 2015 when over three million pilgrims from all over the world visit Makkah, Saudi Arabia.", "references": ["Batty, M. 2013. Big data, smart cities and city planning. Dialogues in Human Geography. 3, 3, 274--279.", "Magdy, A. et al. 2014. Taghreed. Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems - SIGSPATIAL '14, 163--172.", "Mehta, T. and Narmawala, Z. 2011. Survey on multimedia transmission using Network Coding over Wireless Networks. 2011 Nirma University International Conference on Engineering, 1--6."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807986"}, {"title": "In-House Solution for the RecSys Challenge 2015", "authors": ["Nadav Cohen\n,", "Adi Gerzi\n,", "David Ben-Shimon\n,", "Bracha Shapira\n,", "Lior Rokach\n,", "Michael Friedmann"], "publication": "RecSys '15 Challenge: Proceedings of the 2015 International ACM Recommender Systems Challenge", "abstract": "ABSTRACT\nRecSys Challenge 2015 is about predicting the items a user will buy in a given click session. We describe the in-house solution to the challenge as guided by the YOOCHOOSE team. The presented solution achieved 14th place in the challenge's final leaderboard with a score of 51,932 points, while the winner obtained 63,102 points.\nWe suggest two simple and easy to reconstruct approaches for obtaining a prediction in each session. In the first approach we suggest one classifier to determine whether each item in the session will be bought. In the second approach we suggest a two level classification model in which the first level determines whether the session is going to end with a purchase or not, and if it ends with a purchase, the second level classification determines the items that are going to be purchased.", "references": ["Ben-Shimon, D., Tsikinovsky, A., Friedman M., Shapira, B., Rokach, L., Hoerle J. RecSys challenge 2015 and the YOOCHOOSE dataset. In ACM RecSys, 2015.", "Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). The WEKA data mining software: an update. ACM SIGKDD explorations newsletter, 11(1), 10--18."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813448.2813519"}, {"title": "Supervised Hashing with Pseudo Labels for Scalable Multimedia Retrieval", "authors": ["Jingkuan Song\n,", "Lianli Gao\n,", "Yan Yan\n,", "Dongxiang Zhang\n,", "Nicu Sebe"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThere is an increasing interest in using hash codes for efficient multimedia retrieval and data storage. The hash functions are learned in such a way that the hash codes can preserve essential properties of the original space or the label information. Then the Hamming distance of the hash codes can approximate the data similarity. Existing works have demonstrated the success of many supervised hashing models. However, labeling data is time and labor consuming, especially for scalable datasets. In order to utilize the supervised hashing models to improve the discriminative power of hash codes, we propose a Supervised Hashing with Pseudo Labels (SHPL) which uses the cluster centers of the training data to generate pseudo labels, based on which the hash codes can be generated using the criteria of supervised hashing. More specifically, we utilize linear discriminant analysis (LDA) with trace ratio criterion as a showcase for hash functions learning and during the optimization, we prove that the pseudo labels and the hash codes can be jointly learned and iteratively updated in an unified framework. The learned hash functions can harness the discriminant power of trace ratio criterion, and thus can achieve better performance. Experimental results on three large-scale unlabeled datasets (i.e., SIFT1M, GIST1M, and SIFT1B) demonstrate the superior performance of our SHPL over existing hashing methods.", "references": ["L. Gao, J. Song, F. Nie, Y. Yan, N. Sebe, and H. T. Shen. Optimal graph leaning with partial tags and multiple features for image and video annotation. In CVPR, 2015.", "T. Ge, K. He, and J. Sun. Graph cuts for supervised binary coding. In ECCV, 2014.", "Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. TPAMI, 35(12):2916--2929, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806341"}, {"title": "Session details: Session 8B: Web Search", "authors": ["David Hawking"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3252321"}, {"title": "Data Fusion for Japanese Term and Character N-gram Search", "authors": ["Michiko Yasukawa\n,", "J. Shane Culpepper\n,", "Falk Scholer"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nTerm segmentation plays a vital role in building effective information retrieval systems. In particular, languages such as Japanese and Chinese require a morphological analyzer or a word segmenter to identify potential terms. The alternative approach to indexing a segmented collection is n-gram search, where every n-length sequence of symbols is indexed. Both approaches have strengths and weaknesses when applied to non-English collections. In this study, we explore data fusion techniques to answer the following question: if there are multiple ranked lists of documents from both word and n-gram indexes, can we improve overall effectiveness by combining them? We consider three empirical methods for combining search results using eight different search indexes and twenty-one different search models with and without automatic query expansion. Our approach is language independent; however, we focus on Japanese test collections -- NTCIR IR4QA -- as our testbed for the current experiments. Our experimental results demonstrate that the combination of the two different segmentation approaches has the potential to significantly outperform the best word-segmented search methods.", "references": ["ChaSen. https://osdn.jp/projects/chasen-legacy/, 2012.", "JUMAN. http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN, 2012.", "KAKASI. http://kakasi.namazu.org/index.html.en, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838939"}, {"title": "A Layout Technique for Storyline-based Visualization of Consecutive Numerical Time-varying Data", "authors": ["Sayaka Yagi\n,", "Takayuki Itoh\n,", "Masahiro Takatsuka"], "publication": "VINCI '15: Proceedings of the 8th International Symposium on Visual Information Communication and Interaction", "abstract": "ABSTRACT\nWe commonly represent time-varying values as polyline charts or heatmaps; however, both type of techniques are difficult to simultaneously observe short-term features of time-varying values and cluster transitions. This poster proposes storyline-based visualization technique for consecutive numerical time-varying data. Storyline is a visualization technique to show associative feature among elements over time. Our technique measures similarity of each elements and draw similar elements as proximity storyline. The technique also reflects differential values on storyline as a visual variable to emphasize the amount of line changes.", "references": ["R. Munroe. Movie narrative charts. http://xkcd.com/657/, accessed 4 June, 2015.", "Y. Tanahashi and K.-L. Ma. Design considerations for optimizing storyline visualizations. Visualization and Computer Graphics, IEEE Transactions on, 18(12):2679--2688, 2012.", "S. Yagi, Y. Uchida, and T. Itoh. A polyline-based visualization technique for tagged time-varying data. In Information Visualisation (IV), 2012 16th International Conference on, pages 106--111. IEEE, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801040.2801067"}, {"title": "A Survey of CPU-GPU Heterogeneous Computing Techniques", "authors": ["Sparsh Mittal\n,", "Jeffrey S. Vetter"], "publication": "ACM Computing Surveys", "abstract": "Abstract\nAs both CPUs and GPUs become employed in a wide range of applications, it has been acknowledged that both of these Processing Units (PUs) have their unique features and strengths and hence, CPU-GPU collaboration is inevitable to achieve high-performance computing. This has motivated a significant amount of research on heterogeneous computing techniques, along with the design of CPU-GPU fused chips and petascale heterogeneous supercomputers. In this article, we survey Heterogeneous Computing Techniques (HCTs) such as workload partitioning that enable utilizing both CPUs and GPUs to improve performance and/or energy efficiency. We review heterogeneous computing approaches at runtime, algorithm, programming, compiler, and application levels. Further, we review both discrete and fused CPU-GPU systems and discuss benchmark suites designed for evaluating Heterogeneous Computing Systems (HCSs). We believe that this article will provide insights into the workings and scope of applications of HCTs to researchers and motivate them to further harness the computational powers of CPUs and GPUs to achieve the goal of exascale performance.", "references": ["Alejandro Acosta, Robert Corujo, Vicente Blanco, and Francisco Almeida. 2010. Dynamic load balancing on heterogeneous multicore/multi-GPU systems. In International Conference on High Performance Computing and Simulation (HPCS). 467--476.", "Jose Ignacio Agulleiro, Francisco Vazquez, Ester M. Garzon, and Jose J. Fernandez. 2012. Hybrid computing: CPU+ GPU co-processing and its application to tomographic reconstruction. Ultramicroscopy 115 (2012), 109--114.", "Emmanuel Agullo, Cédric Augonnet, Jack Dongarra, Mathieu Faverge, Hatem Ltaief, Samuel Thibault, and Stanimire Tomov. 2011. QR factorization on a multicore node enhanced with multiple GPU accelerators. IEEE International Parallel & Distributed Processing Symposium, 932--943."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2788396"}, {"title": "Embrace the challenges: software engineering in a big data world", "authors": ["Kenneth M. Anderson"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nThe design and development of data-intensive software systems---systems that generate, collect, store, process, analyze, query, and visualize large sets of data---is fraught with significant challenges both technical and social. Project EPIC has been designing and developing data-intensive systems in support of crisis informatics research since Fall 2009. Our experience working on Project EPIC has provided insight into these challenges. In this paper, we share our experience working in this design space and describe the choices we made in tackling these challenges and their attendant trade-offs. We highlight the lack of developer support tools for data-intensive systems, the importance of multidisciplinary teams, the use of highly-iterative life cycles, the need for deep understanding of the frameworks and technologies used in data intensive systems, how simple operations transform into significant challenges at scale, and the paramount significance of data modeling in producing systems that are scalable, robust, and efficient.", "references": ["L. Palen, J. Martin, K. M. Anderson, and D. Sicker, \"Widescale computer-mediated communication in crisis response: Roles, trust & accuracy in the social distribution of information,\" 2009, http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0910586.", "L. Palen, K. M. Anderson, G. Mark, J. Martin, D. Sicker, M. Palmer, and D. Grunwald, \"A vision for technology-mediated support for public participation & assistance in mass emergencies & disasters,\" in ACM-BCS Visions of Computer Science, April 2010, Article 8. 12 pages.", "M. Cox and D. Ellsworth, \"Application-controlled demand paging for out-of-core visualization,\" in Proceedings of the 8th Conference on Visualization. IEEE Computer Society Press, 1997, pp. 235--ff. {Online}. Available: http://dl.acm.org/citation.cfm?id=266989.267068"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819297"}, {"title": "An Efficient Incremental Indexing Mechanism for Extracting Top-k Representative Queries Over Continuous Data-streams", "authors": ["Y. S. Horawalavithana\n,", "D. N. Ranasinghe"], "publication": "ARM 2015: Proceedings of the 14th International Workshop on Adaptive and Reflective Middleware", "abstract": "ABSTRACT\nTop-k publish/subscribe (pub/sub) models have gained traction as an expressive alternative to extend the binary notion of matching. In our study, we focus on the problem of extracting the k-most representative set of publications in the dynamic case where the results are updated over a stream of matching publications. This can be observed as the minimum independent dominating set problem in graph theory, when streaming publications are represented as dynamic graph spaces. Due to the inherent complexity of solving this problem over continuous data, an incremental indexing mechanism is proposed for handling a stream of publications. The proposed mechanism is based on Locality Sensitive Hashing (LSH) to avoid the overhead of recalculating neighborhoods over consecutive sliding windows. The experimental results show that the incremental version of LSH indexing mechanism reduces the computational cost of naive greedy approach significantly, while producing Top-k representative results at 70% accuracy compared to the naive optimal method.", "references": ["M. Drosou and E. Pitoura. Disc diversity: Result diversification based on dissimilarity and coverage. Proc. VLDB Endow., 6(1):13--24, Nov. 2012.", "M. Drosou and E. Pitoura. Diverse Set Selection Over Dynamic Data. IEEE Transactions on Knowledge and Data Engineering, 26(5):1102--1116, 2014.", "K. Pripužić, I. Podnar Žarko, and K. Aberer. Top-k/w publish/subscribe: A publish/subscribe model for continuous top-k processing over data streams. Information Systems, 39:256--276, Jan. 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834965.2834975"}, {"title": "Efficient key grouping for near-optimal load balancing in stream processing systems", "authors": ["Nicoló Rivetti\n,", "Leonardo Querzoni\n,", "Emmanuelle Anceaume\n,", "Yann Busnel\n,", "Bruno Sericola"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nKey grouping is a technique used by stream processing frameworks to simplify the development of parallel stateful operators. Through key grouping a stream of tuples is partitioned in several disjoint sub-streams depending on the values contained in the tuples themselves. Each operator instance target of one sub-stream is guaranteed to receive all the tuples containing a specific key value. A common solution to implement key grouping is through hash functions that, however, are known to cause load imbalances on the target operator instances when the input data stream is characterized by a skewed value distribution. In this paper we present DKG, a novel approach to key grouping that provides near-optimal load distribution for input streams with skewed value distribution. DKG starts from the simple observation that with such inputs the load balance is strongly driven by the most frequent values; it identifies such values and explicitly maps them to sub-streams together with groups of less frequent items to achieve a near-optimal load balance. We provide theoretical approximation bounds for the quality of the mapping derived by DKG and show, through both simulations and a running prototype, its impact on stream processing applications.", "references": ["N. Alon, Y. Matias, and M. Szegedy. The space complexity of approximating the frequency moments. In Proceedings of the 28th annual ACM Symposium on Theory of computing (STOC), 1996.", "E. Anceaume, Y. Busnel, and B. Sericola. Uniform node sampling service robust against collusions of malicious nodes. In Proceedings of the 43rd IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), 2013.", "Z. Bar-Yossef, T. S. Jayram, R. Kumar, D. Sivakumar, and L. Trevisan. Counting distinct elements in a data stream. In Proceedings of the 6th International Workshop on Randomization and Approximation Techniques (RANDOM), 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2771827"}, {"title": "Multiple Measurements and Joint Dimensionality Reduction for Large Scale Image Search with Short Vectors", "authors": ["Filip Radenović\n,", "Hervé Jégou\n,", "Ondrej Chum"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nThis paper addresses the construction of a short-vector (128D) image representation for large-scale image and particular object retrieval. In particular, the method of joint dimensionality reduction of multiple vocabularies is considered. We study a variety of vocabulary generation techniques: different k-means initializations, different descriptor transformations, different measurement regions for descriptor extraction. Our extensive evaluation shows that different combinations of vocabularies, each partitioning the descriptor space in a different yet complementary manner, results in a significant performance improvement, which exceeds the state-of-the-art.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In Proc. CVPR, pages 2911--2918, 2012.", "R. Arandjelović and A. Zisserman. All about VLAD. In Proc. CVPR, 2013.", "O. Chum and J. Matas. Unsupervised discovery of co-occurrence in sparse high dimensional data. In Proc. CVPR, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749366"}, {"title": "Inferring Searcher Attention by Jointly Modeling User Interactions and Content Salience", "authors": ["Dmitry Lagun\n,", "Eugene Agichtein"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModeling and predicting user attention is crucial for interpreting search behavior. The numerous applications include quantifying web search satisfaction, estimating search quality, and measuring and predicting online user engagement. While prior research has demonstrated the value of mouse cursor data and other interactions as a rough proxy of user attention, precisely predicting where a user is looking on a page remains a challenge, exacerbated in Web pages beyond the traditional search results. To improve attention prediction on a wider variety of Web pages, we propose a new way of modeling searcher behavior data by connecting the user interactions to the underlying Web page content. Specifically, we propose a principled model for predicting a searcher's gaze position on a page, that we call Mixture of Interactions and Content Salience (MICS). To our knowledge, our model is the first to effectively combine user interaction data, such as mouse cursor and scrolling positions, with the visual prominence, or salience, of the page content elements. Extensive experiments on multiple popular types of Web content demonstrate that the proposed MICS model significantly outperforms previous approaches to searcher gaze prediction that use only the interaction information. Grounding the observed interactions to the underlying page content provides a general and robust approach to user attention modeling, enabling more powerful tool for search behavior interpretation and ultimately search quality improvements.", "references": ["Mikhail Ageev, Dmitry Lagun, and Eugene Agichtein. Improving search result summaries by using searcher behavior data. In Proc. of SIGIR, 2013.", "Ioannis Arapakis, Mounia Lalmas, B Barla Cambazoglu, Mari-Carmen Marcos, and Joemon M Jose. User engagement in online news: Under the scope of sentiment, interest, affect, and gaze. JASIST, 2014.", "James Bergstra, Olivier Breuleux, Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: a cpu and gpu math expression compiler. In Proceedings of SciPy, volume 4, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767745"}, {"title": "Predicting answering times on stack overflow", "authors": ["Selman Ercan\n,", "Quinten Stokkink\n,", "Alberto Bacchelli"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nUsers of Question & Answer websites often include code fragments in their questions. However, large and unexplained code fragments make it harder for others to understand the question, thus possibly impacting the time required to obtain a correct answer. In this paper, we quantitatively study this relation: We look at questions containing code fragments and investigate the influence of explaining these fragments better on the time to answer. We devise an approach to quantify code explanations and apply it to ~300K posts. We find that it causes up to a 5σ (single-tail significant) increase in precision over baseline prediction times. This supports the use of our approach as an 'edit suggestion': Questions with a low score could trigger a warning suggesting the user to better explain the included code.", "references": ["S. M. Nasehi, J. Sillito, F. Maurer, and C. Burns, \"What makes a good code example?: A study of programming q&a in stackoverflow,\" in Software Maintenance (ICSM), 2012 28th IEEE International Conference on. IEEE, 2012, pp. 25--34.", "P. C. Rigby and M. P. Robillard, \"Discovering essential code elements in informal documentation,\" in Proceedings of the 2013 International Conference on Software Engineering. IEEE Press, 2013, pp. 832--841.", "C.-Y. Lin, \"Rouge: A package for automatic evaluation of summaries,\" in Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, 2004, pp. 74--81."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820582"}, {"title": "IR Evaluation: Designing an End-to-End Offline Evaluation Pipeline", "authors": ["Jin Young Kim\n,", "Emine Yilmaz"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThis tutorial aims to provide attendees with a detailed understanding of end-to-end evaluation pipeline based on human judgments (offline measurement). The tutorial will give an overview of the state of the art methods, techniques, and metrics necessary for each stage of evaluation process. We will mostly focus on evaluating an information retrieval (search) system, but the other tasks such as recommendation and classification will also be discussed. Practical examples will be drawn both from the literature and from real world usage scenarios in industry.", "references": ["Azzah Al-Maskari, Mark Sanderson, and Paul Clough, The relationship between IR effectiveness measures and user satisfaction. SIGIR '07.", "Al-Maskari, A., Sanderson, M., Clough, P., and Airio, E. The good and the bad system: does the test collection predict users' effectiveness? SIGIR '08.", "Peter Bailey et al., \"Evaluating search systems using result page context,\" in IIiX, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767875"}, {"title": "Analysis of the challenges faced in establishing and maintaining an information security management system on the Brazilian scene", "authors": ["Rodrigo Valle Fazenda\n,", "Leonardo Lemes Fagundes"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe ISO 27001 adoption grows worldwide motivated primarily by the need for compliance and as a way of improving the management of assets and risks of organizations. Many are the challenges to establish and maintain a Information Security Management System (ISMS) effective and adds value. However, the Brazilian organizations studies about these challenges are scarce. This article identifies and analyzes some of the challenges faced in establishing and maintaining an ISMS on the national scene using the multiple case study method. Obstacles such as lack of management support, lack of training of information security area, influence of local culture, failures in risk analysis and resistance to change were systematically identified.", "references": ["Solms, R. 1999. Information Security Systems: Why Standards are Important? Information Management & Computer Security vol. 46, no. 8, p. 91-95.", "Rigon, E. e Westphall, C. 2011. Modelo de Avaliação da Maturidade da Segurança da Informação. Biblioteca Digital Brasileira de Computação. VII Simpósio Brasileiro de Sistemas de Informação. http://www.lbd.dcc.ufmg.br/colecoes/sbsi/2011/modelodeavalicao.pdf", "ABNT NBR ISO/IEC 27001. 2013. \"Tecnologia da Informação - Técnicas de segurança - Sistemas de Gestão de Segurança da Informação - Requisitos\"."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814108"}, {"title": "Towards Quantifying the Impact of Non-Uniform Information Access in Collaborative Information Retrieval", "authors": ["Nyi Nyi Htun\n,", "Martin Halvey\n,", "Lynne Baillie"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe majority of research into Collaborative Information Retrieval (CIR) has assumed a uniformity of information access and visibility between collaborators. However in a number of real world scenarios, information access is not uniform between all collaborators in a team e.g. security, health etc. This can be referred to as Multi-Level Collaborative Information Retrieval (MLCIR). To the best of our knowledge, there has not yet been any systematic investigation of the effect of MLCIR on search outcomes. To address this shortcoming, in this paper, we present the results of a simulated evaluation conducted over 4 different non-uniform information access scenarios and 3 different collaborative search strategies. Results indicate that there is some tolerance to removing access to the collection and that there may not always be a negative impact on performance. We also highlight how different access scenarios and search strategies impact on search outcomes.", "references": ["Allan, J: HARD Track Overview in TREC 2005: High Accuracy Retrieval from Documents. TREC 2005, pp. 1--17", "Attfield, S., Blandford, A., Makri, S.: Social and interactional practices for disseminating current awareness infor-mation in an organisational setting. IPM, 46(6), (2008)", "Bjurling, B., Hansen, P.: Contracts for Information Sharing in Collaborative Networks. ISCRAM 2010 (Vol. 1)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767779"}, {"title": "The weight of numbers", "authors": ["Hsin-Hao Chen"], "publication": "Interactions", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2776898"}, {"title": "An Initial Analytical Exploration of Retrievability", "authors": ["Aldo Lipani\n,", "Mihai Lupu\n,", "Akiko Aizawa\n,", "Allan Hanbury"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nWe approach the problem of retrievability from an analytical perspective, starting with modeling conjunctive and disjunctive queries in a boolean model. We show that this represents an upper bound on retrievability for all other best match algorithms. We follow this with an observation of imbalance in the distribution of retrievability, using the Gini coefficient. Simulation-based experiments show the behavior of the Gini coefficient for retrievability under different types and lengths of queries, as well as different assumptions about the document length distribution in a collection.", "references": ["L. Azzopardi and V. Vinay. Accessibility in Information Retrieval, volume 4956. Springer, 2008.", "L. Azzopardi and V. Vinay. Retrievability: An evaluation measure for higher order information access tasks. In Proc. of CIKM. ACM, 2008.", "S. Bashir and A. Rauber. Improving retrievability of patents with cluster-based pseudo-relevance feedback documents selection. In Proc. of CIKM, New York, NY, USA, 2009. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809495"}, {"title": "Exploring Heterogeneity for Multi-Domain Recommendation with Decisive Factors Selection", "authors": ["Shuang Qiu\n,", "Jian Cheng\n,", "Xi Zhang\n,", "Hanqing Lu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nTo address the recommendation problems in the scenarios of multiple domains, in this paper, we propose a novel method, HMRec, which models both consistency and heterogeneity of users' multiple behaviors in a unified framework. Moreover, the decisive factors of each domain can also be captured by our approach successfully. Experiments on the real multi-domain dataset demonstrate the effectiveness of our model.", "references": ["S. Berkovsky, T. Kuflik, and F. Ricci. Cross-domain mediation in collaborative filtering. In User Modeling, pages 355--359. Springer, 2007.", "R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In NIPS, 2007.", "A. P. Singh and G. J. Gordon. Relational learning via collective matrix factorization. In SIGKDD, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742711"}, {"title": "Semiotics contributions to accessible interface design", "authors": ["María Inés Laitano"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nThe aim of this research is to show that a semiotic approach, similar to those who have already been applied in the HCI field, may contribute to design accessible interfaces. Comparing design solutions from a WCAG approach and from a semiotic approach, we show how the latter can contribute to a real communicational accessibility.", "references": ["Andersen, P. B. 1992. Computer semiotics. Scandinavian Journal of Information systems. 4, (1992), 3--30.", "Bootz, P. 2007. Éléments d'analyse de l'interface sémiotique des sites Web. Collaborer, Echanger, Inventer: Expériences de réseaux (Paris, 2007), 107--121.", "Essential Components of Web Accessibility: 2005. http://www.w3.org/WAI/intro/components.php. Accessed: 2014-10-20."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746673"}, {"title": "A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion", "authors": ["Alessandro Sordoni\n,", "Yoshua Bengio\n,", "Hossein Vahabi\n,", "Christina Lioma\n,", "Jakob Grue Simonsen\n,", "Jian-Yun Nie"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUsers may strive to formulate an adequate textual query for their information need. Search engines assist the users by presenting query suggestions. To preserve the original search intent, suggestions should be context-aware and account for the previous queries issued by the user. Achieving context awareness is challenging due to data sparsity. We present a novel hierarchical recurrent encoder-decoder architecture that makes possible to account for sequences of previous queries of arbitrary lengths. As a result, our suggestions are sensitive to the order of queries in the context while avoiding data sparsity. Additionally, our model can suggest for rare, or long-tail, queries. The produced suggestions are synthetic and are sampled one word at a time, using computationally cheap decoding techniques. This is in contrast to current synthetic suggestion models relying upon machine learning pipelines and hand-engineered feature sets. Results show that our model outperforms existing context-aware approaches in a next query prediction setting. In addition to query suggestion, our architecture is general enough to be used in a variety of other applications.", "references": ["R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query recommendation using query logs in search engines. In In Proc. of Int. Conf. on Current Trends in Database Tech., pages 588--596, 2004.", "F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. J. Goodfellow, A. Bergeron, N. Bouchard, and Y. Bengio. Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, 2012.", "Y. Bengio. Deep learning of representations: Looking forward. CoRR, abs/1305.0445, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806493"}, {"title": "RINSE: interactive data series exploration with ADS+", "authors": ["Kostas Zoumpatianos\n,", "Stratos Idreos\n,", "Themis Palpanas"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nNumerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available. An adaptive index data structure, ADS+, which is specifically tailored to solve the problem of indexing and querying very large data series collections has been recently proposed as a solution to this problem. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. In this work, we present a demonstration of ADS+; we introduce RINSE, a system that allows users to experience the benefits of the ADS+ adaptive index through an intuitive web interface. Users can explore large datasets and find patterns of interest, using nearest neighbor search. They can draw queries (data series) using a mouse, or touch screen, or they can select from a predefined list of data series. RINSE can scale to large data sizes, while drastically reducing the data to query delay: by the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), adaptive data series indexing can already answer 3 * 105 queries.", "references": ["R. Agrawal, C. Faloutsos, and A. N. Swami. Efficient similarity search in sequence databases. In FODO, 1993.", "S. Berchtold, D. A. Keim, and H.-P. Kriegel. The X-tree: An index structure for high-dimensional data. In VLDB, 1996.", "A. Camerra, T. Palpanas, J. Shieh, and E. Keogh. iSAX 2.0: Indexing and mining one billion time series. In ICDM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824099"}, {"title": "Visual Saliency and Crowdsourcing-based Priors for an In-car Situated Dialog System", "authors": ["Teruhisa Misu"], "publication": "ICMI '15: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction", "abstract": "ABSTRACT\nThis paper addresses issues in situated language understanding in a moving car. We propose a reference resolution method to identify user queries about specific target objects in their surroundings. We investigate methods of predicting which target object is likely to be queried given a visual scene and what kind of linguistic cues users naturally provide to describe a given target object in a situated environment. We propose methods to incorporate the visual saliency of the visual scene as a prior. Crowdsourced statistics of how people describe an object are also used as a prior. We have collected situated utterances from drivers using our research system, which was embedded in a real vehicle. We demonstrate that the proposed algorithms improve target identification rate by 15.1%.", "references": ["D. Bohus and E. Horvitz. Models for Multiparty Engagement in Open-World Dialog. In Proc. SIGDIAL, pages 225--234, 2009.", "S. Tellex, T. Kollar, S. Dickerson, M. Walter, A. Banerjee, S. Teller, and N. Roy. Understanding natural language commands for robotic navigation and mobile manipulation. In Proc. AAAI, 2011.", "K. Sugiura, N. Iwahashi, H. Kawai, and S. Nakamura. Situated spoken dialogue with robots using active learning. Advance Robotics, 25(17):2207--2232, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818346.2820748"}, {"title": "Cross-Modal Similarity Learning: A Low Rank Bilinear Formulation", "authors": ["Cuicui Kang\n,", "Shengcai Liao\n,", "Yonghao He\n,", "Jian Wang\n,", "Wenjia Niu\n,", "Shiming Xiang\n,", "Chunhong Pan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe cross-media retrieval problem has received much attention in recent years due to the rapid increasing of multimedia data on the Internet. A new approach to the problem has been raised which intends to match features of different modalities directly. In this research, there are two critical issues: how to get rid of the heterogeneity between different modalities and how to match the cross-modal features of different dimensions. Recently metric learning methods show a good capability in learning a distance metric to explore the relationship between data points. However, the traditional metric learning algorithms only focus on single-modal features, which suffer difficulties in addressing the cross-modal features of different dimensions. In this paper, we propose a cross-modal similarity learning algorithm for the cross-modal feature matching. The proposed method takes a bilinear formulation, and with the nuclear-norm penalization, it achieves low-rank representation. Accordingly, the accelerated proximal gradient algorithm is successfully imported to find the optimal solution with a fast convergence rate O(1/t2). Experiments on three well known image-text cross-media retrieval databases show that the proposed method achieves the best performance compared to the state-of-the-art algorithms.", "references": ["F. R. Bach. Consistency of trace norm minimization. Journal of Machine Learning Research, 9:1019--1048, 2008.", "A. Bar-Hillel, T. Hertz, N. Shental, and D. Weinshall. Learning distance functions using equivalence relations. In ICML, pages 11--18, 2003.", "A. Beck and M. Teboulle. A fast iterative shrinkage- thresholding algorithm for linear inverse problems. SIAM J. Imaging Sciences, 2(1):183--202, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806469"}, {"title": "An Experiment with the ERP Systems usage to assist the Knowledge Acquisition of Business Processes in Bachelors on Business Administration Course", "authors": ["Marcio Pires de Oliveira\n,", "Ildeberto Aparecido Rodello"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe ERP systems usage for the teaching/learning process to business administration students is an important tool in the acquisition of knowledge about business process integration view. Several authors have stated that the learning of ERP systems could be favored by the application of the hands on methodology, on which the student build your knowledge through tools provided by educator. The objective of this paper is describe an experience with a 68 students about the ERP system usage according to hands-on approach as a tool to facilitate the teaching/learning process in bachelors on business administration course. The analysis of this approach was made through a methodology based on comparison of a student's knowledge related to a general sales process before and after of hands-on exercise application. It was possible to observe an improvement of knowledge about the sales process, highlighted through the comprehension of the involved actors as well as the relationship between them and the executed tasks.", "references": ["Ayyagari, R. Hands-on ERP Learning: Using OpenERP, an Alternative to SAP®. Journal of Information Systems Education, 22 (2). 123-133.", "Christino, J. M. M., Kaiser, E. L. C. B., Ziviani, F. e Oliveira, J. L. R. O Impacto dos sistemas ERP sobre as variáveis estratégicas organizacionais: Um estudo junto às empresas da Associação Comercial e Industrial de Ji-Paraná-RO. Revista de Administração e Negócios da Amazônia, 5(3). 63-81.", "Davis, C.H., Comeau, J. Enterprise integration in business education: Design and outcomes of a capstone ERP-based undergraduate e-business management course. Journal of Information Systems Education, 15(3). 287-299."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814151"}, {"title": "Intelligent Adaptation to in-Cloud NoSQL Database Remote Backup between Data Centers", "authors": ["Bao Rong Chang\n,", "Hsiu-Fen Tsai\n,", "Yo-Ai Wang\n,", "Chin-Fu Kuo"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper aims to realize high effective remote cloud datacenter backup using Thrift Java on NoSQL database HBase and Cassandra. The binary communications protocol technology from Apache Thrift is employed to ease data manipulation. A stress test has been taken on strictly data reading/writing and remote backup of a vast amount of data, verifying the high performance of proposed method. In order to optimize the traffic flow of remote data center backup, adaptive network-based fuzzy inference system (ANFIS) along with particle swarm optimization (PSO) has been employed off-line to tune seamless handoff and network traffic flow. Finally, performance index has been evaluated for several benchmark databases including two above-mentioned databases. As a result, the proposed HBase approach outperforms the other databases.", "references": ["Chang, B. R., Tsai, H.-F., and Chen, C.-M. 2013. Empirical Analysis of Server Consolidation and Desktop Virtualization in Cloud Computing. Mathematical Problems in Engineering. 2013 (947234), 1--11.", "Chang, B. R., Tsai, H.-F., Chen, C.-Y., and Tsai, Y.-C. 2014. Assessment of In-Cloud Enterprise Resource Planning System Performed in a Virtual Cluster. Mathematical Problems in Engineering. 2014 (520534), 1--8.", "Chang, B. R., Tsai, H.-F. Chen, C.-M., and Huang, C.-F. 2014. Intelligent Adaptation for UEC Video/Voice over IP with Access Control. International Journal of Intelligent Information and Database Systems. 8 (1), 64--80."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818892"}, {"title": "Cost-Effective Information Extraction from Lists in OCRed Historical Documents", "authors": ["Thomas L. Packer\n,", "David W. Embley"], "publication": "HIP '15: Proceedings of the 3rd International Workshop on Historical Document Imaging and Processing", "abstract": "ABSTRACT\nTo work well, machine-learning-based approaches to information extraction and ontology population often require a large number of manually selected and annotated examples. In this paper, we propose ListReader which provides a way to train the structure and parameters of a Hidden Markov Model (HMM) without requiring any labeled training data. The induced HMM is a wrapper---a function that hides within it the complexities of low-level processing---in ListReader's case the complexities of information extraction from OCRed historical documents. The HMM wrapper is capable of recognizing lists of records in text documents and associating subsets of identical fields across related record templates. The algorithmic training method we employ is based on a novel unsupervised active grammar-induction framework. The training produces an HMM wrapper and uses an efficient active sampling process to complete the mapping from wrapper to ontology by requesting annotations from a user for automatically-selected examples. We measure performance of the final HMM in terms of F-measure of extracted information and manual annotation cost and show that ListReader learns faster and better than a state-of-the-art baseline and an alternate version of ListReader that induces a regular-expression wrapper.", "references": ["N. Ashish and C. A. Knoblock. Semi-automatic wrapper generation for internet information sources. In Proceedings of the Second IFCIS International Conference on Cooperative Information Systems, 1997. COOPIS '97, pages 160--169, 1997.", "G. C. Cawley. Baseline methods for active learning. Journal of Machine Learning Research-Proceedings Track, 16:47--57, 2011.", "C.-H. Chang, C.-N. Hsu, and S.-C. Lui. Automatic information extraction from semi-structured web pages by pattern discovery. Decision Support Systems, 35:129--147, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809544.2809547"}, {"title": "Towards the Semantic Interpretation of Personal Health Messages from Social Media", "authors": ["Nut Limsopatham\n,", "Nigel Collier"], "publication": "UCUI '15: Proceedings of the ACM First International Workshop on Understanding the City with Urban Informatics", "abstract": "ABSTRACT\nRecent attempts have been made to utilise social media platforms, such as Twitter, to provide early warning and monitoring of health threats in populations (i.e. Internet bio-surveillance). It has been shown in the literature that a system based on keyword matching that exploits social media messages could report flu surveillance well ahead of the Centers of Disease Control and Prevention (CDC). However, we argue that a simple keyword matching may not capture semantic interpretation of social media messages that would enable healthcare experts or machines to extract and leverage medical knowledge from social media messages. In this paper, we motivate and describe a new task that aims to tackle this technology gap by extracting semantic interpretation of medical terms mentioned in social media messages, which are typically written in layman's language. Achieving such a task would enable an automatic integration between the data about direct patient experiences extracted from social media and existing knowledge from clinical databases, which leads to advances in the use of community health experiences in healthcare services.", "references": ["Allan, James. Incremental relevance feedback for information filtering. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, 1996.", "A. R. Aronson and F.-M. Lang. An overview of metamap: historical perspective and recent advances. Journal of the American Medical Informatics Association, 17(3):229--236, 2010.", "T. Baldwin, P. Cook, M. Lui, A. MacKinlay, and L. Wang. How noisy social media text, how diffrnt social media sources. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811271.2811275"}, {"title": "Large-scale Image Retrieval using Neural Net Descriptors", "authors": ["David Novak\n,", "Michal Batko\n,", "Pavel Zezula"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["P. Budikova, M. Batko, and P. Zezula. Evaluation Platform for Content-based Image Retrieval Systems. In International Conference on Theory and Practice of Digital Libraries, LNCS, pages 130--142. Springer, 2011.", "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. In Proceedings of the International Conference on Machine Learning, pages 647--655, 2014.", "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional Architecture for Fast Feature Embedding. arXiv preprint arXiv:1408.5093, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767868"}, {"title": "AutoRec: Autoencoders Meet Collaborative Filtering", "authors": ["Suvash Sedhain\n,", "Aditya Krishna Menon\n,", "Scott Sanner\n,", "Lexing Xie"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.", "references": ["Y. Koren, R. Bell, C. Volinsky. Matrix factorization techniques for recommender systems. Computer, 42 (8), 2009.", "J. Lee, S. Kim, G. Lebanon, Y. Singer. Local low-rank matrix approximation. ICML, 2013.", "M. Riedmiller, H. Braun. A direct adaptive method for faster backpropagation learning: the RProp algorithm. IEEE International Conference on Neural Networks, 1993."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742726"}, {"title": "Incremental Multimodal Query Construction for Video Search", "authors": ["Shicheng Xu\n,", "Huan Li\n,", "Xiaojun Chang\n,", "Shoou-I Yu\n,", "Xingzhong Du\n,", "Xuanchong Li\n,", "Lu Jiang\n,", "Zexi Mao\n,", "Zhenzhong Lan\n,"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nRecent improvements in content-based video search have led to systems with promising accuracy, thus opening up the possibility for interactive content-based video search to the general public. We present an interactive system based on a state-of-the-art content-based video search pipeline which enables users to do multimodal text-to-video and video-to-video search in large video collections, and to incrementally refine queries through relevance feedback and model visualization. Also, the comprehensive functionalities enhance a flexible formulation of multimodal queries with different characteristics. Quantitative and qualitative analysis shows that our system is capable of assisting users to incrementally build effective queries over complex event topics.", "references": ["P. Natarajan, S. Wu, S. Vitaladevuni, X. Zhuang, S. Tsakalidis, U. Park, and R. Prasad. Multimodal feature fusion for robust event detection in web videos. In CVPR, 2012.", "A. Tamrakar, S. Ali, Q. Yu, J. Liu, O. Javed, A. Divakaran, H. Cheng, and H. Sawhney. Evaluation of low-level features and their combinations for complex event detection in open source videos. In CVPR, 2012.", "S.-I. Yu, L. Jiang, Z. Mao, et al. Cmu-informedia @ trecvid. In TRECVID Video Retrieval Evaluation Workshop, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749413"}, {"title": "Capacitated vehicle routing system applying Monte Carlo methods", "authors": ["Romulo Augusto de Carvalho Oliveira\n,", "Karina Valdivia Delgado"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe Vehicle Routing Problem (VRP) is one of the combinatorial optimization problems most studied in Computer Science and of great relevance to the areas of logistics and transport. This paper presents a new algorithm for solving the Capacitated Vehicle Routing Problem (CVRP) using Monte Carlo methods. Monte Carlo methods are statistical methods that use random sampling to solve probabilistic and deterministic problems. The proposed algorithm was developed based on Monte Carlo simulations and Clarke and Wright Savings heuristic and demonstrated results comparable to the best existing algorithms in the literature, it overcomes previous work with Monte Carlo methods. The comparison, analysis and evaluation of the algorithm were based on existing benchmarks in the literature.", "references": ["TSPLIB, 2014. Disponível em ¿http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/¿. Acesso em: 24 ago 2014.", "VRPLIB: A Vehicle Routing Problem LIBrary, 2014. Disponível em ¿http://www.or.deis.unibo.it/research_pages/ORinstances/VRPLIB/VRPLIB.html¿. Acesso em: 24 ago 2014.", "P. Augerat. Approche polyèdrale du problème de tournées de véhicules. PhD thesis, Institut National Polytechnique de Grenoble-INPG, 1995. Disponível em ¿http://www.branchandcut.org/VRP/data¿. Acesso em: 24 ago 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814060"}, {"title": "Executing Provenance-Enabled Queries over Web Data", "authors": ["Marcin Wylot\n,", "Philippe Cudre-Mauroux\n,", "Paul Groth"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe proliferation of heterogeneous Linked Data on the Web poses new challenges to database systems. In particular, because of this heterogeneity, the capacity to store, track, and query provenance data is becoming a pivotal feature of modern triple stores. In this paper, we tackle the problem of efficiently executing provenance-enabled queries over RDF data. We propose, implement and empirically evaluate five different query execution strategies for RDF queries that incorporate knowledge of provenance. The evaluation is conducted on Web Data obtained from two different Web crawls (The Billion Triple Challenge, and the Web Data Commons). Our evaluation shows that using an adaptive query materialization execution strategy performs best in our context. Interestingly, we find that because provenance is prevalent within Web Data and is highly selective, it can be used to improve query processing performance. This is a counterintuitive result as provenance is often associated with additional overhead.", "references": ["B. Arab, D. Gawlick, V. Radhakrishnan, H. Guo, and B. Glavic. A generic provenance middleware for queries, updates, and transactions. In 6th USENIX Workshop on the Theory and Practice of Provenance (TaPP 2014), Cologne, June 2014. USENIX Association.", "R. Avnur and J. M. Hellerstein. Eddies: Continuously adaptive query processing. SIGMOD Rec., 29(2):261--272, May 2000.", "C. R. Batchelor, C. Y. A. Brenninkmeijer, C. Chichester, M. Davies, D. Digles, I. Dunlop, C. T. A. Evelo, A. Gaulton, C. A. Goble, A. J. G. Gray, P. T. Groth, L. Harland, K. Kara- petyan, A. Loizou, J. P. Overington, S. Pettifer, J. Steele, R. Stevens, V. Tkachenko, A. Waagmeester, A. J. Williams, and E. L. Willighagen. Scientific lenses to support multiple views over linked chemistry data. In ISWC 2014 - 13th International Semantic Web Conference, Riva del Garda, Italy, October 19-23, 2014. Proceedings, Part I, pages 98--113, Oct. 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741143"}, {"title": "A Unsupervised Person Re-identification Method Using Model Based Representation and Ranking", "authors": ["Chao Liang\n,", "Binyue Huang\n,", "Ruimin Hu\n,", "Chunjie Zhang\n,", "Xiaoyuan Jing\n,", "Jing Xiao"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nAs a core technique supporting the multi-camera tracking task, person re-identification attracts increasing research interests in both academic and industrial communities. Its aim is to match individuals across a group of spatially non-overlapping surveillance cameras, which are usually interfered by various imaging conditions and object motions. Current methods mainly focus on robust feature representation and accurate distance measure, where intensive computations and expensive training samples prohibit their practical applications. To address the above problems, this paper proposes a new unsupervised person re-identification method featured by its competitive accuracy and high efficiency. Both merits stem from model based person image representation and ranking, with which, merely 4-dimension pixel-level features can achieve over 20% matching rate at Rank 1 on the challenging VIPeR dataset.", "references": ["C. Beecks, A. M. Ivanescu, S. Kirchhoff, and T. Seidl. Modeling image similarity by gaussian mixture models and the signature quadratic form distance. In ICCV, pages 1754--1761, 2011.", "S. B. D. Gray and H. Tao. Evaluating appearance models for recognition, reacquisition, and tracking. In PETS, 2007.", "A. Ess, B. Leibe, and L. J. V. Gool. Depth and appearance for mobile scene analysis. In ICCV, pages 1--8, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807399"}, {"title": "Designing the techno-somatic", "authors": ["Garth Paine"], "publication": "MOCO '15: Proceedings of the 2nd International Workshop on Movement and Computing", "abstract": "ABSTRACT\nThis paper proposes an alternative approach to the analysis and design of interaction in realtime performance systems. It draws on the idea that the connection between the human engagement with the interface (digital or analog) and the resultant rich media output forms a proposed experiential dimension containing both technical and somatic considerations. The proposed dimension is characterized by its materiality and is referred to by the author as the techno-somatic dimension. The author is proposing that design and analysis efforts for new interactive systems should focus on the techno-somatic dimension. That if this dimension is designed with care to produce a detailed and nuanced experience for the user, then design specifications for the interface will automatically result, and that such an interface will produce the desired materiality and actional intentionality. For the purposes of this discussion, the author will focus principally on musical interfaces.", "references": ["Birringer, J. H. 1999. Contemporary Performance/Technology. Theatre Journal. 51(4), 361--381.", "Gibson, J. 1979 The ecological approach to visual perception. Houghton Mifflin.", "Hanna, T. 1988 Somatics: reawakening the mind's control of movement, flexibility, and health. Addison-Wesley."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790994.2791011"}, {"title": "Combining Text and Formula Queries in Math Information Retrieval: Evaluation of Query Results Merging Strategies", "authors": ["Martin Líška\n,", "Petr Sojka\n,", "Michal Růžička"], "publication": "NWSearch '15: Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems", "abstract": "ABSTRACT\nSpecific to Math Information Retrieval is combining text with mathematical formulae both in documents and in queries. Rigorous evaluation of query expansion and merging strategies combining math and standard textual keyword terms in a query are given. It is shown that techniques similar to those known from textual query processing may be applied in math information retrieval as well, and lead to a cutting edge performance. Striping and merging partial results from subqueries is one technique that improves results measured by information retrieval evaluation metrics like Bpref.", "references": ["A. Aizawa, M. Kohlhase, I. Ounis, and M. Schubotz. NTCIR-11 Math-2 Task Overview. In N. Kando and K. Kishida (Eds) Proc. of the 11th NTCIR Conference on Evaluation of Information Access Technologies, pp. 88--98. NII, Tokyo, Japan, 20140", "N. Craswell. Bpref. In L. Liu and M. T. Özsu (Eds), Encyclopedia of Database Systems, pp. 266--267. Springer US, 2009. http://dx.doi.org/10.1007/978-0-387-39940-9_4890", "M. Líška, P. Sojka, and M. Růžička. Math Indexer and Searcher Web Interface: Towards Fulfillment of Mathematicians' Information Needs. In S. M. Watt et al. (Eds), Proc. of Intelligent Computer Mathematics CICM 2014, pp. 444--448, Zurich, 2014. Springer. http://dx.doi.org/10.1007/978-3-319-08434-3_360"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810355.2810359"}, {"title": "Data visualizations for open government data", "authors": ["Alvaro Graves"], "publication": "dg.o '15: Proceedings of the 16th Annual International Conference on Digital Government Research", "abstract": "ABSTRACT\nThis half-day tutorial offers a brief introduction to data visualizations, especially focused on Open Data and the Web. After a brief introduction on what a data visualization is, we will describe the main technologies used nowadays for creating and publishing visualizations on the Web. The lessons will be based on freely available and open source tools that everybody can use.\nAfter this tutorial, attendants will have a broader knowledge of visualizations in general, its principles, best practices and technologies used.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757401.2757438"}, {"title": "Studying Chinese-English Mixed Language Queries from the User Perspectives", "authors": ["Hengyi Fu\n,", "Shuheng Wu"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWith the increasing number of multilingual webpages on the Internet, cross-language information retrieval has become an important research issue. Using Activity Theory as a theoretical framework, this study employs semi-structured interviews with key informants who are frequent users of Chinese-English mixed language queries in web searching. The findings present the context of and reasons for using Chinese-English mixed language queries, which can inform the design of cross-language controlled vocabularies and information retrieval systems.", "references": ["Auer, P. 1998. Code-Switching in conversation: Language, interaction, and identify. Routledge, London.", "Chau, M., Fang, X., and Yang, C. C. 2007. Web searching in Chinese: A study of a search engine in Hong Kong. Journal of the American Society for Information Science and Technology. 58, 7 (May. 2007), 1044--1054.", "Fu, H., and Wu, S. 2014. Analyzing Chinese-English mixed language queries in a Web search engine. In Proceedings of the 77th Annual Meeting of the Association for Information Science and Technology (Seattle, USA, November 01-05, 2014)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756958"}, {"title": "Spatio-temporal keyword queries for moving objects", "authors": ["Paras Mehta\n,", "Dimitrios Skoutas\n,", "Agnès Voisard"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nMany applications involve queries that combine spatial, temporal and textual filters. In this paper, we address the problem of efficient evaluation of queries that perform spatial, temporal and keyword-based filtering on historical movement data of objects which are additionally associated with textual information in the form of keywords. Our work combines and builds upon concepts and techniques for spatio-temporal and spatio-textual queries, proposing two hybrid indexes for this purpose. An experimental evaluation of the proposed approaches is presented, using real-world datasets from two different types of sources.", "references": ["V. P. Chakka, A. Everspaugh, and J. M. Patel. Indexing large trajectory data sets with SETI. In CIDR, 2003.", "L. Chen, G. Cong, C. S. Jensen, and D. Wu. Spatial keyword query processing: An experimental evaluation. PVLDB, 6(3):217--228, 2013.", "M. Christoforaki, J. He, C. Dimopoulos, A. Markowetz, and T. Suel. Text vs. space: efficient geo-search query processing. In CIKM, pages 423--432, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820845"}, {"title": "Unified Relevance Feedback for Multi-Application User Interest Modeling", "authors": ["Sampath Jayarathna\n,", "Atish Patra\n,", "Frank Shipman"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nA user often interacts with multiple applications while working on a task. User models can be developed individually at each of the individual applications, but there is no easy way to come up with a more complete user model based on the distributed activity of the user. To address this issue, this research studies the importance of combining various implicit and explicit relevance feedback indicators in a multi-application environment. It allows different applications used for different purposes by the user to contribute user activity and its context to mutually support users with unified relevance feedback. Using the data collected by the web browser, Microsoft Word and Microsoft PowerPoint, combinations of implicit relevance feedback with semi-explicit relevance feedback were analyzed and compared with explicit user ratings. Our results are two-fold: first we demonstrate the aggregation of implicit and semi-explicit user interest data across multiple everyday applications using our Interest Profile Manager (IPM) framework. Second, our experimental results show that incorporating implicit feedback with semi-explicit feedback for page-level user interest estimation resulted in a significant improvement over the content-based models.", "references": ["Abel, F., et al., Cross-system user modeling and personalization on the social web. User Modeling and User-Adapted Interaction, 2013. 23(2--3): p. 169--209.", "Agichtein, E., E. Brill, and S. Dumais. Improving web search ranking by incorporating user behavior information. in ACM SIGIR. 2006. p. 19--26.", "Assad, M., et al., PersonisAD: Distributed, active, scrutable model framework for context-aware services, in Pervasive Computing. 2007, Springer. p. 55--72."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756914"}, {"title": "Listener-Inspired Automated Music Playlist Generation", "authors": ["Andreu Vall"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe objective of this PhD research is to deepen the understanding of how people listen to music and construct playlists. We believe that further insights into such mechanisms can lead to enhanced music recommendations. We research on the exploitation of user-generated data in the context of on-line music services, since it constitutes a rich and increasing source of information of user behavior. The research carried out so far has centered on the scenario of producing a single artist recommendation. Concretely, in this paper we show how to mitigate the cold-start problem for new artists, elaborating on our findings on the combined effect of users' listening histories and users' tagging activity. As future research, we will investigate how improved techniques to exploit user-generated data can also be applied to the task of producing sequential recommendations, like playlists. We are particulary interested in creating music playlists similarly as users would do, and in finding mechanisms to make such music streams adapt to users' feedback on-line.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. IEEE TKDE, 17(6):734--749, 2005.", "N. Aizenberg, Y. Koren, and O. Somekh. Build your own music recommender by modeling internet radio streams. In Proc. WWW, pages 1--10. ACM, 2012.", "L. Baltrunas, M. Kaminskas, B. Ludwig, O. Moling, F. Ricci, A. Aydin, K.-H. Luke, and R. Schwaiger. Incarmusic: Context-aware music recommendations in a car. In E-Commerce and Web Technologies, pages 89--100. Springer, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796548"}, {"title": "Structured analytics in social media", "authors": ["Mahashweta Das\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe rise of social media has turned the Web into an online community where people connect, communicate, and collaborate with each other. Structured analytics in social media is the process of discovering the structure of the relationships emerging from this social media use. It focuses on identifying the users involved, the activities they undertake, the actions they perform, and the items (e.g., movies, restaurants, blogs, etc.) they create and interact with. There are two key challenges facing these tasks: how to organize and model social media content, which is often unstructured in its raw form, in order to employ structured analytics on it; and how to employ analytics algorithms to capture both explicit link-based relationships and implicit behavior-based relationships. In this tutorial, we systemize and summarize the research so far in analyzing social interactions between users and items in the Web from data mining and database perspectives. We start with a general overview of the topic, including discourse to various exciting and practical applications. Then, we discuss the state-of-art for modeling the data, formalizing the mining task, developing the algorithmic solutions, and evaluating on real datasets. We also emphasize open problems and challenges for future research in the area of structured analytics and social media.", "references": ["M. Das, S. Amer-Yahia, G. Das, and C. Yu. MRI: meaningful interpretations of collaborative ratings. PVLDB, 4(11):1063--1074, 2011.", "M. Das, S. Thirumuruganathan, S. Amer-Yahia, G. Das, and C. Yu. An expressive framework and efficient algorithms for the analysis of collaborative tagging. VLDB Journal, 23(2):201--226, 2014.", "M. Sarwat, J. Avery, and M. F. Mokbel. A recdb in action: Recommendation made easy in relational databases. PVLDB, 6(12):1242--1245, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824135"}, {"title": "Does Vertical Bring more Satisfaction?: Predicting Search Satisfaction in a Heterogeneous Environment", "authors": ["Ye Chen\n,", "Yiqun Liu\n,", "Ke Zhou\n,", "Meng Wang\n,", "Min Zhang\n,", "Shaoping Ma"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe study of search satisfaction is one of the prime concerns in search performance evaluation research. Most existing works on search satisfaction primarily rely on the hypothesis that all results on search engine result pages (SERPs) are homogeneous. However, a variety of heterogeneous vertical results such as videos, images and instant answers are aggregated into SERPs by search engines to improve the diversity and quality of search results. In this paper, we carry out a lab-based user study with specifically designed SERPs to determine how verticals with different qualities and presentation styles affect search satisfaction. Users' satisfaction feedback and external assessors' satisfaction annotations are both collected to make a comparison regarding the perception of search satisfaction. Mouse click-through / movement data and eye movement information are also collected such that we can investigate the influence of vertical results from the perspectives of both benefit and cost. Finally, a vertical-aware learning-based prediction method is proposed to predict search satisfaction on aggregated SERPs. To the best of our knowledge, this paper is the first to analyze the effect of verticals on search satisfaction. The results show that verticals with different qualities, presentation styles and positions have different effects on search satisfaction, among which Encyclopedia verticals, as well as Download verticals, will bring the largest improvement. Furthermore, our proposed vertical-aware prediction method outperforms state-of-the-art methods that are designed for search satisfaction prediction in homogeneous environment.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: a game for modeling different types of web search success using interaction data. In SIGIR'11, pages 345--354. ACM, 2011.", "A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between ir effectiveness measures and user satisfaction. In SIGIR'07, pages 773--774. ACM, 2007.", "J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. In CIKM'14, pages 539--548. ACM, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806473"}, {"title": "Multi-view Clustering via Structured Low-rank Representation", "authors": ["Dong Wang\n,", "Qiyue Yin\n,", "Ran He\n,", "Liang Wang\n,", "Tieniu Tan"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn this paper, we present a novel solution to multi-view clustering through a structured low-rank representation. When assuming similar samples can be linearly reconstructed by each other, the resulting representational matrix reflects the cluster structure and should ideally be block diagonal. We first impose low-rank constraint on the representational matrix to encourage better grouping effect. Then representational matrices under different views are allowed to communicate with each other and share their mutual cluster structure information. We develop an effective algorithm inspired by iterative re-weighted least squares for solving our formulation. During the optimization process, the intermediate representational matrix from one view serves as a cluster structure constraint for that from another view. Such mutual structural constraint fine-tunes the cluster structures from both views and makes them more and more agreeable. Extensive empirical study manifests the superiority and efficacy of the proposed method.", "references": ["http://archive.ics.uci.edu/ml/datasets/Multiple+Features.", "http://attributes.kyb.tuebingen.mpg.de/.", "http://membres-lig.imag.fr/grimal/data.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806629"}, {"title": "Joint Modeling of User Check-in Behaviors for Point-of-Interest Recommendation", "authors": ["Hongzhi Yin\n,", "Xiaofang Zhou\n,", "Yingxia Shao\n,", "Hao Wang\n,", "Shazia Sadiq"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nPoint-of-Interest (POI) recommendation has become an important means to help people discover attractive and interesting locations, especially when users travel out of town. However, extreme sparsity of user-POI matrix creates a severe challenge. To cope with this challenge, a growing line of research has exploited the temporal effect, geographical-social influence, content effect and word-of-mouth effect. However, current research lacks an integrated analysis of the joint effect of the above factors to deal with the issue of data-sparsity, especially in the out-of-town recommendation scenario which has been ignored by most existing work.\nIn light of the above, we propose a joint probabilistic generative model to mimic user check-in behaviors in a process of decision making, which strategically integrates the above factors to effectively overcome the data sparsity, especially for out-of-town users. To demonstrate the applicability and flexibility of our model, we investigate how it supports two recommendation scenarios in a unified way, i.e., home-town recommendation and out-of-town recommendation. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets in terms of both recommendation effectiveness and efficiency, and the experimental results show its superiority over other competitors.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. Knowledge and Data Engineering, IEEE Transactions on, 17(6):734--749, june 2005.", "J. Bao, Y. Zheng, D. Wilkie, and M. F. Mokbel. A survey on recommendations in location-based social networks. GeoInformatica, 2014.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806500"}, {"title": "Kvasir: Seamless Integration of Latent Semantic Analysis-Based Content Provision into Web Browsing", "authors": ["Liang Wang\n,", "Sotiris Tasoulis\n,", "Teemu Roos\n,", "Jussi Kangasharju"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe Internet is overloading its users with excessive information flows, so that effective content-based filtering becomes crucial in improving user experience and work efficiency. We build Kvasir, a semantic recommendation system, atop latent semantic analysis and other state-of-art technologies to seamlessly integrate an automated and proactive content provision service into web browsing. We utilize the power of Apache Spark to scale up Kvasir to a practical Internet service. Herein we present the architecture of Kvasir, along with our solutions to the technical challenges in the actual system implementation.", "references": ["Kvasir project, http://cs.helsinki.fi/u/lxwang/kvasir.", "T. Berners-Lee, et al. The semantic web. In Scientific american, 284(5):28--37, 2001.", "M. Brand. Fast low-rank modifications of the thin singular value decomposition. In Linear Algebra and its Applications, 415(1):20 -- 30, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742825"}, {"title": "Worker skill estimation in team-based tasks", "authors": ["Habibur Rahman\n,", "Saravanan Thirumuruganathan\n,", "Senjuti Basu Roy\n,", "Sihem Amer-Yahia\n,", "Gautam Das"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMany emerging applications such as collaborative editing, multi-player games, or fan-subbing require to form a team of experts to accomplish a task together. Existing research has investigated how to assign workers to such team-based tasks to ensure the best outcome assuming the skills of individual workers to be known. In this work, we investigate how to estimate individual worker's skill based on the outcome of the team-based tasks they have undertaken. We consider two popular skill aggregation functions and estimate the skill of the workers, where skill is either a deterministic value or a probability distribution. We propose efficient solutions for worker skill estimation using continuous and discrete optimization techniques. We present comprehensive experiments and validate the scalability and effectiveness of our proposed solutions using multiple real-world datasets.", "references": ["A. Anagnostopoulos et al. Power in unity: forming teams in large-scale community systems. In CIKM, 2010.", "A. Anagnostopoulos et al. Online team formation in social networks. In WWW, 2012.", "M. H. Andersen. Max-plus algebra: Properties and applications. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809977"}, {"title": "Acoustruments: passive, acoustically-driven, interactive controls for handheld devices", "authors": ["Gierad Laput\n,", "Eric Brockmeyer\n,", "Moshe Mahler\n,", "Scott E. Hudson\n,", "Chris Harrison"], "publication": "SIGGRAPH '15: ACM SIGGRAPH 2015 Emerging Technologies", "abstract": "ABSTRACT\nSmartphones and handheld devices are increasingly being used in interactive applications beyond their conventional touchscreens. For example, tangibles allow users to interact with mobile devices using physical objects both on screen and around the device. Similarly, there is a growing class of auxiliary devices that require a smartphone to be docked, transforming an otherwise simple object into something with rich interactivity. However, these auxiliary devices still require numerous components, including mechanical mechanisms, PCBs, and sometimes batteries. This increases manufacturing costs, and reduces physical robustness.", "references": ["Laput, G., Brockmeyer, E., Hudson, S. E., Harrison, C. Acoustruments: Passive, Acoustically-Driven, Interactive Controls for Handheld Devices. In Proc. CHI'15."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2782782.2792490"}, {"title": "MP3 Steganography Techniques", "authors": ["Yalinne Castelan\n,", "Ben Khodja"], "publication": "RIIT '15: Proceedings of the 4th Annual ACM Conference on Research in Information Technology", "abstract": "ABSTRACT\nThe MP3 audio encoding format is currently one of the most popular encoding formats in use. On average, it takes significantly less space to store than, for example, a PCM-encoded WAV file, even though it retains most of the original, uncompressed audio information. Most users of MP3 files are unaware that they can be used as carriers of steganographically-hidden information. Although it has not yet been greatly explored, there are various types of steganography techniques that exist which allow for the hiding of information within MP3 files of any type. Two of the techniques the authors studied include those implemented by MP3Stego developed by Fabien Petitcolas and MP3Stegazaurus by former Illinois Institute of Technology student Mikhail Zaturenskiy. The technique implemented by MP3Stego performs the injection of covert information during the encoding process, while the technique implemented by MP3Stegazaurus uses areas of an already-existing MP3 file known to be skipped or ignored by MP3 playing and decoding applications to store covert information. The authors have developed a tool which implements a technique allowing for the hiding of covert information within the audio information-containing portions of an MP3 file in a way that does not yet appear to have been explored. Unlike the technique implemented by MP3Stego, which involves hiding information within the audio information-containing portions of an MP3 file during the encoding process, this new technique involves hiding it after the encoding process has already taken place. This paper details the research carried out by the authors as well as how the tool that makes use of this technique works.", "references": ["Bosi, Marina, and Richard E. Goldberg. Introduction to Digital Audio Coding and Standards. Boston: Kluwer Academic, 2003. Print.", "Edström., Björn. \"Blog.bjrn.se.\" Blog.bjrn.se. N.p., n.d. Web. 25 Nov. 2014.", "Hacker, Scot. MP3: The Definitive Guide. Sebastopol: O'Reilly Media, 2000. Print."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808062.2808074"}, {"title": "Schema-agnostic indexing with Azure DocumentDB", "authors": ["Dharma Shukla\n,", "Shireesh Thota\n,", "Karthik Raman\n,", "Madhan Gajendran\n,", "Ankur Shah\n,", "Sergii Ziuzin\n,", "Krishnan Sundaram\n,", "Miguel Gonzalez Guajardo\n,"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nAzure DocumentDB is Microsoft's multi-tenant distributed database service for managing JSON documents at Internet scale. DocumentDB is now generally available to Azure developers. In this paper, we describe the DocumentDB indexing subsystem. DocumentDB indexing enables automatic indexing of documents without requiring a schema or secondary indices. Uniquely, DocumentDB provides real-time consistent queries in the face of very high rates of document updates. As a multi-tenant service, DocumentDB is designed to operate within extremely frugal resource budgets while providing predictable performance and robust resource isolation to its tenants. This paper describes the DocumentDB capabilities, including document representation, query language, document indexing approach, core index support, and early production experiences.", "references": ["Azure DocumentDB Documentation. http://azure.microsoft.com/en-us/documentation/services/documentdb/", "Javascript Object Notation (JSON). http://www.ietf.org/rfc/rfc4627.txt", "ECMAScript Language Specification, http://www.ecma-international.org/publications/standards/Ecma-262.htm"], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824065"}, {"title": "An information retrieval approach for regression test prioritization based on program changes", "authors": ["Ripon K. Saha\n,", "Lingming Zhang\n,", "Sarfraz Khurshid\n,", "Dewayne E. Perry"], "publication": "ICSE '15: Proceedings of the 37th International Conference on Software Engineering - Volume 1", "abstract": "ABSTRACT\nRegression testing is widely used in practice for validating program changes. However, running large regression suites can be costly. Researchers have developed several techniques for prioritizing tests such that the higher-priority tests have a higher likelihood of finding bugs. A vast majority of these techniques are based on dynamic analysis, which can be precise but can also have significant overhead (e.g., for program instrumentation and test-coverage collection). We introduce a new approach, REPiR, to address the problem of regression test prioritization by reducing it to a standard Information Retrieval problem such that the differences between two program versions form the query and the tests constitute the document collection. REPiR does not require any dynamic profiling or static program analysis. As an enabling technology we leverage the open-source IR toolkit Indri. An empirical evaluation using eight open-source Java projects shows that REPiR is computationally efficient and performs better than existing (dynamic or static) techniques for the majority of subject systems.", "references": ["M. J. Arafeen and H. Do. Test case prioritization using requirements-based clustering. In ICST, pages 312--321, 2013.", "A. Arcuri and L. Briand. A practical guide for using statistical tests to assess randomized algorithms in software engineering. In ICSE, pages 1--10, 2011.", "T. Ball. On the limit of control flow analysis for regression test selection. In ISSTA, pages 134--142, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2818754.2818789"}, {"title": "Supporting online analytics with user-defined estimation and early termination in a MapReduce-like framework", "authors": ["Yi Wang\n,", "Linchuan Chen\n,", "Gagan Agrawal"], "publication": "DISCS '15: Proceedings of the 2015 International Workshop on Data-Intensive Scalable Computing Systems", "abstract": "ABSTRACT\nOnline analytics based on runtime approximation has been widely adopted for meeting time and/or resource constraints. Though MapReduce has been gaining its popularity in both scientific and commercial sectors, there are several obstacles in implementing online analytics in a MapReduce implementation.\nIn this paper, we present a MapReduce-like framework for online analytics. Our system can process the input incrementally, provide fast estimates, and terminate the execution as soon as a user-defined termination state is reached. We have extended the MapReduce API by allowing the user to customize both the estimation method and termination condition. We also have shown both the functionality and efficiency of our system through three approximate applications. A comparison with a batch processing implementation shows a speedup of at least an order of magnitude.", "references": ["A. Aggarwal, A. Deshpande, and R. Kannan. Adaptive sampling for k-means clustering. In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, pages 15--28. Springer, 2009.", "D. Arthur and S. Vassilvitskii. k-means++: The advantages of careful seeding. In SIAM, pages 1027--1035. Society for Industrial and Applied Mathematics, 2007.", "J.-H. Böse, A. Andrzejak, and M. Högqvist. Beyond online aggregation: parallel and incremental data mining with online map-reduce. In Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud, page 3. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2831244.2831247"}, {"title": "Supporting drug prescription via predictive and personalized query system", "authors": ["Samamon Khemmarat\n,", "Lixin Gao"], "publication": "PervasiveHealth '15: Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare", "abstract": "ABSTRACT\nDrug prescription requires consideration of several factors, such as drug interactions and side effects. The process is further complicated by the fact that the presence of some drug properties, such as side effects, depends on patient characteristics, such as age and gender. Our goal is to provide a tool to assist medical practitioners in prescribing drugs. We develop an approach to query for drugs that satisfy a set of conditions based on drug properties. Furthermore, the approach tailors the answers to a given patient profile. We utilize drug information from multiple sources. However, data from these sources are usually noisy and incomplete as they are either manually curated or automatically extracted from text resources. To cope with incomplete and noisy data, our approach considers both the answers that exactly match and those that closely match the query. We represent drug information as a heterogeneous graph and model answering a query as a subgraph matching problem. To rank answers, our approach leverages the structure and the heterogeneity of the drug graph to quantify the likelihood of missing edges and integrates the likelihood into the scores of the answers. Our evaluation shows that for quantifying the edge likelihood, our graph-based approach can improve the AUROC (Area under Receiver Operating Characteristic) [1] by up to 40%, comparing to a baseline approach. We demonstrate the benefits of our system through several query examples.", "references": ["T. Fawcett, \"An introduction to roc analysis,\" Pattern recognition letters, vol. 27, no. 8, pp. 861--874, 2006.", "C. Knox et al., \"Drugbank 3.0: a comprehensive resource for omics research on drugs,\" Nucleic acids research, vol. 39, no. suppl 1, pp. D1035--D1041, 2011.", "M. Kuhn et al., \"A side effect resource to capture phenotypic effects of drugs,\" Molecular systems biology, vol. 6, no. 1, p. 343, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2826165.2826167"}, {"title": "Functional dependency discovery: an experimental evaluation of seven algorithms", "authors": ["Thorsten Papenbrock\n,", "Jens Ehrlich\n,", "Jannik Marten\n,", "Tommy Neubert\n,", "Jan-Peer Rudolph\n,", "Martin Schönberg\n,", "Jakob Zwiener\n,"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nFunctional dependencies are important metadata used for schema normalization, data cleansing and many other tasks. The efficient discovery of functional dependencies in tables is a well-known challenge in database research and has seen several approaches. Because no comprehensive comparison between these algorithms exist at the time, it is hard to choose the best algorithm for a given dataset. In this experimental paper, we describe, evaluate, and compare the seven most cited and most important algorithms, all solving this same problem.\nFirst, we classify the algorithms into three different categories, explaining their commonalities. We then describe all algorithms with their main ideas. The descriptions provide additional details where the original papers were ambiguous or incomplete. Our evaluation of careful re-implementations of all algorithms spans a broad test space including synthetic and real-world data. We show that all functional dependency algorithms optimize for certain data characteristics and provide hints on when to choose which algorithm. In summary, however, all current approaches scale surprisingly poorly, showing potential for future research.", "references": ["Z. Abedjan, P. Schulze, and F. Naumann. DFD: Efficient functional dependency discovery. In Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 949--958, 2014.", "R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proceedings of the International Conference on Very Large Databases (VLDB), pages 487--499, 1994.", "R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proceedings of the International Conference on Very Large Databases (VLDB), pages 487--499, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2794367.2794377"}, {"title": "How to De-identify Your Data", "authors": ["Olivia Angiuli\n,", "Joe Blitzstein\n,", "Jim Waldo"], "publication": "Queue", "abstract": "Abstract\nBalancing statistical accuracy and subject privacy in large social-science data sets", "references": ["Daries, J. P., Reich, J., Waldo, J., Young, E. M., Whittinghill, J., Ho, A.D., Seaton, D. T., Chuang, I. 2014. Privacy, anonymity, and big data in the social sciences. Communications of the ACM 57(9): 56-63.", "Sweeney, L. 2002. k-anonymity: a model for protecting privacy. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 10(5): 557-570.", "Young, E. 2015. Educational privacy in the online classroom: FERPA, MOOCs, and the big data conundrum. Harvard Journal of Law & Technology 28(2): 549-592."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838344.2838930"}, {"title": "If SIGIR had an Academic Track, What Would Be In It?", "authors": ["David Hawking"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIt used to be the case that very little industry research was presented at SIGIR. Now the balance has radically changed -- many accepted papers have industry authors and many rely on industry data sets -- To the extent that a leading academic member of the SIGIR community has light-heartedly proposed the creation of an Academic Track.\nBehind the levity lies the important question of how a researcher can make a meaningful contribution to the field, in the absence of petabyte-scale sets of documents and massive user-interaction logs. Theoretical contributions can revolutionize thinking, but have greatest impact when applicable in practice, and when empirically validated.\nIn my years at Funnelback and more recently at Microsoft I have been very aware of high-impact but not-well-solved IR problems involving relatively tiny datasets. Many of them are characterized by sparsity of user interaction data and are hence not well-suited to simple machine learning approaches or to large scale A/B testing. My talk will illustrate and attempt to characterize these problems and to suggest fruitful areas for academic research.\nIf time permits, I will mention some areas in which academic research has contributed to current large-scale industry practice.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2776784"}, {"title": "Combining Orthogonal Information in Large-Scale Cross-Language Information Retrieval", "authors": ["Shigehiko Schamoni\n,", "Stefan Riezler"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSystem combination is an effective strategy to boost retrieval performance, especially in complex applications such as cross-language information retrieval (CLIR) where the aspects of translation and retrieval have to be optimized jointly. We focus on machine learning-based approaches to CLIR that need large sets of relevance-ranked data to train high-dimensional models. We compare these models under various measures of orthogonality, and present an experimental evaluation on two different domains (patents, Wikipedia) and two different language pairs (Japanese-English, German-English). We show that gains of over 10 points in MAP/NDCG can be achieved over the best single model by a linear combination of the models that contribute the most orthogonal information, rather than by combining the models with the best standalone retrieval performance.", "references": ["J. A. Aslam and M. Montague. Models for metasearch. In SIGIR, 2001.", "B. Bai, J. Weston, D. Grangier, R. Collobert, K. Sadamasa, Y. Qi, O. Chapelle, and K. Weinberger. Learning to rank with (a lot of) word features. Information Retrieval Journal, 13(3), 2010.", "N. J. Belkin, P. Kantor, E. A. Fox, and J. A. Shaw. Combining the evidence of multiple query representations for information retrieval. Inf. Process. Manage., 31(3):431--448, 1995."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767805"}, {"title": "DynaCorrect: Dynamically Correcting Cache for Non-cooperative Systems", "authors": ["Akshat Verma\n,", "Sharat Singh\n,", "Shubham Srivastava\n,", "Sunil Kumar\n,", "Rakesh Ranjan\n,", "Zafar Ansari"], "publication": "Middleware Industry '15: Proceedings of the Industrial Track of the 16th International Middleware Conference", "abstract": "ABSTRACT\nOnline commerce platforms connect suppliers to customers using internet. In online travel industry, the suppliers provide a programmatic interface for the platform to query and book travel services. Typically, multiple competitive platforms connect to the same set of suppliers and any change in inventory level leads to changes in availability and pricing. One of the key problems that online platforms deal with is to ensure the accuracy of inventory availability and pricing, while ensuring low response time to the customers. In this work, we present the design and implementation of DynaCorrect, a dynamically correcting cache for non-cooperative systems. DynaCorrect caches inventory data from remote suppliers to ensure low response time. Since the inventory price and availability may change in the background, DynaCorrect employs random sampling and a feedback loop to correct the cache. Further, in order to ensure high cache hit rate, it refreshes inventory based on popularity, spatial and temporal locality. Finally, it employs deduplication to ensure high resource efficiency for the caching system. We implemented DynaCorrect in production over a period of time and observed significant benefits to achieve the goals of high accuracy, low response time and reduced number of queries to the suppliers.", "references": ["Martin C Brown. Getting Started with Couchbase Server. \"O'Reilly Media, Inc.\", 2012.", "Nathan Bronson et al. Tao: FacebookâĂ&Zacute;s distributed data store for the social graph. In Usenix Annual Technical Conference, 2013.", "Rajesh Nishtala et al. Scaling memcache at facebook. In Usenix NSDI, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2830013.2830014"}, {"title": "Modularity-Based Query Clustering for Identifying Users Sharing a Common Condition", "authors": ["Maayan Gal-On Harel\n,", "Elad Yom-Tov"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe present an algorithm for identifying users who share a common condition from anonymized search engine logs. Input to the algorithm is a set of seed phrases that identify users with the condition of interest with high precision albeit at a very low recall. We expand the set of seed phrases by clustering queries according to the pages users clicked following these queries and the temporal ordering of queries within sessions, emphasizing the subgraph containing seed phrases. To this end, we extend modularity-based clustering such that it uses the information in the initial seed phrases as well as other queries of users in the population of interest. We evaluate the performance of the proposed method on two datasets, one of mood disorders and the other of anorexia, by classifying users according to the clusters in which they appeared and the phrases contained thereof, and show that the area under the receiver operating characteristic curve (AUC) obtained by these methods exceeds 0.87. These results demonstrate the value of our algorithm for both identifying users for future research and to gain better understanding of the language associated with the condition.", "references": ["L. M. Aiello, D. Donato, U. Ozertem, and F. Menczer. Behavior-driven clustering of queries into topics. In 20th ACM international conference on Information and knowledge management, pages 1373--1382, 2011.", "R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query clustering for boosting web page ranking. In Advances in Web Intelligence, pages 164--175. Springer, 2004.", "D. Beeferman and A. Berger. Agglomerative clustering of a search engine query log. In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 407--416. ACM, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767798"}, {"title": "Databrary: Enabling Sharing and Reuse of Research Video", "authors": ["Dylan A. Simon\n,", "Andrew S. Gordon\n,", "Lisa Steiger\n,", "Rick O. Gilmore"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nVideo and audio recordings serve as a primary data source in many fields, especially in the social and behavioral sciences. Recordings present unique opportunities for reuse and reanalysis for novel scientific purposes, but also present challenges related to respecting the privacy of individuals depicted. Databrary is a web-based service for sharing and reusing the video data created by researchers in the developmental and learning sciences. By investigating how researchers organize, analyze, and mine their own recordings, we have implemented a system that empowers researchers to capture, store, and share recordings in a standardized way. This demo will provide a tour through the Databrary service, highlighting how it promotes storage, management, sharing, and reuse of research data, controls access privileges to restricted human subject data, and facilitates browsing and discoverability of datasets.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756951"}, {"title": "Configuring Distributed Computations Using Response Surfaces", "authors": ["Adem Efe Gencer\n,", "David Bindel\n,", "Emin Gün Sirer\n,", "Robbert van Renesse"], "publication": "Middleware '15: Proceedings of the 16th Annual Middleware Conference", "abstract": "ABSTRACT\nConfiguring large distributed computations is a challenging task. Efficiently executing distributed computations requires configuration tuning based on careful examination of application and hardware properties. Considering the large number of parameters and impracticality of using trial and error in a production environment, programmers tend to make these decisions based on their experience and rules of thumb. Such configurations can lead to underutilized and costly clusters, and missed deadlines.\nIn this paper, we present a new methodology for determining desired hardware and software configuration parameters for distributed computations. The key insight behind this methodology is to build a response surface that captures how applications perform under different hardware and software configuration. Such a model can be built through iterated experiments using the real system, or, more efficiently, using a simulator. The resulting model can then generate recommendations for configuration parameters that are likely to yield the desired results even if they have not been tried either in simulation or in real-life. The process can be iterated to refine previous predictions and achieve better results.\nWe have implemented this methodology in a configuration recommendation system for MapReduce 2.0 applications. Performance measurements show that representative applications achieve up to 5× performance improvement when they use the recommended configuration parameters compared to the default ones.", "references": ["Amazon EC2. http://aws.amazon.com/ec2/.", "Ananthanarayanan, G., Agarwal, S., Kandula, S., Greenberg, A., Stoica, I., Harlan, D., and Harris, E. Scarlett: Coping with skewed content popularity in MapReduce clusters. In Proceedings of the Conference on Computer Systems (Salzburg, Austria, 2011), EuroSys '11, ACM, pp. 287--300.", "Ananthanarayanan, G., Kandula, S., Greenberg, A., Stoica, I., Lu, Y., Saha, B., and Harris, E. Reining in the outliers in Map-Reduce clusters using Mantri. In Proceedings of the Conference on Operating Systems Design and Implementation (Vancouver, BC, Canada, 2010), USENIX Association, pp. 265--278."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814576.2814730"}, {"title": "Open and Closed Schema for Aligning Knowledge and Text Collections", "authors": ["Matthew Kelcey"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nWhen it comes to knowledge bases most people's first thought are structured sources such as Freebase/Wikidata and their relationship to similarly structured web sources such as Wikipedia. A lot of additional and interesting \"knowledge\" though is captured in unstructured databases constructed in a less supervised manner using open information extraction techniques. In this talk we'll discuss some of the differences between open/closed schema knowledge bases including the ideas of objective vs subjective content as well as freshness and trust. We'll give an overview on approaches to aligning such data sources in a way that their relative strengths can be combined and finish with applications of such alignments; particularly around open question and answer systems.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810140"}, {"title": "Semi-supervised Coupled Dictionary Learning for Cross-modal Retrieval in Internet Images and Texts", "authors": ["Xing Xu\n,", "Yang Yang\n,", "Atsushi Shimada\n,", "Rin-ichiro Taniguchi\n,", "Li He"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nNowadays massive amount of images and texts has been emerging on the Internet, arousing the demand of effective cross-modal retrieval such as text-to-image search and image-to-text search. To eliminate the heterogeneity between the modalities of images and texts, the existing subspace learning methods try to learn a common latent subspace under which cross-modal matching can be performed. However, these methods usually require fully paired samples (images with corresponding texts) and also ignore the class label information along with the paired samples. This may inhibit these methods from learning an effective subspace since the correlations between two modalities are implicitly incorporated. Indeed, the class label information can reduce the semantic gap between different modalities and explicitly guide the subspace learning procedure. In addition, the large quantities of unpaired samples (images or texts) may provide useful side information to enrich the representations from learned subspace. Thus, in this paper we propose a novel model for cross-modal retrieval problem. It consists of 1) a semi-supervised coupled dictionary learning step to generate homogeneously sparse representations for different modalities based on both paired and unpaired samples; 2) a coupled feature mapping step to project the sparse representations of different modalities into a common subspace defined by class label information to perform cross-modal matching. Experiments on a large scale web image dataset MIRFlickr-1M with both fully paired and unpaired settings show the effectiveness of the proposed model on the cross-modal retrieval task.", "references": ["L. Ballan, T. Uricchio, L. Seidenari, and A. Bimbo. A cross media model for automatic image annotation. In ICMR, 2014.", "Y. Gong, Q. Ke, M. Isard, and S. Lazebnik. A multi-view embedding space for modeling internet images, tags, and their semantics. IJCV, 106:210--233, 2014.", "D. R. Hardoon, S. R. Szedmak, and J. R. Shawe-taylor. Canonical correlation analysis: An overview with application to learning methods. Neural Comput., 16(12):2639--2664, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806346"}, {"title": "Random surfers on a web encyclopedia", "authors": ["Florian Geigl\n,", "Daniel Lamprecht\n,", "Rainer Hofmann-Wellenhof\n,", "Simon Walk\n,", "Markus Strohmaier\n,", "Denis Helic"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nThe random surfer model is a frequently used model for simulating user navigation behavior on the Web. Various algorithms, such as PageRank, are based on the assumption that the model represents a good approximation of users browsing a website. However, the way users browse the Web has been drastically altered over the last decade due to the rise of search engines. Hence, new adaptations for the established random surfer model might be required, which better capture and simulate this change in navigation behavior. In this article we compare the classical uniform random surfer to empirical navigation and page access data in a Web Encyclopedia. Our high level contributions are (i) a comparison of stationary distributions of different types of the random surfer to quantify the similarities and differences between those models as well as (ii) new insights into the impact of search engines on traditional user navigation. Our results suggest that the behavior of the random surfer is almost similar to those of users---as long as users do not use search engines. We also find that classical website navigation structures, such as navigation hierarchies or breadcrumbs, only exercise limited influence on user navigation anymore. Rather, a new kind of navigational tools (e.g., recommendation systems) might be needed to better reflect the changes in browsing behavior of existing users.", "references": ["S. Al-Saffar and G. Heileman. Experimental bounds on the usefulness of personalized and topic-sensitive pagerank. In Web Intelligence, IEEE/WIC/ACM International Conference on, pages 671--675, Nov 2007.", "J. Alstott, E. Bullmore, and D. Plenz. powerlaw: A python package for analysis of heavy-tailed distributions. PLoS ONE, 9(1):e85777, 01 2014.", "A. Blum, T.-H. H. Chan, and M. R. Rwebangira. A random-surfer web-graph model. ANALCO, 6:238--246, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809598"}, {"title": "Recommending relevant sections from a webpage about programming errors and exceptions", "authors": ["Mohammad Masudur Rahman\n,", "Chanchal K. Roy"], "publication": "CASCON '15: Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering", "abstract": "ABSTRACT\nProgramming errors or exceptions are inherent in software development and maintenance, and given today's Internet era, software developers often look at web for finding working solutions. They make use of a search engine for retrieving relevant pages, and then look for the appropriate solutions by manually going through the pages one by one. However, both the manual checking of a page's content against a given exception (and its context) and then working an appropriate solution out are non-trivial tasks. They are even more complex and time-consuming with the bulk of irrelevant (i.e., off-topic) and noisy (e.g., advertisements) content in the web page. In this paper, we propose an IDE-based and context-aware page content recommendation technique that locates and recommends relevant sections from a given web page by exploiting the technical details, in particular, the context of an encountered exception in the IDE. An evaluation with 250 web pages related to 80 programming exceptions, comparison with the only available closely related technique, and a case study involving comparison with VSM and LSA techniques show that the proposed technique is highly promising in terms of precision, recall and F1-measure.", "references": ["ContentSuggest Web Portal. URL http://www.usask.ca/~mor543/contentsuggest.", "Stackoverflow Post. URL http://stackoverflow.com/questions/17485297.", "G. Antoniol, G. Canfora, G. Casazza, A. De Lucia, and E. Merlo. Recovering traceability links between code and documentation. TSE, 28(10): 970--983, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2886444.2886471"}, {"title": "Prediction of User Ratings of Oral Presentations using Label Relations", "authors": ["Toshihiko Yamasaki\n,", "Yusuke Fukushima\n,", "Ryosuke Furuta\n,", "Litian Sun\n,", "Kiyoharu Aizawa\n,", "Danushka Bollegala"], "publication": "ASM '15: Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia", "abstract": "ABSTRACT\nPredicting the users' impressions on a video talk is an important step for recommendation tasks. We propose a method to accurately predict multiple impression-related user ratings for a given video talk. Our proposal considers (a) multimodal features including linguistic as well as acoustic features, (b) correlations between different user ratings (labels), and (c) correlations between different feature types. In particular, the proposed method models both label and feature correlations within a single Markov random field (MRF), and jointly optimizes the label assignment problem to obtain a consistent and multiple set of labels for a given video. We train and evaluate the proposed method using a collection of 1,646 TED talk videos for 14 different tags. Experimental results on this dataset show that the proposed method obtains a statistically significant macro-average accuracy of 93.3%, outperforming several competitive baseline methods.", "references": ["An extensive experimental comparison of methods for multi-label learning. Pattern Recognition, 45(9):3084 -- 3104, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 3:993--1022, 2003.", "J. Davidson, B. Liebaid, J. Liu, P. Nandy, T. V. Vleet, U. Gargi, S. Gupta, Y. He, M. Lambert, B. Livingston, and D. Sampath. The youtube video recommendation system. In RecSys, pages 293 -- 296, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813524.2813533"}, {"title": "Session details: Special Track - Government Information Systems", "authors": ["Claudia Cappelli\n,", "Renata Araujo\n,", "Dalton Lopes Martins"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252441"}, {"title": "Optimal Aggregation Policy for Reducing Tail Latency of Web Search", "authors": ["Jeong-Min Yun\n,", "Yuxiong He\n,", "Sameh Elnikety\n,", "Shaolei Ren"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nA web search engine often employs partition-aggregate architecture, where an aggregator propagates a user query to all index serving nodes (ISNs) and collects the responses from them. An aggregation policy determines how long the aggregators wait for the ISNs before returning aggregated results to users, crucially affecting both query latency and quality. Designing an aggregation policy is, however, challenging: Response latency among queries and among ISNs varies significantly, and aggregators lack of knowledge about when ISNs will respond. In this paper, we propose aggregation policies that minimize tail latency of search queries subject to search quality service level agreements (SLAs), combining data-driven offline analysis with online processing. Beginning with a single aggregator, we formally prove the optimality of our policy: It achieves the offline optimal result without knowing future responses of ISNs. We extend our policy for commonly-used hierarchical levels of aggregators and prove its optimality when messaging times between aggregators are known. We also present an empirically-effective policy to address unknown messaging time. We use production traces from a commercial search engine, a commercial advertisement engine, and synthetic workloads to evaluate the aggregation policy. The results show that compared to prior work, the policy reduces tail latency by up to 40% while satisfying same quality SLAs.", "references": ["M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data center tcp (dctcp). SIGCOMM Comput. Commun. Rev., 41(4):--, Aug. 2010.", "I. S. Altingovde, R. Blanco, B. B. Cambazoglu, R. Ozcan, E. Sarigil, and O. Ulusoy. Characterizing web search queries that match very few or no results. In CIKM, 2012.", "V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with effective early termination. In SIGIR, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767708"}, {"title": "Deep Multimodal Speaker Naming", "authors": ["Yongtao Hu\n,", "Jimmy SJ. Ren\n,", "Jingwen Dai\n,", "Chang Yuan\n,", "Li Xu\n,", "Wenping Wang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nAutomatic speaker naming is the problem of localizing as well as identifying each speaking character in a TV/movie/live show video. This is a challenging problem mainly attributes to its multimodal nature, namely face cue alone is insufficient to achieve good performance. Previous multimodal approaches to this problem usually process the data of different modalities individually and merge them using handcrafted heuristics. Such approaches work well for simple scenes, but fail to achieve high performance for speakers with large appearance variations. In this paper, we propose a novel convolutional neural networks (CNN) based learning framework to automatically learn the fusion function of both face and audio cues. We show that without using face tracking, facial landmark localization or subtitle/transcript, our system with robust multimodal feature extraction is able to achieve state-of-the-art speaker naming performance evaluated on two diverse TV series. The dataset and implementation of our algorithm are publicly available online.", "references": ["T. Ahonen, A. Hadid, and M. Pieti-kainen. Face description with local binary patterns: Application to face recognition. TPAMI, 2006.", "M. Bauml, M. Tapaswi, and R. Stiefelhagen. Semi-supervised learning with constraints for person identification in multimedia data. In CVPR, 2013.", "P. Belhumeur, J. Hespanha, and D. Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. TPAMI, 1997."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806293"}, {"title": "How Well Are Arabic Websites Archived?", "authors": ["Lulwah M. Alkwai\n,", "Michael L. Nelson\n,", "Michele C. Weigle"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nIt is has long been anecdotally known that web archives and search engines favor Western and English-language sites. In this paper we quantitatively explore how well indexed and archived are Arabic language web sites. We began by sampling 15,092 unique URIs from three different website directories: DMOZ (multi-lingual), Raddadi and Star28 (both primarily Arabic language). Using language identification tools we eliminated pages not in the Arabic language (e.g., English language versions of Al-Jazeera sites) and culled the collection to 7,976 definitely Arabic language web pages. We then used these 7,976 pages and crawled the live web and web archives to produce a collection of 300,646 Arabic language pages. We discovered: 1) 46% are not archived and 31% are not indexed by Google (www.google.com), 2) only 14.84% of the URIs had an Arabic country code top-level domain (e.g., .sa) and only 10.53% had a GeoIP in an Arabic country, 3) having either only an Arabic GeoIP or only an Arabic top-level domain appears to negatively impact archiving, 4) most of the archived pages are near the top level of the site and deeper links into the site are not well-archived, 5) the presence in a directory positively impacts indexing and presence in the DMOZ directory, specifically, positively impacts archiving.", "references": ["S. G. Ainsworth, A. Alsum, H. SalahEldeen, M. C. Weigle, and M. L. Nelson. How Much of the Web is Archived? In Proceedings of the IEEE/ACM Joint Conference on Digital Libraries (JCDL), pages 133--136. ACM, 2011.", "A. Alarifi, M. Alghamdi, M. Zarour, B. Aloqail, H. Lraqibah, K. Alsadhan, and L. Alkwai. Estimating the Size of Arabic Indexed Web Content. Scientific Research and Essays, 7(28):2472--2483, 2012.", "A. AlSum. Web Archive Services Framework for Tighter Integration Between the Past and Present Web. PhD thesis, Old Dominion University, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756912"}, {"title": "Pushing the Limits of Instance Matching Systems: A Semantics-Aware Benchmark for Linked Data", "authors": ["Tzanina Saveta\n,", "Evangelia Daskalaki\n,", "Giorgos Flouris\n,", "Irini Fundulaki\n,", "Melanie Herschel\n,", "Axel-Cyrille Ngonga Ngomo"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe architectural choices behind the Data Web have led to the publication of large interrelated data sets that contain different descriptions for the same real-world objects. Due to the mere size of current online datasets, such duplicate instances are most commonly detected (semi-)automatically using instance matching frameworks. Choosing the right framework for this purpose remains tedious, as current instance matching benchmarks fail to provide end users and developers with the necessary insights pertaining to how current frameworks behave when dealing with real data. In this poster, we present the Semantic Publishing Instance Matching Benchmark (SPIMBENCH) which allows the benchmarking of instance matching systems against not only structure-based and value-based test cases, but also against semantics-aware test cases based on OWL axioms. SPIMBENCH features a scalable data generator and a weighted gold standard that can be used for debugging instance matching systems and for reporting how well they perform in various matching tasks.", "references": ["I. Bhattacharya and L. Getoor. Entity resolution in graphs. Mining Graph Data. Wiley and Sons, 2006.", "A. K. Elmagarmid, P.G. Ipeirotis, and V.S. Verykios. Duplicate Record Detection: A Survey. TKDE, 19(1), 2007.", "C. Li, L. Jin, and S. Mehrotra. Supporting efficient record linkage for large data sets using mapping techniques. In WWW, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742729"}, {"title": "Towards amharic semantic search engine", "authors": ["Fekade Getahun\n,", "Genet Asefa"], "publication": "MEDES '15: Proceedings of the 7th International Conference on Management of computational and collective intElligence in Digital EcoSystems", "abstract": "ABSTRACT\nRecently the amount of documents written in Amharic language has been dramatically increasing. Searching such content using localized and regional version of general search engine such as google.com.et returns documents containing search key terms while excluding specific characteristics of Amharic Language.\nIn this paper, we present the design and implementation of Semantic Search Engine for Amharic documents. The search engine has Crawler, Ontology/Knowledge base, Indexer and Query Processor that consider characteristics of Amharic language. The ontology provides shared concepts Sport. This ontology is built manually by language and sport domain experts and it is used in building semantic indexer, ranker and query engine. In addition, we show how the system facilitate meaning based searching, document relevant and popularity based documents ranking.", "references": ["Parul Gupta and A. Sharma, \"Context based Indexing in Search Engines using Ontology,\" International Journal of Computer Applications, vol. 1, no. 14, pp. 53--56, 2010.", "Jacob Kohler, Stephan Philippi, Michael Specht, and Alexander Ruegg, \"Ontology based text indexing and querying for the semantic web,\" Knowledge Based Systems - KBS, vol. 19, no. 8, pp. 744--754, 2006.", "Soner Kara, \"An ontology-based retrieval system using semantic indexing,\" 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2857218.2857235"}, {"title": "Compressed Indexes for String Searching in Labeled Graphs", "authors": ["Paolo Ferragina\n,", "Francesco Piccinno\n,", "Rossano Venturini"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nStoring and searching large labeled graphs is indeed becoming a key issue in the design of space/time efficient online platforms indexing modern social networks or knowledge graphs. But, as far as we know, all these results are limited to design compressed graph indexes which support basic access operations onto the link structure of the input graph, such as: given a node u, return the adjacency list of u. This paper takes inspiration from the Facebook Unicorn's platform and proposes some compressed-indexing schemes for large graphs whose nodes are labeled with strings of variable length - i.e., node's attributes such as user's (nick-)name - that support sophisticated search operations which involve both the linked structure of the graph and the string content of its nodes.\nAn extensive experimental evaluation over real social networks will show the time and space efficiency of the proposed indexing schemes and their query processing algorithms.", "references": ["S. Alstrup, G. S. Brodal, and T. Rauhe. Optimal static range reporting in one dimension. In STOC, pages 476--482, 2001.", "A. Amir, M. Lewenstein, and N. Lewenstein. Pattern matching in hypertext. In WADS, LNCS 1272, pages 160--173, 1997.", "L. Backstrom, D. P. Huttenlocher, J. M. Kleinberg, and X. Lan. Group formation in large social networks: membership, growth, and evolution. In KDD, pages 44--54, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741140"}, {"title": "Spatial Sound and Multimodal Interaction in Immersive Environments", "authors": ["Francesco Grani\n,", "Dan Overholt\n,", "Cumhur Erkut\n,", "Steven Gelineck\n,", "Georgios Triantafyllidis\n,", "Rolf Nordahl\n,", "Stefania Serafin"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nSpatial sound and interactivity are key elements of investigation at the Sound And Music Computing master program at Aalborg University Copenhagen.\nWe present a collection of research directions and recent results from work in these areas, with the focus on our multifaceted approaches to two primary problem areas: 1) creation of interactive spatial audio experiences for immersive virtual and augmented reality scenarios, and 2) production and mixing of spatial audio for cinema, music, and other artistic contexts. Several ongoing research projects are described, wherein the latest developments are discussed.\nThese include elements in which we have provided sonic interaction in virtual environments, interactivity with volumetric sound sources using VBAP and Wave Field Synthesis (WFS), and binaural sound for virtual environments and spatial audio mixing. We show that the variety of approaches presented here are necessary in order to optimize interactivity with spatial audio for each particular type of task.", "references": ["Jens Ahrens and Sascha Spors. Two physical models for spatially extended virtual sound sources. In Proc. AES Convention, New York, NY, USA, 2011.", "V Ralph Algazi, Richard O Duda, Dennis M Thompson, and Carlos Avendano. The cipic hrtf database. In Applications of Signal Processing to Audio and Acoustics, 2001 IEEE Workshop on the, pages 99--102. IEEE, 2001.", "P. Barattini, C. Morand, and N. M. Robertson. A proposed gesture set for the control of industrial collaborative robots. In RO-MAN, 2012 IEEE, pages 132--137, Sept 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814919"}, {"title": "GraphMat: high performance graph analytics made productive", "authors": ["Narayanan Sundaram\n,", "Nadathur Satish\n,", "Md Mostofa Ali Patwary\n,", "Subramanya R. Dulloor\n,", "Michael J. Anderson\n,"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nGiven the growing importance of large-scale graph analytics, there is a need to improve the performance of graph analysis frameworks without compromising on productivity. GraphMat is our solution to bridge this gap between a user-friendly graph analytics framework and native, hand-optimized code. GraphMat functions by taking vertex programs and mapping them to high performance sparse matrix operations in the backend. We thus get the productivity benefits of a vertex programming framework without sacrificing performance. GraphMat is a single-node multicore graph framework written in C++ which has enabled us to write a diverse set of graph algorithms with the same effort compared to other vertex programming frameworks. GraphMat performs 1.1-7X faster than high performance frameworks such as GraphLab, CombBLAS and Galois. GraphMat also matches the performance of MapGraph, a GPU-based graph framework, despite running on a CPU platform with significantly lower compute and bandwidth resources. It achieves better multicore scalability (13-15X on 24 cores) than other frameworks and is 1.2X off native, hand-optimized code on a variety of graph algorithms. Since GraphMat performance depends mainly on a few scalable and well-understood sparse matrix operations, GraphMat can naturally benefit from the trend of increasing parallelism in future hardware.", "references": ["Apache giraph. http://giraph.apache.org/.", "Apache spark. https://spark.apache.org/.", "Combinatorial Blas v 1.3. http://gauss.cs.ucsb.edu/aydin/CombBLAS/html/."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2809974.2809983"}, {"title": "A Comparison of Supervised Keyphrase Extraction Models", "authors": ["Florin Bulgarov\n,", "Cornelia Caragea"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nKeyphrases for a document provide a high-level topic description of the document. Given the number of documents growing exponentially on the Web in the past years, accurate methods for extracting keyphrases from such documents are greatly needed. In this study, we provide a comparison of existing supervised approaches to this task to determine the current best performing model. We use research articles on the Web as the case study.", "references": ["C. Caragea, F. Bulgarov, A. Godea, and S. Das Gollapalli. Citation-enhanced keyphrase extraction from research papers: A supervised approach. In EMNLP, 2014.", "E. Frank, G. W. Paynter, I. H. Witten, C. Gutwin, and C. G. Nevill-Manning. Domain-specific keyphrase extraction. In IJCAI '99, 1999.", "S. D. Gollapalli and C. Caragea. Extracting keyphrases from research papers using citation networks. In AAAI, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742776"}, {"title": "Collaborative Prediction for Multi-entity Interaction With Hierarchical Representation", "authors": ["Qiang Liu\n,", "Shu Wu\n,", "Liang Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWith the rapid growth of Internet applications, there are more and more entities in interaction scenarios, and thus collaborative prediction for multi-entity interaction is becoming a significant problem. The state-of-the-art methods, e.g., tensor factorization and factorization machine, predict multi-entity interaction based on calculating the similarity among all entities. However, these methods are usually not able to reveal the joint characteristics of entities in the interaction. Besides, some methods may succeed in one specific application, but they can not be extended effectively for other applications or interaction scenarios with more entities. In this work, we propose a Hierarchical Interaction Representation (HIR) model, which models the mutual action among different entities as a joint representation. We generate the interaction representation of two entities via tensor multiplication, which is preformed iteratively to construct a hierarchical structure among all entities. Moreover, we employ several hidden layers to reveal the underlying properties of this interaction and enhance the model performance. After generating final representation, the prediction can be calculated using a variety of machine learning methods according to different tasks (i.e., linear regression for regression tasks, pair-wise ranking for ranking tasks and logistic regression for classification tasks). Experimental results show that our proposed HIR model yields significant improvements over the competitive compared methods in four different application scenarios (i.e., general recommendation, context-aware recommendation, latent collaborative retrieval and click-through rate prediction).", "references": ["Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. TPAMI, 35(8):1798--1828, 2013.", "K.-J. Hsiao, A. Kulesza, and A. Hero. Social collaborative retrieval. In WSDM, pages 293--302, 2014.", "M. Jamali and L. Lakshmanan. Heteromf: recommendation in heterogeneous information networks using context dependent factor models. In WWW, pages 643--654, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806530"}, {"title": "Neighbor-sensitive hashing", "authors": ["Yongjoo Park\n,", "Michael Cafarella\n,", "Barzan Mozafari"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nApproximate kNN (k-nearest neighbor) techniques using binary hash functions are among the most commonly used approaches for overcoming the prohibitive cost of performing exact kNN queries. However, the success of these techniques largely depends on their hash functions' ability to distinguish kNN items; that is, the kNN items retrieved based on data items' hashcodes, should include as many true kNN items as possible. A widely-adopted principle for this process is to ensure that similar items are assigned to the same hashcode so that the items with the hashcodes similar to a query's hashcode are likely to be true neighbors.\nIn this work, we abandon this heavily-utilized principle and pursue the opposite direction for generating more effective hash functions for kNN tasks. That is, we aim to increase the distance between similar items in the hashcode space, instead of reducing it. Our contribution begins by providing theoretical analysis on why this revolutionary and seemingly counter-intuitive approach leads to a more accurate identification of kNN items. Our analysis is followed by a proposal for a hashing algorithm that embeds this novel principle. Our empirical studies confirm that a hashing algorithm based on this counter-intuitive idea significantly improves the efficiency and accuracy of state-of-the-art techniques.", "references": ["Presto: Distributed SQL query engine for big data. https://prestodb.io/docs/current/release/release-0.61.html.", "SnappyData. http://www.snappydata.io/.", "S. Agarwal, H. Milner, A. Kleiner, A. Talwalkar, M. Jordan, S. Madden, B. Mozafari, and I. Stoica. Knowing when you're wrong: Building fast and reliable approximate query processing systems. In SIGMOD, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2850583.2850589"}, {"title": "A Soft Computing Approach for Learning to Aggregate Rankings", "authors": ["Javier Alvaro Vargas Muñoz\n,", "Ricardo da Silva Torres\n,", "Marcos André Gonçalves"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThis paper presents an approach to combine rank aggregation techniques using a soft computing technique -- Genetic Programming -- in order to improve the results in Information Retrieval tasks. Previous work shows that by combining rank aggregation techniques in an agglomerative way, it is possible to get better results than with individual methods. However, these works either combine only a small set of lists or are performed in a completely ad-hoc way. Therefore, given a set of ranked lists and a set of rank aggregation techniques, we propose to use a supervised genetic programming approach to search combinations of them that maximize effectiveness in large search spaces. Experimental results conducted using four datasets with different properties show that our proposed approach reaches top performance in most datasets. Moreover, this cross-dataset performance is not matched by any other baseline among the many we experiment with, some being the state-of-the-art in learning-to-rank and in the supervised rank aggregation tasks. We also show that our proposed framework is very efficient, flexible, and scalable.", "references": ["M. S. Beg and N. Ahmad. Soft computing techniques for rank aggregation on the world wide web. World Wide Web, 6(1):5--22, 2003.", "J. C. Borda. Mémoire sur les élections au scrutin. Histoire de l'Académie Royale des Sciences, 1781.", "G. V. Cormack, C. L. Clarke, and S. Buettcher. Reciprocal rank fusion outperforms condorcet and individual rank learning methods. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 758--759. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806478"}, {"title": "From Collision To Exploitation: Unleashing Use-After-Free Vulnerabilities in Linux Kernel", "authors": ["Wen Xu\n,", "Juanru Li\n,", "Junliang Shu\n,", "Wenbo Yang\n,", "Tianyi Xie\n,", "Yuanyuan Zhang\n,", "Dawu Gu"], "publication": "CCS '15: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security", "abstract": "ABSTRACT\nSince vulnerabilities in Linux kernel are on the increase, attackers have turned their interests into related exploitation techniques. However, compared with numerous researches on exploiting use-after-free vulnerabilities in the user applications, few efforts studied how to exploit use-after-free vulnerabilities in Linux kernel due to the difficulties that mainly come from the uncertainty of the kernel memory layout. Without specific information leakage, attackers could only conduct a blind memory overwriting strategy trying to corrupt the critical part of the kernel, for which the success rate is negligible.\nIn this work, we present a novel memory collision strategy to exploit the use-after-free vulnerabilities in Linux kernel reliably. The insight of our exploit strategy is that a probabilistic memory collision can be constructed according to the widely deployed kernel memory reuse mechanisms, which significantly increases the success rate of the attack. Based on this insight, we present two practical memory collision attacks: An object-based attack that leverages the memory recycling mechanism of the kernel allocator to achieve freed vulnerable object covering, and a physmap-based attack that takes advantage of the overlap between the physmap and the SLAB caches to achieve a more flexible memory manipulation. Our proposed attacks are universal for various Linux kernels of different architectures and could successfully exploit systems with use-after-free vulnerabilities in kernel. Particularly, we achieve privilege escalation on various popular Android devices (kernel version>=4.3) including those with 64-bit processors by exploiting the CVE-2015-3636 use-after-free vulnerability in Linux kernel. To our knowledge, this is the first generic kernel exploit for the latest version of Android. Finally, to defend this kind of memory collision, we propose two corresponding mitigation schemes.", "references": ["Attacking the Core: Kernel Exploiting Notes. http://phrack.org/issues/64/6.html.", "CVE-2010--1807. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010--1807.", "CVE-2014--1776. http://www.cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014--1776."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810103.2813637"}, {"title": "Islands in the Stream: A Study of Item Recommendation within an Enterprise Social Stream", "authors": ["Ido Guy\n,", "Roy Levin\n,", "Tal Daniel\n,", "Ella Bolshinsky"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSocial streams allow users to receive updates from their network by syndicating social media activity. These streams have become a popular way to share and consume information both on the web and in the enterprise. With so much activity going on, filtering and personalizing the stream for individual users is a key challenge. In this work, we study the recommendation of enterprise social stream items through a user survey with 510 participants, conducted within a globally distributed organization. In the survey, participants rated their level of interest and surprise for different items from the stream and could also indicate whether they were already familiar with the item. Thus, our evaluation goes beyond the common accuracy measure and examines aspects of serendipity and novelty. We also inspect how various features of the recommended item, its author, and reader, influence its ratings. Our results shed light on the key factors that make a stream item valuable to its reader within the enterprise.", "references": ["Adamopoulos, P. & Tuzhilin, A. 2011. On unexpectedness in recommender systems: or how to expect the unexpected. RecSys '11 Workshop on Novelty and Diversity in RS, 11--18.", "Agarwal, D. et al. 2014. Activity ranking in LinkedIn feed. Proc. KDD '14, 1603--1612.", "Amitay, E., Carmel, D., Har'El, N., Ofek-Koifman, S., Soffer, A., Yogev, S., & Golbandi, N. 2009. Social search and discovery using a unified approach. Proc. HT '09, 199--208."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767746"}, {"title": "Leveraging Joint Interactions for Credibility Analysis in News Communities", "authors": ["Subhabrata Mukherjee\n,", "Gerhard Weikum"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nMedia seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more.\nThis paper presents a model to systematically analyze the different interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of \"citizen journalists\" in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized without losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3, 2003.", "K. R. Canini, B. Suh, and P. Pirolli. Finding credible information sources in social networks based on content and social structure. In PASSAT, 2011.", "C. Castillo, M. Mendoza, and B. Poblete. Information credibility on twitter. In WWW, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806537"}, {"title": "A Demonstration of Rubato DB: A Highly Scalable NewSQL Database System for OLTP and Big Data Applications", "authors": ["Li-Yan Yuan\n,", "Lengdong Wu\n,", "Jia-Huai You\n,", "Yan Chi"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nWe propose to demonstrate Rubato DB, a highly scalable NewSQL system, supporting various consistency levels from ACID to BASE for OLTP and big data applications. Rubato DB employs the staged grid architecture with a novel formula based protocol for distributed concurrency control. Our demonstration will present Rubato DB as one NewSQL database management system running on a collection of commodity servers against two of benchmark sets.\nThe demo attendees can modify the configuration of system size, fine-tune the query workload, and visualize the performance on the fly by the graphical user interface. Attendees can experiment with various system scales, and thus grasp the potential scalability of Rubato DB, whose performance, with the increase of the number of servers used, can achieve a linear growth for both OLTP application with the strong consistency properties and key-value storage applications with the weak consistency properties.", "references": ["F. Chang, J. Dean, S. Ghemawat, and etc. Bigtable: A distributed storage system for structured data. ACM Transactions on Computer Systems, 26(2):4, 2008.", "B. F. Cooper, R. Ramakrishnan, U. Srivastava, A. Silberstein, P. Bohannon, H.-A. Jacobsen, N. Puz, D. Weaver, and R. Yerneni. Pnuts: Yahoo!'s hosted data serving platform. Proceedings of the VLDB Endowment, 1(2):1277--1288, 2008.", "B. F. Cooper, A. Silberstein, E. Tam, R. Ramakrishnan, and R. Sears. Benchmarking cloud serving systems with ycsb. In Proc. the 1st ACM Symposium on Cloud computing, pages 143--154. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2735380"}, {"title": "Small-Scale Incident Detection based on Microposts", "authors": ["Axel Schulz\n,", "Benedikt Schmidt\n,", "Thorsten Strufe"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nDetecting large-scale incidents based on microposts has successfully been proposed and shown. However, the detection of small-scale incidents was not satisfyingly possible so far, though the information that is shared during such local events could improve the situational awareness of both citizens and decision makers alike.\nIn this paper, we propose an approach for small-scale incident detection based on spatial-temporal-type clustering. In contrast to existing work, (1) we employ three distinct properties that define an incident, (2) we use a hybrid approach to reduce the computational overhead, and (3) we extract generalized features to increase robustness towards previously unseen data. Our evaluation in the domain of emergency first response shows that our approach identifies 32.14% of all real world incidents recorded for the city of Seattle just using on tweets. This result greatly outperforms the state of the art, which only detects about 6% of the real-world incidents. Also, a precision of 77% shows that we efficiently discard irrelevant information.", "references": ["Agarwal, P., Vaithiyanathan, R., Sharma, S., and Shroff, G. Catching the long-tail: Extracting local news events from twitter. In Proc. ICWSM 2012 (2012), AAAI Press.", "Atefeh, F., and Khreich, W. A survey of techniques for event detection in twitter. Computational Intelligence (2013).", "Becker, H. Identification and Characterization of Events in Social Media. PhD thesis, Columbia University, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2791038"}, {"title": "Towards content-based publish/subscribe for distributed social networks", "authors": ["Christos Tryfonopoulos\n,", "Paraskevi Raftopoulou\n,", "Vinay Setty\n,", "Argiris Xiros"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nOver the last few years a number of distributed social networks with data management capabilities have been introduced both by academia and industry. However, none of these efforts have so far focused on supporting content-based publish/subscribe functionality in a distributed social networking environment. In this work we present a social networking architecture that offers content-based pub/sub functionality -in addition to the usual social interaction and data management tasks- in distributed social networks, outline the associated distributed protocols, and hint on coping with diversification in pub/sub for such scenarios. To the best of our knowledge, our system is the first of its kind to offer such an unique combination of features in a decentralised setting. Finally, we highlight the feasibility of the proposal by means of experimentation with real social networking data and an implementation of a prototype system.", "references": ["V. Dang and W. B. Croft. Diversity by proportionality: an election-based approach to search result diversification. In SIGIR, 2012.", "M. Drosou, K. Stefanidis, and E. Pitoura. Preference-aware publish/subscribe delivery with diversity. In DEBS, 2009.", "K. Graffi, C. Gross, P. Mukherjee, A. Kovacevic, and R. Steinmetz. LifeSocial.KOM: A P2P-Based Platform for Secure Online Social Networks. In P2P, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2776770"}, {"title": "Session details: Maps & Search", "authors": ["Gonzalo Ramos"], "publication": "MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3261095"}, {"title": "When temporal expressions help to detect vital documents related to an entity", "authors": ["Rafik Abbes\n,", "Karen Pinel-Sauvagnat\n,", "Nathalie Hernandez\n,", "Mohand Boughanem"], "publication": "ACM SIGAPP Applied Computing Review", "abstract": "Abstract\nIn this paper we aim at filtering documents containing timely relevant information about an entity (e.g., a person, a place, an organization) from a document stream. These documents that we call vital documents provide relevant and fresh information about the entity. The approach we propose leverages the temporal information reflected by the temporal expressions in the document in order to infer its vitality. Experiments carried out on the 2013 TREC Knowledge Base Acceleration (KBA) collection show the effectiveness of our approach compared to state-of-the-art ones.", "references": ["R. Abbes, K. Pinel-Sauvagnat, N. Hernandez, and M. Boughanem. Accelerating the update of knowledge base instances by detecting vital information from a document stream. In 2015 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT), Singapore, December 06-09, 2015, 2015. (to appear).", "K. Balog and H. Ramampiaro. Cumulative citation recommendation: Classification vs. ranking. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '13, pages 941--944, New York, NY, USA, 2013. ACM.", "K. Balog, H. Ramampiaro, N. Takhirov, and K. Nørvåg. Multi-step classification approaches to cumulative citation recommendation. In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval, OAIR '13, pages 121--128, Paris, France, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835260.2835263"}, {"title": "Discovering Experts across Multiple Domains", "authors": ["Aditya Pal"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nResearchers have focused on finding experts in individual domains, such as emails, forums, question answering, blogs, and microblogs. In this paper, we propose an algorithm for finding experts across these different domains. To do this, we propose an expertise framework that aims at extracting key expertise features and building an unified scoring model based on SVM ranking algorithm. We evaluate our model on a real World dataset and show that it is significantly better than the prior state-of-art.", "references": ["K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. FTIR, 6(2--3):127--256, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 2003.", "W. B. Cavnar and J. M. Trenkle. N-gram-based text categorization. In SDAIR, 1994."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767774"}, {"title": "Hierarchical Topic Models for Language-based Video Hyperlinking", "authors": ["Anca-Roxana Simon\n,", "Rémi Bois\n,", "Guillaume Gravier\n,", "Pascale Sébillot\n,", "Emmanuel Morin\n,", "Sien Moens"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nWe investigate video hyperlinking based on speech transcripts, leveraging a hierarchical topical structure to address two essential aspects of hyperlinking, namely, serendipity control and link justification. We propose and compare different approaches exploiting a hierarchy of topic models as an intermediate representation to compare the transcripts of video segments. These hierarchical representations offer a basis to characterize the hyperlinks, thanks to the knowledge of the topics who contributed to the creation of the links, and to control serendipity by choosing to give more weights to either general or specific topics. Experiments are performed on BBC videos from the Search and Hyperlinking task at MediaEval. Link precisions similar to those of direct text comparison are achieved however exhibiting different targets along with a potential control of serendipity.", "references": ["C. Bhatt, N. Pappas, M. Habibi, and A. Popescu-Belis. Idiap at MediaEval 2013: Search and hyperlinking task. In Working Notes MediaEval Workshop, 2013.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, 2003.", "T. De Nies, W. De Neve, E. Mannens, and R. Van de Walle. Ghent University-iMinds at MediaEval 2013: an unsupervised named entity-based similarity measure for search and hyperlinking. In Working Notes MediaEval Workshop, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814642"}, {"title": "Information Retrieval as Card Playing: A Formal Model for Optimizing Interactive Retrieval Interface", "authors": ["Yinan Zhang\n,", "Chengxiang Zhai"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe propose a novel formal model for optimizing interactive information retrieval interfaces. To model interactive retrieval in a general way, we frame the task of an interactive retrieval system as to choose a sequence of interface cards to present to the user. At each interaction lap, the system's goal is to choose an interface card that can maximize the expected gain of relevant information for the user while minimizing the effort of the user with consideration of the user's action model and any desired constraints on the interface card. We show that such a formal interface card model can not only cover the Probability Ranking Principle for Interactive Information Retrieval as a special case by making multiple simplification assumptions, but also be used to derive a novel formal interface model for adaptively optimizing navigational interfaces in a retrieval system. Experimental results show that the proposed model is effective in automatically generating adaptive navigational interfaces, which outperform the baseline pre-designed static interfaces.", "references": ["G. Amati and C. J. Van Rijsbergen. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Trans. Inf. Syst., 20(4):357--389, Oct. 2002.", "L. Azzopardi. Modelling interaction with economic models of search. In SIGIR '14, pages 3--12, 2014.", "S. Basu Roy, H. Wang, G. Das, U. Nambiar, and M. Mohania. Minimum-effort driven dynamic faceted search in structured databases. In CIKM '08, pages 13--22, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767761"}, {"title": "Semantic Entities", "authors": ["Christophe Van Gysel\n,", "Maarten de Rijke\n,", "Marcel Worring"], "publication": "ESAIR '15: Proceedings of the Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval", "abstract": "ABSTRACT\nEntity retrieval has seen a lot of interest from the research community over the past decade. Ten years ago, the expertise retrieval task gained popularity in the research community during the TREC Enterprise Track [10]. It has remained relevant ever since, while broadening to social media, to tracking the dynamics of expertise [1-5, 8, 11], and, more generally, to a range of entity retrieval tasks.\nIn the talk, which will be given by the second author, we will point out that existing methods to entity or expert retrieval fail to address key challenges: (1) Queries and expert documents use different representations to describe the same concepts [6, 7]. Term mismatches between entities and experts [7] occur due to the inability of widely used maximum-likelihood language models to make use of semantic similarities between words [9]. (2) As the amount of available data increases, the need for more powerful approaches with greater learning capabilities than smoothed maximum-likelihood language models is obvious [13]. (3) Supervised methods for entity or expertise retrieval [5, 8] were introduced at the turn of the last decade. However, the acceleration of data availability has the major disadvantage that, in the case of supervised methods, manual annotation efforts need to sustain a similar order of growth. This calls for the further development of unsupervised methods. (4) According to some entity or expertise retrieval methods, a language model is constructed for every document in the collection. These methods lack efficient query capabilities for large document collections, as each query term needs to be matched against every document [2].\nIn the talk we will discuss a recently proposed solution [12] that has a strong emphasis on unsupervised model construction, efficient query capabilities and, most importantly, semantic matching between query terms and candidate entities. We show that the proposed approach improves retrieval performance compared to generative language models mainly due to its ability to perform semantic matching [7]. The proposed method does not require any annotations or supervised relevance judgments and is able to learn from raw textual evidence and document-candidate associations alone.\nThe purpose of the proposal is to provide insight in how we avoid explicit annotations and feature engineering and still obtain semantically meaningful retrieval results. In the talk we will provide a comparative error analysis between the proposed semantic entity retrieval model and traditional generative language models that perform exact matching, which yields important insights in the relative strengths of semantic matching and exact matching for the expert retrieval task in particular and entity retrieval in general.\nWe will also discuss extensions of the proposed model that are meant to deal with scalability and dynamic aspects of entity and expert retrieval.", "references": ["K. Balog, L. Azzopardi, and M. de Rijke. A language modeling framework for expert finding. IPM, 45: 1--19, 2009.", "K. Balog, Y. Fang, M. de Rijke, P. Serdyukov, and L. Si. Expertise retrieval. Found. & Tr. in Information Retrieval, 6 (2-3): 127--256, 2012.", "R. Berendsen, M. de Rijke, K. Balog, T. Bogers, and A. van den Bosch. On the assessment of expertise profiles. JASIST, 64 (10): 2024--2044, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2810133.2810139"}, {"title": "A PaaS for composite analytics solutions", "authors": ["Paula Austel\n,", "Han Chen\n,", "Parijat Dube\n,", "Thomas Mikalsen\n,", "Isabelle Rouvellou\n,", "Upendra Sharma\n,", "Ignacio Silva-Lepe\n,", "Revathi Subramanian\n,"], "publication": "CF '15: Proceedings of the 12th ACM International Conference on Computing Frontiers", "abstract": "ABSTRACT\nIn their pursuit of market competitiveness and sustainable top line growth, enterprises are increasingly turning to sophisticated analytics solutions to derive insights and value from the deluge of data that are being generated from all sources. Leading practitioners of Big Data analytics have already moved past the stage of using single analytics modalities on siloed data sources. They are starting to create composite analytics solutions that take advantage of multiple analytics programming models and are also integrating them into their existing enterprise IT systems. At the same time, the CIOs have wholeheartedly embraced cloud computing as a means of reducing the capital and operational cost of their IT systems and streamlining their DevOps processes. Platform-as-a-Service (PaaS) as a cloud computing consumption model has seen wide acceptance by developers and IT administrators. Although there are PaaS platforms for individual workload types involved in these advanced composite analytics solutions, the composition aspect is not addressed by any of these individual PaaS platforms. Further, there is no lifecycle management support for the solution as a single logical entity. This paper argues for the need of a true PaaS for composite analytics solutions in order to accelerate their adoption by the industry and foster the creation of a healthy ecosystem. We present the design and prototype implementation of such a platform and our early experience of using it to deploy a Telco Fraud Detection solution.", "references": ["Apache Spark. https://spark.apache.org/.", "Cloud Foundry Community. http://www.cloudfoundry.org/index.html.", "Deploying with Application Manifests. http://docs.cloudfoundry.org/devguide/deploy-apps/manifest.html."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2742854.2747281"}, {"title": "Using rhetorical structure in sentiment analysis", "authors": ["Alexander Hogenboom\n,", "Flavius Frasincar\n,", "Franciska de Jong\n,", "Uzay Kaymak"], "publication": "Communications of the ACM", "abstract": "Abstract\nA deep, fine-grain analysis of rhetorical structure highlights crucial sentiment-carrying text segments.", "references": ["Baccianella, S., Esuli, A., and Sebastiani, F. SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proceedings of the Seventh Conference on International Language Resources and Evaluation (Valletta, Malta, May 19--21). European Language Resources Association, Paris, France, 2010, 2200--2204.", "Bal, D., Bal, M., van Bunningen, A., Hogenboom, A., Hogenboom, F., and Frasincar, F. Sentiment analysis with a multilingual pipeline. In Proceedings of the 12th International Conference on Web Information System Engineering (Sydney, Australia, Oct. 12--14) Volume 6997 of Lecture Notes in Computer Science. Springer, Berlin, Germany, 2011, 129--142.", "Baldridge, J. and Morton, T. OpenNLP, 2004; http://opennlp.sourceforge.net/"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2699418"}, {"title": "PushTrust: An Efficient Recommendation Algorithm by Leveraging Trust and Distrust Relations", "authors": ["Rana Forsati\n,", "Iman Barjasteh\n,", "Farzan Masrour\n,", "Abdol-Hossein Esfahanian\n,", "Hayder Radha"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThe significance of social-enhanced recommender systems is increasing, along with its practicality, as online reviews, ratings, friendship links, and follower relationships are increasingly becoming available. In recent years, there has been an upsurge of interest in exploiting social information, such as trust and distrust relations in recommendation algorithms. The goal is to improve the quality of suggestions and mitigate the data sparsity and the cold-start users problems in existing systems. In this paper, we introduce a general collaborative social ranking model to rank the latent features of users extracted from rating data based on the social context of users. In contrast to existing social regularization methods, the proposed framework is able to simultaneously leverage trust, distrust, and neutral relations, and has a linear dependency on the social network size. By integrating the ranking based social regularization idea into the matrix factorization algorithm, we propose a novel recommendation algorithm, dubbed PushTrust. Our experiments on the Epinions dataset demonstrate that collaboratively ranking the latent features of users by exploiting trust and distrust relations leads to a substantial increase in performance, and to effectively deal with cold-start users problem.", "references": ["M. Kim and J. Leskovec, \"The network completion problem: Inferring missing nodes and edges in networks.\" in SDM. SIAM, 2011, pp. 47--58.", "A. Annibale and A. Coolen, \"What you see is not what you get: how sampling affects macroscopic features of biological networks,\" Interface Focus, vol. 1, no. 6, pp. 836--856, 2011.", "M. Papagelis, G. Das, and N. Koudas, \"Sampling online social networks,\" Knowledge and Data Engineering, IEEE Transactions on, vol. 25, no. 3, pp. 662--676, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800198"}, {"title": "PathS: Enhancing Geographical Maps with Environmental Sensed Data", "authors": ["Armir Bujari\n,", "Matteo Ciman\n,", "Ombretta Gaggi\n,", "Gustavo Marfia\n,", "Claudio Enrico Palazzi"], "publication": "MobileHealth '15: Proceedings of the 2015 Workshop on Pervasive Wireless Healthcare", "abstract": "ABSTRACT\nThe widespread adoption of mobile technology has opened the door to a new era for the public health sector. The ability to collect, share and access community health related data are key factors that have made mobile health an appealing addon to medicine practitioners and researchers. Mobile sensing and wireless communications can be exploited to create new information and services that could help prevent health risks, benefiting the community as a whole. As a proof of concept, we have developed an augmented reality application offering an enhanced pedestrian route navigation system, while at the same time gathering quality data through the devices. Thanks to this application we are able to enrich geographical maps on the web with historical data about brightness and noise levels, and to provide pedestrians with an improved navigation.", "references": ["E. Agapie, G. Chen, D. Houston, and E. H. et. al. Seeing our signals: Combining location traces and web-based models for personal discovery. In Proceedings of the Workshop on Mobile Computing Systems and Applications, pages 6--10, New York, NY, USA, 2008. ACM.", "F. Aiolli, M. Ciman, M. Donini, and O. Gaggi. A serious game to persuade people to use stairs. In Proceedings of Persuasive 2014, May 2014.", "A. Bujari. A survey of opportunistic data gathering and dissemination techniques. In Proceedings of IEEE International Conference on Computer Communications and Networks (ICCCN), pages 1--6, July 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757290.2757292"}, {"title": "Session details: Main Track - Transparency", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252436"}, {"title": "Inferring Latent Attributes of an Indian Twitter User using Celebrities and Class Influencers", "authors": ["Puneet Singh Ludu"], "publication": "SIdEWayS '15: Proceedings of the 1st ACM Workshop on Social Media World Sensors", "abstract": "ABSTRACT\nIn this paper we classify a user into three categories: \"Gender\", \"Age\" and \"Political Affiliation\" with an application to Indian Twitter users. Our approach automatically predicts these attributes by leveraging observable information such as the tweet behavior, linguistic content of the user's Twitter feed and the celebrities followed by the user.\nThis paper would also use a novel feature that we would define in this paper as \"class influencers\". Class influencers are the Twitter users which influence a particular class so much that, they themselves can be used as a discriminating feature.\nOur approach first extracts the linguistic content based features using LIWC dictionary. Then, we derive features like smiley types, smiley count, tweet frequency, night-time tweet frequency, etc. We have also derived celebrity based feature: age, genre, gender (using Wikipedia and Freebase) of the celebrities a user is following. Finally, we refine the results using class influencers. Results show that rich linguistic features combined with popular neighborhood and influencers prove valuables and promising for additional user classification needs.", "references": ["F. Al Zamal, W. Liu, and D. Ruths. Homophily and latent attribute inference: Inferring latent attributes of twitter users from neighbors. In ICWSM, 2012.", "S. Argamon, S. Dhawle, M. Koppel, and J. Pennebaker. Lexical predictors of personality type. 2005.", "D. Bamman, J. Eisenstein, and T. Schnoebelen. Gender identity and lexical variation in social media. Journal of Sociolinguistics, 18(2):135--160, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806655.2806657"}, {"title": "Batch matching of conjunctive triple patterns over linked data streams in the internet of things", "authors": ["Yongrui Qin\n,", "Quan Z. Sheng\n,", "Nickolas J. G. Falkner\n,", "Ali Shemshadi\n,", "Edward Curry"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nThe Internet of Things (IoT) envisions smart objects collecting and sharing data at a global scale via the Internet. One challenging issue is how to disseminate data to relevant consumers efficiently. This paper leverages semantic technologies, such as Linked Data, which can facilitate machine-to-machine (M2M) communications to build an efficient information dissemination system for semantic IoT. The system integrates Linked Data streams generated from various data collectors and disseminates matched data to relevant data consumers based on conjunctive triple pattern queries registered in the system by the consumers. We also design a new data structure, CTP-automata, to meet the high performance needs of Linked Data dissemination. We evaluate our system using a real-world dataset generated from a Smart Building Project. With CTP-automata, the proposed system can disseminate Linked Data at a speed of an order of magnitude faster than the existing approach with thousands of registered conjunctive queries.", "references": ["D. Anicic, P. Fodor, S. Rudolph, and N. Stojanovic. EP-SPARQL: A Unified Language for Event Processing and Stream Reasoning. In WWW, pages 635--644, 2011.", "P. M. Barnaghi, A. P. Sheth, and C. A. Henson. From Data to Actionable Knowledge: Big Data Challenges in the Web of Things. IEEE Intelligent Systems, 28(6):6--11, 2013.", "P. M. Barnaghi, W. Wang, C. A. Henson, and K. Taylor. Semantics for the Internet of Things: Early Progress and Back to the Future. Int. J. Semantic Web Inf. Syst., 8(1):1--21, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791364"}, {"title": "2nd Workshop on Recommendation Systems for Television and Online Video (RecSysTV 2015)", "authors": ["Jan Neumann\n,", "Danny Bickson\n,", "Hassan Sayyadi\n,", "Roberto Turrin\n,", "John Hannon"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nFor many households the television is the central entertainment hub in their home, and the average TV viewer spends about half of their leisure time in front of a TV. At any given moment, a costumer has hundreds to thousands of entertainment choices available, which makes some sort of automatic, personalized recommendations desirable to help consumers deal with the often overwhelming number of choices they face. The 2nd Workshop on Recommendation Systems for Television and Online Video aims to offer a place to present and discuss the latest academic and industrial research on recommendation systems for this challenging and exciting application domain", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2798717"}, {"title": "Reference Software Architecture for Government Information Systems", "authors": ["Mauricio Serrano\n,", "Milene Serrano\n,", "Andre Cruz Cavalcante"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn this paper, we describe a Reference Software Architecture for a Brazilian Public Entity based on a software design paradigm, called Convention over Configuration, which tries to decrease the decisions made by developers, gaining simplicity, but not necessarily losing flexibility or productivity. Moreover, the proposed architecture deals with auditing, tracing, logging, monitoring and other relevant issues for information systems in the Brazilian government scope. Our Reference Software Architecture has been applying into two information systems' development at a Brazilian Public Entity. One of them is the most important information system at this Entity, nowadays.", "references": ["ePING. Acesso: http://governoeletronico.gov.br/acoes-e-projetos/e-ping-padroes-de-interoperabilidade (Abril 2015).", "Struts. Acesso: https://struts.apache.org/ (Abril 2015).", "Miller, J. (2009). Design For Convention Over Configuration. Acesso: http://msdn.microsoft.com/en-us/magazine/dd419655.aspx (Abril 2015)."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814072"}, {"title": "Graph Search and Beyond: SIGIR 2015 Workshop Summary", "authors": ["Omar Alonso\n,", "Marti A. Hearst\n,", "Jaap Kamps"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nModern Web data is highly structured in terms of entities and relations from large knowledge resources, geo-temporal references and social network structure, resulting in a massive multidimensional graph. This graph essentially unifies both the searcher and the information resources that played a fundamentally different role in traditional IR, and \"Graph Search\" offers major new ways to access relevant information. Graph search affects both query formulation (complex queries about entities and relations building on the searcher's context) as well as result exploration and discovery (slicing and dicing the information using the graph structure) in a completely personalized way. This new graph based approach introduces great opportunities, but also great challenges, in terms of data quality and data integration, user interface design, and privacy. We view the notion of \"graph search\" as searching information from your personal point of view (you are the query) over a highly structured and curated information space. This goes beyond the traditional two-term queries and ten blue links results that users are familiar with, requiring a highly interactive session covering both query formulation and result exploration. The workshop attracted a range of researchers working on this and related topics, and made concrete progress working together on one of the greatest challenges in the years to come.", "references": ["- N. V. Spirin, J. He, M. Develin, K. G. Karahalios, and M. Boucher. People search within an online social network: Large scale analysis of facebook graph search query logs. In CIKM'14, pages 1009--1018. ACM, 2014. URL: http://doi.acm.org/10.1145/2661829.2661967."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767855"}, {"title": "On the Cost of Extracting Proximity Features for Term-Dependency Models", "authors": ["Xiaolu Lu\n,", "Alistair Moffat\n,", "J. Shane Culpepper"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nSophisticated ranking mechanisms make use of term dependency features in order to compute similarity scores for documents. These features often include exact phrase occurrences, and term proximity estimates. Both cases build on the intuition that if multiple query terms appear near each other, the document is more likely to be relevant to the query. In this paper we examine the processes used to compute these statistics. Two distinct input structures can be used -- inverted files and direct files. Inverted files must store the position offsets of the terms, while \"direct\" files represent each document as a sequence of preprocessed term identifiers. Based on these two input modalities, a number of algorithms can be used to compute proximity statistics. Until now, these algorithms have been described in terms of a single set of query terms. But similarity computations such as the Full Dependency Model compute proximity statistics for a collection of related term sets. We present a new approach in which such collections are processed holistically in time that is much less than would be the case if each subquery were to be evaluated independently. The benefits of the new method are demonstrated by a comprehensive experimental study.", "references": ["N. Asadi and J. Lin. Document vector representations for feature extraction in multi-stage document ranking. pInf. Retr., 16 (6): 747--768, 2013.", "M. Bendersky, D. Metzler, and W. B. Croft. Parameterized concept weighting in verbose queries. In Proc. SIGIR, pages 605--614, 2011.", "A. Broschart and R. Schenkel. High-performance processing of text queries with tunable pruned term and term pair indexes. ACM Trans. Information Systems, 30 (1): 1--32, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806467"}, {"title": "Stale view cleaning: getting fresh answers from stale materialized views", "authors": ["Sanjay Krishnan\n,", "Jiannan Wang\n,", "Michael J. Franklin\n,", "Ken Goldberg\n,", "Tim Kraska"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMaterialized views (MVs), stored pre-computed results, are widely used to facilitate fast queries on large datasets. When new records arrive at a high rate, it is infeasible to continuously update (maintain) MVs and a common solution is to defer maintenance by batching updates together. Between batches the MVs become increasingly stale with incorrect, missing, and superfluous rows leading to increasingly inaccurate query results. We propose Stale View Cleaning (SVC) which addresses this problem from a data cleaning perspective. In SVC, we efficiently clean a sample of rows from a stale MV, and use the clean sample to estimate aggregate query results. While approximate, the estimated query results reflect the most recent data. As sampling can be sensitive to long-tailed distributions, we further explore an outlier indexing technique to give increased accuracy when the data distributions are skewed. SVC complements existing deferred maintenance approaches by giving accurate and bounded query answers between maintenance. We evaluate our method on a generated dataset from the TPC-D benchmark and a real video distribution application. Experiments confirm our theoretical results: (1) cleaning an MV sample is more efficient than full view maintenance, (2) the estimated results are more accurate than using the stale MV, and (3) SVC is applicable for a wide variety of MVs.", "references": ["Conviva. http://www.conviva.com/.", "S. Agarwal, H. Milner, A. Kleiner, A. Talwalkar, M. I. Jordan, S. Madden, B. Mozafari, and I. Stoica. Knowing when you're wrong: building fast and reliable approximate query processing systems. In SIGMOD Conference, pages 481--492, 2014.", "S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Madden, and I. Stoica. Blinkdb: queries with bounded errors and bounded response times on very large data. In EuroSys, pages 29--42, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824037"}, {"title": "Towards a Game-Theoretic Framework for Information Retrieval", "authors": ["ChengXiang Zhai"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe task of information retrieval (IR) has traditionally been defined as to rank a collection of documents in response to a query. While this definition has enabled most research progress in IR so far, it does not model accurately the actual retrieval task in a real IR application, where users tend to be engaged in an interactive process with multipe queries, and optimizing the overall performance of an IR system on an entire search session is far more important than its performance on an individual query. In this talk, I will present a new game-theoretic formulation of the IR problem where the key idea is to model information retrieval as a process of a search engine and a user playing a cooperative game, with a shared goal of satisfying the user's information need (or more generally helping the user complete a task) while minimizing the user's effort and the resource overhead on the retrieval system. Such a game-theoretic framework offers several benefits. First, it naturally suggests optimization of the overall utility of an interactive retrieval system over a whole search session, thus breaking the limitation of the traditional formulation that optimizes ranking of documents for a single query. Second, it models the interactions between users and a search engine, and thus can optimize the collaboration of a search engine and its users, maximizing the \"combined intelligence\" of a system and users. Finally, it can serve as a unified framework for optimizing both interactive information retrieval and active relevance judgment acquisition through crowdsourcing. I will discuss how the new framework can not only cover several emerging directions in current IR research as special cases, but also open up many interesting new research directions in IR.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767853"}, {"title": "Building the virtual product with big models", "authors": ["Barclay Brown\n,", "Saurabh Mittal\n,", "Andreas Tolk\n,", "Sayyidul Arafat"], "publication": "SummerSim '15: Proceedings of the Conference on Summer Computer Simulation", "abstract": "ABSTRACT\nModels have demonstrated proven benefits in specific aspects of the engineering process. Mechanical models, performance models, algorithmic models, systems engineering architecture models and others have proven useful and even perhaps indispensable. Models provide value at different points in the lifecycle with some supporting design and architecture while others simulate and evaluate aspects of the new product or system.\nThe panel and paper will explore the question, \"what will be needed to build a virtual product using comprehensive, multi-domain (big) models?\" What new processes, concepts and frameworks must be embraced and what old ones must be discarded?", "references": ["Mittal, S., Model Engineering for Cyber Complex Adaptive Systems, European Modeling and Simulation Symposium, France. 2014.", "Zeigler, B. P., Praehofer, H. and Kim, T. G., Theory of Modeling and Simulation: Integrating Discrete Event and Continuous Complex Dynamic Systems. New York, NY: Academic Press. 2000.", "Mittal, S., Zeigler, B. P., Martin, J. L. R., Sahin, F., Jamshidi, M., Modeling and Simulation for System of Systems Engineering\", in M. Jamshidi (ed.) System of Systems Engineering: Innovations for 21st Century, Wiley. 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2874916.2874987"}, {"title": "A Random Walk Model for Optimization of Search Impact in Web Frontier Ranking", "authors": ["Giang Tran\n,", "Ata Turk\n,", "B. Barla Cambazoglu\n,", "Wolfgang Nejdl"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLarge-scale web search engines need to crawl the Web continuously to discover and download newly created web content. The speed at which the new content is discovered and the quality of the discovered content can have a big impact on the coverage and quality of the results provided by the search engine. In this paper, we propose a search-centric solution to the problem of prioritizing the pages in the frontier of a crawler for download. Our approach essentially orders the web pages in the frontier through a random walk model that takes into account the pages' potential impact on user-perceived search quality. In addition, we propose a link graph enrichment technique that extends this solution. Finally, we explore a machine learning approach that combines different frontier prioritization approaches. We conduct experiments using two very large, real-life web datasets to observe various search quality metrics. Comparisons with several baseline techniques indicate that the proposed approaches have the potential to improve the user-perceived quality of web search results considerably.", "references": ["S. Abiteboul, M. Preda, and G. Cobena. Adaptive on-line page importance computation. In Proc. 12th Int'l Conf. World Wide Web, pages 280--290, 2003.", "E. Adar, J. Teevan, S. T. Dumais, and J. L. Elsas. The Web changes everything: Understanding the dynamics of web content. In Proc. 2nd ACM Int'l Conf. Web Search and Data Mining, pages 282--291, 2009.", "L. Backstrom and J. Leskovec. Supervised random walks: Predicting and recommending links in social networks. In Proc. 4th ACM Int'l Conf. Web Search and Data Mining, pages 635--644, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767737"}, {"title": "TeMex: The Web Template Extractor", "authors": ["Julián Alarte\n,", "David Insa\n,", "Josep Silva\n,", "Salvador Tamarit"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper presents and describes TeMex, a site-level web template extractor. TeMex is fully automatic, and it can work with online webpages without any preprocessing stage (no information about the template or the associated webpages is needed) and, more importantly, it does not need a predefined set of webpages to perform the analysis. TeMex only needs a URL. Contrarily to previous approaches, it includes a mechanism to identify webpage candidates that share the same template. This mechanism increases both recall and precision, and it also reduces the amount of webpages loaded and processed. We describe the tool and its internal architecture, and we present the results of its empirical evaluation.", "references": ["Overlay extension. Available from URL: https://developer.mozilla.org/en-US/Add-ons/Overlay_Extensions, 2005.", "J. Alarte, D. Insa, J. Silva, and S. Tamarit. Automatic Detection of Webpages that Share the Same Web Template. In M. H. ter Beek and A. Ravara, editors, Proceedings of the 10th International Workshop on Automated Specification and Verification of Web Systems (WWV 14), volume 163 of Electronic Proceedings in Theoretical Computer Science, pages 2--15. Open Publishing Association, July 2014.", "J. Alarte, D. Insa, J. Silva, and S. Tamarit. A Benchmark Suite for Template Detection and Content Extraction. CoRR, abs/1409.6182, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742835"}, {"title": "Fast Mining Frequent Patterns with Secondary Memory", "authors": ["Kawuu W. Lin\n,", "Sheng-Hao Chung\n,", "Sheng-Shiung Huang\n,", "Chun-Cheng Lin"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nData mining technology has been widely studied and applied in recent years. Frequent pattern mining is one important technical field of such research. The frequent pattern mining technique is popular not only in academia but also in the business community. With advances in technology, databases have become so large that data mining is impossible because of memory restrictions. In this study, we propose a novel algorithm called Hybrid Mine (H-Mine) to help improve this situation. H-Mine saves a part of the information that is not stored in the memory, and through the use of mixed hard disk and memory mining we are able to complete data mining with limited memory. The results of empirical evaluation under various simulation conditions show that H-Mine delivers excellent performance in terms of execution efficiency and scalability.", "references": ["Agrawal, R. and Srikant, R. 1994. Fast algorithms for mining association rules. Proceedings of the 20th International Conference on Very Large Data Bases. 1215, 487--499.", "Han, J., Pei, J. and Yin, Y. 2000. Mining frequent patterns without candidate generation. In Proc. of the ACM SIGMOD Int. Conf. on Management of Data, 1--12.", "Qiu, Y., Lan, Y.-J. and Xie, Q.-S. 2004. An improved algorithm of mining from FP-tree. Proceedings of the Third International Conference on Machine Learning and Cybernetics, 26--29."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818903"}, {"title": "Business Analytics in Context: Evaluating New Curricular Modules in an Undergraduate Statistics Course", "authors": ["Wingyan Chung"], "publication": "CIC '15: Proceedings of The 2015 NSF Workshop on Curricular Development for Computing in Context", "abstract": "ABSTRACT\nDespite the needs for developing next-generation business analytics professionals, there is a severe lack of curricular modules and materials that emphasize context-specific learning of analytics. In this research, we evaluated a set of new curricular modules developed in the context of intelligence and security informatics (ISI). Our modules use an active learning pedagogy, business issues in the context of ISI, and realistic characters and stories to engage students in active learning of analytics concepts and skills. Findings from the study that compared two groups of students (control vs. treatment groups) show a statistically significant difference in students' average performance in homework assignments. Students who learned the subject using the new contextual curricular modules were found to achieve significantly higher average scores in homework assignments than students who learned the subject through the traditional method. The findings are very encouraging and show promise on using the new curricular modules in the teaching of foundation analytics courses.", "references": ["Bebell, D. and O'Dwyer, L.M., 2010. Educational Outcomes and Research from 1:1 Computing Settings. Journal of Technology, Learning, and Assessment.", "Beck, R., Carr, E., Chung, W., Fox, E., and Nass, C., 2013. Computing in Context. In Proceedings of the 44th ACM Technical Symposium on Computer Science Education ACM Press, Denver, CO.", "Bell, B.S. and Kozlowski, S.W.J., 2008. Active Learning: Effects of Core Training Design Elements on Self-Regulatory Processes, Learning, and Adaptability. Journal of Applied Psychology, 296--316."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757218.2757224"}, {"title": "Health literacy and internet- and mobile app-based health services: a systematic review of the literature", "authors": ["Henna Kim\n,", "Bo Xie"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nAs information and communication technologies (ICTs) are increasingly used to support and deliver health care, access to Internet-based health services is enabling consumers to play an active role in their own health care. Today, this requires consumers to have a certain degree of health literacy within the context of e-health. To understand the extent to which existing studies have addressed health literacy within the context of Internet-based services, we conducted a systematic review of the literature. We performed four rounds of selection to identify relevant publications: database selection, keyword search, screening titles and abstracts, and screening the full text. This process produced a final sample of 42 publications. The findings from our review provide insights into how health literacy has been, and should be, addressed in the e-health era.", "references": ["Berkman, N. D., Sheridan, S. L., Donahue, K. E., Halpern, D. J., & Crotty, K. (2011). Low health literacy and health outcomes: An updated systematic review. Annals of Internal Medicine, 155(2), 97--107.", "Cutilli, C. C., & Bennett, I. M. (2009). Understanding the Health Literacy of America results of the National Assessment of Adult Literacy. National Association of Orthopaedic Nurses, 28(1), 27--34.", "Demiris, G., Afrin, L. B., Speedie, S., Courtney, K. L., Sondhi, M., Vimarlund, V., et al. (2008). Patient-centered applications: Use of information technology to promote disease management and wellness. JAMIA, 15(1), 8--13."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857145"}, {"title": "Accessible on-line graphics", "authors": ["Anuradha Madugalla"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nToday's Internet contains a huge amount of resources and most of these resources include graphics. However, blind users fail to take the maximum advantage of these resources due to limitations in technology. Their devices (screen readers, voice synthesizers etc.) can only read textual content and fail miserably where graphics are involved. Therefore a robust method to help blind users understand on-line graphics would be of great benefit to them.", "references": ["L. Bártek, R. Ošlejšek, and T. Pitner. Is accessibility an issue in the knowledge society? modern web applications in the light of accessibility. In Organizational, Business, and Technological Aspects of the Knowledge Society, pages 359--364. Springer, 2010.", "L.-P. de las Heras, S. Ahmed, M. Liwicki, E. Valveny, and G. Sánchez. Statistical segmentation and structural recognition for floor plan interpretation. International Journal on Document Analysis and Recognition (IJDAR), pages 1--17, 2013.", "Z. B. Fredj and D. A. Duce. Grassml: Accessible smart schematic diagrams for all. In Proceedings of the 2006 International Cross-disciplinary Workshop on Web Accessibility (W4A), pages 57--60, NY, USA, 2006. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746672"}, {"title": "Rise of the Indoor Crowd: Reconstruction of Building Interior View via Mobile Crowdsourcing", "authors": ["Si Chen\n,", "Muyuan Li\n,", "Kui Ren\n,", "Xinwen Fu\n,", "Chunming Qiao"], "publication": "SenSys '15: Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems", "abstract": "ABSTRACT\nCrowdsourcing is a technology with the potential to revolutionize large-scale data gathering in an extremely cost-effective manner. It provides an unprecedented means of collecting data from the physical world, particularly through the use of modern smartphones, which are equipped with high-resolution cameras and various micro-electrical sensors. In this paper, we address the critical task of reconstructing the indoor interior view of a building from crowdsourced data. We propose, design, and prototype IndoorCrowd2D, a smartphone-empowered crowdsourcing system for indoor scene reconstruction. We first formulate the problem via trackable models and then employ a divide and conquer approach to address the inherently incomplete, opportunistic, and noisy crowdsourced data. By utilizing the image information and sensory data in a coordinated way, our system demonstrates high result-accuracy, as well as allows a gradual build-up procedure of the hallway skeleton. Our evaluation result shows that IndoorCrowd2D achieves a precision around 85%, a 100% recall and a F-score around 95% for reconstructing college buildings from 1,151 datasets uploaded by 25 users. This reveals that our image and sensor hybrid method is more robust to overcome errors and outliers as compared to image-only method.", "references": ["S. Agarwal, Y. Furukawa, N. Snavely, I. Simon, B. Curless, S. M. Seitz, and R. Szeliski. Building rome in a day. Communications of the ACM, 54(10):105--112, 2011.", "M. Alzantot and M. Youssef. Crowdinside: automatic construction of indoor floorplans. In SIGSPATIAL GIS, 2012.", "C. Arth, D. Wagner, M. Klopschitz, A. Irschara, and D. Schmalstieg. Wide area localization on mobile phones. In ISMAR, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809695.2809702"}, {"title": "Online Person Name Disambiguation with Constraints", "authors": ["Madian Khabsa\n,", "Pucktada Treeratpituk\n,", "C. Lee Giles"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nWhile many clustering techniques have been successfully applied to the person name disambiguation problem, most do not address two main practical issues: allowing constraints to be added to the clustering process, and allowing the data to be added incrementally without clustering the entire database. Constraints can be particularly useful especially in a system such as a digital library, where users are allowed to make corrections to the disambiguated result. For example, a user correction on a disambiguation result specifying that a record does not belong to an author could be kept as a cannot-link constraint to be used in any future disambiguation (such as when new documents are added). Besides such user corrections, constraints also allow background heuristics to be encoded into the disambiguation process. We propose a constraint-based clustering algorithm for person name disambiguation, based on DBSCAN combined with a pairwise distance based on random forests. We further propose an extension to the density-based clustering algorithm (DBSCAN) to handle online clustering so that the disambiguation process can be done iteratively as new data points are added.\nOur algorithm utilizes similarity features based on both metadata information and citation similarity. We implement two types of clustering constraints to demonstrate the concept. Experiments on the CiteSeer data show that our model can achieve 0.95 pairwise F1 and 0.79 cluster F1. The presence of constraints also consistently improves the disambiguation result across different combinations of features.", "references": ["C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for clustering evolving data streams. The 29th VLDB Conference, Sept. 2003.", "C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for projected clustering of high dimensional data streams. The 30th VLDB Conference, Aug. 2004.", "J. Artiles, J. Gonzalo, and S. Sekine. WePS 2 Evaluation Campaign: Overview of the Web People Search Clustering Task. 2nd Web People Search Evaluation Workshop (WePS 2009), 18th WWW Conference, Jan. 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756915"}, {"title": "Unified address translation for memory-mapped SSDs with FlashMap", "authors": ["Jian Huang\n,", "Anirudh Badam\n,", "Moinuddin K. Qureshi\n,", "Karsten Schwan"], "publication": "ISCA '15: Proceedings of the 42nd Annual International Symposium on Computer Architecture", "abstract": "ABSTRACT\nApplications can map data on SSDs into virtual memory to transparently scale beyond DRAM capacity, permitting them to leverage high SSD capacities with few code changes. Obtaining good performance for memory-mapped SSD content, however, is hard because the virtual memory layer, the file system and the flash translation layer (FTL) perform address translations, sanity and permission checks independently from each other. We introduce FlashMap, an SSD interface that is optimized for memory-mapped SSD-files. FlashMap combines all the address translations into page tables that are used to index files and also to store the FTL-level mappings without altering the guarantees of the file system or the FTL. It uses the state in the OS memory manager and the page tables to perform sanity and permission checks respectively. By combining these layers, FlashMap reduces critical-path latency and improves DRAM caching efficiency. We find that this increases performance for applications by up to 3.32x compared to state-of-the-art SSD file-mapping mechanisms. Additionally, latency of SSD accesses reduces by up to 53.2%.", "references": ["Nitin Agarwal, Vijayan Prabhakaran, Tedd Wobber, John D. Davis, Mark Manasse, and Rina Panigrahy. Design Tradeoffs for SSD Performance. In Proc. USENIX ATC, Boston, MA, June 2008.", "Ganesh Ananthanarayanan, Ali Ghodsi, Andrew Wang, Dhruba Borthakur, Srikath Kandula, Scott Shenker, and Ion Stoica. PAC-Man: Coordinated Memory Caching for Parallel Jobs. In Proc. 9th USENIX NSDI, 2012.", "David G. Andersen, Jason Franklin, Michael Kaminsky, Amar Phanishayee, Lawrence Tan, and Vijay Vasudevan. FAWN: A Fast Array of Wimpy Nodes. In Proc. 22nd ACM SOSP, October 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2749469.2750420"}, {"title": "What Is This Thing Called Linked Data?", "authors": ["Manuel Atencia\n,", "Jérôme David\n,", "Philippe Genoud"], "publication": "DocEng '15: Proceedings of the 2015 ACM Symposium on Document Engineering", "abstract": "ABSTRACT\nThe Linked Data initiative has made it possible for the web to evolve from being a global information space in which only documents are linked to one in which both documents and data are linked: a web of documents and data. This tutorial aims to give an overview of the principles, models and technologies underlying Linked Data.", "references": ["T. Berners-Lee. Linked data - design issues. Retrieved july 23, http://www.w3.org/designissues/linkeddata.html. 2006.", "C. Bizer, T. Heath, and T. Berners-Lee. Linked Data - The story so far. International Journal on Semantic Web and Information Systems, 5(3):1--22, 2009.", "D. Brickley and R. V. Guha. RDF vocabulary description language 1.0: RDF Schema. W3C Recommendation 10 February 2004. http://www.w3.org/tr/rdf-schema/. 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2682571.2801035"}, {"title": "On Divergence Measures and Static Index Pruning", "authors": ["Ruey-Cheng Chen\n,", "Chia-Jung Lee\n,", "W. Bruce Croft"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nWe study the problem of static index pruning in a renowned divergence minimization framework, using a range of divergence measures such as f-divergence and Rényi divergence as the objective. We show that many well-known divergence measures are convex in pruning decisions, and therefore can be exactly minimized using an efficient algorithm. Our approach allows postings be prioritized according to the amount of information they contribute to the index, and through specifying a different divergence measure the contribution is modeled on a different returns curve. In our experiment on GOV2 data, Rényi divergence of order infinity appears the most effective. This divergence measure significantly outperforms many standard methods and achieves identical retrieval effectiveness as full data using only 50% of the postings. When top-k precision is of the only concern, 10% of the data is sufficient to achieve the accuracy that one would usually expect from a full index.", "references": ["I. S. Altingovde, R. Ozcan, and O. Ulusoy. A practitioner's guide for static index pruning. In Proceedings of ECIR '09, pages 675--679. Springer Berlin / Heidelberg, 2009.", "I. S. Altingovde, R. Ozcan, and O. Ulusoy. Static index pruning in web search engines: Combining term and document popularities with query views. ACM Trans. Inf. Syst., 30(1), Mar. 2012.", "C. M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809472"}, {"title": "Unbiased Ranking Evaluation on a Budget", "authors": ["Tobias Schnabel\n,", "Adith Swaminathan\n,", "Thorsten Joachims"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nWe address the problem of assessing the quality of a ranking system (e.g., search engine, recommender system, review ranker) given a fixed budget for collecting expert judgments. In particular, we propose a method that selects which items to judge in order to optimize the accuracy of the quality estimate. Our method is not only efficient, but also provides estimates that are unbiased --- unlike common approaches that tend to underestimate performance or that have a bias against new systems that are evaluated re-using previous relevance scores.", "references": ["J. A. Aslam, V. Pavlu, and E. Yilmaz. A statistical method for system evaluation using incomplete judgments. In SIGIR, pages 541--548, 2006.", "B. Carterette, J. Allan, and R. Sitaraman. Minimal test collections for retrieval evaluation. In SIGIR, pages 268--275, 2006.", "B. Carterette, V. Pavlu, E. Kanoulas, J. A. Aslam, and J. Allan. If I had a million queries. In ECIR, pages 288--300, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742565"}, {"title": "Fotossenti: An app to support on psychological treatments", "authors": ["Darlinton Barbosa Feres Carvalho\n,", "Samuel Moreira Abreu Araujo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents a novel information system to assist in psychological treatments through pictures taken by the camera of smartphones or tablets, creating a new communication channel between patient and therapist by the use of the proposed application Fotossenti. The purpose of this application is to help in the generation and management of information to be considered on the patient's therapy sessions, which could go unnoticed in the traditional way. This paper presents a brief theoretical foundation on Information and Communication Technologies (ICTs) applied to Health, especially those focused on psychology and considered in the development of this work, as well as unique characteristics of Fotossenti, with an assessment by specialist in psychology, and, finally, the challenges and opportunities found along the research. The conclusion recaps the importance of the development and use of new ICTs, particularly new information systems in the field of psychological health, and places the Fotossenti application as a tool to contribute to the generation of information for psychological treatment, and consequently the decisions taken by the therapist, increasing the benefits of treatment.", "references": ["I. C. B. Alvea, J. C. Alchieri, and K. C. Marques. As técnicas de exame psicológico ensinadas nos cursos de graduação de acordo com os professores. Psico USF, 1(7):77-88, Junho 2002.", "R. Barthes. A câmara clara: nota sobre a fotografia. Editora Nova Fronteira, Rio de Janeiro, 1984.", "P. L. Carreiro. O efeitos da probabilidade de reforçamento e do custo da resposta sobre a persistência comportamental. Mestrado, Universidade de Brasília, UNB, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814140"}, {"title": "Experience design in the Asia Pacific ICT landscape", "authors": ["Eunice Sari\n,", "Henry Duh\n,", "Margot Brereton\n,", "Jennyfer Lawrence Taylor\n,", "Kagonya Awori\n,", "Wan Fatimah Wan Bt Ahmad"], "publication": "APCHIUX '15: Proceedings of the Asia Pacific HCI and UX Design Symposium", "abstract": "ABSTRACT\nThis symposium aims to bring forth issues related to HCI and UX in the Asia Pacific region, in the spheres of both industry and academia. Key areas addressed by the symposium include the level awareness of HCI and UX in the Asia Pacific region, and the design, application, and teaching of HCI and UX in a relatively new but complex Asia Pacific context. The symposium provides a platform for sharing and discussing projects that address the challenges, potential solutions, and innovations towards effective interaction in physical and digital world. Particular topics of interest in exploring the future of interaction design in the Asia Pacific include the Internet of Things, User Experience Design and HCI for Development (HCI4D).", "references": ["Eunice Sari, Adi Tedjasaputra, and Tuomo Kujala. 2015. Growing together with Indonesian SIGCHI. interactions, 22, 2 (February 2015), 70--70. DOI=http://dx.doi.org/10.1145/2736098", "Eunice Sari, Bimlesh Wadhwa, Adi Tedjasaputra, Masitah Ghazali, and Anirudha Joshi. 2015. Crossing HCI for Development in Asia Pacific. In Proceedings of the ASEAN CHI Symposium'15(ASEAN CHI Symposium'15). ACM, New York, NY, USA, 1--4. DOI=http://dx.doi.org/10.1145/2776888.2780357", "Eunice Sari, Bimlesh Wadhwa, Understanding HCI Education across Asia-Pacific, Proceedings of the ASEAN CHI Symposium'15, p.36--41, April 18--23, 2015, Seoul, Republic of Korea."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2846439.2846440"}, {"title": "sandFOX: secure sandboxed and isolated environment for firefox browser", "authors": ["Anil Saini\n,", "Manoj Singh Gaur\n,", "Vijay Laxmi\n,", "Priyadarsi Nanda"], "publication": "SIN '15: Proceedings of the 8th International Conference on Security of Information and Networks", "abstract": "ABSTRACT\nBrowser functionalities can be widely extended by browser extensions. One of the key features that makes browser extensions so powerful is that they run with \"high\" privileges. As a consequence, a vulnerable or malicious extension might expose browser, and operating system (OS) resources to possible attacks such as privilege escalation, information stealing, and session hijacking. The resources are referred as browser as well as OS components accessed through browser extension such as accessing information on the web application, executing arbitrary processes, and even access files from a host file system.\nThis paper presents sandFOX (secure sandbox and iso- lated environment), a client-side browser policies for constructing sandbox environment. sandFOX allows the browser extension to express fine-grained OS specific security policies that are enforced at runtime. In particular, our proposed policies provide the protection to OS resources (e.g., host file system, network and processes) from the browser attacks. We use Security-Enhanced Linux (SELinux) to tune OS and build a sandbox that helps in reducing potential damage from attacks on the OS resources. To show the practicality of sandFOX in a range of settings, we compute the effectiveness of sandFOX for various browser attacks on OS resources. We also show that sandFOX enabled browser experiences low overhead on loading pages and utilizes negligible memory when running with sandbox environment.", "references": ["Mozilla developer network-extensions. https://developer.mozilla.org/en/docs/Extensions.", "Devdatta Akhawe, Warren He, Zhiwei Li, Reza Moazzezi, and Dawn Song. Clickjacking revisited a perceptual view of ui security. BlackHat USA, August, 2013.", "Oskar Andreasson. Iptables tutorial, 2006, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2799979.2800000"}, {"title": "Secure friend discovery based on encounter history in mobile social networks", "authors": ["Hongjuan Li\n,", "Yingwen Chen\n,", "Xiuzhen Cheng\n,", "Keqiu Li\n,", "Dechang Chen"], "publication": "Personal and Ubiquitous Computing", "abstract": "Abstract\nMobile social networking becomes increasingly popular with the explosive growth of mobile devices. By allowing mobile users to interact with potential friends around the real world, it enables new social interactions as a complement to Web-based online social networks. In this paper, we introduce a secure friend discovery mechanism based on encounter history in mobile social networks. By exploring the fact that sharing encounters indicate common activities and interests, our scheme can help people make friends with like-minded strangers nearby. To the best of our knowledge, this is the first work to take advantage of the encounter history in friend discovery. We provide peer-to-peer confidential communications with the location privacy and encounter privacy being strictly preserved. Unlike most existing works that either rely on a trusted centralized server or existing social relationships, our algorithm is designed in an ad hoc model with no such limitation. As a result, our design is more suitable and more general for mobile social scenarios. Extensive theoretical analysis and experimental study are conducted, and the results indicate that our scheme is feasible and effective for privacy-preserving friend discovery in mobile social networks.", "references": ["Lin K-Y, Lu H-P (2015) Predicting mobile social network acceptance based on mobile value and social influence. Internet Res 25(1):107---130", "Wei P-S, Lu H-P (2014) Why do people play mobile social games? An examination of network externalities and of uses and gratifications. Internet Res 24(3):313---331", "Li M, Zhu H, Gao Z, Chen S, Yu L, Hu S, Ren K (2014) All your location are belong to us: Breaking mobile social networks for automated user location tracking. In: Proceedings of the 15th ACM international symposium on Mobile ad hoc networking and computing. ACM, pp 43---52"], "doi_url": "https://dl.acm.org/doi/abs/10.1007/s00779-015-0873-9"}, {"title": "Florch: Challenges on developing a new social network accessible for senescent users", "authors": ["Ana Elisa de Oliveira Siena\n,", "André de Lima Salgado\n,", "Renata P. de Mattos Fortes"], "publication": "CLIHC '15: Proceedings of the Latin American Conference on Human Computer Interaction", "abstract": "ABSTRACT\nBrazilian senescent population can grow three times the actual number in the next 20 years [18], being over 88 million people in 2035. This senescent growing number brings new challenges on quality of life for Brazilian society. How to promote digital inclusion to this profile of user is still a challenge in the literature. We believe that a social network focused on senescent users can enhance the digital inclusion for them. However, it's essential that the social network be designed for senescent users. This study aims to create a project with this characteristics. We analyzed a successful social network (WhatsApp) in order to propose a new one (Florch) for senescent users. We developed a high fidelity prototype of Florch and tested it. Our findings show usability and accessibility problems faced on the project's development. In addition, a Hierarchical Task Analysis of our social network showed that it has less and simpler tasks than the successful social network (WhatsApp).", "references": ["CreativeCommons. https://creativecommons.org/licenses/by-sa/2.0/. (21st May 2015).", "Y. Abutaleb and P. Galloway. Apple, ibm announce partnership with japan post to improve elderly care. www.reuters.com/article/2015/04/30/us-usa-apple-partnership-idUSKBN0NL1QK20150430, 2015. (28th May 2015).", "S. M. Affonso de Lara, W. M. Watanabe, E. P. B. dos Santos, and R. P. Fortes. Improving wcag for elderly web accessibility. In Proceedings of the 28th ACM International Conference on Design of Communication, pages 175--182. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2824893.2824900"}, {"title": "Isaac Bloomberg Meets Michael Bloomberg: Better EntityDisambiguation for the News", "authors": ["Luka Bradesko\n,", "Janez Starc\n,", "Stefano Pacifico"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper shows the implementation and evaluation of the Entity Linking or Named Entity Disambiguation system used and developed at Bloomberg. In particular, we present and evaluate a methodology and a system that do not require the use of Wikipedia as a knowledge base or training corpus. We present how we built features for disambiguation algorithms from the Bloomberg News corpus, and how we employed them for both single-entity and joint-entity disambiguation into a Bloomberg proprietary knowledge base of people and companies. Experimental results show high quality in the disambiguation of the available annotated corpus.", "references": ["R. Bunescu and M. Pasca. Using Encyclopedic Knowledge for Named Entity Disambiguation. In Proceesings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), pages 9--16, Trento, Italy, 2006.", "S. Cucerzan. Large-scale Named Entity Disambiguation Based on Wikipedia Data. In In Proc. 2007 Joint Conference on EMNLP and CNLL, pages 708--716, 2007.", "J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes. Improving Efficiency and Accuracy in Multilingual Entity Extraction. In Proceedings of the 9th International Conference on Semantic Systems (I-Semantics), 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741711"}, {"title": "Improving floor localization accuracy in 3D spaces using barometer", "authors": ["Dipyaman Banerjee\n,", "Sheetal K. Agarwal\n,", "Parikshit Sharma"], "publication": "ISWC '15: Proceedings of the 2015 ACM International Symposium on Wearable Computers", "abstract": "ABSTRACT\nTechnologies such as Wifi and BLE have been proven to be effective for indoor localization in two dimensional spaces with sufficiently good accuracy but the same techniques have large margin of errors when it comes to three dimensional spaces. Popular 3D spaces such as malls or airports are marked by distinct structural features - atrium/hollow space and large corridors which reduces spatial variability of WiFi and BLE signal strengths leading to erroneous location prediction. A large fraction of these errors can be attributed to vertical jumps where the predicted location has same horizontal coordinate as the actual location but differs in the vertical coordinate. Smartphones now come equipped with barometer sensor which could be used to solve this problem and create 3D localization solution having better accuracy. Research shows that the barometer can be used to determine relative vertical movement and its direction with nearly 100% accuracy. However exact floor prediction requires repeated calibration of the barometer measurements as pressure values vary significantly across device, time and locations. In this paper we present a method of automatically calibrating smartphone embedded barometers to provide accurate 3D localization. Our method combines a probabilistic learning method with a pressure drift elimination algorithm. We also show that when the floor value is accurately predicted, Wifi localization accuracy improves by 25% for 3D spaces. We validate our techniques in a real shopping mall and provide valuable insights from practical experiences.", "references": ["Bahl, P., and Padmanabhan, V. N. RADAR: an in-building RF-based user location and tracking system. In INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE, vol. 2 (2000).", "Borriello, G., Liu, A., Offer, T., Palistrant, C., and Sharp, R. Walrus: Wireless acoustic location with room-level resolution using ultrasound. In Proceedings of the 3rd International Conference on Mobile Systems, Applications, and Services, MobiSys '05 (2005).", "Chen, Y.-C., Chiang, J.-R., Chu, H.-h., Huang, P., and Tsui, A. W. Sensor-assisted wi-fi indoor location system for adapting to environmental dynamics. In Proceedings of the 8th ACM international symposium on Modeling, analysis and simulation of wireless and mobile systems, ACM (2005), 118--125."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802083.2802089"}, {"title": "Improving bag-of-words representation with efficient twin feature integration", "authors": ["Lei Wang\n,", "Hanli Wang"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn recent years, the Bag-of-Words (BoW) model has been widely used in most state-of-the-art large-scale image retrieval systems. However, the standard BoW based systems suffer from low discriminative power of local features as well as quantization errors that significantly affect the retrieval performance. In this paper, twin feature is employed and well combined with two advanced techniques including Hamming Embedding (HE) and Multiple Assignment (MA) to construct a discriminative image retrieval system on BoW representation in an efficient way. Experimental results on two benchmark datasets Oxford5k and Paris6k demonstrate that the proposed technique can greatly refine the visual matching process and enhance the final performance for image retrieval.", "references": ["Y. Cao, C. Wang, Z. Li, L. Zhang, and L. Zhang. Spatial-bag-of-features. In Proc. CVPR'10, pages 3352--3359, 2010.", "M. Fischler and R. Bolles. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24(6):381--395, 1981.", "H. Jégou, M. Douze, and C. Schmid. Hamming embedding and weak geometric consistency for large scale image search. In Proc. ECCV'08, pages 304--317, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808543"}, {"title": "Effective Web Data Extraction with Ducky", "authors": ["Kei Kanaoka\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nThe World Wide Web has become an invaluable source of data. However, extracting useful information from the vastness of the web can become a challenge as depending on the amount of data needed, manual extraction or creation of web scraping programs may be necessary. These processes can be tedious and complicated. To address these, Ducky, a web wrapper that extracts data from web sources and translates them into structured data based on a user-defined configuration, has been developed. Ducky is able to extract data flexibly from various structured web pages, remove noise from extracted data and integrate multiple pages from different sites. In addition, the current version of Ducky automatically extracts data from Wikipedia and trendy keywords of Google and Yahoo.", "references": ["K. Kanaoka, Y. Fujii, and M. Toyama. Ducky: A data extraction system for various structured web documents. In Proceedings of the 18th International Database Engineering & Applications Symposium, IDEAS '14, pages 342--347, New York, NY, USA, 2014. ACM.", "H. Sleiman and R. Corchuelo. A survey on region extractors from web documents. Knowledge and Data Engineering, IEEE Transactions on, 25(9):1960--1981, Sept 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790787"}, {"title": "FOREST: Focused Object Retrieval by Exploiting Significant Tag Paths", "authors": ["Marilena Oita\n,", "Pierre Senellart"], "publication": "WebDB'15: Proceedings of the 18th International Workshop on Web and Databases", "abstract": "ABSTRACT\nContent-intensive websites, e.g., of blogs or news, present pages that contain Web articles automatically generated by content management systems. Identification and extraction of their main content is critical in many applications, such as indexing or classification. We present a novel unsupervised approach for the extraction of Web articles from dynamically-generated Web pages. Our system, called Forest, combines structural and information-based features to target the main content generated by a Web source, and published in associated Web pages. We extensively evaluate Forest with respect to various baselines and datasets, and report improved results over state-of-the art techniques in content extraction.", "references": ["A. Arasu and H. Garcia-Molina. Extracting structured data from Web pages. In SIGMOD, 2003.", "Z. Bar-Yossef and S. Rajagopalan. Template detection via data mining and its applications. In WWW, 2002.", "P. Bohunsky and W. Gatterbauer. Visual structure-based Web page clustering and retrieval. In WWW, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767109.2767112"}, {"title": "Towards automated creation of high quality domain-specific machine translation resources", "authors": ["Bartholomäus Wloka"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nIn this paper we present a workflow for the automated creation of parallel domain-specific corpora, i.e. multilingual translated text collections of a certain domain, in which the text pieces are aligned at sentence level. The source for the text extraction are Wikipedia articles. This workflow will be adaptable to any language pair, though the first implementation is targeting English/Japanese. The workflow consists of intelligent text acquisition, text alignment including novel techniques, and large scale quality evaluation by human experts. This will enable us to create an adaptable, fine-tuned system as well as high quality corpora, which will be compiled during the implementation.", "references": ["A. Aker, E. Kanoulas, and R. Gaizauskas. A light way to collect comparable corpora from the web. In Proceedings of LREC'12, Istanbul, Turkey, 2012.", "M. Braschler and P. Schäuble. Multilingual information retrieval based on document alignment techniques. In Research and Advanced Technology for Digital Libraries, volume 1513 of Lecture Notes in Computer Science, pages 183--197. Springer Berlin Heidelberg, 1998.", "J. Breen. JMdict: a Japanese-multilingual dictionary. In G. Sérasset, editor, COLING 2004 Multilingual Linguistic Resources, pages 65--72, Geneva, Switzerland, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837273"}, {"title": "Learning to Rank from Noisy Data", "authors": ["Wenkui Ding\n,", "Xiubo Geng\n,", "Xu-Dong Zhang"], "publication": "ACM Transactions on Intelligent Systems and Technology", "abstract": "Abstract\nLearning to rank, which learns the ranking function from training data, has become an emerging research area in information retrieval and machine learning. Most existing work on learning to rank assumes that the training data is clean, which is not always true, however. The ambiguity of query intent, the lack of domain knowledge, and the vague definition of relevance levels all make it difficult for common annotators to give reliable relevance labels to some documents. As a result, the relevance labels in the training data of learning to rank usually contain noise. If we ignore this fact, the performance of learning-to-rank algorithms will be damaged.\nIn this article, we propose considering the labeling noise in the process of learning to rank and using a two-step approach to extend existing algorithms to handle noisy training data. In the first step, we estimate the degree of labeling noise for a training document. To this end, we assume that the majority of the relevance labels in the training data are reliable and we use a graphical model to describe the generative process of a training query, the feature vectors of its associated documents, and the relevance labels of these documents. The parameters in the graphical model are learned by means of maximum likelihood estimation. Then the conditional probability of the relevance label given the feature vector of a document is computed. If the probability is large, we regard the degree of labeling noise for this document as small; otherwise, we regard the degree as large. In the second step, we extend existing learning-to-rank algorithms by incorporating the estimated degree of labeling noise into their loss functions. Specifically, we give larger weights to those training documents with smaller degrees of labeling noise and smaller weights to those with larger degrees of labeling noise. As examples, we demonstrate the extensions for McRank, RankSVM, RankBoost, and RankNet. Empirical results on benchmark datasets show that the proposed approach can effectively distinguish noisy documents from clean ones, and the extended learning-to-rank algorithms can achieve better performances than baselines.", "references": ["D. Angluin and P. Laird. 1988. Learning from noisy examples. Machine Learning 2, 4, 343--370.", "Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999. Modern Information Retrieval. Addison Wesley, New York, NY.", "R. Baeza-Yates, B. Ribeiro-Neto, and others. 1999. Modern information retrieval. Addison-Wesley, Reading, MA."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2576230"}, {"title": "Software Startup Ecosystems: Initial Results in the state of Para", "authors": ["Nagila Natalia de Jesus Torres\n,", "Cleidson R. B. de Souza"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe overall goal of our research is to produce a characterization of the software startup ecosystem in the state of Para, Brazil. This characterization will describe the various actors involved in this ecosystem, as well as the relationships among them. This paper presents our initial results based on a set of interviews conducted with entrepreneurs located in the city of Belem, Para. We report different aspects faced by those involved in startup ecosystems, which can be used to suggest actions to strengthen the ecosystem. We plan to collect additional data in other cities of the state as well as to compare our results with other software startup ecosystems.", "references": ["Grin, E. J. et al. Desenvolvimento de Políticas Públicas de Fomento ao Empreendedorismo em Estados e Municípios. São Paulo: Programa de Gestão Pública e Cidadania, FGVEAESP, 2012. 52p.", "Cassapo, F. Inovação no Brasil X Inovação no Mundo. Revista PEGN. 2013. Acessado em Janeiro de 2014 ¿http://revistapegn.globo.com/Revista/Common/0,,EMI24006618478,00INOVACAO+NO+BRASIL+X+INOVACAO+NO+MUNDO.html¿", "Kallberg, P. An Analysis of Brazil's Startup Ecosystem as a Nurturing Force for Internet-Based Startups: Friend or Foe? 2013, 85f. Trabalho de Conclusão de Curso (Bachelor of Science degree) - Faculty of The School of Business, University of Warwick, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814073"}, {"title": "A new Automatic approach for Understanding the Spontaneous Utterance in Human-Machine Dialogue based on Automatic Text Categorization", "authors": ["Mohamed Lichouri\n,", "Amar Djeradi\n,", "Rachida Djeradi"], "publication": "IPAC '15: Proceedings of the International Conference on Intelligent Information Processing, Security and Advanced Communication", "abstract": "ABSTRACT\nIn the present paper, we suggested an implementation of an automatic understanding system of the statement in Human-Machine Communication. The architecture we adopted was based on a stochastic approach that assumes that the understanding of a statement is nothing but a simple theme identification process. Therefore, we presented a new theme identification method based on a documentary retrieval technique which is text (document) classification [2]. The method we suggested was validated on a basic platform that give information related to university schooling management (Querying a student database), taking into consideration a textual input in french. This method has achieved a theme identification rate of 95% and a correctly utterance understanding rate of about 91.66%.", "references": ["H. Aust, M. Oerder, F. Seide, and V. Steinbiss. The philips automatic train timetable information system. Speech Communication, 17(3):249--262, 1995.", "A. Bawakid and M. Oussalah. A semantic-based text classification system. In Cybernetic Intelligent Systems (CIS), 2010 IEEE 9th International Conference on, pages 1--6, Sept 2010.", "C. Bousquet-Vernhettes. un environnement de compréhension de la parole pour les serveurs interactifs: l'environnement cacao. Rencontres Jeunes Chercheurs en Interaction Homme Machine (RJC-IHM'2000), pages 77--80, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2816839.2816894"}, {"title": "TaxiRec: recommending road clusters to taxi drivers using ranking-based extreme learning machines", "authors": ["Ran Wang\n,", "Chi-Yin Chow\n,", "Yan Lyu\n,", "Victor C. S. Lee\n,", "Sam Kwong\n,", "Yanhua Li\n,", "Jia Zeng"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nUtilizing large-scale GPS data to improve taxi services becomes a popular research problem in the areas of data mining, intelligent transportation, and the Internet of Things. In this paper, we utilize a large-scale GPS data set generated by over 7,000 taxis in a period of one month in Nanjing, China, and propose TaxiRec; a framework for discovering the passenger-finding potentials of road clusters, which is incorporated into a recommender system for taxi drivers to hunt passengers. In TaxiRec, we first construct the road network by defining the nodes and road segments. Then, the road network is divided into a number of road clusters through a clustering process on the mid points of the road segments. Afterwards, a set of features for each road cluster is extracted from real-life data sets, and a ranking-based extreme learning machine (ELM) model is proposed to evaluate the passenger-finding potential of each road cluster. Experimental results demonstrate the feasibility and effectiveness of the proposed framework.", "references": ["J. A. Hartigan and M. A. Wong. Algorithm AS 136: A k-means clustering algorithm. Applied Statistics, pages 100--108, 1979.", "G. B. Huang, H. Zhou, X. Ding, and R. Zhang. Extreme learning machine for regression and multiclass classification. IEEE TSMCB, (99):1--17, 2010.", "G. B. Huang, Q. Y. Zhu, and C. K. Siew. Extreme learning machine: theory and applications. Neurocomputing, 70(1--3):489--501, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820843"}, {"title": "Feature Extraction for Product Advertising Reviews Identification in Social Media", "authors": ["Jenq-Haur Wang\n,", "Yu-Hsin Liu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe social Web has become an important venue for marketing in business. Many vendors hire writers to give product-using experience to promote their products. Promotional texts might give users misleading impressions which are totally far from the truth. However, distinguishing between real and advertising reviews is usually very difficult even for humans. In this paper, we investigate the potential features which might be useful for efficiently identifying advertising reviews (ad reviews) in social media. Based on observations in blog reviews, content, statistical, and social features such as ratio of positive opinion terms, ratio of praise words, and publishing date are extracted to train a SVM classifier for ad review identification. The experimental results on 2,150 reviews showed a good accuracy of 94.55% for classifying cosmetics ad reviews from general articles. Also, experiments on 16,017 cosmetics forum reviews showed the best accuracy of 87.79% in classifying ad reviews from non-ad comments. Our method outperforms conventional text classification using TF-IDF with much higher efficiency. This shows the feasibility of our proposed feature extraction methods in ad review identification.", "references": ["Jindal, N. and Liu, B. 2008. Opinion spam and analysis. In Proceedings of the 2008 International Conference on Web Search and Data Mining (WSDM 2008), 219--230.", "Jindal, N. and Liu, B. 2007. Review spam detection. In Proceedings of the 16th International Conference on World Wide Web (WWW 2007), 1189--1190.", "Ott, M., Choi, Y., Cardie, C., and Hancok, J. T. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL 2011), 309--319."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818920"}, {"title": "An incremental learning technique for detecting driving behaviors using collected EV big data", "authors": ["Chung-Hong Lee\n,", "Chih-Hung Wu"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper presents an expansible machine learning approach applying the EV big data as the human sensor to extract driving behaviors and driving modes. A pattern recognition approach is proposed to model the driving pattern according to the energy consumption of an EV. The growing hierarchical self-organizing maps (GHSOM) is applied to learn driver's behaviors gradually in the offline process, and the clustered neurons are used as the training sets for implementing online classifiers based on support vector machine (SVM). This proposed framework would facilitate the understanding of driver's behaviors and help drivers overcome range anxiety.", "references": ["Loisel, R., Pasaoglu, G., and Thiel, C. 2014. Large-scale deployment of electric vehicles in Germany by 2030: An analysis of grid-to-vehicle and vehicle-to-grid concepts. Energy Policy, 65, (Feb. 2014), 432--443. DOI=http://dx.doi.org/10.1016/j.enpol.2013.10.029.", "Mwasilu, F., Justo, J. J., Kim, E.-K., Do, T. D. and Jung, J.-W. 2014. Electric vehicles and smart grid interaction: A review on vehicle to grid and renewable energy sources integration. Renewable and Sustainable Energy Reviews, 34, (Jun. 2014), 501--516. DOI=http://dx.doi.org/10.1016/j.rser.2014.03.031.", "Mehar, S. Senouci, S. M. and Rémy, G. 2013. EV-planning: Electric vehicle itinerary planning. IEEE, City, 2013. DOI=http://dx.doi.org/10.1109/SaCoNeT.2013.6654583."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818935"}, {"title": "Reconciling user and designer preferences in adapting web pages for people with low vision", "authors": ["Yoann Bonavero\n,", "Marianne Huchard\n,", "Michel Meynard"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nThe web has become a major tool for communication, services and an outstanding source of knowledge. It has also grown in complexity, and end-users may experience difficulties in reading and acquiring good understanding of some overly complex or poorly designed web pages. This observation is even more valid for people with visual disabilities. In this paper, we focus on people with low or weakening vision, for whom we propose to adapt web pages to their needs, while preserving the spirit of the original design. In this context, obtaining a web page adaptation in a very short time may be a difficult problem, because user and designer needs and preferences may contradict each other, and because there may be a large number of adaptation possibilities. Finding a relevant adaptation in a large search space can hardly be done by an algorithm which computes and assesses all possible solutions, which brings us to consider evolutionary algorithms. A characteristic of our problem is to consider a set of preferences, each being implemented by an evaluation function. This optimization problem can be dealt with multiobjective genetic algorithms, including the Non-dominated Sorting Genetic Algorithm II (NSGA-II) and its next version (NSGA-III). NSGA-III has been recently introduced to address many-objective optimization problems (having more that four objectives). We compare NSGA-II and NSGA-III performances in the context of adapting web pages in accordance to a set of preferences. The comparison is based on running time, number of generations and quality of computed adaptation (number of satisfied objectives). We also show the importance of several parameters including population size, crossover/mutation probability, and the opportunity to aggregate objective functions. From the obtained results, we conclude that the approach is feasible and effective on realistic web pages, especially with NSGA-III.", "references": ["Accessibility in Android. https://developer.android.com/design/patterns/accessibility.html. Accessed: 2015-01-10.", "Accessibility in Windows 8. http://www.microsoft.com/enable/products/windows8/. Accessed: 2015-01-10.", "Apple Accessibility OS X. https://www.apple.com/accessibility/osx/. Accessed: 2015-01-10."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746647"}, {"title": "Knowledge Obtention Combining Information Extraction Techniques with Linked Data", "authors": ["Angel Luis Garrido\n,", "Pilar Blazquez\n,", "Maria G. Buey\n,", "Sergio Ilarri"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nToday, we can find a vast amount of textual information stored in proprietary data stores. The experience of searching information in these systems could be improved in a remarkable manner if we combine these private data stores with the information supplied by the Internet, merging both data sources to get new knowledge. In this paper, we propose an architecture with the goal of automatically obtaining knowledge about entities (e.g., persons, places, organizations, etc.) from a set of natural text documents, building smart data from raw data. We have tested the system in the context of the news archive of a real Media Group.", "references": ["E. Agichtein and L. Gravano. Querying text databases for efficient information extraction. In Data Engineering, 2003. Proceedings. 19th International Conference on, pages 113--124. IEEE, 2003.", "H. Alani, S. Kim, D. E. Millard, M. J. Weal, W. Hall, P. H. Lewis, and N. R. Shadbolt. Automatic ontology-based knowledge extraction from web documents. Intelligent Systems, IEEE, 18(1):14--21, 2003.", "X. Carreras, L. Màrquez, and L. Padró. A simple named entity extractor using adaboost. In Seventh Conference on Natural Language Learning at HLT-NAACL, volume 4, pages 152--155. Association for Computational Linguistics, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741708"}, {"title": "Requesting heterogeneous data sources with array comprehensions in hop.js", "authors": ["Yoann Couillec\n,", "Manuel Serrano"], "publication": "DBPL 2015: Proceedings of the 15th Symposium on Database Programming Languages", "abstract": "ABSTRACT\nDuring the past few years the volume of accumulated data has increased dramatically. New kinds of data stores have emerged as NoSQL family stores. Many modern applications now collect, analyze, and produce data from several heterogeneous sources. However implementing such applications is still difficult because of lack of appropriate tools and formalisms. We propose a solution to this problem in the context of the JavaScript programming language by extending array comprehensions. Our extension allows programmers to query data from usual stores, such as SQL databases, NoSQL databases, Semantic Web data repositories, Web pages, or even custom user defined data structures. The extension has been implemented in the Hop.js system. It is the subject of this paper.", "references": ["G. Copeland and D. Maier. Making smalltalk a database system. In ACM Sigmod Record, vol. 14 no 2, pages 316-325, 1984.", "E. Meijer, B. Beckman and G. Bierman. LINQ: Reconciling Object, Relations and XML in the .NET Framework. In SIGMOD ’06, page 706, 2006.", "E. Meijer. There is no impedance mismatch:(language integrated query in Visual Basic 9). In OOPSLA ’06, pages 710-711, 2006"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815072.2815077"}, {"title": "A discriminative classifier for in-air handwritten Chinese characters recognition", "authors": ["Ning Xu\n,", "Weiqiang Wang\n,", "Xiwen Qu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nAs the development of three-dimensional interaction, in-air writing arises as a novel interaction method, and brings traditional writing behavior to the 3D space. In this paper, we propose a discriminative three-level classifier for in-air handwritten Chinese character recognition. Since the existence of characters with similar shapes and structures results in one of the main difficulties of Chinese handwritten character recognition, this paper tackles the problem caused by similar characters using two discriminative analysis techniques. First, we exploit the learning vector quantization (LVQ) to obtain discriminative prototypes. Then, we use the adaptive discriminative locality alignment (ADLA) to distinguish candidate character class among similar character classes. In the experiments, we evaluate the proposed method on the IAHCC-UCAS2014 dataset constructed by ourselves using the writing-in-the-air system based on the Leap Motion Controller. The experimental results show that the proposed method obtain higher recognition accuracy with lower computational cost.", "references": ["C.-L. Liu, S. Jaeger, M. Nakagawa, \\Online recognition of Chinese characters: the state-of-the-art,\" IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 26, no. 2, pp. 198--213, 2004.", "L.-W. Jin, Y. Gao, G. Liu, Y.-Y. Li, K. Ding, \"SCUT-COUCH2009 -- a comprehensive online unconstrained Chinese handwriting database and benchmark evaluation,\" International Journal on Document Analysis and Recognition, vol. 14, no.1 pp. 53--64, 2010.", "N. Xu, W.-Q. Wang, X.-W. Qu, \"Recognition of in-air handwritten Chinese character based on Leap Motion Controller\", the 8th International Conference on Image and Graphics, Aug. 13-16, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808508"}, {"title": "On the Effect of \"Stupid\" Search Components on User Interaction with Search Engines", "authors": ["Lidia Grauer\n,", "Aleksandra Lomakina"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUsing eye-tracking, we investigate how searchers interact with Web search engines which get affected by nonsensical results. We conduct a user survey to choose \"stupid\" components for our laboratory experiment and explore the most conspicuous ones.\nThis research provides insights about searchers' interactions with different kinds of \"stupid\" search components, such as organic search results, vertical results, ads and automatic misspell correction. We investigate the influence of each class of \"stupid\" components on users' attitude to a search engine. We found that sticking in memory of the impression about the \"stupidity\" of the search engine depended on whether the users were finally satisfied with their searches, or did not find the answer. Experimental results show that classes of \"stupid\" components can be differentiated by their influence on users' attitude. The most negative impression is caused by word losses, word collocation breaks and inappropriate misspell corrections.", "references": ["J. Arguello and R. Capra. The effect of aggregated search coherence on search behavior. In CIKM 2012, pages 1293--1302, 2012.", "J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. In CIKM 2014, pages 539--548, 2014.", "A. Aula, R. M. Khan, Z. Guan, P. Fontes, and P. Hong. A comparison of visual and textual page previews in judging the helpfulness of web pages. In WWW 2010, pages 51--60, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806601"}, {"title": "Central Topic Model for Event-oriented Topics Mining in Microblog Stream", "authors": ["Min Peng\n,", "Jiahui Zhu\n,", "Xuhui Li\n,", "Jiajia Huang\n,", "Hua Wang\n,", "Yanchun Zhang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nTo date, data generates and arrives in the form of stream to propagate discussions of public events in microblog services. Discovering event-oriented topics from the stream will lead to a better understanding of the change of public concern. However, as the massive scale of the data stream, traditional static topic models, such as LDA, are no longer fit for topic detection and tracking tasks. In this paper, we propose a central topic model (CenTM), where a Multi-view Clustering algorithm with Two-phase Random Walk (MC-TRW) is devised to aggregate the LDA's latent topics into central topics. Furthermore, we leverage the aggregation of central topics alternately with MC-TRW and sequential topic inference to improve the scalability in the stream fashion, so as to derive the dynamic central topic model (DCenTM). Specifically, our model is able to uncover the intrinsic characteristics of the central topics and predict the trend of their intensity along a life cycle. Experimental results demonstrate that the proposed central topic model is event-oriented and of high generalization, it therefore can dispose the topic trend prediction effectively and precisely in massive data stream.", "references": ["L. AlSumait, D. Barbará, and C. Domeniconi. On-line lda: Adaptive topic models for mining text streams with applications to topic detection and tracking. In ICDM, pages 3--12, 2008.", "P. André, M. S. Bernstein, and K. Luther. Who gives a tweet?: Evaluating microblog content value. In CSCW, pages 471--474, 2012.", "S. Ardon, A. Bagchi, A. Mahanti, A. Ruhela, A. Seth, R. M. Tripathy, and S. Triukose. Spatio-temporal and events based analysis of topic popularity in twitter. In CIKM, pages 219--228, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806561"}, {"title": "Non-Immersive method of Accelerometer calibration for mobile devices", "authors": ["Priydarshi\n,", "Nandita\n,", "Gude Kiran Kumar\n,", "A. Ashok Kumar Senapati\n,", "Renju C. Nair"], "publication": "ICCCT '15: Proceedings of the Sixth International Conference on Computer and Communication Technology 2015", "abstract": "ABSTRACT\nThis paper describes a method of calibrating tri-axial accelerometer sensor without the need of controlled environment and user intervention, available in present day smartphones. These sensors have misalignment errors which are induced during soldering of chip on PCB. Resulting imperfections in accelerometer sensor such as scaling factors and offsets affect the output of the sensor leading to erroneous performance of applications such as navigation, screen rotation, games etc. The paper describes a calibration model which incorporates the fundamental principle i.e. the norm of the sensor output is equal to the earth gravity acceleration. The calibration method evaluates the offset and scale factor for each axis which are computed using a non-linear minimization technique. The method is an iterative process of minimizing the mean square error. The proposed technique ensures that the data points collected doesn't have acceleration due to movement. Post calculation, verification of the output i.e. offset and scaling factor is done to ensure that the correct offsets are written in a persistent file system. The resulting algorithm is device independent and can be used in multiple platforms. Simulation and experimental results shows that the calibration output is unerring and significant improvement in performance of applications using accelerometer sensors.", "references": ["Mark Pedley, High Precision Calibration of a Three-Axis Accelerometer, 2013, Rev. 1, 01/2013.", "Matthias Gietzelt, Klaus-Hendrik Wolf, Michael Marschollek, Reinhold Haux, Automatic Self-Calibration of Body Worn Triaxial-Accelerometers for Application in Healthcare in Proceedings of the 2nd International Conference on Pervasive Computing Technologies for Healthcare, 2008.", "Iuri Frosio, Federico Pedersini, N. Alberto Borghese, Autocalibration of MEMS Accelerometers in IEEE Transactions On Instrumentation And Measurement, 2009, Vol. 58, No. 6."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818567.2818660"}, {"title": "VenueMusic: A Venue-Aware Music Recommender System", "authors": ["Zhiyong Cheng\n,", "Jialie Shen"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nUsers' music preferences can be greatly influenced by their location and environment nearby. In this demonstration, we present an intelligent music recommender system, called VenueMusic, to automatically identify suitable music for various popular venues in our daily lives. VenueMusic enjoys a set of nice features: i) music concept sequence generation scheme and Location-aware Topic Model (LTM) are proposed to map the characteristics of venues and music into a latent semantic space, where suitability of music for a venue can be directly measured, ii) a smart interface enabling user to smoothly interact with VenueMusic, and iii) high quality music playlist. The demonstration will show several interesting use-cases of VenueMusic, and illustrate its superiority on recommending music based on where user presents.", "references": ["Z. Cheng and J. Shen. Just-for-me: An adaptive personalization system for location-aware social music recommendation. In ACM ICMR, 2014.", "Z. Cheng and J. Shen. On effective location-aware music recommendation. Submitted to ACM TOIS, 2015.", "S. Hallam, I. Cross, and M. Thaut. Oxford Handbook of Music Psychology. Oxford University Press, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767869"}, {"title": "Affective Analysis of Professional and Amateur Abstract Paintings Using Statistical Analysis and Art Theory", "authors": ["Andreza Sartori\n,", "Victoria Yanulevskaya\n,", "Almila Akdag Salah\n,", "Jasper Uijlings\n,", "Elia Bruni\n,", "Nicu Sebe"], "publication": "ACM Transactions on Interactive Intelligent Systems", "abstract": "Abstract\nWhen artists express their feelings through the artworks they create, it is believed that the resulting works transform into objects with “emotions” capable of conveying the artists' mood to the audience. There is little to no dispute about this belief: Regardless of the artwork, genre, time, and origin of creation, people from different backgrounds are able to read the emotional messages. This holds true even for the most abstract paintings. Could this idea be applied to machines as well? Can machines learn what makes a work of art “emotional”? In this work, we employ a state-of-the-art recognition system to learn which statistical patterns are associated with positive and negative emotions on two different datasets that comprise professional and amateur abstract artworks. Moreover, we analyze and compare two different annotation methods in order to establish the ground truth of positive and negative emotions in abstract art. Additionally, we use computer vision techniques to quantify which parts of a painting evoke positive and negative emotions. We also demonstrate how the quantification of evidence for positive and negative emotions can be used to predict which parts of a painting people prefer to focus on. This method opens new opportunities of research on why a specific painting is perceived as emotional at global and local scales.", "references": ["D. E. Berlyne. 1971. Aesthetics and Psychobiology. Appleton-Century-Crofts, New York.", "P. Blank, C. Massey, H. Gardner, and E. Winner. 1984. Perceiving what paintings express. Cognitive Processes in the Perception of Art (1984), 127--143.", "D. H. Brainard. 1997. The psychophysics toolbox. Spatial Vision 10, 4 (1997)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2768209"}, {"title": "Compressed spatial hierarchical bitmap (cSHB) indexes for efficiently processing spatial range query workloads", "authors": ["Parth Nagarkar\n,", "K. Selçuk Candan\n,", "Aneesha Bhat"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn most spatial data management applications, objects are represented in terms of their coordinates in a 2-dimensional space and search queries in this space are processed using spatial index structures. On the other hand, bitmap-based indexing, especially thanks to the compression opportunities bitmaps provide, has been shown to be highly effective for query processing workloads including selection and aggregation operations. In this paper, we show that bitmap-based indexing can also be highly effective for managing spatial data sets. More specifically, we propose a novel compressed spatial hierarchical bitmap (cSHB) index structure to support spatial range queries. We consider query workloads involving multiple range queries over spatial data and introduce and consider the problem of bitmap selection for identifying the appropriate subset of the bitmap files for processing the given spatial range query workload. We develop cost models for compressed domain range query processing and present query planning algorithms that not only select index nodes for query processing, but also associate appropriate bitwise logical operations to identify the data objects satisfying the range queries in the given workload. Experiment results confirm the efficiency and effectiveness of the proposed compressed spatial hierarchical bitmap (cSHB) index structure and the range query planning algorithms in supporting spatial range query workloads.", "references": ["Apache Lucene. http://lucene.apache.org/core/4_6_0/spatial/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTree.html", "Using PostGIS: Data Management and Queries. http://postgis.net/docs/using_postgis_dbmanagement.html", "OpenStreetMap. http://www.openstreetmap.org/"], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824038"}, {"title": "Improving Search using Proximity-Based Statistics", "authors": ["Xiaolu Lu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nNo abstract available.", "references": ["C. L. Clarke, G. V. Cormack, and E. A. Tudhope. Relevance ranking for one to three term queries. Inf. Proc. & Man. 36 (2): 291--311, 2000.", "S. Huston and W. B. Croft. A comparison of retrieval models using term dependencies. In Proc. CIKM, pages 111--120, 2014.", "X. Lu, A. Moffat, and J. S. Culpepper. How effective are proximity scores in term dependency models? In Proc. ADCS, page 89, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767847"}, {"title": "An Interactive System based on Yes-No Questions for Affective Image Retrieval", "authors": ["Saemi Choi\n,", "Toshihiko Yamasaki\n,", "Kiyoharu Aizawa"], "publication": "ASM '15: Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia", "abstract": "ABSTRACT\nWe propose an interactive system based on yes-no questions for affective image retrieval. We propose two querying methods, a question generation method, Affective Question and Answer (AQA), and a feedback method, Affective Feedback (AF). Conventional image search systems ask users to input queries by text. However, it is not always easy for users to convert their intention into verbal representations. Especially, the query generation becomes even more difficult when a user tries to find images with affective words due to its subjectivity. In addition, it is not guaranteed that the images are properly annotated with enough number and high quality of tags. To solve these problems, we propose a yes-no questions-based image retrieval system that can effectively narrow down the candidate images. We also provide an affective feedback interface in which users can do the fine tuning of weights of the affective words. We conducted experiments on image retrieval task with 117,866 images. The results showed that our system brings satisfactory results to users in case where the proper text querying is difficult.", "references": ["D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In ACM MM, pages 223--232, 2013.", "R. Datta, D. Joshi, J. Li, and J. Z. Wang. Image retrieval: Ideas, influences, and trends of the new age. ACM Computing Surveys (CSUR), 40(2):5, 2008.", "A. Jahanian, J. Liu, Q. Lin, D. Tretter, E. O'Brien-Strain, S. C. Lee, N. Lyons, and J. Allebach. Recommendation system for automatic design of magazine covers. In ACM IUI, pages 95--106, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813524.2813525"}, {"title": "Crowdsourcing code and process via code hunt", "authors": ["Tao Xie\n,", "Judith Bishop\n,", "R. Nigel Horspool\n,", "Nikolai Tillmann\n,", "Jonathan de Halleux"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nCrowdsourcing programming relies on active participation. One way to get such participation is through an engaging game. Code Hunt (https://www.codehunt.com/) from Microsoft Research is a web-based serious gaming platform with the potential to be leveraged as a crowdsourcing system. In Code Hunt, players create programs by re-engineering against a changing set of test cases. The game has been played by over 100,000 players in world-wide contests, and to practice coding skills. The vast collected data of code modified by players and the process taken to succeed could be used by others for software construction, teaching, or learning. In this position paper, we discuss these existing crowdsourcing activities in Code Hunt and a future game type for crowdsourcing.", "references": ["J. Bishop, N. Horspool, T. Xie, N. Tillmann, and J. de Halleux. Code Hunt: Experience with coding contests at scale. In Proc. ICSE, JSEET, 2015.", "R. A. Cochran, L. DAntoni, B. Livshits, D. Molnar, and M. Veanes. Program boosting: Program synthesis via crowd-sourcing. In Proc. POPL, pages 677--688, 2015.", "A. Doan, R. Ramakrishnan, and A. Y. Halevy. Crowdsourcing systems on the world-wide web. Commun. ACM, 54(4):86--96, Apr. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820119"}, {"title": "Making Second Screen Sustainable in Media Production: the BRIDGET Approach", "authors": ["Alberto Messina\n,", "Francisco Morán Burgos\n,", "Marius Preda\n,", "Skjalg Lepsoy\n,", "Miroslaw Bober\n,", "Davide Bertola\n,", "Stavros Paschalakis"], "publication": "TVX '15: Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video", "abstract": "ABSTRACT\nThis paper presents work in progress of the European Commission FP7 project BRIDGET \"BRIDging the Gap for Enhanced broadcasT\". The project is developing innovative technology and the underlying architecture for efficient production of second screen applications for broadcasters and media companies. The project advancements include novel front-end authoring tools as well as back-end enabling technologies such as visual search, media structure analysis and 3D A/V reconstruction to support new editorial workflows.", "references": ["ISO/IEC FDIS 15938--13, Information technology -- Multimedia content description interface (MPEG-7) -- Part 13:Compact descriptors for visual search, Dec. 2014.", "S. Husain and M. Bober, \"Robust and scalable aggregation of local features for ultra large scale retrieval,\" in IEEE International Conference on Image Processing, Paris, France, Oct. 2014.", "ISO/IEC 23000--13:2014, Information technology -- Multimedia application format (MPEG-A) -- Part 13: Augmented reality application format (ARAF), ISO, May 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745197.2755517"}, {"title": "Parallel Streaming Signature EM-tree: A Clustering Algorithm for Web Scale Applications", "authors": ["Christopher Michael De Vries\n,", "Lance De Vine\n,", "Shlomo Geva\n,", "Richi Nayak"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThe proliferation of the web presents an unsolved problem of automatically analyzing billions of pages of natural language. We introduce a scalable algorithm that clusters hundreds of millions of web pages into hundreds of thousands of clusters. It does this on a single mid-range machine using efficient algorithms and compressed document representations. It is applied to two web-scale crawls covering tens of terabytes. ClueWeb09 and ClueWeb12 contain 500 and 733 million web pages and were clustered into 500,000 to 700,000 clusters. To the best of our knowledge, such fine grained clustering has not been previously demonstrated. Previous approaches clustered a sample that limits the maximum number of discoverable clusters. The proposed EM-tree algorithm uses the entire collection in clustering and produces several orders of magnitude more clusters than the existing algorithms. Fine grained clustering is necessary for meaningful clustering in massive collections where the number of distinct topics grows linearly with collection size. These fine-grained clusters show an improved cluster quality when assessed with two novel evaluations using ad hoc search relevance judgments and spam classifications for external validation. These evaluations solve the problem of assessing the quality of clusters where categorical labeling is unavailable and unfeasible.", "references": ["D. Arthur and S. Vassilvitskii. k-means+: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, pages 1027--1035. Society for Industrial and Applied Mathematics, 2007.", "Bahman Bahmani, Benjamin Moseley, Andrea Vattani, Ravi Kumar, and Sergei Vassilvitskii. Scalable k-means+. Proceedings of the VLDB Endowment, 5(7):622--633, 2012.", "E. Bingham and H. Mannila. Random projection in dimensionality reduction: applications to image and text data. In KDD 2001, pages 245--250. ACM, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741111"}, {"title": "Discovering Credible Events in Near Real Time from Social Media Streams", "authors": ["Cody Buntain"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMy proposed research addresses fundamental deficiencies in social media-based event detection by discovering high-impact moments and evaluating their credibility rapidly. Results from my preliminary work demonstrate one can discover compelling moments by leveraging machine learning to characterize and detect bursts in keyword usage. Though this early work focused primarily on language-agnostic discovery in sporting events, it also showed promising results in adapting this work to earthquake detection. My dissertation will extend this research by adapting models to other types of high-impact events, exploring events with different temporal granularities, and finding methods to connect contextually related events into timelines. To ensure applicability of this research, I will also port these event discovery algorithms to stream processing platforms and evaluate their performance in the real-time context. To address issues of trust, my dissertation will also include developing algorithms that integrate the vast array of social media features to evaluate information credibility in near real time. Such features include structural signatures of information dissemination, the location from which a social media message was posted relative to the location of the event it describes, and metadata from related multimedia (e.g., pictures and video) shared about the event. My preliminary work also suggests methods that could be applied to social networks for stimulating trustworthy behavior and enhancing information quality. Contributions from my dissertation will primarily be practical algorithms for discovering events from various social media streams and algorithms for evaluating and enhancing the credibility of these events in near real time.", "references": ["C. A. Cassa, R. Chunara, K. Mandl, and J. S. Brownstein. Twitter as a Sentinel in Emergency Situations : Lessons from the Boston Marathon Explosions. PLOS Currents Disasters, pages 1--10, 2013.", "C. Castillo, M. Mendoza, and B. Poblete. Information credibility on twitter. In Proceedings of the 20th international conference on World wide web, WWW '11, pages 675--684, New York, NY, USA, 2011. ACM.", "E. F. Davis Iii, A. A. Alves, and D. A. Sklansky. Social Media and Police Leadership: Lessons From Boston. In New Perspectives in Policing Bulletin. Washington, DC: U.S. Department of Justice, National Institute of Justice, NCJ 244760., 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741752"}, {"title": "queryCategorizr: A Large-Scale Semi-Supervised System for Categorization of Web Search Queries", "authors": ["Mihajlo Grbovic\n,", "Nemanja Djuric\n,", "Vladan Radosavljevic\n,", "Narayan Bhamidipati\n,", "Jordan Hawker\n,", "Caleb Johnson"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nUnderstanding interests expressed through user's search query is a task of critical importance for many internet applications. To help identify user interests, web engines commonly utilize classification of queries into one or more pre-defined interest categories. However, majority of the queries are noisy short texts, making accurate classification a challenging task. In this demonstration, we present queryCategorizr, a novel semi-supervised learning system that embeds queries into low-dimensional vector space using a neural language model applied on search log sessions, and classifies them into general interest categories while relying on a small set of labeled queries. Empirical results on large-scale data show that queryCategorizr outperforms the current state-of-the-art approaches. In addition, we describe a Graphical User Interface (GUI) that allows users to query the system and explore classification results in an interactive manner.", "references": ["E. Gabrilovich, A. Broder, M. Fontoura, A. Joshi, V. Josifovski, L. Riedel, and T. Zhang. Classifying search queries using the web as a source of knowledge. ACM Transactions on the Web, 3(2):1--28, April 2009.", "D. Gayo-Avello. A survey on session detection methods in query logs and a proposal for future evaluation. Inf. Sci., 179(12):1822--1843, May 2009.", "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111--3119, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742850"}, {"title": "A Comparative Study of Online Translation Services for Cross Language Information Retrieval", "authors": ["Ali Hosseinzadeh Vahid\n,", "Piyush Arora\n,", "Qun Liu\n,", "Gareth J.F. Jones"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nTechnical advances and its increasing availability, mean that Machine Translation (MT) is now widely used for the translation of search queries in multilingual search tasks. A number of free-to-use high-quality online MT systems are now available and, although imperfect in their translation behavior, are found to produce good performance in Cross-Language Information Retrieval (CLIR) applications. Users of these MT systems in CLIR tasks generally assume that they all behave similarly in CLIR applications, and the choice of MT system is often made on the basis of convenience. We present a set of experiments which compare the impact of applying two of the best known online systems, Google and Bing translation, for query translation across multiple language pairs and for two very different CLIR tasks. Our experiments show that the MT systems perform differently on average for different tasks and language pairs, but more significantly for different individual queries. We examine the differing translation behavior of these tools and seek to draw conclusions in terms of their suitability for use in different settings.", "references": ["P. Arora, J. Foster, and G. J. F. Jones. DCU at FIRE 2013: Cross-Language !ndian News Story Search. In Forum for Information Retrieval Evaluation (FIRE 2013), New Delhi, India, 2013.", "J. Chen and Y. Bao. Information access across languages on the Web: from search engines to digital libraries. Proceedings of the American Society for Information Science and Technology, 46(1):1--14, 2009.", "B. S. Dhakar, S. K. Sinha, and K. K. Pandey. A survey of translation quality of English to Hindi online translation systems (Google and Bing). International Journal of Scientific and Research Publications, page 313, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743008"}, {"title": "Leveraging User Reviews to Improve Accuracy for Mobile App Retrieval", "authors": ["Dae Hoon Park\n,", "Mengwen Liu\n,", "ChengXiang Zhai\n,", "Haohong Wang"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSmartphones and tablets with their apps pervaded our everyday life, leading to a new demand for search tools to help users find the right apps to satisfy their immediate needs. While there are a few commercial mobile app search engines available, the new task of mobile app retrieval has not yet been rigorously studied. Indeed, there does not yet exist a test collection for quantitatively evaluating this new retrieval task. In this paper, we first study the effectiveness of the state-of-the-art retrieval models for the app retrieval task using a new app retrieval test data we created. We then propose and study a novel approach that generates a new representation for each app. Our key idea is to leverage user reviews to find out important features of apps and bridge vocabulary gap between app developers and users. Specifically, we jointly model app descriptions and user reviews using topic model in order to generate app representations while excluding noise in reviews. Experiment results indicate that the proposed approach is effective and outperforms the state-of-the-art retrieval models for app retrieval.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003.", "C. Buckley and E. M. Voorhees. Retrieval evaluation with incomplete information. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 25--32. ACM, 2004.", "A. Datta, K. Dutta, S. Kajanan, and N. Pervin. Mobilewalla: A mobile application search engine. In Mobile Computing, Applications, and Services, pages 172--187. Springer, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767759"}, {"title": "ACCAMS: Additive Co-Clustering to Approximate Matrices Succinctly", "authors": ["Alex Beutel\n,", "Amr Ahmed\n,", "Alexander J. Smola"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nMatrix completion and approximation are popular tools to capture a user's preferences for recommendation and to approximate missing data. Instead of using low-rank factorization we take a drastically different approach, based on the simple insight that an additive model of co-clusterings allows one to approximate matrices efficiently. This allows us to build a concise model that, per bit of model learned, significantly beats all factorization approaches in matrix completion. Even more surprisingly, we find that summing over small co-clusterings is more effective in modeling matrices than classic co-clustering, which uses just one large partitioning of the matrix. Following Occam's razor principle, the fact that our model is more concise and yet just as accurate as more complex models suggests that it better captures the latent preferences and decision making processes present in the real world. We provide an iterative minimization algorithm, a collapsed Gibbs sampler, theoretical guarantees for matrix approximation, and excellent empirical evidence for the efficacy of our approach. We achieve state-of-the-art results for matrix completion on Netflix at a fraction of the model complexity.", "references": ["E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed-membership stochastic blockmodels. Journal of Machine Learning Research, 9:1981--2014, 2008.", "A. Banerjee, I. Dhillon, J. Ghosh, S. Merugu, and D. S. Modha. A generalized maximum entropy approach to bregman co-clustering and matrix approximation. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 509--514. ACM, 2004.", "A. Beutel, K. Murray, C. Faloutsos, and A. J. Smola. CoBaFi: Collaborative Bayesian Filtering. In World Wide Web Conference, pages 97--108, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741091"}, {"title": "Reasoning for Complex Data: Research Initiatives on Data Science", "authors": ["Ricardo da Silva Torres"], "publication": "WebMedia '15: Proceedings of the 21st Brazilian Symposium on Multimedia and the Web", "abstract": "ABSTRACT\nThe exponential growth of digital information production and dissemination, as well as its huge diversification, introduce considerable management and access challenges. At the same time, new opportunities have been created by the development and use of analysis methods for the discovery of interesting and potentially useful patterns, present in the data sets. In this lecture, I will introduce research initiatives at Unicamp concerning the management of large volumes of Complex Data. The term Complex Data is associated with the universe of unstructured, semi-structured, and multimodal data, and therefore covers a wide variety of data as text, sound, image, video, geographic information, among others. This talk will show the versatility of ongoing research initiatives in three important applications: Information Retrieval, Multimedia Classification, and e-Science.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820426.2822360"}, {"title": "Regularised Cross-Modal Hashing", "authors": ["Sean Moran\n,", "Victor Lavrenko"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper we propose Regularised Cross-Modal Hashing (RCMH) a new cross-modal hashing model that projects annotation and visual feature descriptors into a common Hamming space. RCMH optimises the hashcode similarity of related data-points in the annotation modality using an iterative three-step hashing algorithm: in the first step each training image is assigned a K-bit hashcode based on hyperplanes learnt at the previous iteration; in the second step the binary bits are smoothed by a formulation of graph regularisation so that similar data-points have similar bits; in the third step a set of binary classifiers are trained to predict the regularised bits with maximum margin. Visual descriptors are projected into the annotation Hamming space by a set of binary classifiers learnt using the bits of the corresponding annotations as labels. RCMH is shown to consistently improve retrieval effectiveness over state-of-the-art baselines.", "references": ["M. M. Bronstein, A. M. Bronstein, F. Michel, and N. Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, pages 3594--3601, 2010.", "F. Diaz. Regularizing query-based retrieval scores. In IR, pages 531--562, 2007.", "R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. Liblinear: A library for large linear classification. In JLMR, pages 1871--1874, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767816"}, {"title": "Creating accessible PDFs for conference proceedings", "authors": ["Erin Brady\n,", "Yu Zhong\n,", "Jeffrey P. Bigham"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nA responsibility we have as researchers is to disseminate the results of our research widely. A primary way we do this is through research publications. When these publications are not accessible to everyone, some readers will be excluded and the impact of our research limited. In this paper, we explore this problem in two ways. First, we report on the accessibility of 1,811 papers in the technical program of several top conferences related to accessibility and human-computer interaction. Second, we reflect on our experience making papers accessible for any CHI 2015 author who requested it. We offer thoughts on research challenges and future work that may make our community's research more accessible.", "references": ["Brudvik, J. T. and Bigham, J. P. and Cavender, A. C. and Ladner, R. E. Hunting for headings: sighted labeling vs. automatic classification of headings. Proceedings of ASSETS 2008.", "Drümmer, O., and Chang, B. PDF/UA in a Nutshell: Accessible documents with PDF. 2014. http://www.pdfa.org/publication/pdfua-in-a-nutshell/", "Hewson, A. and Tonkin, E. Supporting PDF accessibility evaluation: early results from the FixRep project. Proceedings of QQML2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746665"}, {"title": "INST: An Adaptive Metric for Information Retrieval Evaluation", "authors": ["Alistair Moffat\n,", "Peter Bailey\n,", "Falk Scholer\n,", "Paul Thomas"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nA large number of metrics have been proposed to measure the effectiveness of information retrieval systems. Here we provide a detailed explanation of one recent proposal, INST, articulate the various properties that it embodies, and describe a number of pragmatic issues that need to be taken in to account when writing an implementation. The result is a specification for a program inst_eval for use in TREC-style IR experimentation.", "references": ["P. Bailey, A. Moffat, F. Scholer, and P. Thomas. User variability and IR system evaluation. In Proc. SIGIR, pages 625--634, 2015.", "B. Carterette. System effectiveness, user models, and user utility: A conceptual framework for investigation. In Proc. SIGIR, pages 903--912, 2011.", "O. Chapelle, D. Metzler, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded relevance. In Proc. CIKM, pages 621--630, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838938"}, {"title": "Enabling open software project management data with antipatterns", "authors": ["Panos Fitsilis\n,", "Kyriakos Tilentzidis\n,", "Ilias Moustakas\n,", "Ioannis Stamelos\n,", "Dimitrios Settas"], "publication": "AcademicMindTrek '15: Proceedings of the 19th International Academic Mindtrek Conference", "abstract": "ABSTRACT\nAntipatterns describe commonly occurring solutions to problems that generate negative consequences. By defining a vocabulary of terms for commonly occurring problematic processes and implementations within organisations, antipatterns help in the identification of poor design decisions and offer suggestions on how software can be refactored or improved. Seventeen years have passed since the first publication on Software Project Management (SPM) Antipatterns. Over this period of time a considerable amount of literature has been published on SPM Antipatterns and a significant amount of antipatterns has been listed and documented on Web pages. Despite the fact that a significant body of antipattern research focuses on the identification and documentation of new antipatterns, difficulties associated with SPM antipattern searches on research databases (i.e. the ACM Portal, IEEE Xplore, the Web of Knowledge and Google Scholar) are still being reported in the relevant literature. Furthermore, leveraging from the antipatterns that are listed on Web pages and consolidating them in a single knowledge base with open access remains an open issue. This paper presents a set of tools that transform SPM antipatterns to open SPM data in order to overcome the difficulties associated with detecting and using SPM antipatterns. The common characteristic of these tools is the open data architecture that is achieved with a combination of Semantic Web, Web Interface and Open Source technologies that allows open access to SPM antipattern data, collaborative development of antipatterns, as well as intelligent detection of antipatterns that exist in software projects. These tools have lead to the creation of good quality SPM antipattern data that can be easily accessed via the Web.", "references": ["W. Brown, R. Malveau, H. McCormick, and T. Mowbray. AntiPatterns: Refactoring Software, Architectures, and Projects in Crisis. Wiley Computer publishing, 1998.", "S. Dill, R. Kumar, K. McCurley, S. Rajagopalan, D. Sivakumar, and A. Tomkins. Self-similarity in the web. ACM Trans. Inter. Tech, 2(3):205--223, 2001.", "P. Fitsilis, V. Gerogiannis, and L. Anthopoulos. Project team selection based on social networks. In Technology Management Conference (ITMC), pages 1--4. IEEE, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818187.2818286"}, {"title": "Investigating mobile broadband affordability in developing countries: a cross-national comparison", "authors": ["Jyoti Choudrie\n,", "David J. Yates\n,", "Girish J. \"Jeff\" Gulati"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nThis paper aims to identify and understand whether national policy initiatives, regulatory measures, or governance practices increase a developing nation's mobile broadband affordability. For this purpose, a cross-national multiple regression analysis of non-OECD countries is used. The results revealed that when controlling for wealth, education and other factors, competition to provide mobile services, financial investment in ICTs, and income inequality are all important variables for determining mobile broadband affordability. Findings suggest that service providers and other stakeholders are still recouping the cost of deploying the infrastructure necessary to provide mobile services, and have not yet achieved the economies of scale required for the price of mobile broadband to begin to fall, at least in the developing world. This paper provides contributions to academia, industry, and policymakers.", "references": ["Aker, J. C., & Mbiti, I. M. (2009). Mobile phones and economic development in Africa. Journal of Economic Perspectives, 24(3), 207--32.", "Alsop, R., & Heinsohn, N. (2005). Measuring empowerment in practice: Structuring analysis and framing indicators. World Bank Policy Research Working Paper 3510.", "Atkinson, R. D. (2007). Framing a national broadband policy. Commlaw Conspectus Journal of Communications Law and Policy, 16(1), 145--77."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2737875"}, {"title": "Cross-Platform Emerging Topic Detection and Elaboration from Multimedia Streams", "authors": ["Bing-Kun Bao\n,", "Changsheng Xu\n,", "Weiqing Min\n,", "Mohammod Shamim Hossain"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nWith the explosive growth of online media platforms in recent years, it becomes more and more attractive to provide users a solution of emerging topic detection and elaboration. And this posts a real challenge to both industrial and academic researchers because of the overwhelming information available in multiple modalities and with large outlier noises. This article provides a method on emerging topic detection and elaboration using multimedia streams cross different online platforms. Specifically, Twitter, New York Times and Flickr are selected for the work to represent the microblog, news portal and imaging sharing platforms. The emerging keywords of Twitter are firstly extracted using aging theory. Then, to overcome the nature of short length message in microblog, Robust Cross-Platform Multimedia Co-Clustering (RCPMM-CC) is proposed to detect emerging topics with three novelties: 1) The data from different media platforms are in multimodalities; 2) The coclustering is processed based on a pairwise correlated structure, in which the involved three media platforms are pairwise dependent; 3) The noninformative samples are automatically pruned away at the same time of coclustering. In the last step of cross-platform elaboration, we enrich each emerging topic with the samples from New York Times and Flickr by computing the implicit links between social topics and samples from selected news and Flickr image clusters, which are obtained by RCPMM-CC. Qualitative and quantitative evaluation results demonstrate the effectiveness of our method.", "references": ["L. M. Aiello, G. Petkos, C. Martin, D. Corney, S. Papadopoulos, R. Skraba, A. Göker, I. Kompatsiaris, and A. Jaimes. 2013. Sensing trending topics in Twitter. IEEE Trans. Multimedia 15, 6.", "Foteini Alvanaki, Michel Sebastian, Krithi Ramamritham, and Gerhard Weikum. 2011. EnBlogue: Emergent topic detection in Web 2.0 streams. In Proceedings of the ACM International Conference on Management of Data. 1271--1274.", "A. Banerjee, I. Dhillon, J. Ghosh, S. Merugu, and D. S. Modha. 2007. A generalized maximum entropy approach to Bregman co-clustering and matrix approximation. J. Machine Learning Research 8, 1919--1986."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2730889"}, {"title": "Theoretical Categorization of Query Performance Predictors", "authors": ["Victor Makarenkov\n,", "Bracha Shapira\n,", "Lior Rokach"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe query-performance prediction task aims at estimating the retrieval effectiveness of queries without obtaining relevance feedback from users. Most of the recently proposed predictors were empirically evaluated with various datasets to demonstrate their merits. We propose a framework for theoretical categorization and estimation of the value of query performance predictors (QPP) without empirical evaluation. We demonstrate the application of the proposed framework on four representative selected predictors and show how it emphasizes their strengths and weaknesses. The main contribution of this work is the theoretical grounded categorization of representative QPP.", "references": ["Z. Bar-Yossef and N. Kraus. Context-sensitive query auto-completion. In Proceedings of the 20th international conference on World wide web, WWW '11, pages 107--116, New York, NY, USA, 2011. ACM.", "M. Bunge. Treatise on Basic Philosophy: Ontology 1: The Furniture of the World. Riedel, Boston, 1977.", "D. Carmel and E. Y. Tov. Estimating the Query Difficulty for Information Retrieval. Synthesis Lectures on Information Concepts, Retrieval, and Services. Morgan & Claypool Publishers, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809475"}, {"title": "Online search in english as a non-native language", "authors": ["Peng Chu\n,", "Anita Komlodi\n,", "Gyöngyi Rózsa"], "publication": "ASIST '15: Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community", "abstract": "ABSTRACT\nNon-native English speakers (NNESs) often search in English due to the limited availability of information in their native language on the Web. Information seeking in a non-native language can present special challenges for users. Current research literature on non-native language search behavior is insufficient and even less is known about how online systems and tools may accommodate NNESs' needs and assist their behaviors. To gain a better understanding of user behavior and the search process of NNESs, this paper presents a study of online searching in English as a foreign language (EFL) or second-language (L2). Particular attention is paid to language selection, search challenges, query formulation and reformulation, as well as user interaction with online systems and tools. Results from eight focus groups (36 participants) and 36 questionnaires indicate NNESs face a unique set of challenges that may not be present for native speakers when searching for information in English. A user interaction model is abstracted to address the iterative and spiral search process of NNESs. Implications for design of systems and tools to assist this particular user group are discussed.", "references": ["Amato, G., Cigarrán, J., Gonzalo, J., Peters, C., & Savino, P. (2007). MultiMatch -- Multilingual/Multimedia Access to Cultural Heritage. Research and Advanced Technology for Digital Libraries, 505--508.", "Aula, A., & Kellar, M. (2009) Multilingual search strategies. CHI '09 Extended Abstracts on Human Factors in Computing Systems, New York, NY, USA, 3865--3870. DOI: 10.1145/1520340.1520585.", "Berendt, B., & Kralisch, A. (2009). A user-centric approach to identifying best deployment strategies for language tools: the impact of content and access language on Web user behaviour and attitudes. Information Retrieval, 12, 3, 380--399. DOI: 10.1007/s10791-008-9086-4."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2857070.2857110"}, {"title": "Annotating database schemas to help enterprise search", "authors": ["Eli Cortez\n,", "Philip A. Bernstein\n,", "Yeye He\n,", "Lev Novik"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn large enterprises, data discovery is a common problem faced by users who need to find relevant information in relational databases. In this scenario, schema annotation is a useful tool to enrich a database schema with descriptive keywords. In this paper, we demonstrate Barcelos, a system that automatically annotates corporate databases. Unlike existing annotation approaches that use Web oriented knowledge bases, Barcelos mines enterprise spreadsheets to find candidate annotations. Our experimental evaluation shows that Barcelos produces high quality annotations; the top-5 have an average precision of 87%.", "references": ["K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247--1250, 2008.", "M. J. Cafarella, A. Halevy, D. Z. Wang, E. Wu, and Y. Zhang. Webtables: exploring the power of tables on the web. Proceedings of VLDB, (1):538--549, 2008.", "M. J. Cafarella, J. Madhavan, and A. Y. Halevy. Web-scale extraction of structured data. SIGMOD Record, pages 55--61, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824105"}, {"title": "In Situ Insights", "authors": ["Yuanhua Lv\n,", "Ariel Fuxman"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWhen consuming content in applications such as e-readers, word processors, and Web browsers, users often see mentions to topics (or concepts) that attract their attention. In a scenario of significant practical interest, topics are explored in situ, without leaving the context of the application: The user selects a mention of a topic (in the form of continuous text), and the system subsequently recommends references (e.g., Wikipedia concepts) that are relevant in the context of the application. In order to realize this experience, it is necessary to tackle challenges that include: users may select any continuous text, even potentially noisy text for which there is no corresponding reference in the knowledge base; references must be relevant to both the user selection and the text around it; and the real estate available on the application may be constrained, thus limiting the number of results that can be shown.\nIn this paper, we study this novel recommendation task, that we call in situ insights: recommending reference concepts in response to a text selection and its context in-situ of a document consumption application. We first propose a selection-centric context language model and a selection-centric context semantic model to capture user interest. Based on these models, we then measure the quality of a reference concept across three aspects: selection clarity, context coherence, and concept relevance. By leveraging all these aspects, we put forward a machine learning approach to simultaneously decide if a selection is noisy, and filter out low-quality candidate references. In order to quantitatively evaluate our proposed techniques, we construct a test collection based on the simulation of the in situ insights scenario using crowdsourcing in the context of a real-word e-reader application. Our experimental evaluation demonstrates the effectiveness of the proposed techniques.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of thestate-of-the-art and possible extensions. IEEE TKDE, 17(6):734--749, June 2005.", "R. Agrawal, S. Gollapudi, A. Kannan, and K. Kenthapadi. Enriching textbooks with images. In CIKM '11, pages 1847--1856, 2011.", "K. Balog, A. P. de Vries, P. Serdyukov, P. Thomas, and T. Westerveld. Overview of the trec 2009 entity track. In TREC '09. NIST, November 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767696"}, {"title": "FROY: exploring sentiment-based movie recommendations", "authors": ["Philip Gaag\n,", "Daniel Granvogl\n,", "Robert Jackermeier\n,", "Florian Ludwig\n,", "Johannes Rosenlöhner\n,", "Alexander Uitz"], "publication": "MUM '15: Proceedings of the 14th International Conference on Mobile and Ubiquitous Multimedia", "abstract": "ABSTRACT\nAny unassisted decision a user has to make can be difficult, even if it entails the simple task of selecting which movie to watch. The sheer volume of movies offered by streaming platforms makes this task all the more difficult and time consuming. Many platforms attempt to combat this problem through recommendation systems. These however seem more likely to be making wild suggestions than being a constructive aid to the selection process. In order to offer more accurate recommendations, we propose a system that is based on a user's current emotion, which is matched with the sentiments contained in the movies' spoken language. A study involving our newly designed mobile sentiment-based movie recommender named 'FROY' shows highly promising results. As it turns out, sentiment analysis of spoken language leads to appropriate recommendations.", "references": ["M. Uluyagmur, Z. Cataltepe and E. Tayfur, \"Content-based movie recommendation using different feature sets,\" Proceedings of the World Congress on Engineering and Computer Science, vol. 1, pp. 17-24, 2012.", "E. A. Eyjolfsdottir, G. Tilak and N. Li, \"MovieGEN: A Movie Recommendation System,\" UC Santa Barbara: Technical Report, 2010.", "J. Nessel and B. Cimpa, \"The MovieOracle - Content Based Movie Recommendations,\" Proceedings of the 2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology, vol. Vol. 3, pp. 361-364, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2836041.2841205"}, {"title": "A Personalised Reader for Crowd Curated Content", "authors": ["Gabriella Kazai\n,", "Daoud Clarke\n,", "Iskander Yusof\n,", "Matteo Venanzi"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nPersonalised news recommender systems traditionally rely on content ingested from a select set of publishers and ask users to indicate their interests from a predefined list of topics. They then provide users a feed of news items for each of their topics. In this demo, we present a mobile app that automatically learns users' interests from their browsing or twitter history and provides them with a personalised feed of diverse, crowd curated content. The app also continuously learns from the users' interactions as they swipe to like or skip items recommended to them. In addition, users can discover trending stories and content liked by other users they follow. The crowd is thus formed of the users, who as a whole act as the curators of the content to be recommended.", "references": ["F. Garcin and B. Faltings. Pen recsys: A personalized news recommender systems framework. NRS '13, pages 3--9. ACM, 2013.", "F. Garcin, F. Galle, and B. Faltings. Focal: A personalized mobile news reader. RecSys'14, pages 369--370. ACM, 2014.", "A. Said, J. Lin, A. Bellogın, and A. de Vries. A month in the life of a production news recommender system. In Proc. Workshop on Living Labs for IR Evaluation, pages 7--10. ACM, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2796552"}, {"title": "The Feasibility of Brute Force Scans for Real-Time Tweet Search", "authors": ["Yulu Wang\n,", "Jimmy Lin"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThe real-time search problem requires making ingested documents immediately searchable, which presents architectural challenges for systems built around inverted indexing. In this paper, we explore a radical proposition: What if we abandon document inversion and instead adopt an architecture based on brute force scans of document representations? In such a design, \"indexing\" simply involves appending the parsed representation of an ingested document to an existing buffer, which is simple and fast. Quite surprisingly, experiments with TREC Microblog test collections show that query evaluation with brute force scans is feasible and performance compares favorably to a traditional search architecture based on an inverted index, especially if we take advantage of vectorized SIMD instructions and multiple cores in modern processor architectures. We believe that such a novel design is worth further exploration by IR researchers and practitioners.", "references": ["N. Asadi and J. Lin. Effectiveness/efficiency tradeoffs for candidate generation in multi-stage retrieval architectures. SIGIR, 2013.", "N. Asadi, J. Lin, and M. Busch. Dynamic memory allocation policies for postings in real-time Twitter search. KDD, 2013.", "P. Boncz, M. Kersten, and S. Manegold. Breaking the memory wall in MonetDB. CACM, 51(12):77--85, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809489"}, {"title": "Discriminative Latent Feature Space Learning for Cross-Modal Retrieval", "authors": ["Xu Tang\n,", "Cheng Deng\n,", "Xinbo Gao"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nCross-modal retrieval has drawn much attention in recent years due to its wide applications. Most of existing methods only focus on relevance but overlook heterogeneity and discrimination of features from different modalities, and how to capture and correlate these heterogeneous features is still challenging in this field. Therefore, we propose a general model which jointly learns a discriminative latent feature space for effective cross-modal retrieval. Concretely, a class-specific dictionary is learned to account for each modality, and all resulting sparse codes are simultaneously mapped into a common feature space that describes and associates the cross-modal data. Moreover, label information is leveraged to discriminate different classes inside the intra-modality data and also merge the same class inside the inter-modality data. Cross-modal retrieval is finally performed over the learned common feature space. The experimental results confirmed that our cross-modal method outperforms several competing methods on two public datasets.", "references": ["D. M. Blei and M. I. Jordan. Modeling annotated data. In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 127--134, 2003.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. The Journal of Machine Learning Research, 3:993--1022, 2003.", "D. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonical correlation analysis: An overview with application to learning methods. Neural Computation, 16(12):2639--2664, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749322"}, {"title": "iCrawl: Improving the Freshness of Web Collections by Integrating Social Web and Focused Web Crawling", "authors": ["Gerhard Gossen\n,", "Elena Demidova\n,", "Thomas Risse"], "publication": "JCDL '15: Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries", "abstract": "ABSTRACT\nResearchers in the Digital Humanities and journalists need to monitor, collect and analyze fresh online content regarding current events such as the Ebola outbreak or the Ukraine crisis on demand. However, existing focused crawling approaches only consider topical aspects while ignoring temporal aspects and therefore cannot achieve thematically coherent and fresh Web collections. Especially Social Media provide a rich source of fresh content, which is not used by state-of-the-art focused crawlers. In this paper we address the issues of enabling the collection of fresh and relevant Web and Social Web content for a topic of interest through seamless integration of Web and Social Media in a novel integrated focused crawler. The crawler collects Web and Social Media content in a single system and exploits the stream of fresh Social Media content for guiding the crawler.", "references": ["Apache Nutch: Highly extensible, highly scalable Web crawler. Available online: http://nutch.apache.org/ (accessed on 23 October 2014).", "S. Abiteboul, M. Preda, and G. Cobena. Adaptive on-line page importance computation. In World Wide Web Conference, WWW '03, 2003. 10.1145/775152.775192.", "C. Aggarwal, F. Al-Garawi, and P. S. Yu. Intelligent crawling on the world wide web with arbitrary predicates. In World Wide Web Conference, pages 96--105, 2001. 10.1145/371920.371955."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2756406.2756925"}, {"title": "SciCSM: novel contrast set mining over scientific datasets using bitmap indices", "authors": ["Gangyi Zhu\n,", "Yi Wang\n,", "Gagan Agrawal"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nContrast set mining is a broadly applicable exploratory technique, which identifies interesting differences across contrast groups. The existing algorithms primarily target relational datasets with categorical attributes. There is clearly a need to apply this method to discover interesting patterns across scientific datasets, which feature arrays with numeric values. In this paper, we present a novel algorithm, SciCSM, for efficient contrast set mining over array-based datasets. We define how \"interesting\" contrast sets can be characterized for numeric and array data -- handling the fact that subsets can involve both value-based and/or dimension-based attributes. We extensively use bitmap indices to reduce computational complexity and enable processing of larger-scale data. We demonstrate both high efficiency and effectiveness of our algorithm by using multiple real-life datasets.", "references": ["Stephen D Bay and Michael J Pazzani. Detecting group differences: Mining contrast sets. Data Mining and Knowledge Discovery, 5(3):213--246, 2001.", "Robert J Hilderman and Terry Peckham. A statistically sound alternative approach to mining contrast sets. In Proceedings of the 4th Australia Data Mining Conference (AusDM-05), pages 157--172. Citeseer, 2005.", "Mondelle Simeon, Robert Hilderman, and Howard Hamilton. Mining interesting contrast sets. In INTENSIVE 2012, The Fourth International Conference on Resource Intensive Applications and Services, pages 14--21, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791361"}, {"title": "Constructing and Mining Web-Scale Knowledge Graphs: WWW 2015 Tutorial", "authors": ["Antoine Bordes\n,", "Evgeniy Gabrilovich"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nRecent years have witnessed a proliferation of large-scale knowledge graphs, such as Freebase, Google's Knowledge Graph, YAGO, Facebook's Entity Graph, and Microsoft's Satori. Whereas there is a large body of research on mining homogeneous graphs, this new generation of information networks are highly heterogeneous, with thousands of entity and relation types and billions of instances of vertices and edges. In this tutorial, we will present the state of the art in constructing, mining, and growing knowledge graphs. The purpose of the tutorial is to equip newcomers to this exciting field with an understanding of the basic concepts, tools and methodologies, available datasets, and open research challenges. A publicly available knowledge base (Freebase) will be used throughout the tutorial to exemplify the different techniques.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741993"}, {"title": "M-Health Solution on pre-diagnosis of larynx", "authors": ["Estefania Mayumi Fuzyi\n,", "Matheus Camilo da Silva\n,", "Sylvio Barbon"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThe study of new approaches that seek to improve the diagnosis of pathologies in the vocal folds process, is one of the main motivators for health research based on voice. Not only by the creation of new techniques, but in the use of already existing technologies using new approaches, such as the mobile technologies in fields they were never fully explored, or barely explored at all. This article is intended to further increase the development of the m-health's field, specifically the early diagnosis of the vocal fold's diseases through analysis of the fundamental frequency of the speaker's vocalization improving the support in medical decision. The result shows 95% with a minimum of 10hz difference.", "references": ["J. E. Aikens, K. Zivin, R. Trivedi, and J. D. Piette. Diabetes self-management support using mhealth and enhanced informal caregiving. Journal of diabetes and its complications, 28(2):171-176, 2014.", "O. A. Alsos, A. Das, and D. Svanæs. Mobile health it: The effect of user interface and form factor on doctor-patient communication. International journal of medical informatics, 81(1):12-28, 2012.", "R. J. Baken and R. F. Orlikoff. Clinical measurement of speech and voice. Cengage Learning, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814139"}, {"title": "Scalable Object Retrieval with Compact Image Representation from Generic Object Regions", "authors": ["Shaoyan Sun\n,", "Wengang Zhou\n,", "Qi Tian\n,", "Houqiang Li"], "publication": "ACM Transactions on Multimedia Computing, Communications, and Applications", "abstract": "Abstract\nIn content-based visual object retrieval, image representation is one of the fundamental issues in improving retrieval performance. Existing works adopt either local SIFT-like features or holistic features, and may suffer sensitivity to noise or poor discrimination power. In this article, we propose a compact representation for scalable object retrieval from few generic object regions. The regions are identified with a general object detector and are described with a fusion of learning-based features and aggregated SIFT features. Further, we compress feature representation in large-scale image retrieval scenarios. We evaluate the performance of the proposed method on two public ground-truth datasets, with promising results. Experimental results on a million-scale image database demonstrate superior retrieval accuracy with efficiency gain in both computation and memory usage.", "references": ["Bogdan Alexe, Thomas Deselaers, and Vittorio Ferrari. 2012. Measuring the objectness of image windows. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2189--2202.", "Satpathy Amit, Jiang Xudong, and Eng How-Lung. 2014. Human detection by quadratic classification on subspace of extended histogram of gradients. IEEE Transactions on Image Processing 23, 1, 287--297.", "Relja Arandjelovic and Andrew Zisserman. 2012. Three things everyone should know to improve object retrieval. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2911--2918."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818708"}, {"title": "Exploiting Relevance Feedback in Knowledge Graph Search", "authors": ["Yu Su\n,", "Shengqi Yang\n,", "Huan Sun\n,", "Mudhakar Srivatsa\n,", "Sue Kase\n,", "Michelle Vanni\n,", "Xifeng Yan"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nThe big data era is witnessing a prevalent shift of data from homogeneous to heterogeneous, from isolated to linked. Exemplar outcomes of this shift are a wide range of graph data such as information, social, and knowledge graphs. The unique characteristics of graph data are challenging traditional search techniques like SQL and keyword search. Graph query is emerging as a promising complementary search form. In this paper, we study how to improve graph query by relevance feedback. Specifically, we focus on knowledge graph query, and formulate the graph relevance feedback (GRF) problem. We propose a general GRF framework that is able to (1) tune the original ranking function based on user feedback and (2) further enrich the query itself by mining new features from user feedback. As a consequence, a query-specific ranking function is generated, which is better aligned with the user search intent. Given a newly learned ranking function based on user feedback, we further investigate whether we shall re-rank the existing answers, or choose to search from scratch. We propose a strategy to train a binary classifier to predict which action will be more beneficial for a given query. The GRF framework is applied to searching DBpedia with graph queries derived from YAGO and Wikipedia. Experiment results show that GRF can improve the mean average precision by 80% to 100%.", "references": ["Google Knowledge Graph. http://www.google.com/insidesearch/features/search/knowledge.html.", "JOptimizer. http://www.joptimizer.com.", "SPARQL 1.1. http://www.w3.org/TR/sparql11-overview."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783320"}, {"title": "Multiple beam-forming area sound enhancement (MUBASE) and stereophonic area sound reproduction (SASR) system", "authors": ["Kazuhiro Katagiri\n,", "Tokuo Yamaguchi\n,", "Takashi Yazu\n,", "Masato Nonaka"], "publication": "SA '15: SIGGRAPH Asia 2015 Emerging Technologies", "abstract": "ABSTRACT\nWe proposed a novel technology called Multiple Beam-forming Area Sound Enhancement (MUBASE) to pick up only sound in a particular area. We also proposed a technology called Stereophonic Area Sound Reproduction (SASR) to reproduce area sound with newly stereophonic effect. In this paper we present a system that users can feel high realistic sound as if they are in a remote place. The system consists of MUBASE and SASR, and operates in conjunction with images of the remote place.", "references": ["Asano, F. 2011. Array signal processing for acoustics. Corona publishing co., ltd.", "Cooper, DH., and Bauck, JL. 1989. Prospects for transaural recording. Journal of the Audio Engineering Society, Vol37, 3--9.", "Gardner, WG. 1997. 3-D audio using loudspeakers. Kluwer academic publishers."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818466.2818493"}, {"title": "Preserving the digital record of computing history", "authors": ["David Anderson"], "publication": "Communications of the ACM", "abstract": "Abstract\nReflecting on the complexities associated with maintaining rapidly changing information technology.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2770894"}, {"title": "Automatic Tuning of GRASP with Path-Relinking in data clustering with F-Race and iterated F-Race", "authors": ["Julio Cesar da Silva\n,", "Rafael de M. D. Frinhani\n,", "Ricardo Martins A. Silva\n,", "Geraldo Robson Mateus"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nIn studies that use metaheuristics although the input parameters directly influence the performance of the algorithm its definition is mostly done manually raising questions about the quality of the results. This paper aims to apply the F/I-Race in the self parameterization of GRASP with Path-Relinking in the data clustering in order to obtain better results than the manually tuned algorithms. Experiments performed with five data sets showed that the use of I/F-race contributed to achievement best results than manual tuning.", "references": ["Aiex, R. M.; Resende, M. G. & Ribeiro, C. C. (2007). \"TTT plots: a perl program to create time-to-target plots\". Optimization Letters 1.4, pp. 355-366.", "Binato, S.; de Oliveira, G. & de Araujo, J. (2002). A greedy randomized adaptive search procedure for transmission expansion planning. IEEE Transactions on Power Systems, 16(2) pp. 247-253.", "Birattari, M. & Dorigo, M. (2004). \"The problem of tuning metaheuristics as seen from a machine learning perspective.\" PhD thesis, Univerité Libre de Bruxelles, Brussels, Belgium."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814067"}, {"title": "A confirmatory approach of the Luminance-Texture-Mass model for musical timbre semantics", "authors": ["Asterios Zacharakis\n,", "Konstantinos Pastiadis"], "publication": "AM '15: Proceedings of the Audio Mostly 2015 on Interaction With Sound", "abstract": "ABSTRACT\nThis study presents a listening experiment designed to further examine the previously proposed luminance-texture-mass (LTM) model for timbral semantics. Thirty two musically trained listeners rated twenty four instrument tones on six predefined semantic scales, namely, brilliance, depth, roundness, warmth, fullness and richness. The selection of this limited set of descriptors was based on previous exploratory work. These six semantic scales were analysed through Principal Component Analysis (PCA) and Multidimensional Scaling (MDS) to produce two different timbre spaces. These timbre spaces were subsequently compared for configurational and dimensional similarity with the LTM semantic space and the direct MDS perceptual space obtained with the same stimuli. The results showed that the selected six semantic scales are adequately representing the LTM model and are fair at predicting the configurations of the sounds that result from pairwise dissimilarity ratings.", "references": ["H. Abdi. The RV coefficient and the congruence coefficient. In N. Salkind, editor, Encyclopedia of Measurement and Statistics. SAGE Publications, Inc., 2455 Teller Road, Thousand Oaks, California, 91320, United States, 2007.", "V. Alluri and P. Toiviainen. Exploring perceptual and acoustical correlates of polyphonic timbre. Music Perception, 27(3):223--242, 2010.", "A. Caclin, S. McAdams, B. K. Smith, and S. Winsberg. Acoustic correlates of timbre space dimensions: A confirmatory study using synthetic tones. Journal of the Acoustical Society of America, 118(1):471--482, July 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814895.2814898"}, {"title": "Constrained Optimization for Homepage Relevance", "authors": ["Deepak Agarwal\n,", "Shaunak Chatterjee\n,", "Yang Yang\n,", "Liang Zhang"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nThis paper considers an application of showing promotional widgets to web users on the homepage of a major professional social network site. The types of widgets include address book invitation, group join, friends' skill endorsement and so forth. The objective is to optimize user engagement under certain business constraints. User actions on each widget may have very different downstream utilities, and quantification of such utilities can sometimes be quite difficult. Since there are multiple widgets to rank when a user visits, launching a personalized model to simply optimize user engagement such as clicks is often inappropriate. In this paper we propose a scalable constrained optimization framework to solve this problem. We consider several different types of constraints according to the business needs for this application. We show through both offline experiments and online A/B tests that our optimization framework can lead to significant improvement in user engagement while satisfying the desired set of business objectives.", "references": ["D. Agarwal and B.-C. Chen. Regression-based latent factor models. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 19--28. ACM, 2009.", "D. Agarwal, B.-C. Chen, and P. Elango. Spatio-temporal models for estimating click-through rate. In Proceedings of the 18th international conference on World wide web, pages 21--30. ACM, 2009.", "D. Agarwal, B.-C. Chen, P. Elango, and X. Wang. Personalized click shaping through lagrangian duality for online recommendation. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pages 485--494. ACM, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2745398"}, {"title": "Opportunities and Challenges of Global Network Cameras", "authors": ["Joanna Batstone\n,", "Touradj Ebrahimi\n,", "Tiejun Huang\n,", "Yung-Hsiang Lu\n,", "Yonggang Wen"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nSince the introduction of consumer digital cameras, user-created multimedia content has become increasingly popular. Digital cameras, together with inexpensive editing tools, and free hosting sites have made multimedia an integral part of everyday life. Today, hundreds of hours video are uploaded to hosting sites every minute. Video-on-demand through wireless networks and smartphones have profoundly changed how people consume multimedia content. Meanwhile, the widely deployed network cameras can provide live views of many parts of the world. These cameras can provide rich sources creating multimedia content. This panel will explore the opportunities and discuss the challenges using global network cameras for creating multimedia contents and understanding the world. Every year, millions of network cameras are deployed. The data from some of these network cameras are publicly available, continuously streaming live views of national parks, city halls, streets, highways, and shopping malls. A person may see multiple tourist attractions through these cameras, without leaving home. Researchers may observe the weather in different cities. Using the data from the cameras, it is possible to observe natural disasters, such as volcano eruption or tsunami, at a safe distance. News reporters may obtain instant views of an unfolding riot without risking their lives. A spectator may watch a celebration parade from multiple locations using the street cameras. Despite the many promising applications, the opportunities of using global network cameras for creating multimedia content have not been fully exploited.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806282"}, {"title": "Image Popularity Prediction in Social Media Using Sentiment and Context Features", "authors": ["Francesco Gelli\n,", "Tiberio Uricchio\n,", "Marco Bertini\n,", "Alberto Del Bimbo\n,", "Shih-Fu Chang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nImages in social networks share different destinies: some are going to become popular while others are going to be completely unnoticed. In this paper we propose to use visual sentiment features together with three novel context features to predict a concise popularity score of social images. Experiments on large scale datasets show the benefits of proposed features on the performance of image popularity prediction. Exploiting state-of-the-art sentiment features, we report a qualitative analysis of which sentiments seem to be related to good or poor popularity. To the best of our knowledge, this is the first work understanding specific visual sentiments that positively or negatively influence the eventual popularity of images.", "references": ["Y. Bae and H. Lee. Sentiment analysis of Twitter audiences: Measuring the positive or negative influence of popular twitterers. JASIST, 63(12):2521--2535, 2012.", "D. Borth, R. Ji, T. Chen, T. Breuel, and S.-F. Chang. Large-scale visual sentiment ontology and detectors using adjective noun pairs. In Proc. of ACM MM, 2013.", "K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the devil in the details: Delving deep into convolutional nets. In Proc. of BMVC, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806361"}, {"title": "Thematically Analysing Social Network Content During Disasters Through the Lens of the Disaster Management Lifecycle", "authors": ["Sophie Parsons\n,", "Peter M. Atkinson\n,", "Elena Simperl\n,", "Mark Weal"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSocial Networks such as Twitter are often used for disseminating and collecting information during natural disasters. The potential for its use in Disaster Management has been acknowledged. However, more nuanced understanding of the communications that take place on social networks are required to more effectively integrate this information into the processes within disaster management. The type and value of information shared should be assessed, determining the benefits and issues, with credibility and reliability as known concerns. Mapping the tweets in relation to the modelled stages of a disaster can be a useful evaluation for determining the benefits/drawbacks of using data from social networks, such as Twitter, in disaster management. A thematic analysis of tweets' content, language and tone during the UK Storms and Floods 2013/14 was conducted. Manual scripting was used to determine the official sequence of events, and classify the stages of the disaster into the phases of the Disaster Management Lifecycle, to produce a timeline. Twenty-five topics discussed on Twitter emerged, and three key types of tweets, based on the language and tone, were identified. The timeline represents the events of the disaster, according to the Met Office reports, classed into B. Faulkner's Disaster Management Lifecycle framework. Context is provided when observing the analysed tweets against the timeline. This illustrates a potential basis and benefit for mapping tweets into the Disaster Management Lifecycle phases. Comparing the number of tweets submitted in each month with the timeline, suggests users tweet more as an event heightens and persists. Furthermore, users generally express greater emotion and urgency in their tweets.\nThis paper concludes that the thematic analysis of content on social networks, such as Twitter, can be useful in gaining additional perspectives for disaster management. It demonstrates that mapping tweets into the phases of a Disaster Management Lifecycle model can have benefits in the recovery phase, not just in the response phase, to potentially improve future policies and activities.", "references": ["Alexander, D. 2005. Towards the development of a standard in emergency planning. Disaster Prevention and Management. 14, 2. 158--175.", "Asmatullah, V., & Himayatullah, K. 2008. Disaster Management Cycle - A Theoretical Approach. Management and Marketing -- Craiova. 1, 43--50.", "Bruns, A., and Stieglitz, S. 2012 Quantitative Approaches to Comparing Communication Patterns on Twitter . Journal of Technology in Human Services. 30, 3--4. 60--185."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2741721"}, {"title": "Different Users, Different Opinions: Predicting Search Satisfaction with Mouse Movement Information", "authors": ["Yiqun Liu\n,", "Ye Chen\n,", "Jinhui Tang\n,", "Jiashen Sun\n,", "Min Zhang\n,", "Shaoping Ma\n,", "Xuan Zhu"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSatisfaction prediction is one of the prime concerns in search performance evaluation. It is a non-trivial task for two major reasons: (1) The definition of satisfaction is rather subjective and different users may have different opinions in satisfaction judgement. (2) Most existing studies on satisfaction prediction mainly rely on users' click-through or query reformulation behaviors but there are many sessions without such kind of interactions. To shed light on these research questions, we construct an experimental search engine that could collect users' satisfaction feedback as well as mouse click-through/movement data. Different from existing studies, we compare for the first time search users' and external assessors' opinions on satisfaction. We find that search users pay more attention to the utility of results while external assessors emphasize on the efforts spent in search sessions. Inspired by recent studies in predicting result relevance based on mouse movement patterns (namely motifs), we propose to estimate the utilities of search results and the efforts in search sessions with motifs extracted from mouse movement data on search result pages (SERPs). Besides the existing frequency-based motif selection method, two novel selection strategies (distance-based and distribution-based) are also adopted to extract high quality motifs for satisfaction prediction. Experimental results on over 1,000 user sessions show that the proposed strategies outperform existing methods and also have promising generalization capability for different users and queries.", "references": ["M. Ageev, D. Lagun, and E. Agichtein. Improving search result summaries by using searcher behavior data. In SIGIR'13, pages 13--22. ACM, 2013.", "I. Arapakis, M. Lalmas, and G. Valkanas. Understanding within-content engagement through pattern analysis of mouse gestures. In CIKM'14, pages 1439--1448. ACM, 2014.", "J. Cohen. Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit. Psychological bulletin, 70(4):213, 1968."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767721"}, {"title": "Nudging Grocery Shoppers to Make Healthier Choices", "authors": ["Elizabeth Wayman\n,", "Sriganesh Madhvanath"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nDespite the rampant increase in obesity rates and concomitant increases in rates of mortality from heart disease, cancer and diabetes, getting the general public to adopt a healthy diet has proven to be challenging for a variety of reasons. In this paper, we describe Foodle, a research project aimed at providing automated, personalized and goal-driven dietary guidance to users based on their grocery receipt data, by leveraging the availability of digital receipts for grocery store purchases. We discuss challenges faced, the current state of the project, and directions for future work.", "references": ["A Brief History of USDA Food Guides: 2011.", "Armstrong, K. 2010. Stumped at the Supermarket. Technical Report. Public Health Law Center, William Mitchell College of Law, St. Paul, Minnesota.", "Carol Byrd-Bredbenner, C.A.B. 2010. Assessing the home food environment nutrient supply using mobile barcode (Universal Product Code) scanning technology. Nutrition & Food Science. 40, 3 (2010), 305--313."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799669"}, {"title": "Transfer Learning on High Variety Domains for Activity Recognition", "authors": ["Josh Jia-Ching Ying\n,", "Bo-Hau Lin\n,", "Vincent S. Tseng\n,", "Sun-Yuan Hsieh"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe research topic on transfer learning task has attracted a lot of attentions in recent years due to the wide applications. Although a number of transfer learning techniques have been developed, basically they were designed in the manner of learning and transferring among multiple source domains and it was assumed that the source domains and target domain share the same feature space. However, with the high variety issue under big data environments, this assumption violates the scenario of many real-world applications like activity recognition. In this paper, we propose a novel approach for transfer learning on activity recognition with the new concept of transfer learning on high variety domains. The core idea of our transferring model is based on theoretical statistic hypothesis tests, Kolmogorov-Smirnov test and x2 goodness of fit test, which evaluate how well a domain is covered by another domain based on similarity between each pair of features. Through comprehensive evaluations by experiments, our proposal is shown to deliver excellent effectiveness and substantially outperform state-of-the-art multiple source domain transfer learning methods. To our best knowledge, this is the first work that explores the problem of transfer learning on high variety domains for activity recognition with promising potential in wide applications.", "references": ["Altun, K., Barshan, B., and Tunçel, O. 2010. Comparative study on classifying human activities with miniature inertial and magnetic sensors. Pattern Recognition, 43(10), 3605--3620.", "Anguita, D., Ghio, A., Oneto, L., Parra, X., and Reyes-Ortiz, J. L. 2012. Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine. In Proceedings of Ambient assisted living and home care. 216--223.", "Fasano, G., and Franceschini, A. 1987. A multidimensional version of the Kolmogorov--Smirnov test. Monthly Notices of the Royal Astronomical Society, 225(1), 155--170."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818890"}, {"title": "CAN: composable accessibility infrastructure via data-driven crowdsourcing", "authors": ["Yun Huang\n,", "Brian Dobreski\n,", "Bijay Bhaskar Deo\n,", "Jiahang Xin\n,", "Natã Miccael Barbosa\n,", "Yang Wang\n,", "Jeffrey P. Bigham"], "publication": "W4A '15: Proceedings of the 12th Web for All Conference", "abstract": "ABSTRACT\nDespite persistent effort, many web pages are still not accessible to everyone. Fixing web accessibility problems can be complicated. Developers need to have extensive knowledge not only of possible accessibility problems but also of approaches for fixing them. This paper is about using the large number of accessibility issues on real websites and crowd-sourced fixes for them as a unique source of learning materials for web developers to learn how to build accessible components in a cost-efficient manner. In this paper, we present the design, development and study of CAN (Composable Accessibility Infrastructure), a crowdsourcing infrastructure that collects web accessibility issues and their fixes, dynamically composes solutions on-the-fly, and delivers the crowd-sourced content as teaching materials. Our unique CAN user interaction and system design enables end users with disabilities to both benefit from and contribute to the system without additional effort in their daily web browsing, and allows web developers to experience real accessibility issues and initiate a learning process with first-hand materials. CAN also provides an opportunity for data-driven discovery of the common implementation practices that cause accessibility issues. We show how CAN addresses a set of accessibility issues on the top 100 popular websites. We also present our user study results where web developers who had varying knowledge of web accessibility all found our system an effective and interesting platform to learning web accessibility.", "references": ["Algorithms Contrast Ratio or Contrast/Brightness Difference. http://gmazzocato.altervista.org/colorwheel/.", "CAN Developer Accessibility Tool. https://chrome.google.com/webstore/detail/developer-accessibility-t/fcngonjbamdeknokaghjgdgkbgcdahdl.", "CAN End User Tool - Enhance Web Page Accessibility. https://chrome.google.com/webstore/detail/enhance-web-page-accessib/mceoeijcofnglhhnanfinbemamafooma."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2745555.2746651"}, {"title": "Optimal Spatial Dominance: An Effective Search of Nearest Neighbor Candidates", "authors": ["Xiaoyang Wang\n,", "Ying Zhang\n,", "Wenjie Zhang\n,", "Xuemin Lin\n,", "Muhammad Aamir Cheema"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nIn many domains such as computational geometry and database management, an object may be described by multiple instances (points). Then the distance (or similarity) between two objects is captured by the pair-wise distances among their instances. In the past, numerous nearest neighbor (NN) functions have been proposed to define the distance between objects with multiple instances and to identify the NN object. Nevertheless, considering that a user may not have a specific NN function in mind, it is desirable to provide her with a set of NN candidates. Ideally, the set of NN candidates must include every object that is NN for at least one of the NN functions and must exclude every non-promising object. However, no one has studied the problem of NN candidates computation from this perspective. Although some of the existing works aim at returning a set of candidate objects, they do not focus on the NN functions while computing the candidate objects. As a result, they either fail to include an NN object w.r.t. some NN functions or include a large number of unnecessary objects that have no potential to be the NN regardless of the NN functions.\nMotivated by this, we classify the existing NN functions for objects with multiple instances into three families by characterizing their key features. Then, we advocate three spatial dominance operators to compute NN candidates where each operator is optimal w.r.t. different coverage of NN functions. Efficient algorithms are proposed for the dominance check and corresponding NN candidates computation. Extensive empirical study on real and synthetic datasets shows that our proposed operators can significantly reduce the number of NN candidates. The comprehensive performance evaluation demonstrates the efficiency of our computation techniques.", "references": ["P. K. Agarwal, B. Aronov, S. Har-Peled, J. M. Phillips, K. Yi, and W. Zhang. Nearest neighbor searching under uncertainty II. In PODS, pages 115--126, 2013.", "P. K. Agarwal, A. Efrat, S. Sankararaman, and W. Zhang. Nearest-neighbor searching under uncertainty. In PODS, pages 225--236, 2012.", "L. Antova, T. Jansen, C. Koch, and D. Olteanu. Fast and simple relational processing of uncertain data. In ICDE, pages 983--992, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2749442"}, {"title": "Efficient Visualisation of the Relative Distribution of Keyword Search Results in a Corpus Data Cube", "authors": ["Mark Sifer\n,", "Yutaka Watanobe\n,", "Subhash Bhalla"], "publication": "DOLAP '15: Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP", "abstract": "ABSTRACT\nMost keyword searches target precision for finding the most relevant document. However some target recall, finding all relevant documents. Our system supports high recall searches that return hundreds or thousands of relevant results. In particular, it provides a visualization that shows the distribution of search results relative to the distribution of items for the entire corpus. Such relative distributional features include over and under representation, clusters and outliers. The contribution of this paper is efficient visualisation, that is, how to provide the best relative distribution view for a given data cube size. This requirement is translated to: for which limited size meta-data summary cube are search results disambiguated the most in our relative distribution view. We identify metrics and several algorithms for such a summary cube selection.", "references": ["S. Chaudhuri and U. Dayal. An overview of data warehousing and OLAP technology. ACM SIGMOD Record, 26 (1): 65--74, 1997.", "Flamenco faceted search system. http://flamenco.berkeley.edu/.", "M. Handcock and M. Morris. Relative Distribution Methods. Social Methodology, 28 (1): 53--97, 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811222.2811234"}, {"title": "Entity Linking in Queries: Tasks and Evaluation", "authors": ["Faegheh Hasibi\n,", "Krisztian Balog\n,", "Svein Erik Bratsberg"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nAnnotating queries with entities is one of the core problem areas in query understanding. While seeming similar, the task of entity linking in queries is different from entity linking in documents and requires a methodological departure due to the inherent ambiguity of queries. We differentiate between two specific tasks, semantic mapping and interpretation finding, discuss current evaluation methodology, and propose refinements. We examine publicly available datasets for these tasks and introduce a new manually curated dataset for interpretation finding. To further deepen the understanding of task differences, we present a set of approaches for effectively addressing these tasks and report on experimental results.", "references": ["Yahoo! Webscope L24 dataset - Yahoo! search query log to entities, v1.0. URL http://webscope.sandbox.yahoo.com/.", "A. Alasiry, M. Levene, and A. Poulovassilis. Detecting candidate named entities in search queries. In Proc. of SIGIR '12, pages 1049--1050, 2012.", "K. Balog and R. Neumayer. A test collection for entity search in DBpedia. In Proc. of SIGIR '13, pages 737--740, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809473"}, {"title": "The Benefits of Magnitude Estimation Relevance Assessments for Information Retrieval Evaluation", "authors": ["Andrew Turpin\n,", "Falk Scholer\n,", "Stefano Mizzaro\n,", "Eddy Maddalena"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMagnitude estimation is a psychophysical scaling technique for the measurement of sensation, where observers assign numbers to stimuli in response to their perceived intensity. We investigate the use of magnitude estimation for judging the relevance of documents in the context of information retrieval evaluation, carrying out a large-scale user study across 18 TREC topics and collecting more than 50,000 magnitude estimation judgments. Our analysis shows that on average magnitude estimation judgments are rank-aligned with ordinal judgments made by expert relevance assessors. An advantage of magnitude estimation is that users can chose their own scale for judgments, allowing deeper investigations of user perceptions than when categorical scales are used.\nWe explore the application of magnitude estimation for IR evaluation, calibrating two gain-based effectiveness metrics, nDCG and ERR, directly from user-reported perceptions of relevance. A comparison of TREC system effectiveness rankings based on binary, ordinal, and magnitude estimation relevance shows substantial variation; in particular, the top systems ranked using magnitude estimation and ordinal judgments differ substantially. Analysis of the magnitude estimation scores shows that this effect is due in part to varying perceptions of relevance, in terms of how impactful relative differences in document relevance are perceived to be. We further use magnitude estimation to investigate gain profiles, comparing the currently assumed linear and exponential approaches with actual user-reported relevance perceptions. This indicates that the currently used exponential gain profiles in nDCG and ERR are mismatched with an average user, but perhaps more importantly that individual perceptions are highly variable. These results have direct implications for IR evaluation, suggesting that current assumptions about a single view of relevance being sufficient to represent a population of users are unlikely to hold. Finally, we demonstrate that magnitude estimation judgments can be reliably collected using crowdsourcing, and are competitive in terms of assessor cost.", "references": ["O. Alonso and S. Mizzaro. Using crowdsourcing for TREC relevance assessment. Information Processing and Management, 48 (6): 1053--1066, 2012.", "E. G. Bard, D. Robertson, and A. Sorace. Magnitude estimation of linguistic acceptability. Language, 72 (1): 32--68, 1996.", "C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning, pages 89--96, Bonn, Germany, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767760"}, {"title": "Remnance of form", "authors": ["Sang-won Leigh\n,", "Asta Roseway\n,", "Ann Paradiso"], "publication": "Interactions", "abstract": "Abstract\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2804081"}, {"title": "Probabilistic Multileave for Online Retrieval Evaluation", "authors": ["Anne Schuth\n,", "Robert-Jan Bruintjes\n,", "Fritjof Buüttner\n,", "Joost van Doorn\n,", "Carla Groenland\n,", "Harrie Oosterhuis\n,", "Cong-Nguyen Tran\n,"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nOnline evaluation methods for information retrieval use implicit signals such as clicks from users to infer preferences between rankers. A highly sensitive way of inferring these preferences is through interleaved comparisons. Recently, interleaved comparisons methods that allow for simultaneous evaluation of more than two rankers have been introduced. These so-called multileaving methods are even more sensitive than their interleaving counterparts. Probabilistic interleaving--whose main selling point is the potential for reuse of historical data--has no multileaving counterpart yet. We propose probabilistic multileave and empirically show that it is highly sensitive and unbiased. An important implication of this result is that historical interactions with multileaved comparisons can be reused, allowing for ranker comparisons that need much less user interaction data. Furthermore, we show that our method, as opposed to earlier sensitive multileaving methods, scales well when the number of rankers increases.", "references": ["O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue. Large-scale validation and analysis of interleaved search evaluation. ACM Trans. Inf. Syst., 30 (1), 2012.", "C. W. Cleverdon, J. Mills, and M. Keen. Factors determining the performance of indexing systems. Aslib cranfield project, Cranfield: College of Aeronautics, 1966.", "F. Guo, C. Liu, and Y. M. Wang. Efficient multiple-click models in web search. In WSDM '09. ACM, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767838"}, {"title": "Representative & Informative Query Selection for Learning to Rank using Submodular Functions", "authors": ["Rishabh Mehrotra\n,", "Emine Yilmaz"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nThe performance of Learning to Rank algorithms strongly depend on the number of labelled queries in the training set, while the cost incurred in annotating a large number of queries with relevance judgements is prohibitively high. As a result, constructing such a training dataset involves selecting a set of candidate queries for labelling. In this work, we investigate query selection strategies for learning to rank aimed at actively selecting unlabelled queries to be labelled so as to minimize the data annotation cost. %total number of labelled queries -- without degrading the ranking performance. In particular, we characterize query selection based on two aspects of \\emph{informativeness} and \\emph{representativeness} and propose two novel query selection strategies (i) Permutation Probability based query selection and (ii) Topic Model based query selection which capture the two aspects, respectively. We further argue that an ideal query selection strategy should take into account both these aspects and as our final contribution, we present a submodular objective that couples both these aspects while selecting query subsets. We evaluate the quality of the proposed strategies on three real world learning to rank datasets and show that the proposed query selection methods results in significant performance gains compared to the existing state-of-the-art approaches.", "references": ["J. A. Aslam, E. Kanoulas, V. Pavlu, S. Savev, and E. Yilmaz. Document selection methodologies for efficient and effective learning-to-rank. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 468--475. ACM, 2009.", "M. Bilgic and P. N. Bennett. Active query selection for learning rankers. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pages 1033--1034. ACM, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. the Journal of machine Learning research, 3:993--1022, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767753"}, {"title": "A coarse-to-fine method for subsequence matching of human behavior using multi-dimensional time-series approximation", "authors": ["Kosuke Sugano\n,", "Yu Fang\n,", "Kenta Oku\n,", "Kyoji Kawagoe"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nIn this paper, a novel method for subsequence matching of human behaviors is proposed. Since the human behavior data taken from many sensors monitoring human motions is a multi-dimensional time series, we extend an existing time-series approximation method, A-LTK (Approximation with use of Local features at Thinned-out Keypoints), to improve its performance as well as its accuracy in subsequence matching. Since A-LTK can change its approximation level using a parameter, the approach introduced in this paper uses two types of A-LTK levels, coarse followed by fine. The A-LTK-based Coarse-to-Fine subsequence matching method, called A-LTK 2.0, is discussed. We also evaluate the method, by comparing it with existing matching methods, DTW, AMSS, and the original A-LTK. The evaluations showed that A-LTK 2.0 is superior to the others in subsequence matching for long human-behavior sequences.", "references": ["http://www.optitrack.com/", "http://www.microsoft.com/en-us/kinectforwindows/", "Y. Fang, D. X. Huy, H.-H. Huang, and K. Kawagoe. Multi-dimensional Time Series Approximation Using Local Features at Thinned-out Keypoints. Journal of Computers, 10(1), pages 1--11, Jan. 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837192"}, {"title": "Towards persuasive social recommendation: knowledge model", "authors": ["Javier Palanca\n,", "Stella Heras\n,", "Javier Jorge\n,", "Vicente Julian"], "publication": "ACM SIGAPP Applied Computing Review", "abstract": "Abstract\nThe exponential growth of social networks makes fingerprint let by users on the Internet a great source of information, with data about their preferences, needs, goals, profile and social environment. These data are distributed across different sources of information (social networks, blogs, databases, etc.) that may contain inconsistencies and their accuracy is uncertain. Paradoxically, this unprecedented availability of heterogeneous data has meant that users have more information available than they actually are able to process and understand to extract useful knowledge from it. Therefore, new tools that help users in their decision-making processes within the network (e.g. which friends to contact with or which products to consume) are needed. In this paper, we show how we have used a graph-based model to extract and model data and transform it in valuable knowledge to develop a persuasive social recommendation system.", "references": ["Desel, J., Pernici, B., Weske, M. Mining Social Networks: Uncovering Interaction Patterns in Business Processes. Business Process Management, Berlin, vol. 3080, pp. 244--260 (2004)", "Adomavicius, G., Tuzhilin, A.: Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Trans. on KDE 17(6) (2005) 734--749", "X. Zhou, Y. Xu, Y. Li, A. Josang, and C. Cox, \"The state-of-the-art in personalized recommender systems for social networking,\" Artificial Intelligence Review, vol. 37, no. 2, pp. 119--132, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815169.2815173"}, {"title": "Risk-Hedged Venture Capital Investment Recommendation", "authors": ["Xiaoxue Zhao\n,", "Weinan Zhang\n,", "Jun Wang"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nWith the increasing accessibility of transactional data in venture finance, venture capital firms (VCs) face great challenges in developing quantitative tools to identify new investment opportunities. Recommendation techniques have the possibility of helping VCs making data-driven investment decisions by providing an automatic screening process of a large number of startups across different domains on the basis of their past investment data. A previous study has shown the potential advantage of using collaborative filtering to catch and predict the VCs' investment behaviours. However, two fundamental challenges in venture finance make conventional recommendation techniques difficult to apply. First, risk factors should be cautiously considered when making investments: for a potential startup, a VC needs to specifically estimate how well this new investment can fit into its holding investment portfolio in such a way that investment risk can be hedged. Second, The investment behaviours are much sparser than conventional recommendation applications and a VC's investments are usually limited to a few industry categories, making it impossible to use a topic-diversification method to hedge the risk. In this paper, we solve the startup recommendation problem from a risk management perspective. We propose 5 risk-aware startup selection and ranking algorithms to catch the VCs' investment behaviours and predict their new investments. Apart from the contribution on the new risk-aware recommendation model, our experiments on the collected CrunchBase dataset show significant performance improvements over strong baselines.", "references": ["O. T. Alexy, J. H. Block, P. Sandner, and A. L. Ter Wal. Social capital of venture capitalists and start-up funding. Small Business Economics, 39(4):835--851, 2012.", "S. Anthony. Is venture capital broken? Harvard Business Review Blog, 2012.", "T. Bhaskar and G. Subramanian. Loan recommender system for microfinance loans: Increasing efficiency to assist growth. Journal of Financial Services Marketing, 15(4):334--345, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800181"}, {"title": "Where you Instagram?: Associating Your Instagram Photos with Points of Interest", "authors": ["Xutao Li\n,", "Tuan-Anh Nguyen Pham\n,", "Gao Cong\n,", "Quan Yuan\n,", "Xiao-Li Li\n,", "Shonali Krishnaswamy"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nInstagram, an online photo-sharing platform, has gained increasing popularity. It allows users to take photos, apply digital filters and share them with friends instantaneously by using mobile devices.Instagram provides users with the functionality to associate their photos with points of interest, and it thus becomes feasible to study the association between points of interest and Instagram photos. However, no previous work studies the association. In this paper, we propose to study the problem of mapping Instagram photos to points of interest. To understand the problem, we analyze Instagram datasets, and report our findings, which also characterize the challenges of the problem. To address the challenges, we propose to model the mapping problem as a ranking problem, and develop a method to learn a ranking function by exploiting the textual, visual and user information of photos. To maximize the prediction effectiveness for textual and visual information, and incorporate the users' visiting preferences, we propose three subobjectives for learning the parameters of the proposed ranking function. Experimental results on two sets of Instagram data show that the proposed method substantially outperforms existing methods that are adapted to handle the problem.", "references": ["Y. Avrithis, Y. Kalantidis, G. Tolias, and E. Spyrou. Retrieving landmark and non-landmark images from community photo collections. In Proceedings of ICM, pages 153--162. ACM, 2010.", "L. Backstrom, E. Sun, and C. Marlow. Find me if you can: improving geographical prediction with social and spatial proximity. In Proceedings of WWW, pages 61--70. ACM, 2010.", "W.-C. Chen, A. Battestini, N. Gelfand, and V. Setlur. Visual summaries of popular landmarks from community photo collections. In The Forty-Third Asilomar Conference on Signals, Systems and Computers, pages 1248--1255. IEEE, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806463"}, {"title": "Applying a customer centric development approach for web 2.0 applications", "authors": ["Athina Nikou\n,", "Ioannis Chatzigiannakis"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this work we demonstrate our experiences on applying a customer centric approach to the development of an electronic food ordering Web 2.0 application. Placing customers at the core, interacting with them in a reiterative way and gaining insights from their feedback can be leveraged to create a serviceable product. Combining this approach with the use of existing Web 2.0 APIs simplifies and shortens the development procedure. To scrutinize consumers' viewpoint of electronic food ordering applications we conducted a survey composed of rapid customer-focused iterations. This survey constituted a guideline on developing our application based on customers feedback.", "references": ["D. Gage. The venture capital secret: 3 out of 4 start-ups fail. The Wall Street Journal, 2012.", "M. Poppendieck and T. Poppendieck. Lean Software Development: An Agile Toolkit. Addison-Wesley Longman Publishing Co., 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802020"}, {"title": "Brief Announcement: Fault-tolerant Broadcast in Anonymous Distributed Systems with Fair Lossy Communication Channels", "authors": ["Jian Tang\n,", "Mikel Larrea\n,", "Sergio Arévalo\n,", "Ernesto Jiménez"], "publication": "PODC '15: Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing", "abstract": "ABSTRACT\nFault-tolerant broadcast is a fundamental service in distributed systems, by which processes can communicate with each other consistently and reliably. It has two main forms: Reliable Broadcast (RB) and Uniform Reliable Broadcast (URB). This service has been extensively investigated in non-anonymous distributed systems where processes have unique identifers, usually assume the communication channels are reliable, which is not always the case in real systems. In this paper, the fault-tolerant broadcast service is studied in an anonymous asynchronous message passing distributed system model with fair lossy communication channels. Firstly, two simple and non-quiescent algorithms implementing RB and URB are given. Secondly, two new classes of failure detectors A_Theta and AP* are proposed. Finally, with the information provided by A_Theta and AP*, quiescent algorithms for both RB and URB are given.", "references": ["C. Cachin, R. Guerraoui, and L. Rodrigues. Reliable and secure distributed programming. Springer (second edition), 2011.", "F. Schneider, D. Gries, and R. Schlichting. Fault-tolerant broadcast. Science of Computer Programming 4(1), pp. 1--15, 1984.", "V. Hadzilacos and S. Toueg. Fault tolerant broadcasts and related problems. S.J. Mullender (Ed.), Distributed Systems. New York: ACM Press & Addison-Wesley, 1993."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2767386.2767443"}, {"title": "Large-Scale Cross-Language Web Page Classification via Dual Knowledge Transfer Using Fast Nonnegative Matrix Trifactorization", "authors": ["Hua Wang\n,", "Feiping Nie\n,", "Heng Huang"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nWith the rapid growth of modern technologies, Internet has reached almost every corner of the world. As a result, it becomes more and more important to manage and mine information contained in Web pages in different languages. Traditional supervised learning methods usually require a large amount of training data to obtain accurate and robust classification models. However, labeled Web pages did not increase as fast as the growth of Internet. The lack of sufficient training Web pages in many languages, especially for those in uncommonly used languages, makes it a challenge for traditional classification algorithms to achieve satisfactory performance. To address this, we observe that Web pages for a same topic from different languages usually share some common semantic patterns, though in different representation forms. In addition, we also observe that the associations between word clusters and Web page classes are another type of reliable carriers to transfer knowledge across languages. With these recognitions, in this article we propose a novel joint nonnegative matrix trifactorization (NMTF) based Dual Knowledge Transfer (DKT) approach for cross-language Web page classification. Our approach transfers knowledge from the auxiliary language, in which abundant labeled Web pages are available, to the target languages, in which we want to classify Web pages, through two different paths: word cluster approximation and the associations between word clusters and Web page classes. With the reinforcement between these two different knowledge transfer paths, our approach can achieve better classification accuracy. In order to deal with the large-scale real world data, we further develop the proposed DKT approach by constraining the factor matrices of NMTF to be cluster indicator matrices. Due to the nature of cluster indicator matrices, we can decouple the proposed optimization objective and the resulted subproblems are of much smaller sizes involving much less matrix multiplications, which make our new approach much more computationally efficient. We evaluate the proposed approach in extensive experiments using a real world cross-language Web page data set. Promising results have demonstrated the effectiveness of our approach that are consistent with our theoretical analyses.", "references": ["Nuria Bel, Cornelis H. A. Koster, and Marta Villegas. 2003. Cross-lingual text categorization. Research and Advanced Technology for Digital Libraries. Lecture Notes in Computer Science, Vol. 2769. 126--139.", "John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Stroudsburg, PA, USA, 120--128.", "Gang Chen, Fei Wang, and Changshui Zhang. 2009. Collaborative filtering using orthogonal nonnegative matrix tri-factorization. Information Processing and Management 45, 3 (2009), 368--379."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2710021"}, {"title": "I2RS: a distributed geo-textual image retrieval and recommendation system", "authors": ["Lu Chen\n,", "Yunjun Gao\n,", "Zhihao Xing\n,", "Christian S. Jensen\n,", "Gang Chen"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nMassive amounts of geo-tagged and textually annotated images are provided by online photo services such as Flickr and Zommr. However, most existing image retrieval engines only consider text annotations. We present I2RS, a system that allows users to view geo-textual images on Google Maps, find hot topics within a specific geographic region and time period, retrieve images similar to a query image, and receive recommended images that they might be interested in. I2RS is a distributed geo-textual <u>i</u>mage <u>r</u>etrieval and <u>r</u>ecommendation <u>s</u>ystem that employs SPB-trees to index geo-textual images, and that utilizes metric similarity queries, including top-m spatio-temporal range and k nearest neighbor queries, to support geo-textual image retrieval and recommendation. The system adopts the browser-server model, whereas the server is deployed in a distributed environment that enables efficiency and scalability to huge amounts of data and requests. A rich set of 100 million geo-textual images crawled from Flickr is used to demonstrate that, I2RS can return high-quality answers in an interactive way and support efficient updates for high image arrival rates.", "references": ["P. Bolettieri, A. Esuli, F. Falchi, C. Lucchese, R. Perego, T. Piccioli, and F. Rabitti. CoPhIR: A test collection for content-based image retrieval. CoRR abs/0905.4627, 2009.", "M. Batko, F. Falchi, C. Lucchese, D. Novak, R. Perego, F. Rabitti, J. Sedmidubsky, and P. Zezula. Building a web-scale image similarity search system. Multimedia Tools Appl., 47(3):599--629, 2010.", "L. Chen, Y. Gao, X. Li, C. S. Jensen, and G. Chen. Efficient metric indexing for similarity search. In: ICDE, 519--602, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824092"}, {"title": "Research Collaboration and Topic Trends in Computer Science: An Analysis Based on UCP Authors", "authors": ["Yan Wu\n,", "Srinivasan Venkatramanan\n,", "Dah Ming Chiu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nAcademic publication metadata can be used to analyze the collaboration, productivity and hot topic trends of a research community. Recently, it is shown that authors with uninterrupted and continuous presence (UCP) over a time window, though small in number (about 1%), amass the majority of significant and high-influence academic output. We adopt the UCP metric to retrieve the most active authors in the Computer Science (CS) community over different time windows in the past $50$ years, and use them to analyze collaboration, productivity and topic trends. We show that the UCP authors are representative of the overall population; the community is increasingly moving in the direction of Team Research (as opposed to Soloist or Mentor-mentee research), with increased level and degree of collaboration; and the research topics become increasingly inter-related. By focusing on the UCP authors, we can more easily visualize these trends.", "references": ["J. G. Brookshear. Computer science: an overview. Addison Wesley, 2012.", "A. Clauset, M. E. Newman, and C. Moore. Finding community structure in very large networks. Physical Review E, 70(6):066111, 2004.", "Y. Gingras, V. Lariviere, B. Macaluso, and J.-P. Robitaille. The effects of aging on researchers' publication and citation patterns. PLOS ONE, 3(12):e4048, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742015"}, {"title": "Evento 360: Social Event Discovery from Web-scale Multimedia Collection", "authors": ["Jaeyoung Choi\n,", "Eungchan Kim\n,", "Martha Larson\n,", "Gerald Friedland\n,", "Alan Hanjalic"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present Evento 360 (URL: http://evento360.info), an online interactive social event browser, which allows the user to explore events detected within a web-scale multimedia corpus. The system addresses five key aspects of social multimedia event detection and summarization: multimodality, scale, diversity of representations, noise of multimedia items, and missing metadata. The detection algorithm uses unsupervised clustering approach that exploits temporal, spatial and textual metadata. For each detected event cluster, to choose the best subset of photos that meet both relevance and diversity criteria, the system uses hierarchical clustering that exploits both visual and audio information. Evento 360's user interface provides a search feature that is not limited to a certain set of events, but rather can handle an arbitrary event query. It allows the user to retrieve and explore relevant events. The system scales well and is effective in producing high-quality summaries of the detected events.", "references": ["D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "J. Cao, Z. Huang, Y. Yang, and H. T. Shen. UQ-DKE's participation at MediaEval 2014 placing task. In MediaEval Workshop 2014, 2014.", "D. Dang-Nguyen, L. Piras, G. Giacinto, G. Boato, and F. De Natale. Retrieval of diverse images by pre-filtering and hierarchical clustering. In MediaEval Workshop 2014, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2809934"}, {"title": "Session details: Main Track - Applied Technology", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252437"}, {"title": "60 Hz self-tuning background modeling", "authors": ["Jun Luo\n,", "Jinqiao Wang\n,", "La Zhang\n,", "YingYing Chen\n,", "Huazhong Xu\n,", "Hanqing Lu"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nBackground modeling or change detection is often used as a preprocessing step in many computer vision tasks especially for intelligent surveillance. Despite various methods have been proposed to deal with this problem, they often involve complex parameter settings and have poor adaptability to scene changes. In this paper, we propose a fast and robust approach for background modeling with self-adaptive ability. Like ViBe [7], each pixel model is represented by a sequence of historical samples based on sample consensus. To adapt various changes in complex scenes, a flexible feedback scheme is presented to automatically adjust the model parameters. Moreover, a selective diffusion method is employed to overcome the problems like incomplete foregrounds or false detections brought by intermittent moving objects. Experiment results on ChangeDetection benchmark 2014 show that the proposed approach outperforms state-of-the-art approaches with a speed of 60 fps on CPU for a 640 × 480 image sequence.", "references": ["E. Ahmed, H. David, and D. Larry. Non-parametric model for background subtraction. In ECCV, pages 751--767. Springer, 2000.", "Y. Chen, J. Wang, and H. Lu. Learning sharable models for robust background subtraction. In ICME. IEEE, 2015.", "Y. Chen, J. Wang, and H. Lu. Multiple features based shared models for background subtraction. In ICIP. IEEE, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808571"}, {"title": "Challenges of Mathematical Information Retrievalin the NTCIR-11 Math Wikipedia Task", "authors": ["Moritz Schubotz\n,", "Abdou Youssef\n,", "Volker Markl\n,", "Howard S. Cohl"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMathematical Information Retrieval concerns retrieving information related to a particular mathematical concept. The NTCIR-11 Math Task develops an evaluation test collection for document sections retrieval of scientific articles based on human generated topics. Those topics involve a combination of formula patterns and keywords. In addition, the optional Wikipedia Task provides a test collection for retrieval of individual mathematical formula from Wikipedia based on search topics that contain exactly one formula pattern. We developed a framework for automatic query generation and immediate evaluation. This paper discusses our dataset preparation, topic generation and evaluation methods, and summarizes the results of the participants, with a special focus on the Wikipedia Task.", "references": ["Formats for topics and submissions for the math2 task at ntcir-11. Technical report, NTCIR, 2014.", "Akiko Aizawa, Michael Kohlhase, and Iadh Ounis. NTCIR-10 Math Pilot Task Overview. In Proceedings of the 10th NTCIR Conference on Evaluation of Information Access Technologies, pages 654--661, Tokyo, Japan, 2013.", "Akiko Aizawa, Michael Kohlhase, Iadh Ounis, and Moritz Schubotz. NTCIR-11 Math-2 Task Overview. In Proceedings of the 11th NTCIR Conference on Evaluation of Information Access Technologies, pages 88--98, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767787"}, {"title": "Applying a variation of the ant colony optimization algorithm to solve the multiple traveling salesmen problem to route the teams of the electric power distribution companies", "authors": ["Denilson F. Barbosa\n,", "Carlos N. Silla\n,", "Andre Y. Kashiwabara"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents a methodology to optimize the execution of the commercial services of electric power distribution companies. This activity represents a significant portion of the operational costs of these companies. How to distribute the services to the teams and define efficient routes is a complex problem due to the great number of possible combinations. The set of geographical positions of the services can be seen as an instance of the multiple traveling salesmen problem. We created a variation of the ant colony optimization algorithm to obtain optimized solutions for the distribution of the services and the route of each team. Our methodology was applied to 17 real word instances obtained from an electric power distribution company from the city of Cornelio Procopio, Brazil. Our method obtained an improvement of 42,23% on average when compared to the solutions that were performed in the real world. To allow the reproduction of our results, the source-code of our system and the dataset are freely available at https://github.com/denilsonfag/STACS.", "references": ["J. Augustine. Offline and online variants of the traveling salesman problem. PhD thesis, Louisiana State University, Department of Electrical and Computer Engineering, 2002.", "T. Bektas. The multiple traveling salesman problem: an overview of formulations and solution procedures. Omega, 34(3):209-219, June 2006.", "C. E. d. S. Costa, D. M. B. Costa, and A. R. T. Goes. Determinação de setores de atendimento em uma concessionária de energia. In Anais do Simpósio Brasileiro de Pesquisa Operacional - SBPO, pages 951-962, Goiânia, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814063"}, {"title": "By their fruits shall ye know them: A Data Analyst's Perspective on Massively Parallel System Design", "authors": ["Holger Pirk\n,", "Sam Madden\n,", "Mike Stonebraker"], "publication": "DaMoN'15: Proceedings of the 11th International Workshop on Data Management on New Hardware", "abstract": "ABSTRACT\nIncreasingly parallel systems promise a remedy for the current stagnation of single-core performance. However, the battle to find the most appropriate architecture for the resulting massively parallel systems is still ongoing. Currently, there are two active contenders: Massively Parallel Single Instruction Multiple Threads (SIMT) systems such as GPGPUs and Many Core Single Instruction Multiple Data (SIMD) systems such as Intel's Xeon Phi. While the former is more versatile, the latter is an efficient, time-tested technology with a clear migration path. In this study, we provide a data management perspective to the debate: we study the implementation and performance of a set of common data management operations on an SIMT device (an Nvidia GTX 780) and compare it to a Many Core SIMD system (an Intel Xeon Phi). We interpret the results to pinpoint architectural decisions and tradeoffs that lead to suboptimal performance and point out potential areas for improvement in the next generation of these devices.", "references": ["Balkesen, C., Teubner, J., Alonso, G., and Ozsu, M. T. Main-memory hash joins on multi-core cpus: Tuning to the underlying hardware. In Data Engineering (ICDE), 2013 IEEE 29th International Conference on (2013), IEEE, pp. 362--373.", "Batcher, K. E. Sorting networks and their applications. In AFIPS Conference Proceedings (1968), pp. 307--314.", "Boncz, P., Neumann, T., and Erling, O. Tpc-h analyzed: Hidden messages and lessons learned from an influential benchmark. In Performance Characterization and Benchmarking. Springer, 2014, pp. 61--76."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2771937.2771944"}, {"title": "Large LDPC Codes for Big Data Storage", "authors": ["Wei Yongmei\n,", "Chen Fengmin\n,", "Lim Khai Cher"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nCurrent distributed storage systems mainly rely on data replication to ensure certain level of data availability and reliability. But in scenarios, like data archiving, replication is not cost effective and does not provides a robust solution to prevent data loss. A recent trend is to introduce erasure codes into the distributed storage. Inspired by the RAID system, early attempts have been focused on designing Reed-Solomon (R-S) based solutions with small block sizes. This paper investigates in details about repair traffic to apply Low Density Parity Check (LDPC) codes with relatively large block sizes. It has been demonstrated that the LDPC codes have unique advantages over R-S based solutions including low repair traffic for multiple erasures and parity erasures. The LDPC-based method is integrated with the Hadoop system with various configurations. Both theoretical analysis and simulations show that significant improvement in reliability can be achieved through using large LDPC codes without increasing the repair latency and network traffic especially for multiple erasures. Simulations also show great improvement in terms repairing latencies compared with Reed-Solomon codes. The latency is further improved through parallelism by engaging map-reduce processes from Hadoop.", "references": ["Bin F., Wittawat T., Lin X., Garth G., 2009. DiskReduce: RAID for Data-Intensive Scalable Computing, PDSW 09.", "Benjamin G., Birger K., Nuno S., 2007. Exploring high performance distributed file storage using LDPC codes, Journal Parallel Computing Vol. 33, Issue 4-5.", "James S. P. and Michael G. T., 2003. On the Practical Use of LDPC Erasure Codes for Distributed Storage Applications, Technical Report CS-03-510, University of Tennessee, September."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818881"}, {"title": "Atypical Queries in eCommerce", "authors": ["Neeraj Pradhan\n,", "Vinay Deolalikar\n,", "Kang Li"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUnderstanding how specific, ambiguous, or broad the intent of a search query is, across all users of the system, is important in improving search relevance in eCommerce. There is scant literature on such a structural characterization of queries in eCommerce. In this paper, we use query-click log data to address the problem of identifying \"atypical queries\": these are queries that are extremal in terms of specificity, ambiguity, or breadth of intent. We isolate three components of atypicality: geometric, statistical, and topological. We demonstrate, using query-click logs at Groupon, that certain combinations of these properties render a query atypical, and discuss how search analysts treat such queries differently. Our work is being used to improve search relevance at Groupon.", "references": ["D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg. What makes a query difficult? In Proc. SIGIR '06, pages 390--397, New York, NY, USA, 2006. ACM.", "T. M. Cover and J. A. Thomas. Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing). Wiley-Interscience, 2006.", "S. Cronen-Townsend, Y. Zhou, and W. B. Croft. Predicting query performance. In Proc. SIGIR '02, pages 299--306, New York, NY, USA, 2002. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806605"}, {"title": "HeartMapp: a mobile application to improve CHF outcomes and reduce hospital readmissions", "authors": ["Mark Di Sano\n,", "Andres Perez\n,", "Miguel A. Labrador\n,", "Ponrathi Athilingam\n,", "Federico Giovannetti"], "publication": "WH '15: Proceedings of the conference on Wireless Health", "abstract": "ABSTRACT\nCongestive Heart Failure (CHF), by its very nature, may lead to frequent hospital visits due to the complexity of managing the risk factors associated with it. Prescribed treatments for discharged patients are usually a combination of medicine, life style changing guidelines, and physical therapy. Treatment compliance is usually challenging and frustrating for both patients and providers. HeartMapp provides a multi-dimensional approach to address these issues combining patient engagement techniques, remote physiological monitoring, automation of traditional clinical protocols, and clinical decision support, all in one patient centered, self-care mobile application.", "references": ["Jencks SF, Williams MV, Coleman EA. Rehospitalizations among patients in the Medicare fee-for-service program. The New England Journal of Medicine, 2009; 360(14), 1418--1428. doi:10.1056/NEJMsa0803563; 10.1056/NEJMsa0803563.", "Go AS, Mozaffarian D, Roger VL, et al. American Heart Association Statistics Committee and Stroke Statistics Subcommittee. Executive summary: Heart disease and stroke statistics -2013 update: A report from the American Heart Association. Circulation. 2013;127(1): 143--152", "Dharmarajan K, Hsieh AF, Lin Z, et al. Diagnoses and timing of 30-day readmissions after hospitalization for heart failure, acute myocardial infarction, or pneumonia. JAMA. 2013; 309(4): 355--63. doi:10.1001/jama.2012.216476"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2811780.2811914"}, {"title": "Knowledge Curation and Knowledge Fusion: Challenges, Models and Applications", "authors": ["Xin Luna Dong\n,", "Divesh Srivastava"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nLarge-scale knowledge repositories are becoming increasingly important as a foundation for enabling a wide variety of complex applications. In turn, building high-quality knowledge repositories critically depends on the technologies of knowledge curation and knowledge fusion, which share many similar goals with data integration, while facing even more challenges in extracting knowledge from both structured and unstructured data, across a large variety of domains, and in multiple languages.\nOur tutorial highlights the similarities and differences between knowledge management and data integration, and has two goals. First, we introduce the Database community to the techniques proposed for the problems of entity linkage and relation extraction by the Knowledge Management, Natural Language Processing, and Machine Learning communities. Second, we give a detailed survey of the work done by these communities in knowledge fusion, which is critical to discover and clean errors present in sources and the many mistakes made in the process of knowledge extraction from sources. Our tutorial is example driven and hopes to build bridges between the Database community and other disciplines to advance research in this important area.", "references": ["M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction from the web. In IJCAI, 2007.", "D. Barbosa, H. Wang, and C. Yu. Shallow information extraction for the knowledge web. In ICDE, 2013.", "J. Bleiholder and F. Naumann. Data fusion. ACM Computing Surveys, 41(1):1--41, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2731083"}, {"title": "Civic crowdfunding: how do offline communities engage online?", "authors": ["Alexandra Stiver\n,", "Leonor Barroca\n,", "Marian Petre\n,", "Mike Richards\n,", "Dave Roberts"], "publication": "British HCI '15: Proceedings of the 2015 British HCI Conference", "abstract": "ABSTRACT\nCivic crowdfunding is a sub-type of crowdfunding whereby citizens contribute to funding community-based projects ranging from physical structures to amenities. Though civic crowdfunding has great potential for impact, it remains a developing field in terms of project success and widespread adoption. To explore how technology shapes interactions and outcomes within civic projects, our research addresses two interrelated questions: how do offline communities engage online across civic crowdfunding projects, and, what purpose does this activity serve both projects and communities? These questions are explored through discussion of types of offline communities and description of online activity across civic crowdfunding projects. We conclude by considering the implications of this knowledge for civic crowdfunding and its continued research.", "references": ["Agrawal, A. K., Catalini, C., and Goldfarb, A. 2011. The geography of crowdfunding (No. w16820). National Bureau of Economic Research.", "Braun, V. and Clarke, V. 2006. Using thematic analysis in psychology. Qualitative research in psychology, 3(2), 77--101.", "Butler, B., Sproull, L., Kiesler, S., and Kraut, R. 2002. Community effort in online groups: Who does the work and why. Leadership at a distance: Research in technologically supported work, 171--194."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783446.2783585"}, {"title": "Image indexing and retrieval with Yael", "authors": ["Matthijs Douze\n,", "Hervé Jégou"], "publication": "ACM SIGMultimedia Records", "abstract": "", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2835398.2835405"}, {"title": "Landmark Information Retrieval Based on Name and Road Frequencies in Digital Road Maps", "authors": ["Yoshihide Hosokawa\n,", "Takanori Yamamoto\n,", "Yuichiro Nakazawa"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nRoad maps are utilized by many people with different aims. These emphasize some locations that are well known and often used by them. The locations are used as guides, which are referred to as landmarks, for accomplishing their aims.\nThis paper presents a new method for directly selecting landmarks from the road maps. One of the advantages is to identify landmarks according to the name and road frequencies. The name frequency shows the number of maps in which a location name is drawn. The road frequency shows the number of maps in which a road is drawn. These are used for judging whether locations are emphasized in the maps. Thus, the method finds landmarks from many cities because some road maps cover the cities.\nAn experiment was conducted using 149 subjects to examine the effectiveness of the method. According to the results, the method found 80% of the subjects' landmarks. It also found 30% more landmarks than a conventional method.", "references": ["Baird, J. C., Merrill, A. A., and Tannenbaum J., Studies of the Cognitive Representation of Spatial Relations: II. A Familiar Environment, Experimental Psychology: General, 108 (1), pp.92--98 (1979)", "Grabler, F., Agrawala, M., and Sumner, R. W., and Pauly, M., Automatic Generation of Tourist Maps, Proc. 35th Int'l Conf. on Computer Graphics and Interactive Techniques, pp.100:1--100:11 (2008)", "Golledge, R. G., Wayfinding Behavior: Cognitive Mapping and Other Spatial Processes, JHU Press (1999)"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2837145"}, {"title": "Improving recommender system navigability through diversification: a case study of IMDb", "authors": ["Daniel Lamprecht\n,", "Florian Geigl\n,", "Tomas Karas\n,", "Simon Walk\n,", "Denis Helic\n,", "Markus Strohmaier"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nThe Internet Movie Database (IMDb) is the world's largest collection of facts about movies and features large-scale recommendation systems connecting hundreds of thousands of items. In the past, the principal evaluation criterion for such recommender systems has been the rating accuracy prediction for recommendations within the immediate one-hop-neighborhood. Apart from a few isolated studies, the evaluation methodology for recommender systems has so far lacked approaches that quantify and measure the exposure to novel content while navigating a recommender system. As such, little is known about the support for navigation and browsing as methods to explore, browse and discover novel items within these systems. In this article, we study the navigability of IMDb's recommender systems over multiple hops. To this end, we analyze the recommendation networks of IMDb with a two-level approach: First, we study reachability in terms of components, path lengths and a bow-tie analysis. Second, we simulate practical browsing scenarios based on greedy decentralized search. Our results show that the IMDb recommendation networks are not very well-suited for navigation scenarios. To mitigate this, we apply a method for diversifying recommendations by specifically selecting recommendations which improve connectivity but do not compromise relevance. We demonstrate that this leads to improved reachability and navigability in both recommender systems. Our work underlines the importance of navigability and reachability as evaluation dimension of a large movie recommender system and shows up ways to increase navigational diversity.", "references": ["A. Broder, R. Kumar, F. Maghoul, P. Raghavan, S. Rajagopalan, R. Stata, A. Tomkins, and J. Wiener. Graph structure in the web. Computer Networks, 33(1):309----320, 2000.", "P. Cano, O. Celma, M. Koppenberger, and J. M. Buldu. Topology of music recommendation networks. Chaos: An Interdisciplinary Journal of Nonlinear Science, 16(1):013107, 2006.", "Ò. Celma and P. Herrera. A new approach to evaluating novel recommendations. In Proceedings of the 2nd ACM Conference on Recommender Systems, pages 179--186. ACM, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809603"}, {"title": "The Synonym Processing Mechanism in Web Index", "authors": ["Shiori Ikuta\n,", "Motomichi Toyama"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nWeb Index (WIX) is a hyperlink generation system that achieves joining information resources on the web. The WIX system takes a set of pairs of keywords and URLs written in XML (called WIX Files) and join it to the text content of a web page in order to transform keywords into hyperlinks to a specific web page group of the user's choice. In the previous WIX system, synonymous expressions of the same entity had to be directly added to the WIX File in order to generate hyperlinks for such expressions. In this paper, we propose a synonym processing mechanism, which generates the hyperlink for synonyms without adding them to the WIX File directly. We collected synonymous relations from the redirection function of the Japanese version of Wikipedia and constructed a synonym database for our system. We incorporated the information of the Synonym database into the automaton based on the Aho-Corasick algorithm used for the lexicographic matching process of the WIX system, and achieved to generate hyperlinks on synonymous expressions without barely changing the size of our WIX File database.", "references": ["Masahiro Hayashi, Motomichi Toyama \"Keio WIX System (1) User Interface (Japanese)\". DEIM '11 The 3rd Forum on Data Engineering and Information Management. 2011.", "Kaushik Chakrabarti, Surajit Chaudhuri, Tao Cheng, Dong Xin. \"A Framework for Robust Discovery of Entity Synonyms.\" KDD, 2012.", "Tao Cheng, Hady W. Lauw, Stelios Paparizos. \"Entity Synonyms for Structures Web Search.\" TKDE, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790779"}, {"title": "Effect of Snippets on User Experience in Web Search", "authors": ["Mari-Carmen Marcos\n,", "Ferran Gavin\n,", "Ioannis Arapakis"], "publication": "Interacción '15: Proceedings of the XVI International Conference on Human Computer Interaction", "abstract": "ABSTRACT\nIn recent years, the search engine results pages (SERP's) have been augmented with new markup elements that introduce seamlessly additional semantic information. Examples of such elements are the aggregated results disseminated by vertical portals, and the enriched snippets that display meta-information from the landing pages. In this paper, we investigate the gaze behaviour of web users who inter- act with SERP's that contain plain and rich snippets, and observe the impact of both types of snippets on the web search experience. For our study, we consider a wide range of snippet types, such as multimedia elements (Google Images, Google Videos), recommendation snippets (Author, Google Plus, Reviews, Google Shopping Product), and geo-location snippets (Google Places). We conduct two controlled user studies that employ eye tracking and mouse tracking, and analyse the search interactions of 213 participants, focusing on three factors: noticeability, interest, and conversion. Our findings indicate that ranking remains the most critical factor in relevance perception, although in certain cases the richness of snippets can capture user attention.", "references": ["M. Ageev, D. Lagun, and E. Agichtein. Towards task-based snippet evaluation: preliminary results and challenges. In C. L. A. Clarke, L. Freund, M. D. Smucker, and E. Yilmaz, editors, Proceedings of the SIGIR 2013 Workshop on Modeling User Behavior for Information Retrieval Evaluation (MUBE 2013), pages 1--2, 2013.", "J. Arguello and R. Capra. The effect of aggregated search coherence on search behavior. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM '12, pages 1293--1302, New York, NY, USA, 2012. ACM.", "J. Arguello and R. Capra. The effects of vertical rank and border on aggregated search coherence and search behavior. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM '14, pages 539--548, New York, NY, USA, 2014. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2829875.2829916"}, {"title": "Geo-SAGE: A Geographical Sparse Additive Generative Model for Spatial Item Recommendation", "authors": ["Weiqing Wang\n,", "Hongzhi Yin\n,", "Ling Chen\n,", "Yizhou Sun\n,", "Shazia Sadiq\n,", "Xiaofang Zhou"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nWith the rapid development of location-based social networks (LBSNs), spatial item recommendation has become an important means to help people discover attractive and interesting venues and events, especially when users travel out of town. However, this recommendation is very challenging compared to the traditional recommender systems. A user can visit only a limited number of spatial items, leading to a very sparse user-item matrix. Most of the items visited by a user are located within a short distance from where he/she lives, which makes it hard to recommend items when the user travels to a far away place. Moreover, user interests and behavior patterns may vary dramatically across different geographical regions. In light of this, we propose Geo-SAGE, a geographical sparse additive generative model for spatial item recommendation in this paper. Geo-SAGE considers both user personal interests and the preference of the crowd in the target region, by exploiting both the co-occurrence pattern of spatial items and the content of spatial items. To further alleviate the data sparsity issue, Geo-SAGE exploits the geographical correlation by smoothing the crowd's preferences over a well-designed spatial index structure called spatial pyramid. We conduct extensive experiments and the experimental results clearly demonstrate our Geo-SAGE model outperforms the state-of-the-art.", "references": ["A. Ahmed, B. Kanagal, S. Pandey, V. Josifovski, L. G. Pueyo, and J. Yuan. Latent factor models with additive and hierarchically-smoothed user preferences. In WSDM, pages 385--394, 2013.", "J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In SIGSPATIAL, pages 199--208, 2012.", "J. Bao, Y. Zheng, D. Wilkie, and M. F. Mokbel. A survey on recommendations in location-based social networks. GeoInformatica, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783335"}, {"title": "Learning Distributed Representations from Reviews for Collaborative Filtering", "authors": ["Amjad Almahairi\n,", "Kyle Kastner\n,", "Kyunghyun Cho\n,", "Aaron Courville"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecent work has shown that collaborative filter-based recommender systems can be improved by incorporating side information, such as natural language reviews, as a way of regularizing the derived product representations. Motivated by the success of this approach, we introduce two different models of reviews and study their effect on collaborative filtering performance. While the previous state-of-the-art approach is based on a latent Dirichlet allocation (LDA) model of reviews, the models we explore are neural network based: a bag-of-words product-of-experts model and a recurrent neural network. We demonstrate that the increased flexibility offered by the product-of-experts model allowed it to achieve state-of-the-art performance on the Amazon review dataset, outperforming the LDA-based approach. However, interestingly, the greater modeling power offered by the recurrent neural network appears to undermine the model's ability to act as a regularizer of the product representations.", "references": ["Y. Bao, H. Fang, and J. Zhang. TopicMF: Simultaneously exploiting ratings and reviews for recommendation. In AAAI, 2014.", "F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. J. Goodfellow, A. Bergeron, N. Bouchard, and Y. Bengio. Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, 2012.", "J. Bergstra, F. Bastien, O. Breuleux, P. Lamblin, R. Pascanu, O. Delalleau, G. Desjardins, D. Warde-Farley, I. J. Goodfellow, A. Bergeron, and Y. Bengio. Theano: Deep learning on gpus with python. In Big Learn workshop, NIPS'11, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800192"}, {"title": "Linked Data Queries as Jigsaw Puzzles: a Visual Interface for SPARQL Based on Blockly Library", "authors": ["Paolo Bottoni\n,", "Miguel Ceriani"], "publication": "CHItaly 2015: Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter", "abstract": "ABSTRACT\nSPARQL is a powerful query language for Semantic Web data sources but it is quite complex to master. The jigsaw puzzle methaphor has been succesfully used in Blockly to teach programming to kids. We discuss its applicability to the problem of building SPARQL queries, through the presentation of a dedicated Blockly-based visual user interface.", "references": ["T. Berners-Lee. Linked data. Design Issues, 2006.", "T. Berners-Lee, R. Fielding, and L. Masinter. Uniform Resource Identifier (URI): Generic Syntax. RFC 3986 (INTERNET STANDARD), Jan. 2005. Updated by RFC 6874.", "T. Berners-Lee, J. Hendler, and O. Lassila. The Semantic Web. Scientific American, 284(5):34--43, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808435.2808467"}, {"title": "Content-Based Video Search over 1 Million Videos with 1 Core in 1 Second", "authors": ["Shoou-I Yu\n,", "Lu Jiang\n,", "Zhongwen Xu\n,", "Yi Yang\n,", "Alexander G. Hauptmann"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nMany content-based video search (CBVS) systems have been proposed to analyze the rapidly-increasing amount of user-generated videos on the Internet. Though the accuracy of CBVS systems have drastically improved, these high accuracy systems tend to be too inefficient for interactive search. Therefore, to strive for real-time web-scale CBVS, we perform a comprehensive study on the different components in a CBVS system to understand the trade-offs between accuracy and speed of each component. Directions investigated include exploring different low-level and semantics-based features, testing different compression factors and approximations during video search, and understanding the time v.s. accuracy trade-off of reranking. Extensive experiments on data sets consisting of more than 1,000 hours of video showed that through a combination of effective features, highly compressed representations, and one iteration of reranking, our proposed system can achieve an 10,000-fold speedup while retaining 80% accuracy of a state-of-the-art CBVS system. We further performed search over 1 million videos and demonstrated that our system can complete the search in 0.975 seconds with a single core, which potentially opens the door to interactive web-scale CBVS for the general public.", "references": ["A. Bordes, S. Ertekin, J. Weston, and L. Bottou. Fast kernel classifiers with online and active learning. In JMLR, 2005.", "E. F. Can and R. Manmatha. Modeling concept dependencies for event detection. In ICMR, 2014.", "C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. In ACM Transactions on Intelligent Systems and Technology, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749398"}, {"title": "Image-Text Cross-Modal Retrieval via Modality-Specific Feature Learning", "authors": ["Jian Wang\n,", "Yonghao He\n,", "Cuicui Kang\n,", "Shiming Xiang\n,", "Chunhong Pan"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nCross-modal retrieval extends the ability of search engines to deal with the massive cross-modal data. The goal of image-text cross-modal retrieval is to search images (texts) by using text (image) queries by computing the similarities of images and texts directly. Many existing methods rely on low-level visual features and textual features for cross-modal retrieval, ignoring the characteristics existing in the raw data of different modalities. In this paper, a novel model based on modality-specific feature learning is proposed. Considering the characteristics of different modalities, the model uses two types of convolutional neural networks to map the raw data to the latent space representations for images and texts, respectively. Particularly, the convolution based network used for texts involves word embedding learning, which has been proved effective to extract meaningful textual features for text classification. In the latent space, the mapped features of images and texts form relevant and irrelevant image-text pairs, which are used by the one-vs-more learning scheme. This learning scheme can achieve ranking functionality by allowing for one relevant and more irrelevant pairs. The standard back-propagation technique is employed to update the parameters of two convolutional networks. Extensive cross-modal retrieval experiments are carried out on three challenging datasets that consist of image-document pairs or image-query click-through data from a search engine, and the results firmly demonstrate that the proposed model is much more effective.", "references": ["T. Berg, A. Berg, and J. Shih. Automatic attribute discovery and characterization from noisy web data. In Proceddings of European Conference on Computer Vision, pages 663--676. 2010.", "D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "P. Blunsom, E. Grefenstette, and N. Kalchbrenner. A convolutional neural network for modelling sentences. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749341"}, {"title": "Salton Award Lecture: People, Interacting with Information", "authors": ["Nicholas J. Belkin"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nColleagues, friends, let me begin by expressing how pleased, and humbly honored I am to be a recipient of the Gerard Salton Award. Gerry was a great man, and to receive the award named for him is very special. For me personally, it is especially meaningful, given the sometime disputatious nature of our professional interactions, and what seemed, on the surface, to be quite different ideas about information retrieval. I say, on the surface, because in the end, I believe that he and I both shared the same goal for the field, although we approached it from quite different positions. In this presentation, I will speak at some length on that goal, and on how I think it might be best addressed. I am humbled also by the honor of having joined the ranks of the previous recipients of this award; the founders, leaders and innovators in information retrieval (IR), from the earliest beginnings of the field to today. It has been my distinct good fortune to have known all of the previous recipients, to have collaborated with many of them, to have argued with all of them, to have learned from them, and, I hope, to have been able to appropriately incorporate their insights into my own work. Today, following the example of many of my predecessors, I'd like to take this opportunity to, in Sue Dumais's words of 2009, \"present a personal reflection on information retrieval.\" This will include an overview of my history in IR, a discussion of my personal take on its proper goals, and on how those might be best achieved, and saying something about the challenges that IR theory, experiment and practice face both now, and in the future, and how we might best address those challenges. I came to the field of IR from a starting point in information science; specifically, with the concern of addressing general problems of information in society. I initially thought that the best way to do this would be to establish a firm framework for a science of information. Acting on my then understanding of what a science constituted, I began the project of defining information. Fortunately for me, I did this at University College, London, with B.C. Brookes as my Ph.D. supervisor, and Steve Robertson my office mate. It didn't take long for me to be disabused of a) the idea that information could be defined; and b) that defining its phenomena of interest was a necessary precondition to a \"real\" science. Instead, perhaps under the influence of the great pragmatist, Jeremy Bentham, founder of University College, I turned to attempting to develop a concept of information which would lead to being able to predict its effect on a person's state of knowledge, which I took at that time as what IR systems should be attempting to do.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767854"}, {"title": "Blockbusters and Wallflowers: Accurate, Diverse, and Scalable Recommendations with Random Walks", "authors": ["Fabian Christoffel\n,", "Bibek Paudel\n,", "Chris Newell\n,", "Abraham Bernstein"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nUser satisfaction is often dependent on providing accurate and diverse recommendations. In this paper, we explore scalable algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP^3_beta that re-ranks items based on 3-hop random walk transition probabilities. We show empirically, that RP^3_beta provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present scalable approximate versions of RP^3_beta and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with increasing number of samples.", "references": ["G. Adomavicius and Y. Kwon. Maximizing Aggregate Recommendation Diversity: A Graph-Theoretic Approach. In Workshop on Novelty and Diversity in Recommender Systems, ACM RecSys, 2011.", "G. Adomavicius and Y. Kwon. Improving Aggregate Recommendation Diversity Using Ranking-Based Techniques. IEEE Transactions on Knowledge and Data Engineering, 2012.", "C. C. Aggarwal, J. L. Wolf, K.-L. Wu, and P. S. Yu. Horting Hatches an Egg: A New Graph-Theoretich Approach to Collaborative Filtering. In ACM SIGKDD, 1999."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800180"}, {"title": "Data Governance in Brazilian Organizations", "authors": ["Andre Montoia Barata\n,", "Edmir Parada Vasques Prado"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nOrganizations are increasingly looking for data integrity and quality to assist in strategic making decision and value creation. In this context Data Governance (DG) provide processes and practices that assist in the management and maintenance data. There are many frameworks to implementation DG process and benefits they may provide, however there are few implementation reported in the literature. This study aims to identify the DG process and frameworks implemented in Brazilian organizations and compare the benefits in implementation with those proposed by literature. For this will be carried out case studies in Brazilian organizations that implemented or are implementing DG frameworks.", "references": ["Begg, C. e Caira, T. 2012. Exploring the SME Quandary: Data Governance in Practise in the Small to Medium-Sized Enterprise Sector. Electronic Journal Information Systems Evaluation, Paisley. 15, 1, 3-13.", "Bruening, P. J. e Waterman, K. K. 2010. Data tagging for new information governance models. Security & Privacy, IEEE. 8, 5(Set/Out. 2010), 64-68.", "Chapple, M. 2013. Speaking the same language: Building a data governance program for institutional impact. Educause Review. 48, 6(Nov/Dez. 2013), 14-27."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814102"}, {"title": "Transferring positioning model for device-free passive indoor localization", "authors": ["Kazuya Ohara\n,", "Takuya Maekawa\n,", "Yasue Kishino\n,", "Yoshinari Shirai\n,", "Futoshi Naya"], "publication": "UbiComp '15: Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing", "abstract": "ABSTRACT\nThis paper proposes a new method that makes it easy for us to construct a positioning model for device-free passive indoor localization by using model transfer techniques. With device-free passive indoor positioning, a wireless sensor network is used to detect the movement of a person based on the fact that RF signals transmitted between a transmitter and a receiver are affected by human movement. However, because device-free passive indoor positioning relies on machine learning techniques, we must collect labeled training data at many training points in an end user's environment. This paper proposes a method that transfers a signal strength model used for locating a person obtained in another environment (source environment) to the end user environment. With the transferred models, we can construct a positioning model for the end user environment inexpensively. Our evaluation showed that our method achieved almost the same positioning performance as a supervised method that requires labeled training data obtained in an end user's environment.", "references": ["Chen, S., Chen, Y., and Trappe, W. Exploiting environmental properties for wireless localization and location aware applications. In PerCom 2008 (2008), 90--99.", "Chen, Y.-C., Chiang, J.-R., Chu, H.-h., Huang, P., and Tsui, A. W. Sensor-assisted Wi-Fi indoor location system for adapting to environmental dynamics. In ACM International Symposium on Modeling, Analysis and Simulation of Wireless and Mobile Systems (2005), 118--125.", "De Toledo, A. F., Turkmani, A. M., and Parsons, J. Estimating coverage of radio transmission into and within buildings at 900, 1800, and 2300 MHz. IEEE Personal Communications 5, 2 (1998), 40--47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750858.2806061"}, {"title": "Active Learning for Entity Filtering in Microblog Streams", "authors": ["Damiano Spina\n,", "Maria-Hendrike Peetz\n,", "Maarten de Rijke"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nMonitoring the reputation of entities such as companies or brands in microblog streams (e.g., Twitter) starts by selecting mentions that are related to the entity of interest. Entities are often ambiguous (e.g., \"Jaguar\" or \"Ford\") and effective methods for selectively removing non-relevant mentions often use background knowledge obtained from domain experts. Manual annotations by experts, however, are costly. We therefore approach the problem of entity filtering with active learning, thereby reducing the annotation load for experts. To this end, we use a strong passive baseline and analyze different sampling methods for selecting samples for annotation. We find that margin sampling--an informative type of sampling that considers the distance to the hyperplane used for class separation--can effectively be used for entity filtering and can significantly reduce the cost of annotating initial training data.", "references": ["E. Amigó, J. Artiles, J. Gonzalo, D. Spina, B. Liu, and A. Corujo. WePS-3 evaluation campaign: Overview of the online reputation management task. In CLEF '10 (Online Working Notes/Labs/Workshop), 2010.", "E. Amigó, A. Corujo, J. Gonzalo, E. Meij, and M. de Rijke. Overview of RepLab 2012: Evaluating online reputation management systems. In CLEF '12 (Online Working Notes/Labs/Workshop), 2012.", "E. Amigó, J. Carrillo de Albornoz, I. Chugur, A. Corujo, J. Gonzalo, T. Martın, E. Meij, M. de Rijke, and D. Spina. Overview of RepLab 2013: Evaluating online reputation monitoring systems. In CLEF '13 (Online Working Notes/Labs/Workshop), pages 333--352, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767839"}, {"title": "Investigating Information Search by People with Cognitive Disabilities", "authors": ["Ruimin Hu\n,", "Jinjuan Heidi Feng"], "publication": "ACM Transactions on Accessible Computing", "abstract": "Abstract\nThe ability to gather information online has become increasingly important in the past decades. Previous research suggests that people with cognitive disabilities experience challenges when finding information on websites. Although a number of studies examined the impact of various design guidelines on information search by people with cognitive disabilities, our knowledge in this topic remains limited. To date, no study has been conducted to examine how people with cognitive disabilities navigate in different content structures. We completed an empirical study to investigate the impact of different search methods and content structures on the search behavior of people with cognitive disabilities. 23 participants with various cognitive disabilities completed 15 information search tasks under three conditions: browsing a website with a deep structure (4 × 4 × 4 × 4), browsing a website with a broad structure (16 × 16), and searching through a search engine. The results suggest that the participants overwhelmingly preferred the search engine method to the two browsing conditions. The broad structure resulted in significantly higher failure rates than the search engine condition and the deep structure condition. The causes of failed search tasks were analyzed in detail. Participants frequently visited incorrect categories in both the deep structure and the broad structure conditions. However, it was more difficult to recover from incorrect categories on the lower-level pages in the broad structure than in the deep structure. Under the search engine condition, failed tasks were mainly caused by difficulty in selecting the correct link from the returned list, misspellings, and difficulty in generating appropriate search keywords.", "references": ["A. Aula, R. Khan, and Z. Guan. 2010. How does search behavior change as search becomes more difficult&quest; In Proceedings of Human Factors in Computing Systems Conference. 35--43.", "P. Bohman. 2004. Cognitive Disabilities Part 1: We Still Know Too Little, and We Do Even Less. Retrieved on October 30, 2010 from http://Webaim.org/articles/cognitive/cognitive&lowbar;too&lowbar;little.", "P. Bohman and S. Anderson. 2005. A conceptual framework for accessibility tools to benefit users with cognitive disabilities. In Proceedings of the International Cross-Disciplinary Workshop on Web Accessibility. 85--89."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2729981"}, {"title": "Mining Massive Web Log Data of an Official Tourism Web Site as a Step towards Big Data Analysis in Tourism", "authors": ["Chung Yung"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe focus of this paper is on the conceptual and technical solution design to the analysis of massive web log data of an official tourism web site when integrated with web mining and big data technology. With the rapid development of Internet and World Wide Web, web log becomes one the fastest growing user generated contents, and web log mining plays an important role in many fields, such as personalized information service, design and service improvement of web sites. The underlying technology for analyzing massive web log data includes web log mining and big data analysis. In this paper, we give a comprehensive overview at the underlying technology, and then we propose an open architecture of big data solution design in tourism with mining the massive web log data. We include the discussion on the difficulties in implementing the proposed architecture as a conclusion.", "references": ["X. Yu and T. Korkmaz, \"Finding the most evident co-clusters on web log dataset using frequent super-sequence mining,\" in Proceedings of the IEEE 15th International Conference on Information Reuse and Integration (IRI 2014), August 2014, pp. 529--536.", "J. Duan and S. Liu, \"Research on web log mining analysis,\" in Proceedings of the 2012 International Symposium on Instrumentation and Measurement, Sensor Network and Automation (IMSNA 2012), vol. 2, August 2012, pp. 1981--1985.", "H. S. Du and C. Wagner, \"Weblog success: Exploring the role of technology,\" International Journal of Human-Computer Studies, vol. 54, no. 9, pp. 789--798, September 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818906"}, {"title": "Management of Authorization Rules Using Conceptual Model", "authors": ["Ricardo Diniz Sul\n,", "Bruna Christina P. Brandao\n,", "Leonardo Guerreiro Azevedo\n,", "Fernanda Baiao\n,", "Claudia Cappelli"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nInformation security is an important concern for information systems development. Managing and executing authorization rules (which constrain who is allowed to execute some action over which information) are crucial issues. This work presents a tool for managing authorization rules part of a role-based framework for access control. Business users may use this module to specify authorization rules using an ERM (entity-relationship model). The module was implemented using open-source technologies, in a real organization that is responsible for controlling the access of several information systems to a corporate database. An example of its use is presented, illustrating its viability and efficacy.", "references": ["Azevedo, L.G., Puntar, S., Thiago, R., Baião, F., Cappelli, C., 2010. A Flexible Framework for Applying Data Access Authorization Business Rules. In Proceedings of the 12th International Conference on Enterprise Information Systems (ICEIS 2010), pp. 275-280.", "Baader, F., Calvanese, D., Mcguinness, D. L., Nardi, D., Atelschneider, P. F. (2003) The Description Logic Handbook: Theory, Implementation, Applications. Cambridge University Press, Cambridge, UK, 2003.", "Calì, A., Martinenghi, D (2008). Querying data under access limitations. In Proceedings of IEEE 24th International Conference on Data Engineering, pp. 50-59, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814113"}, {"title": "To lock, swap, or elide: on the interplay of hardware transactional memory and lock-free indexing", "authors": ["Darko Makreshanski\n,", "Justin Levandoski\n,", "Ryan Stutsman"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nThe release of hardware transactional memory (HTM) in commodity CPUs has major implications on the design and implementation of main-memory databases, especially on the architecture of high-performance lock-free indexing methods at the core of several of these systems. This paper studies the interplay of HTM and lock-free indexing methods. First, we evaluate whether HTM will obviate the need for crafty lock-free index designs by integrating it in a traditional B-tree architecture. HTM performs well for simple data sets with small fixed-length keys and payloads, but its benefits disappear for more complex scenarios (e.g., larger variable-length keys and payloads), making it unattractive as a general solution for achieving high performance. Second, we explore fundamental differences between HTM-based and lock-free B-tree designs. While lock-freedom entails design complexity and extra mechanism, it has performance advantages in several scenarios, especially high-contention cases where readers proceed uncontested (whereas HTM aborts readers). Finally, we explore the use of HTM as a method to simplify lock-free design. We find that using HTM to implement a multi-word compare-and-swap greatly reduces lock-free programming complexity at the cost of only a 10-15% performance degradation. Our study uses two state-of-the-art index implementations: a memory-optimized B-tree extended with HTM to provide multi-threaded concurrency and the Bw-tree lock-free B-tree used in several Microsoft production environments.", "references": ["M. Abadi, T. Harris, and M. Mehrara. Transactional Memory with Strong Atomicity Using Off-the-shelf Memory Protection Hardware. In PPoPP, pages 185--196, 2009.", "J. H. Anderson and M. Moir. Universal Constructions for Multi-Object Operations. In PODC, pages 184--193, 1995.", "C. Blundell, E. C. Lewis, and M. M. Martin. Subtleties of Transactional Memory Atomicity Semantics. IEEE Comput. Archit. Lett., 5(2):--, Feb 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2809974.2809990"}, {"title": "A Probabilistic Rating Auto-encoder for Personalized Recommender Systems", "authors": ["Huizhi Liang\n,", "Timothy Baldwin"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nUser profiling is a key component of personalized recommender systems, and is used to generate user profiles that describe individual user interests and preferences. The increasing availability of big data is driving the urgent need for user profiling algorithms that are able to generate accurate user profiles from large-scale user behavior data. In this paper, we propose a probabilistic rating auto-encoder to perform unsupervised feature learning and generate latent user feature profiles from large-scale user rating data. Based on the generated user profiles, neighbourhood based collaborative filtering approaches have been adopted to make personalized rating predictions. The effectiveness of the proposed approach is demonstrated in experiments conducted on a real-world rating dataset from yelp.com.", "references": ["G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 17(6):734--749, 2005.", "Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. J. Mach. Learn. Res., 3:1137--1155, Mar. 2003.", "X. Chen and X. Lin. Big data deep learning: Challenges and perspectives. IEEE Access , 2:514--525, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806633"}, {"title": "Ad Hoc Monitoring of Vocabulary Shifts over Time", "authors": ["Tom Kenter\n,", "Melvin Wevers\n,", "Pim Huijnen\n,", "Maarten de Rijke"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nWord meanings change over time. Detecting shifts in meaning for particular words has been the focus of much research recently. We address the complementary problem of monitoring shifts in vocabulary over time. That is, given a small seed set of words, we are interested in monitoring which terms are used over time to refer to the underlying concept denoted by the seed words.\nIn this paper, we propose an algorithm for monitoring shifts in vocabulary over time, given a small set of seed terms. We use distributional semantic methods to infer a series of semantic spaces over time from a large body of time-stamped unstructured textual documents. We construct semantic networks of terms based on their representation in the semantic spaces and use graph-based measures to calculate saliency of terms. Based on the graph-based measures we produce ranked lists of terms that represent the concept underlying the initial seed terms over time as final output.\nAs the task of monitoring shifting vocabularies over time for an ad hoc set of seed words is, to the best of our knowledge, a new one, we construct our own evaluation set. Our main contributions are the introduction of the task of ad hoc monitoring of vocabulary shifts over time, the description of an algorithm for tracking shifting vocabularies over time given a small set of seed words, and a systematic evaluation of results over a substantial period of time (over four decades). Additionally, we make our newly constructed evaluation set publicly available.", "references": ["J. Allan. Topic detection and tracking: event-based information organization. Springer Science & Business Media, 2002.", "M. Baroni, G. Dinu, and G. Kruszewski. Don't count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In ACL 2014, 2014.", "R. Berendsen, E. Meij, D. Odijk, M. de Rijke, and W. Weerkamp. The university of amsterdam at trec 2012. In TREC 2012, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806474"}, {"title": "Online Searching in English as a Foreign Language", "authors": ["Gyöngyi Rózsa\n,", "Anita Komlodi\n,", "Peng Chu"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline searching is a central element of internet users' information behaviors. Searching is usually executed in a user's native language, but searching in English as a foreign language is often necessitated by the lack of content in languages that are underrepresented in Web content. This paper reports results from a study of searching in English as a foreign language and aims at understanding this particular group of users' behaviors. Searchers whose native language is not English may have to resort to queries in English in support of their information needs due to the lack or low quality of the web content in their own language. However, when searching for information in a foreign language, users face a unique set of challenges that are not present for native language searching. We studied this problem through qualitative research methods and report results from focus groups in this paper. The results reported in this paper describe typical problems foreign language searchers face, the differences in information-seeking behavior in English and in the participants' native language, and advice and ideas shared by the focus group participants about how to search effectively and efficiently in English.", "references": ["Aula, A. and Kellar, M. (2009) Multilingual search strategies, CHI '09 Extended Abstracts on Human Factors in Computing Systems, New York, NY, USA, 3865--3870, DOI: 10.1145/1520340.1520585", "Berendt, B. and Kralisch, A. A user-centric approach to identifying best deployment strategies for language tools: the impact of content and access language on Web user behaviour and attitudes. Inf. Retr., 12, 3 (2009), 380--399., DOI: 10.1007/s10791-008--9086--4", "Caidi, N., Allard, D., & Quirke, L. 2010. The Information Practices of Immigrants. Annual Review of Information Science and Technology (ARIST), 44: 493--531., DOI: 10.1002/aris.2010.1440440118"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2743007"}, {"title": "Approach for investigating crowdfunding campaigns with platform data: case indiegogo", "authors": ["Jukka Huhtamäki\n,", "Lester Lasrado\n,", "Karan Menon\n,", "Hannu Kärkkäinen\n,", "Jari Jussila"], "publication": "AcademicMindTrek '15: Proceedings of the 19th International Academic Mindtrek Conference", "abstract": "ABSTRACT\nCrowdfunding via the internet is a relatively new phenomenon in research and gaining momentum currently. While taking a data-driven approach into investigating the properties and dynamics of crowdfunding campaigns would allow the use of computational social science in investigations on crowdfunding, existing data-driven research on crowdfunding remains very limited. This is particularly true on the level of individual funder data. In this study, we contribute to the empirical body of knowledge on crowdfunding by introducing Indiegogo as a data source and, more specifically, the development and implementation of a crawler and scraper for accessing Indiegogo campaign data, and sharing this openly for other researchers. Due to the extremely dynamic and rapidly increasing amount of crowdfunding data in terms of the number of crowdfunding campaigns and the available investment and individual investor data, we believe our approach is useful for supporting public and open data-driven research, instead of providing merely a static data set.", "references": ["Álvarez, M., Pan, A., Raposo, J. and Hidalgo, J. 2006. Crawling Web Pages with Support for Client-Side Dynamism. Advances in Web-Age Information Management. J. X. Yu, M. Kitsuregawa, and H. V. Leong, eds. Springer Berlin Heidelberg. 252--262.", "An, J., Quercia, D. and Crowcroft, J. 2014. Recommending investors for crowdfunding projects. Proceedings of the 23rd international conference on World wide web (2014), 261--270.", "Belleflamme, P., Lambert, T. and Schwienbacher, A. 2014. Crowdfunding: Tapping the right crowd. Journal of Business Venturing. 29, 5 (2014), 585--609."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818187.2818289"}, {"title": "Storyscope: Supporting the authoring and reading of museum stories using online data sources", "authors": ["Paul Mulholland\n,", "Annika Wolff\n,", "Eoin Kilfeather"], "publication": "WebSci '15: Proceedings of the ACM Web Science Conference", "abstract": "ABSTRACT\nMuseum staff tell stories to assist visitor interpretation of artworks. Visitors also tell their own stories to articulate their understanding and opinion of artworks. Additional knowledge about the concepts mentioned or tagged in these stories can be found from online data sources. These could be used to assist reader interpretation or author development of stories. However, the potentially vast network of heterogeneous knowledge that can be created around the tags or annotations of a story could be bewildering for the story reader or author. Here we present Storyscope, a test-bed environment for the authoring, reading and semantic annotation of museum stories. The integration of online knowledge within the task of story authoring or interpretation is facilitated by mapping the available knowledge to a set of facts and simple events related to each story annotation. Narrative principles of theme and setting are used to discover and highlight aspects of the knowledge of potential value to the author or reader. Preliminary studies indicate the potential of the approach for providing a form of semantic navigation across stories and concepts having a better cognitive fit to story related tasks than existing forms of navigation.", "references": ["Rowe, S., Wertsch, J., Tatyana, K. Linking Little Narratives to Big Ones: Narrative and Public Memory in History Museums. Culture and Psychology, 16 (2): 96--112. 2002.", "http://www.freebase.com", "http://www.mpi-inf.mpg.de/yago-naga/yago"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786451.2786462"}, {"title": "Towards a Sensor-Cloud Infrastructure with Sensor Virtualization", "authors": ["Sunanda Bose\n,", "Atrayee Gupta\n,", "Sriyanjana Adhikary\n,", "Nandini Mukherjee"], "publication": "MSCC '15: Proceedings of the Second Workshop on Mobile Sensing, Computing and Communication", "abstract": "ABSTRACT\nRecent advancements in cloud and sensor technologies have created opportunities for introducing Sensor-Cloud as a convenient framework for developing applications in various fields. It has already been possible to integrate sensor technology with cloud environment and services have been developed to access the sensors via Internet. Here, the sensors can communicate with remote resources and transmit the sensed data. This paper presents a scheme to create Sensor-Cloud infrastructure with virtualization of sensors. We introduce an architectural overview along with new concepts about resource abstraction at the sensor level. We also discuss about providing uninterrupted services by a collection of sensors that can be used as shared resources for online provisioning to the consumers.", "references": ["P. Mell, T. Grance. The NIST Definition of Cloud Computing, Recommendations of the National Institute of Standards and Technology, 24 July 2011.", "compuBase. IT Channel Glossary, March 2013. Retrieved 13 February 2013.", "S. S. Manvi, G. K. Shyam. Resource management for Infrastructure as a Service (IaaS) in cloud computing: A survey, Journal of Network and Computer Applications 41(2014):424--440, October 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2757743.2757748"}, {"title": "Efficient algorithms for answering reverse spatial-keyword nearest neighbor queries", "authors": ["Ying Lu\n,", "Gao Cong\n,", "Jiaheng Lu\n,", "Cyrus Shahabi"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nWith the proliferation of local services and GPS-enabled mobile phones, reverse spatial-keyword Nearest Neighbor queries are becoming an important type of query. Given a service object (e.g., shop) q as the query, which has a location and a text description, we return customers such that q is one of top-k spatial-keyword relevant service objects for each result customer. Existing algorithms for answering reverse nearest neighbor queries cannot be used for processing reverse spatial-keyword nearest neighbor queries due to the additional text information. To design efficient algorithms, for the first time we theoretically analyze an ideal case, which minimizes the object/index node accesses, for processing reverse spatial-keyword nearest neighbor queries. Under the derived theoretical guidelines, we design novel search algorithms for efficiently answering the queries. Empirical studies show that the proposed algorithms offer scalability and are orders of magnitude faster than existing methods for reverse spatial-keyword nearest neighbor queries.", "references": ["Efficient Algorithms for Answering Reverse Spatial-Keyword Nearest Neighbor Queries. http://www.cs.usc.edu/research/technical-reports-list.htm?#2015.", "E. Achtert, H.-P. Kriegel, P. Kröger, M. Renz, and A. Züfle. Reverse k-nearest neighbor search in dynamic and general metric databases. In EDBT, pages 886--897, 2009.", "G. Cong, C. S. Jensen, and D. Wu. Efficient retrieval of the top-k most relevant spatial web objects. In PVLDB, pages 337--348, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820873"}, {"title": "eRS: A System to Facilitate Emotion Recognition in Movies", "authors": ["Joël Dumoulin\n,", "Diana Affi\n,", "Elena Mugellini\n,", "Omar Abou Khaled"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWe present eRS, an open-source system whose purpose is to facilitate the workflow of emotion recognition in movies, released under the MIT license. The system consists of a Django project and an AngularJS web application. It allows to easily create emotional video datasets, process the videos, extract the features and model the emotion. All data is exposed by a REST API, making it available not only to the eRS web application, but also to other applications. All visualizations are interactive and linked to the playing video, allowing researchers to easily analyze the results of their algorithms. The system currently runs on Linux and OS X. eRS can be extended, to integrate new features and algorithms needed in the different steps of emotion recognition in movies.", "references": ["G. Bradski. Dr. Dobb's Journal of Software Tools.", "W. C. Chiang, J. S. Wang, and Y. L. Hsu. A Music Emotion Recognition Algorithm with Hierarchical SVM Based Classifiers. 2014 International Symposium on Computer, Consumer and Control, pages 1249--1252, June 2014.", "F. Eyben, F. Weninger, F. Gross, and B. Schuller. Recent developments in opensmile, the munich open-source multimedia feature extractor. In Proceedings of the 21st ACM International Conference on Multimedia, MM '13, pages 835--838, New York, NY, USA, 2013. ACM."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2807409"}, {"title": "Kidnew: The Kidney Transplant Patient Personal Health Buddy", "authors": ["Mary Jane B. Arcilla\n,", "Viana Celina T. Ang\n,", "Mikaela Nazarene Ochoa\n,", "Christian Paulo L. Padua\n,", "Riezl E. Payawal"], "publication": "DH '15: Proceedings of the 5th International Conference on Digital Health 2015", "abstract": "ABSTRACT\nIn the year 2013, almost 120,000 Filipinos suffered from kidney failure or end-stage renal disease (ESRD). [3] Close to 20,000 of them are undergoing dialysis treatment [3], while a number of them opted for renal transplantation. Kidney transplant patients have to closely monitor their health for at least six to twelve months after surgery in order to prevent rejection or infections. This includes tracking medicine intake, recording vital signs and symptoms, among others. With the aid of technologies such as mHealth, health monitoring for kidney transplant patients would be more convenient.\nKidnew: The Kidney Transplant Patient Personal Health Buddy is a web-based and mobile information system that aims to assist kidney transplant patients in tracking their daily health condition by monitoring their day-to-day activities. It provides doctors real-time access to patient records and generates statistical graphs for making decisions.\nKidnew is a functional prototype that has gone through user-acceptance testing. Results showed that patients and doctors are satisfied with its overall design, functionality, and usability.", "references": ["Arcilla, M.J., Jalandoni, B.P., Ribon, R., Sansano, K.J., Sarmiento, D.B. (2013). Breast cancer case monitoring and mapping system for decision support. International Journal of Innovation, Management and Technology, 4(2), 269--27 doi: 10.7763/ijimt.2013.v4.404", "Care4Today Mobile Health Manager. (2014). Retrieved from Janssen Research & Development LLC: http://www.care4today.com", "Crisostomo, S. (2014, February 25). DOH: Cases of kidney failure on the rise. The Philippine Star. Retrieved from http://www.philstar.com"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2750511.2750539"}, {"title": "Querying semantic trajectory episodes", "authors": ["Tales P. Nogueira\n,", "Hervé Martin"], "publication": "MobiGIS '15: Proceedings of the Fourth ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems", "abstract": "ABSTRACT\nTrajectory acquisition, management, and processing are important tasks for any application that deals with spatiotemporal data. In order to perform these tasks effectively, it is important to rely on flexible structures. Many data models have been proposed for representing spatiotemporal traces. However, modeling trajectory characteristics and context information is still a challenge. In this work, we introduce the STEP ontology (Semantic Trajectory Episodes) for trajectory enrichment. In order to model this domain, we structure trajectories and related contextual data in terms of semantic episodes that allow describing various characteristics of the traces and context along time and space dimensions. We demonstrate the usage of the STEP ontology for enriching raw trajectories and show how the proposed model may be useful for trajectory analysis tasks.", "references": ["S. P. A. Alewijnse, K. Buchin, M. Buchin, A. Kölzsch, H. Kruckenberg, and M. A. Westenberg. A framework for trajectory segmentation by stable criteria. In Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems - SIGSPATIAL '14, pages 351--360, 2014.", "V. Bogorny, C. Renso, A. R. de Aquino, F. de Lucca Siqueira, and L. O. Alvares. CONSTAnT - A Conceptual Data Model for Semantic Trajectories of Moving Objects. Transactions in GIS, 18(1):66--88, Feb. 2013.", "R. B. Braga. LIDU: Location-based approach to IDentify similar interests between Users in social networks. Phd thesis, Université de Grenoble, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834126.2834136"}, {"title": "EventBuilder: Real-time Multimedia Event Summarization by Visualizing Social Media", "authors": ["Rajiv Ratn Shah\n,", "Anwar Dilawar Shaikh\n,", "Yi Yu\n,", "Wenjing Geng\n,", "Roger Zimmermann\n,", "Gangshan Wu"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nDue to the ubiquitous availability of smartphones and digital cameras, the number of photos/videos online has increased rapidly. Therefore, it is challenging to efficiently browse multimedia content and obtain a summary of an event from a large collection of photos/videos aggregated in social media sharing platforms such as Flickr and Instagram. To this end, this paper presents the EventBuilder system that enables people to automatically generate a summary for a given event in real-time by visualizing different social media such as Wikipedia and Flickr. EventBuilder has two novel characteristics: (i) leveraging Wikipedia as event background knowledge to obtain more contextual information about an input event, and (ii) visualizing an interesting event in real-time with a diverse set of social media activities. According to our initial experiments on the YFCC100M dataset from Flickr, the proposed algorithm efficiently summarizes knowledge structures based on the metadata of photos/videos and Wikipedia articles.", "references": ["P. K. Atrey, A. El Saddik, and M. S. Kankanhalli. Effective Multimedia Surveillance using a Human-centric Approach. Springer Multimedia Tools and Applications, 51(2):697--721, 2011.", "M. Del Fabro, A. Sobe, and L. Böszörmenyi. Summarization of real-life events based on community-contributed content. In MMEDIA, 2012.", "E. Filatova and V. Hatzivassiloglou. Event-based Extractive Summarization. In ACL Workshop on Summarization, pages 104--111, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2809932"}, {"title": "Overview of the 2015 Workshop on Speech, Language and Audio in Multimedia", "authors": ["Guillaume Gravier\n,", "Gareth F. Jones\n,", "Martha Larson\n,", "Roeland Ordelman"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThe Workshop on Speech, Language and Audio in Multimedia (SLAM) positions itself at at the crossroad of multiple scientific fields (music and audio processing, speech processing, natural language processing and multimedia) to discuss and stimulate research results, projects, datasets and benchmarks initiatives where audio, speech and language are applied to multimedia data. While the first two editions were collocated with major speech events, SLAM'15 is deeply rooted in the multimedia community, opening up to computer vision and multimodal fusion. To this end, the workshop emphasizes video hyperlinking as an showcase where computer vision meets speech and language. Such techniques provide a powerful illustration of how multimedia technologies incorporating speech, language and audio can make multimedia content collections better accessible, and thereby more useful, to users.", "references": ["F. Bechet and G. Gravier, editors. Proceedings of the 1st IEEE/ISCA International Workshop on Speech, Language and Audio in Multimedia, 2013.", "M. Eskevich, R. Aly, D. N. Racca, R. Ordelman, S. Chen, and G. J. F. Jones. The Search and Hyperlinking task at MediaEval 2014. In Working Notes Proc. of the MediaEval Workshop, 2014.", "M. Eskevich, G. J. Jones, R. Aly, R. J. Ordelman, S. Chen, D. Nadeem, C. Guinaudeau, G. Gravier, P. Sébillot, T. de Nies, P. Debevere, R. Van de Walle, P. Galuscakova, P. Pecina, and M. Larson. Multimedia information seeking through search and hyperlinking. In Proc. ACM Intl. Conf. on Multimedia Retrieval, pages 287--294, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806414"}, {"title": "Analytics for Hospital Management", "authors": ["Shusaku Tsumoto\n,", "Shoji Hirano"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThis paper proposes analytics for hospital management by using big data stored in a hospital information system. The key idea is analytics based on temporal information, whose visualization captures what domain experts cannot grasp from the raw data. The results show that the temporal visualization of stored data will give a powerful tool for hospital management and decision support..", "references": ["I. Bichindaritz. Memoire: A framework for semantic interoperability of case-based reasoning systems in biology and medicine. Artif Intell Med, 36(2):177--192, 2006.", "T. Cox and M. Cox. Multidimensional Scaling. Chapman & Hall/CRC, Boca Raton, 2nd edition, 2000.", "B. S. Everitt, S. Landau, M. Leese, and D. Stahl. Cluster Analysis. Wiley, 5th edition, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818894"}, {"title": "Location familiarity based flickr photographer classification for POI mining", "authors": ["Chenyi Zhuang\n,", "Qiang Ma\n,", "Masatoshi Yoshikawa"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nIn this paper, we propose and compare three ways of modeling photographers' location familiarity: a social network driven model, a time driven model and a location driven model. Then, the integration of the three models is further discussed. Experimental evaluations and analysis on a real data set consisting of 14,112 images collected from three cities well demonstrate the performance of the proposed classification methods. Many applications could benefit from information about the location familiarity, such as personalized geo-social recommendation, epidemic dispersion, urban computing, and so on.", "references": ["https://www.flickr.com/photos/walkingsf/sets/72157624209158632/.", "L. Backstrom, E. Sun, and C. Marlow. Find me if you can: improving geographical prediction with social and spatial proximity. In WWW, pages 61--70, 2010.", "C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag New York, Inc., 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820875"}, {"title": "A Fast k-Nearest Neighbor Search Using Query-Specific Signature Selection", "authors": ["Youngki Park\n,", "Heasoo Hwang\n,", "Sang-goo Lee"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nk-nearest neighbor (k-NN) search aims at finding k points nearest to a query point in a given dataset. k-NN search is important in various applications, but it becomes extremely expensive in a high-dimensional large dataset. To address this performance issue, locality-sensitive hashing (LSH) is suggested as a method of probabilistic dimension reduction while preserving the relative distances between points. However, the performance of existing LSH schemes is still inconsistent, requiring a large amount of search time in some datasets while the k-NN approximation accuracy is low. In this paper, we target on improving the performance of k-NN search and achieving a consistent k-NN search that performs well in various datasets. In this regard, we propose a novel LSH scheme called Signature Selection LSH (S2LSH). First, we generate a highly diversified signature pool containing signature regions of various sizes and shapes. Then, for a given query point, we rank signature regions of the query and select points in the highly ranked signature regions as k-NN candidates of the query. Extensive experiments show that our approach consistently outperforms the state-of-the-art LSH schemes.", "references": ["M. S. Charikar. Similarity estimation techniques from rounding algorithms. In STOC, pages 380--388. ACM, 2002.", "M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In SOCG, pages 253--262. ACM, 2004.", "J. Davidson, B. Liebald, J. Liu, P. Nandy, T. Van Vleet, U. Gargi, S. Gupta, Y. He, M. Lambert, B. Livingston, et al. The youtube video recommendation system. In RecSys, pages 293--296. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806632"}, {"title": "Offline Evaluation of Response Prediction in Online Advertising Auctions", "authors": ["Olivier Chapelle"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nClick-through rates and conversion rates are two core machine learning problems in online advertising. The evaluation of such systems is often based on traditional supervised learning metrics that ignore how the predictions are used. These predictions are in fact part of bidding systems in online advertising auctions. We present here an empirical evaluation of a metric that is specifically tailored for auctions in online advertising and show that it correlates better than standard metrics with A/B test results.", "references": ["O. Chapelle, E. Manavoglu, and R. Rosales. Simple and scalable response prediction for display advertising. ACM Transactions on Intelligent Systems and Technology, 5(4), 2014.", "O. Chapelle, J. Weston, L. Bottou, and V. Vapnik. Vicinal risk minimization. Advances in neural information processing systems, pages 416--422, 2001.", "B. Edelman, M. Ostrovsky, and M. Schwarz. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. American Economic Review, 97(1):242--259, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742566"}, {"title": "Fast Forward Index Methods for Pseudo-Relevance Feedback Retrieval", "authors": ["Edward Kai FUNG Dang\n,", "Robert Wing Pong Luk\n,", "James Allan"], "publication": "ACM Transactions on Information Systems", "abstract": "Abstract\nThe inverted index is the dominant indexing method in information retrieval systems. It enables fast return of the list of all documents containing a given query term. However, for retrieval schemes involving query expansion, as in pseudo-relevance feedback (PRF), the retrieval time based on an inverted index increases linearly with the number of expansion terms. In this regard, we have examined the use of a forward index, which consists of the mapping of each document to its constituent terms. We propose a novel forward index-based reranking scheme to shorten the PRF retrieval time. In our method, a first retrieval of the original query is performed using an inverted index, and then a forward index is employed for the PRF part. We have studied several new forward indexes, including using a novel spstring data structure and the weighted variable bit-block compression (wvbc) signature. With modern hardware such as solid-state drives (SSDs) and sufficiently large main memory, forward index methods are particularly promising. We find that with the whole index stored in main memory, PRF retrieval using a spstring or wvbc forward index excels in time efficiency over an inverted index, being able to obtain the same levels of performance measures at shorter times.", "references": ["Nasreen Abdul-Jaleel, James Allan, W. Bruce Croft, Fernando Diaz, Leah Larkey, Xiaoyan Li, Mark D. Smucker, and Courtney Wade. 2004. UMass at TREC 2004: Novelty and hard. In Proceedings of the 13th Text REtrieval Conference (TREC-13’04). 715--725.", "Giambattista Amati, Claudio Carpineto, and Giovanni Romano. 2004. Query difficulty, robustness, and selective application of query expansion. In Proceedings of the 25th European Conference on Information Retrieval (ECIR’04). 127--137.", "Gianni Amati and Cornelis Joost van Rijsbergen. 2002. Probabilistic models of information retrieval based on measuring the divergence from randomness. ACM Transactions on Information Systems 20, 4 (2002), 357--389."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744199"}, {"title": "Who, What, When, and Where: Multi-Dimensional Collaborative Recommendations Using Tensor Factorization on Sparse User-Generated Data", "authors": ["Preeti Bhargava\n,", "Thomas Phan\n,", "Jiayu Zhou\n,", "Juhan Lee"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nGiven the abundance of online information available to mobile users, particularly tourists and weekend travelers, recommender systems that effectively filter this information and suggest interesting participatory opportunities will become increasingly important. Previous work has explored recommending interesting locations; however, users would also benefit from recommendations for activities in which to participate at those locations along with suitable times and days. Thus, systems that provide collaborative recommendations involving multiple dimensions such as location, activities and time would enhance the overall experience of users.The relationship among these dimensions can be modeled by higher-order matrices called tensors which are then solved by tensor factorization. However, these tensors can be extremely sparse. In this paper, we present a system and an approach for performing multi-dimensional collaborative recommendations for Who (User), What (Activity), When (Time) and Where (Location), using tensor factorization on sparse user-generated data. We formulate an objective function which simultaneously factorizes coupled tensors and matrices constructed from heterogeneous data sources. We evaluate our system and approach on large-scale real world data sets consisting of 588,000 Flickr photos collected from three major metro regions in USA. We compare our approach with several state-of-the-art baselines and demonstrate that it outperforms all of them.", "references": ["E. Acar, D. M. Dunlavy, T. G. Kolda, and M. Mørup. Scalable tensor factorizations with missing data. In Proceedings of the SIAM International Conference on Data Mining, 2010.", "E. Acar, D. M. Dunlavy, T. G. Kolda, and M. Mørup. Scalable tensor factorizations for incomplete data. Chemometrics and Intelligent Laboratory Systems, 106(1):41--56, 2011.", "E. Acar, T. G. Kolda, and D. M. Dunlavy. All-at-once optimization for coupled matrix and tensor factorizations. In Proceedings of Mining and Learning with Graphs, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741077"}, {"title": "Transferring Learning To Rank Models for Web Search", "authors": ["Craig Macdonald\n,", "B. Taner Dinçer\n,", "Iadh Ounis"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nLearning to rank techniques provide mechanisms for combining document feature values into learned models that produce effective rankings. However, issues concerning the transferability of learned models between different corpora or subsets of the same corpus are not yet well understood. For instance, is the importance of different feature sets consistent between subsets of a corpus, or whether a learned model obtained on a small subset of the corpus effectively transfer to the larger corpus? By formulating our experiments around two null hypotheses, in this work, we apply a full-factorial experiment design to empirically investigate these questions using the ClueWeb09 and ClueWeb12 corpora, combined with queries from the TREC Web track. Among other observations, our experiments reveal that Clue-Web09 remains an effective choice of training corpus for learning effective models for ClueWeb12, and also that the importance of query independent features varies among the ClueWeb09 and ClueWeb12 corpora. In doing so, this work contributes an important study into the transferability of learning to rank models, as well as empirically-derived best practices for effective retrieval on the ClueWeb12 corpus.", "references": ["G. Amati, E. Ambrosi, M. Bianchi, C. Gaibisso, and G. Gambosi. FUB, IASI-CNR and University of Tor Vergata at the TREC 2007 Blog track. In Proceedings of TREC, 2007.", "M. Bendersky, W. B. Croft, and Y. Diao. Quality-biased ranking of Web documents. In Proceedings of WSDM, 2011.", "C. J. Burges. From RankNet to LambdaRank to LambdaMART: An Overview. Technical Report MSR-TR-2010-82, Microsoft Research, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809463"}, {"title": "Multimodal tag localization based on deep learning", "authors": ["Rui Zhang\n,", "Sheng Tang\n,", "Wu Liu\n,", "JinTao Li"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nTag localization which localizes the relevant video clips for an associated semantic tag has become an important research topic in the field of video retrieval and recommendation. Most existing approaches adopt and depend in large degree on carefully selected features which are manually designed by experts and do not take into consideration of multimodality. In order to take into account complementarity of different modalities and take advantage of learned features, in this paper, we propose a multimodal tag localization framework by exploiting deep learning to learn both visual and textual features of videos for tag localization, followed by the multimodal fusion of both visual and textual results. Extensive experiments on the public dataset show that our proposed approach achieves promising results. The tag localization based on visual deep learning greatly improves the precision of tag localization, and the multi-modal fusion of both visual and textual modalities further improves the precision despite the low performances of single textual modality.", "references": ["L. Ballan, M. Bertini, A. Del Bimbo, M. Meoni, and G. Serra. Tag suggestion and localization in user-generated videos based on social knowledge. In Proceedings of second ACM SIGMM workshop on Social media, pages 3--8. ACM, 2010.", "W.-T. Chu, C.-J. Li, and Y.-K. Chou. Tag suggestion and localization for web videos by bipartite graph matching. In Proceedings of the 3rd ACM SIGMM international workshop on Social media, pages 35--40. ACM, 2011.", "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248--255. IEEE, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808542"}, {"title": "A Preliminary Examination of the User Behavior in Query-by-Drawing Portrait Painting Search on Mobile Devices", "authors": ["Min Zhang\n,", "Guoping Qiu\n,", "Natasha Alechina\n,", "Sarah Atkinson"], "publication": "MoMM 2015: Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia", "abstract": "ABSTRACT\nAlthough many researchers have studied the user behavior of using text-based information search engine, less is known about search pattern for mobile content-based image search. We developed a Query-by-Drawing (QbD) mobile application, and conducted a user study on it to explore the search behavior of painting search by drawing on the touchscreen phone. Based on the resulting drawings and video-logs of drawing procedures on three task conditions, we analyzed the patterns of query formulation and query modification. We further examined the effects of user characteristic and task type on the search strategy when using our mobile application. The results elicited some guidelines for mobile QbD image search interface design and informed the potential improvements of our application.", "references": ["Aula, A. 2003. Query formulation in web information search. In Proc. WWW/Internet, ACM Press, 403--410.", "Banfi, F. 2000. Content-based image retrieval using hand-drawn sketches and local features -- a study on visual dissimilarities, PhD Thesis, University of Friberg.", "Choi, Y. and Rasmussen, E.M. 2003. Searching for images: the analysis of users' queries for image retrieval in American history. In J. ASIS&T 54, 6, 498--511."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837126.2837182"}, {"title": "Demonstration of the generic software framework for the integrated intelligent computer-assisted language learning (iiCALL) environment", "authors": ["Harald Wahl\n,", "Rudolf Galler\n,", "Werner Winiwarter"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nThe Integrated Intelligent Computer-Assisted Language Learning (iiCALL) environment enables language learning within common working environment like Web browsers or e-mail clients. Based on a generic data model, we developed a software framework for generic and transparent information exchange within those environments. The applicability of both is proven empirically by implementation of a corresponding prototype. The software framework constitutes a major improvement compared to current research. It enables a decoupled realization of individual systems within an iiCALL environment, while still ensuring interoperability during runtime.", "references": ["M. Levy, Computer-Assisted Language Learning: Context and Conceptualization. 198 Madison Ave., New York: Oxford University Press, 1997.", "J. Gamper and J. Knapp, \"A review of intelligent CALL systems,\" Comput. Assist. Lang. Learn., vol. 15, no. 4, pp. 329--342, 2002.", "H. Wahl, W. Winiwarter, and G. Quirchmayr, \"Towards an intelligent integrated language learning environment,\" Int. J. Pervasive Comput. Commun., vol. 7, no. 3, pp. 220--239, Sep. 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837217"}, {"title": "Social network analysis of public lists of POIs", "authors": ["Ioannis Karagiannis\n,", "Avi Arampatzis\n,", "Pavlos S. Efraimidis\n,", "Giorgos Stamatelatos"], "publication": "PCI '15: Proceedings of the 19th Panhellenic Conference on Informatics", "abstract": "ABSTRACT\nIn this work, we show how social network analysis can be applied to lists of points of interest (POIs) in order to extract important information about the POIs and the relations between them. More precisely, we use public lists of POIs to build the PoiGraph, a social graph of POIs, and then apply the Hyperlink-Induced Topic Search (HITS) algorithm and the Normalized Pointwise Mutual Information (NPMI) measure to estimate the user rating of each POI and the pairwise similarity between POIs, respectively. We evaluate our approach on POIs from the cities of Athens, Thessaloniki, and Rhodes. As a data source we use the corresponding publicly accessible user-specified lists of POIs of Foursquare. Our results show that for each POI the authority score obtained with the HITS algorithm is firmly correlated with the actual rating of Foursquare. Moreover, preliminary evidence shows that the NPMI-based measure gives valuable information about the pairwise similarity between POIs.", "references": ["G. Bouma. Normalized (pointwise) mutual information in collocation extraction. Proc. GSCL, pp 31--40, 2009.", "G. Drosatos, P. S. Efraimidis, A. Arampatzis, G. Stamatelatos, and I. N. Athanasiadis. Pythia: A privacy-enhanced personalized contextual suggestion system for tourisms. In IEEE COMPSAC 2015.", "D. Gavalas, C. Konstantopoulos, K. Mastakas, and G. Pantziou. Mobile recommender systems in tourism. J. of Netw. and Comp. Applic., 39(0):319--333, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2801948.2802031"}, {"title": "A Descriptive Analysis of a Large-Scale Collection of App Management Activities", "authors": ["Huoran Li\n,", "Xuanzhe Liu\n,", "Wei Ai\n,", "Qiaozhu Mei\n,", "Feng Feng"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nSmartphone users adopt an increasing number of mobile applications (a.k.a., apps) in the recent years. Investigating how people manage mobile apps in their everyday lives creates a unique opportunity to understand the behaviors and preferences of mobile users. Existing literature provides very limited understanding about app management activities, due to the lack of user behavioral data at scale. This paper analyzes a very large collection of app management log of the users of a leading Android app marketplace in China. The data set covers one month of detailed activities of how users download, update, and uninstall the apps on their smart devices, involving 8,306,181 anonymized users and 394,661 apps. We characterize how these users manage the apps on their devices and identify behavioral patterns that correlate with users' online ratings of the apps.", "references": ["S. Lim, P. Bentley, N. Kanakam, F. Ishikawa, and S. Honiden. Investigating country differences in mobile app user behavior and challenges for software engineering. IEEE Transactions on Software Engineering, 2014.", "B. Liu. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1--167, May 2012.", "M. Ott, C. Cardie, and J. Hancock. Estimating the prevalence of deception in online review communities. page 201. ACM Press, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742771"}, {"title": "CrowdIntent: annotation of intentions hidden in online discussions", "authors": ["Itzel Morales-Ramirez\n,", "Dimitra Papadimitriou\n,", "Anna Perini"], "publication": "CSI-SE '15: Proceedings of the Second International Workshop on CrowdSourcing in Software Engineering", "abstract": "ABSTRACT\nStakeholders working in open-source software development use social media, emails or any available means in the Internet to communicate and express what they want or need through the use of text. The recognition of such needs or desires (that we call intentions) is usually done by a human reader, and it can require a considerable effort when the amount of messages in online discussions increases. The problem is that to support an automated recognition of the intentions hidden in the text, data are needed in the domain of software development for training classifiers. However, so far there is no data annotated with intentions that can be used for data mining purposes. In order to tackle the lack of data we have collected online discussions in the domain of software development and asked people to annotate such discussions with intentions. This collection has been performed by crowdsourcing the task of annotating sentences with their hidden intention. In this paper we report the experience of carrying out a crowdsourcing project with a heterogeneous crowd. We discuss how we applied the steps of the crowdsourcing workflow in CrowdIntent. Lessons learned and future work are also presented.", "references": ["P. Laurent and J. Cleland-Huang, \"Lessons learned from open source projects for facilitating online requirements processes,\" in REFSQ 2009, June 8-9, ser. LNCS, vol. 5512. Springer, 2009, pp. 240--255. {Online}. Available: http://dx.doi.org/10.1007/978-3-642-02050-6_21", "N. Novielli and C. Strapparava, \"Dialogue act classification exploiting lexical semantics,\" in Conversational Agents and Natural Language Interaction: Techniques and Effective Practices. IGI Global, 2011, pp. 80--106.", "I. Morales-Ramirez, M. Vergne, M. Morandini, A. Siena, A. Perini, and A. Susi, \"Who is the expert? combining intention and knowledge of online discussants in collaborative RE tasks,\" in ICSE '14, May 31 - June 07. ACM, 2014, pp. 452--455. {Online}. Available: http://doi.acm.org/10.1145/2591062.2591103"], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820116.2820121"}, {"title": "Learning from the uncertain: leveraging social communities to generate reliable training data for visual concept detection tasks", "authors": ["Christian Hentschel\n,", "Harald Sack"], "publication": "i-KNOW '15: Proceedings of the 15th International Conference on Knowledge Technologies and Data-driven Business", "abstract": "ABSTRACT\nRecent advances for visual concept detection based on deep convolutional neural networks have only been successful because of the availability of huge training datasets provided by benchmarking initiatives such as ImageNet. Assembly of reliably annotated training data still is a largely manual effort and can only be approached efficiently as crowd-working tasks. On the other hand, user generated photos and annotations are available at almost no costs in social photo communities such as Flickr. Leveraging the information available in these communities may help to extend existing datasets as well as to create new ones for completely different classification scenarios. However, user generated annotations of photos are known to be incomplete, subjective and do not necessarily relate to the depicted content. In this paper, we therefore present an approach to reliably identify photos relevant for a given visual concept category. We have downloaded additional metadata for 1 million Flickr images and have trained a language model based on user generated annotations. Relevance estimation is based on accordance of an image's annotation data with our language model and on subsequent visual re-ranking. Experimental results demonstrate the potential of the proposed method -- comparison with a baseline approach based on single tag matching shows significant improvements.", "references": ["K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the Devil in the Details: Delving Deep into Convolutional Nets. In M. Valstar, A. French, and T. Pridmore, editors, Proceedings of the British Machine Vision Conference. BMVA Press, 2014.", "D. Cireşan, U. Meier, J. Masci, and J. Schmidhuber. Multi-column deep neural network for traffic sign classification. Neural Networks, 32:333--338, 2012.", "J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. International Conference on Machine Learning, pages 647--655, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809563.2809587"}, {"title": "A complex event processing for large-scale M2M services and its performance evaluations", "authors": ["Yuji Kobayashi\n,", "Kazuhiko Isoyama\n,", "Koji Kida\n,", "Hiroki Tagato"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nThis paper describes a scalable complex event processing (CEP) system and rule allocation algorithm for large-scale M2M services and presents the results of its performance evaluations. Platforms providing M2M services deal with various data from massive event sources in the real world. To realize these services, a scalable system is required. Our previous system determines efficient allocation of CEP rules based on a single key attribute type. However, it cannot maintain scalability in M2M situation because CEP rules are defined by various attribute types and there is no single key attribute, i.e. common attribute type among CEP rules. The challenging issue in the present work is how to maintain scalability where no common attribute type usable for rule allocation. The key idea in this paper is to allocate CEP rules based on different attribute types for each CEP rule instead of single key attribute type. We propose a rule allocation algorithm that determines the efficient allocation of CEP rules when the system needs processing a large number of events, a large number of CEP rules, and various types of events. Evaluation results show that the system with the proposed algorithm is scalable with many CEP Servers. We thus conclude that the proposed algorithm contributes to the realization of large-scale M2M services.", "references": ["D. Luckham. The Power of Events. ISBN 0-201-72789, 2002.", "Microsoft Corporation. Home | Microsoft Azure Marketplace. http://datamarket.azure.com/. 18 August, 2014.", "Datamarket Inc. DataMarket - Find, Understand and Share Data - DataMarket. https://datamarket.com/. 18 August, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2776771"}, {"title": "A Context-Aware Model for Proactive Recommender Systems in the Tourism Domain", "authors": ["Matthias Braunhofer\n,", "Francesco Ricci\n,", "Béatrice Lamche\n,", "Wolfgang Wörndl"], "publication": "MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct", "abstract": "ABSTRACT\nA Proactive Recommender System (PRS) actively pushes recommendations to users when the current context seems appropriate. Despite the advantages of PRSs, especially in the mobile scenario where users could be provided with relevant items on-the-fly when needed, the area of PRSs is still unexplored with many challenges. In particular, it is crucial to identify the relevant items for the target users as well as to determine the right context for pushing these items, since otherwise the user acceptance, and therefore system success, will be negatively impacted. In this paper, we propose a new model that scores each item on two dimensions, preference fit and context fit, to proactively push relevant items to the target user in the right context. Furthermore, we present the preliminary design of a prototype of a mobile Point of Interest (POI) recommender which will be implemented in order to evaluate the practicality and effectiveness of our proposed model.", "references": ["Gediminas Adomavicius, Linas Baltrunas, Ernesto William de Luca, Tim Hussein, and Alexander Tuzhilin. 2012. 4th Workshop on Context-aware Recommender Systems (CARS 2012). In Proceedings of the Sixth ACM Conference on Recommender Systems. 349--350.", "Gerhard Fischer. 2012. Context-aware systems: the 'right' information, at the 'right' time, in the 'right' place, in the 'right' way, to the 'right' person. In Proceedings of the International Working Conference on Advanced Visual Interfaces. ACM, 287--294.", "Damianos Gavalas, Charalampos Konstantopoulos, Konstantinos Mastakas, and Grammati Pantziou. 2014. Mobile recommender systems in tourism. Journal of Network and Computer Applications 39 (2014), 319--333."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786567.2794332"}, {"title": "Location-Based Parallel Tag Completion for Geo-tagged Social Image Retrieval", "authors": ["Jiaming Zhang\n,", "Shuhui Wang\n,", "Qingming Huang"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nBenefit from tremendous growth of user-generated content, social annotated tags get higher importance in organization and retrieval of large scale image database on Online Sharing Websites (OSW). To obtain high-quality tags from existing community contributed tags with missing information and noise, tag-based annotation or recommendation methods have been proposed for performance promotion of tag prediction. While images from OSW contain rich social attributes, existing studies only utilize the relations between visual content and tags to construct global information completion models. In this paper, beyond the image-tag relation, we take full advantage of the ubiquitous GPS locations and image-user relationship, to enhance the accuracy of tag prediction and improve the computational efficiency. For GPS locations, we define the popular geo-locations where people tend to take more images as Points of Interests (POI), which are discovered by mean shift approach. For image-user relationship, we integrate a localized prior constraint, expecting the completed tag sub-matrix in each POI to maintain consistency with users' tagging behaviors. Based on these two key issues, we propose a unified tag matrix completion framework which learns the image-tag relation within each POI. To solve the proposed model, an efficient proximal sub-gradient descent algorithm is designed. The model optimization can be easily parallelized and distributed to learn the tag sub-matrix for each POI. Extensive experimental results reveal that the learned tag sub-matrix of each POI reflects the major trend of users' tagging results with respect to different POIs and users, and the parallel learning process provides strong support for processing large scale online image database.", "references": ["K. Barnard, P. Duygulu, D. Forsyth, N. De Freitas, D. M. Blei, and M. I. Jordan. Matching words and pictures. Journal of Machine Learning Research, 3:1107--1135, 2003.", "G. Carneiro, A. B. Chan, P. J. Moreno, and N. Vasconcelos. Supervised learning of semantic classes for image annotation and retrieval. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 29(3):394--410, 2007.", "C. Cartis, N. I. Gould, and P. L. Toint. On the evaluation complexity of composite function minimization with applications to nonconvex nonlinear programming. SIAM Journal on Optimization, 21(4):1721--1739, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749353"}, {"title": "ScaAnalyzer: a tool to identify memory scalability bottlenecks in parallel programs", "authors": ["Xu Liu\n,", "Bo Wu"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nIt is difficult to scale parallel programs in a system that employs a large number of cores. To identify scalability bottlenecks, existing tools principally pinpoint poor thread synchronization strategies or unnecessary data communication. Memory subsystem is one of the key contributors to poor parallel scaling in multicore machines. State-of-the-art tools, however, either lack sophisticated capabilities or are completely ignorant in pinpointing scalability bottlenecks arising from the memory subsystem. To address this issue, we develop a tool---ScaAnalyzer---to pinpoint scaling losses due to poor memory access behaviors of parallel programs. ScaAnalyzer collects, attributes, and analyzes memory-related metrics during program execution while incurring very low overhead. ScaAnalyzer provides high-level, detailed guidance to programmers for scalability optimization. We demonstrate the utility of ScaAnalyzer with case studies of three parallel programs. For each benchmark, ScaAnalyzer identifies scalability bottlenecks caused by poor memory access behaviors and provides optimization guidance that yields significant improvement in scalability.", "references": ["B. Bao and C. Ding. Defensive loop tiling for shared cache. In CGO, 2013.", "K. Beyls and E. D'Hollander. Discovery of locality-improving refactorings by reuse path analysis. Proc. of the 2nd Intl. Conf. on High Performance Computing and Communications (HPCC), 2006.", "B. Brett, P. Kumar, M. Kim, and H. Kim. CHiP: A profiler to measure the effect of cache contention on scalability. In IPDPS Workshops. IEEE, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807648"}, {"title": "Synthesis of partial rankings of points of interest using crowdsourcing", "authors": ["Ilkcan Keles\n,", "Simonas Saltenis\n,", "Christian S. Jensen"], "publication": "GIR '15: Proceedings of the 9th Workshop on Geographic Information Retrieval", "abstract": "ABSTRACT\nThe web is increasingly being accessed from mobile devices, and studies suggest that a large fraction of keyword-based search engine queries have local intent, meaning that users are interested in local content and that the underlying ranking function should take into account both relevance to the query keywords and the query location. A key challenge in being able to make progress on the design of ranking functions is to be able to assess the quality of the results returned by ranking functions. We propose a model that synthesizes a ranking of points of interest from answers to crowdsourced pairwise relevance questions. To evaluate the model, we propose an innovative methodology that enables evaluation of the quality of synthesized rankings in a simulated setting. We report on an experimental evaluation based on the methodology that shows that the proposed model produces promising results in pertinent settings and that it is capable of outperforming an approach based on majority voting.", "references": ["Google annual search statistics, June 2015. Available online at http://www.statisticbrain.com/google-searches/.", "O. Alonso and R. Baeza-Yates. Design and implementation of relevance assessments using crowdsourcing. In Advances in Information Retrieval, volume 6611 of Lecture Notes in Computer Science, pages 153--164. 2011.", "R. Blanco, H. Halpin, D. M. Herzig, P. Mika, J. Pound, H. S. Thompson, and T. Tran Duc. Repeatable and reliable search system evaluation using crowdsourcing. In Proc. of ACM SIGIR, pages 923--932, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837689.2837705"}, {"title": "Session details: Evaluation Metrics", "authors": ["Laure Soulier"], "publication": "ECol '15: Proceedings of the 2015 Workshop on Evaluation on Collaborative Information Retrieval and Seeking", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3257883"}, {"title": "Medical Image Mining System: MIMS", "authors": ["Neethu C. Joseph\n,", "Aswathy Wilson"], "publication": "WCI '15: Proceedings of the Third International Symposium on Women in Computing and Informatics", "abstract": "ABSTRACT\nData mining is an egress area for research, because a huge volume of electronic data is generated in each seconds. The image mining is a new outgrowth of data mining, in which the analysis of image data is carried out. In the case of medical images the mining is an important task. The increasingly large medical collections introduces big challenges in medical data management and retrieval. The medical images contains very crucial information's, which are important in the characterization of diseases. There is some medical information retrieval systems and also some medical image retrieval systems are existing. But that systems have some limitations and draw backs. This paper proposed a novel Medical Image Mining System, MIMS that performs the medical image retrieval task. The system extracts the SURF features from the images. The KD Tree method is used to indexing the feature dataset. The KNN classifier is used for image searching. This image retrieval system retrieves most of the similar images from the data base. The performance measures shows that the proposed system worked efficiently.", "references": ["Carlos Ordonez and Edward Omiecinski, Image Mining: A new approach for Data Mining. IEEE Publication", "Jiawei Han, Micheline Kamber, Jian Pei, 2000 Data Mining; Concepts and Techniques, 3rd ed. Morgan Kaufmann Publishers", "J. Priya and Dr. R. Manicka Chezian, july 2013 A survey on image mining techniques for image retrieval. IJARCET."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791405.2791516"}, {"title": "Session details: Workshops", "authors": ["Fernando Diaz\n,", "Diane Kelly"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe are pleased to introduce the Workshop Program for the 38th Annual SIGIR Conference. We received 14 workshop proposals, each of which was peer-reviewed by three members of the Workshops PC. After discussion of all submissions in the Workshops PC, as well as with the PC Chairs of the technical program, 7 workshops were accepted (50% acceptance rate). We sought to include topics that covered the breadth of expertise in the SIGIR community, would appeal to a diverse range of SIGIR attendees, and would push the state-of-the-art in IR research. We greatly appreciate all authors who submitted a proposal for consideration and all reviewers for their help in selecting which proposals to include in the program. Finally, we are grateful to Microsoft Research for providing workshop fee waivers for thirty-five students.\nThis year's workshops include new explorations of established topics such as temporal information retrieval, personalization, and question answering. The Workshop on Temporal, Social and Spatially-aware Information Access (#TAIA2015), now in its fourth year at SIGIR, explores the relationship between temporal information access and other data sources. Similarly, the Workshop on Social Personalization & Search (SPS2015) studies the opportunities for improved personalization provided by social data. The Web Question Answering Workshop studies next generation QA systems that go beyond simple factoid questions.\nIn addition to these familiar topics, you will find workshops investigating entirely new subareas of information retrieval. The Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR) focuses on testing the robustness of existing results in information retrieval. The Workshop on Privacy-Preserving Information Retrieval, which is in its second year, draws together researchers from the privacy and retrieval communities to improve the sensitivity of information retrieval research to user privacy concerns. The Graph Search Workshop studies information retrieval in highly structured information spaces, bringing some of the research topics from industry into a public academic venue. Last but not least, the Workshop on Neuro- Physiological Methods in Information Retrieval Research covers topics on the novel use of physiological data for information retrieval.\nWe believe this year's workshop program reflects the diversity of information retrieval research and are excited for the new directions it will enable and inspire. We hope you find this program interesting and thought-provoking.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/3255942"}, {"title": "Evaluating Tag Recommender Algorithms in Real-World Folksonomies: A Comparative Study", "authors": ["Dominik Kowald\n,", "Elisabeth Lex"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nTo date, the evaluation of tag recommender algorithms has mostly been conducted in limited ways, including p-core pruned datasets, a small set of compared algorithms and solely based on recommender accuracy. In this study, we use an open-source evaluation framework to compare a rich set of state-of-the-art algorithms in six unfiltered, open datasets via various metrics, measuring not only accuracy but also the diversity, novelty and computational costs of the approaches. We therefore provide a transparent and reproducible tag recommender evaluation in real-world folksonomies. Our results suggest that the efficacy of an algorithm highly depends on the given needs and thus, they should be of interest to both researchers and developers in the field of tag-based recommender systems.", "references": ["F. Belém, E. Martins, J. Almeida, and M. Gonçalves. Exploiting novelty and diversity in tag recommendation. In Advances in Information Retrieval, pages 380--391. Springer, 2013.", "S. Doerfel and R. Jaschke. An analysis of tag-recommender evaluation procedures. In Proc. of RecSys'13, pages 343--346. ACM, 2013.", "J. Gemmell, T. Schimoler, M. Ramezani, L. Christiansen, and B. Mobasher. Improving folkrank with item-based collaborative filtering. Recommender Systems & the Social Web, 2009."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2799664"}, {"title": "Session Search by Direct Policy Learning", "authors": ["Jiyun Luo\n,", "Xuchu Dong\n,", "Hui Yang"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nThis paper proposes a novel retrieval model for session search. Through gradient descent, the model finds optimal policies for the best search engine actions from what is observed in the user and search engine interactions. The proposed framework applies direct policy learning to session search such that it greatly reduce the model complexity than prior work. It is also a flexible design, which includes a wide range of features describing the rich interactions in session search. The framework is shown to be highly effective evaluated on the recent TREC Session Tracks. As part of the efforts to bring reinforcement learning to information retrieval, this paper makes a novel contribution in theoretical modeling for session search.", "references": ["M. Ageev, Q. Guo, D. Lagun, and E. Agichtein. Find it if you can: A game for modeling different types of web search success using interaction data. In SIGIR '11.", "L. Baird and A. Moore. Gradient descent for general reinforcement learning. In Advances in neural information processing systems 11. 1999.", "P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, and S. Vigna. The query-flow graph: Model and applications. In CIKM '08."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809461"}, {"title": "Using rule-based classifiers in systematic reviews: a semantic class association rules approach", "authors": ["Hamza Sellak\n,", "Brahim Ouhbi\n,", "Bouchra Frikh"], "publication": "iiWAS '15: Proceedings of the 17th International Conference on Information Integration and Web-based Applications & Services", "abstract": "ABSTRACT\nSystematic review is the scientific process that provides reliable answers to a particular research question by interpreting the current pertinent literature. There is a significant shift from using manual human approach to decision support tools that provides a semi-automated screening phase by reducing the required time and effort to the group of experts. Most of proposed works apply supervised Machine Learning (ML) algorithms to infer exclusion and inclusion rules by observing a human screener. Unless, these techniques holds very little promise in study identification phase, because the rate of excluding citations erroneously still unreasonable. In this paper, we contribute to this line of works by proposing an alternative approach, not yet tested in this domain based on semantic rule-based classifiers. This approach involved applying a novel Hybrid Feature Selection Method (HFSM) within a Class Association Rules (CARs) algorithm. Experiments are conducted on a corpus resulting from an actual systematic review. The obtained results show that our algorithm outperforms the existing algorithms in the literature.", "references": ["Kitchenham, B. A. 2004. Procedures for performing systematic reviews. Tech. Report TR/SE-0401, Software Engineering Group, Department of Computer Science Keele University, United King and Empirical Software Engineering, National ICT Australia Ltd, Australia, 2004.", "Kitchenham, B. A. and Charters, S. 2007. Guidelines for performing systematic literature reviews in software engineering. Technical Report EBSE 2007--001, Keele University and Durham University Joint Report, 2007.", "Wallace, B. C, Trikalinos, T. A. Lau, J., Brodley, C., and Schmid, C. H. 2010. Semi-automated screening of biomedical citations for systematic reviews. BMC Bioinformatics 2010, 11:55."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2837185.2837279"}, {"title": "REFECT: a novel paradigm for correcting short reads", "authors": ["Subrata Saha\n,", "Sanguthevar Rajasekaran"], "publication": "BCB '15: Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics", "abstract": "ABSTRACT\nSequencing technology has advanced rapidly. Millions to billions of short reads are sequenced from a DNA molecule in a single run by parallelizing the whole procedure. Since it is a very cost effective procedure and can be performed in a laboratory environment within a brief period of time, we see an explosion of the biological sequencing data. But there is a tradeoff between the abundance and accuracy of the sequencing reads. The limitations of the sequencing technology result in errors in the reads. The errors could be substitution(s), insertions and/or deletions in a single base or multiple bases. Although the errors are being greatly reduced with the advancement of the modern technology, it is still a serious concern as of today. The sequence assembler often fails to sequence the entire genome because of the errors in the reads. By identifying and correcting the erroneous bases of the reads, not only can we achieve high quality data but also the computational complexity of many biological applications can be greatly reduced. Traditional approaches employ overlaps among the reads to correct them. Biologists have successfully sequenced thousands of species and this effort is growing continuously. As a result, the list of species for which references are available is growing rapidly. Considering this fact we have developed a novel hybrid error correcting algorithm called HECTOR (Hybrid Error CorrecTOR). It employs both referential and de novo error correction techniques to correct errors in reads. We have done extensive experiments to reveal that HECTOR is indeed an effective error correction algorithm.", "references": ["M. Chaisson, P. Pevzner, and H. Tang. Fragment assembly with short reads. Bioinformatics (Oxford, England), 20:2067--2074, 2004.", "P. A. Pevzner, H. Tang, and M. S. Waterman. An Eulerian path approach to DNA fragment assembly. Proceedings of the National Academy of Sciences of the United States of America, 98:9748--9753, 2001.", "J. Butler et al. ALLPATHS: de novo assembly of whole-genome shotgun microreads. Genome Res, 18:810--820, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808719.2808725"}, {"title": "Exploiting NVM in large-scale graph analytics", "authors": ["Jasmina Malicevic\n,", "Subramanya Dulloor\n,", "Narayanan Sundaram\n,", "Nadathur Satish\n,", "Jeff Jackson\n,", "Willy Zwaenepoel"], "publication": "INFLOW '15: Proceedings of the 3rd Workshop on Interactions of NVM/FLASH with Operating Systems and Workloads", "abstract": "ABSTRACT\nData center applications like graph analytics require servers with ever larger memory capacities. DRAM scaling, however, is not able to match the increasing demands for capacity. Emerging byte-addressable, non-volatile memory technologies (NVM) offer a more scalable alternative, with memory that is directly addressable to software, but at a higher latency and lower bandwidth.\nUsing an NVM hardware emulator, we study the suitability of NVM in meeting the memory demands of four state of the art graph analytics frameworks, namely Graphlab, Galois, X-Stream and Graphmat. We evaluate their performance with popular algorithms (Pagerank, BFS, Triangle Counting and Collaborative filtering) by allocating memory exclusive from DRAM (DRAM-only) or emulated NVM (NVM-only).\nWhile all of these applications are sensitive to higher latency or lower bandwidth of NVM, resulting in performance degradation of up to 4x with NVM-only (compared to DRAM-only), we show that the performance impact is somewhat mitigated in the frameworks that exploit CPU memory-level parallelism and hardware prefetchers.\nFurther, we demonstrate that, in a hybrid memory system with NVM and DRAM, intelligent placement of application data based on their relative importance may help offset the overheads of the NVM-only solution in a cost-effective manner (i.e., using only a small amount of DRAM). Specifically, we show that, depending on the algorithm, Graphmat can achieve close to DRAM-only performance (within 1.2x) by placing only 6.7% to 31.5% of its total memory footprint in DRAM.", "references": ["http://newsroom.intel.com/community/intel_newsroom/blog/2015/07/28/intel-and-micron-produce-breakthrough-memory-technology.", "Introducing the Graph 500 - Cray User Group. https://cug.org/5-publications/proceedings_attendee_lists/CUG10CD/pages/1-program/final_program/CUG10_Proceedings/pages/authors/11-15Wednesday/14C-Murphy-paper.pdf, 2010.", "Crossbar Resistive Memory: The Future Technology for NAND Flash. http://www.crossbar-inc.com/assets/img/media/Crossbar-RRAM-Technology-Whitepaper-080413.pdf, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2819001.2819005"}, {"title": "Extracting logical hierarchical structure of HTML documents based on headings", "authors": ["Tomohiro Manabe\n,", "Keishi Tajima"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWe propose a method for extracting logical hierarchical structure of HTML documents. Because mark-up structure in HTML documents does not necessarily coincide with logical hierarchical structure, it is not trivial how to extract logical structure of HTML documents. Human readers, however, easily understand their logical structure. The key information used by them is headings in the documents. Human readers exploit the following properties of headings: (1) headings appear at the beginning of the corresponding blocks, (2) headings are given prominent visual styles, (3) headings of the same level share the same visual style, and (4) headings of higher levels are given more prominent visual styles. Our method also exploits these properties for extracting hierarchical headings and their associated blocks. Our experiment shows that our method outperforms existing methods. In addition, our method extracts not only hierarchical blocks but also their associated headings.", "references": ["M. D. Adelfio and H. Samet. Schema extraction for tabular data on the web. Proc. of VLDB, 6(6):421--432, 2013.", "A. Anjewierden. AIDAS: Incremental logical structure discovery in PDF documents. In Proc. of ICDAR, pages 374--378, 2001.", "A. Arasu and H. Garcia-Molina. Extracting structured data from web pages. In Proc. of SIGMOD, pages 337--348, 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824058"}, {"title": "FLORIN: a system to support (near) real-time applications on user generated content on daily news", "authors": ["Qingyuan Liu\n,", "Eduard C. Dragut\n,", "Arjun Mukherjee\n,", "Weiyi Meng"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nIn this paper, we propose a system, FLORIN, which provides support for near real-time applications on user generated content on daily news. FLORIN continuously crawls news outlets for articles and user comments accompanying them. It attaches the articles and comments to daily event stories. It identifies the opinionated content in user comments and performs named entity recognition on news articles. All these pieces of information are organized hierarchically and exportable to other applications. Multiple applications can be built on this data. We have implemented a sentiment analysis system that runs on top of it.", "references": ["Atefeh, F. and Khreich, W. A Survey of Techniques for Event Detection in Twitter. Computational Intelligence. 31, 1, 2015.", "Chen, Z., Mukherjee, A. and Liu, B. Aspect Extraction with Automated Prior Knowledge Learning. In ACL. 2014.", "Cottle, S. Media and the Arab uprisings of 2011: Research notes. In Journalism. 12, 5, 2011, 647--659."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824107"}, {"title": "A Comparison of Different Strategies for Automated Semantic Document Annotation", "authors": ["Gregor Große-Bölting\n,", "Chifumi Nishioka\n,", "Ansgar Scherp"], "publication": "K-CAP 2015: Proceedings of the 8th International Conference on Knowledge Capture", "abstract": "ABSTRACT\nWe introduce a framework for automated semantic document annotation that is composed of four processes, namely concept extraction, concept activation, annotation selection, and evaluation. The framework is used to implement and compare different annotation strategies motivated by the literature. For concept extraction, we apply entity detection with semantic hierarchical knowledge bases, Tri-gram, RAKE, and LDA. For concept activation, we compare a set of statistical, hierarchy-based, and graph-based methods. For selecting annotations, we compare top-k as well as kNN. In total, we define 43 different strategies including novel combinations like using graph-based activation with kNN. We have evaluated the strategies using three different datasets of varying size from three scientific disciplines (economics, politics, and computer science) that contain 100, 000 manually labeled documents in total. We obtain the best results on all three datasets by our novel combination of entity detection with graph-based activation (e.g., HITS and Degree) and kNN. For the economic and political science datasets, the best F-measure is .39 and .28, respectively. For the computer science dataset, the maximum F-measure of .33 can be reached. The experiments are the by far largest on scholarly content annotation, which typically are up to a few hundred documents per dataset only.", "references": ["F. Abel, E. Herder, and D. Krause. Extraction of professional interests from social web profiles. In Augmenting User Models with Real World Experiences to Enhance Personalization and Adaptation, pages 1--6. Springer, 2011.", "C. M. Bishop. Pattern recognition and machine learning. Springer, 2006.", "D. M. Blei and J. D. Lafferty. Dynamic topic models. In ICML, pages 113--120. ACM, 2006."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815833.2815838"}, {"title": "Geo-tagging non-spatial concepts", "authors": ["Amgad Madkour\n,", "Walid G. Aref\n,", "Mohamed Mokbel\n,", "Saleh Basalamah"], "publication": "MobiGIS '15: Proceedings of the Fourth ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems", "abstract": "ABSTRACT\nConcept Geo-tagging is the process of assigning a textual identifier that describes a real-world entity to a physical geographic location. A concept can either be a spatial concept where it possesses a spatial presence or be a non-spatial concept where it has no explicit spatial presence. Geo-tagging locations with non-spatial concepts that have no direct relation is a very useful and important operation but is also very challenging. The reason is that, being a non-spatial concept, e.g., crime, makes it hard to geo-tag it. This paper proposes using the semantic information associated with concepts and locations such as the type as a mean for identifying these relations. The co-occurrence of spatial and non-spatial concepts within the same textual resources, e.g., in the web, can be an indicator of a relationship between these spatial and non-spatial concepts. Techniques are presented for learning and modeling relations among spatial and non-spatial concepts from web textual resources. Co-occurring concepts are extracted and modeled as a graph of relations. This graph is used to infer the location types related to a concept. A location type can be a hospital, restaurant, an educational facility and so forth. Due to the immense number of relations that are generated from the extraction process, a semantically-guided query processing algorithm is introduced to prune the graph to the most relevant set of related concepts. For each concept, a set of most relevant types are matched against the location types. Experiments evaluate the proposed algorithm based on its filtering efficiency and the relevance of the discovered relationships. Performance results illustrate how semantically-guided query processing can outperform the baseline in terms of efficiency and relevancy. The proposed approach achieves an average precision of 74% across three different datasets.", "references": ["S. Auer, C. Bizer, G. Kobilarov, and J. Lehmann. Dbpedia: A nucleus for a web of open data. ISWC/ASWC, pages 722--735, 2007.", "L. Calderon-Benavides, C. Gonzalez-Caro, and R. Baeza-Yates. Towards a Deeper Understanding of the User's Query Intent. SIGIR, 2010.", "M. Egenhofer. Toward the semantic geospatial web. SIGSPATIAL, pages 1--4, 2002."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2834126.2834138"}, {"title": "On Term Selection Techniques for Patent Prior Art Search", "authors": ["Mona Golestan Far\n,", "Scott Sanner\n,", "Mohamed Reda Bouadjenek\n,", "Gabriela Ferraro\n,", "David Hawking"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nIn this paper, we investigate the influence of term selection on retrieval performance on the CLEF-IP prior art test collection, using the Description section of the patent query with Language Model (LM) and BM25 scoring functions. We find that an oracular relevance feedback system that extracts terms from the judged relevant documents far outperforms the baseline and performs twice as well on MAP as the best competitor in CLEF-IP 2010. We find a very clear term selection value threshold for use when choosing terms. We also noticed that most of the useful feedback terms are actually present in the original query and hypothesized that the baseline system could be substantially improved by removing negative query terms. We tried four simple automated approaches to identify negative terms for query reduction but we were unable to notably improve on the baseline performance with any of them. However, we show that a simple, minimal interactive relevance feedback approach where terms are selected from only the first retrieved relevant document outperforms the best result from CLEF-IP 2010 suggesting the promise of interactive methods for term selection in patent prior art search.", "references": ["S. Bashir and A. Rauber. Improving retrievability of patents in prior-art search. In ECIR, 2010.", "M. R. Bouadjenek, S. Sanner, and G. Ferraro. A Study of Query Reformulation for Patent Prior Art Search with Partial Patent Applications. In ICAIL, 2015.", "D. Ganguly, J. Leveling, W. Magdy, and G. J. Jones. Patent query reduction using pseudo relevance feedback. In CIKM, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767801"}, {"title": "QuickScorer: A Fast Algorithm to Rank Documents with Additive Ensembles of Regression Trees", "authors": ["Claudio Lucchese\n,", "Franco Maria Nardini\n,", "Salvatore Orlando\n,", "Raffaele Perego\n,", "Nicola Tonellotto\n,", "Rossano Venturini"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nLearning-to-Rank models based on additive ensembles of regression trees have proven to be very effective for ranking query results returned by Web search engines, a scenario where quality and efficiency requirements are very demanding. Unfortunately, the computational cost of these ranking models is high. Thus, several works already proposed solutions aiming at improving the efficiency of the scoring process by dealing with features and peculiarities of modern CPUs and memory hierarchies. In this paper, we present QuickScorer, a new algorithm that adopts a novel bitvector representation of the tree-based ranking model, and performs an interleaved traversal of the ensemble by means of simple logical bitwise operations. The performance of the proposed algorithm are unprecedented, due to its cache-aware approach, both in terms of data layout and access patterns, and to a control flow that entails very low branch mis-prediction rates. The experiments on real Learning-to-Rank datasets show that QuickScorer is able to achieve speedups over the best state-of-the-art baseline ranging from 2x to 6.5x.", "references": ["N. Asadi, J. Lin, and A. P. de Vries. Runtime optimizations for tree-based machine learning models. IEEE Trans. Knowl. Data Eng., 26(9):2281--2292, 2014.", "C. J. Burges. From ranknet to lambdarank to lambdamart: An overview. Technical Report MSR-TR-2010--82, 2010.", "B. B. Cambazoglu, H. Zaragoza, O. Chapelle, J. Chen, C. Liao, Z. Zheng, and J. Degenhardt. Early exit optimizations for additive machine learned ranking systems. In Proc. ACM WSDM, pages 411--420. ACM, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767733"}, {"title": "A semantic method for multiple resources exploitation", "authors": ["Abdullah Almuhaimeed\n,", "Maria Fasli"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nBeing able to extract and exploit information that is included in multiple resources (repositories, corpora, etc.) is essential to benefiting from the increasing availability and complementary nature of such data scattered across the World Wide Web. However, such an endeavour raises a number of challenges including dealing with the diverse structures of such resources, different relationships among such data, and the overlapping and complementary nature of the information. Thus, developing a semantic method that can extract semantic information and hidden associations would help overcome such difficulties that occur when dealing with multiple resources. This paper presents a new semantic method that exploits the overlap between various resources with different structures (i.e. ontologies as forms of structured data and corpora as examples of unstructured data) and employs semantic relations, specifically sibling relations, to infer new information that may not exist in the original resources. Then, this method employs the new information in a content-based recommender system to enhance the quality of the provided recommendations (i.e. articles) in complex fields that are inherently characterised by varying relations and structures, such as bioinformatics. In addition, this method is accompanied by an automatic tool that is responsible for tailoring individual recommendations to each user based on his/her profile.", "references": ["R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley Publishing Company, USA, 2nd edition, 2008.", "T. Bogers and A. van den Bosch. Recommending scientific articles using citeulike. In RecSys'08, pages 287--290, 2008.", "P. Borlund. The iir evaluation model: a framework for evaluation of interactive information retrieval systems. Information research, 8(3), 2003."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814868"}, {"title": "Summarizing Entity Descriptions for Effective and Efficient Human-centered Entity Linking", "authors": ["Gong Cheng\n,", "Danyun Xu\n,", "Yuzhong Qu"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nEntity linking connects the Web of documents with knowledge bases. It is the task of linking an entity mention in text to its corresponding entity in a knowledge base. Whereas a large body of work has been devoted to automatically generating candidate entities, or ranking and choosing from them, manual efforts are still needed, e.g., for defining gold-standard links for evaluating automatic approaches, and for improving the quality of links in crowdsourcing approaches. However, structured descriptions of entities in knowledge bases are sometimes very long. To avoid overloading human users with too much information and help them more efficiently choose an entity from candidates, we aim to substitute entire entity descriptions with compact, equally effective structured summaries that are automatically generated. To achieve it, our approach analyzes entity descriptions in the knowledge base and the context of entity mention from multiple perspectives, including characterizing and differentiating power, information overlap, and relevance to context. Extrinsic evaluation (where human users carry out entity linking tasks) and intrinsic evaluation (where human users rate summaries) demonstrate that summaries generated by our approach help human users carry out entity linking tasks more efficiently (22-23% faster), without significantly affecting the quality of links obtained; and our approach outperforms existing approaches to summarizing entity descriptions.", "references": ["J. Carbonell and J. Goldstein. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proc. SIGIR, pages 335--336, August 1998.", "G. Cheng and Y. Qu. Searching linked objects with Falcons: Approach, implementation and evaluation. Int'l J. Semant. Web Inf. Syst., 5(3):49--70, July-September 2009.", "G. Cheng, T. Tran, and Y. Qu. RELIN: Relatedness and informativeness-based centrality for entity summarization. In Proc. ISWC, pages 114--129, October 201"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741094"}, {"title": "Eighth Workshop on Exploiting Semantic Annotations in Information Retrieval (ESAIR'15)", "authors": ["Krisztian Balog\n,", "Jeffrey Dalton\n,", "Antoine Doucet\n,", "Yusra Ibrahim"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nThe amount of structured content published on the Web has been growing rapidly, making it possible to address increasingly complex information access tasks. Recent years have witnessed the emergence of large scale human-curated knowledge bases as well as a growing array of techniques that identify or extract information automatically from unstructured and semi-structured sources. The ESAIR workshop series aims to advance the general research agenda on the problem of creating and exploiting semantic annotations. The eighth edition of ESAIR sets its focus on applications. We dedicate a special \"annotations in action\" track to demonstrations that showcase innovative prototype systems, in addition to the regular research and position paper contributions. The workshop also features invited talks from leaders in the field. The desired outcome of ESAIR'15 is a roadmap and research agenda that guides academic efforts and aligns them with industrial directions and developments.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806879"}, {"title": "Herding \"small\" streaming queries", "authors": ["Bo Zong\n,", "Christos Gkantsidis\n,", "Milan Vojnovic"], "publication": "DEBS '15: Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems", "abstract": "ABSTRACT\nWe study the problem of placing streaming queries into servers. Unlike previous work, we focus on queries that consume events of relative low rates, each computed in a single server (i.e. no scaling-out per query). However, we need to place a very large and dynamic number of queries in relatively few servers. Our focus is motivated by the need to support a platform for hosting end-user streaming queries that may come from a variety of applications, such as the Cortana personal assistant.\nThe placement strives to reduce network and computational overheads. It exploits the observation that a large number of queries consume the same sources of events, and, hence, placing them in the same server in the platform reduces network overheads. However, the placement also needs to balance the load among the servers. A further complication arises from the requirement to allow the queries to read events from multiple sources concurrently (i.e., to join multiple streams).\nIn this paper, we formulate the problem of placing queries into the servers of a streaming platform. We propose approximation algorithms and derive approximation bounds for the following cases (a) the offline case where queries are stable and known ahead of time, akin to an \"oracle\", and (b) the online case without departures and known query popularities. For the general online problem, we propose effective heuristic algorithms. An extensive set of experiments demonstrates that the proposed algorithms provide good performance in a wide-range of scenarios.", "references": ["T. Akidau et al. \"MillWheel: Fault-tolerant Stream Processing at Internet Scale\". English. Proceedings of the VLDB Endowment 6.11 (2013).", "Amazon Elastic Compute Cloud (EC2). URL: http://aws. amazon.com/ec2/ (visited on 12/10/2013).", "Amazon Kinesis. URL: http://aws.amazon.com/kinesis/ (visited on 12/10/2013)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2675743.2771825"}, {"title": "Educational Data Mining and Learning Analytics in Programming: Literature Review and Case Studies", "authors": ["Petri Ihantola\n,", "Arto Vihavainen\n,", "Alireza Ahadi\n,", "Matthew Butler\n,", "Jürgen Börstler\n,", "Stephen H. Edwards\n,", "Essi Isohanni\n,", "Ari Korhonen\n,"], "publication": "ITICSE-WGR '15: Proceedings of the 2015 ITiCSE on Working Group Reports", "abstract": "ABSTRACT\nEducational data mining and learning analytics promise better understanding of student behavior and knowledge, as well as new information on the tacit factors that contribute to student actions. This knowledge can be used to inform decisions related to course and tool design and pedagogy, and to further engage students and guide those at risk of failure. This working group report provides an overview of the body of knowledge regarding the use of educational data mining and learning analytics focused on the teaching and learning of programming. In a literature survey on mining students' programming processes for 2005-2015, we observe a significant increase in work related to the field. However, the majority of the studies focus on simplistic metric analysis and are conducted within a single institution and a single course. This indicates the existence of further avenues of research and a critical need for validation and replication to better understand the various contributing factors and the reasons why certain results occur. We introduce a novel taxonomy to analyse replicating studies and discuss the importance of replicating and reproducing previous work. We describe what is the state of the art in collecting and sharing programming data. To better understand the challenges involved in replicating or reproducing existing studies, we report our experiences from three case studies using programming data. Finally, we present a discussion of future directions for the education and research community.", "references": ["CodingBat. http://codingbat.com/help.html #teacher. Accessed: 2015-07-08.", "edX XServer. https://github.com/edx/xserver. Accessed: 2015-07-07.", "TuringsCraft CodeLab. http://www.turingscraft.com/. Accessed: 2015-07-07."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2858796.2858798"}, {"title": "Spatial Constraint for Image Location Estimation", "authors": ["Yisi Zhao\n,", "Xueming Qian"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nNowadays, image location has been widely used in many application scenarios for large geo-tagged image corpora. As to images which are not geographically tagged, we can estimate their locations with the help of the large geo-tagged image set by content based image retrieval. In this paper, we propose a global feature clustering and local feature refinement based image location estimation approach. We exploit spatial information by processing useful visual words. In this process, visual word groups are generated. Moreover to improve the retrieval performance, spatial constraint is utilized to code the relative position of visual words. Here we generate a position descriptor for each visual word. Experiments show the effectiveness of our proposed approach.", "references": ["Z. Wu, Q. Ke, M. Isard, and J. Sun, \"Bundling features for large scale partial-duplicate web image search,\" IEEE Conference on CVPR, pp. 25--32, 2009.", "W. Zhou, Y. Lu, H. Li, Y. Song, Q. Tian, \"Spatial Coding for Large Scale Partial-Duplicate Web Image Search,\" MM'10, Firenze, Italy. Copyright 2010 ACM.", "Y. Li, D. J. Crandall, D. P. Huttenlocher, \"Landmark Classification in Large-scale Image Collections,\" ICCV'09."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749327"}, {"title": "A fast pedestrians counting method based on haar features and spatio-temporal correlation analysis", "authors": ["Dong Hao\n,", "Xue Feng\n,", "Wu Fan\n,", "Yong Chengxi"], "publication": "ICIMCS '15: Proceedings of the 7th International Conference on Internet Multimedia Computing and Service", "abstract": "ABSTRACT\nIn recent years, with the development of computer vision technology, pedestrians counting is widely used in traffic, business and other applications. As the traditional pedestrians counting methods are susceptible to the influence of occlusion and large amounts of calculation, real-time performance and accuracy can not be solved very well. In this paper, we propose a novel method to fulfill pedestrians counting task accurately. First, we use Haar features and Adaboost algorithm to get a head classifier by sample training, which is consequently used to detect pedestrians in a predefined strip region inside the input video. At last, a statistics model called Spatio-temporal Correlation Analysis is designed to implement pedestrians tracking and counting. The experimental results show that our method is of low cost, high accuracy, and can be applied to many applications.", "references": ["Thomas Michelat, Nicolas Hueber, Pierre Raymond, etal. Automatic Pedestrian Detection and Counting Applied to Urban Planning{C}.Ami 2010, LINCS 6439, pp. 285--289, 2010", "Guillermo Garc, MIguel Torres-Torriti. A Density-Based Approach for Effective Pedestrian Counting at Bus Stops{C}.Proceedings of the 2009 IEEE International Conference on Systems, Man, and Cybernetics, October.2009", "Xia Jingjing, Gao Lin, Fan Yong People Statistics Based on Skeleton Feature Journal of Computer Applications 2014-02"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808492.2808545"}, {"title": "Towards A Novel Approach for Defect Localization Based on Part-of-Speech and Invocation", "authors": ["Yanxiang Tong\n,", "Yu Zhou\n,", "Lisheng Fang\n,", "Taolue Chen"], "publication": "Internetware '15: Proceedings of the 7th Asia-Pacific Symposium on Internetware", "abstract": "ABSTRACT\nGiven a corpus of bug reports, software developers must read various descriptive sentences in order to identify corresponding buggy source files which potentially result in the defects. This process itself represents one of the most expensive, as well as time-consuming, activities during software maintenance and evolution. To alleviate the workload of developers, many methods have been proposed to automate this process and narrow down the scope of reviewing buggy files. In this paper, we present a novel buggy source file localization approach, leveraging both a part-of-speech based weighting strategy and the invocation relationship among source files. We also integrate an adaptive technique to strengthen the optimization of the performance. The adaptive technique consists of two modules. One is to maximize the accuracy of the first recommended file, and the other aims at improving the accuracy of the fixed defect file list. We evaluate our approach on three large-scale open source projects, i.e., ASpectJ, Eclipse, and SWT. Compared with the baseline work, our approach can improve 17.13%, 6.29% and 3.15% on top 1, top 5 and top 10 respectively for ASpectJ, 6.40%, 4.94% and 4.39% on top 1, top 5 and top 10 respectively for Eclipse, and 15.31%, 8.16% and 5.10% on top 1, top 5 and top 10 respectively for SWT.", "references": ["S. L. Abebe and P. Tonella. Natural language parsing of program element names for concept extraction. In Program Comprehension (ICPC), 2010 IEEE 18th International Conference on, pages 156--159. IEEE, 2010.", "R. Abreu, P. Zoeteweij, and A. J. Van Gemund. Spectrum-based multiple fault localization. In Automated Software Engineering, 2009. ASE'09. 24th IEEE/ACM International Conference on, pages 88--99. IEEE, 2009.", "A. Bandyopadhyay. Improving spectrum-based fault localization using proximity-based weighting of test cases. In Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on, pages 660--664. IEEE, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2875913.2875919"}, {"title": "Load-sensitive CPU Power Management for Web Search Engines", "authors": ["Matteo Catena\n,", "Craig Macdonald\n,", "Nicola Tonellotto"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWeb search engine companies require power-hungry data centers with thousands of servers to efficiently perform searches on a large scale. This permits the search engines to serve high arrival rates of user queries with low latency, but poses economical and environmental concerns due to the power consumption of the servers. Existing power saving techniques sacrifice the raw performance of a server for reduced power absorption, by scaling the frequency of the server's CPU according to its utilization. For instance, current Linux kernels include frequency governors i.e., mechanisms designed to dynamically throttle the CPU operational frequency. However, such general-domain techniques work at the operating system level and have no knowledge about the querying operations of the server. In this work, we propose to delegate CPU power management to search engine-specific governors. These can leverage knowledge coming from the querying operations, such as the query server utilization and load. By exploiting such additional knowledge, we can appropriately throttle the CPU frequency thereby reducing the query server power consumption. Experiments are conducted upon the TREC ClueWeb09 corpus and the query stream from the MSN 2006 query log. Results show that we can reduce up to ~24% a server power consumption, with only limited drawbacks in effectiveness w.r.t. a system running at maximum CPU frequency to promote query processing quality.", "references": ["L. A. Barroso, J. Dean, and U. Hölzle. Web Search for a Planet: The Google Cluster Architecture. IEEE Micro, 23(2):22--28, 2003.", "A. Z. Broder, D. Carmel, M. Herscovici, A. Soffer, and J. Zien. Efficient query evaluation using a two-level retrieval process. In CIKM, 2003, pages 426--434.", "D. Brodowski. CPU frequency and voltage scaling code in the Linux kernel: Linux CPUFreq. https://www.kernel.org/doc/Documentation/cpu-freq/index.txt, Visited: 2015-02--16."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767809"}, {"title": "Design and implementation of an artificial neural network applied to finger bad-positioning detection on touchless multiview fingerprints devices", "authors": ["Caue Zaghetto\n,", "Luiz Henrique M. Aguiar\n,", "Alexandre Zaghetto\n,", "Flavio de Barros Vidal"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nThis paper presents a method based on Artificial Neural Network that evaluates the rotational bad-positioning of fingers on touchless multiview fingerprinting devices. The objective is to determine whether the finger is rotated or not, since a proper positioning of the finger is mandatory for high fingerprint matching rates. A test set of 9000 acquired images has being used to train, validate and test the proposed multilayer Artificial Neural Network classifier. To our knowledge, there is no definitive method that addressed the problem of fingerprint quality on touchless multiview scanners. The proposed finger rotation detection here presented is one of the steps that must be taken into account if a future automatic image quality assessment method is to be considered. Average results show that: (a) our classifier correctly identifies bad-positioning in approximately 94% of cases; and (b) if bad-positioning is detected, the rotation angle is correctly estimated in 90% evaluations.", "references": ["R. Allen, P. Sankar, and S. Prabhakar. Fingerprint identification technology. In J. Wayman, A. Jain, D. Maltoni, and D. Maio, editors, Biometric Systems: Technology, Design and Performance Evaluation, chapter 2. Springer, London, 2005.", "M. AlTarawneh, W. Woo, and S. Dlay. Objective fingerprint image quality assessment using gabor spectrum approach. In Digital Signal Processing, 2007 15th International Conference on, pages 248-251, July 2007.", "H. Demuth, M. Beale, H. Demuth, and M. Beale. Neural network toolbox for use with matlab, 1993."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814093"}, {"title": "Enabling Adaptive Scientific Workflows Via Trigger Detection", "authors": ["Maher Salloum\n,", "Janine C. Bennett\n,", "Ali Pinar\n,", "Ankit Bhagatwala\n,", "Jacqueline H. Chen"], "publication": "ISAV2015: Proceedings of the First Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization", "abstract": "ABSTRACT\nNext generation architectures necessitate a shift away from traditional workflows in which the simulation state is saved at prescribed frequencies for post-processing analysis. While the need to shift to in situ workflows has been acknowledged for some time, much of the current research is focused on static workflows, where the analysis that would have been done as a post-process is performed concurrently with the simulation at user-prescribed frequencies. Recently, research efforts are striving to enable adaptive workflows, in which the frequency, composition, and execution of computational and data manipulation steps dynamically depend on the state of the simulation. Adapting the workflow to the state of simulation in such a data-driven fashion puts extremely strict efficiency requirements on the analysis capabilities that are used to identify the transitions in the workflow. In this paper we build upon earlier work on trigger detection using sublinear techniques to drive adaptive workflows. Here we propose a methodology to detect the time when sudden heat release occurs in simulations of turbulent combustion. Our proposed method provides an alternative metric that can be used along with our former metric to increase the robustness of trigger detection. We show the effectiveness of our metric empirically for predicting heat release for two use cases.", "references": ["H. Abbasi, G. Eisenhauer, M. Wolf, K. Schwan, and S. Klasky. Just In Time: Adding Value to The IO Pipelines of High Performance Applications with JITStaging. In Proc. of 20th International Symposium on High Performance Distributed Computing (HPDC'11), June 2011.", "J. C. Bennett, H. Abbasi, P.-T. Bremer, R. Grout, A. Gyulassy, T. Jin, S. Klasky, H. Kolla, M. Parashar, V. Pascucci, P. Pebay, D. Thompson, H. Yu, F. Zhang, and J. Chen. Combining in-situ and in-transit processing to enable extreme-scale scientific analysis. In J. Hollingsworth, editor, SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis, Salt Lake Convention Center, Salt Lake City, UT, USA, November 10--16, 2012, pages 49:1--49:9, pub-IEEE:adr, 2012. IEEE Computer Society Press.", "J. C. Bennett, A. Bhagatwala, J. H. Chen, C. Seshadhri, A. Pinar, and M. Salloum. Trigger detection for adaptive scientific workflows using percentile sampling. Technical report, 2015. arXiv:1506.08258."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2828612.2828619"}, {"title": "Affect Recognition in a Realistic Movie Dataset Using a Hierarchical Approach", "authors": ["Joël Dumoulin\n,", "Diana Affi\n,", "Elena Mugellini\n,", "Omar Abou Khaled\n,", "Marco Bertini\n,", "Alberto Del Bimbo"], "publication": "ASM '15: Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia", "abstract": "ABSTRACT\nAffective content analysis has gained great attention in recent years and is an important challenge of content-based multimedia information retrieval. In this paper, a hierarchical approach is proposed for affect recognition in movie datasets. This approach has been verified on the AFEW dataset, showing an improvement in classification results compared to the baseline. In order to use all the visual sentiment aspects contained in the movies excerpts of a realistic dataset such as FilmStim, deep learning features trained on a large set of emotional images are added to the standard audio and visual features. The proposed approach will be integrated in a system that communicates the emotions of a movie to impaired people and contribute to improve their television experience.", "references": ["T. Chen, D. Borth, T. Darrell, and S.-f. Chang. DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks. CoRR, abs/1410.8, 2014.", "A. Dhall, R. Goecke, J. Joshi, K. Sikka, and T. Gedeon. Emotion Recognition In The Wild Challenge 2014 : Baseline , Data and Protocol. In Proc. of ICMI, 2014.", "A. Dhall, R. Goecke, S. Lucey, and T. Gedeon. Collecting large, richly annotated facial-expression databases from movies. IEEE MultiMedia, 19(3):34--41, July 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2813524.2813526"}, {"title": "Scalable methods to collect and visualize sidewalk accessibility data for people with mobility impairments: an overview", "authors": ["Kotaro Hara"], "publication": "ACM SIGACCESS Accessibility and Computing", "abstract": "Abstract\nPoorly maintained sidewalks pose considerable accessibility challenges for mobility impaired persons; however, there are currently few, if any, mechanisms to determine accessible areas of a city a priori. In this paper, I introduce four threads of research that I will conduct for my Ph.D. thesis aimed at creating new methods and tools to provide unprecedented levels of information on the accessibility of streets and sidewalk.", "references": ["Han, F. and Zhu, S.C. Bottom-Up/Top-Down Image Parsing with Attribute Grammar. IEEE Trans. Pattern Anal. Mach. Intell. 31, 1 (2009), 59-73.", "Hara, K., Le, V., and Froehlich, J. A Feasibility Study of Crowdsourcing and Google Street View to Determine Sidewalk Accessibility. Proc. of ASSETS 2012", "Hara, K., Le, V., and Froehlich, J. Combining Crowdsourcing and Google Street View to Identify Street-level Accessibility Problems. Proc. of CHI 2013"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2809904.2809912"}, {"title": "Location and Time Aware Social Collaborative Retrieval for New Successive Point-of-Interest Recommendation", "authors": ["Wei Zhang\n,", "Jianyong Wang"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nIn location-based social networks (LBSNs), new successive point-of-interest (POI) recommendation is a newly formulated task which tries to regard the POI a user currently visits as his POI-related query and recommend new POIs the user has not visited before. While carefully designed methods are proposed to solve this problem, they ignore the essence of the task which involves retrieval and recommendation problem simultaneously and fail to employ the social relations or temporal information adequately to improve the results.\nIn order to solve this problem, we propose a new model called location and time aware social collaborative retrieval model (LTSCR), which has two distinct advantages: (1) it models the location, time, and social information simultaneously for the successive POI recommendation task; (2) it efficiently utilizes the merits of the collaborative retrieval model which leverages weighted approximately ranked pairwise (WARP) loss for achieving better top-n ranking results, just as the new successive POI recommendation task needs. We conducted some comprehensive experiments on publicly available datasets and demonstrate the power of the proposed method, with 46.6% growth in Precision@5 and 47.3% improvement in Recall@5 over the best previous method.", "references": ["A. Ahmed, L. Hong, and A. J. Smola. Hierarchical geographical modeling of user locations from social media posts. In WWW, pages 25--36, 2013.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993--1022, Mar. 2003.", "C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix factorization with geographical and social influence in location-based social networks. In AAAI, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806564"}, {"title": "A Security-assured Accuracy-maximised Privacy Preserving Collaborative Filtering Recommendation Algorithm", "authors": ["Zhigang Lu\n,", "Hong Shen"], "publication": "IDEAS '15: Proceedings of the 19th International Database Engineering & Applications Symposium", "abstract": "ABSTRACT\nThe neighbourhood-based Collaborative Filtering is a widely used method in recommender systems. However, the risks of revealing customers' privacy during the process of filtering have attracted noticeable public concern recently. Specifically, kNN attack discloses the target user's sensitive information by creating k fake nearest neighbours by non-sensitive information. Among the current solutions against kNN attack, the probabilistic methods showed a powerful privacy preserving effect. However, the existing probabilistic methods neither guarantee enough prediction accuracy due to the global randomness, nor provide assured security enforcement against kNN attack. To overcome the problems of current probabilistic methods, we propose a novel approach, Probabilistic Partitioned Neighbour Selection, to ensure a required security guarantee while achieving the optimal prediction accuracy against kNN attack. In this paper, we define the sum of k neighbours' similarity as the accuracy metric α, the number of user partitions, across which we select the k neighbours, as the security metric β. Differing from the present methods that globally selected neighbours, our method selects neighbours from each group with exponential differential privacy to decrease the magnitude of noise. Theoretical and experimental analysis show that to achieve the same security guarantee against kNN attack, our approach ensures the optimal prediction accuracy.", "references": ["P. Adamopoulos and A. Tuzhilin. On over-specialization and concentration bias of recommendations: Probabilistic neighborhood selection in collaborative filtering systems. In Proceedings of the 8th ACM Conference on Recommender Systems, RecSys '14, pages 153--160, New York, NY, USA, 2014. ACM.", "G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. on Knowl. and Data Eng., 17(6):734--749, June 2005.", "A. Bilge and H. Polat. An improved privacy-preserving dwt-based collaborative filtering scheme. Expert Systems with Applications, 39(3):3841--3854, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2790755.2790757"}, {"title": "StORMeD: stack overflow ready made data", "authors": ["Luca Ponzanelli\n,", "Andrea Mocci\n,", "Michele Lanza"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nStack Overflow is the de facto Question and Answer (Q&A) website for developers, and it has been used in many approaches by software engineering researchers to mine useful data. However, the contents of a Stack Overflow discussion are inherently heterogeneous, mixing natural language, source code, stack traces and configuration files in XML or JSON format.\nWe constructed a full island grammar capable of modeling the set of 700,000 Stack Overflow discussions talking about Java, building a heterogeneous abstract syntax tree (H-AST) of each post (question, answer or comment) in a discussion. The resulting dataset models every Stack Overflow discussion, providing a full H-AST for each type of structured fragment (i.e., JSON, XML, Java, Stack traces), and complementing this information with a set of basic meta-information like term frequency to enable natural language analyses. Our dataset allows the end-user to perform combined analyses of the Stack Overflow by visiting the H-AST of a discussion.", "references": ["L. Mamykina, B. Manoim, M. Mittal, G. Hripcsak, and B. Hartmann, \"Design lessons from the fastest Q&A site in the west,\" in Proc. of CHI 2011 (29th Conference on Human factors in computing systems). ACM, 2011, pp. 2857--2866.", "L. Ponzanelli, A. Mocci, A. Bacchelli, and M. Lanza, \"Understanding and Classifying the Quality of Technical Forum Questions,\" in Proceedings of QSIC 2014 (14th International Conference on Quality Software). IEEE CS Press, 2014, pp. 343--352.", "C. Treude, O. Barzilay, and M.-A. Storey, \"How do programmers ask and answer questions on the web? (nier track),\" in Proceedings of ICSE 2011 (33rd International Conference on Software Engineering), ACM, Ed., 2011, pp. 804--807."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820591"}, {"title": "A Study of Query Length Heuristics in Information Retrieval", "authors": ["Yuanhua Lv"], "publication": "CIKM '15: Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "abstract": "ABSTRACT\nQuery length has generally been regarded as a query-specific constant that does not affect document ranking. In this paper, we reveal that query length actually interacts with term frequency (TF) normalization, a key component of all effective retrieval models. Specifically, the longer the query is, the smaller the TF decay speed should be. In order to study the impact of query length, we present a desirable formal constraint to capture the heuristic of query length for retrieval. Our constraint analysis shows that current state-of-the-art retrieval functions, including BM25 and language models, fail to satisfy the constraint, and that, in order to solve this problem, the TF normalization component in a retrieval function should be adapted to query length. As an application, we develop a simple regression algorithm to adapt BM25 to query length, and demonstrate its effectiveness on several representative TREC collections.", "references": ["T. L. Chung, R. W. P. Luk, K. F. Wong, K. L. Kwok, and D. L. Lee. Adapting pivoted document-length normalization for query size: Experiments in chinese and english. ACM Trans. Asian Lang. Inf. Proc., 5(3):245--263, Sept. 2006.", "R. Cummins and C. O'Riordan. A constraint to automatically regulate document-length normalisation. In CIKM '12, pages 2443--2446, 2012.", "H. Fang, T. Tao, and C. Zhai. A formal study of information retrieval heuristics. In SIGIR '04, pages 49--56, 2004."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2806416.2806592"}, {"title": "Re-organized Topic Modeling for Micro-blogging Data", "authors": ["Guan-Bin Chen\n,", "Hung-Yu Kao"], "publication": "ASE BD&SI '15: Proceedings of the ASE BigData & SocialInformatics 2015", "abstract": "ABSTRACT\nThe large amount of text on the Internet cause people hard to understand the meaning in a short limit time. Topic models (e.g. LDA and PLSA) has been proposed to summarize the long text into several topic terms. In the recent years, the short text media such as tweet is very popular. However, directly applies the transitional topic model on the short text corpus usually gating non-coherent topics. Because there is no enough words to discover the word co-occurrence pattern in a short document. In this paper, we solve the lack of the local word co-occurrence problem in LDA. Thus, we proposed an improvement of word co-occurrence method to enhance the topic models. We generate new virtual documents by re-organizing the words in documents and just apply in the traditional LDA. The experimental result that show our RO-LDA method gets well results in the noisy Tweet dataset and the regular news title dataset. Moreover, there are two advantages in our methods. We do not need any external data and our proposed methods are based on the original topic model that we did not modify the model itself, thus our methods can easily apply to some other existing LDA based models.", "references": ["T. Hofmann, \"Probabilistic latent semantic analysis,\" in Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, pp. 289--296, 1999.", "D. M. Blei, A. Y. Ng, and M. I. Jordan, \"Latent dirichlet allocation,\" the Journal of machine Learning research, vol. 3, pp. 993--1022, 2003.", "M. Divya, K. Thendral, and S. Chitrakala, \"A Survey on Topic Modeling,\" International Journal of Recent Advances in Engineering & Technology (IJRAET), vol. 1, pp. 57--61, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818869.2818875"}, {"title": "What's Hot in The Theme: Query Dependent Emerging Topic Extraction from Social Streams", "authors": ["Yuki Endo\n,", "Hiroyuki Toda\n,", "Yoshimasa Koike"], "publication": "WWW '15 Companion: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nAnalyzing emerging topics from social media enables users to overview social movement and several web services to adopt current trends. Although existing studies mainly focus on extracting global emerging topics, efficient extraction of local ones related to a specific theme is still a challenging and unavoidable problem in social media analysis. We focus on extracting emerging social topics related to user-specified query words, and propose an extraction framework that uses a non-negative matrix factorization (NMF) modified for detecting temporal concentration and reducing noises. We conduct preliminary experiments for verifying our method using a Twitter dataset.", "references": ["ndersen, R. and Peres, Y.: Finding sparse cuts locally using evolving sets, In STOC'09, pp.235--244, 2009.", "uckley, C., Salton, G. and Allan, J.: Automatic retrieval with locality information using SMART, In the 1st Text Retrieval Conference (TREC-1), pp.59--72, 1992.", "hen, Y., Amiri, H., Li, Z. and Chua, T.-S.: Emerging topic detection for organizations from microblogs, In SIGIR'13, pp.43--52, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2740908.2742727"}, {"title": "Building 3D web applications using WebGL", "authors": ["Kenneth Russell"], "publication": "SA '15: SIGGRAPH Asia 2015 Courses", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2818143.2835232"}, {"title": "Petuum: A New Platform for Distributed Machine Learning on Big Data", "authors": ["Eric P. Xing\n,", "Qirong Ho\n,", "Wei Dai\n,", "Jin-Kyu Kim\n,", "Jinliang Wei\n,", "Seunghak Lee\n,", "Xun Zheng\n,", "Pengtao Xie\n,", "Abhimanu Kumar\n,", "Yaoliang Yu"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nHow can one build a distributed framework that allows efficient deployment of a wide spectrum of modern advanced machine learning (ML) programs for industrial-scale problems using Big Models (100s of billions of parameters) on Big Data (terabytes or petabytes)- Contemporary parallelization strategies employ fine-grained operations and scheduling beyond the classic bulk-synchronous processing paradigm popularized by MapReduce, or even specialized operators relying on graphical representations of ML programs. The variety of approaches tends to pull systems and algorithms design in different directions, and it remains difficult to find a universal platform applicable to a wide range of different ML programs at scale. We propose a general-purpose framework that systematically addresses data- and model-parallel challenges in large-scale ML, by leveraging several fundamental properties underlying ML programs that make them different from conventional operation-centric programs: error tolerance, dynamic structure, and nonuniform convergence; all stem from the optimization-centric nature shared in ML programs' mathematical definitions, and the iterative-convergent behavior of their algorithmic solutions. These properties present unique opportunities for an integrative system design, built on bounded-latency network synchronization and dynamic load-balancing scheduling, which is efficient, programmable, and enjoys provable correctness guarantees. We demonstrate how such a design in light of ML-first principles leads to significant performance improvements versus well-known implementations of several ML programs, allowing them to run in much less time and at considerably larger model sizes, on modestly-sized computer clusters.", "references": ["A. Agarwal and J. C. Duchi. Distributed delayed stochastic optimization. In NIPS, 2011.", "A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In WSDM, 2012.", "L. Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT'2010, pages 177--186. Springer, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783323"}, {"title": "Graph Learning on K Nearest Neighbours for Automatic Image Annotation", "authors": ["Feng Su\n,", "Like Xue"], "publication": "ICMR '15: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval", "abstract": "ABSTRACT\nImage annotation is an open and challenging task, especially with large label vocabulary. In this paper, we propose a novel graph learning based method for image annotation, which takes both advantages of the nearest neighbour based and the graph-based methods, by exploiting the graph learning method to propagate the labels on the graph corresponding to the K nearest neighbours of a test image. To acquire more effective graph weights for computing score for each label, besides the similarity of visual features, our method also considers the similarity of two label sets, which is computed based on the label correlation that captures the semantic information between two labels. In addition, we combine the image-to-label distance with the graph learning based score to compute the final decision value for labelling. The proposed method is evaluated on three benchmark datasets for image annotation. The result shows our method substantially outperforms the previous graph learning based methods, and our result matches the current state-of-the-art results in annotation quality.", "references": ["K. Barnard, P. Duygulu, D. Forsyth, N. de Freitas, D. M. Blei, and M. I. Jordan. Matching words and pictures. Journal of Machine Learning Research, 3:1107--1135, 2003.", "O. Boiman, E. Shechtman, and M. Irani. In defense of nearest-neighbor based image classification. In CVPR 2008, pages 1--8, 2008.", "G. Carneiro, A. B. Chan, P. J. Moreno, and N. Vasconcelos. Supervised learning of semantic classes for image annotation and retrieval. IEEE TPAMI 2007, 29(3):394--410, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2671188.2749383"}, {"title": "Session details: Best Paper Candidates", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252426"}, {"title": "Quick trigger on stack overflow: a study of gamification-influenced member tendencies", "authors": ["Yong Jin\n,", "Xin Yang\n,", "Raula Gaikovina Kula\n,", "Eunjong Choi\n,", "Katsuro Inoue\n,", "Hajimu Iida"], "publication": "MSR '15: Proceedings of the 12th Working Conference on Mining Software Repositories", "abstract": "ABSTRACT\nIn recent times, gamification has become a popular technique to aid online communities stimulate active member participation. Gamification promotes a reward-driven approach, usually measured by response-time. Possible concerns of gamification could a trade-off between speedy over quality responses. Conversely, bias toward easier question selection for maximum reward may exist. In this study, we analyze the distribution gamification-influenced tendencies on the Q&A Stack Overflow online community. In addition, we define some gamification-influenced metrics related to response time to a question post. We carried experiments of a four-month period analyzing 101,291 members posts. Over this period, we determined a Rapid Response time of 327 seconds (5.45 minutes). Key findings suggest that around 92% of SO members have fewer rapid responses that non-rapid responses. Accepted answers have no clear relationship with rapid responses. However, we did find that rapid responses significantly contain tags that did not follow their usual tagging tendencies.", "references": ["S. Subramanian, L. Inozemtseva, and R. Holmes, \"Live api documentation,\" in Proc. of Internl Conf. on Soft. Eng., ser. ICSE 2014. New York, NY, USA: ACM, 2014, pp. 643--652.", "P. C. Rigby and M. P. Robillard, \"Discovering essential code elements in informal documentation,\" in Proc. of Internl Conf. on Soft. Eng., ser. ICSE '13. Piscataway, NJ, USA: IEEE Press, 2013, pp. 832--841.", "M. Linares-Vásquez, G. Bavota, M. Di Penta, R. Oliveto, and D. Poshyvanyk, \"How do api changes trigger stack overflow discussions? a study on the android sdk,\" in Proc. of Internl Conf. on Prog. Comp., ser. ICPC 2014. New York, NY, USA: ACM, 2014, pp. 83--94."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2820518.2820580"}, {"title": "Probabilistic estimation of link travel times in dynamic road networks", "authors": ["Mohammad Asghari\n,", "Tobias Emrich\n,", "Ugur Demiryurek\n,", "Cyrus Shahabi"], "publication": "SIGSPATIAL '15: Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems", "abstract": "ABSTRACT\nDue to the availability of large historical and real-time traffic data, car navigation systems are becoming more and more advanced in predicting the travel time for various routes and finding the fastest route from a source to a destination given a start time. The most advanced of these systems predict the travel time of the routes, given past traffic patterns in order to find the best route. However, the best route is not necessarily a reliable route as well, i.e., the route with the least variation in possible travel times. The most reliable route is desirable when traveling with a deadline, e.g., to reach a flight at the airport or to arrive on time for an important meeting. To find the most reliable route, one needs to predict the probability distribution of travel times for that route. This in turn requires the estimation of travel time probability distributions for each and every link, given a link-entrance-time. In this paper we address the problem of computing these link travel time distributions. To the best of our knowledge there has not been any study on how to compute probability distributions for links (/edges) in road networks. We show how this first step can affect the accuracy of the travel time distribution over the entire route. Our final challenge is to evaluate the result of different approaches in computing these travel time distributions, which is difficult because the reported travel time is not a single value but a probabilistic distribution highly depending on the trip start time. We thus propose a statistical test that enables us to evaluate these outcomes.", "references": ["B. Pan, U. Demiryurek, C. Shahabi, and C. Gupta, \"Forecasting spatiotemporal impact of traffic incidents on road networks,\" in Data Mining (ICDM), 2013 IEEE 13th International Conference on, Dec 2013, pp. 587--596.", "A. D. Sarma, \"Why uncertainty in data is great?\" http://infoblog.stanford.edu/2008/07/why-uncertainty-in-data-is-great-posted.html, accessed: 2008-07.", "H. Frank, \"Shortest paths in probabilistic graphs,\" Operations Research, vol. 17, no. 4, pp. 583--599, 1969."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2820783.2820836"}, {"title": "Lecture Butler: Teaching Reasonable Lectures from a Lecture Video Archive", "authors": ["Martin Malchow\n,", "Matthias Bauer\n,", "Christoph Meinel"], "publication": "SIGUCCS '15: Proceedings of the 2015 ACM SIGUCCS Annual Conference", "abstract": "ABSTRACT\nLecture video archives offer a large variety of lecture recordings in different topics. Naturally, topics are described superficially, easily or detailed in different lectures. Users interested in certain topics have problems finding lectures describing a topic chronology from basic lectures to more detailed difficult lectures. The Lecture Butler is going to automatically offer e-learning students lectures for the topics of interest in chronological playlists. The approach is finding lecture information using title, description, OCR and ASR data. This data is indexed and searched by an in-memory database to fulfill the speed requirements for playlist creation. In the search results lectures are going to be ordered by lecture occurrence in the university semester time schedule or by given lecture level of difficulty. As a result students can automatically create playlists for their topic of interest in sequence of the lecture level. Hence, students are not overstrained by lectures when they start with basic lectures first. Basic lectures provide information to understand more complex lectures. The research shows that an automatic approach by adding the level of difficulty or university semester time table is going to show reasonable playlists to find topics of interest. This solves the main problem students encounter when they try to learn a topic step-by-step using recorded lectures. The approach will support and motivate students using e-learning opportunities.", "references": ["M. Bauer, M. Malchow, and C. Meinel. Enhance teleteaching videos with semantic technologies. In V. L. Uskov, R. J. Howlett, and L. C. Jain, editors, Smart Education and Smart e-Learning, volume 41 of Smart Innovation, Systems and Technologies, pages 105--115. Springer International Publishing, 2015.", "C. Bizer, J. Lehmann, G. Kobilarov, S. Auer, C. Becker, R. Cyganiak, and S. Hellmann. Dbpedia - a crystallization point for the web of data. Web Semantics: Science, Services and Agents on the World Wide Web, 7(3), 2009.", "K. H. Coursey, R. Mihalcea, and W. E. Moen. Automatic keyword extraction for learning object repositories. Proceedings of the American Society for Information Science and Technology, 45(1):1--10, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815546.2815557"}, {"title": "Big data system development: an embedded case study with a global outsourcing firm", "authors": ["Hong-Mei Chen\n,", "Rick Kazman\n,", "Serge Haziyev\n,", "Olha Hrytsay"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nBig data system development is dramatically different from small (traditional, structured) data system development. At the end of 2014, big data deployment is still scarce and failures abound. Outsourcing has become a main strategy for many enterprises. We therefore selected an outsourcing company who has successfully deployed big data projects for our study. Our research results from analyzing 10 outsourced big data projects provide a glimpse into early adopters of big data, illuminates the challenges for system development that stem from the 5Vs of big data and crystallizes the importance of architecture design choices and technology selection. We followed a collaborative practice research (CPR) method to develop and validate a new method, called BDD. BDD is the first attempt to systematically combine architecture design with data modeling approaches to address big data system development challenges. The use of reference architectures and a technology catalog are advancements to architecture design methods and are proving to be well-suited for big data system architecture design and system development.", "references": ["ADD (Attribute-Driven Design Method), SEI, http://www.sei.cmu.edu/architecture/tools/define/add.cfm.", "Brewer, E., \"CAP Twelve Years Later: How the \"Rules\" Have Changed\", Computer, vol. 45, no. 2, pp. 23--29, Feb. 2012.", "Bass, L. Clements, P. and Kazman, R. Software Architecture in Practice (3rd ed.). Pearson, 2013."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819302"}, {"title": "Bayesian Inference for Information Retrieval Evaluation", "authors": ["Ben Carterette"], "publication": "ICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information Retrieval", "abstract": "ABSTRACT\nA key component of experimentation in IR is statistical hypothesis testing, which researchers and developers use to make inferences about the effectiveness of their system relative to others. A statistical hypothesis test can tell us the likelihood that small mean differences in effectiveness (on the order of 5%, say) is due to randomness or measurement error, and thus is critical for making progress in research. But the tests typically used in IR - the t-test, the Wilcoxon signed-rank test - are very general, not developed specifically for the problems we face in information retrieval evaluation. A better approach would take advantage of the fact that the atomic unit of measurement in IR is the relevance judgment rather than the effectiveness measure, and develop tests that model relevance directly. In this work we present such an approach, showing theoretically that modeling relevance in this way naturally gives rise to the effectiveness measures we care about. We demonstrate the usefulness of our model on both simulated data and a diverse set of runs from various TREC tracks.", "references": ["Ben Carterette. On rank correlation and the distance between rankings. In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 436--443, 2009.", "Ben Carterette. Model-based inference about IR systems. In Proceedings of ICTIR, 2011.", "Ben Carterette. System effectiveness, user models, and user utility: A conceptual framework for investigation. In Proceedings of SIGIR, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2808194.2809469"}, {"title": "Distributed top-k query processing on multi-dimensional data with keywords", "authors": ["Daichi Amagata\n,", "Takahiro Hara\n,", "Shojiro Nishio"], "publication": "SSDBM '15: Proceedings of the 27th International Conference on Scientific and Statistical Database Management", "abstract": "ABSTRACT\nAs we are in the big data era, techniques for retrieving only user-desirable data objects from massive and diverse datasets is being required. Ranking queries, e.g., top-k queries, which rank data objects based on a user-specified scoring function, enable to find such interesting data for users, and have received significant attention due to its wide range of applications. While many techniques for both centralized and distributed top-k query processing have been developed, they do not consider query keywords, i.e., simply retrieving k data with the best score. Utilizing keywords, on the other hand, is a common approach in data (and information) retrieval. Despite of this fact, there is no study on retrieving top-k data containing all query keywords. We define, in this paper, a new query which enriches the conventional top-k queries, and propose some algorithms to solve the novel problem of how to efficiently retrieve k data objects with the best score and all query from distributed databases. Extensive experiments on both real and synthetic data have demonstrated the efficiency and scalability of our algorithms in terms of communication cost and running time.", "references": ["R. Akbarinia, E. Pacitti, and P. Valduriez. Reducing network traffic in unstructured p2p systems using top-k queries. Distributed and Parallel Databases, Springer, 19(2):67--86, 2006.", "B. Babcock and C. Olston. Distributed top-k monitoring. In SIGMOD, pages 28--39, 2003.", "W.-T. Balke and W. Kießling. Optimizing multi-feature queries for image databases. In VLDB, pages 10--14, 2000."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2791347.2791355"}, {"title": "Improving Top-N Recommendation for Cold-Start Users via Cross-Domain Information", "authors": ["Nima Mirbakhsh\n,", "Charles X. Ling"], "publication": "ACM Transactions on Knowledge Discovery from Data", "abstract": "Abstract\nMaking accurate recommendations for cold-start users is a challenging yet important problem in recommendation systems. Including more information from other domains is a natural solution to improve the recommendations. However, most previous work in cross-domain recommendations has focused on improving prediction accuracy with several severe limitations. In this article, we extend our previous work on clustering-based matrix factorization in single domains into cross domains. In addition, we utilize recent results on unobserved ratings. Our new method can more effectively utilize data from auxiliary domains to achieve better recommendations, especially for cold-start users. For example, our method improves the recall to 21% on average for cold-start users, whereas previous methods result in only 15% recall in the cross-domain Amazon dataset. We also observe almost the same improvements in the Epinions dataset. Considering that it is often difficult to make even a small improvement in recommendations, for cold- start users in particular, our result is quite significant.", "references": ["Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering 17, 6, 734--749. DOI:http://dx.doi.org/10.1109/TKDE.2005.99", "Wei Chen, Wynne Hsu, and Mong Li Lee. 2013. Making recommendations from multiple domains. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’13). ACM, New York, NY, 892--900. DOI:http://dx.doi.org/10.1145/2487575.2487638", "Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of recommender algorithms on top-N recommendation tasks. In Proceedings of the 4th ACM Conference on Recommender Systems (RecSys’10). ACM, New York, NY, 39--46. DOI:http://dx.doi.org/10.1145/1864708.1864721"], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2724720"}, {"title": "Industrial big data analytics: lessons from the trenches", "authors": ["Flavio Villanustre"], "publication": "BIGDSE '15: Proceedings of the First International Workshop on BIG Data Software Engineering", "abstract": "ABSTRACT\nBig Data Analytics in particular and Data Science in general have become key disciplines in the last decade. The convergence of Information Technology, Statistics and Mathematics, to explore and extract information from Big Data have challenged the way many industries used to operate, shifting the decision making process in many organizations. A new breed of Big Data platforms has appeared, to fulfill the needs to process data that is large, complex, variable and rapidly generated. The author describes the experience in this field from a company that provides Big Data analytics as its core business.", "references": ["G. Cao, and Y. Duan, \"A path model linking business analytics, data-driven culture, and competitive analysis,\" ECIS Proceedings, ECIS 2014, 2014.", "J. Dean and, S. Ghemawat, \"MapReduce: simplified data processing on large clusters,\" Sixth symposium on Operating System design and implementation, OSDI'04, San Francisco, CA, December 2004.", "A. Yoo, and I. Kaplan, \"Evaluating use of data flow systems for large graph analysis,\" Proceedings of the 2nd Workshop on many-task computing on grids and supercomputers, Article No. 5, ACM, New York, 2009, pp. 271--350."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2819289.2819291"}, {"title": "Yesquel: scalable sql storage for web applications", "authors": ["Marcos K. Aguilera\n,", "Joshua B. Leners\n,", "Michael Walfish"], "publication": "SOSP '15: Proceedings of the 25th Symposium on Operating Systems Principles", "abstract": "ABSTRACT\nWeb applications have been shifting their storage systems from sql to nosql systems. nosql systems scale well but drop many convenient sql features, such as joins, secondary indexes, and/or transactions. We design, develop, and evaluate Yesquel, a system that provides performance and scalability comparable to nosql with all the features of a sql relational system. Yesquel has a new architecture and a new distributed data structure, called YDBT, which Yesquel uses for storage, and which performs well under contention by many concurrent clients. We evaluate Yesquel and find that Yesquel performs almost as well as Redis---a popular nosql system---and much better than mysql Cluster, while handling sql queries at scale.", "references": ["Adya, A., Gruber, R., Liskov, B., and Maheshwari, U. Efficient optimistic concurrency control using loosely synchronized clocks. In International Conference on Management of Data (May 1995), pp. 23--34.", "Aguilera, M. K., Golab, W., and Shah, M. A practical scalable distributed B-tree. Proceedings of the VLDB Endowment 1, 1 (Aug. 2008), 598--609.", "Aguilera, M. K., Leners, J. B., Kotla, R., and Walfish, M. Yesquel: Scalable SQL storage for Web applications. In International Conference on Distributed Computing and Networking (Jan. 2015). Invited keynote presentation."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2815400.2815413"}, {"title": "Language Innovation and Change in On-line Social Networks", "authors": ["Daniel Kershaw\n,", "Matthew Rowe\n,", "Patrick Stacey"], "publication": "HT '15: Proceedings of the 26th ACM Conference on Hypertext & Social Media", "abstract": "ABSTRACT\nLanguage is fundamental to human communication - throughout the course of history language has constantly evolved. This can currently be seen in the changing forms of colloquial language in various on-line social networks (OSN's). These innovations in language are even appearing in every day life with the recent induction of `lol' and `rofl' into modern dictionaries. Changes and varying forms of language pose challenges to both academics and people in business when attempting to assess and communicate with different communities.\nIn this Ph.D, we aim to forecast online language change through the use of predictive and descriptive methodologies. Through using data sets mined from a number of OSNs, we aim to develop generalizable models and theories for assessing and predicting such language changes. We philosophically frame this work by drawing on structuration theory which helps us structure our analysis of the dynamics of language (re)production - i.e. by the agent (user), the social structure and their interplay. We draw on state-of-the-art work and methods, including the development of neural nets to analyse language usage, along with network and community classification too uncover social structures within language. Preliminary results have identified statistically significant innovations usage across communities across a number of OSN's, this was done by operationalizing known linguistic models of innovation acceptance.", "references": ["Distributional Semantics Resources for Biomedical Text Processing. pages 1--5, Nov. 2013.", "G. Aston and L. Burnard. The BNC handbook: exploring the British National Corpus with SARA. Capstone, 1998.", "D. K. Barnhart. A Calculus for New Words. 28(1):132--138, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2700171.2804449"}, {"title": "Relevance Scores for Triples from Type-Like Relations", "authors": ["Hannah Bast\n,", "Björn Buchhold\n,", "Elmar Haussmann"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nWe compute and evaluate relevance scores for knowledge-base triples from type-like relations. Such a score measures the degree to which an entity \"belongs\" to a type. For example, Quentin Tarantino has various professions, including Film Director, Screenwriter, and Actor. The first two would get a high score in our setting, because those are his main professions. The third would get a low score, because he mostly had cameo appearances in his own movies. Such scores are essential in the ranking for entity queries, e.g. \"American actors\" or \"Quentin Tarantino professions\". These scores are different from scores for \"correctness\" or \"accuracy\" (all three professions above are correct and accurate). We propose a variety of algorithms to compute these scores. For our evaluation we designed a new benchmark, which includes a ground truth based on about 14K human judgments obtained via crowdsourcing. Inter-judge agreement is slightly over 90%. Existing approaches from the literature give results far from the optimum. Our best algorithms achieve an agreement of about 80% with the ground truth.", "references": ["A. Balmin, V. Hristidis, and Y. Papakonstantinou. ObjectRank: Authority-based keyword search in databases. In VLDB, pages 564--575, 2004.", "K. Balog, P. Serdyukov, and A. P. de Vries. Overview of the TREC 2011 Entity Track. In TREC, 2011.", "H. Bast, F. Baurle, B. Buchhold, and E. Haussmann. Broccoli: Semantic full-text search at your fingertips. CoRR, abs/1207.2615, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767734"}, {"title": "Testing web applications with state objects", "authors": ["Arie van Deursen"], "publication": "Communications of the ACM", "abstract": "Abstract\nUse states to drive your tests.", "references": ["AngularJS. ngInclude directive; https://docs.angularjs.org/api/ng/directive/ngInclude.", "Antoniol, G., Briand, L.C., Di Penta, M. and Labiche, Y. A case study using the round-trip strategy for state-based class testing. In Proceedings 13th International Symposium on Software Reliability Engineering. IEEE (2002), 269--279.", "Binder, R.V. Testing Object-oriented Systems. Addison-Wesley, Reading, PA, 1999, Chapter 7."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2755501"}, {"title": "Urban data visualisation in a web browser", "authors": ["Jérémy Gaillard\n,", "Alexandre Vienne\n,", "Rémi Baume\n,", "Frédéric Pedrinis\n,", "Adrien Peytavie\n,", "Gilles Gesquière"], "publication": "Web3D '15: Proceedings of the 20th International Conference on 3D Web Technology", "abstract": "ABSTRACT\nCityGML is a recent standard developed to describe, store and exchange virtual city models. Numerous software programmes have been proposed to construct, edit, modify and visualize city models, but visualisation in a web browser is still challenging. In this paper we propose a framework based on standards for visualising a large amount of 3D city data. CityGML files are processed automatically to provide a city model composed of geometries, textures and semantics. Exchanges follow the pending Open Geospatial standard named 3D portrayal. In this paper, we also demonstrate that a solution where semantics and geometries are exchanged together is possible. An effort has been made to show that an approach based on progressive textures may also be possible.", "references": ["Behr, J., Eschler, P., Jung, Y. and Zöllner, M. 2009. X3DOM: A DOM-based HTML5/X3D Integration Model. Proceedings of the 14th International Conference on 3D Web Technology (2009), DOI = http://doi.acm.org/10.1145/1559764.1559784, 127--135.", "Chatuverdi, K. 2014. Web based 3D analysis and visualization using HTML5 and WebGL (2014)", "Evans, A., Romeo, M., Bahrehmand, A., Agenjo, J., and Blat, J. 2014. 3D graphics on the web: A survey. Computers & Graphics vol. 41 (2014), DOI = http://dx.doi.org/10.1016/j.cag.2014.02.002, 43--61."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2775292.2775302"}, {"title": "Spatial-aware Multimodal Location Estimation for Social Images", "authors": ["Jiewei Cao\n,", "Zi Huang\n,", "Yang Yang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nNowadays the locations of social images play an important role in geographic knowledge discovery. However, most social images still lack the location information, driving location estimation for social images to have recently become an active research topic. With the rapid growth of social images, new challenges have been posed: 1) data quality of social images is an issue because they are often associated with noises and error-prone user-generated content, such as junk comments and misspelled words; and 2) data sparsity exists in social images despite the large volume, since most of them are unevenly distributed around the world and their contextual information is often missing or incomplete. In this paper, we propose a spatial-aware multimodal location estimation (SMLE) framework to tackle the above challenges. Specifically, a spatial-aware language model (SLM) is proposed to detect the high quality location-indicative tags from large datasets. We also design a spatial-aware topic model, namely spatial-aware regularized latent semantic indexing (SRLSI), to discover geographic topics and alleviate the data sparseness problem existing in language modeling. Taking multi-modalities of social images into consideration, we employ the learning to rank approach to fuse multiple evidences derived from textual features represented by SLM and SRLSI, and visual features represented by bag-of-visual-words (BoVW). Importantly, an ad hoc method is introduced to construct the training dataset with spatial-aware relevance labels for learning to rank training. Finally, given a query image, its location is estimated as the location of its most relevant image returned from the learning to rank model. The proposed framework is evaluated on a public benchmark provided by MediaEval 2013 Placing Task, which contains more than 8.5 million images crawled from Flickr. Extensive experiments on this dataset demonstrate the superior performance of the proposed methods over the state-of-the-art approaches.", "references": ["R. Arandjelovic and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, pages 2911--2918, 2012.", "D. M. Blei. Probabilistic topic models. Commun. ACM, 55(4):77--84, 2012.", "Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: from pairwise approach to listwise approach. In ICML, pages 129--136, 2007."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806249"}, {"title": "A Risk Management Approach for Software Product Line Engineering", "authors": ["Luanna Lopes Lobato\n,", "Thiago Jabur Bittar"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nTSoftware Product Line (SPL) Engineering is a software development paradigm that fosters systematic reuse. It is focused on improving software practices, leading companies to experience benefits, such as reduced time-to-market and effort, and higher quality for the products delivered to customers. However, establishing a SPL is neither a simple nor a cheap task, and may affect several aspects of a software company. Besides, it involves a range of risks that may hinder project success. These have to be managed accordingly, so as to minimize the likelihood of project failure. Despite the importance of Risk Management (RM) for SPL Engineering, little has been published in terms of suitable and structured practices to cope with that. This present paper reports an approach for RM in SPL Engineering, named RiPLERM (Rise Product Line Engineering and Risk Management). The approach presents activities to structure RM in SPL projects, The design of the RiPLE-RM approach elaborated on results from empirical investigations, and was proposed to facilitate the management and provide significant insights that can be used to avoid and solve risks.", "references": ["Clements, P. and Northrop, L. Software Product Lines: Practices and Patterns. Addison-Wesley, Boston, MA, USA. 2001.", "Sommerville, I. Software engineering (8th ed.). Redwood City, CA, USA: Addison Wesley Longman Publishing Co., Inc., 2007.", "Quilty, G. and Cinnéide, M. Ó. Experiences with Software Product Line Development in Risk Management Software. Software Product Line Conference. Munich, august 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814112"}, {"title": "Software suite for gene and protein annotation prediction and similarity search", "authors": ["Davide Chicco\n,", "Marco Masseroli"], "publication": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "abstract": "Abstract\nIn the computational biology community, machine learning algorithms are key instruments for many applications, including the prediction of gene-functions based upon the available biomolecular annotations. Additionally, they may also be employed to compute similarity between genes or proteins. Here, we describe and discuss a software suite we developed to implement and make publicly available some of such prediction methods and a computational technique based upon Latent Semantic Indexing (LSI), which leverages both inferred and available annotations to search for semantically similar genes. The suite consists of three components. BioAnnotationPredictor is a computational software module to predict new gene-functions based upon Singular Value Decomposition of available annotations. SimilBio is a Web module that leverages annotations available or predicted by BioAnnotationPredictor to discover similarities between genes via LSI. The suite includes also SemSim, a new Web service built upon these modules to allow accessing them programmatically. We integrated SemSim in the Bio Search Computing framework (http://www.bioinformatics.deib.polimi.it/bio-seco/seco/), where users can exploit the Search Computing technology to run multi-topic complex queries on multiple integrated Web services. Accordingly, researchers may obtain ranked answers involving the computation of the functional similarity between genes in support of biomedical knowledge discovery.", "references": ["G. Pandey, V. Kumar, and M. Steinbach, \"Computational approaches for protein function prediction: A survey,\" Twin Cities: Dept. Comput. Sci. Eng., Univ. Minnesota, Minneapolis, MN, USA, 2006.", "G. H. Golub and C. Reinsch. \"Singular value decomposition and least squares solutions,\" Numerische Mathematik, vol. 14.5, pp. 403--420, 1970.", "P. Khatri, B. Done, A. Rao, A. Done, and S. Draghici, \"A semantic analysis of the annotations of the human genome,\" Bioinformatics, vol. 21, no. 16, pp. 3416--3421, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/TCBB.2014.2382127"}, {"title": "The 2014 Indian general election on Twitter: an analysis of changing political traditions", "authors": ["Kokil Jaidka\n,", "Saifuddin Ahmed"], "publication": "ICTD '15: Proceedings of the Seventh International Conference on Information and Communication Technologies and Development", "abstract": "ABSTRACT\nThis study investigates how politicians and citizens cooperate to create an e-democracy based on information dissemination and political awareness in an ICT environment, especially during elections. This research is conducted in the Indian context, where new ICT channels, such as Facebook and Twitter, were extensively used for campaigning and citizen engagement prior to elections. We downloaded 98,396 tweets posted by the official Twitter accounts of the top ten political parties during a two month period prior to election and conducted a three-level analysis to identify the overall trend in usage, the interactive characteristics of tweets and the functions driving the Twitter usage of political parties. Our findings show that the more successful parties used Twitter to push timely updates on online and offline campaign activities, to their followers. The exemplary use of Twitter for campaigns was by the Bharatiya Janta Party (BJP) Twitter account for interacting with the public, and by the Aam Aadmi Party (AAP) account for self-promotion and highlighting its party manifesto. Further, we identify the new paradigms created by political parties to engage and inform voters, driven on modern ICT. Our study is the first in analyzing Twitter usage by Indian political parties, and its findings corroborate seminal research in other developing countries.", "references": ["Heeks, R. (2009). The ICT4D 2.0 manifesto: Where next for ICTs and international development. University of Manchester. Institute for development policy and management (IDPM). Development informatics group.", "Gomez, R., Baron, L. and Fiore-Silfvast, B. (2012). The changing field of ICTD: content analysis of research published in selected journals and conferences, 2000--2010. Proceedings of the Fifth ICTD. ACM.", "Melkote, S., and Steeves, L. (2001). Communication for development in the Third World: Theory and practice for empowerment. Sage."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2737856.2737889"}, {"title": "Learning Pairwise Neural Network Encoder for Depth Image-based 3D Model Retrieval", "authors": ["Jing Zhu\n,", "Fan Zhu\n,", "Edward K. Wong\n,", "Yi Fang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nWith the emergence of RGB-D cameras (e.g., Kinect), the sensing capability of artificial intelligence systems has been dramatically increased, and as a consequence, a wide range of depth image-based human-machine interaction applications are proposed. In design industry, a 3D model always contains abundant information, which are required for manufacture. Since depth images can be conveniently acquired, a retrieval system that can return 3D models based on depth image inputs can assist or improve the traditional product design process. In this work, we address the depth image-based 3D model retrieval problem. By extending the neural network to a neural network pair with identical output layers for objects of the same category, unified domain-invariant representations can be learned based on the low-level mismatched depth image features and 3D model features. A unique advantage of the framework is that the correspondence information between depth images and 3D models are not required, so that it can easily be generalized to large-scale databases. In order to evaluate the effectiveness of our approach, depth images (with Kinect-type noise) in the NYU Depth V2 dataset are used as queries to retrieve 3D models of the same categories in the SHREC 2014 dataset. Experimental results suggest that our approach can outperform the state-of-the-arts methods, and the paradigm that directly uses the original representations of depth images and 3D models for retrieval.", "references": ["T. Darom and Y. Keller. Scale-invariant features for 3-d mesh models. Image Processing, IEEE Transactions on, 21(5):2758--2769, 2012.", "P. Dollár and C. L. Zitnick. Structured forests for fast edge detection. In International Conference on Computer Vision, pages 1841--1848. IEEE, 2013.", "Y. Fang, J. Xie, G. Dai, M. Wang, F. Zhu, T. Xu, and E. Wong. 3d deep shape descriptor. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2319--2328, 2015."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806323"}, {"title": "Letting Users Choose Recommender Algorithms: An Experimental Study", "authors": ["Michael D. Ekstrand\n,", "Daniel Kluver\n,", "F. Maxwell Harper\n,", "Joseph A. Konstan"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nRecommender systems are not one-size-fits-all; different algorithms and data sources have different strengths, making them a better or worse fit for different users and use cases. As one way of taking advantage of the relative merits of different algorithms, we gave users the ability to change the algorithm providing their movie recommendations and studied how they make use of this power. We conducted our study with the launch of a new version of the MovieLens movie recommender that supports multiple recommender algorithms and allows users to choose the algorithm they want to provide their recommendations. We examine log data from user interactions with this new feature to under-stand whether and how users switch among recommender algorithms, and select a final algorithm to use. We also look at the properties of the algorithms as they were experienced by users and examine their relationships to user behavior. We found that a substantial portion of our user base (25%) used the recommender-switching feature. The majority of users who used the control only switched algorithms a few times, trying a few out and settling down on an algorithm that they would leave alone. The largest number of users prefer a matrix factorization algorithm, followed closely by item-item collaborative filtering; users selected both of these algorithms much more often than they chose a non-personalized mean recommender. The algorithms did produce measurably different recommender lists for the users in the study, but these differences were not directly predictive of user choice.", "references": ["Balabanović, M. and Shoham, Y. 1997. Fab: content-based, collaborative recommendation. Commun. ACM. 40, 3 (1997), 66--72.", "Burke, R. 2002. Hybrid Recommender Systems: Survey and Experiments. User Modeling and User-Adapted Interaction. 12, 4 (Nov. 2002), 331--370.", "Chang, S., Harper, F.M. and Terveen, L. 2015. Using Groups of Items for Preference Elicitation in Recommender Systems. In Proc. ACM CSCW '15 (2015), 1258--1269."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800195"}, {"title": "Learning Semantic Correlation of Web Images and Text with Mixture of Local Linear Mappings", "authors": ["Youtian Du\n,", "Kai Yang"], "publication": "MM '15: Proceedings of the 23rd ACM international conference on Multimedia", "abstract": "ABSTRACT\nThis paper proposes a new approach, called mixture of local linear mappings (MLLM), to the modeling of semantic correlation between web images and text. We consider that close examples generally represent a uniform concept and can be supposed to be locally transformed based on a linear mapping into the feature space of another modality. Thus, we use a mixture of local linear transformations, each local component being constrained by a neighborhood model into a finite local space, instead of a more complex nonlinear one. To handle the sparseness of data representation, we introduce the constraints of sparseness and non-negativeness into the approach. MLLM is with good interpretability due to its explicit closed form and concept-related local components, and it avoids the determination of capacity that is often considered for nonlinear transformations. Experimental results demonstrate the effectiveness of the proposed approach.", "references": ["J. Jeon, V. Lavrenko, and R. Manmatha. Automatic image annotation and retrieval using cross-media relevance models. In ACM SIGIR, pages 119--126. ACM, 2003.", "L. Wu, R. Jin, and A.K.Jain. Tag completion for image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(3):716--727, 2013.", "M. Wang, B. Ni, X. Hua, and T. Chua. Assistive tagging: a survey of multimedia tagging with human-computer joint exploration. ACM Computing Surveys, 44(4):25--25, August 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2733373.2806331"}, {"title": "Exact Top-k Nearest Keyword Search in Large Networks", "authors": ["Minhao Jiang\n,", "Ada Wai-Chee Fu\n,", "Raymond Chi-Wing Wong"], "publication": "SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data", "abstract": "ABSTRACT\nTop-k nearest keyword search has been of interest because of applications ranging from road network location search by keyword to search of information on an RDF repository. We consider the evaluation of a query with a given vertex and a keyword, and the problem is to find a set of $k$ nearest vertices that contain the keyword. The known algorithms for handling this problem only give approximate answers. In this paper, we propose algorithms for top-k nearest keyword search that provide exact solutions and which handle networks of very large sizes. We have also verified the performance of our solutions compared with the best-known approximation algorithms with experiments on real datasets.", "references": ["I. Abraham, D. Delling, A. V. Goldberg, and R. F. F. Werneck. A hub-based labeling algorithm for shortest paths in road networks. In SEA, pages 230--241, 2011.", "T. Akiba, Y. Iwata, and Y. Yoshida. Fast exact shortest-path distance queries on large networks by pruned landmark labeling. In SIGMOD, 2013.", "T. Akiba, Y. Iwata, and Y. Yoshida. Dynamic and historical shortest-path distance queries on large evolving networks by pruned landmark labeling. In WWW, pages 237--248, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2723372.2749447"}, {"title": "Tackling the Achilles Heel of Social Networks: Influence Propagation based Language Model Smoothing", "authors": ["Rui Yan\n,", "Ian E.H. Yen\n,", "Cheng-Te Li\n,", "Shiqi Zhao\n,", "Xiaohua Hu"], "publication": "WWW '15: Proceedings of the 24th International Conference on World Wide Web", "abstract": "ABSTRACT\nOnline social networks nowadays enjoy their worldwide prosperity, as they have revolutionized the way for people to discover, to share, and to distribute information. With millions of registered users and the proliferation of user-generated contents, the social networks become \"giants\", likely eligible to carry on any research tasks. However, the giants do have their Achilles Heel: extreme data sparsity. Compared with the massive data over the whole collection, individual posting documents, (e.g., a microblog less than 140 characters), seem to be too sparse to make a difference under various research scenarios, while actually they are different. In this paper we propose to tackle the Achilles Heel of social networks by smoothing the language model via influence propagation. We formulate a socialized factor graph model, which utilizes both the textual correlations between document pairs and the socialized augmentation networks behind the documents, such as user relationships and social interactions. These factors are modeled as attributes and dependencies among documents and their corresponding users. An efficient algorithm is designed to learn the proposed factor graph model. Finally we propagate term counts to smooth documents based on the estimated influence. Experimental results on Twitter and Weibo datasets validate the effectiveness of the proposed model. By leveraging the smoothed language model with social factors, our approach obtains significant improvement over several alternative methods on both intrinsic and extrinsic evaluations measured in terms of perplexity, nDCG and MAP results.", "references": ["P. Analytics. Twitter study--august 2009. 15, 2009.", "L. Bottou. Online learning and stochastic approximations. On-line learning in neural networks, 17:9, 1998.", "M. A. Carreira-Perpinan and G. E. Hinton. On contrastive divergence learning. In Artificial Intelligence and Statistics, volume 2005, page 17, 2005."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2736277.2741673"}, {"title": "BD-CATS: big data clustering at trillion particle scale", "authors": ["Md. Mostofa Ali Patwary\n,", "Suren Byna\n,", "Nadathur Rajagopalan Satish\n,", "Narayanan Sundaram\n,", "Zarija Lukić\n,", "Vadim Roytershteyn\n,"], "publication": "SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis", "abstract": "ABSTRACT\nModern cosmology and plasma physics codes are now capable of simulating trillions of particles on petascale systems. Each timestep output from such simulations is on the order of 10s of TBs. Summarizing and analyzing raw particle data is challenging, and scientists often focus on density structures, whether in the real 3D space, or a high-dimensional phase space. In this work, we develop a highly scalable version of the clustering algorithm Dbscan, and apply it to the largest datasets produced by state-of-the-art codes. Our system, called Bd-Cats, is the first one capable of performing end-to-end analysis at trillion particle scale (including: loading the data, geometric partitioning, computing kd-trees, performing clustering analysis, and storing the results). We show analysis of 1.4 trillion particles from a plasma physics simulation, and a 10,2403 particle cosmological simulation, utilizing ~100,000 cores in 30 minutes. Bd-Cats is helping infer mechanisms behind particle acceleration in plasma physics and holds promise for qualitatively superior clustering in cosmology. Both of these results were previously intractable at the trillion particle scale.", "references": ["Magnetospheric multiscale (mms) mission. http://mms.gsfc.nasa.gov/.", "M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. Optics: ordering points to identify the clustering structure. In Proceedings of the 1999 ACM SIGMOD, pages 49--60, New York, NY, USA, 1999. ACM.", "D. Arlia and M. Coppola. Experiments in parallel clustering with DBSCAN. In Euro-Par 2001 Parallel Processing, pages 326--331. Springer, LNCS, 2001."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2807591.2807616"}, {"title": "Complex event extraction from real-time news streams", "authors": ["Alexandra La Fleur\n,", "Kia Teymourian\n,", "Adrian Paschke"], "publication": "SEMANTICS '15: Proceedings of the 11th International Conference on Semantic Systems", "abstract": "ABSTRACT\nInformation overload on news data is a known problem these days. People and organizations have an increasing demand for extraction of relevant information from massive amounts of news data arriving in real-time as news streams. In this paper, we present a novel approach for real-time extraction of news, based on user specifications and by using background knowledge from specific news domains. We create a powerful filtering service which limits the news data to the concrete and essential preferences of a user. In our approach, enrichment of real-time news with background knowledge is a preprocessing step. We use a Complex Event Processor to detect complex events from the enriched articles and match them to the user specified query. Each time a news article is matched, its result is notified to the user immediately. Our experimental evaluation shows that our approach is feasible for detecting news in real-time with high precision and recall.", "references": ["N. Bansal and N. Koudas. Blogscope: A system for online analysis of high volume text streams. In Proceedings of the 33rd International Conference on Very Large Data Bases, VLDB '07. VLDB Endowment, 2007.", "I. Cantador, A. Bellogín, and P. Castells. News@hand: A semantic web approach to recommending news. In Proceedings of the 5th International Conference on Adaptive Hypermedia and Adaptive Web-Based Systems, AH '08. Springer-Verlag, 2008.", "I. Cantador, A. Bellogín, and P. Castells. Ontology-based personalised and context-aware recommendations of news items. In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 01, WI-IAT '08. IEEE Computer Society, 2008."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2814864.2814870"}, {"title": "Discovering the influence of socioeconomic factors on online game behaviors", "authors": ["Min Zhan\n,", "Y. Dora Cai\n,", "Dahai Guo"], "publication": "XSEDE '15: Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure", "abstract": "ABSTRACT\nWith the rapid growth of popularity of online games in recent years, research has increased the knowledge about game playing behaviors and some demographic correlates, such as age and gender. Contributing to this line of research, we further examined the associations of socioeconomic factors (education, employment, income, and poverty status) and demographic characteristics (age, gender, and race/ethnicity) with online gaming behaviors (player count, total game sessions, total actions taken, and maximum level reached). We focused on one form of online games, Massively Multiplayer Online Games (MMOGs), which has received much attention recently. Analyses were conducted by extracting and linking the related data from the EverQuest II game logs, a popular form of MMOGs, and the summarized U.S. Census data for the zip-code areas of players from the state of Illinois (n=495). This study was performed on Gordon, a supercomputer hosted at San Diego Supercomputer center.\nResults from multiple regression analyses indicated positive associations between education rate (Bachelor's degree or above) and employment rate (for 16 years or older) at the zip-code level with game playing behaviors. The impact of median income on gaming behaviors appeared to operate through education and employment. Although male players outnumbered female players, female players tended to play more games sessions and take more actions. Results also indicated that a higher percentage of white population in a geography area seemed to be negatively related to game playing activities. These study findings provides valuable information and highlight the importance of further research and theoretical development in this area.", "references": ["Anderson, C., & Bushman, B. (2001). Effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, and prosocial behavior: A meta-analytic review of the scientific literature. Psychological Science, 12, 353--359.", "Anderson, C., & Dill, K. (2000). Video games and aggressive thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 78, 772--790.", "Becker, G. S. (1993). Human capital: a theoretical and empirical analysis, with special reference to education. Chicago: University of Chicago Press."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792745.2792752"}, {"title": "Scalable Recommender Systems: Where Machine Learning Meets Search", "authors": ["Si ying Diana Hu\n,", "Joaquin Delgado"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nThis tutorial provides an overview of how search engines and machine learning techniques can be tightly coupled to address the need for building scalable recommender or other prediction-based systems. In particular, we will review ML-Scoring, an open source framework, created by the authors that tightly integrates machine-learning models into Elasticsearch, a popular search engine that is distributed, scalable, highly available with real-time search and analytic functionalities. The fundamentals and basic methods in information retrieval and machine learning will be explained. Accompanying the theory, practical examples will illustrate their applications with a series of hands-on exercises. These will demonstrate how to load a dataset into Elasticsearch, how to train a model in an external software framework such as Spark, Weka, or R, and finally how to load the trained models as a ML-Scoring plugins created for Elasticsearch.", "references": ["Baeza-Yates, R., & Ribeiro-Neto, B. 2011. Modern information retrieval. New York: ACM press.", "Chirita, P. A., Firan, C. S., & Nejdl, W. 2007. Personalized query expansion for the web. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval (pp. 7--14). ACM.", "Croft, W. B., Metzler, D., & Strohman, T. 2010. Search engines: Information retrieval in practice. Reading: Addison-Wesley."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2792842"}, {"title": "Improving Throughput of a Pipeline Model Indexer", "authors": ["Matt Crane\n,", "Andrew Trotman\n,", "David Eyers"], "publication": "ADCS '15: Proceedings of the 20th Australasian Document Computing Symposium", "abstract": "ABSTRACT\nThere are many competing models for the indexing process of an information retrieval system, one of which is a pipeline based model. Information retrieval is also an inherently parallel process, indexing one document is independent of another document. A pipeline model allows for easy experimentation on the parallelism within an indexer. In this paper we investigate areas within a pipeline where indexing throughput can be increased, as well as exploiting the inherent parallelism of indexing.", "references": ["J. Dean and S. Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. Commun. ACM, 51(1):107--113.", "T. Elsayed, F. Ture, and J. Lin. Brute-Force Approaches to Batch Retrieval: Scalable Indexing with MapReduce, or Why Bother? Technical report, HCIL-2010-23, University of Maryland.", "S. Heinz and J. Zobel. Efficient Single-Pass Index Construction for Text Databases. JASIST, 54(8):713--729."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2838931.2838943"}, {"title": "Evaluation Data and Benchmarks for Cascaded Speech Recognition and Entity Extraction", "authors": ["Liyuan Zhou\n,", "Hanna Suominen\n,", "Leif Hanlen"], "publication": "SLAM '15: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia", "abstract": "ABSTRACT\nDuring clinical handover, clinicians exchange information about the patients and the state of clinical management. To improve care safety and quality, both handover and its documentation have been standardized. Speech recognition and entity extraction provide a way to help health service providers to follow these standards by implementing the handover process as a structured form, whose headings guide the handover narrative, and the documentation process as proofing and sign-off of the automatically filled-out form. In this paper, we evaluate such systems. The form considers the sections of Handover nurse, Patient introduction, My shift, Medication, Appointments, and Future care, divided in 49 mutually exclusive headings to fill out with speech recognized and extracted entities. Our system correctly recognizes 10,244 out of 14,095 spoken words and regardless of 6,692 erroneous words, its error percentage is significantly smaller than for systems submitted to the CLEF eHealth Evaluation Lab 2015. In the extraction of 35 entities with training data (i.e., 14 headings were not present in the 101 expert-annotated training documents with 8,487 words in total), the system correctly extracts 2,375 out of 3,793 words in 50 test documents after calibration on 3,937 words in 50 validation documents. This translates to over 90% F1 in extracting information for the patient's age, current bed, current room, and given name and over 70% F1 for patient's admission reason/diagnosis and last name. F1 for filtering out irrelevant information is 78%. We have made the data publicly available for 201 handover cases together with processing results and code and proposed the extraction task for CLEF eHealth 2016.", "references": ["Sherlock, C. The patient handover: a study of its form, function and efficiency. Nurs Stand. 9 (Sep 1995), 33--36.", "Matic, J., Davidson, P., & Salamonson, Y. Review: bringing patient safety to the forefront through structured computerisation during clinical handover. J Clin Nurs. 20 (Jan 2011),184--189.", "Australian Commission on Safety and Quality in Healthcare (ACSQHC). Standard 6: clinical handover. In National Safety and Quality Health Standards, ACSQHC, Sydney, NSW, 44--47."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2802558.2814646"}, {"title": "Open Source Tools Applied to Text Data Recovery in Big Data Environments", "authors": ["Brunno F. M. Attorre\n,", "Leandro A. Silva"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nAs the volume of data on the web continue to increase, it is getting more challenging for the search mechanism to find with a high precision rate what the users want to find. As a solution to improve these results, the development of a recommender engine, based on the content of the documents, would prove itself very useful. In this context, this research has the objective to show how the current search and indexing tools could be improved with recommendation, Machine Learning and textual analysis algorithms. The idea behind these project would be to, based on the content of the documents recovered in the search, find similar documents using most of the Open Source technology we have available right now.", "references": ["I. Antonellis, E. Gallopoulos, I. Antonellis, and E. Gallopoulos. Exploring term document matrices from matrix models in text mining, 2006.", "R. Berman and Z. Katona. The role of search engine optimization in search marketing. Marketing Science, 32(4):644-651, 2013.", "S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In Seventh International World-Wide Web Conference (WWW 1998), 1998."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814137"}, {"title": "Recommending Tours and Places-of-Interest based on User Interests from Geo-tagged Photos", "authors": ["Kwan Hui Lim"], "publication": "SIGMOD '15 PhD Symposium: Proceedings of the 2015 ACM SIGMOD on PhD Symposium", "abstract": "ABSTRACT\nPhoto sharing sites like Flickr and Instagram have grown increasingly popular in recent years, resulting in a large amount of uploaded photos. In addition, these photos contain useful meta-data such as the taken time and geo-location. Using such geo-tagged photos and Wikipedia, we propose an approach for recommending tours based on user interests from his/her visit history. We evaluate our proposed approach on a Flickr dataset comprising three cities and find that our approach is able to recommend tours that are more popular and comprise more places/points-of-interest, compared to various baselines. More importantly, we find that our recommended tours reflect the ground truth of real-life tours taken by users, based on measures of recall, precision and F1-score.", "references": ["J. Bao, Y. Zheng, and M. F. Mokbel. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proc. of SIGSPATIAL'12, pages 199--208, 2012.", "R. Baraglia, C. I. Muntean, F. M. Nardini, and F. Silvestri. Learnext: learning to predict tourists movements. In Proc. of CIKM'13, 2013.", "M. Berkelaar, K. Eikland, and P. Notebaert. lpsolve: Open source (mixed-integer) linear programming system, 2004. http://lpsolve.sourceforge.net/."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744680.2744693"}, {"title": "User Satisfaction of the Website for National Center for Health Communication and Education in Vietnam: An Application of IS Success Model", "authors": ["Ming-Hsiung Hsiao\n,", "Tran Quang Mai\n,", "Nguyen Thi My Loc\n,", "Yung-Ting Lee"], "publication": "ICEC '15: Proceedings of the 17th International Conference on Electronic Commerce 2015", "abstract": "ABSTRACT\nWebsite of National Center for Health Communication and Education (CHCE), Vietnam, has been designed and used from July 2006. The website is an important information channel which provides quickly, accurately and timely information on food safety, hygiene, and disease prevention, and also provides necessary documents, data and information for managers, policy makers and researchers in the health sector. This study aimed to assess the satisfaction of the CHCE website users and propose solutions to improve the quality of the website to meet the needs of users. For this purpose, this study built a research model by applying IS Success Model, and conducted a survey by delivering questionnaires to the users from CHCE in 9 provinces and one Institute of MOH in Vietnam. The results show that three factors (information quality, system quality, system design quality) have positive effect on user satisfaction of using CHCE website. Moreover, users care more about quality systems and quality information. In other words, users are more interested in what information and knowledge the website provides, and how good is its information quality; e.g., reliable or useful, for organization management or for people's everyday life.", "references": ["Bailey J. and Pearson S. 1983. Development of a tool for measurement and analyzing computer user satisfaction. Management Science, 29(5), 530--545.", "Baroudi, J.J. and Orlikowski, W.J. 1988. A short measure of user information satisfaction: A psychometric evaluation and notes on use. Journal of Management Information Systems, 4(4), 44--59.", "Chen L, Soliman, K.S., Mao E, and Frolick M.N. 2000. Measuring user satisfaction with data warehouses: An exploratory study. Information & Management, 37(3), 103--110."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2781562.2781568"}, {"title": "Session details: Main Track - Database, Information Retrieval, Data Mining, and Knowledge Discovery", "authors": ["Sean W. M. Siqueira\n,", "Sergio T. Carvalho"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nNo abstract available.", "references": [], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.3252430"}, {"title": "A time machine for information: looking back to look forward", "authors": ["Xin Luna Dong\n,", "Wang-Chiew Tan"], "publication": "Proceedings of the VLDB Endowment", "abstract": "Abstract\nWith the abundant availability of information one can mine from the Web today, there is increasing interest to develop a complete understanding of the history of an entity (i.e., a person, a company, a music genre, a country, etc.) (see, for example, [7, 9, 10, 11]) and to depict trends over time [5, 12, 13]. This, however, remains a largely difficult and manual task despite more than a couple of decades of research in the areas of temporal databases and data integration.", "references": ["K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247--1250, 2008.", "A. Doan, A. Halevy, and Z. Ives. Principles of Data Integration. Morgan Kaufmann, 2012.", "X. L. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In SIGKDD, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.14778/2824032.2824134"}, {"title": "Personalizing Search on Shared Devices", "authors": ["Ryen W. White\n,", "Ahmed Hassan Awadallah"], "publication": "SIGIR '15: Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval", "abstract": "ABSTRACT\nSearch personalization tailors the search experience to individual searchers. To do this, search engines construct interest models comprising signals from observed behavior associated with ma-chines, often via Web browser cookies or other user identifiers. However, shared device usage is common, meaning that the activities of multiple searchers may be interwoven in the interest models generated. Recent research on activity attribution has led to methods to automatically disentangle the histories of multiple searchers and correctly ascribe newly-observed search activity to the correct per-son. Building on this, we introduce attribution-based personalization (ABP), a procedure that extends traditional personalization to target individual searchers on shared devices. Activity attribution may improve personalization, but its benefits are not yet fully understood. We present an oracle study (with perfect knowledge of which searchers perform each action on each machine) to under-stand the effectiveness of ABP in predicting searchers' future interests. We utilize a large Web search log dataset containing both per-son identifiers and machine identifiers to quantify the gain in personalization performance from ABP, identify the circumstances under which ABP is most effective, and develop a classifier to determine when to apply it that yields sizable gains in personalization performance. ABP allows search providers to personalize experiences for individuals rather than targeting all users of a device collectively.", "references": ["Agichtein, E., Brill, E., and Dumais, S. (2006). Improving web search ranking by incorporating user behavior information. SIGIR, 19--26.", "Amari, S.I., Cichocki, A., and Yang, H.H. (1996). A new learning algorithm for blind signal separation. NIPS, 757--763.", "Bennett, P., Svore, K., and Dumais, S. (2010). Classification-enhanced ranking. WWW, 111--120."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2766462.2767736"}, {"title": "A Case Study in Mobile-Optimized vs. Responsive Web Application Design", "authors": ["Jay Patel\n,", "Gil Gershoni\n,", "Sanjay Krishnan\n,", "Matti Nelimarkka\n,", "Brandie Nonnecke\n,", "Ken Goldberg"], "publication": "MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct", "abstract": "ABSTRACT\nResponsive web design is being widely adopted to maintain usability across a diversity of devices and screen sizes in contrast to earlier approaches which focus only on mobile or non-mobile (desktop) devices. This paper evaluates the effectiveness of responsive web design with a specific case study, the California Report Card, an online civic engagement tool. We compare Version 1.0, a mobile-optimized design, with Version 2.0, a responsive web design and consider three hypotheses: (H1) a mobile-optimized web application will receive most of its users from mobile devices, (H2) mobile-optimized design loses engagement from non-mobile users and (H3) responsive design mitigates these losses. Our results support H2 and H3 but not H1. These results support the adoption of responsive web design to maintain access for the significant population of non-mobile (desktop) users.", "references": ["Gilbert Louis Bernstein and Scott Klemmer. 2014. Towards Responsive Retargeting of Existing Websites. In Proc. UIST'14 Adjunct. ACM, 119--120.", "Siamak Faridani, Ephrat Bitton, Kimiko Ryokai, and Ken Goldberg. 2010. Opinion space: a scalable tool for browsing online comments. In Proc. CHI. ACM.", "Google Think Insights. 2013. How to Make Your Website Work Across Multiple Devices. (December 2013)."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2786567.2787135"}, {"title": "Co-Occurrence of Design Patterns and Bad Smells in Software Systems: An Exploratory Study", "authors": ["Bruno Cardoso\n,", "Eduardo Figueiredo"], "publication": "SBSI 2015: Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1", "abstract": "ABSTRACT\nA design pattern is a general reusable solution to a recurring problem in software design. Bad smells are symptoms that may indicate something wrong in the system design or code. Therefore, design patterns and bad smells represent antagonistic structures. They are subject of recurring research and typically appear in software systems. Although design patterns represent good design, their use is often inadequate because their implementation is not always trivial or they may be unnecessarily employed. The inadequate use of design patterns may lead to a bad smell. Therefore, this paper performs an exploratory study in order to identify instances of co-occurrences of design patterns and bad smells. This study is performed over five systems and discovers some co-occurrences between design patterns and bad smells. For instance, we observed the co-occurrences of Command with God Class and Template Method with Duplicated Code. The results of this study make it possible to understand in which situations design patterns are misused or overused and establish guidelines for their better use.", "references": ["B. Cardoso and E. Figueiredo. Co-Occurrence of Design Patterns and Bad Smells in Software Systems: A Systematic Literature Review. In proc. of the Workshop on Software Modularity, 2014.", "C. Bouhours, H. Leblanc, and C. Percebois. Sharing bad practices in design to improve the use of patterns. In proc. of the Conference on Pattern Languages of Programs, 2010.", "C. Jebelean, C. Chirila, and V. Cretu. A Logic Based Approach to Locate Composite Refactoring Opportunities in Object-Oriented Code. In Int'l Conf. on Automation Quality and Testing Robotics, vol. 3, p. 1-6, 2010."], "doi_url": "https://dl.acm.org/doi/abs/10.5555/2814058.2814114"}, {"title": "A Collective Bayesian Poisson Factorization Model for Cold-start Local Event Recommendation", "authors": ["Wei Zhang\n,", "Jianyong Wang"], "publication": "KDD '15: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "abstract": "ABSTRACT\nEvent-based social networks (EBSNs), in which organizers publish events to attract other users in local city to attend offline, emerge in recent years and grow rapidly. Due to the large volume of events in EBSNs, event recommendation is essential. A few recent works focus on this task, while almost all the methods need that each event to be recommended should have been registered by some users to attend. Thus they ignore two essential characteristics of events in EBSNs: (1) a large number of new events will be published every day which means many events have few participants in the beginning, (2) events have life cycles which means outdated events should not be recommended. Overall, event recommendation in EBSNs inevitably faces the cold-start problem.\nIn this work, we address the new problem of cold-start local event recommendation in EBSNs. We propose a collective Bayesian Poisson factorization (CBPF) model for handling this problem. CBPF takes recently proposed Bayesian Poisson factorization as its basic unit to model user response to events, social relation, and content text separately. Then it further jointly connects these units by the idea of standard collective matrix factorization model. Moreover, in our model event textual content, organizer, and location information are utilized to learn representation of cold-start events for predicting user response to them. Besides, an efficient coordinate ascent algorithm is adopted to learn the model. We conducted comprehensive experiments on real datasets crawled from EBSNs and the results demonstrate our proposed model is effective and outperforms several alternative methods.", "references": ["N. Aizenberg, Y. Koren, and O. Somekh. Build your own music recommender by modeling internet radio streams. In WWW, Lyon, France, April 16-20, pages 1--10, 2012.", "D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993--1022, 2003.", "K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. Collaborative personalized tweet recommendation. In SIGIR, Portland, OR, USA, August 12-16, pages 661--670, 2012."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2783258.2783336"}, {"title": "Flexible Query Answering over Graph-modeled Data", "authors": ["Antonio Maccioni"], "publication": "SIGMOD '15 PhD Symposium: Proceedings of the 2015 ACM SIGMOD on PhD Symposium", "abstract": "ABSTRACT\nThe lack of familiarity that users have with information systems has led to different flexible methods to access data (keyword search, faceted search, similarity search, etc.). Since flexible query answering techniques differ from one another, their integration in the same system is hard. Flexible query capabilities require, in fact, ad-hoc representations of the datasets, which often result in duplications and computational overhead. Moreover, if we want to query heterogeneous data sources, the problem becomes almost impossible. To address such variety in one fell swoop, we propose a meta-approach for different kinds of flexible query answering over heterogeneous data sources. We consider structured and semi-structured sources that can be modeled through graph databases. To improve the platform storing the data, we have conducted research on the representation of graph databases. In particular, we have devised a layer that compresses the graph database without having to decompress it back into the original graph before query execution.", "references": ["A. Baid, I. Rae, J. Li, A. Doan, and J. F. Naughton. Toward scalable keyword search over relational data. PVLDB, 2010.", "A.-L. Barabási and R. Albert. Emergence of scaling in random networks. Science, 286(5439):509--512, 1999.", "P. Cappellari, R. De Virgilio, A. Maccioni, and M. Roantree. A path-oriented rdf index for keyword search query processing. In DEXA, pages 366--380, 2011."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2744680.2744686"}, {"title": "It Takes Two to Tango: An Exploration of Domain Pairs for Cross-Domain Collaborative Filtering", "authors": ["Shaghayegh Sahebi\n,", "Peter Brusilovsky"], "publication": "RecSys '15: Proceedings of the 9th ACM Conference on Recommender Systems", "abstract": "ABSTRACT\nAs the heterogeneity of data sources are increasing on the web, and due to the sparsity of data in each of these data sources, cross-domain recommendation is becoming an emerging research topic in the recent years. Cross-domain collaborative filtering aims to transfer the user rating pattern from source (auxiliary) domains to a target domain for the purpose of alleviating the sparsity problem and providing better target recommendations. However, the studies so far have either focused on a limited number of domains that are assumed to be related to each other (such as books and movies), or a division of the same dataset (such as movies) into different domains based on an item characteristic (such as genre). In this paper, we study a broad set of domains and their characteristics to understand the factors that affect the success or failure of cross-domain collaborative filtering, the amount of improvement in cross-domain approaches, and the selection of best source domains for a specific target domain. We propose to use Canonical Correlation Analysis (CCA) as a significant major factor in finding the most promising source domains for a target domain, and suggest a cross-domain collaborative filtering based on CCA (CD-CCA) that proves to be successful in using the shared information between domains in the target recommendations.", "references": ["S. Berkovsky, T. Kuflik, and F. Ricci. Cross-domain mediation in collaborative filtering. In Proc. 11th int'l conference on User Modeling, UM '07, 2007.", "S. Berkovsky, T. Kuflik, and F. Ricci. Mediation of user models for enhanced personalization in recommender systems. UMUAI, 18(3), Aug. 2008.", "P. Cremonesi and M. Quadrana. Cross-domain recommendations without overlapping data: Myth or reality? In Proc. 8th ACM Conference on Recommender Systems, pages 297--300, 2014."], "doi_url": "https://dl.acm.org/doi/abs/10.1145/2792838.2800188"}, {"title": "CodeExchange: supporting reformulation of internet-scale code queries in context", "authors": ["Lee Martie\n,", "Thomas D. LaToza\n,", "André van der Hoek"], "publication": "ASE '15: Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering", "abstract": "ABSTRACT\nProgramming today regularly involves searching for source code online, whether through a general search engine such as Google or a specialized code search engine such as SearchCode, Ohloh, or GitHub. Searching typically is an iterative process, with developers adjusting the keywords they use based on the results of the previous query. However, searching in this manner is not ideal, because just using keywords places limits on what developers can express as well as the overall interaction that is required. Based on the observation that the results from one query create a context in which a next is formulated, we present CodeExchange, a new code search engine that we developed to explicitly leverage this context to support fluid, expressive reformulation of queries. We motivate the need for CodeExchange, highlight its key design decisions and overall architecture, and evaluate its use in both a field deployment and a laboratory study.", "references": ["\"Apache Lucene - Apache Solr.\" {Online}. Available: http://lucene.apache.org/solr/. {Accessed: 05-Sep-2014}.", "\"Code Search · GitHub.\" {Online}. Available: https://github.com/search. {Accessed: 05-Sep-2014}.", "\"CodeExchange.\" {Online}. Available: http://codeexchange.ics.uci.edu/. {Accessed: 05-Sep-2014}."], "doi_url": "https://dl.acm.org/doi/abs/10.1109/ASE.2015.51"}]